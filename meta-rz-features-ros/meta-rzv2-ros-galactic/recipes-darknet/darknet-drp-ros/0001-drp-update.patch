diff --git a/CMakeLists.txt b/CMakeLists.txt
new file mode 100644
index 0000000..f641c2c
--- /dev/null
+++ b/CMakeLists.txt
@@ -0,0 +1 @@
+add_subdirectory(darknet_drp_ros)
diff --git a/darknet_ros/CHANGELOG.rst b/darknet_drp_ros/CHANGELOG.rst
similarity index 100%
rename from darknet_ros/CHANGELOG.rst
rename to darknet_drp_ros/CHANGELOG.rst
diff --git a/darknet_drp_ros/CMakeLists.txt b/darknet_drp_ros/CMakeLists.txt
new file mode 100644
index 0000000..7d492da
--- /dev/null
+++ b/darknet_drp_ros/CMakeLists.txt
@@ -0,0 +1,96 @@
+cmake_minimum_required(VERSION 3.5)
+project(darknet_drp_ros)
+set(CMAKE_CXX_STANDARD 17)
+
+# Define path of darknet folder here.
+set(DARKNET_PATH ../darknet)
+#find_path(DARKNET_PATH
+#  NAMES "README.md"
+#  HINTS "${CMAKE_CURRENT_SOURCE_DIR}/../darknet/")
+#message(STATUS "Darknet path dir = ${DARKNET_PATH}")
+add_definitions(-DDARKNET_FILE_PATH="${DARKNET_PATH}")
+
+list(APPEND LIBRARIES "m")
+
+# Find rquired packeges
+find_package(OpenCV REQUIRED)
+include_directories(${OpenCV_INCLUDE_DIRS})
+
+find_package(ament_cmake REQUIRED)
+find_package(rclcpp REQUIRED)
+find_package(rclpy REQUIRED)
+find_package(rclcpp_action REQUIRED)
+find_package(std_msgs REQUIRED)
+find_package(image_transport REQUIRED)
+find_package(cv_bridge REQUIRED)
+find_package(sensor_msgs REQUIRED)
+find_package(darknet_ros_msgs REQUIRED)
+find_package(ament_index_cpp REQUIRED)
+
+set(dependencies
+    rclcpp
+    rclpy
+    rclcpp_action
+    std_msgs
+    image_transport
+    cv_bridge
+    sensor_msgs
+    darknet_ros_msgs
+    ament_index_cpp
+)
+
+# Enable OPENCV in darknet
+# add_definitions(-DOPENCV)
+add_definitions(-O4 -g)
+
+include_directories(
+  ${DARKNET_PATH}/src
+  ${DARKNET_PATH}/include
+  include
+  include/darknet_drp_ros
+  ${catkin_INCLUDE_DIRS}
+)
+
+add_executable(${PROJECT_NAME}
+    src/main.cpp
+    src/box.cpp
+    src/image.cpp
+    src/ascii.cpp
+    src/PreRuntimeV2H.cpp
+    src/MeraDrpRuntimeWrapper.cpp
+)
+ament_target_dependencies(${PROJECT_NAME} ${dependencies})
+
+target_link_libraries(${PROJECT_NAME} 
+  m
+  pthread
+  stdc++
+  ${OpenCV_LIBRARIES}
+  ${catkin_LIBRARIES}
+  ${OpenCV_LIBS}
+  mmngr
+  mmngrbuf
+  tvm_runtime
+)
+
+target_compile_definitions(${PROJECT_NAME} PRIVATE -DOPENCV)
+
+install(TARGETS ${PROJECT_NAME}
+  ARCHIVE DESTINATION lib
+  LIBRARY DESTINATION lib
+  RUNTIME DESTINATION lib/${PROJECT_NAME}
+)
+
+
+install(
+  DIRECTORY include/
+  DESTINATION include/
+  FILES_MATCHING PATTERN "*.h"
+)
+
+install(DIRECTORY launch config DESTINATION share/${PROJECT_NAME}/)
+
+ament_export_include_directories(include)
+ament_export_dependencies(${dependencies})
+
+ament_package()
diff --git a/darknet_ros/config/ros.yaml b/darknet_drp_ros/config/ros.yaml
similarity index 100%
rename from darknet_ros/config/ros.yaml
rename to darknet_drp_ros/config/ros.yaml
diff --git a/darknet_ros/config/yolov2-tiny-voc.yaml b/darknet_drp_ros/config/yolov2-tiny-voc.yaml
similarity index 100%
rename from darknet_ros/config/yolov2-tiny-voc.yaml
rename to darknet_drp_ros/config/yolov2-tiny-voc.yaml
diff --git a/darknet_ros/config/yolov2-tiny.yaml b/darknet_drp_ros/config/yolov2-tiny.yaml
similarity index 100%
rename from darknet_ros/config/yolov2-tiny.yaml
rename to darknet_drp_ros/config/yolov2-tiny.yaml
diff --git a/darknet_ros/config/yolov2-voc.yaml b/darknet_drp_ros/config/yolov2-voc.yaml
similarity index 100%
rename from darknet_ros/config/yolov2-voc.yaml
rename to darknet_drp_ros/config/yolov2-voc.yaml
diff --git a/darknet_ros/config/yolov2.yaml b/darknet_drp_ros/config/yolov2.yaml
similarity index 100%
rename from darknet_ros/config/yolov2.yaml
rename to darknet_drp_ros/config/yolov2.yaml
diff --git a/darknet_ros/config/yolov3-voc.yaml b/darknet_drp_ros/config/yolov3-voc.yaml
similarity index 100%
rename from darknet_ros/config/yolov3-voc.yaml
rename to darknet_drp_ros/config/yolov3-voc.yaml
diff --git a/darknet_ros/config/yolov3.yaml b/darknet_drp_ros/config/yolov3.yaml
similarity index 100%
rename from darknet_ros/config/yolov3.yaml
rename to darknet_drp_ros/config/yolov3.yaml
diff --git a/darknet_ros/doc/quadruped_anymal_and_person.JPG b/darknet_drp_ros/doc/quadruped_anymal_and_person.JPG
similarity index 100%
rename from darknet_ros/doc/quadruped_anymal_and_person.JPG
rename to darknet_drp_ros/doc/quadruped_anymal_and_person.JPG
diff --git a/darknet_ros/doc/test_detection.png b/darknet_drp_ros/doc/test_detection.png
similarity index 100%
rename from darknet_ros/doc/test_detection.png
rename to darknet_drp_ros/doc/test_detection.png
diff --git a/darknet_ros/doc/test_detection_anymal.png b/darknet_drp_ros/doc/test_detection_anymal.png
similarity index 100%
rename from darknet_ros/doc/test_detection_anymal.png
rename to darknet_drp_ros/doc/test_detection_anymal.png
diff --git a/darknet_drp_ros/include/builtin_fp16.h b/darknet_drp_ros/include/builtin_fp16.h
new file mode 100644
index 0000000..51465b7
--- /dev/null
+++ b/darknet_drp_ros/include/builtin_fp16.h
@@ -0,0 +1,246 @@
+/*
+ * Copyright (c) 2009-2015 by llvm/compiler-rt contributors
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ * \file builtin_fp16.h
+ * \brief Functions for conversion between fp32 and fp16, adopted from compiler-rt.
+ */
+#ifndef COMPILER_RT_BUILTIN_FP16_H_
+#define COMPILER_RT_BUILTIN_FP16_H_
+
+#ifdef _MSC_VER
+#pragma warning(disable : 4305 4805)
+#endif
+
+#include <cstdint>
+
+static inline uint32_t __clz(uint32_t x) {
+  // count leading zeros
+  int n = 32;
+  uint32_t y;
+
+  y = x >> 16;
+  if (y) {
+    n = n - 16;
+    x = y;
+  }
+  y = x >> 8;
+  if (y) {
+    n = n - 8;
+    x = y;
+  }
+  y = x >> 4;
+  if (y) {
+    n = n - 4;
+    x = y;
+  }
+  y = x >> 2;
+  if (y) {
+    n = n - 2;
+    x = y;
+  }
+  y = x >> 1;
+  if (y) return n - 2;
+  return n - x;
+}
+
+template <typename SRC_T, typename SRC_REP_T, int SRC_SIG_BITS, typename DST_T, typename DST_REP_T,
+          int DST_SIG_BITS>
+static inline DST_T __truncXfYf2__(SRC_T a) {
+  // Various constants whose values follow from the type parameters.
+  // Any reasonable optimizer will fold and propagate all of these.
+  const int srcBits = sizeof(SRC_T) * 8;
+  const int srcExpBits = srcBits - SRC_SIG_BITS - 1;
+  const int srcInfExp = (1 << srcExpBits) - 1;
+  const int srcExpBias = srcInfExp >> 1;
+
+  const SRC_REP_T srcMinNormal = SRC_REP_T(1) << SRC_SIG_BITS;
+  const SRC_REP_T srcSignificandMask = srcMinNormal - 1;
+  const SRC_REP_T srcInfinity = (SRC_REP_T)srcInfExp << SRC_SIG_BITS;
+  const SRC_REP_T srcSignMask = SRC_REP_T(1) << (SRC_SIG_BITS + srcExpBits);
+  const SRC_REP_T srcAbsMask = srcSignMask - 1;
+  const SRC_REP_T roundMask = (SRC_REP_T(1) << (SRC_SIG_BITS - DST_SIG_BITS)) - 1;
+  const SRC_REP_T halfway = SRC_REP_T(1) << (SRC_SIG_BITS - DST_SIG_BITS - 1);
+  const SRC_REP_T srcQNaN = SRC_REP_T(1) << (SRC_SIG_BITS - 1);
+  const SRC_REP_T srcNaNCode = srcQNaN - 1;
+
+  const int dstBits = sizeof(DST_T) * 8;
+  const int dstExpBits = dstBits - DST_SIG_BITS - 1;
+  const int dstInfExp = (1 << dstExpBits) - 1;
+  const int dstExpBias = dstInfExp >> 1;
+
+  const int underflowExponent = srcExpBias + 1 - dstExpBias;
+  const int overflowExponent = srcExpBias + dstInfExp - dstExpBias;
+  const SRC_REP_T underflow = (SRC_REP_T)underflowExponent << SRC_SIG_BITS;
+  const SRC_REP_T overflow = (SRC_REP_T)overflowExponent << SRC_SIG_BITS;
+
+  const DST_REP_T dstQNaN = DST_REP_T(1) << (DST_SIG_BITS - 1);
+  const DST_REP_T dstNaNCode = dstQNaN - 1;
+
+  // Break a into a sign and representation of the absolute value
+  union SrcExchangeType {
+    SRC_T f;
+    SRC_REP_T i;
+  };
+  SrcExchangeType src_rep;
+  src_rep.f = a;
+  const SRC_REP_T aRep = src_rep.i;
+  const SRC_REP_T aAbs = aRep & srcAbsMask;
+  const SRC_REP_T sign = aRep & srcSignMask;
+  DST_REP_T absResult;
+
+  if (aAbs - underflow < aAbs - overflow) {
+    // The exponent of a is within the range of normal numbers in the
+    // destination format.  We can convert by simply right-shifting with
+    // rounding and adjusting the exponent.
+    absResult = aAbs >> (SRC_SIG_BITS - DST_SIG_BITS);
+    absResult -= (DST_REP_T)(srcExpBias - dstExpBias) << DST_SIG_BITS;
+
+    const SRC_REP_T roundBits = aAbs & roundMask;
+    // Round to nearest
+    if (roundBits > halfway) absResult++;
+    // Ties to even
+    else if (roundBits == halfway)
+      absResult += absResult & 1;
+  } else if (aAbs > srcInfinity) {
+    // a is NaN.
+    // Conjure the result by beginning with infinity, setting the qNaN
+    // bit and inserting the (truncated) trailing NaN field.
+    absResult = (DST_REP_T)dstInfExp << DST_SIG_BITS;
+    absResult |= dstQNaN;
+    absResult |= ((aAbs & srcNaNCode) >> (SRC_SIG_BITS - DST_SIG_BITS)) & dstNaNCode;
+  } else if (aAbs >= overflow) {
+    // a overflows to infinity.
+    absResult = (DST_REP_T)dstInfExp << DST_SIG_BITS;
+  } else {
+    // a underflows on conversion to the destination type or is an exact
+    // zero.  The result may be a denormal or zero.  Extract the exponent
+    // to get the shift amount for the denormalization.
+    const int aExp = aAbs >> SRC_SIG_BITS;
+    const int shift = srcExpBias - dstExpBias - aExp + 1;
+
+    const SRC_REP_T significand = (aRep & srcSignificandMask) | srcMinNormal;
+
+    // Right shift by the denormalization amount with sticky.
+    if (shift > SRC_SIG_BITS) {
+      absResult = 0;
+    } else {
+      const bool sticky = significand << (srcBits - shift);
+      SRC_REP_T denormalizedSignificand = significand >> shift | sticky;
+      absResult = denormalizedSignificand >> (SRC_SIG_BITS - DST_SIG_BITS);
+      const SRC_REP_T roundBits = denormalizedSignificand & roundMask;
+      // Round to nearest
+      if (roundBits > halfway) absResult++;
+      // Ties to even
+      else if (roundBits == halfway)
+        absResult += absResult & 1;
+    }
+  }
+
+  // Apply the signbit to (DST_T)abs(a).
+  const DST_REP_T result = absResult | sign >> (srcBits - dstBits);
+  union DstExchangeType {
+    DST_T f;
+    DST_REP_T i;
+  };
+  DstExchangeType dst_rep;
+  dst_rep.i = result;
+  return dst_rep.f;
+}
+
+template <typename SRC_T, typename SRC_REP_T, int SRC_SIG_BITS, typename DST_T, typename DST_REP_T,
+          int DST_SIG_BITS>
+static inline DST_T __extendXfYf2__(SRC_T a) {
+  // Various constants whose values follow from the type parameters.
+  // Any reasonable optimizer will fold and propagate all of these.
+  const int srcBits = sizeof(SRC_T) * 8;
+  const int srcExpBits = srcBits - SRC_SIG_BITS - 1;
+  const int srcInfExp = (1 << srcExpBits) - 1;
+  const int srcExpBias = srcInfExp >> 1;
+
+  const SRC_REP_T srcMinNormal = SRC_REP_T(1) << SRC_SIG_BITS;
+  const SRC_REP_T srcInfinity = (SRC_REP_T)srcInfExp << SRC_SIG_BITS;
+  const SRC_REP_T srcSignMask = SRC_REP_T(1) << (SRC_SIG_BITS + srcExpBits);
+  const SRC_REP_T srcAbsMask = srcSignMask - 1;
+  const SRC_REP_T srcQNaN = SRC_REP_T(1) << (SRC_SIG_BITS - 1);
+  const SRC_REP_T srcNaNCode = srcQNaN - 1;
+
+  const int dstBits = sizeof(DST_T) * 8;
+  const int dstExpBits = dstBits - DST_SIG_BITS - 1;
+  const int dstInfExp = (1 << dstExpBits) - 1;
+  const int dstExpBias = dstInfExp >> 1;
+
+  const DST_REP_T dstMinNormal = DST_REP_T(1) << DST_SIG_BITS;
+
+  // Break a into a sign and representation of the absolute value
+  union SrcExchangeType {
+    SRC_T f;
+    SRC_REP_T i;
+  };
+  SrcExchangeType src_rep;
+  src_rep.f = a;
+  const SRC_REP_T aRep = src_rep.i;
+  const SRC_REP_T aAbs = aRep & srcAbsMask;
+  const SRC_REP_T sign = aRep & srcSignMask;
+  DST_REP_T absResult;
+
+  // If sizeof(SRC_REP_T) < sizeof(int), the subtraction result is promoted
+  // to (signed) int.  To avoid that, explicitly cast to SRC_REP_T.
+  if ((SRC_REP_T)(aAbs - srcMinNormal) < srcInfinity - srcMinNormal) {
+    // a is a normal number.
+    // Extend to the destination type by shifting the significand and
+    // exponent into the proper position and rebiasing the exponent.
+    absResult = (DST_REP_T)aAbs << (DST_SIG_BITS - SRC_SIG_BITS);
+    absResult += (DST_REP_T)(dstExpBias - srcExpBias) << DST_SIG_BITS;
+  }
+
+  else if (aAbs >= srcInfinity) {
+    // a is NaN or infinity.
+    // Conjure the result by beginning with infinity, then setting the qNaN
+    // bit (if needed) and right-aligning the rest of the trailing NaN
+    // payload field.
+    absResult = (DST_REP_T)dstInfExp << DST_SIG_BITS;
+    absResult |= (DST_REP_T)(aAbs & srcQNaN) << (DST_SIG_BITS - SRC_SIG_BITS);
+    absResult |= (DST_REP_T)(aAbs & srcNaNCode) << (DST_SIG_BITS - SRC_SIG_BITS);
+  } else if (aAbs) {
+    // a is denormal.
+    // renormalize the significand and clear the leading bit, then insert
+    // the correct adjusted exponent in the destination type.
+    const int scale = __clz(aAbs) - __clz(srcMinNormal);
+    absResult = (DST_REP_T)aAbs << (DST_SIG_BITS - SRC_SIG_BITS + scale);
+    absResult ^= dstMinNormal;
+    const int resultExponent = dstExpBias - srcExpBias - scale + 1;
+    absResult |= (DST_REP_T)resultExponent << DST_SIG_BITS;
+  } else {
+    // a is zero.
+    absResult = 0;
+  }
+
+  // Apply the signbit to (DST_T)abs(a).
+  const DST_REP_T result = absResult | (DST_REP_T)sign << (dstBits - srcBits);
+  union DstExchangeType {
+    DST_T f;
+    DST_REP_T i;
+  };
+  DstExchangeType dst_rep;
+  dst_rep.i = result;
+  return dst_rep.f;
+}
+
+#endif  // COMPILER_RT_BUILTIN_FP16_H_
diff --git a/darknet_drp_ros/include/dlpack/dlpack.h b/darknet_drp_ros/include/dlpack/dlpack.h
new file mode 100644
index 0000000..06a3625
--- /dev/null
+++ b/darknet_drp_ros/include/dlpack/dlpack.h
@@ -0,0 +1,229 @@
+/*!
+ *  Copyright (c) 2017 by Contributors
+ * \file dlpack.h
+ * \brief The common header of DLPack.
+ */
+#ifndef DLPACK_DLPACK_H_
+#define DLPACK_DLPACK_H_
+
+/**
+ * \brief Compatibility with C++
+ */
+#ifdef __cplusplus
+#define DLPACK_EXTERN_C extern "C"
+#else
+#define DLPACK_EXTERN_C
+#endif
+
+/*! \brief The current version of dlpack */
+#define DLPACK_VERSION 70
+
+/*! \brief The current ABI version of dlpack */
+#define DLPACK_ABI_VERSION 1
+
+/*! \brief DLPACK_DLL prefix for windows */
+#ifdef _WIN32
+#ifdef DLPACK_EXPORTS
+#define DLPACK_DLL __declspec(dllexport)
+#else
+#define DLPACK_DLL __declspec(dllimport)
+#endif
+#else
+#define DLPACK_DLL
+#endif
+
+#include <stdint.h>
+#include <stddef.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+/*!
+ * \brief The device type in DLDevice.
+ */
+#ifdef __cplusplus
+typedef enum : int32_t {
+#else
+typedef enum {
+#endif
+  /*! \brief CPU device */
+  kDLCPU = 1,
+  /*! \brief CUDA GPU device */
+  kDLCUDA = 2,
+  /*!
+   * \brief Pinned CUDA CPU memory by cudaMallocHost
+   */
+  kDLCUDAHost = 3,
+  /*! \brief OpenCL devices. */
+  kDLOpenCL = 4,
+  /*! \brief Vulkan buffer for next generation graphics. */
+  kDLVulkan = 7,
+  /*! \brief Metal for Apple GPU. */
+  kDLMetal = 8,
+  /*! \brief Verilog simulator buffer */
+  kDLVPI = 9,
+  /*! \brief ROCm GPUs for AMD GPUs */
+  kDLROCM = 10,
+  /*!
+   * \brief Pinned ROCm CPU memory allocated by hipMallocHost
+   */
+  kDLROCMHost = 11,
+  /*!
+   * \brief Reserved extension device type,
+   * used for quickly test extension device
+   * The semantics can differ depending on the implementation.
+   */
+  kDLExtDev = 12,
+  /*!
+   * \brief CUDA managed/unified memory allocated by cudaMallocManaged
+   */
+  kDLCUDAManaged = 13,
+  /*!
+   * \brief Unified shared memory allocated on a oneAPI non-partititioned
+   * device. Call to oneAPI runtime is required to determine the device
+   * type, the USM allocation type and the sycl context it is bound to.
+   *
+   */
+  kDLOneAPI = 14,
+  /*! \brief GPU support for next generation WebGPU standard. */
+  kDLWebGPU = 15,
+  /*! \brief Qualcomm Hexagon DSP */
+  kDLHexagon = 16,
+} DLDeviceType;
+
+/*!
+ * \brief A Device for Tensor and operator.
+ */
+typedef struct {
+  /*! \brief The device type used in the device. */
+  DLDeviceType device_type;
+  /*!
+   * \brief The device index.
+   * For vanilla CPU memory, pinned memory, or managed memory, this is set to 0.
+   */
+  int32_t device_id;
+} DLDevice;
+
+/*!
+ * \brief The type code options DLDataType.
+ */
+typedef enum {
+  /*! \brief signed integer */
+  kDLInt = 0U,
+  /*! \brief unsigned integer */
+  kDLUInt = 1U,
+  /*! \brief IEEE floating point */
+  kDLFloat = 2U,
+  /*!
+   * \brief Opaque handle type, reserved for testing purposes.
+   * Frameworks need to agree on the handle data type for the exchange to be well-defined.
+   */
+  kDLOpaqueHandle = 3U,
+  /*! \brief bfloat16 */
+  kDLBfloat = 4U,
+  /*!
+   * \brief complex number
+   * (C/C++/Python layout: compact struct per complex number)
+   */
+  kDLComplex = 5U,
+} DLDataTypeCode;
+
+/*!
+ * \brief The data type the tensor can hold. The data type is assumed to follow the
+ * native endian-ness. An explicit error message should be raised when attempting to
+ * export an array with non-native endianness
+ *
+ *  Examples
+ *   - float: type_code = 2, bits = 32, lanes=1
+ *   - float4(vectorized 4 float): type_code = 2, bits = 32, lanes=4
+ *   - int8: type_code = 0, bits = 8, lanes=1
+ *   - std::complex<float>: type_code = 5, bits = 64, lanes = 1
+ */
+typedef struct {
+  /*!
+   * \brief Type code of base types.
+   * We keep it uint8_t instead of DLDataTypeCode for minimal memory
+   * footprint, but the value should be one of DLDataTypeCode enum values.
+   * */
+  uint8_t code;
+  /*!
+   * \brief Number of bits, common choices are 8, 16, 32.
+   */
+  uint8_t bits;
+  /*! \brief Number of lanes in the type, used for vector types. */
+  uint16_t lanes;
+} DLDataType;
+
+/*!
+ * \brief Plain C Tensor object, does not manage memory.
+ */
+typedef struct {
+  /*!
+   * \brief The data pointer points to the allocated data. This will be CUDA
+   * device pointer or cl_mem handle in OpenCL. It may be opaque on some device
+   * types. This pointer is always aligned to 256 bytes as in CUDA. The
+   * `byte_offset` field should be used to point to the beginning of the data.
+   *
+   * Note that as of Nov 2021, multiply libraries (CuPy, PyTorch, TensorFlow,
+   * TVM, perhaps others) do not adhere to this 256 byte aligment requirement
+   * on CPU/CUDA/ROCm, and always use `byte_offset=0`.  This must be fixed
+   * (after which this note will be updated); at the moment it is recommended
+   * to not rely on the data pointer being correctly aligned.
+   *
+   * For given DLTensor, the size of memory required to store the contents of
+   * data is calculated as follows:
+   *
+   * \code{.c}
+   * static inline size_t GetDataSize(const DLTensor* t) {
+   *   size_t size = 1;
+   *   for (tvm_index_t i = 0; i < t->ndim; ++i) {
+   *     size *= t->shape[i];
+   *   }
+   *   size *= (t->dtype.bits * t->dtype.lanes + 7) / 8;
+   *   return size;
+   * }
+   * \endcode
+   */
+  void* data;
+  /*! \brief The device of the tensor */
+  DLDevice device;
+  /*! \brief Number of dimensions */
+  int32_t ndim;
+  /*! \brief The data type of the pointer*/
+  DLDataType dtype;
+  /*! \brief The shape of the tensor */
+  int64_t* shape;
+  /*!
+   * \brief strides of the tensor (in number of elements, not bytes)
+   *  can be NULL, indicating tensor is compact and row-majored.
+   */
+  int64_t* strides;
+  /*! \brief The offset in bytes to the beginning pointer to data */
+  uint64_t byte_offset;
+} DLTensor;
+
+/*!
+ * \brief C Tensor object, manage memory of DLTensor. This data structure is
+ *  intended to facilitate the borrowing of DLTensor by another framework. It is
+ *  not meant to transfer the tensor. When the borrowing framework doesn't need
+ *  the tensor, it should call the deleter to notify the host that the resource
+ *  is no longer needed.
+ */
+typedef struct DLManagedTensor {
+  /*! \brief DLTensor which is being memory managed */
+  DLTensor dl_tensor;
+  /*! \brief the context of the original host framework of DLManagedTensor in
+   *   which DLManagedTensor is used in the framework. It can also be NULL.
+   */
+  void * manager_ctx;
+  /*! \brief Destructor signature void (*)(void*) - this should be called
+   *   to destruct manager_ctx which holds the DLManagedTensor. It can be NULL
+   *   if there is no way for the caller to provide a reasonable destructor.
+   *   The destructors deletes the argument self as well.
+   */
+  void (*deleter)(struct DLManagedTensor * self);
+} DLManagedTensor;
+#ifdef __cplusplus
+}  // DLPACK_EXTERN_C
+#endif
+#endif  // DLPACK_DLPACK_H_
diff --git a/darknet_drp_ros/include/dmlc/any.h b/darknet_drp_ros/include/dmlc/any.h
new file mode 100644
index 0000000..e8d8b99
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/any.h
@@ -0,0 +1,427 @@
+/*!
+ * Copyright (c) 2016 by Contributors
+ * \file any.h
+ * \brief Container to hold any data type.
+ */
+#ifndef DMLC_ANY_H_
+#define DMLC_ANY_H_
+
+// This code need c++11 to compile
+#include <typeinfo>
+#include <type_traits>
+#include <utility>
+#include <algorithm>
+#include <cstring>
+
+#include "./base.h"
+#include "./logging.h"
+
+namespace dmlc {
+// forward declare any;
+class any;
+
+/*!
+ * Get a reference to content stored in the any as type T.
+ * This will cause an error if
+ * T does not match the type stored.
+ * This function is not part of std::any standard.
+ *
+ * \param src The source source any container.
+ * \return The reference of content
+ * \tparam T The type of the value to be fetched.
+ */
+template<typename T>
+inline T& get(any& src);  // NOLINT(*)
+
+/*!
+ * Get the const reference content stored in the any as type T.
+ * This will cause an error if
+ * T does not match the type stored.
+ * This function is not part of std::any standard.
+ *
+ * \param src The source source any container.
+ * \return The reference of content
+ * \tparam T The type of the value to be fetched.
+ */
+template<typename T>
+inline const T& get(const any& src);
+
+/*!
+ * The "unsafe" versions of get. It is required when where we know
+ * what type is stored in the any and can't use typeid() comparison,
+ * e.g., when our types may travel across different shared libraries.
+ * This function is not part of std::any standard.
+ *
+ * \param src The source source any container.
+ * \return The reference of content
+ * \tparam T The type of the value to be fetched.
+ */
+template<typename T>
+inline const T& unsafe_get(const any& src);
+
+/*!
+ * The "unsafe" versions of get. It is required when where we know
+ * what type is stored in the any and can't use typeid() comparison,
+ * e.g., when our types may travel across different shared libraries.
+ * This function is not part of std::any standard.
+ *
+ * \param src The source source any container.
+ * \return The reference of content
+ * \tparam T The type of the value to be fetched.
+ */
+template<typename T>
+inline T& unsafe_get(any& src);  // NOLINT(*)
+
+/*!
+ * \brief An any class that is compatible to std::any in c++17.
+ *
+ * \code
+ *   dmlc::any a = std::string("mydear"), b = 1;
+ *   // get reference out and add it
+ *   dmlc::get<int>(b) += 1;
+ *   // a is now string
+ *   LOG(INFO) << dmlc::get<std::string>(a);
+ *   // a is now 2, the string stored will be properly destructed
+ *   a = std::move(b);
+ *   LOG(INFO) << dmlc::get<int>(a);
+ * \endcode
+ * \sa get
+ */
+class any {
+ public:
+  /*! \brief default constructor */
+  inline any() = default;
+  /*!
+   * \brief move constructor from another any
+   * \param other The other any to be moved
+   */
+  inline any(any&& other);  // NOLINT(*)
+  /*!
+   * \brief copy constructor
+   * \param other The other any to be copied
+   */
+  inline any(const any& other);  // NOLINT(*)
+  /*!
+   * \brief constructor from any types
+   * \param other The other types to be constructed into any.
+   * \tparam T The value type of other.
+   */
+  template<typename T>
+  inline any(T&& other);  // NOLINT(*)
+  /*! \brief destructor */
+  inline ~any();
+  /*!
+   * \brief assign operator from other
+   * \param other The other any to be copy or moved.
+   * \return self
+   */
+  inline any& operator=(any&& other);
+  /*!
+   * \brief assign operator from other
+   * \param other The other any to be copy or moved.
+   * \return self
+   */
+  inline any& operator=(const any& other);
+  /*!
+   * \brief assign operator from any type.
+   * \param other The other any to be copy or moved.
+   * \tparam T The value type of other.
+   * \return self
+   */
+  template<typename T>
+  inline any& operator=(T&& other);
+  /*!
+   * \return whether the container is empty.
+   */
+  inline bool empty() const;
+  /*!
+   * \brief clear the content of container
+   */
+  inline void clear();
+  /*!
+   * swap current content with other
+   * \param other The other data to be swapped.
+   */
+  inline void swap(any& other); // NOLINT(*)
+  /*!
+   * \return The type_info about the stored type.
+   */
+  inline const std::type_info& type() const;
+  /*! \brief Construct value of type T inplace */
+  template<typename T, typename... Args>
+  inline void construct(Args&&... args);
+
+ private:
+  //! \cond Doxygen_Suppress
+  // declare of helper class
+  template<typename T>
+  class TypeOnHeap;
+  template<typename T>
+  class TypeOnStack;
+  template<typename T>
+  class TypeInfo;
+  // size of stack space, it takes 32 bytes for one any type.
+  static const size_t kStack = sizeof(void*) * 3;
+  static const size_t kAlign = sizeof(void*);
+  // container use dynamic storage only when space runs lager
+  union Data {
+    // stack space
+    std::aligned_storage<kStack, kAlign>::type stack;
+    // pointer to heap space
+    void* pheap;
+  };
+  // type specific information
+  struct Type {
+    // destructor function
+    void (*destroy)(Data* data);
+    // copy constructor
+    void (*create_from_data)(Data* dst, const Data& src);
+    // the type info function
+    const std::type_info* ptype_info;
+  };
+  // constant to check if data can be stored on heap.
+  template<typename T>
+  struct data_on_stack {
+    static const bool value = alignof(T) <= kAlign && sizeof(T) <= kStack;
+  };
+  // declare friend with
+  template<typename T>
+  friend T& get(any& src);  // NOLINT(*)
+  template<typename T>
+  friend const T& get(const any& src);
+  template<typename T>
+  friend T& unsafe_get(any& src);  // NOLINT(*)
+  template<typename T>
+  friend const T& unsafe_get(const any& src);
+  // internal construct function
+  inline void construct(any&& other);
+  // internal construct function
+  inline void construct(const any& other);
+  // internal function to check if type is correct.
+  template<typename T>
+  inline void check_type() const;
+  template<typename T>
+  inline void check_type_by_name() const;
+  // internal type specific information
+  const Type* type_{nullptr};
+  // internal data
+  Data data_;
+};
+
+template<typename T>
+inline any::any(T&& other) {
+  typedef typename std::decay<T>::type DT;
+  if (std::is_same<DT, any>::value) {
+    this->construct(std::forward<T>(other));
+  } else {
+    static_assert(std::is_copy_constructible<DT>::value,
+                  "Any can only hold value that is copy constructable");
+    type_ = TypeInfo<DT>::get_type();
+    if (data_on_stack<DT>::value) {
+#pragma GCC diagnostic push
+#if 6 <= __GNUC__
+#pragma GCC diagnostic ignored "-Wplacement-new"
+#endif
+      new (&(data_.stack)) DT(std::forward<T>(other));
+#pragma GCC diagnostic pop
+    } else {
+      data_.pheap = new DT(std::forward<T>(other));
+    }
+  }
+}
+
+inline any::any(any&& other) {
+  this->construct(std::move(other));
+}
+
+inline any::any(const any& other) {
+  this->construct(other);
+}
+
+inline void any::construct(any&& other) {
+  type_ = other.type_;
+  data_ = other.data_;
+  other.type_ = nullptr;
+}
+
+inline void any::construct(const any& other) {
+  type_ = other.type_;
+  if (type_ != nullptr) {
+    type_->create_from_data(&data_, other.data_);
+  }
+}
+
+template<typename T, typename... Args>
+inline void any::construct(Args&&... args) {
+  clear();
+  typedef typename std::decay<T>::type DT;
+  type_ = TypeInfo<DT>::get_type();
+  if (data_on_stack<DT>::value) {
+#pragma GCC diagnostic push
+#if 6 <= __GNUC__
+#pragma GCC diagnostic ignored "-Wplacement-new"
+#endif
+    new (&(data_.stack)) DT(std::forward<Args>(args)...);
+#pragma GCC diagnostic pop
+  } else {
+    data_.pheap = new DT(std::forward<Args>(args)...);
+  }
+}
+
+inline any::~any() {
+  this->clear();
+}
+
+inline any& any::operator=(any&& other) {
+  any(std::move(other)).swap(*this);
+  return *this;
+}
+
+inline any& any::operator=(const any& other) {
+  any(other).swap(*this);
+  return *this;
+}
+
+template<typename T>
+inline any& any::operator=(T&& other) {
+  any(std::forward<T>(other)).swap(*this);
+  return *this;
+}
+
+inline void any::swap(any& other) { // NOLINT(*)
+  std::swap(type_, other.type_);
+  std::swap(data_, other.data_);
+}
+
+inline void any::clear() {
+  if (type_ != nullptr) {
+    if (type_->destroy != nullptr) {
+      type_->destroy(&data_);
+    }
+    type_ = nullptr;
+  }
+}
+
+inline bool any::empty() const {
+  return type_ == nullptr;
+}
+
+inline const std::type_info& any::type() const {
+  if (type_ != nullptr) {
+    return *(type_->ptype_info);
+  } else {
+    return typeid(void);
+  }
+}
+
+template<typename T>
+inline void any::check_type() const {
+  CHECK(type_ != nullptr)
+      << "The any container is empty"
+      << " requested=" << typeid(T).name();
+  CHECK(*(type_->ptype_info) == typeid(T))
+      << "The stored type mismatch"
+      << " stored=" << type_->ptype_info->name()
+      << " requested=" << typeid(T).name();
+}
+
+template<typename T>
+inline void any::check_type_by_name() const {
+  CHECK(type_ != nullptr)
+      << "The any container is empty"
+      << " requested=" << typeid(T).name();
+  CHECK(strcmp(type_->ptype_info->name(), typeid(T).name()) == 0)
+      << "The stored type name mismatch"
+      << " stored=" << type_->ptype_info->name()
+      << " requested=" << typeid(T).name();
+}
+
+template<typename T>
+inline const T& get(const any& src) {
+  src.check_type<T>();
+  return *any::TypeInfo<T>::get_ptr(&(src.data_));
+}
+
+template<typename T>
+inline T& get(any& src) { // NOLINT(*)
+  src.check_type<T>();
+  return *any::TypeInfo<T>::get_ptr(&(src.data_));
+}
+
+template<typename T>
+inline const T& unsafe_get(const any& src) {
+  src.check_type_by_name<T>();
+  return *any::TypeInfo<T>::get_ptr(&(src.data_));
+}
+
+template<typename T>
+inline T& unsafe_get(any& src) { // NOLINT(*)
+  src.check_type_by_name<T>();
+  return *any::TypeInfo<T>::get_ptr(&(src.data_));
+}
+
+template<typename T>
+class any::TypeOnHeap {
+ public:
+  inline static T* get_ptr(any::Data* data) {
+    return static_cast<T*>(data->pheap);
+  }
+  inline static const T* get_ptr(const any::Data* data) {
+    return static_cast<const T*>(data->pheap);
+  }
+  inline static void create_from_data(any::Data* dst, const any::Data& data) {
+    dst->pheap = new T(*get_ptr(&data));
+  }
+  inline static void destroy(Data* data) {
+    delete static_cast<T*>(data->pheap);
+  }
+};
+
+template<typename T>
+class any::TypeOnStack {
+ public:
+  inline static T* get_ptr(any::Data* data) {
+    return reinterpret_cast<T*>(&(data->stack));
+  }
+  inline static const T* get_ptr(const any::Data* data) {
+    return reinterpret_cast<const T*>(&(data->stack));
+  }
+  inline static void create_from_data(any::Data* dst, const any::Data& data) {
+    new (&(dst->stack)) T(*get_ptr(&data));
+  }
+  inline static void destroy(Data* data) {
+    T* dptr = reinterpret_cast<T*>(&(data->stack));
+    dptr->~T();
+  }
+};
+
+template<typename T>
+class any::TypeInfo
+    : public std::conditional<any::data_on_stack<T>::value,
+                              any::TypeOnStack<T>,
+                              any::TypeOnHeap<T> >::type {
+ public:
+  inline static const Type* get_type() {
+    static TypeInfo<T> tp;
+    return &(tp.type_);
+  }
+
+ private:
+  // local type
+  Type type_;
+  // constructor
+  TypeInfo() {
+    if (std::is_pod<T>::value && data_on_stack<T>::value) {
+      type_.destroy = nullptr;
+    } else {
+      type_.destroy = TypeInfo<T>::destroy;
+    }
+    type_.create_from_data = TypeInfo<T>::create_from_data;
+    type_.ptype_info = &typeid(T);
+  }
+};
+//! \endcond
+
+}  // namespace dmlc
+
+#endif  // DMLC_ANY_H_
diff --git a/darknet_drp_ros/include/dmlc/array_view.h b/darknet_drp_ros/include/dmlc/array_view.h
new file mode 100644
index 0000000..5e01a78
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/array_view.h
@@ -0,0 +1,128 @@
+/*!
+ *  Copyright (c) 2016 by Contributors
+ * \file array_view.h
+ * \brief Read only data structure to reference array
+ */
+#ifndef DMLC_ARRAY_VIEW_H_
+#define DMLC_ARRAY_VIEW_H_
+
+#include <vector>
+#include <array>
+
+namespace dmlc {
+
+/*!
+ * \brief Read only data structure to reference continuous memory region of array.
+ * Provide unified view for vector, array and C style array.
+ * This data structure do not guarantee aliveness of referenced array.
+ *
+ * Make sure do not use array_view to record data in async function closures.
+ * Also do not use array_view to create reference to temporary data structure.
+ *
+ * \tparam ValueType The value
+ *
+ * \code
+ *  std::vector<int> myvec{1,2,3};
+ *  dmlc::array_view<int> view(myvec);
+ *  // indexed visit to the view.
+ *  LOG(INFO) << view[0];
+ *
+ *  for (int v : view) {
+ *     // visit each element in the view
+ *  }
+ * \endcode
+ */
+template<typename ValueType>
+class array_view {
+ public:
+  /*! \brief default constructor */
+  array_view() = default;
+  /*!
+   * \brief default copy constructor
+   * \param other another array view.
+   */
+  array_view(const array_view<ValueType> &other) = default;  // NOLINT(*)
+#ifndef _MSC_VER
+  /*!
+   * \brief default move constructor
+   * \param other another array view.
+   */
+  array_view(array_view<ValueType>&& other) = default; // NOLINT(*)
+#else
+  /*!
+  * \brief default move constructor
+  * \param other another array view.
+  */
+  array_view(array_view<ValueType>&& other) { // NOLINT(*)
+    begin_ = other.begin_;
+    size_ = other.size_;
+    other.begin_ = nullptr;
+  }
+#endif
+  /*!
+   * \brief default assign constructor
+   * \param other another array view.
+   * \return self.
+   */
+  array_view<ValueType>& operator=(const array_view<ValueType>& other) = default; // NOLINT(*)
+  /*!
+   * \brief construct array view std::vector
+   * \param other vector container
+   */
+  array_view(const std::vector<ValueType>& other) {  // NOLINT(*)
+    if (other.size() != 0) {
+      begin_ = &other[0]; size_ = other.size();
+    }
+  }
+  /*!
+   * \brief construct array std::array
+   * \param other another array view.
+   */
+  template<std::size_t size>
+  array_view(const std::array<ValueType, size>& other) {  // NOLINT(*)
+    if (size != 0) {
+      begin_ = &other[0]; size_ = size;
+    }
+  }
+  /*!
+   * \brief construct array view from continuous segment
+   * \param begin beginning pointre
+   * \param end end pointer
+   */
+  array_view(const ValueType* begin, const ValueType* end) {
+    if (begin < end) {
+      begin_ = begin;
+      size_ = end - begin;
+    }
+  }
+  /*! \return size of the array */
+  inline size_t size() const {
+    return size_;
+  }
+  /*! \return begin of the array */
+  inline const ValueType* begin() const {
+    return begin_;
+  }
+  /*! \return end point of the array */
+  inline const ValueType* end() const {
+    return begin_ + size_;
+  }
+  /*!
+   * \brief get i-th element from the view
+   * \param i The index.
+   * \return const reference to i-th element.
+   */
+  inline const ValueType& operator[](size_t i) const {
+    return begin_[i];
+  }
+
+ private:
+  /*! \brief the begin of the view */
+  const ValueType* begin_{nullptr};
+  /*! \brief The size of the view */
+  size_t size_{0};
+};
+
+}  // namespace dmlc
+
+#endif  // DMLC_ARRAY_VIEW_H_
diff --git a/darknet_drp_ros/include/dmlc/base.h b/darknet_drp_ros/include/dmlc/base.h
new file mode 100644
index 0000000..0fde0c1
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/base.h
@@ -0,0 +1,337 @@
+/*!
+ *  Copyright (c) 2015 by Contributors
+ * \file base.h
+ * \brief defines configuration macros
+ */
+#ifndef DMLC_BASE_H_
+#define DMLC_BASE_H_
+
+/*! \brief whether use glog for logging */
+#ifndef DMLC_USE_GLOG
+#define DMLC_USE_GLOG 0
+#endif
+
+/*
+ * The preprocessor definition DMLC_USE_LOGGING_LIBRARY determines whether to
+ * use a user-defined logging library. If defined, dmlc will not define the
+ * macros CHECK() and LOG() and instead locate CHECK() and LOG() from the value
+ * of DMLC_USE_LOGGING_LIBRARY. The DMLC_USE_LOGGING_LIBRARY macro shall be of
+ * form <my_logging.h>:
+ *
+ * #define DMLC_USE_LOGGING_LIBRARY <my_logging.h>
+ *
+ * Make sure to define CHECK() and LOG() macros in the provided header;
+ * otherwise the build will fail.
+ */
+
+/*!
+ * \brief whether throw dmlc::Error instead of
+ *  directly calling abort when FATAL error occured
+ *  NOTE: this may still not be perfect.
+ *  do not use FATAL and CHECK in destructors
+ */
+#ifndef DMLC_LOG_FATAL_THROW
+#define DMLC_LOG_FATAL_THROW 1
+#endif
+
+/*!
+ * \brief whether always log a message before throw
+ * This can help identify the error that cannot be catched.
+ */
+#ifndef DMLC_LOG_BEFORE_THROW
+#define DMLC_LOG_BEFORE_THROW 0
+#endif
+
+/*!
+ * \brief Whether to use customized logger,
+ * whose output can be decided by other libraries.
+ */
+#ifndef DMLC_LOG_CUSTOMIZE
+#define DMLC_LOG_CUSTOMIZE 0
+#endif
+
+/*!
+ * \brief Whether to enable debug logging feature.
+ */
+#ifndef DMLC_LOG_DEBUG
+#ifdef NDEBUG
+#define DMLC_LOG_DEBUG 0
+#else
+#define DMLC_LOG_DEBUG 1
+#endif
+#endif
+
+/*!
+ * \brief Whether to disable date message on the log.
+ */
+#ifndef DMLC_LOG_NODATE
+#define DMLC_LOG_NODATE 0
+#endif
+
+/*! \brief whether compile with hdfs support */
+#ifndef DMLC_USE_HDFS
+#define DMLC_USE_HDFS 0
+#endif
+
+/*! \brief whether compile with s3 support */
+#ifndef DMLC_USE_S3
+#define DMLC_USE_S3 0
+#endif
+
+/*! \brief whether or not use parameter server */
+#ifndef DMLC_USE_PS
+#define DMLC_USE_PS 0
+#endif
+
+/*! \brief whether or not use c++11 support */
+#ifndef DMLC_USE_CXX11
+#if defined(__GXX_EXPERIMENTAL_CXX0X__) || defined(_MSC_VER)
+#define DMLC_USE_CXX11 1
+#else
+#define DMLC_USE_CXX11 (__cplusplus >= 201103L)
+#endif
+#endif
+
+/*! \brief strict CXX11 support */
+#ifndef DMLC_STRICT_CXX11
+#if defined(_MSC_VER)
+#define DMLC_STRICT_CXX11 1
+#else
+#define DMLC_STRICT_CXX11 (__cplusplus >= 201103L)
+#endif
+#endif
+
+/*! \brief Whether cxx11 thread local is supported */
+#ifndef DMLC_CXX11_THREAD_LOCAL
+#if defined(_MSC_VER)
+#define DMLC_CXX11_THREAD_LOCAL (_MSC_VER >= 1900)
+#elif defined(__clang__)
+#define DMLC_CXX11_THREAD_LOCAL (__has_feature(cxx_thread_local))
+#else
+#define DMLC_CXX11_THREAD_LOCAL (__cplusplus >= 201103L)
+#endif
+#endif
+
+/*! \brief Whether to use modern thread local construct */
+#ifndef DMLC_MODERN_THREAD_LOCAL
+#define DMLC_MODERN_THREAD_LOCAL 1
+#endif
+
+
+
+/*! \brief whether RTTI is enabled */
+#ifndef DMLC_ENABLE_RTTI
+#define DMLC_ENABLE_RTTI 1
+#endif
+
+/*! \brief whether use fopen64 */
+#ifndef DMLC_USE_FOPEN64
+#define DMLC_USE_FOPEN64 1
+#endif
+
+/// check if g++ is before 5.0
+#if DMLC_USE_CXX11 && defined(__GNUC__) && !defined(__clang_version__)
+#if __GNUC__ < 5
+#pragma message("Will need g++-5.0 or higher to compile all"           \
+                "the features in dmlc-core, "                           \
+                "compile without c++11, some features may be disabled")
+#undef DMLC_USE_CXX11
+#define DMLC_USE_CXX11 0
+#endif
+#endif
+
+/*!
+ * \brief Use little endian for binary serialization
+ *  if this is set to 0, use big endian.
+ */
+#ifndef DMLC_IO_USE_LITTLE_ENDIAN
+#define DMLC_IO_USE_LITTLE_ENDIAN 1
+#endif
+
+/*!
+ * \brief Enable std::thread related modules,
+ *  Used to disable some module in mingw compile.
+ */
+#ifndef DMLC_ENABLE_STD_THREAD
+#define DMLC_ENABLE_STD_THREAD DMLC_USE_CXX11
+#endif
+
+/*! \brief whether enable regex support, actually need g++-4.9 or higher*/
+#ifndef DMLC_USE_REGEX
+#define DMLC_USE_REGEX DMLC_STRICT_CXX11
+#endif
+
+/*! \brief helper macro to supress unused warning */
+#if defined(__GNUC__)
+#define DMLC_ATTRIBUTE_UNUSED __attribute__((unused))
+#else
+#define DMLC_ATTRIBUTE_UNUSED
+#endif
+
+/*! \brief helper macro to supress Undefined Behavior Sanitizer for a specific function */
+#if defined(__clang__)
+#define DMLC_SUPPRESS_UBSAN __attribute__((no_sanitize("undefined")))
+#elif defined(__GNUC__) && (__GNUC__ * 100 + __GNUC_MINOR__ >= 409)
+#define DMLC_SUPPRESS_UBSAN __attribute__((no_sanitize_undefined))
+#else
+#define DMLC_SUPPRESS_UBSAN
+#endif
+
+/*! \brief helper macro to generate string concat */
+#define DMLC_STR_CONCAT_(__x, __y) __x##__y
+#define DMLC_STR_CONCAT(__x, __y) DMLC_STR_CONCAT_(__x, __y)
+
+/*!
+ * \brief Disable copy constructor and assignment operator.
+ *
+ * If C++11 is supported, both copy and move constructors and
+ * assignment operators are deleted explicitly. Otherwise, they are
+ * only declared but not implemented. Place this macro in private
+ * section if C++11 is not available.
+ */
+#ifndef DISALLOW_COPY_AND_ASSIGN
+#  if DMLC_USE_CXX11
+#    define DISALLOW_COPY_AND_ASSIGN(T) \
+       T(T const&) = delete; \
+       T(T&&) = delete; \
+       T& operator=(T const&) = delete; \
+       T& operator=(T&&) = delete
+#  else
+#    define DISALLOW_COPY_AND_ASSIGN(T) \
+       T(T const&); \
+       T& operator=(T const&)
+#  endif
+#endif
+
+#ifdef __APPLE__
+#  define off64_t off_t
+#endif
+
+#ifdef _MSC_VER
+#if _MSC_VER < 1900
+// NOTE: sprintf_s is not equivalent to snprintf,
+// they are equivalent when success, which is sufficient for our case
+#define snprintf sprintf_s
+#define vsnprintf vsprintf_s
+#endif
+#else
+#ifdef _FILE_OFFSET_BITS
+#if _FILE_OFFSET_BITS == 32
+#pragma message("Warning: FILE OFFSET BITS defined to be 32 bit")
+#endif
+#endif
+
+extern "C" {
+#include <sys/types.h>
+}
+#endif
+
+#ifdef _MSC_VER
+//! \cond Doxygen_Suppress
+typedef signed char int8_t;
+typedef __int16 int16_t;
+typedef __int32 int32_t;
+typedef __int64 int64_t;
+typedef unsigned char uint8_t;
+typedef unsigned __int16 uint16_t;
+typedef unsigned __int32 uint32_t;
+typedef unsigned __int64 uint64_t;
+//! \endcond
+#else
+#include <inttypes.h>
+#endif
+#include <string>
+#include <vector>
+
+#if defined(_MSC_VER) && _MSC_VER < 1900
+#define noexcept_true throw ()
+#define noexcept_false
+#define noexcept(a) noexcept_##a
+#endif
+
+#if defined(_MSC_VER)
+#define DMLC_NO_INLINE __declspec(noinline)
+#else
+#define DMLC_NO_INLINE __attribute__((noinline))
+#endif
+
+#if defined(__GNUC__) || defined(__clang__)
+#define DMLC_ALWAYS_INLINE inline __attribute__((__always_inline__))
+#elif defined(_MSC_VER)
+#define DMLC_ALWAYS_INLINE __forceinline
+#else
+#define DMLC_ALWAYS_INLINE inline
+#endif
+
+#if DMLC_USE_CXX11
+#define DMLC_THROW_EXCEPTION noexcept(false)
+#define DMLC_NO_EXCEPTION  noexcept(true)
+#else
+#define DMLC_THROW_EXCEPTION
+#define DMLC_NO_EXCEPTION
+#endif
+
+/*! \brief namespace for dmlc */
+namespace dmlc {
+/*!
+ * \brief safely get the beginning address of a vector
+ * \param vec input vector
+ * \return beginning address of a vector
+ */
+template<typename T>
+inline T *BeginPtr(std::vector<T> &vec) {  // NOLINT(*)
+  if (vec.size() == 0) {
+    return NULL;
+  } else {
+    return &vec[0];
+  }
+}
+/*!
+ * \brief get the beginning address of a const vector
+ * \param vec input vector
+ * \return beginning address of a vector
+ */
+template<typename T>
+inline const T *BeginPtr(const std::vector<T> &vec) {
+  if (vec.size() == 0) {
+    return NULL;
+  } else {
+    return &vec[0];
+  }
+}
+/*!
+ * \brief get the beginning address of a string
+ * \param str input string
+ * \return beginning address of a string
+ */
+inline char* BeginPtr(std::string &str) {  // NOLINT(*)
+  if (str.length() == 0) return NULL;
+  return &str[0];
+}
+/*!
+ * \brief get the beginning address of a const string
+ * \param str input string
+ * \return beginning address of a string
+ */
+inline const char* BeginPtr(const std::string &str) {
+  if (str.length() == 0) return NULL;
+  return &str[0];
+}
+}  // namespace dmlc
+
+#if defined(_MSC_VER) && _MSC_VER < 1900
+#define constexpr const
+#define alignof __alignof
+#endif
+
+/* If fopen64 is not defined by current machine,
+   replace fopen64 with std::fopen. Also determine ability to print stack trace
+   for fatal error and define DMLC_LOG_STACK_TRACE if stack trace can be
+   produced. Always keep this include directive at the bottom of dmlc/base.h */
+#ifdef DMLC_CORE_USE_CMAKE
+#include <dmlc/build_config.h>
+#else
+#include <dmlc/build_config_default.h>
+#endif
+
+#endif  // DMLC_BASE_H_
diff --git a/darknet_drp_ros/include/dmlc/blockingconcurrentqueue.h b/darknet_drp_ros/include/dmlc/blockingconcurrentqueue.h
new file mode 100644
index 0000000..9d24943
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/blockingconcurrentqueue.h
@@ -0,0 +1,991 @@
+//! \cond Doxygen_Suppress
+// Provides an efficient blocking version of moodycamel::ConcurrentQueue.
+// ©2015-2016 Cameron Desrochers. Distributed under the terms of the simplified
+// BSD license, available at the top of concurrentqueue.h.
+// Uses Jeff Preshing's semaphore implementation (under the terms of its
+// separate zlib license, embedded below).
+
+#ifndef DMLC_BLOCKINGCONCURRENTQUEUE_H_
+#define DMLC_BLOCKINGCONCURRENTQUEUE_H_
+
+#pragma once
+
+#include "concurrentqueue.h"
+#include <type_traits>
+#include <cerrno>
+#include <memory>
+#include <chrono>
+#include <ctime>
+
+#if defined(_WIN32)
+// Avoid including windows.h in a header; we only need a handful of
+// items, so we'll redeclare them here (this is relatively safe since
+// the API generally has to remain stable between Windows versions).
+// I know this is an ugly hack but it still beats polluting the global
+// namespace with thousands of generic names or adding a .cpp for nothing.
+extern "C" {
+	struct _SECURITY_ATTRIBUTES;
+	__declspec(dllimport) void* __stdcall CreateSemaphoreW(_SECURITY_ATTRIBUTES* lpSemaphoreAttributes, long lInitialCount, long lMaximumCount, const wchar_t* lpName);
+	__declspec(dllimport) int __stdcall CloseHandle(void* hObject);
+	__declspec(dllimport) unsigned long __stdcall WaitForSingleObject(void* hHandle, unsigned long dwMilliseconds);
+	__declspec(dllimport) int __stdcall ReleaseSemaphore(void* hSemaphore, long lReleaseCount, long* lpPreviousCount);
+}
+#elif defined(__MACH__)
+#include <mach/mach.h>
+#elif defined(__unix__)
+#include <semaphore.h>
+#endif
+
+namespace dmlc {
+
+namespace moodycamel
+{
+namespace details
+{
+	// Code in the mpmc_sema namespace below is an adaptation of Jeff Preshing's
+	// portable + lightweight semaphore implementations, originally from
+	// https://github.com/preshing/cpp11-on-multicore/blob/master/common/sema.h
+	// LICENSE:
+	// Copyright (c) 2015 Jeff Preshing
+	//
+	// This software is provided 'as-is', without any express or implied
+	// warranty. In no event will the authors be held liable for any damages
+	// arising from the use of this software.
+	//
+	// Permission is granted to anyone to use this software for any purpose,
+	// including commercial applications, and to alter it and redistribute it
+	// freely, subject to the following restrictions:
+	//
+	// 1. The origin of this software must not be misrepresented; you must not
+	//	claim that you wrote the original software. If you use this software
+	//	in a product, an acknowledgement in the product documentation would be
+	//	appreciated but is not required.
+	// 2. Altered source versions must be plainly marked as such, and must not be
+	//	misrepresented as being the original software.
+	// 3. This notice may not be removed or altered from any source distribution.
+	namespace mpmc_sema
+	{
+#if defined(_WIN32)
+		class Semaphore
+		{
+		private:
+			void* m_hSema;
+
+			Semaphore(const Semaphore& other) MOODYCAMEL_DELETE_FUNCTION;
+			Semaphore& operator=(const Semaphore& other) MOODYCAMEL_DELETE_FUNCTION;
+
+		public:
+			Semaphore(int initialCount = 0)
+			{
+				assert(initialCount >= 0);
+				const long maxLong = 0x7fffffff;
+				m_hSema = CreateSemaphoreW(nullptr, initialCount, maxLong, nullptr);
+			}
+
+			~Semaphore()
+			{
+				CloseHandle(m_hSema);
+			}
+
+			void wait()
+			{
+				const unsigned long infinite = 0xffffffff;
+				WaitForSingleObject(m_hSema, infinite);
+			}
+
+			bool try_wait()
+			{
+				const unsigned long RC_WAIT_TIMEOUT = 0x00000102;
+				return WaitForSingleObject(m_hSema, 0) != RC_WAIT_TIMEOUT;
+			}
+
+			bool timed_wait(std::uint64_t usecs)
+			{
+				const unsigned long RC_WAIT_TIMEOUT = 0x00000102;
+				return WaitForSingleObject(m_hSema, (unsigned long)(usecs / 1000)) != RC_WAIT_TIMEOUT;
+			}
+
+			void signal(int count = 1)
+			{
+				ReleaseSemaphore(m_hSema, count, nullptr);
+			}
+		};
+#elif defined(__MACH__)
+		//---------------------------------------------------------
+		// Semaphore (Apple iOS and OSX)
+		// Can't use POSIX semaphores due to http://lists.apple.com/archives/darwin-kernel/2009/Apr/msg00010.html
+		//---------------------------------------------------------
+		class Semaphore
+		{
+		private:
+			semaphore_t m_sema;
+
+			Semaphore(const Semaphore& other) MOODYCAMEL_DELETE_FUNCTION;
+			Semaphore& operator=(const Semaphore& other) MOODYCAMEL_DELETE_FUNCTION;
+
+		public:
+			Semaphore(int initialCount = 0)
+			{
+				assert(initialCount >= 0);
+				semaphore_create(mach_task_self(), &m_sema, SYNC_POLICY_FIFO, initialCount);
+			}
+
+			~Semaphore()
+			{
+				semaphore_destroy(mach_task_self(), m_sema);
+			}
+
+			void wait()
+			{
+				semaphore_wait(m_sema);
+			}
+
+			bool try_wait()
+			{
+				return timed_wait(0);
+			}
+
+			bool timed_wait(std::uint64_t timeout_usecs)
+			{
+				mach_timespec_t ts;
+				ts.tv_sec = static_cast<unsigned int>(timeout_usecs / 1000000);
+				ts.tv_nsec = (timeout_usecs % 1000000) * 1000;
+
+				// added in OSX 10.10: https://developer.apple.com/library/prerelease/mac/documentation/General/Reference/APIDiffsMacOSX10_10SeedDiff/modules/Darwin.html
+				kern_return_t rc = semaphore_timedwait(m_sema, ts);
+
+				return rc != KERN_OPERATION_TIMED_OUT;
+			}
+
+			void signal()
+			{
+				semaphore_signal(m_sema);
+			}
+
+			void signal(int count)
+			{
+				while (count-- > 0)
+				{
+					semaphore_signal(m_sema);
+				}
+			}
+		};
+#elif defined(__unix__)
+		//---------------------------------------------------------
+		// Semaphore (POSIX, Linux)
+		//---------------------------------------------------------
+		class Semaphore
+		{
+		private:
+			sem_t m_sema;
+
+			Semaphore(const Semaphore& other) MOODYCAMEL_DELETE_FUNCTION;
+			Semaphore& operator=(const Semaphore& other) MOODYCAMEL_DELETE_FUNCTION;
+
+		public:
+			Semaphore(int initialCount = 0)
+			{
+				assert(initialCount >= 0);
+				sem_init(&m_sema, 0, initialCount);
+			}
+
+			~Semaphore()
+			{
+				sem_destroy(&m_sema);
+			}
+
+			void wait()
+			{
+				// http://stackoverflow.com/questions/2013181/gdb-causes-sem-wait-to-fail-with-eintr-error
+				int rc;
+				do {
+					rc = sem_wait(&m_sema);
+				} while (rc == -1 && errno == EINTR);
+			}
+
+			bool try_wait()
+			{
+				int rc;
+				do {
+					rc = sem_trywait(&m_sema);
+				} while (rc == -1 && errno == EINTR);
+				return !(rc == -1 && errno == EAGAIN);
+			}
+
+			bool timed_wait(std::uint64_t usecs)
+			{
+				struct timespec ts;
+				const int usecs_in_1_sec = 1000000;
+				const int nsecs_in_1_sec = 1000000000;
+				clock_gettime(CLOCK_REALTIME, &ts);
+				ts.tv_sec += usecs / usecs_in_1_sec;
+				ts.tv_nsec += (usecs % usecs_in_1_sec) * 1000;
+				// sem_timedwait bombs if you have more than 1e9 in tv_nsec
+				// so we have to clean things up before passing it in
+				if (ts.tv_nsec >= nsecs_in_1_sec) {
+					ts.tv_nsec -= nsecs_in_1_sec;
+					++ts.tv_sec;
+				}
+
+				int rc;
+				do {
+					rc = sem_timedwait(&m_sema, &ts);
+				} while (rc == -1 && errno == EINTR);
+				return !(rc == -1 && errno == ETIMEDOUT);
+			}
+
+			void signal()
+			{
+				sem_post(&m_sema);
+			}
+
+			void signal(int count)
+			{
+				while (count-- > 0)
+				{
+					sem_post(&m_sema);
+				}
+			}
+		};
+#else
+#error Unsupported platform! (No semaphore wrapper available)
+#endif
+
+		//---------------------------------------------------------
+		// LightweightSemaphore
+		//---------------------------------------------------------
+		class LightweightSemaphore
+		{
+		public:
+			typedef std::make_signed<std::size_t>::type ssize_t;
+
+		private:
+			std::atomic<ssize_t> m_count;
+			Semaphore m_sema;
+
+			bool waitWithPartialSpinning(std::int64_t timeout_usecs = -1)
+			{
+				ssize_t oldCount;
+				// Is there a better way to set the initial spin count?
+				// If we lower it to 1000, testBenaphore becomes 15x slower on my Core i7-5930K Windows PC,
+				// as threads start hitting the kernel semaphore.
+				int spin = 10000;
+				while (--spin >= 0)
+				{
+					oldCount = m_count.load(std::memory_order_relaxed);
+					if ((oldCount > 0) && m_count.compare_exchange_strong(oldCount, oldCount - 1, std::memory_order_acquire, std::memory_order_relaxed))
+						return true;
+					std::atomic_signal_fence(std::memory_order_acquire);	 // Prevent the compiler from collapsing the loop.
+				}
+				oldCount = m_count.fetch_sub(1, std::memory_order_acquire);
+				if (oldCount > 0)
+					return true;
+				if (timeout_usecs < 0)
+				{
+					m_sema.wait();
+					return true;
+				}
+				if (m_sema.timed_wait((std::uint64_t)timeout_usecs))
+					return true;
+				// At this point, we've timed out waiting for the semaphore, but the
+				// count is still decremented indicating we may still be waiting on
+				// it. So we have to re-adjust the count, but only if the semaphore
+				// wasn't signaled enough times for us too since then. If it was, we
+				// need to release the semaphore too.
+				while (true)
+				{
+					oldCount = m_count.load(std::memory_order_acquire);
+					if (oldCount >= 0 && m_sema.try_wait())
+						return true;
+					if (oldCount < 0 && m_count.compare_exchange_strong(oldCount, oldCount + 1, std::memory_order_relaxed, std::memory_order_relaxed))
+						return false;
+				}
+			}
+
+			ssize_t waitManyWithPartialSpinning(ssize_t max, std::int64_t timeout_usecs = -1)
+			{
+				assert(max > 0);
+				ssize_t oldCount;
+				int spin = 10000;
+				while (--spin >= 0)
+				{
+					oldCount = m_count.load(std::memory_order_relaxed);
+					if (oldCount > 0)
+					{
+						ssize_t newCount = oldCount > max ? oldCount - max : 0;
+						if (m_count.compare_exchange_strong(oldCount, newCount, std::memory_order_acquire, std::memory_order_relaxed))
+							return oldCount - newCount;
+					}
+					std::atomic_signal_fence(std::memory_order_acquire);
+				}
+				oldCount = m_count.fetch_sub(1, std::memory_order_acquire);
+				if (oldCount <= 0)
+				{
+					if (timeout_usecs < 0)
+						m_sema.wait();
+					else if (!m_sema.timed_wait((std::uint64_t)timeout_usecs))
+					{
+						while (true)
+						{
+							oldCount = m_count.load(std::memory_order_acquire);
+							if (oldCount >= 0 && m_sema.try_wait())
+								break;
+							if (oldCount < 0 && m_count.compare_exchange_strong(oldCount, oldCount + 1, std::memory_order_relaxed, std::memory_order_relaxed))
+								return 0;
+						}
+					}
+				}
+				if (max > 1)
+					return 1 + tryWaitMany(max - 1);
+				return 1;
+			}
+
+		public:
+			LightweightSemaphore(ssize_t initialCount = 0) : m_count(initialCount)
+			{
+				assert(initialCount >= 0);
+			}
+
+			bool tryWait()
+			{
+				ssize_t oldCount = m_count.load(std::memory_order_relaxed);
+				while (oldCount > 0)
+				{
+					if (m_count.compare_exchange_weak(oldCount, oldCount - 1, std::memory_order_acquire, std::memory_order_relaxed))
+						return true;
+				}
+				return false;
+			}
+
+			void wait()
+			{
+				if (!tryWait())
+					waitWithPartialSpinning();
+			}
+
+			bool wait(std::int64_t timeout_usecs)
+			{
+				return tryWait() || waitWithPartialSpinning(timeout_usecs);
+			}
+
+			// Acquires between 0 and (greedily) max, inclusive
+			ssize_t tryWaitMany(ssize_t max)
+			{
+				assert(max >= 0);
+				ssize_t oldCount = m_count.load(std::memory_order_relaxed);
+				while (oldCount > 0)
+				{
+					ssize_t newCount = oldCount > max ? oldCount - max : 0;
+					if (m_count.compare_exchange_weak(oldCount, newCount, std::memory_order_acquire, std::memory_order_relaxed))
+						return oldCount - newCount;
+				}
+				return 0;
+			}
+
+			// Acquires at least one, and (greedily) at most max
+			ssize_t waitMany(ssize_t max, std::int64_t timeout_usecs)
+			{
+				assert(max >= 0);
+				ssize_t result = tryWaitMany(max);
+				if (result == 0 && max > 0)
+					result = waitManyWithPartialSpinning(max, timeout_usecs);
+				return result;
+			}
+
+			ssize_t waitMany(ssize_t max)
+			{
+				ssize_t result = waitMany(max, -1);
+				assert(result > 0);
+				return result;
+			}
+
+			void signal(ssize_t count = 1)
+			{
+				assert(count >= 0);
+				ssize_t oldCount = m_count.fetch_add(count, std::memory_order_release);
+				ssize_t toRelease = -oldCount < count ? -oldCount : count;
+				if (toRelease > 0)
+				{
+					m_sema.signal((int)toRelease);
+				}
+			}
+
+			ssize_t availableApprox() const
+			{
+				ssize_t count = m_count.load(std::memory_order_relaxed);
+				return count > 0 ? count : 0;
+			}
+		};
+	}	// end namespace mpmc_sema
+}	// end namespace details
+
+
+// This is a blocking version of the queue. It has an almost identical interface to
+// the normal non-blocking version, with the addition of various wait_dequeue() methods
+// and the removal of producer-specific dequeue methods.
+template<typename T, typename Traits = ConcurrentQueueDefaultTraits>
+class BlockingConcurrentQueue
+{
+private:
+	typedef ::dmlc::moodycamel::ConcurrentQueue<T, Traits> ConcurrentQueue;
+	typedef details::mpmc_sema::LightweightSemaphore LightweightSemaphore;
+
+public:
+	typedef typename ConcurrentQueue::producer_token_t producer_token_t;
+	typedef typename ConcurrentQueue::consumer_token_t consumer_token_t;
+
+	typedef typename ConcurrentQueue::index_t index_t;
+	typedef typename ConcurrentQueue::size_t size_t;
+	typedef typename std::make_signed<size_t>::type ssize_t;
+
+	static const size_t BLOCK_SIZE = ConcurrentQueue::BLOCK_SIZE;
+	static const size_t EXPLICIT_BLOCK_EMPTY_COUNTER_THRESHOLD = ConcurrentQueue::EXPLICIT_BLOCK_EMPTY_COUNTER_THRESHOLD;
+	static const size_t EXPLICIT_INITIAL_INDEX_SIZE = ConcurrentQueue::EXPLICIT_INITIAL_INDEX_SIZE;
+	static const size_t IMPLICIT_INITIAL_INDEX_SIZE = ConcurrentQueue::IMPLICIT_INITIAL_INDEX_SIZE;
+	static const size_t INITIAL_IMPLICIT_PRODUCER_HASH_SIZE = ConcurrentQueue::INITIAL_IMPLICIT_PRODUCER_HASH_SIZE;
+	static const std::uint32_t EXPLICIT_CONSUMER_CONSUMPTION_QUOTA_BEFORE_ROTATE = ConcurrentQueue::EXPLICIT_CONSUMER_CONSUMPTION_QUOTA_BEFORE_ROTATE;
+	static const size_t MAX_SUBQUEUE_SIZE = ConcurrentQueue::MAX_SUBQUEUE_SIZE;
+
+public:
+	// Creates a queue with at least `capacity` element slots; note that the
+	// actual number of elements that can be inserted without additional memory
+	// allocation depends on the number of producers and the block size (e.g. if
+	// the block size is equal to `capacity`, only a single block will be allocated
+	// up-front, which means only a single producer will be able to enqueue elements
+	// without an extra allocation -- blocks aren't shared between producers).
+	// This method is not thread safe -- it is up to the user to ensure that the
+	// queue is fully constructed before it starts being used by other threads (this
+	// includes making the memory effects of construction visible, possibly with a
+	// memory barrier).
+	explicit BlockingConcurrentQueue(size_t capacity = 6 * BLOCK_SIZE)
+		: inner(capacity), sema(create<LightweightSemaphore>(), &BlockingConcurrentQueue::template destroy<LightweightSemaphore>)
+	{
+		assert(reinterpret_cast<ConcurrentQueue*>((BlockingConcurrentQueue*)1) == &((BlockingConcurrentQueue*)1)->inner && "BlockingConcurrentQueue must have ConcurrentQueue as its first member");
+		if (!sema) {
+			MOODYCAMEL_THROW(std::bad_alloc());
+		}
+	}
+
+	BlockingConcurrentQueue(size_t minCapacity, size_t maxExplicitProducers, size_t maxImplicitProducers)
+		: inner(minCapacity, maxExplicitProducers, maxImplicitProducers), sema(create<LightweightSemaphore>(), &BlockingConcurrentQueue::template destroy<LightweightSemaphore>)
+	{
+		assert(reinterpret_cast<ConcurrentQueue*>((BlockingConcurrentQueue*)1) == &((BlockingConcurrentQueue*)1)->inner && "BlockingConcurrentQueue must have ConcurrentQueue as its first member");
+		if (!sema) {
+			MOODYCAMEL_THROW(std::bad_alloc());
+		}
+	}
+
+	// Disable copying and copy assignment
+	BlockingConcurrentQueue(BlockingConcurrentQueue const&) MOODYCAMEL_DELETE_FUNCTION;
+	BlockingConcurrentQueue& operator=(BlockingConcurrentQueue const&) MOODYCAMEL_DELETE_FUNCTION;
+
+	// Moving is supported, but note that it is *not* a thread-safe operation.
+	// Nobody can use the queue while it's being moved, and the memory effects
+	// of that move must be propagated to other threads before they can use it.
+	// Note: When a queue is moved, its tokens are still valid but can only be
+	// used with the destination queue (i.e. semantically they are moved along
+	// with the queue itself).
+	BlockingConcurrentQueue(BlockingConcurrentQueue&& other) MOODYCAMEL_NOEXCEPT
+		: inner(std::move(other.inner)), sema(std::move(other.sema))
+	{ }
+
+	inline BlockingConcurrentQueue& operator=(BlockingConcurrentQueue&& other) MOODYCAMEL_NOEXCEPT
+	{
+		return swap_internal(other);
+	}
+
+	// Swaps this queue's state with the other's. Not thread-safe.
+	// Swapping two queues does not invalidate their tokens, however
+	// the tokens that were created for one queue must be used with
+	// only the swapped queue (i.e. the tokens are tied to the
+	// queue's movable state, not the object itself).
+	inline void swap(BlockingConcurrentQueue& other) MOODYCAMEL_NOEXCEPT
+	{
+		swap_internal(other);
+	}
+
+private:
+	BlockingConcurrentQueue& swap_internal(BlockingConcurrentQueue& other)
+	{
+		if (this == &other) {
+			return *this;
+		}
+
+		inner.swap(other.inner);
+		sema.swap(other.sema);
+		return *this;
+	}
+
+public:
+	// Enqueues a single item (by copying it).
+	// Allocates memory if required. Only fails if memory allocation fails (or implicit
+	// production is disabled because Traits::INITIAL_IMPLICIT_PRODUCER_HASH_SIZE is 0,
+	// or Traits::MAX_SUBQUEUE_SIZE has been defined and would be surpassed).
+	// Thread-safe.
+	inline bool enqueue(T const& item)
+	{
+		if (details::likely(inner.enqueue(item))) {
+			sema->signal();
+			return true;
+		}
+		return false;
+	}
+
+	// Enqueues a single item (by moving it, if possible).
+	// Allocates memory if required. Only fails if memory allocation fails (or implicit
+	// production is disabled because Traits::INITIAL_IMPLICIT_PRODUCER_HASH_SIZE is 0,
+	// or Traits::MAX_SUBQUEUE_SIZE has been defined and would be surpassed).
+	// Thread-safe.
+	inline bool enqueue(T&& item)
+	{
+		if (details::likely(inner.enqueue(std::move(item)))) {
+			sema->signal();
+			return true;
+		}
+		return false;
+	}
+
+	// Enqueues a single item (by copying it) using an explicit producer token.
+	// Allocates memory if required. Only fails if memory allocation fails (or
+	// Traits::MAX_SUBQUEUE_SIZE has been defined and would be surpassed).
+	// Thread-safe.
+	inline bool enqueue(producer_token_t const& token, T const& item)
+	{
+		if (details::likely(inner.enqueue(token, item))) {
+			sema->signal();
+			return true;
+		}
+		return false;
+	}
+
+	// Enqueues a single item (by moving it, if possible) using an explicit producer token.
+	// Allocates memory if required. Only fails if memory allocation fails (or
+	// Traits::MAX_SUBQUEUE_SIZE has been defined and would be surpassed).
+	// Thread-safe.
+	inline bool enqueue(producer_token_t const& token, T&& item)
+	{
+		if (details::likely(inner.enqueue(token, std::move(item)))) {
+			sema->signal();
+			return true;
+		}
+		return false;
+	}
+
+	// Enqueues several items.
+	// Allocates memory if required. Only fails if memory allocation fails (or
+	// implicit production is disabled because Traits::INITIAL_IMPLICIT_PRODUCER_HASH_SIZE
+	// is 0, or Traits::MAX_SUBQUEUE_SIZE has been defined and would be surpassed).
+	// Note: Use std::make_move_iterator if the elements should be moved instead of copied.
+	// Thread-safe.
+	template<typename It>
+	inline bool enqueue_bulk(It itemFirst, size_t count)
+	{
+		if (details::likely(inner.enqueue_bulk(std::forward<It>(itemFirst), count))) {
+			sema->signal((LightweightSemaphore::ssize_t)(ssize_t)count);
+			return true;
+		}
+		return false;
+	}
+
+	// Enqueues several items using an explicit producer token.
+	// Allocates memory if required. Only fails if memory allocation fails
+	// (or Traits::MAX_SUBQUEUE_SIZE has been defined and would be surpassed).
+	// Note: Use std::make_move_iterator if the elements should be moved
+	// instead of copied.
+	// Thread-safe.
+	template<typename It>
+	inline bool enqueue_bulk(producer_token_t const& token, It itemFirst, size_t count)
+	{
+		if (details::likely(inner.enqueue_bulk(token, std::forward<It>(itemFirst), count))) {
+			sema->signal((LightweightSemaphore::ssize_t)(ssize_t)count);
+			return true;
+		}
+		return false;
+	}
+
+	// Enqueues a single item (by copying it).
+	// Does not allocate memory. Fails if not enough room to enqueue (or implicit
+	// production is disabled because Traits::INITIAL_IMPLICIT_PRODUCER_HASH_SIZE
+	// is 0).
+	// Thread-safe.
+	inline bool try_enqueue(T const& item)
+	{
+		if (inner.try_enqueue(item)) {
+			sema->signal();
+			return true;
+		}
+		return false;
+	}
+
+	// Enqueues a single item (by moving it, if possible).
+	// Does not allocate memory (except for one-time implicit producer).
+	// Fails if not enough room to enqueue (or implicit production is
+	// disabled because Traits::INITIAL_IMPLICIT_PRODUCER_HASH_SIZE is 0).
+	// Thread-safe.
+	inline bool try_enqueue(T&& item)
+	{
+		if (inner.try_enqueue(std::move(item))) {
+			sema->signal();
+			return true;
+		}
+		return false;
+	}
+
+	// Enqueues a single item (by copying it) using an explicit producer token.
+	// Does not allocate memory. Fails if not enough room to enqueue.
+	// Thread-safe.
+	inline bool try_enqueue(producer_token_t const& token, T const& item)
+	{
+		if (inner.try_enqueue(token, item)) {
+			sema->signal();
+			return true;
+		}
+		return false;
+	}
+
+	// Enqueues a single item (by moving it, if possible) using an explicit producer token.
+	// Does not allocate memory. Fails if not enough room to enqueue.
+	// Thread-safe.
+	inline bool try_enqueue(producer_token_t const& token, T&& item)
+	{
+		if (inner.try_enqueue(token, std::move(item))) {
+			sema->signal();
+			return true;
+		}
+		return false;
+	}
+
+	// Enqueues several items.
+	// Does not allocate memory (except for one-time implicit producer).
+	// Fails if not enough room to enqueue (or implicit production is
+	// disabled because Traits::INITIAL_IMPLICIT_PRODUCER_HASH_SIZE is 0).
+	// Note: Use std::make_move_iterator if the elements should be moved
+	// instead of copied.
+	// Thread-safe.
+	template<typename It>
+	inline bool try_enqueue_bulk(It itemFirst, size_t count)
+	{
+		if (inner.try_enqueue_bulk(std::forward<It>(itemFirst), count)) {
+			sema->signal((LightweightSemaphore::ssize_t)(ssize_t)count);
+			return true;
+		}
+		return false;
+	}
+
+	// Enqueues several items using an explicit producer token.
+	// Does not allocate memory. Fails if not enough room to enqueue.
+	// Note: Use std::make_move_iterator if the elements should be moved
+	// instead of copied.
+	// Thread-safe.
+	template<typename It>
+	inline bool try_enqueue_bulk(producer_token_t const& token, It itemFirst, size_t count)
+	{
+		if (inner.try_enqueue_bulk(token, std::forward<It>(itemFirst), count)) {
+			sema->signal((LightweightSemaphore::ssize_t)(ssize_t)count);
+			return true;
+		}
+		return false;
+	}
+
+
+	// Attempts to dequeue from the queue.
+	// Returns false if all producer streams appeared empty at the time they
+	// were checked (so, the queue is likely but not guaranteed to be empty).
+	// Never allocates. Thread-safe.
+	template<typename U>
+	inline bool try_dequeue(U& item)
+	{
+		if (sema->tryWait()) {
+			while (!inner.try_dequeue(item)) {
+				continue;
+			}
+			return true;
+		}
+		return false;
+	}
+
+	// Attempts to dequeue from the queue using an explicit consumer token.
+	// Returns false if all producer streams appeared empty at the time they
+	// were checked (so, the queue is likely but not guaranteed to be empty).
+	// Never allocates. Thread-safe.
+	template<typename U>
+	inline bool try_dequeue(consumer_token_t& token, U& item)
+	{
+		if (sema->tryWait()) {
+			while (!inner.try_dequeue(token, item)) {
+				continue;
+			}
+			return true;
+		}
+		return false;
+	}
+
+	// Attempts to dequeue several elements from the queue.
+	// Returns the number of items actually dequeued.
+	// Returns 0 if all producer streams appeared empty at the time they
+	// were checked (so, the queue is likely but not guaranteed to be empty).
+	// Never allocates. Thread-safe.
+	template<typename It>
+	inline size_t try_dequeue_bulk(It itemFirst, size_t max)
+	{
+		size_t count = 0;
+		max = (size_t)sema->tryWaitMany((LightweightSemaphore::ssize_t)(ssize_t)max);
+		while (count != max) {
+			count += inner.template try_dequeue_bulk<It&>(itemFirst, max - count);
+		}
+		return count;
+	}
+
+	// Attempts to dequeue several elements from the queue using an explicit consumer token.
+	// Returns the number of items actually dequeued.
+	// Returns 0 if all producer streams appeared empty at the time they
+	// were checked (so, the queue is likely but not guaranteed to be empty).
+	// Never allocates. Thread-safe.
+	template<typename It>
+	inline size_t try_dequeue_bulk(consumer_token_t& token, It itemFirst, size_t max)
+	{
+		size_t count = 0;
+		max = (size_t)sema->tryWaitMany((LightweightSemaphore::ssize_t)(ssize_t)max);
+		while (count != max) {
+			count += inner.template try_dequeue_bulk<It&>(token, itemFirst, max - count);
+		}
+		return count;
+	}
+
+
+
+	// Blocks the current thread until there's something to dequeue, then
+	// dequeues it.
+	// Never allocates. Thread-safe.
+	template<typename U>
+	inline void wait_dequeue(U& item)
+	{
+		sema->wait();
+		while (!inner.try_dequeue(item)) {
+			continue;
+		}
+	}
+
+	// Blocks the current thread until either there's something to dequeue
+	// or the timeout (specified in microseconds) expires. Returns false
+	// without setting `item` if the timeout expires, otherwise assigns
+	// to `item` and returns true.
+	// Using a negative timeout indicates an indefinite timeout,
+	// and is thus functionally equivalent to calling wait_dequeue.
+	// Never allocates. Thread-safe.
+	template<typename U>
+	inline bool wait_dequeue_timed(U& item, std::int64_t timeout_usecs)
+	{
+		if (!sema->wait(timeout_usecs)) {
+			return false;
+		}
+		while (!inner.try_dequeue(item)) {
+			continue;
+		}
+		return true;
+	}
+
+    // Blocks the current thread until either there's something to dequeue
+	// or the timeout expires. Returns false without setting `item` if the
+    // timeout expires, otherwise assigns to `item` and returns true.
+	// Never allocates. Thread-safe.
+	template<typename U, typename Rep, typename Period>
+	inline bool wait_dequeue_timed(U& item, std::chrono::duration<Rep, Period> const& timeout)
+    {
+        return wait_dequeue_timed(item, std::chrono::duration_cast<std::chrono::microseconds>(timeout).count());
+    }
+
+	// Blocks the current thread until there's something to dequeue, then
+	// dequeues it using an explicit consumer token.
+	// Never allocates. Thread-safe.
+	template<typename U>
+	inline void wait_dequeue(consumer_token_t& token, U& item)
+	{
+		sema->wait();
+		while (!inner.try_dequeue(token, item)) {
+			continue;
+		}
+	}
+
+	// Blocks the current thread until either there's something to dequeue
+	// or the timeout (specified in microseconds) expires. Returns false
+	// without setting `item` if the timeout expires, otherwise assigns
+	// to `item` and returns true.
+	// Using a negative timeout indicates an indefinite timeout,
+	// and is thus functionally equivalent to calling wait_dequeue.
+	// Never allocates. Thread-safe.
+	template<typename U>
+	inline bool wait_dequeue_timed(consumer_token_t& token, U& item, std::int64_t timeout_usecs)
+	{
+		if (!sema->wait(timeout_usecs)) {
+			return false;
+		}
+		while (!inner.try_dequeue(token, item)) {
+			continue;
+		}
+		return true;
+	}
+
+    // Blocks the current thread until either there's something to dequeue
+	// or the timeout expires. Returns false without setting `item` if the
+    // timeout expires, otherwise assigns to `item` and returns true.
+	// Never allocates. Thread-safe.
+	template<typename U, typename Rep, typename Period>
+	inline bool wait_dequeue_timed(consumer_token_t& token, U& item, std::chrono::duration<Rep, Period> const& timeout)
+    {
+        return wait_dequeue_timed(token, item, std::chrono::duration_cast<std::chrono::microseconds>(timeout).count());
+    }
+
+	// Attempts to dequeue several elements from the queue.
+	// Returns the number of items actually dequeued, which will
+	// always be at least one (this method blocks until the queue
+	// is non-empty) and at most max.
+	// Never allocates. Thread-safe.
+	template<typename It>
+	inline size_t wait_dequeue_bulk(It itemFirst, size_t max)
+	{
+		size_t count = 0;
+		max = (size_t)sema->waitMany((LightweightSemaphore::ssize_t)(ssize_t)max);
+		while (count != max) {
+			count += inner.template try_dequeue_bulk<It&>(itemFirst, max - count);
+		}
+		return count;
+	}
+
+	// Attempts to dequeue several elements from the queue.
+	// Returns the number of items actually dequeued, which can
+	// be 0 if the timeout expires while waiting for elements,
+	// and at most max.
+	// Using a negative timeout indicates an indefinite timeout,
+	// and is thus functionally equivalent to calling wait_dequeue_bulk.
+	// Never allocates. Thread-safe.
+	template<typename It>
+	inline size_t wait_dequeue_bulk_timed(It itemFirst, size_t max, std::int64_t timeout_usecs)
+	{
+		size_t count = 0;
+		max = (size_t)sema->waitMany((LightweightSemaphore::ssize_t)(ssize_t)max, timeout_usecs);
+		while (count != max) {
+			count += inner.template try_dequeue_bulk<It&>(itemFirst, max - count);
+		}
+		return count;
+	}
+
+    // Attempts to dequeue several elements from the queue.
+	// Returns the number of items actually dequeued, which can
+	// be 0 if the timeout expires while waiting for elements,
+	// and at most max.
+	// Never allocates. Thread-safe.
+	template<typename It, typename Rep, typename Period>
+	inline size_t wait_dequeue_bulk_timed(It itemFirst, size_t max, std::chrono::duration<Rep, Period> const& timeout)
+    {
+        return wait_dequeue_bulk_timed<It&>(itemFirst, max, std::chrono::duration_cast<std::chrono::microseconds>(timeout).count());
+    }
+
+	// Attempts to dequeue several elements from the queue using an explicit consumer token.
+	// Returns the number of items actually dequeued, which will
+	// always be at least one (this method blocks until the queue
+	// is non-empty) and at most max.
+	// Never allocates. Thread-safe.
+	template<typename It>
+	inline size_t wait_dequeue_bulk(consumer_token_t& token, It itemFirst, size_t max)
+	{
+		size_t count = 0;
+		max = (size_t)sema->waitMany((LightweightSemaphore::ssize_t)(ssize_t)max);
+		while (count != max) {
+			count += inner.template try_dequeue_bulk<It&>(token, itemFirst, max - count);
+		}
+		return count;
+	}
+
+	// Attempts to dequeue several elements from the queue using an explicit consumer token.
+	// Returns the number of items actually dequeued, which can
+	// be 0 if the timeout expires while waiting for elements,
+	// and at most max.
+	// Using a negative timeout indicates an indefinite timeout,
+	// and is thus functionally equivalent to calling wait_dequeue_bulk.
+	// Never allocates. Thread-safe.
+	template<typename It>
+	inline size_t wait_dequeue_bulk_timed(consumer_token_t& token, It itemFirst, size_t max, std::int64_t timeout_usecs)
+	{
+		size_t count = 0;
+		max = (size_t)sema->waitMany((LightweightSemaphore::ssize_t)(ssize_t)max, timeout_usecs);
+		while (count != max) {
+			count += inner.template try_dequeue_bulk<It&>(token, itemFirst, max - count);
+		}
+		return count;
+	}
+
+	// Attempts to dequeue several elements from the queue using an explicit consumer token.
+	// Returns the number of items actually dequeued, which can
+	// be 0 if the timeout expires while waiting for elements,
+	// and at most max.
+	// Never allocates. Thread-safe.
+	template<typename It, typename Rep, typename Period>
+	inline size_t wait_dequeue_bulk_timed(consumer_token_t& token, It itemFirst, size_t max, std::chrono::duration<Rep, Period> const& timeout)
+    {
+        return wait_dequeue_bulk_timed<It&>(token, itemFirst, max, std::chrono::duration_cast<std::chrono::microseconds>(timeout).count());
+    }
+
+
+	// Returns an estimate of the total number of elements currently in the queue. This
+	// estimate is only accurate if the queue has completely stabilized before it is called
+	// (i.e. all enqueue and dequeue operations have completed and their memory effects are
+	// visible on the calling thread, and no further operations start while this method is
+	// being called).
+	// Thread-safe.
+	inline size_t size_approx() const
+	{
+		return (size_t)sema->availableApprox();
+	}
+
+
+	// Returns true if the underlying atomic variables used by
+	// the queue are lock-free (they should be on most platforms).
+	// Thread-safe.
+	static bool is_lock_free()
+	{
+		return ConcurrentQueue::is_lock_free();
+	}
+
+
+private:
+	template<typename U>
+	static inline U* create()
+	{
+		auto p = (Traits::malloc)(sizeof(U));
+		return p != nullptr ? new (p) U : nullptr;
+	}
+
+	template<typename U, typename A1>
+	static inline U* create(A1&& a1)
+	{
+		auto p = (Traits::malloc)(sizeof(U));
+		return p != nullptr ? new (p) U(std::forward<A1>(a1)) : nullptr;
+	}
+
+	template<typename U>
+	static inline void destroy(U* p)
+	{
+		if (p != nullptr) {
+			p->~U();
+		}
+		(Traits::free)(p);
+	}
+
+private:
+	ConcurrentQueue inner;
+	std::unique_ptr<LightweightSemaphore, void (*)(LightweightSemaphore*)> sema;
+};
+
+
+template<typename T, typename Traits>
+inline void swap(BlockingConcurrentQueue<T, Traits>& a, BlockingConcurrentQueue<T, Traits>& b) MOODYCAMEL_NOEXCEPT
+{
+	a.swap(b);
+}
+
+}	// end namespace moodycamel
+}  // namespace dmlc
+
+#endif  // DMLC_BLOCKINGCONCURRENTQUEUE_H_
+//! \endcond Doxygen_Suppress
diff --git a/darknet_drp_ros/include/dmlc/build_config_default.h b/darknet_drp_ros/include/dmlc/build_config_default.h
new file mode 100644
index 0000000..e57367c
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/build_config_default.h
@@ -0,0 +1,39 @@
+/*!
+ * Copyright (c) 2018 by Contributors
+ * \file build_config_default.h
+ * \brief Default detection logic for fopen64 and other symbols.
+ *        May be overriden by CMake
+ * \author KOLANICH
+ */
+#ifndef DMLC_BUILD_CONFIG_DEFAULT_H_
+#define DMLC_BUILD_CONFIG_DEFAULT_H_
+
+/* default logic for fopen64 */
+#if DMLC_USE_FOPEN64 && \
+  (!defined(__GNUC__) || (defined __ANDROID__) || (defined __FreeBSD__) \
+  || (defined __APPLE__) || ((defined __MINGW32__) && !(defined __MINGW64__)) \
+  || (defined __CYGWIN__) )
+  #define fopen64 std::fopen
+#endif
+
+/* default logic for stack trace */
+#if (defined(__GNUC__) && !defined(__MINGW32__)\
+     && !defined(__sun) && !defined(__SVR4)\
+     && !(defined __MINGW64__) && !(defined __ANDROID__))\
+     && !defined(__CYGWIN__) && !defined(__EMSCRIPTEN__)\
+     && !defined(__RISCV__) && !defined(__hexagon__)
+  #ifndef DMLC_LOG_STACK_TRACE
+  #define DMLC_LOG_STACK_TRACE 1
+  #endif
+  #ifndef DMLC_LOG_STACK_TRACE_SIZE
+  #define DMLC_LOG_STACK_TRACE_SIZE 10
+  #endif
+  #define DMLC_EXECINFO_H <execinfo.h>
+#endif
+
+/* default logic for detecting existence of nanosleep() */
+#if !(defined _WIN32) || (defined __CYGWIN__)
+  #define DMLC_NANOSLEEP_PRESENT
+#endif
+
+#endif  // DMLC_BUILD_CONFIG_DEFAULT_H_
diff --git a/darknet_drp_ros/include/dmlc/common.h b/darknet_drp_ros/include/dmlc/common.h
new file mode 100644
index 0000000..f2f0c73
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/common.h
@@ -0,0 +1,91 @@
+/*!
+ *  Copyright (c) 2015 by Contributors
+ * \file common.h
+ * \brief defines some common utility function.
+ */
+#ifndef DMLC_COMMON_H_
+#define DMLC_COMMON_H_
+
+#include <vector>
+#include <string>
+#include <sstream>
+#include <mutex>
+#include <utility>
+#include "./logging.h"
+
+namespace dmlc {
+/*!
+ * \brief Split a string by delimiter
+ * \param s String to be splitted.
+ * \param delim The delimiter.
+ * \return a splitted vector of strings.
+ */
+inline std::vector<std::string> Split(const std::string& s, char delim) {
+  std::string item;
+  std::istringstream is(s);
+  std::vector<std::string> ret;
+  while (std::getline(is, item, delim)) {
+    ret.push_back(item);
+  }
+  return ret;
+}
+
+/*!
+ * \brief hash an object and combines the key with previous keys
+ */
+template<typename T>
+inline size_t HashCombine(size_t key, const T& value) {
+  std::hash<T> hash_func;
+  return key ^ (hash_func(value) + 0x9e3779b9 + (key << 6) + (key >> 2));
+}
+
+/*!
+ * \brief specialize for size_t
+ */
+template<>
+inline size_t HashCombine<size_t>(size_t key, const size_t& value) {
+  return key ^ (value + 0x9e3779b9 + (key << 6) + (key >> 2));
+}
+
+/*!
+ * \brief OMP Exception class catches, saves and rethrows exception from OMP blocks
+ */
+class OMPException {
+ private:
+  // exception_ptr member to store the exception
+  std::exception_ptr omp_exception_;
+  // mutex to be acquired during catch to set the exception_ptr
+  std::mutex mutex_;
+
+ public:
+  /*!
+   * \brief Parallel OMP blocks should be placed within Run to save exception
+   */
+  template <typename Function, typename... Parameters>
+  void Run(Function f, Parameters... params) {
+    try {
+      f(params...);
+    } catch (dmlc::Error &ex) {
+      std::lock_guard<std::mutex> lock(mutex_);
+      if (!omp_exception_) {
+        omp_exception_ = std::current_exception();
+      }
+    } catch (std::exception &ex) {
+      std::lock_guard<std::mutex> lock(mutex_);
+      if (!omp_exception_) {
+        omp_exception_ = std::current_exception();
+      }
+    }
+  }
+
+  /*!
+   * \brief should be called from the main thread to rethrow the exception
+   */
+  void Rethrow() {
+    if (this->omp_exception_) std::rethrow_exception(this->omp_exception_);
+  }
+};
+
+}  // namespace dmlc
+
+#endif  // DMLC_COMMON_H_
diff --git a/darknet_drp_ros/include/dmlc/concurrency.h b/darknet_drp_ros/include/dmlc/concurrency.h
new file mode 100644
index 0000000..105c576
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/concurrency.h
@@ -0,0 +1,263 @@
+/*!
+ * Copyright (c) 2015 by Contributors
+ * \file concurrency.h
+ * \brief thread-safe data structures.
+ * \author Yutian Li
+ */
+#ifndef DMLC_CONCURRENCY_H_
+#define DMLC_CONCURRENCY_H_
+// this code depends on c++11
+#if DMLC_USE_CXX11
+#include <atomic>
+#include <deque>
+#include <queue>
+#include <mutex>
+#include <vector>
+#include <utility>
+#include <condition_variable>
+#include "dmlc/base.h"
+
+namespace dmlc {
+
+/*!
+ * \brief Simple userspace spinlock implementation.
+ */
+class Spinlock {
+ public:
+#ifdef _MSC_VER
+  Spinlock() {
+    lock_.clear();
+  }
+#else
+#if defined(__clang__)
+#pragma clang diagnostic push
+#pragma clang diagnostic ignored "-Wbraced-scalar-init"
+#endif  // defined(__clang__)
+  Spinlock() : lock_(ATOMIC_FLAG_INIT) {
+  }
+#if defined(__clang__)
+#pragma clang diagnostic pop
+#endif  // defined(__clang__)
+#endif
+  ~Spinlock() = default;
+  /*!
+   * \brief Acquire lock.
+   */
+  inline void lock() noexcept(true);
+  /*!
+   * \brief Release lock.
+   */
+  inline void unlock() noexcept(true);
+
+ private:
+  std::atomic_flag lock_;
+  /*!
+   * \brief Disable copy and move.
+   */
+  DISALLOW_COPY_AND_ASSIGN(Spinlock);
+};
+
+/*! \brief type of concurrent queue */
+enum class ConcurrentQueueType {
+  /*! \brief FIFO queue */
+  kFIFO,
+  /*! \brief queue with priority */
+  kPriority
+};
+
+/*!
+ * \brief Cocurrent blocking queue.
+ */
+template <typename T,
+          ConcurrentQueueType type = ConcurrentQueueType::kFIFO>
+class ConcurrentBlockingQueue {
+ public:
+  ConcurrentBlockingQueue();
+  ~ConcurrentBlockingQueue() = default;
+  /*!
+   * \brief Push element to the end of the queue.
+   * \param e Element to push into.
+   * \param priority the priority of the element, only used for priority queue.
+   *            The higher the priority is, the better.
+   * \tparam E the element type
+   *
+   * It will copy or move the element into the queue, depending on the type of
+   * the parameter.
+   */
+  template <typename E>
+  void Push(E&& e, int priority = 0);
+
+  /*!
+   * \brief Push element to the front of the queue. Only works for FIFO queue.
+   *        For priority queue it is the same as Push.
+   * \param e Element to push into.
+   * \param priority the priority of the element, only used for priority queue.
+   *            The higher the priority is, the better.
+   * \tparam E the element type
+   *
+   * It will copy or move the element into the queue, depending on the type of
+   * the parameter.
+   */
+  template <typename E>
+  void PushFront(E&& e, int priority = 0);
+  /*!
+   * \brief Pop element from the queue.
+   * \param rv Element popped.
+   * \return On false, the queue is exiting.
+   *
+   * The element will be copied or moved into the object passed in.
+   */
+  bool Pop(T* rv);
+  /*!
+   * \brief Signal the queue for destruction.
+   *
+   * After calling this method, all blocking pop call to the queue will return
+   * false.
+   */
+  void SignalForKill();
+  /*!
+   * \brief Get the size of the queue.
+   * \return The size of the queue.
+   */
+  size_t Size();
+
+ private:
+  struct Entry {
+    T data;
+    int priority;
+    inline bool operator<(const Entry &b) const {
+      return priority < b.priority;
+    }
+  };
+
+  std::mutex mutex_;
+  std::condition_variable cv_;
+  std::atomic<bool> exit_now_;
+  int nwait_consumer_;
+  // a priority queue
+  std::vector<Entry> priority_queue_;
+  // a FIFO queue
+  std::deque<T> fifo_queue_;
+  /*!
+   * \brief Disable copy and move.
+   */
+  DISALLOW_COPY_AND_ASSIGN(ConcurrentBlockingQueue);
+};
+
+inline void Spinlock::lock() noexcept(true) {
+  while (lock_.test_and_set(std::memory_order_acquire)) {
+  }
+}
+
+inline void Spinlock::unlock() noexcept(true) {
+  lock_.clear(std::memory_order_release);
+}
+
+template <typename T, ConcurrentQueueType type>
+ConcurrentBlockingQueue<T, type>::ConcurrentBlockingQueue()
+    : exit_now_{false}, nwait_consumer_{0} {}
+
+template <typename T, ConcurrentQueueType type>
+template <typename E>
+void ConcurrentBlockingQueue<T, type>::Push(E&& e, int priority) {
+  static_assert(std::is_same<typename std::remove_cv<
+                                 typename std::remove_reference<E>::type>::type,
+                             T>::value,
+                "Types must match.");
+  bool notify;
+  {
+    std::lock_guard<std::mutex> lock{mutex_};
+    if (type == ConcurrentQueueType::kFIFO) {
+      fifo_queue_.emplace_back(std::forward<E>(e));
+      notify = nwait_consumer_ != 0;
+    } else {
+      Entry entry;
+      entry.data = std::move(e);
+      entry.priority = priority;
+      priority_queue_.push_back(std::move(entry));
+      std::push_heap(priority_queue_.begin(), priority_queue_.end());
+      notify = nwait_consumer_ != 0;
+    }
+  }
+  if (notify) cv_.notify_one();
+}
+
+template <typename T, ConcurrentQueueType type>
+template <typename E>
+void ConcurrentBlockingQueue<T, type>::PushFront(E&& e, int priority) {
+  static_assert(std::is_same<typename std::remove_cv<
+                                 typename std::remove_reference<E>::type>::type,
+                             T>::value,
+                "Types must match.");
+  bool notify;
+  {
+    std::lock_guard<std::mutex> lock{mutex_};
+    if (type == ConcurrentQueueType::kFIFO) {
+      fifo_queue_.emplace_front(std::forward<E>(e));
+      notify = nwait_consumer_ != 0;
+    } else {
+      Entry entry;
+      entry.data = std::move(e);
+      entry.priority = priority;
+      priority_queue_.push_back(std::move(entry));
+      std::push_heap(priority_queue_.begin(), priority_queue_.end());
+      notify = nwait_consumer_ != 0;
+    }
+  }
+  if (notify) cv_.notify_one();
+}
+
+template <typename T, ConcurrentQueueType type>
+bool ConcurrentBlockingQueue<T, type>::Pop(T* rv) {
+  std::unique_lock<std::mutex> lock{mutex_};
+  if (type == ConcurrentQueueType::kFIFO) {
+    ++nwait_consumer_;
+    cv_.wait(lock, [this] {
+        return !fifo_queue_.empty() || exit_now_.load();
+      });
+    --nwait_consumer_;
+    if (!exit_now_.load()) {
+      *rv = std::move(fifo_queue_.front());
+      fifo_queue_.pop_front();
+      return true;
+    } else {
+      return false;
+    }
+  } else {
+    ++nwait_consumer_;
+    cv_.wait(lock, [this] {
+        return !priority_queue_.empty() || exit_now_.load();
+      });
+    --nwait_consumer_;
+    if (!exit_now_.load()) {
+      std::pop_heap(priority_queue_.begin(), priority_queue_.end());
+      *rv = std::move(priority_queue_.back().data);
+      priority_queue_.pop_back();
+      return true;
+    } else {
+      return false;
+    }
+  }
+}
+
+template <typename T, ConcurrentQueueType type>
+void ConcurrentBlockingQueue<T, type>::SignalForKill() {
+  {
+    std::lock_guard<std::mutex> lock{mutex_};
+    exit_now_.store(true);
+  }
+  cv_.notify_all();
+}
+
+template <typename T, ConcurrentQueueType type>
+size_t ConcurrentBlockingQueue<T, type>::Size() {
+  std::lock_guard<std::mutex> lock{mutex_};
+  if (type == ConcurrentQueueType::kFIFO) {
+    return fifo_queue_.size();
+  } else {
+    return priority_queue_.size();
+  }
+}
+}  // namespace dmlc
+#endif  // DMLC_USE_CXX11
+#endif  // DMLC_CONCURRENCY_H_
diff --git a/darknet_drp_ros/include/dmlc/concurrentqueue.h b/darknet_drp_ros/include/dmlc/concurrentqueue.h
new file mode 100644
index 0000000..e80e84a
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/concurrentqueue.h
@@ -0,0 +1,3719 @@
+//! \cond Doxygen_Suppress
+// Provides a C++11 implementation of a multi-producer, multi-consumer lock-free queue.
+// An overview, including benchmark results, is provided here:
+//     http://moodycamel.com/blog/2014/a-fast-general-purpose-lock-free-queue-for-c++
+// The full design is also described in excruciating detail at:
+//    http://moodycamel.com/blog/2014/detailed-design-of-a-lock-free-queue
+
+// Simplified BSD license:
+// Copyright (c) 2013-2016, Cameron Desrochers.
+// All rights reserved.
+//
+// Redistribution and use in source and binary forms, with or without modification,
+// are permitted provided that the following conditions are met:
+//
+// - Redistributions of source code must retain the above copyright notice, this list of
+// conditions and the following disclaimer.
+// - Redistributions in binary form must reproduce the above copyright notice, this list of
+// conditions and the following disclaimer in the documentation and/or other materials
+// provided with the distribution.
+//
+// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY
+// EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+// MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL
+// THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+// OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+// HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR
+// TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
+// EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+#ifndef DMLC_CONCURRENTQUEUE_H_
+#define DMLC_CONCURRENTQUEUE_H_
+#pragma once
+
+#if defined(__GNUC__)
+// Disable -Wconversion warnings (spuriously triggered when Traits::size_t and
+// Traits::index_t are set to < 32 bits, causing integer promotion, causing warnings
+// upon assigning any computed values)
+#pragma GCC diagnostic push
+#pragma GCC diagnostic ignored "-Wconversion"
+
+#ifdef MCDBGQ_USE_RELACY
+#pragma GCC diagnostic ignored "-Wint-to-pointer-cast"
+#endif
+#endif
+
+#if defined(_WIN32) || defined(__WINDOWS__) || defined(__WIN32__) || defined(_WIN64)
+#include <windows.h>  // for GetCurrentThreadId()
+#endif
+
+#if defined(__APPLE__)
+#include "TargetConditionals.h"
+#endif
+
+#ifdef MCDBGQ_USE_RELACY
+#include "relacy/relacy_std.hpp"
+#include "relacy_shims.h"
+// We only use malloc/free anyway, and the delete macro messes up `= delete` method declarations.
+// We'll override the default trait malloc ourselves without a macro.
+#undef new
+#undef delete
+#undef malloc
+#undef free
+#else
+#include <atomic>		// Requires C++11. Sorry VS2010.
+#include <cassert>
+#endif
+#include <cstddef>              // for max_align_t
+#include <cstdint>
+#include <cstdlib>
+#include <type_traits>
+#include <algorithm>
+#include <utility>
+#include <limits>
+#include <climits>		// for CHAR_BIT
+#include <array>
+#include <thread>		// partly for __WINPTHREADS_VERSION if on MinGW-w64 w/ POSIX threading
+
+namespace dmlc {
+
+// Platform-specific definitions of a numeric thread ID type and an invalid value
+namespace moodycamel { namespace details {
+template<typename thread_id_t> struct thread_id_converter {
+  typedef thread_id_t thread_id_numeric_size_t;
+  typedef thread_id_t thread_id_hash_t;
+  static thread_id_hash_t prehash(thread_id_t const& x) { return x; }
+};
+} }
+#if defined(MCDBGQ_USE_RELACY)
+namespace moodycamel { namespace details {
+  typedef std::uint32_t thread_id_t;
+  static const thread_id_t invalid_thread_id  = 0xFFFFFFFFU;
+  static const thread_id_t invalid_thread_id2 = 0xFFFFFFFEU;
+  static inline thread_id_t thread_id() { return rl::thread_index(); }
+} }
+#elif defined(_WIN32) || defined(__WINDOWS__) || defined(__WIN32__)
+// No sense pulling in windows.h in a header, we'll manually declare the function
+// we use and rely on backwards-compatibility for this not to break
+extern "C" __declspec(dllimport) unsigned long __stdcall GetCurrentThreadId(void);
+namespace moodycamel { namespace details {
+  static_assert(sizeof(unsigned long) == sizeof(std::uint32_t), "Expected size of unsigned long to be 32 bits on Windows");
+  typedef std::uint32_t thread_id_t;
+  static const thread_id_t invalid_thread_id  = 0;			// See http://blogs.msdn.com/b/oldnewthing/archive/2004/02/23/78395.aspx
+  static const thread_id_t invalid_thread_id2 = 0xFFFFFFFFU;	// Not technically guaranteed to be invalid, but is never used in practice. Note that all Win32 thread IDs are presently multiples of 4.
+  static inline thread_id_t thread_id() { return static_cast<thread_id_t>(::GetCurrentThreadId()); }
+} }
+#elif defined(__arm__) || defined(_M_ARM) || defined(__aarch64__) || (defined(__APPLE__) && TARGET_OS_IPHONE)
+namespace moodycamel { namespace details {
+  static_assert(sizeof(std::thread::id) == 4 || sizeof(std::thread::id) == 8, "std::thread::id is expected to be either 4 or 8 bytes");
+
+  typedef std::thread::id thread_id_t;
+  static const thread_id_t invalid_thread_id;         // Default ctor creates invalid ID
+
+  // Note we don't define a invalid_thread_id2 since std::thread::id doesn't have one; it's
+  // only used if MOODYCAMEL_CPP11_THREAD_LOCAL_SUPPORTED is defined anyway, which it won't
+  // be.
+  static inline thread_id_t thread_id() { return std::this_thread::get_id(); }
+
+  template<std::size_t> struct thread_id_size { };
+  template<> struct thread_id_size<4> { typedef std::uint32_t numeric_t; };
+  template<> struct thread_id_size<8> { typedef std::uint64_t numeric_t; };
+
+  template<> struct thread_id_converter<thread_id_t> {
+    typedef thread_id_size<sizeof(thread_id_t)>::numeric_t thread_id_numeric_size_t;
+#ifndef __APPLE__
+    typedef std::size_t thread_id_hash_t;
+#else
+    typedef thread_id_numeric_size_t thread_id_hash_t;
+#endif
+
+    static thread_id_hash_t prehash(thread_id_t const& x)
+    {
+#ifndef __APPLE__
+      return std::hash<std::thread::id>()(x);
+#else
+      return *reinterpret_cast<thread_id_hash_t const*>(&x);
+#endif
+    }
+  };
+} }
+#else
+// Use a nice trick from this answer: http://stackoverflow.com/a/8438730/21475
+// In order to get a numeric thread ID in a platform-independent way, we use a thread-local
+// static variable's address as a thread identifier :-)
+#if defined(__GNUC__) || defined(__INTEL_COMPILER)
+#define MOODYCAMEL_THREADLOCAL __thread
+#elif defined(_MSC_VER)
+#define MOODYCAMEL_THREADLOCAL __declspec(thread)
+#else
+// Assume C++11 compliant compiler
+#define MOODYCAMEL_THREADLOCAL thread_local
+#endif
+namespace moodycamel { namespace details {
+typedef std::uintptr_t thread_id_t;
+static const thread_id_t invalid_thread_id  = 0;		// Address can't be nullptr
+static const thread_id_t invalid_thread_id2 = 1;		// Member accesses off a null pointer are also generally invalid. Plus it's not aligned.
+static inline thread_id_t thread_id() { static MOODYCAMEL_THREADLOCAL int x; return reinterpret_cast<thread_id_t>(&x); }
+} }
+#endif
+
+// Exceptions
+#ifndef MOODYCAMEL_EXCEPTIONS_ENABLED
+#if (defined(_MSC_VER) && defined(_CPPUNWIND)) || (defined(__GNUC__) && defined(__EXCEPTIONS)) || (!defined(_MSC_VER) && !defined(__GNUC__))
+#define MOODYCAMEL_EXCEPTIONS_ENABLED
+#endif
+#endif
+#ifdef MOODYCAMEL_EXCEPTIONS_ENABLED
+#define MOODYCAMEL_TRY try
+#define MOODYCAMEL_CATCH(...) catch(__VA_ARGS__)
+#define MOODYCAMEL_RETHROW throw
+#define MOODYCAMEL_THROW(expr) throw (expr)
+#else
+#define MOODYCAMEL_TRY if (true)
+#define MOODYCAMEL_CATCH(...) else if (false)
+#define MOODYCAMEL_RETHROW
+#define MOODYCAMEL_THROW(expr)
+#endif
+
+#ifndef MOODYCAMEL_NOEXCEPT
+#if !defined(MOODYCAMEL_EXCEPTIONS_ENABLED)
+#define MOODYCAMEL_NOEXCEPT
+#define MOODYCAMEL_NOEXCEPT_CTOR(type, valueType, expr) true
+#define MOODYCAMEL_NOEXCEPT_ASSIGN(type, valueType, expr) true
+#elif defined(_MSC_VER) && defined(_NOEXCEPT) && _MSC_VER < 1800
+// VS2012's std::is_nothrow_[move_]constructible is broken and returns true when it shouldn't :-(
+// We have to assume *all* non-trivial constructors may throw on VS2012!
+#define MOODYCAMEL_NOEXCEPT _NOEXCEPT
+#define MOODYCAMEL_NOEXCEPT_CTOR(type, valueType, expr) (std::is_rvalue_reference<valueType>::value && std::is_move_constructible<type>::value ? std::is_trivially_move_constructible<type>::value : std::is_trivially_copy_constructible<type>::value)
+#define MOODYCAMEL_NOEXCEPT_ASSIGN(type, valueType, expr) ((std::is_rvalue_reference<valueType>::value && std::is_move_assignable<type>::value ? std::is_trivially_move_assignable<type>::value || std::is_nothrow_move_assignable<type>::value : std::is_trivially_copy_assignable<type>::value || std::is_nothrow_copy_assignable<type>::value) && MOODYCAMEL_NOEXCEPT_CTOR(type, valueType, expr))
+#elif defined(_MSC_VER) && defined(_NOEXCEPT) && _MSC_VER < 1900
+#define MOODYCAMEL_NOEXCEPT _NOEXCEPT
+#define MOODYCAMEL_NOEXCEPT_CTOR(type, valueType, expr) (std::is_rvalue_reference<valueType>::value && std::is_move_constructible<type>::value ? std::is_trivially_move_constructible<type>::value || std::is_nothrow_move_constructible<type>::value : std::is_trivially_copy_constructible<type>::value || std::is_nothrow_copy_constructible<type>::value)
+#define MOODYCAMEL_NOEXCEPT_ASSIGN(type, valueType, expr) ((std::is_rvalue_reference<valueType>::value && std::is_move_assignable<type>::value ? std::is_trivially_move_assignable<type>::value || std::is_nothrow_move_assignable<type>::value : std::is_trivially_copy_assignable<type>::value || std::is_nothrow_copy_assignable<type>::value) && MOODYCAMEL_NOEXCEPT_CTOR(type, valueType, expr))
+#else
+#define MOODYCAMEL_NOEXCEPT noexcept
+#define MOODYCAMEL_NOEXCEPT_CTOR(type, valueType, expr) noexcept(expr)
+#define MOODYCAMEL_NOEXCEPT_ASSIGN(type, valueType, expr) noexcept(expr)
+#endif
+#endif
+
+#ifndef MOODYCAMEL_CPP11_THREAD_LOCAL_SUPPORTED
+#ifdef MCDBGQ_USE_RELACY
+#define MOODYCAMEL_CPP11_THREAD_LOCAL_SUPPORTED
+#else
+// VS2013 doesn't support `thread_local`, and MinGW-w64 w/ POSIX threading has a crippling bug: http://sourceforge.net/p/mingw-w64/bugs/445
+// g++ <=4.7 doesn't support thread_local either.
+// Finally, iOS/ARM doesn't have support for it either, and g++/ARM allows it to compile but it's unconfirmed to actually work
+#if (!defined(_MSC_VER) || _MSC_VER >= 1900) && (!defined(__MINGW32__) && !defined(__MINGW64__) || !defined(__WINPTHREADS_VERSION)) && (!defined(__GNUC__) || __GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 8)) && (!defined(__APPLE__) || !TARGET_OS_IPHONE) && !defined(__arm__) && !defined(_M_ARM) && !defined(__aarch64__)
+// Assume `thread_local` is fully supported in all other C++11 compilers/platforms
+//#define MOODYCAMEL_CPP11_THREAD_LOCAL_SUPPORTED    // always disabled for now since several users report having problems with it on
+#endif
+#endif
+#endif
+
+// VS2012 doesn't support deleted functions.
+// In this case, we declare the function normally but don't define it. A link error will be generated if the function is called.
+#ifndef MOODYCAMEL_DELETE_FUNCTION
+#if defined(_MSC_VER) && _MSC_VER < 1800
+#define MOODYCAMEL_DELETE_FUNCTION
+#else
+#define MOODYCAMEL_DELETE_FUNCTION = delete
+#endif
+#endif
+
+// Compiler-specific likely/unlikely hints
+namespace moodycamel { namespace details {
+#if defined(__GNUC__)
+inline bool likely(bool x) { return __builtin_expect((x), true); }
+inline bool unlikely(bool x) { return __builtin_expect((x), false); }
+#else
+inline bool likely(bool x) { return x; }
+  inline bool unlikely(bool x) { return x; }
+#endif
+} }
+
+#ifdef MOODYCAMEL_QUEUE_INTERNAL_DEBUG
+#include "internal/concurrentqueue_internal_debug.h"
+#endif
+
+namespace moodycamel {
+namespace details {
+template<typename T>
+struct const_numeric_max {
+  static_assert(std::is_integral<T>::value, "const_numeric_max can only be used with integers");
+  static const T value = std::numeric_limits<T>::is_signed
+                         ? (static_cast<T>(1) << (sizeof(T) * CHAR_BIT - 1)) - static_cast<T>(1)
+                         : static_cast<T>(-1);
+};
+
+#if defined(__GLIBCXX__)
+typedef ::max_align_t std_max_align_t;      // libstdc++ forgot to add it to std:: for a while
+#else
+typedef std::max_align_t std_max_align_t;   // Others (e.g. MSVC) insist it can *only* be accessed via std::
+#endif
+
+// Some platforms have incorrectly set max_align_t to a type with <8 bytes alignment even while supporting
+// 8-byte aligned scalar values (*cough* 32-bit iOS). Work around this with our own union. See issue #64.
+typedef union {
+  std_max_align_t x;
+  long long y;
+  void* z;
+} max_align_t;
+}
+
+// Default traits for the ConcurrentQueue. To change some of the
+// traits without re-implementing all of them, inherit from this
+// struct and shadow the declarations you wish to be different;
+// since the traits are used as a template type parameter, the
+// shadowed declarations will be used where defined, and the defaults
+// otherwise.
+struct ConcurrentQueueDefaultTraits
+{
+  // General-purpose size type. std::size_t is strongly recommended.
+  typedef std::size_t size_t;
+
+  // The type used for the enqueue and dequeue indices. Must be at least as
+  // large as size_t. Should be significantly larger than the number of elements
+  // you expect to hold at once, especially if you have a high turnover rate;
+  // for example, on 32-bit x86, if you expect to have over a hundred million
+  // elements or pump several million elements through your queue in a very
+  // short space of time, using a 32-bit type *may* trigger a race condition.
+  // A 64-bit int type is recommended in that case, and in practice will
+  // prevent a race condition no matter the usage of the queue. Note that
+  // whether the queue is lock-free with a 64-int type depends on the whether
+  // std::atomic<std::uint64_t> is lock-free, which is platform-specific.
+  typedef std::size_t index_t;
+
+  // Internally, all elements are enqueued and dequeued from multi-element
+  // blocks; this is the smallest controllable unit. If you expect few elements
+  // but many producers, a smaller block size should be favoured. For few producers
+  // and/or many elements, a larger block size is preferred. A sane default
+  // is provided. Must be a power of 2.
+  static const size_t BLOCK_SIZE = 32;
+
+  // For explicit producers (i.e. when using a producer token), the block is
+  // checked for being empty by iterating through a list of flags, one per element.
+  // For large block sizes, this is too inefficient, and switching to an atomic
+  // counter-based approach is faster. The switch is made for block sizes strictly
+  // larger than this threshold.
+  static const size_t EXPLICIT_BLOCK_EMPTY_COUNTER_THRESHOLD = 32;
+
+  // How many full blocks can be expected for a single explicit producer? This should
+  // reflect that number's maximum for optimal performance. Must be a power of 2.
+  static const size_t EXPLICIT_INITIAL_INDEX_SIZE = 32;
+
+  // How many full blocks can be expected for a single implicit producer? This should
+  // reflect that number's maximum for optimal performance. Must be a power of 2.
+  static const size_t IMPLICIT_INITIAL_INDEX_SIZE = 32;
+
+  // The initial size of the hash table mapping thread IDs to implicit producers.
+  // Note that the hash is resized every time it becomes half full.
+  // Must be a power of two, and either 0 or at least 1. If 0, implicit production
+  // (using the enqueue methods without an explicit producer token) is disabled.
+  static const size_t INITIAL_IMPLICIT_PRODUCER_HASH_SIZE = 32;
+
+  // Controls the number of items that an explicit consumer (i.e. one with a token)
+  // must consume before it causes all consumers to rotate and move on to the next
+  // internal queue.
+  static const std::uint32_t EXPLICIT_CONSUMER_CONSUMPTION_QUOTA_BEFORE_ROTATE = 256;
+
+  // The maximum number of elements (inclusive) that can be enqueued to a sub-queue.
+  // Enqueue operations that would cause this limit to be surpassed will fail. Note
+  // that this limit is enforced at the block level (for performance reasons), i.e.
+  // it's rounded up to the nearest block size.
+  static const size_t MAX_SUBQUEUE_SIZE = details::const_numeric_max<size_t>::value;
+
+
+#ifndef MCDBGQ_USE_RELACY
+  // Memory allocation can be customized if needed.
+  // malloc should return nullptr on failure, and handle alignment like std::malloc.
+#if defined(malloc) || defined(free)
+  // Gah, this is 2015, stop defining macros that break standard code already!
+  // Work around malloc/free being special macros:
+  static inline void* WORKAROUND_malloc(size_t size) { return malloc(size); }
+  static inline void WORKAROUND_free(void* ptr) { return free(ptr); }
+  static inline void* (malloc)(size_t size) { return WORKAROUND_malloc(size); }
+  static inline void (free)(void* ptr) { return WORKAROUND_free(ptr); }
+#else
+  static inline void* malloc(size_t size) { return std::malloc(size); }
+  static inline void free(void* ptr) { return std::free(ptr); }
+#endif
+#else
+  // Debug versions when running under the Relacy race detector (ignore
+  // these in user code)
+  static inline void* malloc(size_t size) { return rl::rl_malloc(size, $); }
+  static inline void free(void* ptr) { return rl::rl_free(ptr, $); }
+#endif
+};
+
+
+// When producing or consuming many elements, the most efficient way is to:
+//    1) Use one of the bulk-operation methods of the queue with a token
+//    2) Failing that, use the bulk-operation methods without a token
+//    3) Failing that, create a token and use that with the single-item methods
+//    4) Failing that, use the single-parameter methods of the queue
+// Having said that, don't create tokens willy-nilly -- ideally there should be
+// a maximum of one token per thread (of each kind).
+struct ProducerToken;
+struct ConsumerToken;
+
+template<typename T, typename Traits> class ConcurrentQueue;
+template<typename T, typename Traits> class BlockingConcurrentQueue;
+class ConcurrentQueueTests;
+
+
+namespace details
+{
+struct ConcurrentQueueProducerTypelessBase
+{
+  ConcurrentQueueProducerTypelessBase* next;
+  std::atomic<bool> inactive;
+  ProducerToken* token;
+
+  ConcurrentQueueProducerTypelessBase()
+    : next(nullptr), inactive(false), token(nullptr)
+  {
+  }
+};
+
+template<bool use32> struct _hash_32_or_64 {
+  static inline std::uint32_t hash(std::uint32_t h)
+  {
+    // MurmurHash3 finalizer -- see https://code.google.com/p/smhasher/source/browse/trunk/MurmurHash3.cpp
+    // Since the thread ID is already unique, all we really want to do is propagate that
+    // uniqueness evenly across all the bits, so that we can use a subset of the bits while
+    // reducing collisions significantly
+    h ^= h >> 16;
+    h *= 0x85ebca6b;
+    h ^= h >> 13;
+    h *= 0xc2b2ae35;
+    return h ^ (h >> 16);
+  }
+};
+template<> struct _hash_32_or_64<1> {
+  static inline std::uint64_t hash(std::uint64_t h)
+  {
+    h ^= h >> 33;
+    h *= 0xff51afd7ed558ccd;
+    h ^= h >> 33;
+    h *= 0xc4ceb9fe1a85ec53;
+    return h ^ (h >> 33);
+  }
+};
+template<std::size_t size> struct hash_32_or_64 : public _hash_32_or_64<(size > 4)> {  };
+
+static inline size_t hash_thread_id(thread_id_t id)
+{
+  static_assert(sizeof(thread_id_t) <= 8, "Expected a platform where thread IDs are at most 64-bit values");
+  return static_cast<size_t>(hash_32_or_64<sizeof(thread_id_converter<thread_id_t>::thread_id_hash_t)>::hash(
+    thread_id_converter<thread_id_t>::prehash(id)));
+}
+
+template<typename T>
+static inline bool circular_less_than(T a, T b)
+{
+#ifdef _MSC_VER
+  #pragma warning(push)
+#pragma warning(disable: 4554)
+#endif
+  static_assert(std::is_integral<T>::value && !std::numeric_limits<T>::is_signed, "circular_less_than is intended to be used only with unsigned integer types");
+  return static_cast<T>(a - b) > static_cast<T>(static_cast<T>(1) << static_cast<T>(sizeof(T) * CHAR_BIT - 1));
+#ifdef _MSC_VER
+#pragma warning(pop)
+#endif
+}
+
+template<typename U>
+static inline char* align_for(char* ptr)
+{
+  const std::size_t alignment = std::alignment_of<U>::value;
+  return ptr + (alignment - (reinterpret_cast<std::uintptr_t>(ptr) % alignment)) % alignment;
+}
+
+template<typename T>
+static inline T ceil_to_pow_2(T x)
+{
+  static_assert(std::is_integral<T>::value && !std::numeric_limits<T>::is_signed, "ceil_to_pow_2 is intended to be used only with unsigned integer types");
+
+  // Adapted from http://graphics.stanford.edu/~seander/bithacks.html#RoundUpPowerOf2
+  --x;
+  x |= x >> 1;
+  x |= x >> 2;
+  x |= x >> 4;
+  for (std::size_t i = 1; i < sizeof(T); i <<= 1) {
+    x |= x >> (i << 3);
+  }
+  ++x;
+  return x;
+}
+
+template<typename T>
+static inline void swap_relaxed(std::atomic<T>& left, std::atomic<T>& right)
+{
+  T temp = std::move(left.load(std::memory_order_relaxed));
+  left.store(std::move(right.load(std::memory_order_relaxed)), std::memory_order_relaxed);
+  right.store(std::move(temp), std::memory_order_relaxed);
+}
+
+template<typename T>
+static inline T const& nomove(T const& x)
+{
+  return x;
+}
+
+template<bool Enable>
+struct nomove_if
+{
+  template<typename T>
+  static inline T const& eval(T const& x)
+  {
+    return x;
+  }
+};
+
+template<>
+struct nomove_if<false>
+{
+  template<typename U>
+  static inline auto eval(U&& x)
+  -> decltype(std::forward<U>(x))
+  {
+    return std::forward<U>(x);
+  }
+};
+
+template<typename It>
+static inline auto deref_noexcept(It& it) MOODYCAMEL_NOEXCEPT -> decltype(*it)
+{
+  return *it;
+}
+
+#if defined(__clang__) || !defined(__GNUC__) || __GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 8)
+template<typename T> struct is_trivially_destructible : std::is_trivially_destructible<T> { };
+#else
+template<typename T> struct is_trivially_destructible : std::has_trivial_destructor<T> { };
+#endif
+
+#ifdef MOODYCAMEL_CPP11_THREAD_LOCAL_SUPPORTED
+#ifdef MCDBGQ_USE_RELACY
+  typedef RelacyThreadExitListener ThreadExitListener;
+  typedef RelacyThreadExitNotifier ThreadExitNotifier;
+#else
+  struct ThreadExitListener
+  {
+    typedef void (*callback_t)(void*);
+    callback_t callback;
+    void* userData;
+
+    ThreadExitListener* next;		// reserved for use by the ThreadExitNotifier
+  };
+
+
+  class ThreadExitNotifier
+  {
+  public:
+    static void subscribe(ThreadExitListener* listener)
+    {
+      auto& tlsInst = instance();
+      listener->next = tlsInst.tail;
+      tlsInst.tail = listener;
+    }
+
+    static void unsubscribe(ThreadExitListener* listener)
+    {
+      auto& tlsInst = instance();
+      ThreadExitListener** prev = &tlsInst.tail;
+      for (auto ptr = tlsInst.tail; ptr != nullptr; ptr = ptr->next) {
+        if (ptr == listener) {
+          *prev = ptr->next;
+          break;
+        }
+        prev = &ptr->next;
+      }
+    }
+
+  private:
+    ThreadExitNotifier() : tail(nullptr) { }
+    ThreadExitNotifier(ThreadExitNotifier const&) MOODYCAMEL_DELETE_FUNCTION;
+    ThreadExitNotifier& operator=(ThreadExitNotifier const&) MOODYCAMEL_DELETE_FUNCTION;
+
+    ~ThreadExitNotifier()
+    {
+      // This thread is about to exit, let everyone know!
+      assert(this == &instance() && "If this assert fails, you likely have a buggy compiler! Change the preprocessor conditions such that MOODYCAMEL_CPP11_THREAD_LOCAL_SUPPORTED is no longer defined.");
+      for (auto ptr = tail; ptr != nullptr; ptr = ptr->next) {
+        ptr->callback(ptr->userData);
+      }
+    }
+
+    // Thread-local
+    static inline ThreadExitNotifier& instance()
+    {
+      static thread_local ThreadExitNotifier notifier;
+      return notifier;
+    }
+
+  private:
+    ThreadExitListener* tail;
+  };
+#endif
+#endif
+
+template<typename T> struct static_is_lock_free_num { enum { value = 0 }; };
+template<> struct static_is_lock_free_num<signed char> { enum { value = ATOMIC_CHAR_LOCK_FREE }; };
+template<> struct static_is_lock_free_num<short> { enum { value = ATOMIC_SHORT_LOCK_FREE }; };
+template<> struct static_is_lock_free_num<int> { enum { value = ATOMIC_INT_LOCK_FREE }; };
+template<> struct static_is_lock_free_num<long> { enum { value = ATOMIC_LONG_LOCK_FREE }; };
+template<> struct static_is_lock_free_num<long long> { enum { value = ATOMIC_LLONG_LOCK_FREE }; };
+template<typename T> struct static_is_lock_free : static_is_lock_free_num<typename std::make_signed<T>::type> {  };
+template<> struct static_is_lock_free<bool> { enum { value = ATOMIC_BOOL_LOCK_FREE }; };
+template<typename U> struct static_is_lock_free<U*> { enum { value = ATOMIC_POINTER_LOCK_FREE }; };
+}
+
+
+struct ProducerToken
+{
+  template<typename T, typename Traits>
+  explicit ProducerToken(ConcurrentQueue<T, Traits>& queue);
+
+  template<typename T, typename Traits>
+  explicit ProducerToken(BlockingConcurrentQueue<T, Traits>& queue);
+
+  ProducerToken(ProducerToken&& other) MOODYCAMEL_NOEXCEPT
+    : producer(other.producer)
+  {
+    other.producer = nullptr;
+    if (producer != nullptr) {
+      producer->token = this;
+    }
+  }
+
+  inline ProducerToken& operator=(ProducerToken&& other) MOODYCAMEL_NOEXCEPT
+  {
+    swap(other);
+    return *this;
+  }
+
+  void swap(ProducerToken& other) MOODYCAMEL_NOEXCEPT
+  {
+    std::swap(producer, other.producer);
+    if (producer != nullptr) {
+      producer->token = this;
+    }
+    if (other.producer != nullptr) {
+      other.producer->token = &other;
+    }
+  }
+
+  // A token is always valid unless:
+  //     1) Memory allocation failed during construction
+  //     2) It was moved via the move constructor
+  //        (Note: assignment does a swap, leaving both potentially valid)
+  //     3) The associated queue was destroyed
+  // Note that if valid() returns true, that only indicates
+  // that the token is valid for use with a specific queue,
+  // but not which one; that's up to the user to track.
+  inline bool valid() const { return producer != nullptr; }
+
+  ~ProducerToken()
+  {
+    if (producer != nullptr) {
+      producer->token = nullptr;
+      producer->inactive.store(true, std::memory_order_release);
+    }
+  }
+
+  // Disable copying and assignment
+  ProducerToken(ProducerToken const&) MOODYCAMEL_DELETE_FUNCTION;
+  ProducerToken& operator=(ProducerToken const&) MOODYCAMEL_DELETE_FUNCTION;
+
+ private:
+  template<typename T, typename Traits> friend class ConcurrentQueue;
+  friend class ConcurrentQueueTests;
+
+ protected:
+  details::ConcurrentQueueProducerTypelessBase* producer;
+};
+
+
+struct ConsumerToken
+{
+  template<typename T, typename Traits>
+  explicit ConsumerToken(ConcurrentQueue<T, Traits>& q);
+
+  template<typename T, typename Traits>
+  explicit ConsumerToken(BlockingConcurrentQueue<T, Traits>& q);
+
+  ConsumerToken(ConsumerToken&& other) MOODYCAMEL_NOEXCEPT
+    : initialOffset(other.initialOffset), lastKnownGlobalOffset(other.lastKnownGlobalOffset), itemsConsumedFromCurrent(other.itemsConsumedFromCurrent), currentProducer(other.currentProducer), desiredProducer(other.desiredProducer)
+  {
+  }
+
+  inline ConsumerToken& operator=(ConsumerToken&& other) MOODYCAMEL_NOEXCEPT
+  {
+    swap(other);
+    return *this;
+  }
+
+  void swap(ConsumerToken& other) MOODYCAMEL_NOEXCEPT
+  {
+    std::swap(initialOffset, other.initialOffset);
+    std::swap(lastKnownGlobalOffset, other.lastKnownGlobalOffset);
+    std::swap(itemsConsumedFromCurrent, other.itemsConsumedFromCurrent);
+    std::swap(currentProducer, other.currentProducer);
+    std::swap(desiredProducer, other.desiredProducer);
+  }
+
+  // Disable copying and assignment
+  ConsumerToken(ConsumerToken const&) MOODYCAMEL_DELETE_FUNCTION;
+  ConsumerToken& operator=(ConsumerToken const&) MOODYCAMEL_DELETE_FUNCTION;
+
+ private:
+  template<typename T, typename Traits> friend class ConcurrentQueue;
+  friend class ConcurrentQueueTests;
+
+ private: // but shared with ConcurrentQueue
+  std::uint32_t initialOffset;
+  std::uint32_t lastKnownGlobalOffset;
+  std::uint32_t itemsConsumedFromCurrent;
+  details::ConcurrentQueueProducerTypelessBase* currentProducer;
+  details::ConcurrentQueueProducerTypelessBase* desiredProducer;
+};
+
+// Need to forward-declare this swap because it's in a namespace.
+// See http://stackoverflow.com/questions/4492062/why-does-a-c-friend-class-need-a-forward-declaration-only-in-other-namespaces
+template<typename T, typename Traits>
+inline void swap(typename ConcurrentQueue<T, Traits>::ImplicitProducerKVP& a, typename ConcurrentQueue<T, Traits>::ImplicitProducerKVP& b) MOODYCAMEL_NOEXCEPT;
+
+
+template<typename T, typename Traits = ConcurrentQueueDefaultTraits>
+class ConcurrentQueue {
+ public:
+  typedef ::dmlc::moodycamel::ProducerToken producer_token_t;
+  typedef ::dmlc::moodycamel::ConsumerToken consumer_token_t;
+
+  typedef typename Traits::index_t index_t;
+  typedef typename Traits::size_t size_t;
+
+  static const size_t BLOCK_SIZE = static_cast<size_t>(Traits::BLOCK_SIZE);
+  static const size_t EXPLICIT_BLOCK_EMPTY_COUNTER_THRESHOLD = static_cast<size_t>(Traits::EXPLICIT_BLOCK_EMPTY_COUNTER_THRESHOLD);
+  static const size_t EXPLICIT_INITIAL_INDEX_SIZE = static_cast<size_t>(Traits::EXPLICIT_INITIAL_INDEX_SIZE);
+  static const size_t IMPLICIT_INITIAL_INDEX_SIZE = static_cast<size_t>(Traits::IMPLICIT_INITIAL_INDEX_SIZE);
+  static const size_t INITIAL_IMPLICIT_PRODUCER_HASH_SIZE = static_cast<size_t>(Traits::INITIAL_IMPLICIT_PRODUCER_HASH_SIZE);
+  static const std::uint32_t EXPLICIT_CONSUMER_CONSUMPTION_QUOTA_BEFORE_ROTATE = static_cast<std::uint32_t>(Traits::EXPLICIT_CONSUMER_CONSUMPTION_QUOTA_BEFORE_ROTATE);
+#ifdef _MSC_VER
+  #pragma warning(push)
+#pragma warning(disable: 4307)		// + integral constant overflow (that's what the ternary expression is for!)
+#pragma warning(disable: 4309)		// static_cast: Truncation of constant value
+#endif
+  static const size_t MAX_SUBQUEUE_SIZE = (details::const_numeric_max<size_t>::value -
+                                           static_cast<size_t>(Traits::MAX_SUBQUEUE_SIZE) <
+                                           BLOCK_SIZE) ? details::const_numeric_max<size_t>::value
+                                                       : (
+                                            (static_cast<size_t>(Traits::MAX_SUBQUEUE_SIZE) +
+                                             (BLOCK_SIZE - 1)) / BLOCK_SIZE * BLOCK_SIZE);
+#ifdef _MSC_VER
+#pragma warning(pop)
+#endif
+
+  static_assert(!std::numeric_limits<size_t>::is_signed && std::is_integral<size_t>::value,
+                "Traits::size_t must be an unsigned integral type");
+  static_assert(!std::numeric_limits<index_t>::is_signed && std::is_integral<index_t>::value,
+                "Traits::index_t must be an unsigned integral type");
+  static_assert(sizeof(index_t) >= sizeof(size_t),
+                "Traits::index_t must be at least as wide as Traits::size_t");
+  static_assert((BLOCK_SIZE > 1) && !(BLOCK_SIZE & (BLOCK_SIZE - 1)),
+                "Traits::BLOCK_SIZE must be a power of 2 (and at least 2)");
+  static_assert((EXPLICIT_BLOCK_EMPTY_COUNTER_THRESHOLD > 1) &&
+                !(EXPLICIT_BLOCK_EMPTY_COUNTER_THRESHOLD &
+                  (EXPLICIT_BLOCK_EMPTY_COUNTER_THRESHOLD - 1)),
+                "Traits::EXPLICIT_BLOCK_EMPTY_COUNTER_THRESHOLD must be a power of 2 (and greater than 1)");
+  static_assert((EXPLICIT_INITIAL_INDEX_SIZE > 1) &&
+                !(EXPLICIT_INITIAL_INDEX_SIZE & (EXPLICIT_INITIAL_INDEX_SIZE - 1)),
+                "Traits::EXPLICIT_INITIAL_INDEX_SIZE must be a power of 2 (and greater than 1)");
+  static_assert((IMPLICIT_INITIAL_INDEX_SIZE > 1) &&
+                !(IMPLICIT_INITIAL_INDEX_SIZE & (IMPLICIT_INITIAL_INDEX_SIZE - 1)),
+                "Traits::IMPLICIT_INITIAL_INDEX_SIZE must be a power of 2 (and greater than 1)");
+  static_assert((INITIAL_IMPLICIT_PRODUCER_HASH_SIZE == 0) ||
+                !(INITIAL_IMPLICIT_PRODUCER_HASH_SIZE & (INITIAL_IMPLICIT_PRODUCER_HASH_SIZE - 1)),
+                "Traits::INITIAL_IMPLICIT_PRODUCER_HASH_SIZE must be a power of 2");
+  static_assert(
+    INITIAL_IMPLICIT_PRODUCER_HASH_SIZE == 0 || INITIAL_IMPLICIT_PRODUCER_HASH_SIZE >= 1,
+    "Traits::INITIAL_IMPLICIT_PRODUCER_HASH_SIZE must be at least 1 (or 0 to disable implicit enqueueing)");
+
+ public:
+  // Creates a queue with at least `capacity` element slots; note that the
+  // actual number of elements that can be inserted without additional memory
+  // allocation depends on the number of producers and the block size (e.g. if
+  // the block size is equal to `capacity`, only a single block will be allocated
+  // up-front, which means only a single producer will be able to enqueue elements
+  // without an extra allocation -- blocks aren't shared between producers).
+  // This method is not thread safe -- it is up to the user to ensure that the
+  // queue is fully constructed before it starts being used by other threads (this
+  // includes making the memory effects of construction visible, possibly with a
+  // memory barrier).
+  explicit ConcurrentQueue(size_t capacity = 6 * BLOCK_SIZE)
+    : producerListTail(nullptr), producerCount(0), initialBlockPoolIndex(0), nextExplicitConsumerId(
+    0), globalExplicitConsumerOffset(0) {
+    implicitProducerHashResizeInProgress.clear(std::memory_order_relaxed);
+    populate_initial_implicit_producer_hash();
+    populate_initial_block_list(
+      capacity / BLOCK_SIZE + ((capacity & (BLOCK_SIZE - 1)) == 0 ? 0 : 1));
+
+#ifdef MOODYCAMEL_QUEUE_INTERNAL_DEBUG
+    // Track all the producers using a fully-resolved typed list for
+    // each kind; this makes it possible to debug them starting from
+    // the root queue object (otherwise wacky casts are needed that
+    // don't compile in the debugger's expression evaluator).
+    explicitProducers.store(nullptr, std::memory_order_relaxed);
+    implicitProducers.store(nullptr, std::memory_order_relaxed);
+#endif
+  }
+
+  // Computes the correct amount of pre-allocated blocks for you based
+  // on the minimum number of elements you want available at any given
+  // time, and the maximum concurrent number of each type of producer.
+  ConcurrentQueue(size_t minCapacity, size_t maxExplicitProducers, size_t maxImplicitProducers)
+    : producerListTail(nullptr), producerCount(0), initialBlockPoolIndex(0), nextExplicitConsumerId(
+    0), globalExplicitConsumerOffset(0) {
+    implicitProducerHashResizeInProgress.clear(std::memory_order_relaxed);
+    populate_initial_implicit_producer_hash();
+    size_t blocks =
+      (((minCapacity + BLOCK_SIZE - 1) / BLOCK_SIZE) - 1) * (maxExplicitProducers + 1) +
+      2 * (maxExplicitProducers + maxImplicitProducers);
+    populate_initial_block_list(blocks);
+
+#ifdef MOODYCAMEL_QUEUE_INTERNAL_DEBUG
+    explicitProducers.store(nullptr, std::memory_order_relaxed);
+    implicitProducers.store(nullptr, std::memory_order_relaxed);
+#endif
+  }
+
+  // Note: The queue should not be accessed concurrently while it's
+  // being deleted. It's up to the user to synchronize this.
+  // This method is not thread safe.
+  ~ConcurrentQueue() {
+    // Destroy producers
+    auto ptr = producerListTail.load(std::memory_order_relaxed);
+    while (ptr != nullptr) {
+      auto next = ptr->next_prod();
+      if (ptr->token != nullptr) {
+        ptr->token->producer = nullptr;
+      }
+      destroy(ptr);
+      ptr = next;
+    }
+
+    // Destroy implicit producer hash tables
+    if (INITIAL_IMPLICIT_PRODUCER_HASH_SIZE != 0) {
+      auto hash = implicitProducerHash.load(std::memory_order_relaxed);
+      while (hash != nullptr) {
+        auto prev = hash->prev;
+        if (prev !=
+            nullptr) {    // The last hash is part of this object and was not allocated dynamically
+          for (size_t i = 0; i != hash->capacity; ++i) {
+            hash->entries[i].~ImplicitProducerKVP();
+          }
+          hash->~ImplicitProducerHash();
+          (Traits::free)(hash);
+        }
+        hash = prev;
+      }
+    }
+
+    // Destroy global free list
+    auto block = freeList.head_unsafe();
+    while (block != nullptr) {
+      auto next = block->freeListNext.load(std::memory_order_relaxed);
+      if (block->dynamicallyAllocated) {
+        destroy(block);
+      }
+      block = next;
+    }
+
+    // Destroy initial free list
+    destroy_array(initialBlockPool, initialBlockPoolSize);
+  }
+
+  // Disable copying and copy assignment
+  ConcurrentQueue(ConcurrentQueue const &) MOODYCAMEL_DELETE_FUNCTION;
+
+  ConcurrentQueue &operator=(ConcurrentQueue const &) MOODYCAMEL_DELETE_FUNCTION;
+
+  // Moving is supported, but note that it is *not* a thread-safe operation.
+  // Nobody can use the queue while it's being moved, and the memory effects
+  // of that move must be propagated to other threads before they can use it.
+  // Note: When a queue is moved, its tokens are still valid but can only be
+  // used with the destination queue (i.e. semantically they are moved along
+  // with the queue itself).
+  ConcurrentQueue(ConcurrentQueue &&other) MOODYCAMEL_NOEXCEPT
+    : producerListTail(other.producerListTail.load(std::memory_order_relaxed)), producerCount(
+    other.producerCount.load(std::memory_order_relaxed)), initialBlockPoolIndex(
+    other.initialBlockPoolIndex.load(std::memory_order_relaxed)), initialBlockPool(
+    other.initialBlockPool), initialBlockPoolSize(other.initialBlockPoolSize), freeList(
+    std::move(other.freeList)), nextExplicitConsumerId(
+    other.nextExplicitConsumerId.load(std::memory_order_relaxed)), globalExplicitConsumerOffset(
+    other.globalExplicitConsumerOffset.load(std::memory_order_relaxed)) {
+    // Move the other one into this, and leave the other one as an empty queue
+    implicitProducerHashResizeInProgress.clear(std::memory_order_relaxed);
+    populate_initial_implicit_producer_hash();
+    swap_implicit_producer_hashes(other);
+
+    other.producerListTail.store(nullptr, std::memory_order_relaxed);
+    other.producerCount.store(0, std::memory_order_relaxed);
+    other.nextExplicitConsumerId.store(0, std::memory_order_relaxed);
+    other.globalExplicitConsumerOffset.store(0, std::memory_order_relaxed);
+
+#ifdef MOODYCAMEL_QUEUE_INTERNAL_DEBUG
+    explicitProducers.store(other.explicitProducers.load(std::memory_order_relaxed), std::memory_order_relaxed);
+    other.explicitProducers.store(nullptr, std::memory_order_relaxed);
+    implicitProducers.store(other.implicitProducers.load(std::memory_order_relaxed), std::memory_order_relaxed);
+    other.implicitProducers.store(nullptr, std::memory_order_relaxed);
+#endif
+
+    other.initialBlockPoolIndex.store(0, std::memory_order_relaxed);
+    other.initialBlockPoolSize = 0;
+    other.initialBlockPool = nullptr;
+
+    reown_producers();
+  }
+
+  inline ConcurrentQueue &operator=(ConcurrentQueue &&other) MOODYCAMEL_NOEXCEPT {
+    return swap_internal(other);
+  }
+
+  // Swaps this queue's state with the other's. Not thread-safe.
+  // Swapping two queues does not invalidate their tokens, however
+  // the tokens that were created for one queue must be used with
+  // only the swapped queue (i.e. the tokens are tied to the
+  // queue's movable state, not the object itself).
+  inline void swap(ConcurrentQueue &other) MOODYCAMEL_NOEXCEPT {
+    swap_internal(other);
+  }
+
+ private:
+  ConcurrentQueue &swap_internal(ConcurrentQueue &other) {
+    if (this == &other) {
+      return *this;
+    }
+
+    details::swap_relaxed(producerListTail, other.producerListTail);
+    details::swap_relaxed(producerCount, other.producerCount);
+    details::swap_relaxed(initialBlockPoolIndex, other.initialBlockPoolIndex);
+    std::swap(initialBlockPool, other.initialBlockPool);
+    std::swap(initialBlockPoolSize, other.initialBlockPoolSize);
+    freeList.swap(other.freeList);
+    details::swap_relaxed(nextExplicitConsumerId, other.nextExplicitConsumerId);
+    details::swap_relaxed(globalExplicitConsumerOffset, other.globalExplicitConsumerOffset);
+
+    swap_implicit_producer_hashes(other);
+
+    reown_producers();
+    other.reown_producers();
+
+#ifdef MOODYCAMEL_QUEUE_INTERNAL_DEBUG
+    details::swap_relaxed(explicitProducers, other.explicitProducers);
+    details::swap_relaxed(implicitProducers, other.implicitProducers);
+#endif
+
+    return *this;
+  }
+
+ public:
+  // Enqueues a single item (by copying it).
+  // Allocates memory if required. Only fails if memory allocation fails (or implicit
+  // production is disabled because Traits::INITIAL_IMPLICIT_PRODUCER_HASH_SIZE is 0,
+  // or Traits::MAX_SUBQUEUE_SIZE has been defined and would be surpassed).
+  // Thread-safe.
+  inline bool enqueue(T const &item) {
+    if (INITIAL_IMPLICIT_PRODUCER_HASH_SIZE == 0) return false;
+    return inner_enqueue<CanAlloc>(item);
+  }
+
+  // Enqueues a single item (by moving it, if possible).
+  // Allocates memory if required. Only fails if memory allocation fails (or implicit
+  // production is disabled because Traits::INITIAL_IMPLICIT_PRODUCER_HASH_SIZE is 0,
+  // or Traits::MAX_SUBQUEUE_SIZE has been defined and would be surpassed).
+  // Thread-safe.
+  inline bool enqueue(T &&item) {
+    if (INITIAL_IMPLICIT_PRODUCER_HASH_SIZE == 0) return false;
+    return inner_enqueue<CanAlloc>(std::move(item));
+  }
+
+  // Enqueues a single item (by copying it) using an explicit producer token.
+  // Allocates memory if required. Only fails if memory allocation fails (or
+  // Traits::MAX_SUBQUEUE_SIZE has been defined and would be surpassed).
+  // Thread-safe.
+  inline bool enqueue(producer_token_t const &token, T const &item) {
+    return inner_enqueue<CanAlloc>(token, item);
+  }
+
+  // Enqueues a single item (by moving it, if possible) using an explicit producer token.
+  // Allocates memory if required. Only fails if memory allocation fails (or
+  // Traits::MAX_SUBQUEUE_SIZE has been defined and would be surpassed).
+  // Thread-safe.
+  inline bool enqueue(producer_token_t const &token, T &&item) {
+    return inner_enqueue<CanAlloc>(token, std::move(item));
+  }
+
+  // Enqueues several items.
+  // Allocates memory if required. Only fails if memory allocation fails (or
+  // implicit production is disabled because Traits::INITIAL_IMPLICIT_PRODUCER_HASH_SIZE
+  // is 0, or Traits::MAX_SUBQUEUE_SIZE has been defined and would be surpassed).
+  // Note: Use std::make_move_iterator if the elements should be moved instead of copied.
+  // Thread-safe.
+  template<typename It>
+  bool enqueue_bulk(It itemFirst, size_t count) {
+    if (INITIAL_IMPLICIT_PRODUCER_HASH_SIZE == 0) return false;
+    return inner_enqueue_bulk<CanAlloc>(itemFirst, count);
+  }
+
+  // Enqueues several items using an explicit producer token.
+  // Allocates memory if required. Only fails if memory allocation fails
+  // (or Traits::MAX_SUBQUEUE_SIZE has been defined and would be surpassed).
+  // Note: Use std::make_move_iterator if the elements should be moved
+  // instead of copied.
+  // Thread-safe.
+  template<typename It>
+  bool enqueue_bulk(producer_token_t const &token, It itemFirst, size_t count) {
+    return inner_enqueue_bulk<CanAlloc>(token, itemFirst, count);
+  }
+
+  // Enqueues a single item (by copying it).
+  // Does not allocate memory. Fails if not enough room to enqueue (or implicit
+  // production is disabled because Traits::INITIAL_IMPLICIT_PRODUCER_HASH_SIZE
+  // is 0).
+  // Thread-safe.
+  inline bool try_enqueue(T const &item) {
+    if (INITIAL_IMPLICIT_PRODUCER_HASH_SIZE == 0) return false;
+    return inner_enqueue<CannotAlloc>(item);
+  }
+
+  // Enqueues a single item (by moving it, if possible).
+  // Does not allocate memory (except for one-time implicit producer).
+  // Fails if not enough room to enqueue (or implicit production is
+  // disabled because Traits::INITIAL_IMPLICIT_PRODUCER_HASH_SIZE is 0).
+  // Thread-safe.
+  inline bool try_enqueue(T &&item) {
+    if (INITIAL_IMPLICIT_PRODUCER_HASH_SIZE == 0) return false;
+    return inner_enqueue<CannotAlloc>(std::move(item));
+  }
+
+  // Enqueues a single item (by copying it) using an explicit producer token.
+  // Does not allocate memory. Fails if not enough room to enqueue.
+  // Thread-safe.
+  inline bool try_enqueue(producer_token_t const &token, T const &item) {
+    return inner_enqueue<CannotAlloc>(token, item);
+  }
+
+  // Enqueues a single item (by moving it, if possible) using an explicit producer token.
+  // Does not allocate memory. Fails if not enough room to enqueue.
+  // Thread-safe.
+  inline bool try_enqueue(producer_token_t const &token, T &&item) {
+    return inner_enqueue<CannotAlloc>(token, std::move(item));
+  }
+
+  // Enqueues several items.
+  // Does not allocate memory (except for one-time implicit producer).
+  // Fails if not enough room to enqueue (or implicit production is
+  // disabled because Traits::INITIAL_IMPLICIT_PRODUCER_HASH_SIZE is 0).
+  // Note: Use std::make_move_iterator if the elements should be moved
+  // instead of copied.
+  // Thread-safe.
+  template<typename It>
+  bool try_enqueue_bulk(It itemFirst, size_t count) {
+    if (INITIAL_IMPLICIT_PRODUCER_HASH_SIZE == 0) return false;
+    return inner_enqueue_bulk<CannotAlloc>(itemFirst, count);
+  }
+
+  // Enqueues several items using an explicit producer token.
+  // Does not allocate memory. Fails if not enough room to enqueue.
+  // Note: Use std::make_move_iterator if the elements should be moved
+  // instead of copied.
+  // Thread-safe.
+  template<typename It>
+  bool try_enqueue_bulk(producer_token_t const &token, It itemFirst, size_t count) {
+    return inner_enqueue_bulk<CannotAlloc>(token, itemFirst, count);
+  }
+
+
+  // Attempts to dequeue from the queue.
+  // Returns false if all producer streams appeared empty at the time they
+  // were checked (so, the queue is likely but not guaranteed to be empty).
+  // Never allocates. Thread-safe.
+  template<typename U>
+  bool try_dequeue(U &item) {
+    // Instead of simply trying each producer in turn (which could cause needless contention on the first
+    // producer), we score them heuristically.
+    size_t nonEmptyCount = 0;
+    ProducerBase *best = nullptr;
+    size_t bestSize = 0;
+    for (auto ptr = producerListTail.load(std::memory_order_acquire);
+         nonEmptyCount < 3 && ptr != nullptr; ptr = ptr->next_prod()) {
+      auto size = ptr->size_approx();
+      if (size > 0) {
+        if (size > bestSize) {
+          bestSize = size;
+          best = ptr;
+        }
+        ++nonEmptyCount;
+      }
+    }
+
+    // If there was at least one non-empty queue but it appears empty at the time
+    // we try to dequeue from it, we need to make sure every queue's been tried
+    if (nonEmptyCount > 0) {
+      if (details::likely(best->dequeue(item))) {
+        return true;
+      }
+      for (auto ptr = producerListTail.load(std::memory_order_acquire);
+           ptr != nullptr; ptr = ptr->next_prod()) {
+        if (ptr != best && ptr->dequeue(item)) {
+          return true;
+        }
+      }
+    }
+    return false;
+  }
+
+  // Attempts to dequeue from the queue.
+  // Returns false if all producer streams appeared empty at the time they
+  // were checked (so, the queue is likely but not guaranteed to be empty).
+  // This differs from the try_dequeue(item) method in that this one does
+  // not attempt to reduce contention by interleaving the order that producer
+  // streams are dequeued from. So, using this method can reduce overall throughput
+  // under contention, but will give more predictable results in single-threaded
+  // consumer scenarios. This is mostly only useful for internal unit tests.
+  // Never allocates. Thread-safe.
+  template<typename U>
+  bool try_dequeue_non_interleaved(U &item) {
+    for (auto ptr = producerListTail.load(std::memory_order_acquire);
+         ptr != nullptr; ptr = ptr->next_prod()) {
+      if (ptr->dequeue(item)) {
+        return true;
+      }
+    }
+    return false;
+  }
+
+  // Attempts to dequeue from the queue using an explicit consumer token.
+  // Returns false if all producer streams appeared empty at the time they
+  // were checked (so, the queue is likely but not guaranteed to be empty).
+  // Never allocates. Thread-safe.
+  template<typename U>
+  bool try_dequeue(consumer_token_t &token, U &item) {
+    // The idea is roughly as follows:
+    // Every 256 items from one producer, make everyone rotate (increase the global offset) -> this means the highest efficiency consumer dictates the rotation speed of everyone else, more or less
+    // If you see that the global offset has changed, you must reset your consumption counter and move to your designated place
+    // If there's no items where you're supposed to be, keep moving until you find a producer with some items
+    // If the global offset has not changed but you've run out of items to consume, move over from your current position until you find an producer with something in it
+
+    if (token.desiredProducer == nullptr || token.lastKnownGlobalOffset !=
+                                            globalExplicitConsumerOffset.load(
+                                              std::memory_order_relaxed)) {
+      if (!update_current_producer_after_rotation(token)) {
+        return false;
+      }
+    }
+
+    // If there was at least one non-empty queue but it appears empty at the time
+    // we try to dequeue from it, we need to make sure every queue's been tried
+    if (static_cast<ProducerBase *>(token.currentProducer)->dequeue(item)) {
+      if (++token.itemsConsumedFromCurrent == EXPLICIT_CONSUMER_CONSUMPTION_QUOTA_BEFORE_ROTATE) {
+        globalExplicitConsumerOffset.fetch_add(1, std::memory_order_relaxed);
+      }
+      return true;
+    }
+
+    auto tail = producerListTail.load(std::memory_order_acquire);
+    auto ptr = static_cast<ProducerBase *>(token.currentProducer)->next_prod();
+    if (ptr == nullptr) {
+      ptr = tail;
+    }
+    while (ptr != static_cast<ProducerBase *>(token.currentProducer)) {
+      if (ptr->dequeue(item)) {
+        token.currentProducer = ptr;
+        token.itemsConsumedFromCurrent = 1;
+        return true;
+      }
+      ptr = ptr->next_prod();
+      if (ptr == nullptr) {
+        ptr = tail;
+      }
+    }
+    return false;
+  }
+
+  // Attempts to dequeue several elements from the queue.
+  // Returns the number of items actually dequeued.
+  // Returns 0 if all producer streams appeared empty at the time they
+  // were checked (so, the queue is likely but not guaranteed to be empty).
+  // Never allocates. Thread-safe.
+  template<typename It>
+  size_t try_dequeue_bulk(It itemFirst, size_t max) {
+    size_t count = 0;
+    for (auto ptr = producerListTail.load(std::memory_order_acquire);
+         ptr != nullptr; ptr = ptr->next_prod()) {
+      count += ptr->dequeue_bulk(itemFirst, max - count);
+      if (count == max) {
+        break;
+      }
+    }
+    return count;
+  }
+
+  // Attempts to dequeue several elements from the queue using an explicit consumer token.
+  // Returns the number of items actually dequeued.
+  // Returns 0 if all producer streams appeared empty at the time they
+  // were checked (so, the queue is likely but not guaranteed to be empty).
+  // Never allocates. Thread-safe.
+  template<typename It>
+  size_t try_dequeue_bulk(consumer_token_t &token, It itemFirst, size_t max) {
+    if (token.desiredProducer == nullptr || token.lastKnownGlobalOffset !=
+                                            globalExplicitConsumerOffset.load(
+                                              std::memory_order_relaxed)) {
+      if (!update_current_producer_after_rotation(token)) {
+        return 0;
+      }
+    }
+
+    size_t count = static_cast<ProducerBase *>(token.currentProducer)->dequeue_bulk(itemFirst, max);
+    if (count == max) {
+      if ((token.itemsConsumedFromCurrent += static_cast<std::uint32_t>(max)) >=
+          EXPLICIT_CONSUMER_CONSUMPTION_QUOTA_BEFORE_ROTATE) {
+        globalExplicitConsumerOffset.fetch_add(1, std::memory_order_relaxed);
+      }
+      return max;
+    }
+    token.itemsConsumedFromCurrent += static_cast<std::uint32_t>(count);
+    max -= count;
+
+    auto tail = producerListTail.load(std::memory_order_acquire);
+    auto ptr = static_cast<ProducerBase *>(token.currentProducer)->next_prod();
+    if (ptr == nullptr) {
+      ptr = tail;
+    }
+    while (ptr != static_cast<ProducerBase *>(token.currentProducer)) {
+      auto dequeued = ptr->dequeue_bulk(itemFirst, max);
+      count += dequeued;
+      if (dequeued != 0) {
+        token.currentProducer = ptr;
+        token.itemsConsumedFromCurrent = static_cast<std::uint32_t>(dequeued);
+      }
+      if (dequeued == max) {
+        break;
+      }
+      max -= dequeued;
+      ptr = ptr->next_prod();
+      if (ptr == nullptr) {
+        ptr = tail;
+      }
+    }
+    return count;
+  }
+
+
+  // Attempts to dequeue from a specific producer's inner queue.
+  // If you happen to know which producer you want to dequeue from, this
+  // is significantly faster than using the general-case try_dequeue methods.
+  // Returns false if the producer's queue appeared empty at the time it
+  // was checked (so, the queue is likely but not guaranteed to be empty).
+  // Never allocates. Thread-safe.
+  template<typename U>
+  inline bool try_dequeue_from_producer(producer_token_t const &producer, U &item) {
+    return static_cast<ExplicitProducer *>(producer.producer)->dequeue(item);
+  }
+
+  // Attempts to dequeue several elements from a specific producer's inner queue.
+  // Returns the number of items actually dequeued.
+  // If you happen to know which producer you want to dequeue from, this
+  // is significantly faster than using the general-case try_dequeue methods.
+  // Returns 0 if the producer's queue appeared empty at the time it
+  // was checked (so, the queue is likely but not guaranteed to be empty).
+  // Never allocates. Thread-safe.
+  template<typename It>
+  inline size_t
+  try_dequeue_bulk_from_producer(producer_token_t const &producer, It itemFirst, size_t max) {
+    return static_cast<ExplicitProducer *>(producer.producer)->dequeue_bulk(itemFirst, max);
+  }
+
+
+  // Returns an estimate of the total number of elements currently in the queue. This
+  // estimate is only accurate if the queue has completely stabilized before it is called
+  // (i.e. all enqueue and dequeue operations have completed and their memory effects are
+  // visible on the calling thread, and no further operations start while this method is
+  // being called).
+  // Thread-safe.
+  size_t size_approx() const {
+    size_t size = 0;
+    for (auto ptr = producerListTail.load(std::memory_order_acquire);
+         ptr != nullptr; ptr = ptr->next_prod()) {
+      size += ptr->size_approx();
+    }
+    return size;
+  }
+
+
+  // Returns true if the underlying atomic variables used by
+  // the queue are lock-free (they should be on most platforms).
+  // Thread-safe.
+  static bool is_lock_free() {
+    return
+      details::static_is_lock_free<bool>::value == 2 &&
+      details::static_is_lock_free<size_t>::value == 2 &&
+      details::static_is_lock_free<std::uint32_t>::value == 2 &&
+      details::static_is_lock_free<index_t>::value == 2 &&
+      details::static_is_lock_free<void *>::value == 2 &&
+      details::static_is_lock_free<typename details::thread_id_converter<details::thread_id_t>::thread_id_numeric_size_t>::value ==
+      2;
+  }
+
+
+ private:
+  friend struct ProducerToken;
+  friend struct ConsumerToken;
+  friend struct ExplicitProducer;
+
+  friend class ConcurrentQueueTests;
+
+  enum AllocationMode {
+    CanAlloc, CannotAlloc
+  };
+
+
+  ///////////////////////////////
+  // Queue methods
+  ///////////////////////////////
+
+  template<AllocationMode canAlloc, typename U>
+  inline bool inner_enqueue(producer_token_t const &token, U &&element) {
+    return static_cast<ExplicitProducer *>(token.producer)->ConcurrentQueue::ExplicitProducer::template enqueue<canAlloc>(
+      std::forward<U>(element));
+  }
+
+  template<AllocationMode canAlloc, typename U>
+  inline bool inner_enqueue(U &&element) {
+    auto producer = get_or_add_implicit_producer();
+    return producer == nullptr ? false
+                               : producer->ConcurrentQueue::ImplicitProducer::template enqueue<canAlloc>(
+        std::forward<U>(element));
+  }
+
+  template<AllocationMode canAlloc, typename It>
+  inline bool inner_enqueue_bulk(producer_token_t const &token, It itemFirst, size_t count) {
+    return static_cast<ExplicitProducer *>(token.producer)->ConcurrentQueue::ExplicitProducer::template enqueue_bulk<canAlloc>(
+      itemFirst, count);
+  }
+
+  template<AllocationMode canAlloc, typename It>
+  inline bool inner_enqueue_bulk(It itemFirst, size_t count) {
+    auto producer = get_or_add_implicit_producer();
+    return producer == nullptr ? false
+                               : producer->ConcurrentQueue::ImplicitProducer::template enqueue_bulk<canAlloc>(
+        itemFirst, count);
+  }
+
+  inline bool update_current_producer_after_rotation(consumer_token_t &token) {
+    // Ah, there's been a rotation, figure out where we should be!
+    auto tail = producerListTail.load(std::memory_order_acquire);
+    if (token.desiredProducer == nullptr && tail == nullptr) {
+      return false;
+    }
+    auto prodCount = producerCount.load(std::memory_order_relaxed);
+    auto globalOffset = globalExplicitConsumerOffset.load(std::memory_order_relaxed);
+    if (details::unlikely(token.desiredProducer == nullptr)) {
+      // Aha, first time we're dequeueing anything.
+      // Figure out our local position
+      // Note: offset is from start, not end, but we're traversing from end -- subtract from count first
+      std::uint32_t offset = prodCount - 1 - (token.initialOffset % prodCount);
+      token.desiredProducer = tail;
+      for (std::uint32_t i = 0; i != offset; ++i) {
+        token.desiredProducer = static_cast<ProducerBase *>(token.desiredProducer)->next_prod();
+        if (token.desiredProducer == nullptr) {
+          token.desiredProducer = tail;
+        }
+      }
+    }
+
+    std::uint32_t delta = globalOffset - token.lastKnownGlobalOffset;
+    if (delta >= prodCount) {
+      delta = delta % prodCount;
+    }
+    for (std::uint32_t i = 0; i != delta; ++i) {
+      token.desiredProducer = static_cast<ProducerBase *>(token.desiredProducer)->next_prod();
+      if (token.desiredProducer == nullptr) {
+        token.desiredProducer = tail;
+      }
+    }
+
+    token.lastKnownGlobalOffset = globalOffset;
+    token.currentProducer = token.desiredProducer;
+    token.itemsConsumedFromCurrent = 0;
+    return true;
+  }
+
+
+  ///////////////////////////
+  // Free list
+  ///////////////////////////
+
+  template<typename N>
+  struct FreeListNode {
+    FreeListNode()
+      : freeListRefs(0), freeListNext(nullptr) {}
+
+    std::atomic<std::uint32_t> freeListRefs;
+    std::atomic<N *> freeListNext;
+  };
+
+  // A simple CAS-based lock-free free list. Not the fastest thing in the world under heavy contention, but
+  // simple and correct (assuming nodes are never freed until after the free list is destroyed), and fairly
+  // speedy under low contention.
+  template<typename N>    // N must inherit FreeListNode or have the same fields (and initialization of them)
+  struct FreeList {
+    FreeList()
+      : freeListHead(nullptr) {}
+
+    FreeList(FreeList &&other)
+      : freeListHead(other.freeListHead.load(std::memory_order_relaxed)) {
+      other.freeListHead.store(nullptr, std::memory_order_relaxed);
+    }
+
+    void swap(FreeList &other) { details::swap_relaxed(freeListHead, other.freeListHead); }
+
+    FreeList(FreeList const &) MOODYCAMEL_DELETE_FUNCTION;
+
+    FreeList &operator=(FreeList const &) MOODYCAMEL_DELETE_FUNCTION;
+
+    inline void add(N *node) {
+#if MCDBGQ_NOLOCKFREE_FREELIST
+      debug::DebugLock lock(mutex);
+#endif
+      // We know that the should-be-on-freelist bit is 0 at this point, so it's safe to
+      // set it using a fetch_add
+      if (node->freeListRefs.fetch_add(SHOULD_BE_ON_FREELIST, std::memory_order_acq_rel) == 0) {
+        // Oh look! We were the last ones referencing this node, and we know
+        // we want to add it to the free list, so let's do it!
+        add_knowing_refcount_is_zero(node);
+      }
+    }
+
+    inline N *try_get() {
+#if MCDBGQ_NOLOCKFREE_FREELIST
+      debug::DebugLock lock(mutex);
+#endif
+      auto head = freeListHead.load(std::memory_order_acquire);
+      while (head != nullptr) {
+        auto prevHead = head;
+        auto refs = head->freeListRefs.load(std::memory_order_relaxed);
+        if ((refs & REFS_MASK) == 0 ||
+            !head->freeListRefs.compare_exchange_strong(refs, refs + 1, std::memory_order_acquire,
+                                                        std::memory_order_relaxed)) {
+          head = freeListHead.load(std::memory_order_acquire);
+          continue;
+        }
+
+        // Good, reference count has been incremented (it wasn't at zero), which means we can read the
+        // next and not worry about it changing between now and the time we do the CAS
+        auto next = head->freeListNext.load(std::memory_order_relaxed);
+        if (freeListHead.compare_exchange_strong(head, next, std::memory_order_acquire,
+                                                 std::memory_order_relaxed)) {
+          // Yay, got the node. This means it was on the list, which means shouldBeOnFreeList must be false no
+          // matter the refcount (because nobody else knows it's been taken off yet, it can't have been put back on).
+          assert((head->freeListRefs.load(std::memory_order_relaxed) & SHOULD_BE_ON_FREELIST) == 0);
+
+          // Decrease refcount twice, once for our ref, and once for the list's ref
+          head->freeListRefs.fetch_sub(2, std::memory_order_release);
+          return head;
+        }
+
+        // OK, the head must have changed on us, but we still need to decrease the refcount we increased.
+        // Note that we don't need to release any memory effects, but we do need to ensure that the reference
+        // count decrement happens-after the CAS on the head.
+        refs = prevHead->freeListRefs.fetch_sub(1, std::memory_order_acq_rel);
+        if (refs == SHOULD_BE_ON_FREELIST + 1) {
+          add_knowing_refcount_is_zero(prevHead);
+        }
+      }
+
+      return nullptr;
+    }
+
+    // Useful for traversing the list when there's no contention (e.g. to destroy remaining nodes)
+    N *head_unsafe() const { return freeListHead.load(std::memory_order_relaxed); }
+
+   private:
+    inline void add_knowing_refcount_is_zero(N *node) {
+      // Since the refcount is zero, and nobody can increase it once it's zero (except us, and we run
+      // only one copy of this method per node at a time, i.e. the single thread case), then we know
+      // we can safely change the next pointer of the node; however, once the refcount is back above
+      // zero, then other threads could increase it (happens under heavy contention, when the refcount
+      // goes to zero in between a load and a refcount increment of a node in try_get, then back up to
+      // something non-zero, then the refcount increment is done by the other thread) -- so, if the CAS
+      // to add the node to the actual list fails, decrease the refcount and leave the add operation to
+      // the next thread who puts the refcount back at zero (which could be us, hence the loop).
+      auto head = freeListHead.load(std::memory_order_relaxed);
+      while (true) {
+        node->freeListNext.store(head, std::memory_order_relaxed);
+        node->freeListRefs.store(1, std::memory_order_release);
+        if (!freeListHead.compare_exchange_strong(head, node, std::memory_order_release,
+                                                  std::memory_order_relaxed)) {
+          // Hmm, the add failed, but we can only try again when the refcount goes back to zero
+          if (node->freeListRefs.fetch_add(SHOULD_BE_ON_FREELIST - 1, std::memory_order_release) ==
+              1) {
+            continue;
+          }
+        }
+        return;
+      }
+    }
+
+   private:
+    // Implemented like a stack, but where node order doesn't matter (nodes are inserted out of order under contention)
+    std::atomic<N *> freeListHead;
+
+    static const std::uint32_t REFS_MASK = 0x7FFFFFFF;
+    static const std::uint32_t SHOULD_BE_ON_FREELIST = 0x80000000;
+
+#if MCDBGQ_NOLOCKFREE_FREELIST
+    debug::DebugMutex mutex;
+#endif
+  };
+
+
+  ///////////////////////////
+  // Block
+  ///////////////////////////
+
+  enum InnerQueueContext {
+    implicit_context = 0, explicit_context = 1
+  };
+
+  struct Block {
+    Block()
+      : next(nullptr), elementsCompletelyDequeued(0), freeListRefs(0), freeListNext(nullptr)
+        , shouldBeOnFreeList(false), dynamicallyAllocated(true) {
+#if MCDBGQ_TRACKMEM
+      owner = nullptr;
+#endif
+    }
+
+    template<InnerQueueContext context>
+    inline bool is_empty() const {
+      if (context == explicit_context && BLOCK_SIZE <= EXPLICIT_BLOCK_EMPTY_COUNTER_THRESHOLD) {
+        // Check flags
+        for (size_t i = 0; i < BLOCK_SIZE; ++i) {
+          if (!emptyFlags[i].load(std::memory_order_relaxed)) {
+            return false;
+          }
+        }
+
+        // Aha, empty; make sure we have all other memory effects that happened before the empty flags were set
+        std::atomic_thread_fence(std::memory_order_acquire);
+        return true;
+      } else {
+        // Check counter
+        if (elementsCompletelyDequeued.load(std::memory_order_relaxed) == BLOCK_SIZE) {
+          std::atomic_thread_fence(std::memory_order_acquire);
+          return true;
+        }
+        assert(elementsCompletelyDequeued.load(std::memory_order_relaxed) <= BLOCK_SIZE);
+        return false;
+      }
+    }
+
+    // Returns true if the block is now empty (does not apply in explicit context)
+    template<InnerQueueContext context>
+    inline bool set_empty(index_t i) {
+      if (context == explicit_context && BLOCK_SIZE <= EXPLICIT_BLOCK_EMPTY_COUNTER_THRESHOLD) {
+        // Set flag
+        assert(!emptyFlags[BLOCK_SIZE - 1 -
+                           static_cast<size_t>(i & static_cast<index_t>(BLOCK_SIZE - 1))].load(
+          std::memory_order_relaxed));
+        emptyFlags[BLOCK_SIZE - 1 -
+                   static_cast<size_t>(i & static_cast<index_t>(BLOCK_SIZE - 1))].store(true,
+                                                                                        std::memory_order_release);
+        return false;
+      } else {
+        // Increment counter
+        auto prevVal = elementsCompletelyDequeued.fetch_add(1, std::memory_order_release);
+        assert(prevVal < BLOCK_SIZE);
+        return prevVal == BLOCK_SIZE - 1;
+      }
+    }
+
+    // Sets multiple contiguous item statuses to 'empty' (assumes no wrapping and count > 0).
+    // Returns true if the block is now empty (does not apply in explicit context).
+    template<InnerQueueContext context>
+    inline bool set_many_empty(index_t i, size_t count) {
+      if (context == explicit_context && BLOCK_SIZE <= EXPLICIT_BLOCK_EMPTY_COUNTER_THRESHOLD) {
+        // Set flags
+        std::atomic_thread_fence(std::memory_order_release);
+        i = BLOCK_SIZE - 1 - static_cast<size_t>(i & static_cast<index_t>(BLOCK_SIZE - 1)) - count +
+            1;
+        for (size_t j = 0; j != count; ++j) {
+          assert(!emptyFlags[i + j].load(std::memory_order_relaxed));
+          emptyFlags[i + j].store(true, std::memory_order_relaxed);
+        }
+        return false;
+      } else {
+        // Increment counter
+        auto prevVal = elementsCompletelyDequeued.fetch_add(count, std::memory_order_release);
+        assert(prevVal + count <= BLOCK_SIZE);
+        return prevVal + count == BLOCK_SIZE;
+      }
+    }
+
+    template<InnerQueueContext context>
+    inline void set_all_empty() {
+      if (context == explicit_context && BLOCK_SIZE <= EXPLICIT_BLOCK_EMPTY_COUNTER_THRESHOLD) {
+        // Set all flags
+        for (size_t i = 0; i != BLOCK_SIZE; ++i) {
+          emptyFlags[i].store(true, std::memory_order_relaxed);
+        }
+      } else {
+        // Reset counter
+        elementsCompletelyDequeued.store(BLOCK_SIZE, std::memory_order_relaxed);
+      }
+    }
+
+    template<InnerQueueContext context>
+    inline void reset_empty() {
+      if (context == explicit_context && BLOCK_SIZE <= EXPLICIT_BLOCK_EMPTY_COUNTER_THRESHOLD) {
+        // Reset flags
+        for (size_t i = 0; i != BLOCK_SIZE; ++i) {
+          emptyFlags[i].store(false, std::memory_order_relaxed);
+        }
+      } else {
+        // Reset counter
+        elementsCompletelyDequeued.store(0, std::memory_order_relaxed);
+      }
+    }
+
+    inline T *operator[](index_t idx) MOODYCAMEL_NOEXCEPT {
+      return static_cast<T *>(static_cast<void *>(elements)) +
+             static_cast<size_t>(idx & static_cast<index_t>(BLOCK_SIZE - 1));
+    }
+
+    inline T const *operator[](index_t idx) const MOODYCAMEL_NOEXCEPT {
+      return static_cast<T const *>(static_cast<void const *>(elements)) +
+             static_cast<size_t>(idx & static_cast<index_t>(BLOCK_SIZE - 1));
+    }
+
+   private:
+    // IMPORTANT: This must be the first member in Block, so that if T depends on the alignment of
+    // addresses returned by malloc, that alignment will be preserved. Apparently clang actually
+    // generates code that uses this assumption for AVX instructions in some cases. Ideally, we
+    // should also align Block to the alignment of T in case it's higher than malloc's 16-byte
+    // alignment, but this is hard to do in a cross-platform way. Assert for this case:
+    static_assert(std::alignment_of<T>::value <= std::alignment_of<details::max_align_t>::value,
+                  "The queue does not support super-aligned types at this time");
+    // Additionally, we need the alignment of Block itself to be a multiple of max_align_t since
+    // otherwise the appropriate padding will not be added at the end of Block in order to make
+    // arrays of Blocks all be properly aligned (not just the first one). We use a union to force
+    // this.
+    union {
+      char elements[sizeof(T) * BLOCK_SIZE];
+      details::max_align_t dummy;
+    };
+   public:
+    Block *next;
+    std::atomic<size_t> elementsCompletelyDequeued;
+    std::atomic<bool> emptyFlags[
+      BLOCK_SIZE <= EXPLICIT_BLOCK_EMPTY_COUNTER_THRESHOLD ? BLOCK_SIZE : 1];
+   public:
+    std::atomic<std::uint32_t> freeListRefs;
+    std::atomic<Block *> freeListNext;
+    std::atomic<bool> shouldBeOnFreeList;
+    bool dynamicallyAllocated;    // Perhaps a better name for this would be 'isNotPartOfInitialBlockPool'
+
+#if MCDBGQ_TRACKMEM
+    void* owner;
+#endif
+  };
+
+  static_assert(std::alignment_of<Block>::value >= std::alignment_of<details::max_align_t>::value,
+                "Internal error: Blocks must be at least as aligned as the type they are wrapping");
+
+
+#if MCDBGQ_TRACKMEM
+  public:
+    struct MemStats;
+  private:
+#endif
+
+  ///////////////////////////
+  // Producer base
+  ///////////////////////////
+
+  struct ProducerBase : public details::ConcurrentQueueProducerTypelessBase {
+    ProducerBase(ConcurrentQueue *parent_, bool isExplicit_)
+      :
+      tailIndex(0), headIndex(0), dequeueOptimisticCount(0), dequeueOvercommit(0), tailBlock(
+      nullptr), isExplicit(isExplicit_), parent(parent_) {
+    }
+
+    virtual ~ProducerBase() {};
+
+    template<typename U>
+    inline bool dequeue(U &element) {
+      if (isExplicit) {
+        return static_cast<ExplicitProducer *>(this)->dequeue(element);
+      } else {
+        return static_cast<ImplicitProducer *>(this)->dequeue(element);
+      }
+    }
+
+    template<typename It>
+    inline size_t dequeue_bulk(It &itemFirst, size_t max) {
+      if (isExplicit) {
+        return static_cast<ExplicitProducer *>(this)->dequeue_bulk(itemFirst, max);
+      } else {
+        return static_cast<ImplicitProducer *>(this)->dequeue_bulk(itemFirst, max);
+      }
+    }
+
+    inline ProducerBase *next_prod() const { return static_cast<ProducerBase *>(next); }
+
+    inline size_t size_approx() const {
+      auto tail = tailIndex.load(std::memory_order_relaxed);
+      auto head = headIndex.load(std::memory_order_relaxed);
+      return details::circular_less_than(head, tail) ? static_cast<size_t>(tail - head) : 0;
+    }
+
+    inline index_t getTail() const { return tailIndex.load(std::memory_order_relaxed); }
+
+   protected:
+    std::atomic<index_t> tailIndex;    // Where to enqueue to next
+    std::atomic<index_t> headIndex;    // Where to dequeue from next
+
+    std::atomic<index_t> dequeueOptimisticCount;
+    std::atomic<index_t> dequeueOvercommit;
+
+    Block *tailBlock;
+
+   public:
+    bool isExplicit;
+    ConcurrentQueue *parent;
+
+   protected:
+#if MCDBGQ_TRACKMEM
+    friend struct MemStats;
+#endif
+  };
+
+
+  ///////////////////////////
+  // Explicit queue
+  ///////////////////////////
+
+  struct ExplicitProducer : public ProducerBase {
+    explicit ExplicitProducer(ConcurrentQueue *parent)
+      :
+      ProducerBase(parent, true), blockIndex(nullptr), pr_blockIndexSlotsUsed(0), pr_blockIndexSize(
+      EXPLICIT_INITIAL_INDEX_SIZE >> 1), pr_blockIndexFront(0), pr_blockIndexEntries(nullptr)
+      , pr_blockIndexRaw(nullptr) {
+      size_t poolBasedIndexSize = details::ceil_to_pow_2(parent->initialBlockPoolSize) >> 1;
+      if (poolBasedIndexSize > pr_blockIndexSize) {
+        pr_blockIndexSize = poolBasedIndexSize;
+      }
+
+      new_block_index(
+        0);    // This creates an index with double the number of current entries, i.e. EXPLICIT_INITIAL_INDEX_SIZE
+    }
+
+    ~ExplicitProducer() {
+      // Destruct any elements not yet dequeued.
+      // Since we're in the destructor, we can assume all elements
+      // are either completely dequeued or completely not (no halfways).
+      if (this->tailBlock != nullptr) {    // Note this means there must be a block index too
+        // First find the block that's partially dequeued, if any
+        Block *halfDequeuedBlock = nullptr;
+        if ((this->headIndex.load(std::memory_order_relaxed) &
+             static_cast<index_t>(BLOCK_SIZE - 1)) != 0) {
+          // The head's not on a block boundary, meaning a block somewhere is partially dequeued
+          // (or the head block is the tail block and was fully dequeued, but the head/tail are still not on a boundary)
+          size_t i = (pr_blockIndexFront - pr_blockIndexSlotsUsed) & (pr_blockIndexSize - 1);
+          while (details::circular_less_than<index_t>(pr_blockIndexEntries[i].base + BLOCK_SIZE,
+                                                      this->headIndex.load(
+                                                        std::memory_order_relaxed))) {
+            i = (i + 1) & (pr_blockIndexSize - 1);
+          }
+          assert(details::circular_less_than<index_t>(pr_blockIndexEntries[i].base,
+                                                      this->headIndex.load(
+                                                        std::memory_order_relaxed)));
+          halfDequeuedBlock = pr_blockIndexEntries[i].block;
+        }
+
+        // Start at the head block (note the first line in the loop gives us the head from the tail on the first iteration)
+        auto block = this->tailBlock;
+        do {
+          block = block->next;
+          if (block->template is_empty<explicit_context>()) {
+            continue;
+          }
+
+          size_t i = 0;  // Offset into block
+          if (block == halfDequeuedBlock) {
+            i = static_cast<size_t>(this->headIndex.load(std::memory_order_relaxed) &
+                                    static_cast<index_t>(BLOCK_SIZE - 1));
+          }
+
+          // Walk through all the items in the block; if this is the tail block, we need to stop when we reach the tail index
+          auto lastValidIndex = (this->tailIndex.load(std::memory_order_relaxed) &
+                                 static_cast<index_t>(BLOCK_SIZE - 1)) == 0 ? BLOCK_SIZE
+                                                                            : static_cast<size_t>(
+                                  this->tailIndex.load(std::memory_order_relaxed) &
+                                  static_cast<index_t>(BLOCK_SIZE - 1));
+          while (i != BLOCK_SIZE && (block != this->tailBlock || i != lastValidIndex)) {
+            (*block)[i++]->~T();
+          }
+        } while (block != this->tailBlock);
+      }
+
+      // Destroy all blocks that we own
+      if (this->tailBlock != nullptr) {
+        auto block = this->tailBlock;
+        do {
+          auto nextBlock = block->next;
+          if (block->dynamicallyAllocated) {
+            destroy(block);
+          } else {
+            this->parent->add_block_to_free_list(block);
+          }
+          block = nextBlock;
+        } while (block != this->tailBlock);
+      }
+
+      // Destroy the block indices
+      auto header = static_cast<BlockIndexHeader *>(pr_blockIndexRaw);
+      while (header != nullptr) {
+        auto prev = static_cast<BlockIndexHeader *>(header->prev);
+        header->~BlockIndexHeader();
+        (Traits::free)(header);
+        header = prev;
+      }
+    }
+
+    template<AllocationMode allocMode, typename U>
+    inline bool enqueue(U &&element) {
+      index_t currentTailIndex = this->tailIndex.load(std::memory_order_relaxed);
+      index_t newTailIndex = 1 + currentTailIndex;
+      if ((currentTailIndex & static_cast<index_t>(BLOCK_SIZE - 1)) == 0) {
+        // We reached the end of a block, start a new one
+        auto startBlock = this->tailBlock;
+        auto originalBlockIndexSlotsUsed = pr_blockIndexSlotsUsed;
+        if (this->tailBlock != nullptr &&
+            this->tailBlock->next->template is_empty<explicit_context>()) {
+          // We can re-use the block ahead of us, it's empty!
+          this->tailBlock = this->tailBlock->next;
+          this->tailBlock->template reset_empty<explicit_context>();
+
+          // We'll put the block on the block index (guaranteed to be room since we're conceptually removing the
+          // last block from it first -- except instead of removing then adding, we can just overwrite).
+          // Note that there must be a valid block index here, since even if allocation failed in the ctor,
+          // it would have been re-attempted when adding the first block to the queue; since there is such
+          // a block, a block index must have been successfully allocated.
+        } else {
+          // Whatever head value we see here is >= the last value we saw here (relatively),
+          // and <= its current value. Since we have the most recent tail, the head must be
+          // <= to it.
+          auto head = this->headIndex.load(std::memory_order_relaxed);
+          assert(!details::circular_less_than<index_t>(currentTailIndex, head));
+          if (!details::circular_less_than<index_t>(head, currentTailIndex + BLOCK_SIZE)
+              || (MAX_SUBQUEUE_SIZE != details::const_numeric_max<size_t>::value &&
+                  (MAX_SUBQUEUE_SIZE == 0 ||
+                   MAX_SUBQUEUE_SIZE - BLOCK_SIZE < currentTailIndex - head))) {
+            // We can't enqueue in another block because there's not enough leeway -- the
+            // tail could surpass the head by the time the block fills up! (Or we'll exceed
+            // the size limit, if the second part of the condition was true.)
+            return false;
+          }
+          // We're going to need a new block; check that the block index has room
+          if (pr_blockIndexRaw == nullptr || pr_blockIndexSlotsUsed == pr_blockIndexSize) {
+            // Hmm, the circular block index is already full -- we'll need
+            // to allocate a new index. Note pr_blockIndexRaw can only be nullptr if
+            // the initial allocation failed in the constructor.
+
+            if (allocMode == CannotAlloc || !new_block_index(pr_blockIndexSlotsUsed)) {
+              return false;
+            }
+          }
+
+          // Insert a new block in the circular linked list
+          auto newBlock = this->parent->ConcurrentQueue::template requisition_block<allocMode>();
+          if (newBlock == nullptr) {
+            return false;
+          }
+#if MCDBGQ_TRACKMEM
+          newBlock->owner = this;
+#endif
+          newBlock->template reset_empty<explicit_context>();
+          if (this->tailBlock == nullptr) {
+            newBlock->next = newBlock;
+          } else {
+            newBlock->next = this->tailBlock->next;
+            this->tailBlock->next = newBlock;
+          }
+          this->tailBlock = newBlock;
+          ++pr_blockIndexSlotsUsed;
+        }
+
+        if (!MOODYCAMEL_NOEXCEPT_CTOR(T, U, new(nullptr) T(std::forward<U>(element)))) {
+          // The constructor may throw. We want the element not to appear in the queue in
+          // that case (without corrupting the queue):
+          MOODYCAMEL_TRY {
+            new((*this->tailBlock)[currentTailIndex]) T(std::forward<U>(element));
+          }
+          MOODYCAMEL_CATCH (...) {
+            // Revert change to the current block, but leave the new block available
+            // for next time
+            pr_blockIndexSlotsUsed = originalBlockIndexSlotsUsed;
+            this->tailBlock = startBlock == nullptr ? this->tailBlock : startBlock;
+            MOODYCAMEL_RETHROW;
+          }
+        } else {
+          (void) startBlock;
+          (void) originalBlockIndexSlotsUsed;
+        }
+
+        // Add block to block index
+        auto &entry = blockIndex.load(std::memory_order_relaxed)->entries[pr_blockIndexFront];
+        entry.base = currentTailIndex;
+        entry.block = this->tailBlock;
+        blockIndex.load(std::memory_order_relaxed)->front.store(pr_blockIndexFront,
+                                                                std::memory_order_release);
+        pr_blockIndexFront = (pr_blockIndexFront + 1) & (pr_blockIndexSize - 1);
+
+        if (!MOODYCAMEL_NOEXCEPT_CTOR(T, U, new(nullptr) T(std::forward<U>(element)))) {
+          this->tailIndex.store(newTailIndex, std::memory_order_release);
+          return true;
+        }
+      }
+
+      // Enqueue
+      new((*this->tailBlock)[currentTailIndex]) T(std::forward<U>(element));
+
+      this->tailIndex.store(newTailIndex, std::memory_order_release);
+      return true;
+    }
+
+    template<typename U>
+    bool dequeue(U &element) {
+      auto tail = this->tailIndex.load(std::memory_order_relaxed);
+      auto overcommit = this->dequeueOvercommit.load(std::memory_order_relaxed);
+      if (details::circular_less_than<index_t>(
+        this->dequeueOptimisticCount.load(std::memory_order_relaxed) - overcommit, tail)) {
+        // Might be something to dequeue, let's give it a try
+
+        // Note that this if is purely for performance purposes in the common case when the queue is
+        // empty and the values are eventually consistent -- we may enter here spuriously.
+
+        // Note that whatever the values of overcommit and tail are, they are not going to change (unless we
+        // change them) and must be the same value at this point (inside the if) as when the if condition was
+        // evaluated.
+
+        // We insert an acquire fence here to synchronize-with the release upon incrementing dequeueOvercommit below.
+        // This ensures that whatever the value we got loaded into overcommit, the load of dequeueOptisticCount in
+        // the fetch_add below will result in a value at least as recent as that (and therefore at least as large).
+        // Note that I believe a compiler (signal) fence here would be sufficient due to the nature of fetch_add (all
+        // read-modify-write operations are guaranteed to work on the latest value in the modification order), but
+        // unfortunately that can't be shown to be correct using only the C++11 standard.
+        // See http://stackoverflow.com/questions/18223161/what-are-the-c11-memory-ordering-guarantees-in-this-corner-case
+        std::atomic_thread_fence(std::memory_order_acquire);
+
+        // Increment optimistic counter, then check if it went over the boundary
+        auto myDequeueCount = this->dequeueOptimisticCount.fetch_add(1, std::memory_order_relaxed);
+
+        // Note that since dequeueOvercommit must be <= dequeueOptimisticCount (because dequeueOvercommit is only ever
+        // incremented after dequeueOptimisticCount -- this is enforced in the `else` block below), and since we now
+        // have a version of dequeueOptimisticCount that is at least as recent as overcommit (due to the release upon
+        // incrementing dequeueOvercommit and the acquire above that synchronizes with it), overcommit <= myDequeueCount.
+        assert(overcommit <= myDequeueCount);
+
+        // Note that we reload tail here in case it changed; it will be the same value as before or greater, since
+        // this load is sequenced after (happens after) the earlier load above. This is supported by read-read
+        // coherency (as defined in the standard), explained here: http://en.cppreference.com/w/cpp/atomic/memory_order
+        tail = this->tailIndex.load(std::memory_order_acquire);
+        if (details::likely(
+          details::circular_less_than<index_t>(myDequeueCount - overcommit, tail))) {
+          // Guaranteed to be at least one element to dequeue!
+
+          // Get the index. Note that since there's guaranteed to be at least one element, this
+          // will never exceed tail. We need to do an acquire-release fence here since it's possible
+          // that whatever condition got us to this point was for an earlier enqueued element (that
+          // we already see the memory effects for), but that by the time we increment somebody else
+          // has incremented it, and we need to see the memory effects for *that* element, which is
+          // in such a case is necessarily visible on the thread that incremented it in the first
+          // place with the more current condition (they must have acquired a tail that is at least
+          // as recent).
+          auto index = this->headIndex.fetch_add(1, std::memory_order_acq_rel);
+
+
+          // Determine which block the element is in
+
+          auto localBlockIndex = blockIndex.load(std::memory_order_acquire);
+          auto localBlockIndexHead = localBlockIndex->front.load(std::memory_order_acquire);
+
+          // We need to be careful here about subtracting and dividing because of index wrap-around.
+          // When an index wraps, we need to preserve the sign of the offset when dividing it by the
+          // block size (in order to get a correct signed block count offset in all cases):
+          auto headBase = localBlockIndex->entries[localBlockIndexHead].base;
+          auto blockBaseIndex = index & ~static_cast<index_t>(BLOCK_SIZE - 1);
+          auto offset = static_cast<size_t>(
+            static_cast<typename std::make_signed<index_t>::type>(blockBaseIndex - headBase) /
+            BLOCK_SIZE);
+          auto block = localBlockIndex->entries[(localBlockIndexHead + offset) &
+                                                (localBlockIndex->size - 1)].block;
+
+          // Dequeue
+          auto &el = *((*block)[index]);
+          if (!MOODYCAMEL_NOEXCEPT_ASSIGN(T, T &&, element = std::move(el))) {
+            // Make sure the element is still fully dequeued and destroyed even if the assignment
+            // throws
+            struct Guard {
+              Block *block;
+              index_t index;
+
+              ~Guard() {
+                (*block)[index]->~T();
+                block->template set_empty<explicit_context>(index);
+              }
+            } guard = {block, index};
+
+            element = std::move(el);
+          } else {
+            element = std::move(el);
+            el.~T();
+            block->template set_empty<explicit_context>(index);
+          }
+
+          return true;
+        } else {
+          // Wasn't anything to dequeue after all; make the effective dequeue count eventually consistent
+          this->dequeueOvercommit.fetch_add(1,
+                                            std::memory_order_release);    // Release so that the fetch_add on dequeueOptimisticCount is guaranteed to happen before this write
+        }
+      }
+
+      return false;
+    }
+
+    template<AllocationMode allocMode, typename It>
+    bool enqueue_bulk(It itemFirst, size_t count) {
+      // First, we need to make sure we have enough room to enqueue all of the elements;
+      // this means pre-allocating blocks and putting them in the block index (but only if
+      // all the allocations succeeded).
+      index_t startTailIndex = this->tailIndex.load(std::memory_order_relaxed);
+      auto startBlock = this->tailBlock;
+      auto originalBlockIndexFront = pr_blockIndexFront;
+      auto originalBlockIndexSlotsUsed = pr_blockIndexSlotsUsed;
+
+      Block *firstAllocatedBlock = nullptr;
+
+      // Figure out how many blocks we'll need to allocate, and do so
+      size_t blockBaseDiff =
+        ((startTailIndex + count - 1) & ~static_cast<index_t>(BLOCK_SIZE - 1)) -
+        ((startTailIndex - 1) & ~static_cast<index_t>(BLOCK_SIZE - 1));
+      index_t currentTailIndex = (startTailIndex - 1) & ~static_cast<index_t>(BLOCK_SIZE - 1);
+      if (blockBaseDiff > 0) {
+        // Allocate as many blocks as possible from ahead
+        while (blockBaseDiff > 0 && this->tailBlock != nullptr &&
+               this->tailBlock->next != firstAllocatedBlock &&
+               this->tailBlock->next->template is_empty<explicit_context>()) {
+          blockBaseDiff -= static_cast<index_t>(BLOCK_SIZE);
+          currentTailIndex += static_cast<index_t>(BLOCK_SIZE);
+
+          this->tailBlock = this->tailBlock->next;
+          firstAllocatedBlock =
+            firstAllocatedBlock == nullptr ? this->tailBlock : firstAllocatedBlock;
+
+          auto &entry = blockIndex.load(std::memory_order_relaxed)->entries[pr_blockIndexFront];
+          entry.base = currentTailIndex;
+          entry.block = this->tailBlock;
+          pr_blockIndexFront = (pr_blockIndexFront + 1) & (pr_blockIndexSize - 1);
+        }
+
+        // Now allocate as many blocks as necessary from the block pool
+        while (blockBaseDiff > 0) {
+          blockBaseDiff -= static_cast<index_t>(BLOCK_SIZE);
+          currentTailIndex += static_cast<index_t>(BLOCK_SIZE);
+
+          auto head = this->headIndex.load(std::memory_order_relaxed);
+          assert(!details::circular_less_than<index_t>(currentTailIndex, head));
+          bool full = !details::circular_less_than<index_t>(head, currentTailIndex + BLOCK_SIZE) ||
+                      (MAX_SUBQUEUE_SIZE != details::const_numeric_max<size_t>::value &&
+                       (MAX_SUBQUEUE_SIZE == 0 ||
+                        MAX_SUBQUEUE_SIZE - BLOCK_SIZE < currentTailIndex - head));
+          if (pr_blockIndexRaw == nullptr || pr_blockIndexSlotsUsed == pr_blockIndexSize || full) {
+            if (allocMode == CannotAlloc || full || !new_block_index(originalBlockIndexSlotsUsed)) {
+              // Failed to allocate, undo changes (but keep injected blocks)
+              pr_blockIndexFront = originalBlockIndexFront;
+              pr_blockIndexSlotsUsed = originalBlockIndexSlotsUsed;
+              this->tailBlock = startBlock == nullptr ? firstAllocatedBlock : startBlock;
+              return false;
+            }
+
+            // pr_blockIndexFront is updated inside new_block_index, so we need to
+            // update our fallback value too (since we keep the new index even if we
+            // later fail)
+            originalBlockIndexFront = originalBlockIndexSlotsUsed;
+          }
+
+          // Insert a new block in the circular linked list
+          auto newBlock = this->parent->ConcurrentQueue::template requisition_block<allocMode>();
+          if (newBlock == nullptr) {
+            pr_blockIndexFront = originalBlockIndexFront;
+            pr_blockIndexSlotsUsed = originalBlockIndexSlotsUsed;
+            this->tailBlock = startBlock == nullptr ? firstAllocatedBlock : startBlock;
+            return false;
+          }
+
+#if MCDBGQ_TRACKMEM
+          newBlock->owner = this;
+#endif
+          newBlock->template set_all_empty<explicit_context>();
+          if (this->tailBlock == nullptr) {
+            newBlock->next = newBlock;
+          } else {
+            newBlock->next = this->tailBlock->next;
+            this->tailBlock->next = newBlock;
+          }
+          this->tailBlock = newBlock;
+          firstAllocatedBlock =
+            firstAllocatedBlock == nullptr ? this->tailBlock : firstAllocatedBlock;
+
+          ++pr_blockIndexSlotsUsed;
+
+          auto &entry = blockIndex.load(std::memory_order_relaxed)->entries[pr_blockIndexFront];
+          entry.base = currentTailIndex;
+          entry.block = this->tailBlock;
+          pr_blockIndexFront = (pr_blockIndexFront + 1) & (pr_blockIndexSize - 1);
+        }
+
+        // Excellent, all allocations succeeded. Reset each block's emptiness before we fill them up, and
+        // publish the new block index front
+        auto block = firstAllocatedBlock;
+        while (true) {
+          block->template reset_empty<explicit_context>();
+          if (block == this->tailBlock) {
+            break;
+          }
+          block = block->next;
+        }
+
+        if (MOODYCAMEL_NOEXCEPT_CTOR(T, decltype(*itemFirst),
+                                     new(nullptr) T(details::deref_noexcept(itemFirst)))) {
+          blockIndex.load(std::memory_order_relaxed)->front.store(
+            (pr_blockIndexFront - 1) & (pr_blockIndexSize - 1), std::memory_order_release);
+        }
+      }
+
+      // Enqueue, one block at a time
+      index_t newTailIndex = startTailIndex + static_cast<index_t>(count);
+      currentTailIndex = startTailIndex;
+      auto endBlock = this->tailBlock;
+      this->tailBlock = startBlock;
+      assert((startTailIndex & static_cast<index_t>(BLOCK_SIZE - 1)) != 0 ||
+             firstAllocatedBlock != nullptr || count == 0);
+      if ((startTailIndex & static_cast<index_t>(BLOCK_SIZE - 1)) == 0 &&
+          firstAllocatedBlock != nullptr) {
+        this->tailBlock = firstAllocatedBlock;
+      }
+      while (true) {
+        auto stopIndex = (currentTailIndex & ~static_cast<index_t>(BLOCK_SIZE - 1)) +
+                         static_cast<index_t>(BLOCK_SIZE);
+        if (details::circular_less_than<index_t>(newTailIndex, stopIndex)) {
+          stopIndex = newTailIndex;
+        }
+        if (MOODYCAMEL_NOEXCEPT_CTOR(T, decltype(*itemFirst),
+                                     new(nullptr) T(details::deref_noexcept(itemFirst)))) {
+          while (currentTailIndex != stopIndex) {
+            new((*this->tailBlock)[currentTailIndex++]) T(*itemFirst++);
+          }
+        } else {
+          MOODYCAMEL_TRY {
+            while (currentTailIndex != stopIndex) {
+              // Must use copy constructor even if move constructor is available
+              // because we may have to revert if there's an exception.
+              // Sorry about the horrible templated next line, but it was the only way
+              // to disable moving *at compile time*, which is important because a type
+              // may only define a (noexcept) move constructor, and so calls to the
+              // cctor will not compile, even if they are in an if branch that will never
+              // be executed
+              new((*this->tailBlock)[currentTailIndex]) T(
+                details::nomove_if<(bool) !MOODYCAMEL_NOEXCEPT_CTOR(T, decltype(*itemFirst),
+                                                                    new(nullptr) T(
+                                                                      details::deref_noexcept(
+                                                                        itemFirst)))>::eval(
+                  *itemFirst));
+              ++currentTailIndex;
+              ++itemFirst;
+            }
+          }
+          MOODYCAMEL_CATCH (...) {
+            // Oh dear, an exception's been thrown -- destroy the elements that
+            // were enqueued so far and revert the entire bulk operation (we'll keep
+            // any allocated blocks in our linked list for later, though).
+            auto constructedStopIndex = currentTailIndex;
+            auto lastBlockEnqueued = this->tailBlock;
+
+            pr_blockIndexFront = originalBlockIndexFront;
+            pr_blockIndexSlotsUsed = originalBlockIndexSlotsUsed;
+            this->tailBlock = startBlock == nullptr ? firstAllocatedBlock : startBlock;
+
+            if (!details::is_trivially_destructible<T>::value) {
+              auto block = startBlock;
+              if ((startTailIndex & static_cast<index_t>(BLOCK_SIZE - 1)) == 0) {
+                block = firstAllocatedBlock;
+              }
+              currentTailIndex = startTailIndex;
+              while (true) {
+                stopIndex = (currentTailIndex & ~static_cast<index_t>(BLOCK_SIZE - 1)) +
+                            static_cast<index_t>(BLOCK_SIZE);
+                if (details::circular_less_than<index_t>(constructedStopIndex, stopIndex)) {
+                  stopIndex = constructedStopIndex;
+                }
+                while (currentTailIndex != stopIndex) {
+                  (*block)[currentTailIndex++]->~T();
+                }
+                if (block == lastBlockEnqueued) {
+                  break;
+                }
+                block = block->next;
+              }
+            }
+            MOODYCAMEL_RETHROW;
+          }
+        }
+
+        if (this->tailBlock == endBlock) {
+          assert(currentTailIndex == newTailIndex);
+          break;
+        }
+        this->tailBlock = this->tailBlock->next;
+      }
+
+      if (!MOODYCAMEL_NOEXCEPT_CTOR(T, decltype(*itemFirst),
+                                    new(nullptr) T(details::deref_noexcept(itemFirst))) &&
+          firstAllocatedBlock != nullptr) {
+        blockIndex.load(std::memory_order_relaxed)->front.store(
+          (pr_blockIndexFront - 1) & (pr_blockIndexSize - 1), std::memory_order_release);
+      }
+
+      this->tailIndex.store(newTailIndex, std::memory_order_release);
+      return true;
+    }
+
+    template<typename It>
+    size_t dequeue_bulk(It &itemFirst, size_t max) {
+      auto tail = this->tailIndex.load(std::memory_order_relaxed);
+      auto overcommit = this->dequeueOvercommit.load(std::memory_order_relaxed);
+      auto desiredCount = static_cast<size_t>(tail - (this->dequeueOptimisticCount.load(
+        std::memory_order_relaxed) - overcommit));
+      if (details::circular_less_than<size_t>(0, desiredCount)) {
+        desiredCount = desiredCount < max ? desiredCount : max;
+        std::atomic_thread_fence(std::memory_order_acquire);
+
+        auto myDequeueCount = this->dequeueOptimisticCount.fetch_add(desiredCount,
+                                                                     std::memory_order_relaxed);
+        assert(overcommit <= myDequeueCount);
+
+        tail = this->tailIndex.load(std::memory_order_acquire);
+        auto actualCount = static_cast<size_t>(tail - (myDequeueCount - overcommit));
+        if (details::circular_less_than<size_t>(0, actualCount)) {
+          actualCount = desiredCount < actualCount ? desiredCount : actualCount;
+          if (actualCount < desiredCount) {
+            this->dequeueOvercommit.fetch_add(desiredCount - actualCount,
+                                              std::memory_order_release);
+          }
+
+          // Get the first index. Note that since there's guaranteed to be at least actualCount elements, this
+          // will never exceed tail.
+          auto firstIndex = this->headIndex.fetch_add(actualCount, std::memory_order_acq_rel);
+
+          // Determine which block the first element is in
+          auto localBlockIndex = blockIndex.load(std::memory_order_acquire);
+          auto localBlockIndexHead = localBlockIndex->front.load(std::memory_order_acquire);
+
+          auto headBase = localBlockIndex->entries[localBlockIndexHead].base;
+          auto firstBlockBaseIndex = firstIndex & ~static_cast<index_t>(BLOCK_SIZE - 1);
+          auto offset = static_cast<size_t>(
+            static_cast<typename std::make_signed<index_t>::type>(firstBlockBaseIndex - headBase) /
+            BLOCK_SIZE);
+          auto indexIndex = (localBlockIndexHead + offset) & (localBlockIndex->size - 1);
+
+          // Iterate the blocks and dequeue
+          auto index = firstIndex;
+          do {
+            auto firstIndexInBlock = index;
+            auto endIndex =
+              (index & ~static_cast<index_t>(BLOCK_SIZE - 1)) + static_cast<index_t>(BLOCK_SIZE);
+            endIndex = details::circular_less_than<index_t>(
+              firstIndex + static_cast<index_t>(actualCount), endIndex) ? firstIndex +
+                                                                          static_cast<index_t>(actualCount)
+                                                                        : endIndex;
+            auto block = localBlockIndex->entries[indexIndex].block;
+            if (MOODYCAMEL_NOEXCEPT_ASSIGN(T, T &&, details::deref_noexcept(itemFirst) = std::move(
+              (*(*block)[index])))) {
+              while (index != endIndex) {
+                auto &el = *((*block)[index]);
+                *itemFirst++ = std::move(el);
+                el.~T();
+                ++index;
+              }
+            } else {
+              MOODYCAMEL_TRY {
+                while (index != endIndex) {
+                  auto &el = *((*block)[index]);
+                  *itemFirst = std::move(el);
+                  ++itemFirst;
+                  el.~T();
+                  ++index;
+                }
+              }
+              MOODYCAMEL_CATCH (...) {
+                // It's too late to revert the dequeue, but we can make sure that all
+                // the dequeued objects are properly destroyed and the block index
+                // (and empty count) are properly updated before we propagate the exception
+                do {
+                  block = localBlockIndex->entries[indexIndex].block;
+                  while (index != endIndex) {
+                    (*block)[index++]->~T();
+                  }
+                  block->template set_many_empty<explicit_context>(
+                    firstIndexInBlock, static_cast<size_t>(endIndex - firstIndexInBlock));
+                  indexIndex = (indexIndex + 1) & (localBlockIndex->size - 1);
+
+                  firstIndexInBlock = index;
+                  endIndex = (index & ~static_cast<index_t>(BLOCK_SIZE - 1)) +
+                             static_cast<index_t>(BLOCK_SIZE);
+                  endIndex = details::circular_less_than<index_t>(
+                    firstIndex + static_cast<index_t>(actualCount), endIndex) ? firstIndex +
+                                                                                static_cast<index_t>(actualCount)
+                                                                              : endIndex;
+                } while (index != firstIndex + actualCount);
+
+                MOODYCAMEL_RETHROW;
+              }
+            }
+            block->template set_many_empty<explicit_context>(
+              firstIndexInBlock, static_cast<size_t>(endIndex - firstIndexInBlock));
+            indexIndex = (indexIndex + 1) & (localBlockIndex->size - 1);
+          } while (index != firstIndex + actualCount);
+
+          return actualCount;
+        } else {
+          // Wasn't anything to dequeue after all; make the effective dequeue count eventually consistent
+          this->dequeueOvercommit.fetch_add(desiredCount, std::memory_order_release);
+        }
+      }
+
+      return 0;
+    }
+
+   private:
+    struct BlockIndexEntry {
+      index_t base;
+      Block *block;
+    };
+
+    struct BlockIndexHeader {
+      size_t size;
+      std::atomic<size_t> front;    // Current slot (not next, like pr_blockIndexFront)
+      BlockIndexEntry *entries;
+      void *prev;
+    };
+
+
+    bool new_block_index(size_t numberOfFilledSlotsToExpose) {
+      auto prevBlockSizeMask = pr_blockIndexSize - 1;
+
+      // Create the new block
+      pr_blockIndexSize <<= 1;
+      auto newRawPtr = static_cast<char *>((Traits::malloc)(
+        sizeof(BlockIndexHeader) + std::alignment_of<BlockIndexEntry>::value - 1 +
+        sizeof(BlockIndexEntry) * pr_blockIndexSize));
+      if (newRawPtr == nullptr) {
+        pr_blockIndexSize >>= 1;    // Reset to allow graceful retry
+        return false;
+      }
+
+      auto newBlockIndexEntries = reinterpret_cast<BlockIndexEntry *>(details::align_for<BlockIndexEntry>(
+        newRawPtr + sizeof(BlockIndexHeader)));
+
+      // Copy in all the old indices, if any
+      size_t j = 0;
+      if (pr_blockIndexSlotsUsed != 0) {
+        auto i = (pr_blockIndexFront - pr_blockIndexSlotsUsed) & prevBlockSizeMask;
+        do {
+          newBlockIndexEntries[j++] = pr_blockIndexEntries[i];
+          i = (i + 1) & prevBlockSizeMask;
+        } while (i != pr_blockIndexFront);
+      }
+
+      // Update everything
+      auto header = new(newRawPtr) BlockIndexHeader;
+      header->size = pr_blockIndexSize;
+      header->front.store(numberOfFilledSlotsToExpose - 1, std::memory_order_relaxed);
+      header->entries = newBlockIndexEntries;
+      header->prev = pr_blockIndexRaw;    // we link the new block to the old one so we can free it later
+
+      pr_blockIndexFront = j;
+      pr_blockIndexEntries = newBlockIndexEntries;
+      pr_blockIndexRaw = newRawPtr;
+      blockIndex.store(header, std::memory_order_release);
+
+      return true;
+    }
+
+   private:
+    std::atomic<BlockIndexHeader *> blockIndex;
+
+    // To be used by producer only -- consumer must use the ones in referenced by blockIndex
+    size_t pr_blockIndexSlotsUsed;
+    size_t pr_blockIndexSize;
+    size_t pr_blockIndexFront;    // Next slot (not current)
+    BlockIndexEntry *pr_blockIndexEntries;
+    void *pr_blockIndexRaw;
+
+#ifdef MOODYCAMEL_QUEUE_INTERNAL_DEBUG
+    public:
+      ExplicitProducer* nextExplicitProducer;
+    private:
+#endif
+
+#if MCDBGQ_TRACKMEM
+    friend struct MemStats;
+#endif
+  };
+
+
+  //////////////////////////////////
+  // Implicit queue
+  //////////////////////////////////
+
+  struct ImplicitProducer : public ProducerBase {
+    ImplicitProducer(ConcurrentQueue *parent)
+      :
+      ProducerBase(parent, false), nextBlockIndexCapacity(IMPLICIT_INITIAL_INDEX_SIZE), blockIndex(
+      nullptr) {
+      new_block_index();
+    }
+
+    ~ImplicitProducer() {
+      // Note that since we're in the destructor we can assume that all enqueue/dequeue operations
+      // completed already; this means that all undequeued elements are placed contiguously across
+      // contiguous blocks, and that only the first and last remaining blocks can be only partially
+      // empty (all other remaining blocks must be completely full).
+
+#ifdef MOODYCAMEL_CPP11_THREAD_LOCAL_SUPPORTED
+      // Unregister ourselves for thread termination notification
+      if (!this->inactive.load(std::memory_order_relaxed)) {
+        details::ThreadExitNotifier::unsubscribe(&threadExitListener);
+      }
+#endif
+
+      // Destroy all remaining elements!
+      auto tail = this->tailIndex.load(std::memory_order_relaxed);
+      auto index = this->headIndex.load(std::memory_order_relaxed);
+      Block *block = nullptr;
+      assert(index == tail || details::circular_less_than(index, tail));
+      bool forceFreeLastBlock =
+        index != tail;    // If we enter the loop, then the last (tail) block will not be freed
+      while (index != tail) {
+        if ((index & static_cast<index_t>(BLOCK_SIZE - 1)) == 0 || block == nullptr) {
+          if (block != nullptr) {
+            // Free the old block
+            this->parent->add_block_to_free_list(block);
+          }
+
+          block = get_block_index_entry_for_index(index)->value.load(std::memory_order_relaxed);
+        }
+
+        ((*block)[index])->~T();
+        ++index;
+      }
+      // Even if the queue is empty, there's still one block that's not on the free list
+      // (unless the head index reached the end of it, in which case the tail will be poised
+      // to create a new block).
+      if (this->tailBlock != nullptr &&
+          (forceFreeLastBlock || (tail & static_cast<index_t>(BLOCK_SIZE - 1)) != 0)) {
+        this->parent->add_block_to_free_list(this->tailBlock);
+      }
+
+      // Destroy block index
+      auto localBlockIndex = blockIndex.load(std::memory_order_relaxed);
+      if (localBlockIndex != nullptr) {
+        for (size_t i = 0; i != localBlockIndex->capacity; ++i) {
+          localBlockIndex->index[i]->~BlockIndexEntry();
+        }
+        do {
+          auto prev = localBlockIndex->prev;
+          localBlockIndex->~BlockIndexHeader();
+          (Traits::free)(localBlockIndex);
+          localBlockIndex = prev;
+        } while (localBlockIndex != nullptr);
+      }
+    }
+
+    template<AllocationMode allocMode, typename U>
+    inline bool enqueue(U &&element) {
+      index_t currentTailIndex = this->tailIndex.load(std::memory_order_relaxed);
+      index_t newTailIndex = 1 + currentTailIndex;
+      if ((currentTailIndex & static_cast<index_t>(BLOCK_SIZE - 1)) == 0) {
+        // We reached the end of a block, start a new one
+        auto head = this->headIndex.load(std::memory_order_relaxed);
+        assert(!details::circular_less_than<index_t>(currentTailIndex, head));
+        if (!details::circular_less_than<index_t>(head, currentTailIndex + BLOCK_SIZE) ||
+            (MAX_SUBQUEUE_SIZE != details::const_numeric_max<size_t>::value &&
+             (MAX_SUBQUEUE_SIZE == 0 ||
+              MAX_SUBQUEUE_SIZE - BLOCK_SIZE < currentTailIndex - head))) {
+          return false;
+        }
+#if MCDBGQ_NOLOCKFREE_IMPLICITPRODBLOCKINDEX
+        debug::DebugLock lock(mutex);
+#endif
+        // Find out where we'll be inserting this block in the block index
+        BlockIndexEntry *idxEntry;
+        if (!insert_block_index_entry<allocMode>(idxEntry, currentTailIndex)) {
+          return false;
+        }
+
+        // Get ahold of a new block
+        auto newBlock = this->parent->ConcurrentQueue::template requisition_block<allocMode>();
+        if (newBlock == nullptr) {
+          rewind_block_index_tail();
+          idxEntry->value.store(nullptr, std::memory_order_relaxed);
+          return false;
+        }
+#if MCDBGQ_TRACKMEM
+        newBlock->owner = this;
+#endif
+        newBlock->template reset_empty<implicit_context>();
+
+        if (!MOODYCAMEL_NOEXCEPT_CTOR(T, U, new(nullptr) T(std::forward<U>(element)))) {
+          // May throw, try to insert now before we publish the fact that we have this new block
+          MOODYCAMEL_TRY {
+            new((*newBlock)[currentTailIndex]) T(std::forward<U>(element));
+          }
+          MOODYCAMEL_CATCH (...) {
+            rewind_block_index_tail();
+            idxEntry->value.store(nullptr, std::memory_order_relaxed);
+            this->parent->add_block_to_free_list(newBlock);
+            MOODYCAMEL_RETHROW;
+          }
+        }
+
+        // Insert the new block into the index
+        idxEntry->value.store(newBlock, std::memory_order_relaxed);
+
+        this->tailBlock = newBlock;
+
+        if (!MOODYCAMEL_NOEXCEPT_CTOR(T, U, new(nullptr) T(std::forward<U>(element)))) {
+          this->tailIndex.store(newTailIndex, std::memory_order_release);
+          return true;
+        }
+      }
+
+      // Enqueue
+      new((*this->tailBlock)[currentTailIndex]) T(std::forward<U>(element));
+
+      this->tailIndex.store(newTailIndex, std::memory_order_release);
+      return true;
+    }
+
+    template<typename U>
+    bool dequeue(U &element) {
+      // See ExplicitProducer::dequeue for rationale and explanation
+      index_t tail = this->tailIndex.load(std::memory_order_relaxed);
+      index_t overcommit = this->dequeueOvercommit.load(std::memory_order_relaxed);
+      if (details::circular_less_than<index_t>(
+        this->dequeueOptimisticCount.load(std::memory_order_relaxed) - overcommit, tail)) {
+        std::atomic_thread_fence(std::memory_order_acquire);
+
+        index_t myDequeueCount = this->dequeueOptimisticCount.fetch_add(1,
+                                                                        std::memory_order_relaxed);
+        assert(overcommit <= myDequeueCount);
+        tail = this->tailIndex.load(std::memory_order_acquire);
+        if (details::likely(
+          details::circular_less_than<index_t>(myDequeueCount - overcommit, tail))) {
+          index_t index = this->headIndex.fetch_add(1, std::memory_order_acq_rel);
+
+          // Determine which block the element is in
+          auto entry = get_block_index_entry_for_index(index);
+
+          // Dequeue
+          auto block = entry->value.load(std::memory_order_relaxed);
+          auto &el = *((*block)[index]);
+
+          if (!MOODYCAMEL_NOEXCEPT_ASSIGN(T, T &&, element = std::move(el))) {
+#if MCDBGQ_NOLOCKFREE_IMPLICITPRODBLOCKINDEX
+            // Note: Acquiring the mutex with every dequeue instead of only when a block
+            // is released is very sub-optimal, but it is, after all, purely debug code.
+            debug::DebugLock lock(producer->mutex);
+#endif
+            struct Guard {
+              Block *block;
+              index_t index;
+              BlockIndexEntry *entry;
+              ConcurrentQueue *parent;
+
+              ~Guard() {
+                (*block)[index]->~T();
+                if (block->template set_empty<implicit_context>(index)) {
+                  entry->value.store(nullptr, std::memory_order_relaxed);
+                  parent->add_block_to_free_list(block);
+                }
+              }
+            } guard = {block, index, entry, this->parent};
+
+            element = std::move(el);
+          } else {
+            element = std::move(el);
+            el.~T();
+
+            if (block->template set_empty<implicit_context>(index)) {
+              {
+#if MCDBGQ_NOLOCKFREE_IMPLICITPRODBLOCKINDEX
+                debug::DebugLock lock(mutex);
+#endif
+                // Add the block back into the global free pool (and remove from block index)
+                entry->value.store(nullptr, std::memory_order_relaxed);
+              }
+              this->parent->add_block_to_free_list(block);    // releases the above store
+            }
+          }
+
+          return true;
+        } else {
+          this->dequeueOvercommit.fetch_add(1, std::memory_order_release);
+        }
+      }
+
+      return false;
+    }
+
+    template<AllocationMode allocMode, typename It>
+    bool enqueue_bulk(It itemFirst, size_t count) {
+      // First, we need to make sure we have enough room to enqueue all of the elements;
+      // this means pre-allocating blocks and putting them in the block index (but only if
+      // all the allocations succeeded).
+
+      // Note that the tailBlock we start off with may not be owned by us any more;
+      // this happens if it was filled up exactly to the top (setting tailIndex to
+      // the first index of the next block which is not yet allocated), then dequeued
+      // completely (putting it on the free list) before we enqueue again.
+
+      index_t startTailIndex = this->tailIndex.load(std::memory_order_relaxed);
+      auto startBlock = this->tailBlock;
+      Block *firstAllocatedBlock = nullptr;
+      auto endBlock = this->tailBlock;
+
+      // Figure out how many blocks we'll need to allocate, and do so
+      size_t blockBaseDiff =
+        ((startTailIndex + count - 1) & ~static_cast<index_t>(BLOCK_SIZE - 1)) -
+        ((startTailIndex - 1) & ~static_cast<index_t>(BLOCK_SIZE - 1));
+      index_t currentTailIndex = (startTailIndex - 1) & ~static_cast<index_t>(BLOCK_SIZE - 1);
+      if (blockBaseDiff > 0) {
+#if MCDBGQ_NOLOCKFREE_IMPLICITPRODBLOCKINDEX
+        debug::DebugLock lock(mutex);
+#endif
+        do {
+          blockBaseDiff -= static_cast<index_t>(BLOCK_SIZE);
+          currentTailIndex += static_cast<index_t>(BLOCK_SIZE);
+
+          // Find out where we'll be inserting this block in the block index
+          BlockIndexEntry *idxEntry = nullptr;  // initialization here unnecessary but compiler can't always tell
+          Block *newBlock;
+          bool indexInserted = false;
+          auto head = this->headIndex.load(std::memory_order_relaxed);
+          assert(!details::circular_less_than<index_t>(currentTailIndex, head));
+          bool full = !details::circular_less_than<index_t>(head, currentTailIndex + BLOCK_SIZE) ||
+                      (MAX_SUBQUEUE_SIZE != details::const_numeric_max<size_t>::value &&
+                       (MAX_SUBQUEUE_SIZE == 0 ||
+                        MAX_SUBQUEUE_SIZE - BLOCK_SIZE < currentTailIndex - head));
+          if (full ||
+              !(indexInserted = insert_block_index_entry<allocMode>(idxEntry, currentTailIndex)) ||
+              (newBlock = this->parent->ConcurrentQueue::template requisition_block<allocMode>()) ==
+              nullptr) {
+            // Index allocation or block allocation failed; revert any other allocations
+            // and index insertions done so far for this operation
+            if (indexInserted) {
+              rewind_block_index_tail();
+              idxEntry->value.store(nullptr, std::memory_order_relaxed);
+            }
+            currentTailIndex = (startTailIndex - 1) & ~static_cast<index_t>(BLOCK_SIZE - 1);
+            for (auto block = firstAllocatedBlock; block != nullptr; block = block->next) {
+              currentTailIndex += static_cast<index_t>(BLOCK_SIZE);
+              idxEntry = get_block_index_entry_for_index(currentTailIndex);
+              idxEntry->value.store(nullptr, std::memory_order_relaxed);
+              rewind_block_index_tail();
+            }
+            this->parent->add_blocks_to_free_list(firstAllocatedBlock);
+            this->tailBlock = startBlock;
+
+            return false;
+          }
+
+#if MCDBGQ_TRACKMEM
+          newBlock->owner = this;
+#endif
+          newBlock->template reset_empty<implicit_context>();
+          newBlock->next = nullptr;
+
+          // Insert the new block into the index
+          idxEntry->value.store(newBlock, std::memory_order_relaxed);
+
+          // Store the chain of blocks so that we can undo if later allocations fail,
+          // and so that we can find the blocks when we do the actual enqueueing
+          if ((startTailIndex & static_cast<index_t>(BLOCK_SIZE - 1)) != 0 ||
+              firstAllocatedBlock != nullptr) {
+            assert(this->tailBlock != nullptr);
+            this->tailBlock->next = newBlock;
+          }
+          this->tailBlock = newBlock;
+          endBlock = newBlock;
+          firstAllocatedBlock = firstAllocatedBlock == nullptr ? newBlock : firstAllocatedBlock;
+        } while (blockBaseDiff > 0);
+      }
+
+      // Enqueue, one block at a time
+      index_t newTailIndex = startTailIndex + static_cast<index_t>(count);
+      currentTailIndex = startTailIndex;
+      this->tailBlock = startBlock;
+      assert((startTailIndex & static_cast<index_t>(BLOCK_SIZE - 1)) != 0 ||
+             firstAllocatedBlock != nullptr || count == 0);
+      if ((startTailIndex & static_cast<index_t>(BLOCK_SIZE - 1)) == 0 &&
+          firstAllocatedBlock != nullptr) {
+        this->tailBlock = firstAllocatedBlock;
+      }
+      while (true) {
+        auto stopIndex = (currentTailIndex & ~static_cast<index_t>(BLOCK_SIZE - 1)) +
+                         static_cast<index_t>(BLOCK_SIZE);
+        if (details::circular_less_than<index_t>(newTailIndex, stopIndex)) {
+          stopIndex = newTailIndex;
+        }
+        if (MOODYCAMEL_NOEXCEPT_CTOR(T, decltype(*itemFirst),
+                                     new(nullptr) T(details::deref_noexcept(itemFirst)))) {
+          while (currentTailIndex != stopIndex) {
+            new((*this->tailBlock)[currentTailIndex++]) T(*itemFirst++);
+          }
+        } else {
+          MOODYCAMEL_TRY {
+            while (currentTailIndex != stopIndex) {
+              new((*this->tailBlock)[currentTailIndex]) T(
+                details::nomove_if<(bool) !MOODYCAMEL_NOEXCEPT_CTOR(T, decltype(*itemFirst),
+                                                                    new(nullptr) T(
+                                                                      details::deref_noexcept(
+                                                                        itemFirst)))>::eval(
+                  *itemFirst));
+              ++currentTailIndex;
+              ++itemFirst;
+            }
+          }
+          MOODYCAMEL_CATCH (...) {
+            auto constructedStopIndex = currentTailIndex;
+            auto lastBlockEnqueued = this->tailBlock;
+
+            if (!details::is_trivially_destructible<T>::value) {
+              auto block = startBlock;
+              if ((startTailIndex & static_cast<index_t>(BLOCK_SIZE - 1)) == 0) {
+                block = firstAllocatedBlock;
+              }
+              currentTailIndex = startTailIndex;
+              while (true) {
+                stopIndex = (currentTailIndex & ~static_cast<index_t>(BLOCK_SIZE - 1)) +
+                            static_cast<index_t>(BLOCK_SIZE);
+                if (details::circular_less_than<index_t>(constructedStopIndex, stopIndex)) {
+                  stopIndex = constructedStopIndex;
+                }
+                while (currentTailIndex != stopIndex) {
+                  (*block)[currentTailIndex++]->~T();
+                }
+                if (block == lastBlockEnqueued) {
+                  break;
+                }
+                block = block->next;
+              }
+            }
+
+            currentTailIndex = (startTailIndex - 1) & ~static_cast<index_t>(BLOCK_SIZE - 1);
+            for (auto block = firstAllocatedBlock; block != nullptr; block = block->next) {
+              currentTailIndex += static_cast<index_t>(BLOCK_SIZE);
+              auto idxEntry = get_block_index_entry_for_index(currentTailIndex);
+              idxEntry->value.store(nullptr, std::memory_order_relaxed);
+              rewind_block_index_tail();
+            }
+            this->parent->add_blocks_to_free_list(firstAllocatedBlock);
+            this->tailBlock = startBlock;
+            MOODYCAMEL_RETHROW;
+          }
+        }
+
+        if (this->tailBlock == endBlock) {
+          assert(currentTailIndex == newTailIndex);
+          break;
+        }
+        this->tailBlock = this->tailBlock->next;
+      }
+      this->tailIndex.store(newTailIndex, std::memory_order_release);
+      return true;
+    }
+
+    template<typename It>
+    size_t dequeue_bulk(It &itemFirst, size_t max) {
+      auto tail = this->tailIndex.load(std::memory_order_relaxed);
+      auto overcommit = this->dequeueOvercommit.load(std::memory_order_relaxed);
+      auto desiredCount = static_cast<size_t>(tail - (this->dequeueOptimisticCount.load(
+        std::memory_order_relaxed) - overcommit));
+      if (details::circular_less_than<size_t>(0, desiredCount)) {
+        desiredCount = desiredCount < max ? desiredCount : max;
+        std::atomic_thread_fence(std::memory_order_acquire);
+
+        auto myDequeueCount = this->dequeueOptimisticCount.fetch_add(desiredCount,
+                                                                     std::memory_order_relaxed);
+        assert(overcommit <= myDequeueCount);
+
+        tail = this->tailIndex.load(std::memory_order_acquire);
+        auto actualCount = static_cast<size_t>(tail - (myDequeueCount - overcommit));
+        if (details::circular_less_than<size_t>(0, actualCount)) {
+          actualCount = desiredCount < actualCount ? desiredCount : actualCount;
+          if (actualCount < desiredCount) {
+            this->dequeueOvercommit.fetch_add(desiredCount - actualCount,
+                                              std::memory_order_release);
+          }
+
+          // Get the first index. Note that since there's guaranteed to be at least actualCount elements, this
+          // will never exceed tail.
+          auto firstIndex = this->headIndex.fetch_add(actualCount, std::memory_order_acq_rel);
+
+          // Iterate the blocks and dequeue
+          auto index = firstIndex;
+          BlockIndexHeader *localBlockIndex;
+          auto indexIndex = get_block_index_index_for_index(index, localBlockIndex);
+          do {
+            auto blockStartIndex = index;
+            auto endIndex =
+              (index & ~static_cast<index_t>(BLOCK_SIZE - 1)) + static_cast<index_t>(BLOCK_SIZE);
+            endIndex = details::circular_less_than<index_t>(
+              firstIndex + static_cast<index_t>(actualCount), endIndex) ? firstIndex +
+                                                                          static_cast<index_t>(actualCount)
+                                                                        : endIndex;
+
+            auto entry = localBlockIndex->index[indexIndex];
+            auto block = entry->value.load(std::memory_order_relaxed);
+            if (MOODYCAMEL_NOEXCEPT_ASSIGN(T, T &&, details::deref_noexcept(itemFirst) = std::move(
+              (*(*block)[index])))) {
+              while (index != endIndex) {
+                auto &el = *((*block)[index]);
+                *itemFirst++ = std::move(el);
+                el.~T();
+                ++index;
+              }
+            } else {
+              MOODYCAMEL_TRY {
+                while (index != endIndex) {
+                  auto &el = *((*block)[index]);
+                  *itemFirst = std::move(el);
+                  ++itemFirst;
+                  el.~T();
+                  ++index;
+                }
+              }
+              MOODYCAMEL_CATCH (...) {
+                do {
+                  entry = localBlockIndex->index[indexIndex];
+                  block = entry->value.load(std::memory_order_relaxed);
+                  while (index != endIndex) {
+                    (*block)[index++]->~T();
+                  }
+
+                  if (block->template set_many_empty<implicit_context>(
+                    blockStartIndex, static_cast<size_t>(endIndex - blockStartIndex))) {
+#if MCDBGQ_NOLOCKFREE_IMPLICITPRODBLOCKINDEX
+                    debug::DebugLock lock(mutex);
+#endif
+                    entry->value.store(nullptr, std::memory_order_relaxed);
+                    this->parent->add_block_to_free_list(block);
+                  }
+                  indexIndex = (indexIndex + 1) & (localBlockIndex->capacity - 1);
+
+                  blockStartIndex = index;
+                  endIndex = (index & ~static_cast<index_t>(BLOCK_SIZE - 1)) +
+                             static_cast<index_t>(BLOCK_SIZE);
+                  endIndex = details::circular_less_than<index_t>(
+                    firstIndex + static_cast<index_t>(actualCount), endIndex) ? firstIndex +
+                                                                                static_cast<index_t>(actualCount)
+                                                                              : endIndex;
+                } while (index != firstIndex + actualCount);
+
+                MOODYCAMEL_RETHROW;
+              }
+            }
+            if (block->template set_many_empty<implicit_context>(
+              blockStartIndex, static_cast<size_t>(endIndex - blockStartIndex))) {
+              {
+#if MCDBGQ_NOLOCKFREE_IMPLICITPRODBLOCKINDEX
+                debug::DebugLock lock(mutex);
+#endif
+                // Note that the set_many_empty above did a release, meaning that anybody who acquires the block
+                // we're about to free can use it safely since our writes (and reads!) will have happened-before then.
+                entry->value.store(nullptr, std::memory_order_relaxed);
+              }
+              this->parent->add_block_to_free_list(block);    // releases the above store
+            }
+            indexIndex = (indexIndex + 1) & (localBlockIndex->capacity - 1);
+          } while (index != firstIndex + actualCount);
+
+          return actualCount;
+        } else {
+          this->dequeueOvercommit.fetch_add(desiredCount, std::memory_order_release);
+        }
+      }
+
+      return 0;
+    }
+
+   private:
+    // The block size must be > 1, so any number with the low bit set is an invalid block base index
+    static const index_t INVALID_BLOCK_BASE = 1;
+
+    struct BlockIndexEntry {
+      std::atomic<index_t> key;
+      std::atomic<Block *> value;
+    };
+
+    struct BlockIndexHeader {
+      size_t capacity;
+      std::atomic<size_t> tail;
+      BlockIndexEntry *entries;
+      BlockIndexEntry **index;
+      BlockIndexHeader *prev;
+    };
+
+    template<AllocationMode allocMode>
+    inline bool insert_block_index_entry(BlockIndexEntry *&idxEntry, index_t blockStartIndex) {
+      auto localBlockIndex = blockIndex.load(
+        std::memory_order_relaxed);    // We're the only writer thread, relaxed is OK
+      if (localBlockIndex == nullptr) {
+        return false;  // this can happen if new_block_index failed in the constructor
+      }
+      auto newTail = (localBlockIndex->tail.load(std::memory_order_relaxed) + 1) &
+                     (localBlockIndex->capacity - 1);
+      idxEntry = localBlockIndex->index[newTail];
+      if (idxEntry->key.load(std::memory_order_relaxed) == INVALID_BLOCK_BASE ||
+          idxEntry->value.load(std::memory_order_relaxed) == nullptr) {
+
+        idxEntry->key.store(blockStartIndex, std::memory_order_relaxed);
+        localBlockIndex->tail.store(newTail, std::memory_order_release);
+        return true;
+      }
+
+      // No room in the old block index, try to allocate another one!
+      if (allocMode == CannotAlloc || !new_block_index()) {
+        return false;
+      }
+      localBlockIndex = blockIndex.load(std::memory_order_relaxed);
+      newTail = (localBlockIndex->tail.load(std::memory_order_relaxed) + 1) &
+                (localBlockIndex->capacity - 1);
+      idxEntry = localBlockIndex->index[newTail];
+      assert(idxEntry->key.load(std::memory_order_relaxed) == INVALID_BLOCK_BASE);
+      idxEntry->key.store(blockStartIndex, std::memory_order_relaxed);
+      localBlockIndex->tail.store(newTail, std::memory_order_release);
+      return true;
+    }
+
+    inline void rewind_block_index_tail() {
+      auto localBlockIndex = blockIndex.load(std::memory_order_relaxed);
+      localBlockIndex->tail.store((localBlockIndex->tail.load(std::memory_order_relaxed) - 1) &
+                                  (localBlockIndex->capacity - 1), std::memory_order_relaxed);
+    }
+
+    inline BlockIndexEntry *get_block_index_entry_for_index(index_t index) const {
+      BlockIndexHeader *localBlockIndex;
+      auto idx = get_block_index_index_for_index(index, localBlockIndex);
+      return localBlockIndex->index[idx];
+    }
+
+    inline size_t
+    get_block_index_index_for_index(index_t index, BlockIndexHeader *&localBlockIndex) const {
+#if MCDBGQ_NOLOCKFREE_IMPLICITPRODBLOCKINDEX
+      debug::DebugLock lock(mutex);
+#endif
+      index &= ~static_cast<index_t>(BLOCK_SIZE - 1);
+      localBlockIndex = blockIndex.load(std::memory_order_acquire);
+      auto tail = localBlockIndex->tail.load(std::memory_order_acquire);
+      auto tailBase = localBlockIndex->index[tail]->key.load(std::memory_order_relaxed);
+      assert(tailBase != INVALID_BLOCK_BASE);
+      // Note: Must use division instead of shift because the index may wrap around, causing a negative
+      // offset, whose negativity we want to preserve
+      auto offset = static_cast<size_t>(
+        static_cast<typename std::make_signed<index_t>::type>(index - tailBase) / BLOCK_SIZE);
+      size_t idx = (tail + offset) & (localBlockIndex->capacity - 1);
+      assert(localBlockIndex->index[idx]->key.load(std::memory_order_relaxed) == index &&
+             localBlockIndex->index[idx]->value.load(std::memory_order_relaxed) != nullptr);
+      return idx;
+    }
+
+    bool new_block_index() {
+      auto prev = blockIndex.load(std::memory_order_relaxed);
+      size_t prevCapacity = prev == nullptr ? 0 : prev->capacity;
+      auto entryCount = prev == nullptr ? nextBlockIndexCapacity : prevCapacity;
+      auto raw = static_cast<char *>((Traits::malloc)(
+        sizeof(BlockIndexHeader) +
+        std::alignment_of<BlockIndexEntry>::value - 1 + sizeof(BlockIndexEntry) * entryCount +
+        std::alignment_of<BlockIndexEntry *>::value - 1 +
+        sizeof(BlockIndexEntry * ) * nextBlockIndexCapacity));
+      if (raw == nullptr) {
+        return false;
+      }
+
+      auto header = new(raw) BlockIndexHeader;
+      auto entries = reinterpret_cast<BlockIndexEntry *>(details::align_for<BlockIndexEntry>(
+        raw + sizeof(BlockIndexHeader)));
+      auto index = reinterpret_cast<BlockIndexEntry **>(details::align_for<BlockIndexEntry *>(
+        reinterpret_cast<char *>(entries) + sizeof(BlockIndexEntry) * entryCount));
+      if (prev != nullptr) {
+        auto prevTail = prev->tail.load(std::memory_order_relaxed);
+        auto prevPos = prevTail;
+        size_t i = 0;
+        do {
+          prevPos = (prevPos + 1) & (prev->capacity - 1);
+          index[i++] = prev->index[prevPos];
+        } while (prevPos != prevTail);
+        assert(i == prevCapacity);
+      }
+      for (size_t i = 0; i != entryCount; ++i) {
+        new(entries + i) BlockIndexEntry;
+        entries[i].key.store(INVALID_BLOCK_BASE, std::memory_order_relaxed);
+        index[prevCapacity + i] = entries + i;
+      }
+      header->prev = prev;
+      header->entries = entries;
+      header->index = index;
+      header->capacity = nextBlockIndexCapacity;
+      header->tail.store((prevCapacity - 1) & (nextBlockIndexCapacity - 1),
+                         std::memory_order_relaxed);
+
+      blockIndex.store(header, std::memory_order_release);
+
+      nextBlockIndexCapacity <<= 1;
+
+      return true;
+    }
+
+   private:
+    size_t nextBlockIndexCapacity;
+    std::atomic<BlockIndexHeader *> blockIndex;
+
+#ifdef MOODYCAMEL_CPP11_THREAD_LOCAL_SUPPORTED
+    public:
+      details::ThreadExitListener threadExitListener;
+    private:
+#endif
+
+#ifdef MOODYCAMEL_QUEUE_INTERNAL_DEBUG
+    public:
+      ImplicitProducer* nextImplicitProducer;
+    private:
+#endif
+
+#if MCDBGQ_NOLOCKFREE_IMPLICITPRODBLOCKINDEX
+    mutable debug::DebugMutex mutex;
+#endif
+#if MCDBGQ_TRACKMEM
+    friend struct MemStats;
+#endif
+  };
+
+
+  //////////////////////////////////
+  // Block pool manipulation
+  //////////////////////////////////
+
+  void populate_initial_block_list(size_t blockCount) {
+    initialBlockPoolSize = blockCount;
+    if (initialBlockPoolSize == 0) {
+      initialBlockPool = nullptr;
+      return;
+    }
+
+    initialBlockPool = create_array<Block>(blockCount);
+    if (initialBlockPool == nullptr) {
+      initialBlockPoolSize = 0;
+    }
+    for (size_t i = 0; i < initialBlockPoolSize; ++i) {
+      initialBlockPool[i].dynamicallyAllocated = false;
+    }
+  }
+
+  inline Block *try_get_block_from_initial_pool() {
+    if (initialBlockPoolIndex.load(std::memory_order_relaxed) >= initialBlockPoolSize) {
+      return nullptr;
+    }
+
+    auto index = initialBlockPoolIndex.fetch_add(1, std::memory_order_relaxed);
+
+    return index < initialBlockPoolSize ? (initialBlockPool + index) : nullptr;
+  }
+
+  inline void add_block_to_free_list(Block *block) {
+#if MCDBGQ_TRACKMEM
+    block->owner = nullptr;
+#endif
+    freeList.add(block);
+  }
+
+  inline void add_blocks_to_free_list(Block *block) {
+    while (block != nullptr) {
+      auto next = block->next;
+      add_block_to_free_list(block);
+      block = next;
+    }
+  }
+
+  inline Block *try_get_block_from_free_list() {
+    return freeList.try_get();
+  }
+
+  // Gets a free block from one of the memory pools, or allocates a new one (if applicable)
+  template<AllocationMode canAlloc>
+  Block *requisition_block() {
+    auto block = try_get_block_from_initial_pool();
+    if (block != nullptr) {
+      return block;
+    }
+
+    block = try_get_block_from_free_list();
+    if (block != nullptr) {
+      return block;
+    }
+
+    if (canAlloc == CanAlloc) {
+      return create<Block>();
+    }
+
+    return nullptr;
+  }
+
+
+#if MCDBGQ_TRACKMEM
+  public:
+    struct MemStats {
+      size_t allocatedBlocks;
+      size_t usedBlocks;
+      size_t freeBlocks;
+      size_t ownedBlocksExplicit;
+      size_t ownedBlocksImplicit;
+      size_t implicitProducers;
+      size_t explicitProducers;
+      size_t elementsEnqueued;
+      size_t blockClassBytes;
+      size_t queueClassBytes;
+      size_t implicitBlockIndexBytes;
+      size_t explicitBlockIndexBytes;
+
+      friend class ConcurrentQueue;
+
+    private:
+      static MemStats getFor(ConcurrentQueue* q)
+      {
+        MemStats stats = { 0 };
+
+        stats.elementsEnqueued = q->size_approx();
+
+        auto block = q->freeList.head_unsafe();
+        while (block != nullptr) {
+          ++stats.allocatedBlocks;
+          ++stats.freeBlocks;
+          block = block->freeListNext.load(std::memory_order_relaxed);
+        }
+
+        for (auto ptr = q->producerListTail.load(std::memory_order_acquire); ptr != nullptr; ptr = ptr->next_prod()) {
+          bool implicit = dynamic_cast<ImplicitProducer*>(ptr) != nullptr;
+          stats.implicitProducers += implicit ? 1 : 0;
+          stats.explicitProducers += implicit ? 0 : 1;
+
+          if (implicit) {
+            auto prod = static_cast<ImplicitProducer*>(ptr);
+            stats.queueClassBytes += sizeof(ImplicitProducer);
+            auto head = prod->headIndex.load(std::memory_order_relaxed);
+            auto tail = prod->tailIndex.load(std::memory_order_relaxed);
+            auto hash = prod->blockIndex.load(std::memory_order_relaxed);
+            if (hash != nullptr) {
+              for (size_t i = 0; i != hash->capacity; ++i) {
+                if (hash->index[i]->key.load(std::memory_order_relaxed) != ImplicitProducer::INVALID_BLOCK_BASE && hash->index[i]->value.load(std::memory_order_relaxed) != nullptr) {
+                  ++stats.allocatedBlocks;
+                  ++stats.ownedBlocksImplicit;
+                }
+              }
+              stats.implicitBlockIndexBytes += hash->capacity * sizeof(typename ImplicitProducer::BlockIndexEntry);
+              for (; hash != nullptr; hash = hash->prev) {
+                stats.implicitBlockIndexBytes += sizeof(typename ImplicitProducer::BlockIndexHeader) + hash->capacity * sizeof(typename ImplicitProducer::BlockIndexEntry*);
+              }
+            }
+            for (; details::circular_less_than<index_t>(head, tail); head += BLOCK_SIZE) {
+              //auto block = prod->get_block_index_entry_for_index(head);
+              ++stats.usedBlocks;
+            }
+          }
+          else {
+            auto prod = static_cast<ExplicitProducer*>(ptr);
+            stats.queueClassBytes += sizeof(ExplicitProducer);
+            auto tailBlock = prod->tailBlock;
+            bool wasNonEmpty = false;
+            if (tailBlock != nullptr) {
+              auto block = tailBlock;
+              do {
+                ++stats.allocatedBlocks;
+                if (!block->template is_empty<explicit_context>() || wasNonEmpty) {
+                  ++stats.usedBlocks;
+                  wasNonEmpty = wasNonEmpty || block != tailBlock;
+                }
+                ++stats.ownedBlocksExplicit;
+                block = block->next;
+              } while (block != tailBlock);
+            }
+            auto index = prod->blockIndex.load(std::memory_order_relaxed);
+            while (index != nullptr) {
+              stats.explicitBlockIndexBytes += sizeof(typename ExplicitProducer::BlockIndexHeader) + index->size * sizeof(typename ExplicitProducer::BlockIndexEntry);
+              index = static_cast<typename ExplicitProducer::BlockIndexHeader*>(index->prev);
+            }
+          }
+        }
+
+        auto freeOnInitialPool = q->initialBlockPoolIndex.load(std::memory_order_relaxed) >= q->initialBlockPoolSize ? 0 : q->initialBlockPoolSize - q->initialBlockPoolIndex.load(std::memory_order_relaxed);
+        stats.allocatedBlocks += freeOnInitialPool;
+        stats.freeBlocks += freeOnInitialPool;
+
+        stats.blockClassBytes = sizeof(Block) * stats.allocatedBlocks;
+        stats.queueClassBytes += sizeof(ConcurrentQueue);
+
+        return stats;
+      }
+    };
+
+    // For debugging only. Not thread-safe.
+    MemStats getMemStats()
+    {
+      return MemStats::getFor(this);
+    }
+  private:
+    friend struct MemStats;
+#endif
+
+
+  //////////////////////////////////
+  // Producer list manipulation
+  //////////////////////////////////
+
+  ProducerBase *recycle_or_create_producer(bool isExplicit) {
+    bool recycled;
+    return recycle_or_create_producer(isExplicit, recycled);
+  }
+
+  ProducerBase *recycle_or_create_producer(bool isExplicit, bool &recycled) {
+#if MCDBGQ_NOLOCKFREE_IMPLICITPRODHASH
+    debug::DebugLock lock(implicitProdMutex);
+#endif
+    // Try to re-use one first
+    for (auto ptr = producerListTail.load(std::memory_order_acquire);
+         ptr != nullptr; ptr = ptr->next_prod()) {
+      if (ptr->inactive.load(std::memory_order_relaxed) && ptr->isExplicit == isExplicit) {
+        bool expected = true;
+        if (ptr->inactive.compare_exchange_strong(expected, /* desired */ false,
+                                                  std::memory_order_acquire,
+                                                  std::memory_order_relaxed)) {
+          // We caught one! It's been marked as activated, the caller can have it
+          recycled = true;
+          return ptr;
+        }
+      }
+    }
+
+    recycled = false;
+    return add_producer(isExplicit ? static_cast<ProducerBase *>(create<ExplicitProducer>(this))
+                                   : create<ImplicitProducer>(this));
+  }
+
+  ProducerBase *add_producer(ProducerBase *producer) {
+    // Handle failed memory allocation
+    if (producer == nullptr) {
+      return nullptr;
+    }
+
+    producerCount.fetch_add(1, std::memory_order_relaxed);
+
+    // Add it to the lock-free list
+    auto prevTail = producerListTail.load(std::memory_order_relaxed);
+    do {
+      producer->next = prevTail;
+    } while (!producerListTail.compare_exchange_weak(prevTail, producer, std::memory_order_release,
+                                                     std::memory_order_relaxed));
+
+#ifdef MOODYCAMEL_QUEUE_INTERNAL_DEBUG
+    if (producer->isExplicit) {
+      auto prevTailExplicit = explicitProducers.load(std::memory_order_relaxed);
+      do {
+        static_cast<ExplicitProducer*>(producer)->nextExplicitProducer = prevTailExplicit;
+      } while (!explicitProducers.compare_exchange_weak(prevTailExplicit, static_cast<ExplicitProducer*>(producer), std::memory_order_release, std::memory_order_relaxed));
+    }
+    else {
+      auto prevTailImplicit = implicitProducers.load(std::memory_order_relaxed);
+      do {
+        static_cast<ImplicitProducer*>(producer)->nextImplicitProducer = prevTailImplicit;
+      } while (!implicitProducers.compare_exchange_weak(prevTailImplicit, static_cast<ImplicitProducer*>(producer), std::memory_order_release, std::memory_order_relaxed));
+    }
+#endif
+
+    return producer;
+  }
+
+  void reown_producers() {
+    // After another instance is moved-into/swapped-with this one, all the
+    // producers we stole still think their parents are the other queue.
+    // So fix them up!
+    for (auto ptr = producerListTail.load(std::memory_order_relaxed);
+         ptr != nullptr; ptr = ptr->next_prod()) {
+      ptr->parent = this;
+    }
+  }
+
+
+  //////////////////////////////////
+  // Implicit producer hash
+  //////////////////////////////////
+
+  struct ImplicitProducerKVP {
+    std::atomic<details::thread_id_t> key;
+    ImplicitProducer *value;    // No need for atomicity since it's only read by the thread that sets it in the first place
+
+    ImplicitProducerKVP()
+      : value(nullptr) {}
+
+    ImplicitProducerKVP(ImplicitProducerKVP &&other) MOODYCAMEL_NOEXCEPT {
+      key.store(other.key.load(std::memory_order_relaxed), std::memory_order_relaxed);
+      value = other.value;
+    }
+
+    inline ImplicitProducerKVP &operator=(ImplicitProducerKVP &&other) MOODYCAMEL_NOEXCEPT {
+      swap(other);
+      return *this;
+    }
+
+    inline void swap(ImplicitProducerKVP &other) MOODYCAMEL_NOEXCEPT {
+      if (this != &other) {
+        details::swap_relaxed(key, other.key);
+        std::swap(value, other.value);
+      }
+    }
+  };
+
+  template<typename XT, typename XTraits>
+  friend void moodycamel::swap(typename ConcurrentQueue<XT, XTraits>::ImplicitProducerKVP &,
+                               typename ConcurrentQueue<XT, XTraits>::ImplicitProducerKVP &) MOODYCAMEL_NOEXCEPT;
+
+  struct ImplicitProducerHash {
+    size_t capacity;
+    ImplicitProducerKVP *entries;
+    ImplicitProducerHash *prev;
+  };
+
+  inline void populate_initial_implicit_producer_hash() {
+    if (INITIAL_IMPLICIT_PRODUCER_HASH_SIZE == 0) return;
+
+    implicitProducerHashCount.store(0, std::memory_order_relaxed);
+    auto hash = &initialImplicitProducerHash;
+    hash->capacity = INITIAL_IMPLICIT_PRODUCER_HASH_SIZE;
+    hash->entries = &initialImplicitProducerHashEntries[0];
+    for (size_t i = 0; i != INITIAL_IMPLICIT_PRODUCER_HASH_SIZE; ++i) {
+      initialImplicitProducerHashEntries[i].key.store(details::invalid_thread_id,
+                                                      std::memory_order_relaxed);
+    }
+    hash->prev = nullptr;
+    implicitProducerHash.store(hash, std::memory_order_relaxed);
+  }
+
+  void swap_implicit_producer_hashes(ConcurrentQueue &other) {
+    if (INITIAL_IMPLICIT_PRODUCER_HASH_SIZE == 0) return;
+
+    // Swap (assumes our implicit producer hash is initialized)
+    initialImplicitProducerHashEntries.swap(other.initialImplicitProducerHashEntries);
+    initialImplicitProducerHash.entries = &initialImplicitProducerHashEntries[0];
+    other.initialImplicitProducerHash.entries = &other.initialImplicitProducerHashEntries[0];
+
+    details::swap_relaxed(implicitProducerHashCount, other.implicitProducerHashCount);
+
+    details::swap_relaxed(implicitProducerHash, other.implicitProducerHash);
+    if (implicitProducerHash.load(std::memory_order_relaxed) ==
+        &other.initialImplicitProducerHash) {
+      implicitProducerHash.store(&initialImplicitProducerHash, std::memory_order_relaxed);
+    } else {
+      ImplicitProducerHash *hash;
+      for (hash = implicitProducerHash.load(std::memory_order_relaxed);
+           hash->prev != &other.initialImplicitProducerHash; hash = hash->prev) {
+        continue;
+      }
+      hash->prev = &initialImplicitProducerHash;
+    }
+    if (other.implicitProducerHash.load(std::memory_order_relaxed) ==
+        &initialImplicitProducerHash) {
+      other.implicitProducerHash.store(&other.initialImplicitProducerHash,
+                                       std::memory_order_relaxed);
+    } else {
+      ImplicitProducerHash *hash;
+      for (hash = other.implicitProducerHash.load(std::memory_order_relaxed);
+           hash->prev != &initialImplicitProducerHash; hash = hash->prev) {
+        continue;
+      }
+      hash->prev = &other.initialImplicitProducerHash;
+    }
+  }
+
+  // Only fails (returns nullptr) if memory allocation fails
+  ImplicitProducer *get_or_add_implicit_producer() {
+    // Note that since the data is essentially thread-local (key is thread ID),
+    // there's a reduced need for fences (memory ordering is already consistent
+    // for any individual thread), except for the current table itself.
+
+    // Start by looking for the thread ID in the current and all previous hash tables.
+    // If it's not found, it must not be in there yet, since this same thread would
+    // have added it previously to one of the tables that we traversed.
+
+    // Code and algorithm adapted from http://preshing.com/20130605/the-worlds-simplest-lock-free-hash-table
+
+#if MCDBGQ_NOLOCKFREE_IMPLICITPRODHASH
+    debug::DebugLock lock(implicitProdMutex);
+#endif
+
+    auto id = details::thread_id();
+    auto hashedId = details::hash_thread_id(id);
+
+    auto mainHash = implicitProducerHash.load(std::memory_order_acquire);
+    for (auto hash = mainHash; hash != nullptr; hash = hash->prev) {
+      // Look for the id in this hash
+      auto index = hashedId;
+      while (true) {    // Not an infinite loop because at least one slot is free in the hash table
+        index &= hash->capacity - 1;
+
+        auto probedKey = hash->entries[index].key.load(std::memory_order_relaxed);
+        if (probedKey == id) {
+          // Found it! If we had to search several hashes deep, though, we should lazily add it
+          // to the current main hash table to avoid the extended search next time.
+          // Note there's guaranteed to be room in the current hash table since every subsequent
+          // table implicitly reserves space for all previous tables (there's only one
+          // implicitProducerHashCount).
+          auto value = hash->entries[index].value;
+          if (hash != mainHash) {
+            index = hashedId;
+            while (true) {
+              index &= mainHash->capacity - 1;
+              probedKey = mainHash->entries[index].key.load(std::memory_order_relaxed);
+              auto empty = details::invalid_thread_id;
+#ifdef MOODYCAMEL_CPP11_THREAD_LOCAL_SUPPORTED
+              auto reusable = details::invalid_thread_id2;
+              if ((probedKey == empty    && mainHash->entries[index].key.compare_exchange_strong(empty,    id, std::memory_order_relaxed, std::memory_order_relaxed)) ||
+                (probedKey == reusable && mainHash->entries[index].key.compare_exchange_strong(reusable, id, std::memory_order_acquire, std::memory_order_acquire))) {
+#else
+              if ((probedKey == empty &&
+                   mainHash->entries[index].key.compare_exchange_strong(empty, id,
+                                                                        std::memory_order_relaxed,
+                                                                        std::memory_order_relaxed))) {
+#endif
+                mainHash->entries[index].value = value;
+                break;
+              }
+              ++index;
+            }
+          }
+
+          return value;
+        }
+        if (probedKey == details::invalid_thread_id) {
+          break;    // Not in this hash table
+        }
+        ++index;
+      }
+    }
+
+    // Insert!
+    auto newCount = 1 + implicitProducerHashCount.fetch_add(1, std::memory_order_relaxed);
+    while (true) {
+      if (newCount >= (mainHash->capacity >> 1) &&
+          !implicitProducerHashResizeInProgress.test_and_set(std::memory_order_acquire)) {
+        // We've acquired the resize lock, try to allocate a bigger hash table.
+        // Note the acquire fence synchronizes with the release fence at the end of this block, and hence when
+        // we reload implicitProducerHash it must be the most recent version (it only gets changed within this
+        // locked block).
+        mainHash = implicitProducerHash.load(std::memory_order_acquire);
+        if (newCount >= (mainHash->capacity >> 1)) {
+          auto newCapacity = mainHash->capacity << 1;
+          while (newCount >= (newCapacity >> 1)) {
+            newCapacity <<= 1;
+          }
+          auto raw = static_cast<char *>((Traits::malloc)(
+            sizeof(ImplicitProducerHash) + std::alignment_of<ImplicitProducerKVP>::value - 1 +
+            sizeof(ImplicitProducerKVP) * newCapacity));
+          if (raw == nullptr) {
+            // Allocation failed
+            implicitProducerHashCount.fetch_sub(1, std::memory_order_relaxed);
+            implicitProducerHashResizeInProgress.clear(std::memory_order_relaxed);
+            return nullptr;
+          }
+
+          auto newHash = new(raw) ImplicitProducerHash;
+          newHash->capacity = newCapacity;
+          newHash->entries = reinterpret_cast<ImplicitProducerKVP *>(details::align_for<ImplicitProducerKVP>(
+            raw + sizeof(ImplicitProducerHash)));
+          for (size_t i = 0; i != newCapacity; ++i) {
+            new(newHash->entries + i) ImplicitProducerKVP;
+            newHash->entries[i].key.store(details::invalid_thread_id, std::memory_order_relaxed);
+          }
+          newHash->prev = mainHash;
+          implicitProducerHash.store(newHash, std::memory_order_release);
+          implicitProducerHashResizeInProgress.clear(std::memory_order_release);
+          mainHash = newHash;
+        } else {
+          implicitProducerHashResizeInProgress.clear(std::memory_order_release);
+        }
+      }
+
+      // If it's < three-quarters full, add to the old one anyway so that we don't have to wait for the next table
+      // to finish being allocated by another thread (and if we just finished allocating above, the condition will
+      // always be true)
+      if (newCount < (mainHash->capacity >> 1) + (mainHash->capacity >> 2)) {
+        bool recycled;
+        auto producer = static_cast<ImplicitProducer *>(recycle_or_create_producer(false,
+                                                                                   recycled));
+        if (producer == nullptr) {
+          implicitProducerHashCount.fetch_sub(1, std::memory_order_relaxed);
+          return nullptr;
+        }
+        if (recycled) {
+          implicitProducerHashCount.fetch_sub(1, std::memory_order_relaxed);
+        }
+
+#ifdef MOODYCAMEL_CPP11_THREAD_LOCAL_SUPPORTED
+        producer->threadExitListener.callback = &ConcurrentQueue::implicit_producer_thread_exited_callback;
+        producer->threadExitListener.userData = producer;
+        details::ThreadExitNotifier::subscribe(&producer->threadExitListener);
+#endif
+
+        auto index = hashedId;
+        while (true) {
+          index &= mainHash->capacity - 1;
+          auto probedKey = mainHash->entries[index].key.load(std::memory_order_relaxed);
+
+          auto empty = details::invalid_thread_id;
+#ifdef MOODYCAMEL_CPP11_THREAD_LOCAL_SUPPORTED
+          auto reusable = details::invalid_thread_id2;
+          if ((probedKey == empty    && mainHash->entries[index].key.compare_exchange_strong(empty,    id, std::memory_order_relaxed, std::memory_order_relaxed)) ||
+            (probedKey == reusable && mainHash->entries[index].key.compare_exchange_strong(reusable, id, std::memory_order_acquire, std::memory_order_acquire))) {
+#else
+          if ((probedKey == empty && mainHash->entries[index].key.compare_exchange_strong(empty, id,
+                                                                                          std::memory_order_relaxed,
+                                                                                          std::memory_order_relaxed))) {
+#endif
+            mainHash->entries[index].value = producer;
+            break;
+          }
+          ++index;
+        }
+        return producer;
+      }
+
+      // Hmm, the old hash is quite full and somebody else is busy allocating a new one.
+      // We need to wait for the allocating thread to finish (if it succeeds, we add, if not,
+      // we try to allocate ourselves).
+      mainHash = implicitProducerHash.load(std::memory_order_acquire);
+    }
+  }
+
+#ifdef MOODYCAMEL_CPP11_THREAD_LOCAL_SUPPORTED
+  void implicit_producer_thread_exited(ImplicitProducer* producer)
+  {
+    // Remove from thread exit listeners
+    details::ThreadExitNotifier::unsubscribe(&producer->threadExitListener);
+
+    // Remove from hash
+#if MCDBGQ_NOLOCKFREE_IMPLICITPRODHASH
+    debug::DebugLock lock(implicitProdMutex);
+#endif
+    auto hash = implicitProducerHash.load(std::memory_order_acquire);
+    assert(hash != nullptr);		// The thread exit listener is only registered if we were added to a hash in the first place
+    auto id = details::thread_id();
+    auto hashedId = details::hash_thread_id(id);
+    details::thread_id_t probedKey;
+
+    // We need to traverse all the hashes just in case other threads aren't on the current one yet and are
+    // trying to add an entry thinking there's a free slot (because they reused a producer)
+    for (; hash != nullptr; hash = hash->prev) {
+      auto index = hashedId;
+      do {
+        index &= hash->capacity - 1;
+        probedKey = hash->entries[index].key.load(std::memory_order_relaxed);
+        if (probedKey == id) {
+          hash->entries[index].key.store(details::invalid_thread_id2, std::memory_order_release);
+          break;
+        }
+        ++index;
+      } while (probedKey != details::invalid_thread_id);		// Can happen if the hash has changed but we weren't put back in it yet, or if we weren't added to this hash in the first place
+    }
+
+    // Mark the queue as being recyclable
+    producer->inactive.store(true, std::memory_order_release);
+  }
+
+  static void implicit_producer_thread_exited_callback(void* userData)
+  {
+    auto producer = static_cast<ImplicitProducer*>(userData);
+    auto queue = producer->parent;
+    queue->implicit_producer_thread_exited(producer);
+  }
+#endif
+
+  //////////////////////////////////
+  // Utility functions
+  //////////////////////////////////
+
+  template<typename U>
+  static inline U *create_array(size_t count) {
+    assert(count > 0);
+    auto p = static_cast<U *>((Traits::malloc)(sizeof(U) * count));
+    if (p == nullptr) {
+      return nullptr;
+    }
+
+    for (size_t i = 0; i != count; ++i) {
+      new(p + i) U();
+    }
+    return p;
+  }
+
+  template<typename U>
+  static inline void destroy_array(U *p, size_t count) {
+    if (p != nullptr) {
+      assert(count > 0);
+      for (size_t i = count; i != 0;) {
+        (p + --i)->~U();
+      }
+      (Traits::free)(p);
+    }
+  }
+
+  template<typename U>
+  static inline U *create() {
+    auto p = (Traits::malloc)(sizeof(U));
+    return p != nullptr ? new(p) U : nullptr;
+  }
+
+  template<typename U, typename A1>
+  static inline U *create(A1 &&a1) {
+    auto p = (Traits::malloc)(sizeof(U));
+    return p != nullptr ? new(p) U(std::forward<A1>(a1)) : nullptr;
+  }
+
+  template<typename U>
+  static inline void destroy(U *p) {
+    if (p != nullptr) {
+      p->~U();
+    }
+    (Traits::free)(p);
+  }
+
+ private:
+  std::atomic<ProducerBase *> producerListTail;
+  std::atomic<std::uint32_t> producerCount;
+
+  std::atomic<size_t> initialBlockPoolIndex;
+  Block *initialBlockPool;
+  size_t initialBlockPoolSize;
+
+#if !MCDBGQ_USEDEBUGFREELIST
+  FreeList<Block> freeList;
+#else
+  debug::DebugFreeList<Block> freeList;
+#endif
+
+  std::atomic<ImplicitProducerHash *> implicitProducerHash;
+  std::atomic<size_t> implicitProducerHashCount;    // Number of slots logically used
+  ImplicitProducerHash initialImplicitProducerHash;
+  std::array<ImplicitProducerKVP, INITIAL_IMPLICIT_PRODUCER_HASH_SIZE> initialImplicitProducerHashEntries;
+  std::atomic_flag implicitProducerHashResizeInProgress;
+
+  std::atomic<std::uint32_t> nextExplicitConsumerId;
+  std::atomic<std::uint32_t> globalExplicitConsumerOffset;
+
+#if MCDBGQ_NOLOCKFREE_IMPLICITPRODHASH
+  debug::DebugMutex implicitProdMutex;
+#endif
+
+#ifdef MOODYCAMEL_QUEUE_INTERNAL_DEBUG
+  std::atomic<ExplicitProducer*> explicitProducers;
+  std::atomic<ImplicitProducer*> implicitProducers;
+#endif
+};
+
+
+template<typename T, typename Traits>
+ProducerToken::ProducerToken(ConcurrentQueue<T, Traits> &queue)
+  : producer(queue.recycle_or_create_producer(true)) {
+  if (producer != nullptr) {
+    producer->token = this;
+  }
+}
+
+template<typename T, typename Traits>
+ProducerToken::ProducerToken(BlockingConcurrentQueue<T, Traits> &queue)
+  : producer(
+  reinterpret_cast<ConcurrentQueue<T, Traits> *>(&queue)->recycle_or_create_producer(true)) {
+  if (producer != nullptr) {
+    producer->token = this;
+  }
+}
+
+template<typename T, typename Traits>
+ConsumerToken::ConsumerToken(ConcurrentQueue<T, Traits> &queue)
+  : itemsConsumedFromCurrent(0), currentProducer(nullptr), desiredProducer(nullptr) {
+  initialOffset = queue.nextExplicitConsumerId.fetch_add(1, std::memory_order_release);
+  lastKnownGlobalOffset = -1;
+}
+
+template<typename T, typename Traits>
+ConsumerToken::ConsumerToken(BlockingConcurrentQueue<T, Traits> &queue)
+  : itemsConsumedFromCurrent(0), currentProducer(nullptr), desiredProducer(nullptr) {
+  initialOffset = reinterpret_cast<ConcurrentQueue <T, Traits> *>(&queue)->nextExplicitConsumerId.fetch_add(
+    1, std::memory_order_release);
+  lastKnownGlobalOffset = -1;
+}
+
+template<typename T, typename Traits>
+inline void swap(ConcurrentQueue<T, Traits> &a, ConcurrentQueue<T, Traits> &b) MOODYCAMEL_NOEXCEPT {
+  a.swap(b);
+}
+
+inline void swap(ProducerToken &a, ProducerToken &b) MOODYCAMEL_NOEXCEPT {
+  a.swap(b);
+}
+
+inline void swap(ConsumerToken &a, ConsumerToken &b) MOODYCAMEL_NOEXCEPT {
+  a.swap(b);
+}
+
+template<typename T, typename Traits>
+inline void swap(typename ConcurrentQueue<T, Traits>::ImplicitProducerKVP &a,
+                 typename ConcurrentQueue<T, Traits>::ImplicitProducerKVP &b) MOODYCAMEL_NOEXCEPT {
+  a.swap(b);
+}
+
+}
+
+}  // namespace dmlc
+
+#if defined(__GNUC__)
+#pragma GCC diagnostic pop
+#endif
+
+#endif  // DMLC_CONCURRENTQUEUE_H_
+//! \endcond Doxygen_Suppress
diff --git a/darknet_drp_ros/include/dmlc/config.h b/darknet_drp_ros/include/dmlc/config.h
new file mode 100644
index 0000000..a4c5b53
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/config.h
@@ -0,0 +1,186 @@
+/*!
+ * Copyright (c) 2015 by Contributors
+ * \file config.h
+ * \brief defines config parser class
+ */
+#ifndef DMLC_CONFIG_H_
+#define DMLC_CONFIG_H_
+
+#include <cstring>
+#include <iostream>
+#include <iterator>
+#include <map>
+#include <vector>
+#include <utility>
+#include <string>
+#include <sstream>
+
+/*! \brief namespace for dmlc */
+namespace dmlc {
+
+/*!
+ * \brief class for config parser
+ *
+ * Two modes are supported:
+ * 1. non-multi value mode: if two same keys in the configure file, the later one will replace the
+ *      ealier one; when using iterator, the order will be the "last effective insersion" order
+ * 2. multi value mode: multiple values with the same key could co-exist; when using iterator, the
+ *      order will be the insersion order.
+ *
+ * [Basic usage]
+ *
+ * Config cfg(file_input_stream);
+ * for(Config::ConfigIterator iter = cfg.begin(); iter != cfg.end(); ++iter) {
+ *     ConfigEntry ent = *iter;
+ *     std::string key = ent.first;
+ *     std::string value = ent.second;
+ *     do_something_with(key, value);
+ * }
+ */
+class Config {
+ public:
+  /*!
+   * \brief type when extracting from iterator
+   */
+  typedef std::pair<std::string, std::string> ConfigEntry;
+
+  /*!
+   * \brief iterator class
+   */
+  class ConfigIterator;
+
+  /*!
+   * \brief create empty config
+   * \param multi_value whether the config supports multi value
+   */
+  explicit Config(bool multi_value = false);
+  /*!
+   * \brief create config and load content from the given stream
+   * \param is input stream
+   * \param multi_value whether the config supports multi value
+   */
+  explicit Config(std::istream& is, bool multi_value = false);  // NOLINT(*)
+  /*!
+   * \brief clear all the values
+   */
+  void Clear(void);
+  /*!
+   * \brief load the contents from the stream
+   * \param is the stream as input
+   */
+  void LoadFromStream(std::istream& is);  // NOLINT(*)
+  /*!
+   * \brief set a key-value pair into the config; if the key already exists in the configure file,
+   *        it will either replace the old value with the given one (in non-multi value mode) or
+   *        store it directly (in multi-value mode);
+   * \param key key
+   * \param value value
+   * \param is_string whether the value should be wrapped by quotes in proto string
+   */
+  template<class T>
+  void SetParam(const std::string& key, const T& value, bool is_string = false);
+
+  /*!
+   * \brief get the config under the key; if multiple values exist for the same key,
+   *        return the last inserted one.
+   * \param key key
+   * \return config value
+   */
+  const std::string& GetParam(const std::string& key) const;
+
+  /*!
+   * \brief check whether the configure value given by the key should be wrapped by quotes
+   * \param key key
+   * \return whether the configure value is represented by string
+   */
+  bool IsGenuineString(const std::string& key) const;
+
+  /*!
+   * \brief transform all the configuration into string recognizable to protobuf
+   * \return string that could be parsed directly by protobuf
+   */
+  std::string ToProtoString(void) const;
+
+  /*!
+   * \brief get begin iterator
+   * \return begin iterator
+   */
+  ConfigIterator begin() const;
+
+  /*!
+   * \brief get end iterator
+   * \return end iterator
+   */
+  ConfigIterator end() const;
+
+ public:
+  /*!
+   * \brief iterator class
+   */
+  class ConfigIterator : public std::iterator< std::input_iterator_tag, ConfigEntry > {
+    friend class Config;
+   public:
+    /*!
+     * \brief copy constructor
+     */
+    ConfigIterator(const ConfigIterator& other);
+    /*!
+     * \brief uni-increment operators
+     * \return the reference of current config
+     */
+    ConfigIterator& operator++();
+    /*!
+     * \brief uni-increment operators
+     * \return the reference of current config
+     */
+    ConfigIterator operator++(int);  // NOLINT(*)
+    /*!
+     * \brief compare operators
+     * \param rhs the other config to compare against
+     * \return the compared result
+     */
+    bool operator == (const ConfigIterator& rhs) const;
+    /*!
+     * \brief compare operators not equal
+     * \param rhs the other config to compare against
+     * \return the compared result
+     */
+    bool operator != (const ConfigIterator& rhs) const;
+    /*!
+     * \brief retrieve value from operator
+     */
+    ConfigEntry operator * () const;
+
+   private:
+    ConfigIterator(size_t index, const Config* config);
+    void FindNextIndex();
+
+   private:
+    size_t index_;
+    const Config* config_;
+  };
+
+ private:
+  struct ConfigValue {
+    std::vector<std::string> val;
+    std::vector<size_t> insert_index;
+    bool is_string;
+  };
+  void Insert(const std::string& key, const std::string& value, bool is_string);
+
+ private:
+  std::map<std::string, ConfigValue> config_map_;
+  std::vector<std::pair<std::string, size_t> > order_;
+  const bool multi_value_;
+};
+
+template<class T>
+void Config::SetParam(const std::string& key, const T& value, bool is_string) {
+  std::ostringstream oss;
+  oss << value;
+  Insert(key, oss.str(), is_string);
+}
+
+}  // namespace dmlc
+
+#endif  // DMLC_CONFIG_H_
diff --git a/darknet_drp_ros/include/dmlc/data.h b/darknet_drp_ros/include/dmlc/data.h
new file mode 100644
index 0000000..9447e09
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/data.h
@@ -0,0 +1,397 @@
+/*!
+ *  Copyright (c) 2015 by Contributors
+ * \file data.h
+ * \brief defines common input data structure,
+ *  and interface for handling the input data
+ */
+#ifndef DMLC_DATA_H_
+#define DMLC_DATA_H_
+
+#include <string>
+#include <vector>
+#include <map>
+#include "./base.h"
+#include "./io.h"
+#include "./logging.h"
+#include "./registry.h"
+
+// To help C Preprocessor with processing c++ templated types
+#define __DMLC_COMMA ,
+
+namespace dmlc {
+/*!
+ * \brief this defines the float point
+ * that will be used to store feature values
+ */
+typedef float real_t;
+
+/*!
+ * \brief this defines the unsigned integer type
+ * that can normally be used to store feature index
+ */
+typedef unsigned index_t;
+
+// This file describes common data structure that can be used
+// for large-scale machine learning, this may not be a complete list
+// But we will keep the most common and useful ones, and keep adding new ones
+/*!
+ * \brief data iterator interface
+ *  this is not a C++ style iterator, but nice for data pulling:)
+ *  This interface is used to pull in the data
+ *  The system can do some useful tricks for you like pre-fetching
+ *  from disk and pre-computation.
+ *
+ * Usage example:
+ * \code
+ *
+ *   itr->BeforeFirst();
+ *   while (itr->Next()) {
+ *      const DType &batch = itr->Value();
+ *      // some computations
+ *   }
+ * \endcode
+ * \tparam DType the data type
+ */
+template<typename DType>
+class DataIter {
+ public:
+  /*! \brief destructor */
+  virtual ~DataIter(void) DMLC_THROW_EXCEPTION {}
+  /*! \brief set before first of the item */
+  virtual void BeforeFirst(void) = 0;
+  /*! \brief move to next item */
+  virtual bool Next(void) = 0;
+  /*! \brief get current data */
+  virtual const DType &Value(void) const = 0;
+};
+
+/*!
+ * \brief one row of training instance
+ * \tparam IndexType type of index
+ * \tparam DType type of data (both label and value will be of DType
+ */
+template<typename IndexType, typename DType = real_t>
+class Row {
+ public:
+  /*! \brief label of the instance */
+  const DType *label;
+  /*! \brief weight of the instance */
+  const real_t *weight;
+  /*! \brief session-id of the instance */
+  const uint64_t *qid;
+  /*! \brief length of the sparse vector */
+  size_t length;
+  /*!
+   * \brief field of each instance
+   */
+  const IndexType *field;
+  /*!
+   * \brief index of each instance
+   */
+  const IndexType *index;
+  /*!
+   * \brief array value of each instance, this can be NULL
+   *  indicating every value is set to be 1
+   */
+  const DType *value;
+  /*!
+   * \param i the input index
+   * \return field for i-th feature
+   */
+  inline IndexType get_field(size_t i) const {
+    return field[i];
+  }
+  /*!
+   * \param i the input index
+   * \return i-th feature
+   */
+  inline IndexType get_index(size_t i) const {
+    return index[i];
+  }
+  /*!
+   * \param i the input index
+   * \return i-th feature value, this function is always
+   *  safe even when value == NULL
+   */
+  inline DType get_value(size_t i) const {
+    return value == NULL ? DType(1.0f) : value[i];
+  }
+  /*!
+   * \return the label of the instance
+   */
+  inline DType get_label() const {
+    return *label;
+  }
+  /*!
+   * \return the weight of the instance, this function is always
+   *  safe even when weight == NULL
+   */
+  inline real_t get_weight() const {
+    return weight == NULL ? 1.0f : *weight;
+  }
+  /*!
+   * \return the qid of the instance, this function is always
+   *  safe even when qid == NULL
+   */
+  inline uint64_t get_qid() const {
+    return qid == NULL ? 0 : *qid;
+  }
+  /*!
+   * \brief helper function to compute dot product of current
+   * \param weight the dense array of weight we want to product
+   * \param size the size of the weight vector
+   * \tparam V type of the weight vector
+   * \return the result of dot product
+   */
+  template<typename V>
+  inline V SDot(const V *weight, size_t size) const {
+    V sum = static_cast<V>(0);
+    if (value == NULL) {
+      for (size_t i = 0; i < length; ++i) {
+        CHECK(index[i] < size) << "feature index exceed bound";
+        sum += weight[index[i]];
+      }
+    } else {
+      for (size_t i = 0; i < length; ++i) {
+        CHECK(index[i] < size) << "feature index exceed bound";
+        sum += weight[index[i]] * value[i];
+      }
+    }
+    return sum;
+  }
+};
+
+/*!
+ * \brief a block of data, containing several rows in sparse matrix
+ *  This is useful for (streaming-sxtyle) algorithms that scans through rows of data
+ *  examples include: SGD, GD, L-BFGS, kmeans
+ *
+ *  The size of batch is usually large enough so that parallelizing over the rows
+ *  can give significant speedup
+ * \tparam IndexType type to store the index used in row batch
+ * \tparam DType type to store the label and value used in row batch
+ */
+template<typename IndexType, typename DType = real_t>
+struct RowBlock {
+  /*! \brief batch size */
+  size_t size;
+  /*! \brief array[size+1], row pointer to beginning of each rows */
+  const size_t *offset;
+  /*! \brief array[size] label of each instance */
+  const DType *label;
+  /*! \brief With weight: array[size] label of each instance, otherwise nullptr */
+  const real_t *weight;
+  /*! \brief With qid: array[size] session id of each instance, otherwise nullptr */
+  const uint64_t *qid;
+  /*! \brief field id*/
+  const IndexType *field;
+  /*! \brief feature index */
+  const IndexType *index;
+  /*! \brief feature value, can be NULL, indicating all values are 1 */
+  const DType *value;
+  /*!
+   * \brief get specific rows in the batch
+   * \param rowid the rowid in that row
+   * \return the instance corresponding to the row
+   */
+  inline Row<IndexType, DType> operator[](size_t rowid) const;
+  /*! \return memory cost of the block in bytes */
+  inline size_t MemCostBytes(void) const {
+    size_t cost = size * (sizeof(size_t) + sizeof(DType));
+    if (weight != NULL) cost += size * sizeof(real_t);
+    if (qid != NULL) cost += size * sizeof(size_t);
+    size_t ndata = offset[size] - offset[0];
+    if (field != NULL) cost += ndata * sizeof(IndexType);
+    if (index != NULL) cost += ndata * sizeof(IndexType);
+    if (value != NULL) cost += ndata * sizeof(DType);
+    return cost;
+  }
+  /*!
+   * \brief slice a RowBlock to get rows in [begin, end)
+   * \param begin the begin row index
+   * \param end the end row index
+   * \return the sliced RowBlock
+   */
+  inline RowBlock Slice(size_t begin, size_t end) const {
+    CHECK(begin <= end && end <= size);
+    RowBlock ret;
+    ret.size = end - begin;
+    ret.label = label + begin;
+    if (weight != NULL) {
+      ret.weight = weight + begin;
+    } else {
+      ret.weight = NULL;
+    }
+    if (qid != NULL) {
+      ret.qid = qid + begin;
+    } else {
+      ret.qid = NULL;
+    }
+    ret.offset = offset + begin;
+    ret.field = field;
+    ret.index = index;
+    ret.value = value;
+    return ret;
+  }
+};
+
+/*!
+ * \brief Data structure that holds the data
+ * Row block iterator interface that gets RowBlocks
+ * Difference between RowBlockIter and Parser:
+ *     RowBlockIter caches the data internally that can be used
+ *     to iterate the dataset multiple times,
+ *     Parser holds very limited internal state and was usually
+ *     used to read data only once
+ *
+ * \sa Parser
+ * \tparam IndexType type of index in RowBlock
+ * \tparam DType type of label and value in RowBlock
+ *  Create function was only implemented for IndexType uint64_t and uint32_t
+ *  and DType real_t and int
+ */
+template<typename IndexType, typename DType = real_t>
+class RowBlockIter : public DataIter<RowBlock<IndexType, DType> > {
+ public:
+  /*!
+   * \brief create a new instance of iterator that returns rowbatch
+   *  by default, a in-memory based iterator will be returned
+   *
+   * \param uri the uri of the input, can contain hdfs prefix
+   * \param part_index the part id of current input
+   * \param num_parts total number of splits
+   * \param type type of dataset can be: "libsvm", ...
+   *
+   * \return the created data iterator
+   */
+  static RowBlockIter<IndexType, DType> *
+  Create(const char *uri,
+         unsigned part_index,
+         unsigned num_parts,
+         const char *type);
+  /*! \return maximum feature dimension in the dataset */
+  virtual size_t NumCol() const = 0;
+};
+
+/*!
+ * \brief parser interface that parses input data
+ * used to load dmlc data format into your own data format
+ * Difference between RowBlockIter and Parser:
+ *     RowBlockIter caches the data internally that can be used
+ *     to iterate the dataset multiple times,
+ *     Parser holds very limited internal state and was usually
+ *     used to read data only once
+ *
+ *
+ * \sa RowBlockIter
+ * \tparam IndexType type of index in RowBlock
+ * \tparam DType type of label and value in RowBlock
+ *  Create function was only implemented for IndexType uint64_t and uint32_t
+ *  and DType real_t and int
+ */
+template <typename IndexType, typename DType = real_t>
+class Parser : public DataIter<RowBlock<IndexType, DType> > {
+ public:
+  /*!
+  * \brief create a new instance of parser based on the "type"
+  *
+  * \param uri_ the uri of the input, can contain hdfs prefix
+  * \param part_index the part id of current input
+  * \param num_parts total number of splits
+  * \param type type of dataset can be: "libsvm", "auto", ...
+  *
+  * When "auto" is passed, the type is decided by format argument string in URI.
+  *
+  * \return the created parser
+  */
+  static Parser<IndexType, DType> *
+  Create(const char *uri_,
+         unsigned part_index,
+         unsigned num_parts,
+         const char *type);
+  /*! \return size of bytes read so far */
+  virtual size_t BytesRead(void) const = 0;
+  /*! \brief Factory type of the parser*/
+  typedef Parser<IndexType, DType>* (*Factory)
+      (const std::string& path,
+       const std::map<std::string, std::string>& args,
+       unsigned part_index,
+       unsigned num_parts);
+};
+
+/*!
+ * \brief registry entry of parser factory
+ * \tparam IndexType The type of index
+ * \tparam DType The type of label and value
+ */
+template<typename IndexType, typename DType = real_t>
+struct ParserFactoryReg
+    : public FunctionRegEntryBase<ParserFactoryReg<IndexType, DType>,
+                                  typename Parser<IndexType, DType>::Factory> {};
+
+/*!
+ * \brief Register a new distributed parser to dmlc-core.
+ *
+ * \param IndexType The type of Batch index, can be uint32_t or uint64_t
+ * \param DataType The type of Batch label and value, can be real_t or int
+ * \param TypeName The typename of of the data.
+ * \param FactoryFunction The factory function that creates the parser.
+ *
+ * \code
+ *
+ *  // define the factory function
+ *  template<typename IndexType, typename DType = real_t>
+ *  Parser<IndexType, DType>*
+ *  CreateLibSVMParser(const char* uri, unsigned part_index, unsigned num_parts) {
+ *    return new LibSVMParser(uri, part_index, num_parts);
+ *  }
+ *
+ *  // Register it to DMLC
+ *  // Then we can use Parser<uint32_t>::Create(uri, part_index, num_parts, "libsvm");
+ *  // to create the parser
+ *
+ *  DMLC_REGISTER_DATA_PARSER(uint32_t, real_t, libsvm, CreateLibSVMParser<uint32_t>);
+ *  DMLC_REGISTER_DATA_PARSER(uint64_t, real_t, libsvm, CreateLibSVMParser<uint64_t>);
+ *
+ * \endcode
+ */
+#define DMLC_REGISTER_DATA_PARSER(IndexType, DataType, TypeName, FactoryFunction) \
+  DMLC_REGISTRY_REGISTER(ParserFactoryReg<IndexType __DMLC_COMMA DataType>,           \
+                         ParserFactoryReg ## _ ## IndexType ## _ ## DataType, TypeName)  \
+  .set_body(FactoryFunction)
+
+
+// implementation of operator[]
+template<typename IndexType, typename DType>
+inline Row<IndexType, DType>
+RowBlock<IndexType, DType>::operator[](size_t rowid) const {
+  CHECK(rowid < size);
+  Row<IndexType, DType> inst;
+  inst.label = label + rowid;
+  if (weight != NULL) {
+    inst.weight = weight + rowid;
+  } else {
+    inst.weight = NULL;
+  }
+  if (qid != NULL) {
+    inst.qid = qid + rowid;
+  } else {
+    inst.qid = NULL;
+  }
+  inst.length = offset[rowid + 1] - offset[rowid];
+  if (field != NULL) {
+    inst.field = field + offset[rowid];
+  } else {
+    inst.field = NULL;
+  }
+  inst.index = index + offset[rowid];
+  if (value == NULL) {
+    inst.value = NULL;
+  } else {
+    inst.value = value + offset[rowid];
+  }
+  return inst;
+}
+
+}  // namespace dmlc
+#endif  // DMLC_DATA_H_
diff --git a/darknet_drp_ros/include/dmlc/endian.h b/darknet_drp_ros/include/dmlc/endian.h
new file mode 100644
index 0000000..c72739e
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/endian.h
@@ -0,0 +1,63 @@
+/*!
+ *  Copyright (c) 2017 by Contributors
+ * \file endian.h
+ * \brief Endian testing, need c++11
+ */
+#ifndef DMLC_ENDIAN_H_
+#define DMLC_ENDIAN_H_
+
+#include "./base.h"
+
+#ifdef DMLC_CMAKE_LITTLE_ENDIAN
+  // If compiled with CMake, use CMake's endian detection logic
+  #define DMLC_LITTLE_ENDIAN DMLC_CMAKE_LITTLE_ENDIAN
+#else
+  #if defined(__APPLE__) || defined(_WIN32)
+    #define DMLC_LITTLE_ENDIAN 1
+  #elif defined(__GLIBC__) || defined(__GNU_LIBRARY__) \
+        || defined(__ANDROID__) || defined(__RISCV__)
+    #include <endian.h>
+    #define DMLC_LITTLE_ENDIAN (__BYTE_ORDER == __LITTLE_ENDIAN)
+  #elif defined(__FreeBSD__) || defined(__OpenBSD__)
+    #include <sys/endian.h>
+    #define DMLC_LITTLE_ENDIAN (_BYTE_ORDER == _LITTLE_ENDIAN)
+  #elif defined(__EMSCRIPTEN__) || defined(__hexagon__)
+    #define DMLC_LITTLE_ENDIAN 1
+  #elif defined(__sun) || defined(sun)
+    #include <sys/isa_defs.h>
+    #if defined(_LITTLE_ENDIAN)
+      #define DMLC_LITTLE_ENDIAN 1
+    #else
+      #define DMLC_LITTLE_ENDIAN 0
+    #endif
+  #else
+    #error "Unable to determine endianness of your machine; use CMake to compile"
+  #endif
+#endif
+
+/*! \brief whether serialize using little endian */
+#define DMLC_IO_NO_ENDIAN_SWAP (DMLC_LITTLE_ENDIAN == DMLC_IO_USE_LITTLE_ENDIAN)
+
+namespace dmlc {
+
+/*!
+ * \brief A generic inplace byte swapping function.
+ * \param data The data pointer.
+ * \param elem_bytes The number of bytes of the data elements
+ * \param num_elems Number of elements in the data.
+ * \note Always try pass in constant elem_bytes to enable
+ *       compiler optimization
+ */
+inline void ByteSwap(void* data, size_t elem_bytes, size_t num_elems) {
+  for (size_t i = 0; i < num_elems; ++i) {
+    uint8_t* bptr = reinterpret_cast<uint8_t*>(data) + elem_bytes * i;
+    for (size_t j = 0; j < elem_bytes / 2; ++j) {
+      uint8_t v = bptr[elem_bytes - 1 - j];
+      bptr[elem_bytes - 1 - j] = bptr[j];
+      bptr[j] = v;
+    }
+  }
+}
+
+}  // namespace dmlc
+#endif  // DMLC_ENDIAN_H_
diff --git a/darknet_drp_ros/include/dmlc/filesystem.h b/darknet_drp_ros/include/dmlc/filesystem.h
new file mode 100644
index 0000000..64d1073
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/filesystem.h
@@ -0,0 +1,158 @@
+/*!
+ *  Copyright (c) 2018 by Contributors
+ * \file filesystem.h
+ * \brief Utilities to manipulate files
+ * \author Hyunsu Philip Cho
+ */
+#ifndef DMLC_FILESYSTEM_H_
+#define DMLC_FILESYSTEM_H_
+
+#include <dmlc/logging.h>
+#include <dmlc/io.h>
+#include <algorithm>
+#include <string>
+#include <vector>
+#include <random>
+
+/* platform specific headers */
+#ifdef _WIN32
+#define NOMINMAX
+#include <windows.h>
+#include <Shlwapi.h>
+#pragma comment(lib, "Shlwapi.lib")
+#else  // _WIN32
+#include <unistd.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#endif  // _WIN32
+
+namespace dmlc {
+
+/*!
+ * \brief Manager class for temporary directories. Whenever a new
+ *        TemporaryDirectory object is constructed, a temporary directory is
+ *        created. The directory is deleted when the object is deleted or goes
+ *        out of scope. Note: no symbolic links are allowed inside the
+ *        temporary directory.
+ *
+ * Usage example:
+ * \code
+ *
+ *   void foo() {
+ *     dmlc::TemporaryDirectory tempdir;
+ *     // Create a file my_file.txt inside the temporary directory
+ *     std::ofstream of(tempdir.path + "/my_file.txt");
+ *     // ... write to my_file.txt ...
+ *
+ *     // ... use my_file.txt
+ *
+ *     // When tempdir goes out of scope, the temporary directory is deleted
+ *   }
+ *
+ * \endcode
+ */
+class TemporaryDirectory {
+ public:
+  /*!
+   * \brief Default constructor.
+   *        Creates a new temporary directory with a unique name.
+   * \param verbose whether to emit extra messages
+   */
+  explicit TemporaryDirectory(bool verbose = false)
+    : verbose_(verbose) {
+#if _WIN32
+    /* locate the root directory of temporary area */
+    char tmproot[MAX_PATH] = {0};
+    const DWORD dw_retval = GetTempPathA(MAX_PATH, tmproot);
+    if (dw_retval > MAX_PATH || dw_retval == 0) {
+      LOG(FATAL) << "TemporaryDirectory(): "
+                 << "Could not create temporary directory";
+    }
+    /* generate a unique 8-letter alphanumeric string */
+    const std::string letters = "abcdefghijklmnopqrstuvwxyz0123456789_";
+    std::string uniqstr(8, '\0');
+    std::random_device rd;
+    std::mt19937 gen(rd());
+    std::uniform_int_distribution<int> dis(0, letters.length() - 1);
+    std::generate(uniqstr.begin(), uniqstr.end(),
+      [&dis, &gen, &letters]() -> char {
+        return letters[dis(gen)];
+      });
+    /* combine paths to get the name of the temporary directory */
+    char tmpdir[MAX_PATH] = {0};
+    PathCombineA(tmpdir, tmproot, uniqstr.c_str());
+    if (!CreateDirectoryA(tmpdir, NULL)) {
+      LOG(FATAL) << "TemporaryDirectory(): "
+                 << "Could not create temporary directory";
+    }
+    path = std::string(tmpdir);
+#else  // _WIN32
+    std::string tmproot; /* root directory of temporary area */
+    std::string dirtemplate; /* template for temporary directory name */
+    /* Get TMPDIR env variable or fall back to /tmp/ */
+    {
+      const char* tmpenv = getenv("TMPDIR");
+      if (tmpenv) {
+        tmproot = std::string(tmpenv);
+        // strip trailing forward slashes
+        while (tmproot.length() != 0 && tmproot[tmproot.length() - 1] == '/') {
+          tmproot.resize(tmproot.length() - 1);
+        }
+      } else {
+        tmproot = "/tmp";
+      }
+    }
+    dirtemplate = tmproot + "/tmpdir.XXXXXX";
+    std::vector<char> dirtemplate_buf(dirtemplate.begin(), dirtemplate.end());
+    dirtemplate_buf.push_back('\0');
+    char* tmpdir = mkdtemp(&dirtemplate_buf[0]);
+    if (!tmpdir) {
+      LOG(FATAL) << "TemporaryDirectory(): "
+                 << "Could not create temporary directory";
+    }
+    path = std::string(tmpdir);
+#endif  // _WIN32
+    if (verbose_) {
+      LOG(INFO) << "Created temporary directory " << path;
+    }
+  }
+
+  /*! \brief Destructor. Will perform recursive deletion via RecursiveDelete() */
+  ~TemporaryDirectory() {
+    RecursiveDelete(path);
+  }
+
+  /*! \brief Full path of the temporary directory */
+  std::string path;
+
+ private:
+  /*! \brief Whether to emit extra messages */
+  bool verbose_;
+
+  /*!
+   * \brief Determine whether a given path is a symbolic link
+   * \param path String representation of path
+   */
+  inline bool IsSymlink(const std::string& path) {
+#ifdef _WIN32
+    DWORD attr = GetFileAttributesA(path.c_str());
+    CHECK_NE(attr, INVALID_FILE_ATTRIBUTES)
+      << "dmlc::TemporaryDirectory::IsSymlink(): Unable to read file attributes";
+    return attr & FILE_ATTRIBUTE_REPARSE_POINT;
+#else  // _WIN32
+    struct stat sb;
+    CHECK_EQ(lstat(path.c_str(), &sb), 0)
+      << "dmlc::TemporaryDirectory::IsSymlink(): Unable to read file attributes";
+    return S_ISLNK(sb.st_mode);
+#endif  // _WIN32
+  }
+
+  /*!
+   * \brief Delete a directory recursively, along with sub-directories and files.
+   * \param path String representation of path. It must refer to a directory.
+   */
+  void RecursiveDelete(const std::string& path);
+};
+
+}  // namespace dmlc
+#endif  // DMLC_FILESYSTEM_H_
diff --git a/darknet_drp_ros/include/dmlc/input_split_shuffle.h b/darknet_drp_ros/include/dmlc/input_split_shuffle.h
new file mode 100644
index 0000000..fc2c65e
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/input_split_shuffle.h
@@ -0,0 +1,168 @@
+/*!
+ *  Copyright (c) 2016 by Contributors
+ * \file input_split_shuffle.h
+ * \brief base class to construct input split with global shuffling
+ * \author Yifeng Geng
+ */
+#ifndef DMLC_INPUT_SPLIT_SHUFFLE_H_
+#define DMLC_INPUT_SPLIT_SHUFFLE_H_
+
+#include <cstdio>
+#include <cstring>
+#include <vector>
+#include <string>
+#include <algorithm>
+#include <memory>
+
+namespace dmlc {
+/*! \brief class to construct input split with global shuffling */
+class InputSplitShuffle : public InputSplit {
+ public:
+  // destructor
+  virtual ~InputSplitShuffle(void) { source_.reset(); }
+  // implement BeforeFirst
+  virtual void BeforeFirst(void) {
+    if (num_shuffle_parts_ > 1) {
+      std::shuffle(shuffle_indexes_.begin(), shuffle_indexes_.end(), trnd_);
+      int idx = shuffle_indexes_[0] + part_index_ * num_shuffle_parts_;
+      source_->ResetPartition(idx, num_parts_ * num_shuffle_parts_);
+      cur_shuffle_idx_ = 0;
+    } else {
+      source_->BeforeFirst();
+    }
+  }
+  virtual void HintChunkSize(size_t chunk_size) {
+    source_->HintChunkSize(chunk_size);
+  }
+  virtual size_t GetTotalSize(void) {
+    return source_->GetTotalSize();
+  }
+  // implement next record
+  virtual bool NextRecord(Blob *out_rec) {
+    if (num_shuffle_parts_ > 1) {
+      if (!source_->NextRecord(out_rec)) {
+        if (cur_shuffle_idx_ == num_shuffle_parts_ - 1) {
+          return false;
+        }
+        ++cur_shuffle_idx_;
+        int idx =
+            shuffle_indexes_[cur_shuffle_idx_] + part_index_ * num_shuffle_parts_;
+        source_->ResetPartition(idx, num_parts_ * num_shuffle_parts_);
+        return NextRecord(out_rec);
+      } else {
+        return true;
+      }
+    } else {
+      return source_->NextRecord(out_rec);
+    }
+  }
+  // implement next chunk
+  virtual bool NextChunk(Blob* out_chunk) {
+    if (num_shuffle_parts_ > 1) {
+      if (!source_->NextChunk(out_chunk)) {
+        if (cur_shuffle_idx_ == num_shuffle_parts_ - 1) {
+          return false;
+        }
+        ++cur_shuffle_idx_;
+        int idx =
+            shuffle_indexes_[cur_shuffle_idx_] + part_index_ * num_shuffle_parts_;
+        source_->ResetPartition(idx, num_parts_ * num_shuffle_parts_);
+        return NextChunk(out_chunk);
+      } else {
+        return true;
+      }
+    } else {
+      return source_->NextChunk(out_chunk);
+    }
+  }
+  // implement ResetPartition.
+  virtual void ResetPartition(unsigned rank, unsigned nsplit) {
+    CHECK(nsplit == num_parts_) << "num_parts is not consistent!";
+    int idx = shuffle_indexes_[0] + rank * num_shuffle_parts_;
+    source_->ResetPartition(idx, nsplit * num_shuffle_parts_);
+    cur_shuffle_idx_ = 0;
+  }
+  /*!
+   * \brief constructor
+   * \param uri the uri of the input, can contain hdfs prefix
+   * \param part_index the part id of current input
+   * \param num_parts total number of splits
+   * \param type type of record
+   *   List of possible types: "text", "recordio"
+   *     - "text":
+   *         text file, each line is treated as a record
+   *         input split will split on '\\n' or '\\r'
+   *     - "recordio":
+   *         binary recordio file, see recordio.h
+   * \param num_shuffle_parts number of shuffle chunks for each split
+   * \param shuffle_seed shuffle seed for chunk shuffling
+   */
+  InputSplitShuffle(const char* uri,
+                    unsigned part_index,
+                    unsigned num_parts,
+                    const char* type,
+                    unsigned num_shuffle_parts,
+                    int shuffle_seed)
+      : part_index_(part_index),
+        num_parts_(num_parts),
+        num_shuffle_parts_(num_shuffle_parts),
+        cur_shuffle_idx_(0) {
+    for (unsigned i = 0; i < num_shuffle_parts_; i++) {
+      shuffle_indexes_.push_back(i);
+    }
+    trnd_.seed(kRandMagic_ + part_index_ + num_parts_ + num_shuffle_parts_ +
+               shuffle_seed);
+    std::shuffle(shuffle_indexes_.begin(), shuffle_indexes_.end(), trnd_);
+    int idx = shuffle_indexes_[cur_shuffle_idx_] + part_index_ * num_shuffle_parts_;
+    source_.reset(
+        InputSplit::Create(uri, idx , num_parts_ * num_shuffle_parts_, type));
+  }
+  /*!
+   * \brief factory function:
+   *  create input split with chunk shuffling given a uri
+   * \param uri the uri of the input, can contain hdfs prefix
+   * \param part_index the part id of current input
+   * \param num_parts total number of splits
+   * \param type type of record
+   *   List of possible types: "text", "recordio"
+   *     - "text":
+   *         text file, each line is treated as a record
+   *         input split will split on '\\n' or '\\r'
+   *     - "recordio":
+   *         binary recordio file, see recordio.h
+   * \param num_shuffle_parts number of shuffle chunks for each split
+   * \param shuffle_seed shuffle seed for chunk shuffling
+   * \return a new input split
+   * \sa InputSplit::Type
+   */
+  static InputSplit* Create(const char* uri,
+                            unsigned part_index,
+                            unsigned num_parts,
+                            const char* type,
+                            unsigned num_shuffle_parts,
+                            int shuffle_seed) {
+    CHECK(num_shuffle_parts > 0) << "number of shuffle parts should be greater than zero!";
+    return new InputSplitShuffle(
+        uri, part_index, num_parts, type, num_shuffle_parts, shuffle_seed);
+  }
+
+ private:
+  // magic nyumber for seed
+  static const int kRandMagic_ = 666;
+  /*! \brief random engine */
+  std::mt19937 trnd_;
+  /*! \brief inner inputsplit */
+  std::unique_ptr<InputSplit> source_;
+  /*! \brief part index */
+  unsigned part_index_;
+  /*! \brief number of parts */
+  unsigned num_parts_;
+  /*! \brief the number of block for shuffling*/
+  unsigned num_shuffle_parts_;
+  /*! \brief current shuffle block index */
+  unsigned cur_shuffle_idx_;
+  /*! \brief shuffled indexes */
+  std::vector<int> shuffle_indexes_;
+};
+}  // namespace dmlc
+#endif  // DMLC_INPUT_SPLIT_SHUFFLE_H_
diff --git a/darknet_drp_ros/include/dmlc/io.h b/darknet_drp_ros/include/dmlc/io.h
new file mode 100644
index 0000000..c1bc75e
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/io.h
@@ -0,0 +1,635 @@
+/*!
+ *  Copyright (c) 2015 by Contributors
+ * \file io.h
+ * \brief defines serializable interface of dmlc
+ */
+#ifndef DMLC_IO_H_
+#define DMLC_IO_H_
+#include <cstdio>
+#include <string>
+#include <cstring>
+#include <vector>
+#include <istream>
+#include <ostream>
+#include <streambuf>
+#include "./logging.h"
+
+// include uint64_t only to make io standalone
+#ifdef _MSC_VER
+/*! \brief uint64 */
+typedef unsigned __int64 uint64_t;
+#else
+#include <inttypes.h>
+#endif
+
+/*! \brief namespace for dmlc */
+namespace dmlc {
+/*!
+ * \brief interface of stream I/O for serialization
+ */
+class Stream {  // NOLINT(*)
+ public:
+  /*!
+   * \brief reads data from a stream
+   * \param ptr pointer to a memory buffer
+   * \param size block size
+   * \return the size of data read
+   */
+  virtual size_t Read(void *ptr, size_t size) = 0;
+  /*!
+   * \brief writes data to a stream
+   * \param ptr pointer to a memory buffer
+   * \param size block size
+   */
+  virtual void Write(const void *ptr, size_t size) = 0;
+  /*! \brief virtual destructor */
+  virtual ~Stream(void) {}
+  /*!
+   * \brief generic factory function
+   *  create an stream, the stream will close the underlying files upon deletion
+   *
+   * \param uri the uri of the input currently we support
+   *            hdfs://, s3://, and file:// by default file:// will be used
+   * \param flag can be "w", "r", "a"
+   * \param allow_null whether NULL can be returned, or directly report error
+   * \return the created stream, can be NULL when allow_null == true and file do not exist
+   */
+  static Stream *Create(const char *uri,
+                        const char* const flag,
+                        bool allow_null = false);
+  // helper functions to write/read different data structures
+  /*!
+   * \brief writes a data to stream.
+   *
+   * dmlc::Stream support Write/Read of most STL composites and base types.
+   * If the data type is not supported, a compile time error will be issued.
+   *
+   * This function is endian-aware,
+   * the output endian defined by DMLC_IO_USE_LITTLE_ENDIAN
+   *
+   * \param data data to be written
+   * \tparam T the data type to be written
+   */
+  template<typename T>
+  inline void Write(const T &data);
+  /*!
+   * \brief loads a data from stream.
+   *
+   * dmlc::Stream support Write/Read of most STL composites and base types.
+   * If the data type is not supported, a compile time error will be issued.
+   *
+   * This function is endian-aware,
+   * the input endian defined by DMLC_IO_USE_LITTLE_ENDIAN
+   *
+   * \param out_data place holder of data to be deserialized
+   * \return whether the load was successful
+   */
+  template<typename T>
+  inline bool Read(T *out_data);
+  /*!
+   * \brief Endian aware write array of data.
+   * \param data The data pointer
+   * \param num_elems Number of elements
+   * \tparam T the data type.
+   */
+  template<typename T>
+  inline void WriteArray(const T* data, size_t num_elems);
+  /*!
+   * \brief Endian aware read array of data.
+   * \param data The data pointer
+   * \param num_elems Number of elements
+   * \tparam T the data type.
+   * \return whether the load was successful
+   */
+  template<typename T>
+  inline bool ReadArray(T* data, size_t num_elems);
+};
+
+/*! \brief interface of i/o stream that support seek */
+class SeekStream: public Stream {
+ public:
+  // virtual destructor
+  virtual ~SeekStream(void) {}
+  /*! \brief seek to certain position of the file */
+  virtual void Seek(size_t pos) = 0;
+  /*! \brief tell the position of the stream */
+  virtual size_t Tell(void) = 0;
+  /*!
+   * \brief generic factory function
+   *  create an SeekStream for read only,
+   *  the stream will close the underlying files upon deletion
+   *  error will be reported and the system will exit when create failed
+   * \param uri the uri of the input currently we support
+   *            hdfs://, s3://, and file:// by default file:// will be used
+   * \param allow_null whether NULL can be returned, or directly report error
+   * \return the created stream, can be NULL when allow_null == true and file do not exist
+   */
+  static SeekStream *CreateForRead(const char *uri,
+                                   bool allow_null = false);
+};
+
+/*! \brief interface for serializable objects */
+class Serializable {
+ public:
+  /*! \brief virtual destructor */
+  virtual ~Serializable() {}
+  /*!
+  * \brief load the model from a stream
+  * \param fi stream where to load the model from
+  */
+  virtual void Load(Stream *fi) = 0;
+  /*!
+  * \brief saves the model to a stream
+  * \param fo stream where to save the model to
+  */
+  virtual void Save(Stream *fo) const = 0;
+};
+
+/*!
+ * \brief input split creates that allows reading
+ *  of records from split of data,
+ *  independent part that covers all the dataset
+ *
+ *  see InputSplit::Create for definition of record
+ */
+class InputSplit {
+ public:
+  /*! \brief a blob of memory region */
+  struct Blob {
+    /*! \brief points to start of the memory region */
+    void *dptr;
+    /*! \brief size of the memory region */
+    size_t size;
+  };
+  /*!
+   * \brief hint the inputsplit how large the chunk size
+   *  it should return when implementing NextChunk
+   *  this is a hint so may not be enforced,
+   *  but InputSplit will try adjust its internal buffer
+   *  size to the hinted value
+   * \param chunk_size the chunk size
+   */
+  virtual void HintChunkSize(size_t chunk_size) {}
+  /*! \brief get the total size of the InputSplit */
+  virtual size_t GetTotalSize(void) = 0;
+  /*! \brief reset the position of InputSplit to beginning */
+  virtual void BeforeFirst(void) = 0;
+  /*!
+   * \brief get the next record, the returning value
+   *   is valid until next call to NextRecord, NextChunk or NextBatch
+   *   caller can modify the memory content of out_rec
+   *
+   *   For text, out_rec contains a single line
+   *   For recordio, out_rec contains one record content(with header striped)
+   *
+   * \param out_rec used to store the result
+   * \return true if we can successfully get next record
+   *     false if we reached end of split
+   * \sa InputSplit::Create for definition of record
+   */
+  virtual bool NextRecord(Blob *out_rec) = 0;
+  /*!
+   * \brief get a chunk of memory that can contain multiple records,
+   *  the caller needs to parse the content of the resulting chunk,
+   *  for text file, out_chunk can contain data of multiple lines
+   *  for recordio, out_chunk can contain multiple records(including headers)
+   *
+   *  This function ensures there won't be partial record in the chunk
+   *  caller can modify the memory content of out_chunk,
+   *  the memory is valid until next call to NextRecord, NextChunk or NextBatch
+   *
+   *  Usually NextRecord is sufficient, NextChunk can be used by some
+   *  multi-threaded parsers to parse the input content
+   *
+   * \param out_chunk used to store the result
+   * \return true if we can successfully get next record
+   *     false if we reached end of split
+   * \sa InputSplit::Create for definition of record
+   * \sa RecordIOChunkReader to parse recordio content from out_chunk
+   */
+  virtual bool NextChunk(Blob *out_chunk) = 0;
+  /*!
+   * \brief get a chunk of memory that can contain multiple records,
+   *  with hint for how many records is needed,
+   *  the caller needs to parse the content of the resulting chunk,
+   *  for text file, out_chunk can contain data of multiple lines
+   *  for recordio, out_chunk can contain multiple records(including headers)
+   *
+   *  This function ensures there won't be partial record in the chunk
+   *  caller can modify the memory content of out_chunk,
+   *  the memory is valid until next call to NextRecord, NextChunk or NextBatch
+   *
+   *
+   * \param out_chunk used to store the result
+   * \param n_records used as a hint for how many records should be returned, may be ignored
+   * \return true if we can successfully get next record
+   *     false if we reached end of split
+   * \sa InputSplit::Create for definition of record
+   * \sa RecordIOChunkReader to parse recordio content from out_chunk
+   */
+  virtual bool NextBatch(Blob *out_chunk, size_t n_records) {
+    return NextChunk(out_chunk);
+  }
+  /*! \brief destructor*/
+  virtual ~InputSplit(void) DMLC_THROW_EXCEPTION {}
+  /*!
+   * \brief reset the Input split to a certain part id,
+   *  The InputSplit will be pointed to the head of the new specified segment.
+   *  This feature may not be supported by every implementation of InputSplit.
+   * \param part_index The part id of the new input.
+   * \param num_parts The total number of parts.
+   */
+  virtual void ResetPartition(unsigned part_index, unsigned num_parts) = 0;
+  /*!
+   * \brief factory function:
+   *  create input split given a uri
+   * \param uri the uri of the input, can contain hdfs prefix
+   * \param part_index the part id of current input
+   * \param num_parts total number of splits
+   * \param type type of record
+   *   List of possible types: "text", "recordio", "indexed_recordio"
+   *     - "text":
+   *         text file, each line is treated as a record
+   *         input split will split on '\\n' or '\\r'
+   *     - "recordio":
+   *         binary recordio file, see recordio.h
+   *     - "indexed_recordio":
+   *         binary recordio file with index, see recordio.h
+   * \return a new input split
+   * \sa InputSplit::Type
+   */
+  static InputSplit* Create(const char *uri,
+                            unsigned part_index,
+                            unsigned num_parts,
+                            const char *type);
+  /*!
+   * \brief factory function:
+   *  create input split given a uri for input and index
+   * \param uri the uri of the input, can contain hdfs prefix
+   * \param index_uri the uri of the index, can contain hdfs prefix
+   * \param part_index the part id of current input
+   * \param num_parts total number of splits
+   * \param type type of record
+   *   List of possible types: "text", "recordio", "indexed_recordio"
+   *     - "text":
+   *         text file, each line is treated as a record
+   *         input split will split on '\\n' or '\\r'
+   *     - "recordio":
+   *         binary recordio file, see recordio.h
+   *     - "indexed_recordio":
+   *         binary recordio file with index, see recordio.h
+   * \param shuffle whether to shuffle the output from the InputSplit,
+   *                supported only by "indexed_recordio" type.
+   *                Defaults to "false"
+   * \param seed random seed to use in conjunction with the "shuffle"
+   *             option. Defaults to 0
+   * \param batch_size a hint to InputSplit what is the intended number
+   *                   of examples return per batch. Used only by
+   *                   "indexed_recordio" type
+   * \param recurse_directories whether to recursively traverse directories
+   * \return a new input split
+   * \sa InputSplit::Type
+   */
+  static InputSplit* Create(const char *uri,
+                            const char *index_uri,
+                            unsigned part_index,
+                            unsigned num_parts,
+                            const char *type,
+                            const bool shuffle = false,
+                            const int seed = 0,
+                            const size_t batch_size = 256,
+                            const bool recurse_directories = false);
+};
+
+#ifndef _LIBCPP_SGX_NO_IOSTREAMS
+/*!
+ * \brief a std::ostream class that can can wrap Stream objects,
+ *  can use ostream with that output to underlying Stream
+ *
+ * Usage example:
+ * \code
+ *
+ *   Stream *fs = Stream::Create("hdfs:///test.txt", "w");
+ *   dmlc::ostream os(fs);
+ *   os << "hello world" << std::endl;
+ *   delete fs;
+ * \endcode
+ */
+class ostream : public std::basic_ostream<char> {
+ public:
+  /*!
+   * \brief construct std::ostream type
+   * \param stream the Stream output to be used
+   * \param buffer_size internal streambuf size
+   */
+  explicit ostream(Stream *stream,
+                   size_t buffer_size = (1 << 10))
+      : std::basic_ostream<char>(NULL), buf_(buffer_size) {
+    this->set_stream(stream);
+  }
+  // explictly synchronize the buffer
+  virtual ~ostream() DMLC_NO_EXCEPTION {
+    buf_.pubsync();
+  }
+  /*!
+   * \brief set internal stream to be stream, reset states
+   * \param stream new stream as output
+   */
+  inline void set_stream(Stream *stream) {
+    buf_.set_stream(stream);
+    this->rdbuf(&buf_);
+  }
+
+  /*! \return how many bytes we written so far */
+  inline size_t bytes_written(void) const {
+    return buf_.bytes_out();
+  }
+
+ private:
+  // internal streambuf
+  class OutBuf : public std::streambuf {
+   public:
+    explicit OutBuf(size_t buffer_size)
+        : stream_(NULL), buffer_(buffer_size), bytes_out_(0) {
+      if (buffer_size == 0) buffer_.resize(2);
+    }
+    // set stream to the buffer
+    inline void set_stream(Stream *stream);
+
+    inline size_t bytes_out() const { return bytes_out_; }
+   private:
+    /*! \brief internal stream by StreamBuf */
+    Stream *stream_;
+    /*! \brief internal buffer */
+    std::vector<char> buffer_;
+    /*! \brief number of bytes written so far */
+    size_t bytes_out_;
+    // override sync
+    inline int_type sync(void);
+    // override overflow
+    inline int_type overflow(int c);
+  };
+  /*! \brief buffer of the stream */
+  OutBuf buf_;
+};
+
+/*!
+ * \brief a std::istream class that can can wrap Stream objects,
+ *  can use istream with that output to underlying Stream
+ *
+ * Usage example:
+ * \code
+ *
+ *   Stream *fs = Stream::Create("hdfs:///test.txt", "r");
+ *   dmlc::istream is(fs);
+ *   is >> mydata;
+ *   delete fs;
+ * \endcode
+ */
+class istream : public std::basic_istream<char> {
+ public:
+  /*!
+   * \brief construct std::ostream type
+   * \param stream the Stream output to be used
+   * \param buffer_size internal buffer size
+   */
+  explicit istream(Stream *stream,
+                   size_t buffer_size = (1 << 10))
+      : std::basic_istream<char>(NULL), buf_(buffer_size) {
+    this->set_stream(stream);
+  }
+  virtual ~istream() DMLC_NO_EXCEPTION {}
+  /*!
+   * \brief set internal stream to be stream, reset states
+   * \param stream new stream as output
+   */
+  inline void set_stream(Stream *stream) {
+    buf_.set_stream(stream);
+    this->rdbuf(&buf_);
+  }
+  /*! \return how many bytes we read so far */
+  inline size_t bytes_read(void) const {
+    return buf_.bytes_read();
+  }
+
+ private:
+  // internal streambuf
+  class InBuf : public std::streambuf {
+   public:
+    explicit InBuf(size_t buffer_size)
+        : stream_(NULL), bytes_read_(0),
+          buffer_(buffer_size) {
+      if (buffer_size == 0) buffer_.resize(2);
+    }
+    // set stream to the buffer
+    inline void set_stream(Stream *stream);
+    // return how many bytes read so far
+    inline size_t bytes_read(void) const {
+      return bytes_read_;
+    }
+   private:
+    /*! \brief internal stream by StreamBuf */
+    Stream *stream_;
+    /*! \brief how many bytes we read so far */
+    size_t bytes_read_;
+    /*! \brief internal buffer */
+    std::vector<char> buffer_;
+    // override underflow
+    inline int_type underflow();
+  };
+  /*! \brief input buffer */
+  InBuf buf_;
+};
+#endif
+}  // namespace dmlc
+
+#include "./serializer.h"
+
+namespace dmlc {
+// implementations of inline functions
+template<typename T>
+inline void Stream::Write(const T &data) {
+  serializer::Handler<T>::Write(this, data);
+}
+template<typename T>
+inline bool Stream::Read(T *out_data) {
+  return serializer::Handler<T>::Read(this, out_data);
+}
+
+template<typename T>
+inline void Stream::WriteArray(const T* data, size_t num_elems) {
+  for (size_t i = 0; i < num_elems; ++i) {
+    this->Write<T>(data[i]);
+  }
+}
+
+template<typename T>
+inline bool Stream::ReadArray(T* data, size_t num_elems) {
+  for (size_t i = 0; i < num_elems; ++i) {
+    if (!this->Read<T>(data + i)) return false;
+  }
+  return true;
+}
+
+#ifndef _LIBCPP_SGX_NO_IOSTREAMS
+// implementations for ostream
+inline void ostream::OutBuf::set_stream(Stream *stream) {
+  if (stream_ != NULL) this->pubsync();
+  this->stream_ = stream;
+  this->setp(&buffer_[0], &buffer_[0] + buffer_.size() - 1);
+}
+inline int ostream::OutBuf::sync(void) {
+  if (stream_ == NULL) return -1;
+  std::ptrdiff_t n = pptr() - pbase();
+  stream_->Write(pbase(), n);
+  this->pbump(-static_cast<int>(n));
+  bytes_out_ += n;
+  return 0;
+}
+inline int ostream::OutBuf::overflow(int c) {
+  *(this->pptr()) = c;
+  std::ptrdiff_t n = pptr() - pbase();
+  this->pbump(-static_cast<int>(n));
+  if (c == EOF) {
+    stream_->Write(pbase(), n);
+    bytes_out_ += n;
+  } else {
+    stream_->Write(pbase(), n + 1);
+    bytes_out_ += n + 1;
+  }
+  return c;
+}
+
+// implementations for istream
+inline void istream::InBuf::set_stream(Stream *stream) {
+  stream_ = stream;
+  this->setg(&buffer_[0], &buffer_[0], &buffer_[0]);
+}
+inline int istream::InBuf::underflow() {
+  char *bhead = &buffer_[0];
+  if (this->gptr() == this->egptr()) {
+    size_t sz = stream_->Read(bhead, buffer_.size());
+    this->setg(bhead, bhead, bhead + sz);
+    bytes_read_ += sz;
+  }
+  if (this->gptr() == this->egptr()) {
+    return traits_type::eof();
+  } else {
+    return traits_type::to_int_type(*gptr());
+  }
+}
+#endif
+
+namespace io {
+/*! \brief common data structure for URI */
+struct URI {
+  /*! \brief protocol */
+  std::string protocol;
+  /*!
+   * \brief host name, namenode for HDFS, bucket name for s3
+   */
+  std::string host;
+  /*! \brief name of the path */
+  std::string name;
+  /*! \brief enable default constructor */
+  URI(void) {}
+  /*!
+   * \brief construct from URI string
+   */
+  explicit URI(const char *uri) {
+    const char *p = std::strstr(uri, "://");
+    if (p == NULL) {
+      name = uri;
+    } else {
+      protocol = std::string(uri, p - uri + 3);
+      uri = p + 3;
+      p = std::strchr(uri, '/');
+      if (p == NULL) {
+        host = uri; name = '/';
+      } else {
+        host = std::string(uri, p - uri);
+        name = p;
+      }
+    }
+  }
+  /*! \brief string representation */
+  inline std::string str(void) const {
+    return protocol + host + name;
+  }
+};
+
+/*! \brief type of file */
+enum FileType {
+  /*! \brief the file is file */
+  kFile,
+  /*! \brief the file is directory */
+  kDirectory
+};
+
+/*! \brief use to store file information */
+struct FileInfo {
+  /*! \brief full path to the file */
+  URI path;
+  /*! \brief the size of the file */
+  size_t size;
+  /*! \brief the type of the file */
+  FileType type;
+  /*! \brief default constructor */
+  FileInfo() : size(0), type(kFile) {}
+};
+
+/*! \brief file system system interface */
+class FileSystem {
+ public:
+  /*!
+   * \brief get singleton of filesystem instance according to URI
+   * \param path can be s3://..., hdfs://..., file://...,
+   *            empty string(will return local)
+   * \return a corresponding filesystem, report error if
+   *         we cannot find a matching system
+   */
+  static FileSystem *GetInstance(const URI &path);
+  /*! \brief virtual destructor */
+  virtual ~FileSystem() {}
+  /*!
+   * \brief get information about a path
+   * \param path the path to the file
+   * \return the information about the file
+   */
+  virtual FileInfo GetPathInfo(const URI &path) = 0;
+  /*!
+   * \brief list files in a directory
+   * \param path to the file
+   * \param out_list the output information about the files
+   */
+  virtual void ListDirectory(const URI &path, std::vector<FileInfo> *out_list) = 0;
+  /*!
+   * \brief list files in a directory recursively using ListDirectory
+   * \param path to the file
+   * \param out_list the output information about the files
+   */
+  virtual void ListDirectoryRecursive(const URI &path,
+                                      std::vector<FileInfo> *out_list);
+  /*!
+   * \brief open a stream
+   * \param path path to file
+   * \param flag can be "w", "r", "a
+   * \param allow_null whether NULL can be returned, or directly report error
+   * \return the created stream, can be NULL when allow_null == true and file do not exist
+   */
+  virtual Stream *Open(const URI &path,
+                       const char* const flag,
+                       bool allow_null = false) = 0;
+  /*!
+   * \brief open a seekable stream for read
+   * \param path the path to the file
+   * \param allow_null whether NULL can be returned, or directly report error
+   * \return the created stream, can be NULL when allow_null == true and file do not exist
+   */
+  virtual SeekStream *OpenForRead(const URI &path,
+                                  bool allow_null = false) = 0;
+};
+
+}  // namespace io
+}  // namespace dmlc
+#endif  // DMLC_IO_H_
diff --git a/darknet_drp_ros/include/dmlc/json.h b/darknet_drp_ros/include/dmlc/json.h
new file mode 100644
index 0000000..fcc20bd
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/json.h
@@ -0,0 +1,983 @@
+/*!
+ * Copyright (c) 2015 by Contributors
+ * \file json.h
+ * \brief Lightweight JSON Reader/Writer that read save into C++ data structs.
+ *  This includes STL composites and structures.
+ */
+#ifndef DMLC_JSON_H_
+#define DMLC_JSON_H_
+
+// This code requires C++11 to compile
+#include <vector>
+#ifndef _LIBCPP_SGX_NO_IOSTREAMS
+#include <iostream>
+#include <sstream>
+#endif
+#include <cctype>
+#include <string>
+#include <algorithm>
+#include <map>
+#include <list>
+#include <utility>
+
+#include "./base.h"
+#include "./logging.h"
+#include "./type_traits.h"
+
+#if DMLC_USE_CXX11
+#include <typeindex>
+#include <typeinfo>
+#include <unordered_map>
+#if DMLC_STRICT_CXX11
+#if DMLC_ENABLE_RTTI
+#include "./any.h"
+#endif  // DMLC_ENABLE_RTTI
+#endif  // DMLC_STRICT_CXX11
+#endif  // DMLC_USE_CXX11
+
+namespace dmlc {
+/*!
+ * \brief Lightweight JSON Reader to read any STL compositions and structs.
+ *  The user need to know the schema of the
+ *
+ */
+class JSONReader {
+ public:
+  /*!
+   * \brief Constructor.
+   * \param is the input source.
+   */
+#ifndef _LIBCPP_SGX_NO_IOSTREAMS
+  explicit JSONReader(std::istream *is)
+#else
+  explicit JSONReader(std::string *is)
+#endif
+      : is_(is),
+        line_count_r_(0),
+        line_count_n_(0) {}
+  /*!
+   * \brief Parse next JSON string.
+   * \param out_str the output string.
+   * \throw dmlc::Error when next token is not string
+   */
+  inline void ReadString(std::string *out_str);
+  /*!
+   * \brief Read Number.
+   * \param out_value output value;
+   * \throw dmlc::Error when next token is not number of ValueType.
+   * \tparam ValueType type of the number
+   */
+  template<typename ValueType>
+  inline void ReadNumber(ValueType *out_value);
+  /*!
+   * \brief Begin parsing an object.
+   * \code
+   *  std::string key;
+   *  // value can be any type that is json serializable.
+   *  std::string value;
+   *  reader->BeginObject();
+   *  while (reader->NextObjectItem(&key)) {
+   *    // do somthing to key value
+   *    reader->Read(&value);
+   *  }
+   * \endcode
+   */
+  inline void BeginObject();
+  /*!
+   * \brief Begin parsing an array.
+   * \code
+   *  // value can be any type that is json serializable.
+   *  std::string value;
+   *  reader->BeginArray();
+   *  while (reader->NextArrayItem()) {
+   *    reader->Read(&value);
+   *    // do somthing to value
+   *  }
+   * \endcode
+   */
+  inline void BeginArray();
+  /*!
+   * \brief Try to move to next object item.
+   *  If this call is successful, user can proceed to call
+   *  reader->Read to read in the value.
+   * \param out_key the key to the next object.
+   * \return true if the read is successful, false if we are at end of the object.
+   */
+  inline bool NextObjectItem(std::string *out_key);
+  /*!
+   * \brief Try to read the next element in the array.
+   *  If this call is successful, user can proceed to call
+   *  reader->Read to read in the value.
+   * \return true if the read is successful, false if we are at end of the array.
+   */
+  inline bool NextArrayItem();
+  /*!
+   * \brief Read next ValueType.
+   * \param out_value any STL or json readable type to be read
+   * \throw dmlc::Error when the read of ValueType is not successful.
+   * \tparam ValueType the data type to be read.
+   */
+  template<typename ValueType>
+  inline void Read(ValueType *out_value);
+
+  /*! \return current line count */
+  inline std::string line_info() const {
+#ifndef _LIBCPP_SGX_NO_IOSTREAMS
+    char temp[64];
+    std::ostringstream os;
+    os << " Line " << std::max(line_count_r_, line_count_n_);
+    is_->getline(temp, 64);
+    os << ", around ^`" << temp << "`";
+    return os.str();
+#else
+    std::string info = " Line ";
+    info += std::to_string(std::max(line_count_r_, line_count_n_));
+
+    // string getline
+    size_t end_pos = is_->find('\n');
+    end_pos = std::min((size_t)64,
+        end_pos == std::string::npos ? is_->size() : end_pos);
+    std::string line = is_->substr(0, end_pos);
+    is_->erase(0, line.size() + 1);  // +1 for \n
+
+    info += ", around ^`" + line + "`";
+    return info;
+#endif
+  }
+
+ private:
+#ifndef _LIBCPP_SGX_NO_IOSTREAMS
+  /*! \brief internal reader stream */
+  std::istream *is_;
+#else
+  /*! \brief internal reader string */
+  std::string *is_;
+#endif
+  /*! \brief "\\r" counter */
+  size_t line_count_r_;
+  /*! \brief "\\n" counter */
+  size_t line_count_n_;
+  /*!
+   * \brief record how many element processed in
+   *  current array/object scope.
+   */
+  std::vector<size_t> scope_counter_;
+  /*!
+   * \brief Read next nonspace character.
+   * \return the next nonspace character.
+   */
+  inline int NextNonSpace();
+  /*!
+   * \brief Read just before next nonspace but not read that.
+   * \return the next nonspace character.
+   */
+  inline int PeekNextNonSpace();
+  /*!
+   * \brief Takes the next char from the input source.
+   * \return the next character.
+   */
+  inline int NextChar();
+  /*!
+   * \brief Returns the next char from the input source.
+   * \return the next character.
+   */
+  inline int PeekNextChar();
+};
+
+/*!
+ * \brief Lightweight json to write any STL compositions.
+ */
+class JSONWriter {
+ public:
+  /*!
+   * \brief Constructor.
+   * \param os the output reciever.
+   */
+#ifndef _LIBCPP_SGX_NO_IOSTREAMS
+  explicit JSONWriter(std::ostream *os)
+#else
+  explicit JSONWriter(std::string *os)
+#endif
+      : os_(os) {}
+  /*!
+   * \brief Write a string that do not contain escape characters.
+   * \param s the string to be written.
+   */
+  inline void WriteNoEscape(const std::string &s);
+  /*!
+   * \brief Write a string that can contain escape characters.
+   * \param s the string to be written.
+   */
+  inline void WriteString(const std::string &s);
+  /*!
+   * \brief Write a string that can contain escape characters.
+   * \param v the value to be written.
+   * \tparam ValueType The value type to be written.
+   */
+  template<typename ValueType>
+  inline void WriteNumber(const ValueType &v);
+  /*!
+   * \brief Start beginning of array.
+   * \param multi_line whether to start an multi_line array.
+   * \code
+   *  writer->BeginArray();
+   *  for (auto& v : vdata) {
+   *    writer->WriteArrayItem(v);
+   *  }
+   *  writer->EndArray();
+   * \endcode
+   */
+  inline void BeginArray(bool multi_line = true);
+  /*! \brief Finish writing an array. */
+  inline void EndArray();
+  /*!
+   * \brief Start beginning of array.
+   * \param multi_line whether to start an multi_line array.
+   * \code
+   *  writer->BeginObject();
+   *  for (auto& kv : vmap) {
+   *    writer->WriteObjectKeyValue(kv.first, kv.second);
+   *  }
+   *  writer->EndObject();
+   * \endcode
+   */
+  inline void BeginObject(bool multi_line = true);
+  /*! \brief Finish writing object. */
+  inline void EndObject();
+  /*!
+   * \brief Write key value pair in the object.
+   * \param key the key of the object.
+   * \param value the value of to be written.
+   * \tparam ValueType The value type to be written.
+   */
+  template<typename ValueType>
+  inline void WriteObjectKeyValue(const std::string &key,
+                                  const ValueType &value);
+  /*!
+   * \brief Write seperator of array, before writing next element.
+   * User can proceed to call writer->Write to write next item
+   */
+  inline void WriteArraySeperator();
+  /*!
+   * \brief Write value into array.
+   * \param value The value of to be written.
+   * \tparam ValueType The value type to be written.
+   */
+  template<typename ValueType>
+  inline void WriteArrayItem(const ValueType &value);
+  /*!
+   * \brief Write value to json.
+   * \param value any STL or json readable that can be written.
+   * \tparam ValueType the data type to be write.
+   */
+  template<typename ValueType>
+  inline void Write(const ValueType &value);
+
+ private:
+#ifndef _LIBCPP_SGX_NO_IOSTREAMS
+  /*! \brief Output stream */
+  std::ostream *os_;
+#else
+  std::string *os_;
+#endif
+  /*!
+   * \brief record how many element processed in
+   *  current array/object scope.
+   */
+  std::vector<size_t> scope_counter_;
+  /*! \brief Record whether current is a multiline scope */
+  std::vector<bool> scope_multi_line_;
+  /*!
+   * \brief Write seperating space and newlines
+   */
+  inline void WriteSeperator();
+};
+
+/*!
+ * \brief Helper class to read JSON into a class or struct object.
+ * \code
+ *  struct Param {
+ *    std::string name;
+ *    int value;
+ *    // define load function from JSON
+ *    inline void Load(dmlc::JSONReader *reader) {
+ *      dmlc::JSONStructReadHelper helper;
+ *      helper.DeclareField("name", &name);
+ *      helper.DeclareField("value", &value);
+ *      helper.ReadAllFields(reader);
+ *    }
+ *  };
+ * \endcode
+ */
+class JSONObjectReadHelper {
+ public:
+  /*!
+   * \brief Declare field of type T
+   * \param key the key of the of field.
+   * \param addr address of the data type.
+   * \tparam T the data type to be read, must be STL composition of JSON serializable.
+   */
+  template<typename T>
+  inline void DeclareField(const std::string &key, T *addr) {
+    DeclareFieldInternal(key, addr, false);
+  }
+  /*!
+   * \brief Declare optional field of type T
+   * \param key the key of the of field.
+   * \param addr address of the data type.
+   * \tparam T the data type to be read, must be STL composition of JSON serializable.
+   */
+  template<typename T>
+  inline void DeclareOptionalField(const std::string &key, T *addr) {
+    DeclareFieldInternal(key, addr, true);
+  }
+  /*!
+   * \brief Read in all the declared fields.
+   * \param reader the JSONReader to read the json.
+   */
+  inline void ReadAllFields(JSONReader *reader);
+
+ private:
+  /*!
+   * \brief Internal function to declare field.
+   * \param key the key of the of field.
+   * \param addr address of the data type.
+   * \param optional if set to true, no error will be reported if the key is not presented.
+   * \tparam T the data type to be read, must be STL composition of JSON serializable.
+   */
+  template<typename T>
+  inline void DeclareFieldInternal(const std::string &key, T *addr, bool optional);
+  /*!
+   * \brief The internal reader function.
+   * \param reader The reader to read.
+   * \param addr The memory address to read.
+   */
+  template<typename T>
+  inline static void ReaderFunction(JSONReader *reader, void *addr);
+  /*! \brief callback type to reader function */
+  typedef void (*ReadFunction)(JSONReader *reader, void *addr);
+  /*! \brief internal data entry */
+  struct Entry {
+    /*! \brief the reader function */
+    ReadFunction func;
+    /*! \brief the address to read */
+    void *addr;
+    /*! \brief whether it is optional */
+    bool optional;
+  };
+  /*! \brief the internal map of reader callbacks */
+  std::map<std::string, Entry> map_;
+};
+
+#define DMLC_JSON_ENABLE_ANY_VAR_DEF(KeyName)                  \
+  static DMLC_ATTRIBUTE_UNUSED ::dmlc::json::AnyJSONManager&   \
+  __make_AnyJSONType ## _ ## KeyName ## __
+
+/*!
+ * \def DMLC_JSON_ENABLE_ANY
+ * \brief Macro to enable save/load JSON of dmlc:: whose actual type is Type.
+ * Any type will be saved as json array [KeyName, content]
+ *
+ * \param Type The type to be registered.
+ * \param KeyName The Type key assigned to the type, must be same during load.
+ */
+#define DMLC_JSON_ENABLE_ANY(Type, KeyName)                             \
+  DMLC_STR_CONCAT(DMLC_JSON_ENABLE_ANY_VAR_DEF(KeyName), __COUNTER__) = \
+    ::dmlc::json::AnyJSONManager::Global()->EnableType<Type>(#KeyName) \
+
+//! \cond Doxygen_Suppress
+namespace json {
+
+/*!
+ * \brief generic serialization handler
+ * \tparam T the type to be serialized
+ */
+template<typename T>
+struct Handler;
+
+template<typename ValueType>
+struct NumericHandler {
+  inline static void Write(JSONWriter *writer, const ValueType &value) {
+    writer->WriteNumber<ValueType>(value);
+  }
+  inline static void Read(JSONReader *reader, ValueType *value) {
+    reader->ReadNumber<ValueType>(value);
+  }
+};
+
+template<typename ContainerType>
+struct ArrayHandler {
+  inline static void Write(JSONWriter *writer, const ContainerType &array) {
+    typedef typename ContainerType::value_type ElemType;
+    writer->BeginArray(array.size() > 10 || !dmlc::is_pod<ElemType>::value);
+    for (typename ContainerType::const_iterator it = array.begin();
+         it != array.end(); ++it) {
+      writer->WriteArrayItem(*it);
+    }
+    writer->EndArray();
+  }
+  inline static void Read(JSONReader *reader, ContainerType *array) {
+    typedef typename ContainerType::value_type ElemType;
+    array->clear();
+    reader->BeginArray();
+    while (reader->NextArrayItem()) {
+      ElemType value;
+      Handler<ElemType>::Read(reader, &value);
+      array->insert(array->end(), value);
+    }
+  }
+};
+
+template<typename ContainerType>
+struct MapHandler{
+  inline static void Write(JSONWriter *writer, const ContainerType &map) {
+    writer->BeginObject(map.size() > 1);
+    for (typename ContainerType::const_iterator it = map.begin(); it != map.end(); ++it) {
+      writer->WriteObjectKeyValue(it->first, it->second);
+    }
+    writer->EndObject();
+  }
+  inline static void Read(JSONReader *reader, ContainerType *map) {
+    typedef typename ContainerType::mapped_type ElemType;
+    map->clear();
+    reader->BeginObject();
+    std::string key;
+    while (reader->NextObjectItem(&key)) {
+      ElemType value;
+      reader->Read(&value);
+      (*map)[key] = value;
+    }
+  }
+};
+
+template<typename T>
+struct CommonJSONSerializer {
+  inline static void Write(JSONWriter *writer, const T &value) {
+    value.Save(writer);
+  }
+  inline static void Read(JSONReader *reader, T *value) {
+    value->Load(reader);
+  }
+};
+
+template<>
+struct Handler<std::string> {
+  inline static void Write(JSONWriter *writer, const std::string &value) {
+    writer->WriteString(value);
+  }
+  inline static void Read(JSONReader *reader, std::string *str) {
+    reader->ReadString(str);
+  }
+};
+
+template<typename T>
+struct Handler<std::vector<T> > : public ArrayHandler<std::vector<T> > {
+};
+
+template<typename K, typename V>
+struct Handler<std::pair<K, V> > {
+  inline static void Write(JSONWriter *writer, const std::pair<K, V> &kv) {
+    writer->BeginArray();
+    writer->WriteArrayItem(kv.first);
+    writer->WriteArrayItem(kv.second);
+    writer->EndArray();
+  }
+  inline static void Read(JSONReader *reader, std::pair<K, V> *kv) {
+    reader->BeginArray();
+    CHECK(reader->NextArrayItem())
+        << "Expect array of length 2";
+    Handler<K>::Read(reader, &(kv->first));
+    CHECK(reader->NextArrayItem())
+        << "Expect array of length 2";
+    Handler<V>::Read(reader, &(kv->second));
+    CHECK(!reader->NextArrayItem())
+        << "Expect array of length 2";
+  }
+};
+
+template<typename T>
+struct Handler<std::list<T> > : public ArrayHandler<std::list<T> > {
+};
+
+template<typename V>
+struct Handler<std::map<std::string, V> > : public MapHandler<std::map<std::string, V> > {
+};
+
+#if DMLC_USE_CXX11
+template<typename V>
+struct Handler<std::unordered_map<std::string, V> >
+    : public MapHandler<std::unordered_map<std::string, V> > {
+};
+#endif  // DMLC_USE_CXX11
+
+template<typename T>
+struct Handler {
+  inline static void Write(JSONWriter *writer, const T &data) {
+    typedef typename dmlc::IfThenElseType<dmlc::is_arithmetic<T>::value,
+                                          NumericHandler<T>,
+                                          CommonJSONSerializer<T> >::Type THandler;
+    THandler::Write(writer, data);
+  }
+  inline static void Read(JSONReader *reader, T *data) {
+    typedef typename dmlc::IfThenElseType<dmlc::is_arithmetic<T>::value,
+                                          NumericHandler<T>,
+                                          CommonJSONSerializer<T> >::Type THandler;
+    THandler::Read(reader, data);
+  }
+};
+
+#if DMLC_STRICT_CXX11
+#if DMLC_ENABLE_RTTI
+// Manager to store json serialization strategy.
+class AnyJSONManager {
+ public:
+  template<typename T>
+  inline AnyJSONManager& EnableType(const std::string& type_name) {  // NOLINT(*)
+    std::type_index tp = std::type_index(typeid(T));
+    if (type_name_.count(tp) != 0) {
+      CHECK(type_name_.at(tp) == type_name)
+          << "Type has already been registered as another typename " << type_name_.at(tp);
+      return *this;
+    }
+    CHECK(type_map_.count(type_name) == 0)
+        << "Type name " << type_name << " already registered in registry";
+    Entry e;
+    e.read = ReadAny<T>;
+    e.write = WriteAny<T>;
+    type_name_[tp] = type_name;
+    type_map_[type_name] = e;
+    return *this;
+  }
+  // return global singleton
+  inline static AnyJSONManager* Global() {
+    static AnyJSONManager inst;
+    return &inst;
+  }
+
+ private:
+  AnyJSONManager() {}
+
+  template<typename T>
+  inline static void WriteAny(JSONWriter *writer, const any &data) {
+    writer->Write(dmlc::unsafe_get<T>(data));
+  }
+  template<typename T>
+  inline static void ReadAny(JSONReader *reader, any* data) {
+    T temp;
+    reader->Read(&temp);
+    *data = std::move(temp);
+  }
+  // data entry to store vtable for any type
+  struct Entry {
+    void (*read)(JSONReader* reader, any *data);
+    void (*write)(JSONWriter* reader, const any& data);
+  };
+
+  template<typename T>
+  friend struct Handler;
+
+  std::unordered_map<std::type_index, std::string> type_name_;
+  std::unordered_map<std::string, Entry> type_map_;
+};
+
+template<>
+struct Handler<any> {
+  inline static void Write(JSONWriter *writer, const any &data) {
+    std::unordered_map<std::type_index, std::string>&
+        nmap = AnyJSONManager::Global()->type_name_;
+    std::type_index id = std::type_index(data.type());
+    auto it = nmap.find(id);
+    CHECK(it != nmap.end() && it->first == id)
+        << "Type " << id.name() << " has not been registered via DMLC_JSON_ENABLE_ANY";
+    std::string type_name = it->second;
+    AnyJSONManager::Entry e = AnyJSONManager::Global()->type_map_.at(type_name);
+    writer->BeginArray(false);
+    writer->WriteArrayItem(type_name);
+    writer->WriteArraySeperator();
+    e.write(writer, data);
+    writer->EndArray();
+  }
+  inline static void Read(JSONReader *reader, any *data) {
+    std::string type_name;
+    reader->BeginArray();
+    CHECK(reader->NextArrayItem()) << "invalid any json format";
+    Handler<std::string>::Read(reader, &type_name);
+    std::unordered_map<std::string, AnyJSONManager::Entry>&
+        tmap = AnyJSONManager::Global()->type_map_;
+    auto it = tmap.find(type_name);
+    CHECK(it != tmap.end() && it->first == type_name)
+        << "Typename " << type_name << " has not been registered via DMLC_JSON_ENABLE_ANY";
+    AnyJSONManager::Entry e = it->second;
+    CHECK(reader->NextArrayItem()) << "invalid any json format";
+    e.read(reader, data);
+    CHECK(!reader->NextArrayItem()) << "invalid any json format";
+  }
+};
+#endif  // DMLC_ENABLE_RTTI
+#endif  // DMLC_STRICT_CXX11
+
+}  // namespace json
+
+// implementations of JSONReader/Writer
+inline int JSONReader::NextChar() {
+#ifndef _LIBCPP_SGX_NO_IOSTREAMS
+  return is_->get();
+#else
+  int ch = is_->at(0);
+  is_->erase(0, 1);
+  return ch;
+#endif
+}
+
+inline int JSONReader::PeekNextChar() {
+#ifndef _LIBCPP_SGX_NO_IOSTREAMS
+  return is_->peek();
+#else
+  return is_->at(0);
+#endif
+}
+
+inline int JSONReader::NextNonSpace() {
+  int ch;
+  do {
+    ch = NextChar();
+    if (ch == '\n') ++line_count_n_;
+    if (ch == '\r') ++line_count_r_;
+  } while (isspace(ch));
+  return ch;
+}
+
+inline int JSONReader::PeekNextNonSpace() {
+  int ch;
+  while (true) {
+    ch = PeekNextChar();
+    if (ch == '\n') ++line_count_n_;
+    if (ch == '\r') ++line_count_r_;
+    if (!isspace(ch)) break;
+    NextChar();
+  }
+  return ch;
+}
+
+namespace {
+  template<typename T>
+#ifndef _LIBCPP_SGX_NO_IOSTREAMS
+  void Extend(std::ostream *os, T item) {
+    *os << item;
+  }
+#else
+  void Extend(std::string *ostr, T item) {
+    *ostr += item;
+  }
+#endif
+}  // namespace
+
+inline void JSONReader::ReadString(std::string *out_str) {
+  int ch = NextNonSpace();
+  CHECK_EQ(ch, '\"')
+      << "Error at" << line_info()
+      << ", Expect \'\"\' but get \'" << static_cast<char>(ch) << '\'';
+#ifndef _LIBCPP_SGX_NO_IOSTREAMS
+  std::ostringstream output;
+#else
+  std::string output = "";
+#endif
+  while (true) {
+    ch = NextChar();
+    if (ch == '\\') {
+      char sch = static_cast<char>(NextChar());
+      switch (sch) {
+        case 'r': Extend(&output, "\r"); break;
+        case 'n': Extend(&output, "\n"); break;
+        case '\\': Extend(&output, "\\"); break;
+        case 't': Extend(&output, "\t"); break;
+        case '\"': Extend(&output, "\""); break;
+        default: LOG(FATAL) << "unknown string escape \\" << sch;
+      }
+    } else {
+      if (ch == '\"') break;
+      Extend(&output, static_cast<char>(ch));
+    }
+    if (ch == EOF || ch == '\r' || ch == '\n') {
+      LOG(FATAL)
+          << "Error at" << line_info()
+          << ", Expect \'\"\' but reach end of line ";
+    }
+  }
+#ifndef _LIBCPP_SGX_NO_IOSTREAMS
+  *out_str = output.str();
+#else
+  *out_str = output;
+#endif
+}
+
+template<typename ValueType>
+inline void JSONReader::ReadNumber(ValueType *out_value) {
+#ifndef _LIBCPP_SGX_NO_IOSTREAMS
+  *is_ >> *out_value;
+  CHECK(!is_->fail())
+      << "Error at" << line_info()
+      << ", Expect number";
+#else
+  char* endptr;
+  const char* icstr = is_->c_str();
+  unsigned number = strtol(icstr, &endptr, 10);
+  is_->erase(0, endptr - icstr);
+  *out_value = static_cast<ValueType>(number);
+#endif
+}
+
+inline void JSONReader::BeginObject() {
+  int ch = NextNonSpace();
+  CHECK_EQ(ch, '{')
+      << "Error at" << line_info()
+      << ", Expect \'{\' but get \'" << static_cast<char>(ch) << '\'';
+  scope_counter_.push_back(0);
+}
+
+inline void JSONReader::BeginArray() {
+  int ch = NextNonSpace();
+  CHECK_EQ(ch, '[')
+      << "Error at" << line_info()
+      << ", Expect \'[\' but get \'" << static_cast<char>(ch) << '\'';
+  scope_counter_.push_back(0);
+}
+
+inline bool JSONReader::NextObjectItem(std::string *out_key) {
+  bool next = true;
+  if (scope_counter_.back() != 0) {
+    int ch = NextNonSpace();
+    if (ch == EOF) {
+      next = false;
+    } else if (ch == '}') {
+      next = false;
+    } else {
+      CHECK_EQ(ch, ',')
+          << "Error at" << line_info()
+          << ", JSON object expect \'}\' or \',\' \'" << static_cast<char>(ch) << '\'';
+    }
+  } else {
+    int ch = PeekNextNonSpace();
+    if (ch == '}') {
+      NextChar();
+      next = false;
+    }
+  }
+  if (!next) {
+    scope_counter_.pop_back();
+    return false;
+  } else {
+    scope_counter_.back() += 1;
+    ReadString(out_key);
+    int ch = NextNonSpace();
+    CHECK_EQ(ch, ':')
+        << "Error at" << line_info()
+        << ", Expect \':\' but get \'" << static_cast<char>(ch) << '\'';
+    return true;
+  }
+}
+
+inline bool JSONReader::NextArrayItem() {
+  bool next = true;
+  if (scope_counter_.back() != 0) {
+    int ch = NextNonSpace();
+    if (ch == EOF) {
+      next = false;
+    } else if (ch == ']') {
+      next = false;
+    } else {
+      CHECK_EQ(ch, ',')
+          << "Error at" << line_info()
+          << ", JSON array expect \']\' or \',\'. Get \'" << static_cast<char>(ch) << "\' instead";
+    }
+  } else {
+    int ch = PeekNextNonSpace();
+    if (ch == ']') {
+      NextChar();
+      next = false;
+    }
+  }
+  if (!next) {
+    scope_counter_.pop_back();
+    return false;
+  } else {
+    scope_counter_.back() += 1;
+    return true;
+  }
+}
+
+template<typename ValueType>
+inline void JSONReader::Read(ValueType *out_value) {
+  json::Handler<ValueType>::Read(this, out_value);
+}
+
+inline void JSONWriter::WriteNoEscape(const std::string &s) {
+  Extend(os_, '\"');
+  Extend(os_, s);
+  Extend(os_, '\"');
+}
+
+inline void JSONWriter::WriteString(const std::string &s) {
+  Extend(os_, '\"');
+  for (size_t i = 0; i < s.length(); ++i) {
+    char ch = s[i];
+    switch (ch) {
+      case '\r': Extend(os_, "\\r"); break;
+      case '\n': Extend(os_, "\\n"); break;
+      case '\\': Extend(os_, "\\\\"); break;
+      case '\t': Extend(os_, "\\t"); break;
+      case '\"': Extend(os_, "\\\""); break;
+      default: Extend(os_, ch);
+    }
+  }
+  Extend(os_, '\"');
+}
+
+template<typename ValueType>
+inline void JSONWriter::WriteNumber(const ValueType &v) {
+#ifndef _LIBCPP_SGX_NO_IOSTREAMS
+  Extend(os_, v);
+#else
+  Extend(os_, std::to_string(v));
+#endif
+}
+
+inline void JSONWriter::BeginArray(bool multi_line) {
+  Extend(os_, '[');
+  scope_multi_line_.push_back(multi_line);
+  scope_counter_.push_back(0);
+}
+
+inline void JSONWriter::EndArray() {
+  CHECK_NE(scope_multi_line_.size(), 0U);
+  CHECK_NE(scope_counter_.size(), 0U);
+  bool newline = scope_multi_line_.back();
+  size_t nelem = scope_counter_.back();
+  scope_multi_line_.pop_back();
+  scope_counter_.pop_back();
+  if (newline && nelem != 0) WriteSeperator();
+  Extend(os_, ']');
+}
+
+inline void JSONWriter::BeginObject(bool multi_line) {
+  Extend(os_, '{');
+  scope_multi_line_.push_back(multi_line);
+  scope_counter_.push_back(0);
+}
+
+inline void JSONWriter::EndObject() {
+  CHECK_NE(scope_multi_line_.size(), 0U);
+  CHECK_NE(scope_counter_.size(), 0U);
+  bool newline = scope_multi_line_.back();
+  size_t nelem = scope_counter_.back();
+  scope_multi_line_.pop_back();
+  scope_counter_.pop_back();
+  if (newline && nelem != 0) WriteSeperator();
+  Extend(os_, '}');
+}
+
+template<typename ValueType>
+inline void JSONWriter::WriteObjectKeyValue(const std::string &key,
+                                            const ValueType &value) {
+  if (scope_counter_.back() > 0) {
+    Extend(os_, ", ");
+  }
+  WriteSeperator();
+  Extend(os_, '\"');
+  Extend(os_, key);
+  Extend(os_, "\": ");
+  scope_counter_.back() += 1;
+  json::Handler<ValueType>::Write(this, value);
+}
+
+inline void JSONWriter::WriteArraySeperator() {
+  if (scope_counter_.back() != 0) {
+    Extend(os_, ", ");
+  }
+  scope_counter_.back() += 1;
+  WriteSeperator();
+}
+
+template<typename ValueType>
+inline void JSONWriter::WriteArrayItem(const ValueType &value) {
+  this->WriteArraySeperator();
+  json::Handler<ValueType>::Write(this, value);
+}
+
+template<typename ValueType>
+inline void JSONWriter::Write(const ValueType &value) {
+  size_t nscope = scope_multi_line_.size();
+  json::Handler<ValueType>::Write(this, value);
+  CHECK_EQ(nscope, scope_multi_line_.size())
+      << "Uneven scope, did you call EndArray/EndObject after each BeginObject/Array?";
+}
+
+inline void JSONWriter::WriteSeperator() {
+  if (scope_multi_line_.size() == 0 || scope_multi_line_.back()) {
+    Extend(os_, '\n');
+    Extend(os_, std::string(scope_multi_line_.size() * 2, ' '));
+  }
+}
+
+inline void JSONObjectReadHelper::ReadAllFields(JSONReader *reader) {
+  reader->BeginObject();
+  std::map<std::string, int> visited;
+  std::string key;
+  while (reader->NextObjectItem(&key)) {
+    if (map_.count(key) != 0) {
+      Entry e = map_[key];
+      (*e.func)(reader, e.addr);
+      visited[key] = 0;
+    } else {
+#ifndef _LIBCPP_SGX_NO_IOSTREAMS
+      std::ostringstream err;
+#else
+      std::string err("");
+#endif
+      Extend(&err, "JSONReader: Unknown field ");
+      Extend(&err, key);
+      Extend(&err, ", candidates are: \n");
+      for (std::map<std::string, Entry>::iterator
+               it = map_.begin(); it != map_.end(); ++it) {
+        Extend(&err, '\"');
+        Extend(&err, it->first);
+        Extend(&err, "\"\n");
+      }
+#ifndef _LIBCPP_SGX_NO_IOSTREAMS
+      LOG(FATAL) << err.str();
+#else
+      LOG(FATAL) << err;
+#endif
+    }
+  }
+  if (visited.size() != map_.size()) {
+    for (std::map<std::string, Entry>::iterator
+             it = map_.begin(); it != map_.end(); ++it) {
+      if (it->second.optional) continue;
+      CHECK_NE(visited.count(it->first), 0U)
+          << "JSONReader: Missing field \"" << it->first << "\"\n At "
+          << reader->line_info();
+    }
+  }
+}
+
+template<typename T>
+inline void JSONObjectReadHelper::ReaderFunction(JSONReader *reader, void *addr) {
+  json::Handler<T>::Read(reader, static_cast<T*>(addr));
+}
+
+template<typename T>
+inline void JSONObjectReadHelper::
+DeclareFieldInternal(const std::string &key, T *addr, bool optional) {
+  CHECK_EQ(map_.count(key), 0U)
+      << "Adding duplicate field " << key;
+  Entry e;
+  e.func = ReaderFunction<T>;
+  e.addr = static_cast<void*>(addr);
+  e.optional = optional;
+  map_[key] = e;
+}
+
+//! \endcond
+}  // namespace dmlc
+#endif  // DMLC_JSON_H_
diff --git a/darknet_drp_ros/include/dmlc/logging.h b/darknet_drp_ros/include/dmlc/logging.h
new file mode 100644
index 0000000..9a2a288
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/logging.h
@@ -0,0 +1,490 @@
+/*!
+ *  Copyright (c) 2015 by Contributors
+ * \file logging.h
+ * \brief defines logging macros of dmlc
+ *  allows use of GLOG, fall back to internal
+ *  implementation when disabled
+ */
+#ifndef DMLC_LOGGING_H_
+#define DMLC_LOGGING_H_
+#include <cstdio>
+#include <cstdlib>
+#include <string>
+#include <vector>
+#include <stdexcept>
+#include <memory>
+#include "./base.h"
+
+#if DMLC_LOG_STACK_TRACE
+#include <cxxabi.h>
+#include <sstream>
+#include DMLC_EXECINFO_H
+#endif
+
+namespace dmlc {
+/*!
+ * \brief exception class that will be thrown by
+ *  default logger if DMLC_LOG_FATAL_THROW == 1
+ */
+struct Error : public std::runtime_error {
+  /*!
+   * \brief constructor
+   * \param s the error message
+   */
+  explicit Error(const std::string &s) : std::runtime_error(s) {}
+};
+
+#if DMLC_LOG_STACK_TRACE
+// get stack trace logging depth from env variable.
+inline size_t LogStackTraceLevel() {
+  size_t level;
+  if (auto var = std::getenv("DMLC_LOG_STACK_TRACE_DEPTH")) {
+    if (1 == sscanf(var, "%zu", &level)) {
+      return level + 1;
+    }
+  }
+  return DMLC_LOG_STACK_TRACE_SIZE;
+}
+
+inline std::string Demangle(char const *msg_str) {
+  using std::string;
+  string msg(msg_str);
+  size_t symbol_start = string::npos;
+  size_t symbol_end = string::npos;
+  if ( ((symbol_start = msg.find("_Z")) != string::npos)
+       && (symbol_end = msg.find_first_of(" +", symbol_start)) ) {
+    string left_of_symbol(msg, 0, symbol_start);
+    string symbol(msg, symbol_start, symbol_end - symbol_start);
+    string right_of_symbol(msg, symbol_end);
+
+    int status = 0;
+    size_t length = string::npos;
+    std::unique_ptr<char, void (*)(void *__ptr)> demangled_symbol =
+        {abi::__cxa_demangle(symbol.c_str(), 0, &length, &status), &std::free};
+    if (demangled_symbol && status == 0 && length > 0) {
+      string symbol_str(demangled_symbol.get());
+      std::ostringstream os;
+      os << left_of_symbol << symbol_str << right_of_symbol;
+      return os.str();
+    }
+  }
+  return string(msg_str);
+}
+
+// By default skip the first frame because
+// that belongs to ~LogMessageFatal
+inline std::string StackTrace(
+    size_t start_frame = 1,
+    const size_t stack_size = DMLC_LOG_STACK_TRACE_SIZE) {
+  using std::string;
+  std::ostringstream stacktrace_os;
+  std::vector<void*> stack(stack_size);
+  int nframes = backtrace(stack.data(), static_cast<int>(stack_size));
+  if (start_frame < static_cast<size_t>(nframes)) {
+    stacktrace_os << "Stack trace:\n";
+  }
+  char **msgs = backtrace_symbols(stack.data(), nframes);
+  if (msgs != nullptr) {
+    for (int frameno = start_frame; frameno < nframes; ++frameno) {
+      string msg = dmlc::Demangle(msgs[frameno]);
+      stacktrace_os << "  [bt] (" << frameno - start_frame << ") " << msg << "\n";
+    }
+  }
+  free(msgs);
+  string stack_trace = stacktrace_os.str();
+  return stack_trace;
+}
+
+#else  // DMLC_LOG_STACK_TRACE is off
+
+inline size_t LogStackTraceLevel() {
+  return 0;
+}
+
+inline std::string demangle(char const* msg_str) {
+  return std::string();
+}
+
+inline std::string StackTrace(size_t start_frame = 1,
+                              const size_t stack_size = 0) {
+  return std::string("Stack trace not available when "
+  "DMLC_LOG_STACK_TRACE is disabled at compile time.");
+}
+
+#endif  // DMLC_LOG_STACK_TRACE
+}  // namespace dmlc
+
+#if DMLC_USE_GLOG
+#include <glog/logging.h>
+
+namespace dmlc {
+/*!
+ * \brief optionally redirect to google's init log
+ * \param argv0 The arguments.
+ */
+inline void InitLogging(const char* argv0) {
+  google::InitGoogleLogging(argv0);
+}
+}  // namespace dmlc
+
+#elif defined DMLC_USE_LOGGING_LIBRARY
+
+#include DMLC_USE_LOGGING_LIBRARY
+namespace dmlc {
+inline void InitLogging(const char*) {
+  // DO NOTHING
+}
+}
+
+#else
+// use a light version of glog
+#include <assert.h>
+#include <iostream>
+#include <sstream>
+#include <ctime>
+
+#if defined(_MSC_VER)
+#pragma warning(disable : 4722)
+#pragma warning(disable : 4068)
+#endif
+
+namespace dmlc {
+inline void InitLogging(const char*) {
+  // DO NOTHING
+}
+
+// get debug option from env variable.
+inline bool DebugLoggingEnabled() {
+  static int state = 0;
+  if (state == 0) {
+    if (auto var = std::getenv("DMLC_LOG_DEBUG")) {
+      if (std::string(var) == "1") {
+        state = 1;
+      } else {
+        state = -1;
+      }
+    } else {
+      // by default hide debug logging.
+      state = -1;
+    }
+  }
+  return state == 1;
+}
+
+#ifndef DMLC_GLOG_DEFINED
+
+template <typename X, typename Y>
+std::unique_ptr<std::string> LogCheckFormat(const X& x, const Y& y) {
+  std::ostringstream os;
+  os << " (" << x << " vs. " << y << ") "; /* CHECK_XX(x, y) requires x and y can be serialized to string. Use CHECK(x OP y) otherwise. NOLINT(*) */
+  // no std::make_unique until c++14
+  return std::unique_ptr<std::string>(new std::string(os.str()));
+}
+
+// This function allows us to ignore sign comparison in the right scope.
+#define DEFINE_CHECK_FUNC(name, op)                                                        \
+  template <typename X, typename Y>                                                        \
+  DMLC_ALWAYS_INLINE std::unique_ptr<std::string> LogCheck##name(const X& x, const Y& y) { \
+    if (x op y) return nullptr;                                                            \
+    return LogCheckFormat(x, y);                                                           \
+  }                                                                                        \
+  DMLC_ALWAYS_INLINE std::unique_ptr<std::string> LogCheck##name(int x, int y) {           \
+    return LogCheck##name<int, int>(x, y);                                                 \
+  }
+
+#pragma GCC diagnostic push
+#pragma GCC diagnostic ignored "-Wsign-compare"
+DEFINE_CHECK_FUNC(_LT, <)
+DEFINE_CHECK_FUNC(_GT, >)
+DEFINE_CHECK_FUNC(_LE, <=)
+DEFINE_CHECK_FUNC(_GE, >=)
+DEFINE_CHECK_FUNC(_EQ, ==)
+DEFINE_CHECK_FUNC(_NE, !=)
+#pragma GCC diagnostic pop
+
+#define CHECK_BINARY_OP(name, op, x, y)                  \
+  if (auto __dmlc__log__err = dmlc::LogCheck##name(x, y))  \
+      dmlc::LogMessageFatal(__FILE__, __LINE__).stream() \
+        << "Check failed: " << #x " " #op " " #y << *__dmlc__log__err << ": "
+
+// Always-on checking
+#define CHECK(x)                                           \
+  if (!(x))                                                \
+    dmlc::LogMessageFatal(__FILE__, __LINE__).stream()     \
+      << "Check failed: " #x << ": "
+#define CHECK_LT(x, y) CHECK_BINARY_OP(_LT, <, x, y)
+#define CHECK_GT(x, y) CHECK_BINARY_OP(_GT, >, x, y)
+#define CHECK_LE(x, y) CHECK_BINARY_OP(_LE, <=, x, y)
+#define CHECK_GE(x, y) CHECK_BINARY_OP(_GE, >=, x, y)
+#define CHECK_EQ(x, y) CHECK_BINARY_OP(_EQ, ==, x, y)
+#define CHECK_NE(x, y) CHECK_BINARY_OP(_NE, !=, x, y)
+#define CHECK_NOTNULL(x) \
+  ((x) == NULL ? dmlc::LogMessageFatal(__FILE__, __LINE__).stream() << "Check  notnull: "  #x << ' ', (x) : (x)) // NOLINT(*)
+
+// Debug-only checking.
+#if DMLC_LOG_DEBUG
+#define DCHECK(x) \
+  while (false) CHECK(x)
+#define DCHECK_LT(x, y) \
+  while (false) CHECK((x) < (y))
+#define DCHECK_GT(x, y) \
+  while (false) CHECK((x) > (y))
+#define DCHECK_LE(x, y) \
+  while (false) CHECK((x) <= (y))
+#define DCHECK_GE(x, y) \
+  while (false) CHECK((x) >= (y))
+#define DCHECK_EQ(x, y) \
+  while (false) CHECK((x) == (y))
+#define DCHECK_NE(x, y) \
+  while (false) CHECK((x) != (y))
+#else
+#define DCHECK(x) CHECK(x)
+#define DCHECK_LT(x, y) CHECK((x) < (y))
+#define DCHECK_GT(x, y) CHECK((x) > (y))
+#define DCHECK_LE(x, y) CHECK((x) <= (y))
+#define DCHECK_GE(x, y) CHECK((x) >= (y))
+#define DCHECK_EQ(x, y) CHECK((x) == (y))
+#define DCHECK_NE(x, y) CHECK((x) != (y))
+#endif  // DMLC_LOG_DEBUG
+
+#if DMLC_LOG_CUSTOMIZE
+#define LOG_INFO dmlc::CustomLogMessage(__FILE__, __LINE__)
+#else
+#define LOG_INFO dmlc::LogMessage(__FILE__, __LINE__)
+#endif
+#define LOG_ERROR LOG_INFO
+#define LOG_WARNING LOG_INFO
+#define LOG_FATAL dmlc::LogMessageFatal(__FILE__, __LINE__)
+#define LOG_QFATAL LOG_FATAL
+
+// Poor man version of VLOG
+#define VLOG(x) LOG_INFO.stream()
+
+#define LOG(severity) LOG_##severity.stream()
+#define LG LOG_INFO.stream()
+#define LOG_IF(severity, condition) \
+  !(condition) ? (void)0 : dmlc::LogMessageVoidify() & LOG(severity)
+
+#if DMLC_LOG_DEBUG
+
+#define LOG_DFATAL LOG_FATAL
+#define DFATAL FATAL
+#define DLOG(severity) LOG_IF(severity, ::dmlc::DebugLoggingEnabled())
+#define DLOG_IF(severity, condition) LOG_IF(severity, ::dmlc::DebugLoggingEnabled() && (condition))
+
+#else
+
+#define LOG_DFATAL LOG_ERROR
+#define DFATAL ERROR
+#define DLOG(severity) true ? (void)0 : dmlc::LogMessageVoidify() & LOG(severity)
+#define DLOG_IF(severity, condition) \
+  (true || !(condition)) ? (void)0 : dmlc::LogMessageVoidify() & LOG(severity)
+#endif
+
+// Poor man version of LOG_EVERY_N
+#define LOG_EVERY_N(severity, n) LOG(severity)
+
+#endif  // DMLC_GLOG_DEFINED
+
+class DateLogger {
+ public:
+  DateLogger() {
+#if defined(_MSC_VER)
+    _tzset();
+#endif
+  }
+  const char* HumanDate() {
+#if !defined(_LIBCPP_SGX_CONFIG) && DMLC_LOG_NODATE == 0
+#if defined(_MSC_VER)
+    _strtime_s(buffer_, sizeof(buffer_));
+#else
+    time_t time_value = time(NULL);
+    struct tm *pnow;
+#if !defined(_WIN32)
+    struct tm now;
+    pnow = localtime_r(&time_value, &now);
+#else
+    pnow = localtime(&time_value);  // NOLINT(*)
+#endif
+    snprintf(buffer_, sizeof(buffer_), "%02d:%02d:%02d",
+             pnow->tm_hour, pnow->tm_min, pnow->tm_sec);
+#endif
+    return buffer_;
+#else
+    return "";
+#endif  // _LIBCPP_SGX_CONFIG
+  }
+
+ private:
+  char buffer_[9];
+};
+
+#ifndef _LIBCPP_SGX_NO_IOSTREAMS
+class LogMessage {
+ public:
+  LogMessage(const char* file, int line)
+      :
+#ifdef __ANDROID__
+        log_stream_(std::cout)
+#else
+        log_stream_(std::cerr)
+#endif
+  {
+    log_stream_ << "[" << pretty_date_.HumanDate() << "] " << file << ":"
+                << line << ": ";
+  }
+  ~LogMessage() { log_stream_ << '\n'; }
+  std::ostream& stream() { return log_stream_; }
+
+ protected:
+  std::ostream& log_stream_;
+
+ private:
+  DateLogger pretty_date_;
+  LogMessage(const LogMessage&);
+  void operator=(const LogMessage&);
+};
+
+// customized logger that can allow user to define where to log the message.
+class CustomLogMessage {
+ public:
+  CustomLogMessage(const char* file, int line) {
+    log_stream_ << "[" << DateLogger().HumanDate() << "] " << file << ":"
+                << line << ": ";
+  }
+  ~CustomLogMessage() {
+    Log(log_stream_.str());
+  }
+  std::ostream& stream() { return log_stream_; }
+  /*!
+   * \brief customized logging of the message.
+   * This function won't be implemented by libdmlc
+   * \param msg The message to be logged.
+   */
+  static void Log(const std::string& msg);
+
+ private:
+  std::ostringstream log_stream_;
+};
+#else
+class DummyOStream {
+ public:
+  template <typename T>
+  DummyOStream& operator<<(T _) { return *this; }
+  inline std::string str() { return ""; }
+};
+class LogMessage {
+ public:
+  LogMessage(const char* file, int line) : log_stream_() {}
+  DummyOStream& stream() { return log_stream_; }
+
+ protected:
+  DummyOStream log_stream_;
+
+ private:
+  LogMessage(const LogMessage&);
+  void operator=(const LogMessage&);
+};
+#endif
+
+
+#if defined(_LIBCPP_SGX_NO_IOSTREAMS)
+class LogMessageFatal : public LogMessage {
+ public:
+  LogMessageFatal(const char* file, int line) : LogMessage(file, line) {}
+  ~LogMessageFatal() {
+    abort();
+  }
+ private:
+  LogMessageFatal(const LogMessageFatal&);
+  void operator=(const LogMessageFatal&);
+};
+#elif DMLC_LOG_FATAL_THROW == 0
+class LogMessageFatal : public LogMessage {
+ public:
+  LogMessageFatal(const char* file, int line) : LogMessage(file, line) {}
+  ~LogMessageFatal() {
+    log_stream_ << "\n" << StackTrace(1, LogStackTraceLevel()) << "\n";
+    abort();
+  }
+
+ private:
+  LogMessageFatal(const LogMessageFatal&);
+  void operator=(const LogMessageFatal&);
+};
+#else
+class LogMessageFatal {
+ public:
+  LogMessageFatal(const char *file, int line) {
+    GetEntry().Init(file, line);
+  }
+  std::ostringstream &stream() { return GetEntry().log_stream; }
+  DMLC_NO_INLINE ~LogMessageFatal() DMLC_THROW_EXCEPTION {
+#if DMLC_LOG_STACK_TRACE
+    GetEntry().log_stream << "\n"
+                          << StackTrace(1, LogStackTraceLevel())
+                          << "\n";
+#endif
+    throw GetEntry().Finalize();
+  }
+
+ private:
+  struct Entry {
+    std::ostringstream log_stream;
+    DMLC_NO_INLINE void Init(const char *file, int line) {
+      DateLogger date;
+      log_stream.str("");
+      log_stream.clear();
+      log_stream << "[" << date.HumanDate() << "] " << file << ":" << line
+                 << ": ";
+    }
+    dmlc::Error Finalize() {
+#if DMLC_LOG_BEFORE_THROW
+      LOG(ERROR) << log_stream.str();
+#endif
+      return dmlc::Error(log_stream.str());
+    }
+    // Due to a bug in MinGW, objects with non-trivial destructor cannot be thread-local.
+    // See https://sourceforge.net/p/mingw-w64/bugs/527/
+    // Hence, don't use thread-local for the log stream if the compiler is MinGW.
+#if !(defined(__MINGW32__) || defined(__MINGW64__))
+    DMLC_NO_INLINE static Entry& ThreadLocal() {
+      static thread_local Entry result;
+      return result;
+    }
+#endif
+  };
+  LogMessageFatal(const LogMessageFatal &);
+  void operator=(const LogMessageFatal &);
+
+#if defined(__MINGW32__) || defined(__MINGW64__)
+  DMLC_NO_INLINE Entry& GetEntry() {
+    return entry_;
+  }
+
+  Entry entry_;
+#else
+  DMLC_NO_INLINE Entry& GetEntry() {
+    return Entry::ThreadLocal();
+  }
+#endif
+};
+#endif
+
+// This class is used to explicitly ignore values in the conditional
+// logging macros.  This avoids compiler warnings like "value computed
+// is not used" and "statement has no effect".
+class LogMessageVoidify {
+ public:
+  LogMessageVoidify() {}
+  // This has to be an operator with a precedence lower than << but
+  // higher than "?:". See its usage.
+#if !defined(_LIBCPP_SGX_NO_IOSTREAMS)
+  void operator&(std::ostream&) {}
+#endif
+};
+
+}  // namespace dmlc
+
+#endif
+#endif  // DMLC_LOGGING_H_
diff --git a/darknet_drp_ros/include/dmlc/lua.h b/darknet_drp_ros/include/dmlc/lua.h
new file mode 100644
index 0000000..13aa7b7
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/lua.h
@@ -0,0 +1,739 @@
+/*!
+ *  Copyright (c) 2016 by Contributors
+ * \file lua.h
+ * \brief C++11 header only interface to easily interact with Lua and Torch.
+ *  This code is evolved from torch plugin code for MXNet.
+ *
+ *  This header will require Torch and Lua to be presented, do not include.
+ *
+ * \author Junyuan Xie, Min Lin, Tianqi Chen
+ *
+ * \code
+ *
+ * // Example code to use the lua module.
+ * dmlc::LuaState* lua = dmlc::LuaState::ThreadLocalState();
+ * // vectors converts automatically to lua table.
+ * auto tbl = lua->Convert(std::vector<int>{1,2,3});
+ * // use eval to get lua reference, this is a function
+ * auto print = lua->Eval("return function(x) print(x) end");
+ * // lua function can be directly called from c++, arguments are converted.
+ * print(100);
+ *
+ * // set field in the table.
+ * tbl.SetField("square", lua->Eval("return function(x) x*x end"));
+ * // call the function, covert back to C++ values.
+ * int x = tbl["square"](100).Get<int>();
+ *
+ * \endcode
+ */
+#ifndef DMLC_LUA_H_
+#define DMLC_LUA_H_
+
+extern "C" {
+#include <lua.h>
+#include <luaT.h>
+#include <lualib.h>
+}
+
+#include <string>
+#include <stdexcept>
+#include <tuple>
+#include <mutex>
+#include <memory>
+#include <vector>
+#include <utility>
+#include <algorithm>
+#include <unordered_map>
+#include <type_traits>
+
+#include "./base.h"
+#include "./logging.h"
+#include "./thread_local.h"
+
+namespace dmlc {
+
+// forward declare torch state
+class LuaState;
+
+namespace lua_stack {
+template<typename T>
+struct Handler;
+};
+
+/*! \brief an reference to lua object */
+class LuaRef {
+ public:
+  /*! \brief construct an nil ref */
+  LuaRef() = default;
+  /*!
+   * \brief move constructor from another LuaRef
+   * \param other The other LuaRef to be moved
+   */
+  inline LuaRef(LuaRef&& other);  // NOLINT(*)
+  /*!
+   * \brief copy constructor
+   * \param other The other LuaRef to be copied
+   */
+  inline LuaRef(const LuaRef& other);  // NOLINT(*)
+  /*!
+   * \brief assign operator from other
+   * \param other The other LuaRef to be copy or moved.
+   * \return self
+   */
+  inline LuaRef& operator=(LuaRef&& other);
+  /*!
+   * \brief assign operator from other
+   * \param other The other LuaRef to be copy or moved.
+   * \return self
+   */
+  inline LuaRef& operator=(const LuaRef& other);
+  /*! \brief destructor */
+  inline ~LuaRef();
+  /*!
+   * \brief swap content with another ref
+   * \param other another LuaRef to be swaped.
+   */
+  inline void swap(LuaRef& other); // NOLINT(*)
+  /*!
+   * \brief Get content out as type T.
+   *
+   * \tparam T the type to be fetched.
+   * \return the corresponding c type.
+   */
+  template<typename T>
+  inline T Get() const;
+  /*!
+   * \brief Get user data pointer from LuaRef
+   *
+   *  CAREFUL when getting userdata(e.g. pointer to Tensor's storage) from LuaRef.
+   *  Remember they are managed by Lua, and can get deleted when all the
+   *  LuaRef to the userdata destructs. A good practice is always use a LuaRef to keep
+   *  the userdata alive when you need them from C++ side.
+   *
+   * \tparam T the type of pointer to be fetched.
+   * \return the corresponding c type.
+   */
+  template<typename T>
+  inline T* GetUDataPtr() const;
+  /*! \return whether the value is nil */
+  inline bool is_nil() const;
+  /*!
+   * \brief invoke the LuaRef as function
+   * \param args Arguments to be passed.
+   * \tparam Args arguments to be passed.
+   * \return The first return value.
+   */
+  template<typename... Args>
+  inline LuaRef operator()(Args&& ...args) const;
+  /*!
+   * \brief Get field from the lua table.
+   *  The reference must be a table
+   * \param key The key to the table
+   * \return a new ref to the corresponding field.
+   */
+  inline LuaRef operator[](const std::string& key) const;
+  /*!
+   * \brief Get field from the lua array
+   *  The reference must be a array
+   * \param index The index to the array,
+   *  Note: the index convention follows lua table, starts from 1
+   * \return a new ref to the corresponding field.
+   */
+  inline LuaRef operator[](size_t index) const;
+  /*!
+   * \brief Set field of lua table.
+   *  The reference must be a table
+   * \param key The key to the table
+   * \param value Lua convertable value to be setted.
+   * \return self.
+   */
+  template<typename T>
+  inline LuaRef& SetField(const std::string& key, const T& value);  // NOLINT(*)
+  /*!
+   * \brief Set LuaRef to the value on top of the stack.
+   *  This state must be nil.
+   *  This is API used by developer.
+   *
+   * \param s the corresponding lua state.
+   */
+  inline void SetByPopStack_(LuaState* s);
+
+ private:
+  // friend with luastate
+  friend struct lua_stack::Handler<LuaRef>;
+  friend class LuaState;
+  friend std::ostream &operator<<(std::ostream &os, const LuaRef &r);
+  /*! \brief pointer to the state */
+  LuaState* state_{nullptr};
+  /*! \brief reference index */
+  int ref_;
+};
+
+/*! \brief A Lua state */
+class LuaState {
+ public:
+  /*! \brief options to be provided in lua state */
+  enum Option {
+    kNoThreadProtect,
+    kThreadLocal,
+    kLocking,
+  };
+  /*! \brief destructor */
+  inline ~LuaState();
+  /*!
+   * \brief evaluate a piece of lua code, return the first result.
+   * \param lua_code Lua code
+   * \return A LuaRef object of the first returned result,
+   *  Can be nil if the code did not return LuaRefthing.
+   */
+  inline LuaRef Eval(const char* lua_code);
+  /*!
+   * \brief evaluate a piece of lua code, return the first result.
+   * \param lua_code Lua code
+   * \return A LuaRef object of the first returned result,
+   *  Can be nil if the code did not return anything.
+   */
+  inline LuaRef Eval(const std::string& lua_code) {
+    return this->Eval(lua_code.c_str());
+  }
+  /*!
+   * \brief convert a C++ type to lua type
+   * \param value The data to be converted.
+   *  vector, map will be converted to table.
+   * \return a converted value.
+   * \tparam T the type to be converted.
+   */
+  template<typename T>
+  inline LuaRef Convert(const T& value);
+  /*!
+   * \brief get global field from the state
+   * \param key The key to the global field.
+   * \return The global field value.
+   */
+  inline LuaRef operator[](const std::string& key);
+  /*!
+   * \brief Set the value to the global table.
+   * \param key The key of the global field.
+   * \param value The value to the set.
+   */
+  inline void SetGlobalField(const std::string& key, const LuaRef& value);
+  /*!
+   *  Get a thread local version of lua state.
+   *  The LuaState runs in thread local mode,
+   *  all the LuaRef can only be run on the current thread.
+   *  This is the recommended behavior when invoking Lua.
+   *
+   * \return a threadlocal version of lua state.
+   */
+  static inline LuaState* ThreadLocalState();
+  /*!
+   * Create a new lua state.
+   * \note It is highly recommended to use ThreadLocalState instead.
+   *
+   *  Most Lua program assumes it only runs from the same thread.
+   *  Some Lua code that wraps C library(e.g. Torch) could rely
+   *  on thread_local storage to store global state such as random number generator.
+   *  This means if the code is invoked by another thread, the thread_local
+   *  might become inavailable, depending on the implementation.
+   *
+   *  If the global state is stored only in Lua's global table, then
+   *  it is safe to use kLocking mode and call the code from multiple thread.
+   *  Never-the-less, using ThreadLocalState removes the need to lock,
+   *  and is the desirable usecase in most times.
+   *
+   * \sa ThreadLocalState
+   * \param option The option to use the state.
+   * \return a newly created lua state
+   */
+  static inline LuaState* Create_(Option option);
+
+  /*!
+   * \brief protected run f, this is used by API developers.
+   *  always call this to access lua state
+   *  f must not destruct LuaRef, or access the mutex
+   *
+   * \param f the function to be called.
+   * \tparam F the function to be called, signiture (lua_State *L)
+   */
+  template<typename F>
+  inline void PRun_(F f);
+  /*!
+   * \param L the other lua state.
+   * \return if the internal lua state is same as L
+   */
+  inline bool SameLuaState(lua_State *L) const {
+    return L_ == L;
+  }
+
+ protected:
+  struct StackReset;
+  friend class LuaRef;
+  friend struct ThreadLocalStore<LuaState>;
+  /*!
+   * \brief constructor
+   */
+  inline LuaState();
+
+  /*! \brief internal option, default to thread local */
+  Option option_{kThreadLocal};
+  /*! \brief internal lua state */
+  lua_State* L_;
+  /*! \brief internal lock about the state */
+  std::mutex mutex_;
+};
+
+// implementations after this line
+//! \cond Doxygen_Suppress
+/*! \brief macro to check error during lua call */
+#define LUA_CALL(x)                                                     \
+  if ((x)) {                                                            \
+    LOG(FATAL) << "Lua Call Error:" <<  lua_tostring(L, -1);            \
+  }
+
+/*!
+ * \brief namespace to handle conversions between lua and c++
+ *  User can provide an specialization of dmlc::lua_stack::Handler
+ *  to allow customized c++ data types to interact with Lua.
+ *
+ *  By default basic data types, composition of vector, and unordered_map is supported.
+ *  The conversion rules
+ *  - basic types(string, int, float) to corresponding lua types.
+ *  - unordered_map to Lua table.
+ *  - vector to lua indexed table.
+ */
+namespace lua_stack {
+inline int lua_abs_index(lua_State* L, int index) {
+  if (index > 0 || index <= LUA_REGISTRYINDEX) return index;
+  return lua_gettop(L) + index + 1;
+}
+
+template<typename T>
+struct Handler;
+
+template<typename T>
+struct NumberHandler {
+  static inline T Get(lua_State* L, int index, LuaState* s) {
+    CHECK_EQ(lua_type(L, index), LUA_TNUMBER)
+        << "Attempt to get number but type is \'"
+        << lua_typename(L, lua_type(L, index)) << '\'';
+    if (std::is_integral<T>::value) {
+      return static_cast<T>(lua_tointeger(L, index));
+    } else {
+      return static_cast<T>(lua_tonumber(L, index));
+    }
+  }
+  static inline void Push(lua_State* L, const T& v) {
+    if (std::is_integral<T>::value) {
+      lua_pushinteger(L, static_cast<lua_Integer>(v));
+    } else {
+      lua_pushnumber(L, static_cast<lua_Number>(v));
+    }
+  }
+};
+
+template<typename ContainerType>
+struct MapHandler {
+  using K = typename ContainerType::key_type;
+  using V = typename ContainerType::mapped_type;
+  static inline ContainerType Get(lua_State* L, int index, LuaState* s) {
+    ContainerType ret;
+    CHECK(lua_istable(L, index))
+        << "Expected a table but get "
+        << lua_typename(L, lua_type(L, index)) << '\'';
+    int tid = lua_abs_index(L, index);
+    lua_pushnil(L);
+    while (lua_next(L, -2)) {
+      ret[Handler<K>::Get(L, -2, s)] = Handler<V>::Pop(L, -1, s);
+      lua_pop(L, 1);
+    }
+    lua_settop(L, tid);
+    return ret;
+  }
+  static inline void Push(lua_State* L, const ContainerType& v) {
+    lua_createtable(L, v.size(), 0);
+    for (const auto& kv : v) {
+      Handler<K>::Push(L, kv.first);
+      Handler<V>::Push(L, kv.second);
+      lua_settable(L, -3);
+    }
+  }
+};
+
+struct UndefinedHandler {
+};
+
+template<typename T>
+struct Handler
+    : public std::conditional<std::is_arithmetic<T>::value,
+                              NumberHandler<T>,
+                              UndefinedHandler>::type {
+};
+
+template<>
+struct Handler<std::string> {
+  static inline std::string Get(lua_State* L, int index, LuaState* s) {
+    CHECK_EQ(lua_type(L, index), LUA_TSTRING);
+    return std::string(lua_tostring(L, index));
+  }
+  static inline void Push(lua_State* L, const std::string& v) {
+    lua_pushstring(L, v.c_str());
+  }
+};
+
+template<typename T>
+struct Handler<std::vector<T> > {
+  static inline std::vector<T> Get(lua_State* L, int index, LuaState* s) {
+    std::vector<T> ret;
+    CHECK(lua_istable(L, index))
+        << "Expected a table but get "
+        << lua_typename(L, lua_type(L, index)) << '\'';
+    int tid = lua_abs_index(L, index);
+    lua_pushnil(L);
+    while (lua_next(L, tid)) {
+      CHECK_EQ(Handler<size_t>::Get(L, -2, s), ret.size() + 1)
+          << "Target table is not an array";
+      ret.push_back(Handler<T>::Get(L, -1, s));
+      lua_pop(L, 1);
+    }
+    lua_settop(L, tid);
+    return ret;
+  }
+  static inline void Push(lua_State* L, const std::vector<T>& v) {
+    lua_createtable(L, v.size(), 0);
+    for (size_t i = 0; i < v.size(); ++i) {
+      Handler<T>::Push(L, v[i]);
+      lua_rawseti(L, -2, i + 1);
+    }
+  }
+};
+
+template<typename K, typename V>
+struct Handler<std::unordered_map<K, V> >
+    : public MapHandler<std::unordered_map<K, V> > {
+};
+
+template<>
+struct Handler<LuaRef> {
+  static inline LuaRef Get(lua_State* L, int index, LuaState* s) {
+    LuaRef ret;
+    lua_pushvalue(L, index);
+    ret.SetByPopStack_(s);
+    return ret;
+  }
+
+  static inline void Push(lua_State* L, const LuaRef& v) {
+    if (v.is_nil()) {
+      lua_pushnil(L);
+    } else {
+      CHECK(v.state_->SameLuaState(L))
+          << "Cannot pass LuaRef on a different LuaState's function";
+      lua_rawgeti(L, LUA_REGISTRYINDEX, v.ref_);
+    }
+  }
+};
+
+template<>
+struct Handler<std::nullptr_t> {
+  static inline LuaRef Get(lua_State* L, int index, LuaState* s) {
+    LOG(FATAL) << "not supported";
+    return LuaRef();
+  }
+  static inline void Push(lua_State* L, const std::nullptr_t& v) {
+    lua_pushnil(L);
+  }
+};
+
+// generic functor to call push the arguments.
+struct PushArg {
+  lua_State* L;
+  template<typename T>
+  inline void operator()(const T& v) const {
+    Handler<T>::Push(L, v);
+  }
+};
+
+}  // namespace lua_stack
+
+inline LuaState::LuaState() {
+  L_ = luaL_newstate();
+  CHECK(L_ != nullptr)
+      << "Failed to create new lua state";
+  luaL_openlibs(L_);
+}
+
+inline LuaState::~LuaState() {
+  if (option_ != kThreadLocal && L_ != nullptr) {
+    // never close threadlocal, for save destruction.
+    lua_close(L_);
+  }
+}
+
+inline LuaState* LuaState::Create_(Option opt) {
+  LuaState* s = new LuaState();
+  s->option_ = opt;
+  CHECK_NE(opt, kThreadLocal)
+      << "use LuaState::ThreadLocalState() to get the thread local state";
+  return s;
+}
+
+inline void LuaRef::SetByPopStack_(LuaState* s) {
+  CHECK(state_ == nullptr);
+  lua_State* L = s->L_;
+  if (!lua_isnil(L, -1)) {
+    ref_ = lua_ref(L, LUA_REGISTRYINDEX);
+    state_ = s;
+  } else {
+    lua_pop(L, 1);
+  }
+}
+
+// RAII guard to reset stack
+struct LuaState::StackReset {
+  lua_State* L;
+  int top;
+  ~StackReset() {
+    lua_settop(L, top);
+  }
+};
+
+template<typename F>
+inline void LuaState::PRun_(F f) {
+  if (option_ != kLocking) {
+    StackReset reset{L_, lua_gettop(L_)};
+    if (option_ == kThreadLocal) {
+      CHECK_EQ(ThreadLocalState(), this)
+          << "Invoke lua from a different thread in ThreadLocal mode.";
+    }
+    f(L_);
+    CHECK_EQ(reset.top, lua_gettop(L_));
+  } else {
+    std::lock_guard<std::mutex> lock(mutex_);
+    StackReset reset{L_, lua_gettop(L_)};
+    f(L_);
+    CHECK_EQ(reset.top, lua_gettop(L_));
+  }
+}
+
+inline LuaState* LuaState::ThreadLocalState() {
+  return ThreadLocalStore<LuaState>::Get();
+}
+
+inline LuaRef LuaState::Eval(const char* lua_code) {
+  LuaRef ret;
+  this->PRun_([this, lua_code, &ret](lua_State* L) {
+      luaL_loadstring(L, lua_code);
+      CHECK_EQ(lua_pcall(L, 0, 1, 0), 0)
+          << "Lua call error: " << lua_tostring(L, -1) << '\n'
+          << "---------\n"
+          << lua_code
+          << "\n----------";
+      ret.SetByPopStack_(this);
+    });
+  return ret;
+}
+
+template<typename T>
+inline LuaRef LuaState::Convert(const T& value) {
+  LuaRef ret;
+  this->PRun_([this, &value, &ret](lua_State* L) {
+      lua_stack::Handler<T>::Push(L, value);
+      ret.SetByPopStack_(this);
+    });
+  return ret;
+}
+
+inline LuaRef LuaState::operator[](const std::string& key) {
+  LuaRef ret;
+  this->PRun_([this, &key, &ret](lua_State* L) {
+      lua_getglobal(L, key.c_str());
+      ret.SetByPopStack_(this);
+    });
+  return ret;
+}
+
+inline void LuaState::SetGlobalField(
+    const std::string& key, const LuaRef& value) {
+  this->PRun_([this, &key, &value](lua_State* L) {
+      lua_rawgeti(L, LUA_REGISTRYINDEX, value.ref_);
+      lua_setglobal(L, key.c_str());
+    });
+}
+
+inline LuaRef::LuaRef(const LuaRef& other) {
+  if (other.state_ != nullptr) {
+    state_ = other.state_;
+    state_->PRun_([this, &other](lua_State* L) {
+        lua_rawgeti(L, LUA_REGISTRYINDEX, other.ref_);
+        ref_ = luaL_ref(L, LUA_REGISTRYINDEX);
+      });
+  }
+}
+
+inline LuaRef::LuaRef(LuaRef&& other) {
+  ref_ = other.ref_;
+  state_ = other.state_;
+  other.state_ = nullptr;
+}
+
+inline LuaRef& LuaRef::operator=(LuaRef&& other) {
+  LuaRef(std::move(other)).swap(*this);
+  return *this;
+}
+
+inline LuaRef& LuaRef::operator=(const LuaRef& other) {
+  LuaRef(other).swap(*this);
+  return *this;
+}
+
+inline void LuaRef::swap(LuaRef& other) { // NOLINT(*)
+  std::swap(state_, other.state_);
+  std::swap(ref_, other.ref_);
+}
+
+inline LuaRef::~LuaRef() {
+  if (state_ != nullptr) {
+    state_->PRun_([this](lua_State* L) {
+        luaL_unref(L, LUA_REGISTRYINDEX, ref_);
+      });
+  }
+}
+
+inline bool LuaRef::is_nil() const {
+  return state_ == nullptr;
+}
+
+std::ostream &operator<<(std::ostream &os, const LuaRef &r) {
+  if (!r.is_nil()) {
+    r.state_->PRun_([&os, &r](lua_State* L) {
+        lua_rawgeti(L, LUA_REGISTRYINDEX, r.ref_);
+        int type = lua_type(L, -1);
+        switch (type) {
+          case LUA_TSTRING:
+            os << "lua_string:'" << lua_tostring(L, -1) << "'"; break;
+          case LUA_TBOOLEAN:
+            os << "lua_bool:" << (lua_toboolean(L, -1) ? "true" : "false"); break;
+          case LUA_TNUMBER:
+            os << "lua_number:" << lua_tonumber(L, -1); break;
+          default:
+            os << "lua[ref=" << r.ref_ << ']' << lua_typename(L, type); break;
+        }
+        lua_pop(L, 1);
+      });
+  } else {
+    os << "lua_nil";
+  }
+  return os;
+}
+
+template<typename T>
+inline T LuaRef::Get() const {
+  CHECK(state_ != nullptr) << "Get:: LuaRef is nil";
+  T ret;
+  state_->PRun_([&ret, this](lua_State* L) {
+      lua_rawgeti(L, LUA_REGISTRYINDEX, ref_);
+      ret = lua_stack::Handler<T>::Get(L, -1, state_);
+      lua_pop(L, 1);
+    });
+  return ret;
+}
+
+template<typename T>
+inline T* LuaRef::GetUDataPtr() const {
+  CHECK(state_ != nullptr) << "Get:: LuaRef is nil";
+  T* ret;
+  state_->PRun_([&ret, this](lua_State* L) {
+      lua_rawgeti(L, LUA_REGISTRYINDEX, ref_);
+      ret = reinterpret_cast<T*>(lua_touserdata(L, -1));
+      lua_pop(L, 1);
+    });
+  return ret;
+}
+
+// helper function to dispatch varg foreach
+template<bool stop, std::size_t I, typename F, typename ...Args>
+struct for_each_dispatcher_ {
+  static inline void run(const std::tuple<Args...>& args, F f) {
+    f(std::get<I>(args));
+    for_each_dispatcher_<(I + 1) == sizeof...(Args), (I+1), F, Args...>::run(args, f);
+  }
+};
+// helper function to run foreach
+template<std::size_t I, typename F, typename ...Args>
+struct for_each_dispatcher_<true, I, F, Args...>  {
+  static inline void run(const std::tuple<Args...>& args, F f) {
+  }
+};
+
+// template function to iterate over tuples
+template<typename F, typename ...Args>
+inline void for_each(const std::tuple<Args...>& args, F f) {
+  for_each_dispatcher_<sizeof...(Args) == 0, 0, F, Args...>::run(args, f);
+}
+
+template<typename... Args>
+inline LuaRef LuaRef::operator()(Args&& ...args) const {
+  CHECK(state_ != nullptr) << "LuaRef is nil";
+  auto targ = std::make_tuple(std::forward<Args>(args)...);
+  size_t nargs = sizeof...(Args);
+  LuaRef ret;
+  state_->PRun_([this, nargs, &targ, &ret](lua_State* L) {
+      lua_rawgeti(L, LUA_REGISTRYINDEX, this->ref_);
+      CHECK(lua_isfunction(L, -1))
+          << "Expect to invoke a function but type='"
+          << lua_typename(L, lua_type(L, -1)) << '\'';
+      for_each(targ, lua_stack::PushArg{L});
+      LUA_CALL(lua_pcall(L, nargs, 1, 0));
+      ret.SetByPopStack_(state_);
+    });
+  return ret;
+}
+
+template<typename T>
+inline LuaRef& LuaRef::SetField(const std::string& key, const T& value) {  // NOLINT(*)
+  CHECK(state_ != nullptr) << "LuaRef is nil";
+  state_->PRun_([this, &key, &value](lua_State* L) {
+      lua_rawgeti(L, LUA_REGISTRYINDEX, this->ref_);
+      CHECK(lua_istable(L, -1))
+          << "Expect a table but type='"
+          << lua_typename(L, lua_type(L, -1)) << '\'';
+      lua_stack::Handler<T>::Push(L, value);
+      lua_setfield(L, -2, key.c_str());
+      lua_pop(L, 1);
+    });
+  return *this;
+}
+
+inline LuaRef LuaRef::operator[](const std::string& key) const {
+  CHECK(state_ != nullptr) << "LuaRef is nil";
+  LuaRef ret;
+  state_->PRun_([this, &key, &ret](lua_State* L) {
+      lua_rawgeti(L, LUA_REGISTRYINDEX, this->ref_);
+      CHECK(lua_istable(L, -1))
+          << "Expect a table but type='"
+          << lua_typename(L, lua_type(L, -1)) << '\'';
+      lua_getfield(L, -1, key.c_str());
+      ret.SetByPopStack_(state_);
+      lua_pop(L, 1);
+    });
+  return ret;
+}
+
+inline LuaRef LuaRef::operator[](size_t index) const {
+  CHECK(state_ != nullptr) << "LuaRef is nil";
+  LuaRef ret;
+  state_->PRun_([this, index, &ret](lua_State* L) {
+      lua_rawgeti(L, LUA_REGISTRYINDEX, this->ref_);
+      CHECK(lua_istable(L, -1))
+          << "Expect a table but type='"
+          << lua_typename(L, lua_type(L, -1)) << '\'';
+      lua_rawgeti(L, -1, index);
+      ret.SetByPopStack_(state_);
+      lua_pop(L, 1);
+    });
+  return ret;
+}
+
+//! \endcond
+}  // namespace dmlc
+
+#endif  // DMLC_LUA_H_
diff --git a/darknet_drp_ros/include/dmlc/memory.h b/darknet_drp_ros/include/dmlc/memory.h
new file mode 100644
index 0000000..0080112
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/memory.h
@@ -0,0 +1,263 @@
+/*!
+ *  Copyright (c) 2015 by Contributors
+ * \file memory.h
+ * \brief Additional memory hanlding utilities.
+ */
+#ifndef DMLC_MEMORY_H_
+#define DMLC_MEMORY_H_
+
+#include <vector>
+#include <memory>
+#include <utility>
+#include "./base.h"
+#include "./logging.h"
+#include "./thread_local.h"
+
+namespace dmlc {
+
+/*!
+ * \brief A memory pool that allocate memory of fixed size and alignment.
+ * \tparam size The size of each piece.
+ * \tparam align The alignment requirement of the memory.
+ */
+template<size_t size, size_t align>
+class MemoryPool {
+ public:
+  /*! \brief constructor */
+  MemoryPool() {
+    static_assert(align % alignof(LinkedList) == 0,
+                  "alignment requirement failed.");
+    curr_page_.reset(new Page());
+  }
+  /*! \brief allocate a new memory of size */
+  inline void* allocate() {
+    if (head_ != nullptr) {
+      LinkedList* ret = head_;
+      head_ = head_->next;
+      return ret;
+    } else {
+      if (page_ptr_ < kPageSize) {
+        return &(curr_page_->data[page_ptr_++]);
+      } else {
+        allocated_.push_back(std::move(curr_page_));
+        curr_page_.reset(new Page());
+        page_ptr_ = 1;
+        return &(curr_page_->data[0]);
+      }
+    }
+  }
+  /*!
+   * \brief deallocate a piece of memory
+   * \param p The pointer to the memory to be de-allocated.
+   */
+  inline void deallocate(void* p) {
+    LinkedList* ptr = static_cast<LinkedList*>(p);
+    ptr->next = head_;
+    head_ = ptr;
+  }
+
+ private:
+  // page size of each member
+  static const int kPageSize = ((1 << 22) / size);
+  // page to be requested.
+  struct Page {
+    typename std::aligned_storage<size, align>::type data[kPageSize];
+  };
+  // internal linked list structure.
+  struct LinkedList {
+    LinkedList* next{nullptr};
+  };
+  // head of free list
+  LinkedList* head_{nullptr};
+  // current free page
+  std::unique_ptr<Page> curr_page_;
+  // pointer to the current free page position.
+  size_t page_ptr_{0};
+  // allocated pages.
+  std::vector<std::unique_ptr<Page> > allocated_;
+};
+
+
+/*!
+ * \brief A thread local allocator that get memory from a threadlocal memory pool.
+ * This is suitable to allocate objects that do not cross thread.
+ * \tparam T the type of the data to be allocated.
+ */
+template<typename T>
+class ThreadlocalAllocator {
+ public:
+  /*! \brief pointer type */
+  typedef T* pointer;
+  /*! \brief const pointer type */
+  typedef const T* const_ptr;
+  /*! \brief value type */
+  typedef T value_type;
+  /*! \brief default constructor */
+  ThreadlocalAllocator() {}
+  /*!
+   * \brief constructor from another allocator
+   * \param other another allocator
+   * \tparam U another type
+   */
+  template<typename U>
+  ThreadlocalAllocator(const ThreadlocalAllocator<U>& other) {}
+  /*!
+   * \brief allocate memory
+   * \param n number of blocks
+   * \return an uninitialized memory of type T.
+   */
+  inline T* allocate(size_t n) {
+    CHECK_EQ(n, 1);
+    typedef ThreadLocalStore<MemoryPool<sizeof(T), alignof(T)> > Store;
+    return static_cast<T*>(Store::Get()->allocate());
+  }
+  /*!
+   * \brief deallocate memory
+   * \param p a memory to be returned.
+   * \param n number of blocks
+   */
+  inline void deallocate(T* p, size_t n) {
+    CHECK_EQ(n, 1);
+    typedef ThreadLocalStore<MemoryPool<sizeof(T), alignof(T)> > Store;
+    Store::Get()->deallocate(p);
+  }
+};
+
+
+/*!
+ * \brief a shared pointer like type that allocate object
+ *   from a threadlocal object pool. This object is not thread-safe
+ *   but can be faster than shared_ptr in certain usecases.
+ * \tparam T the data type.
+ */
+template<typename T>
+struct ThreadlocalSharedPtr {
+ public:
+  /*! \brief default constructor */
+  ThreadlocalSharedPtr() : block_(nullptr) {}
+  /*!
+   * \brief constructor from nullptr
+   * \param other the nullptr type
+   */
+  ThreadlocalSharedPtr(std::nullptr_t other) : block_(nullptr) {}  // NOLINT(*)
+  /*!
+   * \brief copy constructor
+   * \param other another pointer.
+   */
+  ThreadlocalSharedPtr(const ThreadlocalSharedPtr<T>& other)
+      : block_(other.block_) {
+    IncRef(block_);
+  }
+  /*!
+   * \brief move constructor
+   * \param other another pointer.
+   */
+  ThreadlocalSharedPtr(ThreadlocalSharedPtr<T>&& other)
+      : block_(other.block_) {
+    other.block_ = nullptr;
+  }
+  /*!
+   * \brief destructor
+   */
+  ~ThreadlocalSharedPtr() {
+    DecRef(block_);
+  }
+  /*!
+   * \brief move assignment
+   * \param other another object to be assigned.
+   * \return self.
+   */
+  inline ThreadlocalSharedPtr<T>& operator=(ThreadlocalSharedPtr<T>&& other) {
+    DecRef(block_);
+    block_ = other.block_;
+    other.block_ = nullptr;
+    return *this;
+  }
+  /*!
+   * \brief copy assignment
+   * \param other another object to be assigned.
+   * \return self.
+   */
+  inline ThreadlocalSharedPtr<T> &operator=(const ThreadlocalSharedPtr<T>& other) {
+    DecRef(block_);
+    block_ = other.block_;
+    IncRef(block_);
+    return *this;
+  }
+  /*! \brief check if nullptr */
+  inline bool operator==(std::nullptr_t other) const {
+    return block_ == nullptr;
+  }
+  /*!
+   * \return get the pointer content.
+   */
+  inline T* get() const {
+    if (block_ == nullptr) return nullptr;
+    return reinterpret_cast<T*>(&(block_->data));
+  }
+  /*!
+   * \brief reset the pointer to nullptr.
+   */
+  inline void reset() {
+    DecRef(block_);
+    block_ = nullptr;
+  }
+  /*! \return if use_count == 1*/
+  inline bool unique() const {
+    if (block_ == nullptr) return false;
+    return block_->use_count_ == 1;
+  }
+  /*! \return dereference pointer */
+  inline T* operator*() const {
+    return reinterpret_cast<T*>(&(block_->data));
+  }
+  /*! \return dereference pointer */
+  inline T* operator->() const {
+    return reinterpret_cast<T*>(&(block_->data));
+  }
+  /*!
+   * \brief create a new space from threadlocal storage and return it.
+   * \tparam Args the arguments.
+   * \param args The input argument
+   * \return the allocated pointer.
+   */
+  template <typename... Args>
+  inline static ThreadlocalSharedPtr<T> Create(Args&&... args) {
+    ThreadlocalAllocator<RefBlock> arena;
+    ThreadlocalSharedPtr<T> p;
+    p.block_ = arena.allocate(1);
+    p.block_->use_count_ = 1;
+    new (&(p.block_->data)) T(std::forward<Args>(args)...);
+    return p;
+  }
+
+ private:
+  // internal reference block
+  struct RefBlock {
+    typename std::aligned_storage<sizeof(T), alignof(T)>::type data;
+    unsigned use_count_;
+  };
+  // decrease ref counter
+  inline static void DecRef(RefBlock* block) {
+    if (block != nullptr) {
+      if (--block->use_count_ == 0) {
+        ThreadlocalAllocator<RefBlock> arena;
+        T* dptr = reinterpret_cast<T*>(&(block->data));
+        dptr->~T();
+        arena.deallocate(block, 1);
+      }
+    }
+  }
+  // increase ref counter
+  inline static void IncRef(RefBlock* block) {
+    if (block != nullptr) {
+      ++block->use_count_;
+    }
+  }
+  // internal block
+  RefBlock *block_;
+};
+
+}  // namespace dmlc
+
+#endif  // DMLC_MEMORY_H_
diff --git a/darknet_drp_ros/include/dmlc/memory_io.h b/darknet_drp_ros/include/dmlc/memory_io.h
new file mode 100644
index 0000000..4e80758
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/memory_io.h
@@ -0,0 +1,105 @@
+/*!
+ *  Copyright (c) 2015 by Contributors
+ * \file memory_io.h
+ * \brief defines binary serialization class to serialize things into/from memory region.
+ */
+#ifndef DMLC_MEMORY_IO_H_
+#define DMLC_MEMORY_IO_H_
+
+#include <cstring>
+#include <string>
+#include <algorithm>
+#include "./base.h"
+#include "./io.h"
+#include "./logging.h"
+
+namespace dmlc {
+/*!
+ * \brief A Stream that operates on fixed region of memory
+ *  This class allows us to read/write from/to a fixed memory region.
+ */
+struct MemoryFixedSizeStream : public SeekStream {
+ public:
+  /*!
+   * \brief constructor
+   * \param p_buffer the head pointer of the memory region.
+   * \param buffer_size the size of the memorybuffer
+   */
+  MemoryFixedSizeStream(void *p_buffer, size_t buffer_size)
+      : p_buffer_(reinterpret_cast<char*>(p_buffer)),
+        buffer_size_(buffer_size) {
+    curr_ptr_ = 0;
+  }
+  virtual size_t Read(void *ptr, size_t size) {
+    CHECK(curr_ptr_ + size <= buffer_size_);
+    size_t nread = std::min(buffer_size_ - curr_ptr_, size);
+    if (nread != 0) std::memcpy(ptr, p_buffer_ + curr_ptr_, nread);
+    curr_ptr_ += nread;
+    return nread;
+  }
+  virtual void Write(const void *ptr, size_t size) {
+    if (size == 0) return;
+    CHECK(curr_ptr_ + size <=  buffer_size_);
+    std::memcpy(p_buffer_ + curr_ptr_, ptr, size);
+    curr_ptr_ += size;
+  }
+  virtual void Seek(size_t pos) {
+    curr_ptr_ = static_cast<size_t>(pos);
+  }
+  virtual size_t Tell(void) {
+    return curr_ptr_;
+  }
+
+ private:
+  /*! \brief in memory buffer */
+  char *p_buffer_;
+  /*! \brief current pointer */
+  size_t buffer_size_;
+  /*! \brief current pointer */
+  size_t curr_ptr_;
+};  // class MemoryFixedSizeStream
+
+/*!
+ * \brief A in memory stream that is backed by std::string.
+ *  This class allows us to read/write from/to a std::string.
+ */
+struct MemoryStringStream : public dmlc::SeekStream {
+ public:
+  /*!
+   * \brief constructor
+   * \param p_buffer the pointer to the string.
+   */
+  explicit MemoryStringStream(std::string *p_buffer)
+      : p_buffer_(p_buffer) {
+    curr_ptr_ = 0;
+  }
+  virtual size_t Read(void *ptr, size_t size) {
+    CHECK(curr_ptr_ <= p_buffer_->length());
+    size_t nread = std::min(p_buffer_->length() - curr_ptr_, size);
+    if (nread != 0) std::memcpy(ptr, &(*p_buffer_)[0] + curr_ptr_, nread);
+    curr_ptr_ += nread;
+    return nread;
+  }
+  virtual void Write(const void *ptr, size_t size) {
+    if (size == 0) return;
+    if (curr_ptr_ + size > p_buffer_->length()) {
+      p_buffer_->resize(curr_ptr_+size);
+    }
+    std::memcpy(&(*p_buffer_)[0] + curr_ptr_, ptr, size);
+    curr_ptr_ += size;
+  }
+  virtual void Seek(size_t pos) {
+    curr_ptr_ = static_cast<size_t>(pos);
+  }
+  virtual size_t Tell(void) {
+    return curr_ptr_;
+  }
+
+ private:
+  /*! \brief in memory buffer */
+  std::string *p_buffer_;
+  /*! \brief current pointer */
+  size_t curr_ptr_;
+};  // class MemoryStringStream
+}  // namespace dmlc
+#endif  // DMLC_MEMORY_IO_H_
diff --git a/darknet_drp_ros/include/dmlc/omp.h b/darknet_drp_ros/include/dmlc/omp.h
new file mode 100644
index 0000000..b447470
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/omp.h
@@ -0,0 +1,51 @@
+/*!
+ *  Copyright (c) 2015 by Contributors
+ * \file omp.h
+ * \brief header to handle OpenMP compatibility issues
+ */
+#ifndef DMLC_OMP_H_
+#define DMLC_OMP_H_
+
+
+#if defined(_OPENMP)
+#include <omp.h>
+#else
+
+#if defined(__clang__)
+#undef __GOMP_NOTHROW
+#define __GOMP_NOTHROW
+#elif defined(__cplusplus)
+#undef __GOMP_NOTHROW
+#define __GOMP_NOTHROW throw()
+#else
+#undef __GOMP_NOTHROW
+#define __GOMP_NOTHROW __attribute__((__nothrow__))
+#endif
+
+//! \cond Doxygen_Suppress
+#ifdef __cplusplus
+extern "C" {
+#endif
+inline int omp_get_thread_num() __GOMP_NOTHROW { return 0; }
+inline int omp_get_num_threads() __GOMP_NOTHROW { return 1; }
+inline int omp_get_max_threads() __GOMP_NOTHROW { return 1; }
+inline int omp_get_num_procs() __GOMP_NOTHROW { return 1; }
+inline void omp_set_num_threads(int nthread) __GOMP_NOTHROW {}
+inline int omp_in_parallel() __GOMP_NOTHROW { return 0; }
+#ifdef __cplusplus
+}
+#endif  // __cplusplus
+#endif  // _OPENMP
+
+// loop variable used in openmp
+namespace dmlc {
+#ifdef _MSC_VER
+typedef int omp_uint;
+typedef long omp_ulong;  // NOLINT(*)
+#else
+typedef unsigned omp_uint;
+typedef unsigned long omp_ulong; // NOLINT(*)
+#endif
+//! \endcond
+}  // namespace dmlc
+#endif  // DMLC_OMP_H_
diff --git a/darknet_drp_ros/include/dmlc/optional.h b/darknet_drp_ros/include/dmlc/optional.h
new file mode 100644
index 0000000..7ed2e85
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/optional.h
@@ -0,0 +1,271 @@
+/*!
+ * Copyright (c) 2016 by Contributors
+ * \file optional.h
+ * \brief Container to hold optional data.
+ */
+#ifndef DMLC_OPTIONAL_H_
+#define DMLC_OPTIONAL_H_
+
+#include <iostream>
+#include <string>
+#include <utility>
+#include <algorithm>
+
+#include "./base.h"
+#include "./common.h"
+#include "./logging.h"
+#include "./type_traits.h"
+
+namespace dmlc {
+
+/*! \brief dummy type for assign null to optional */
+struct nullopt_t {
+#if defined(_MSC_VER) && _MSC_VER < 1900
+  /*! \brief dummy constructor */
+  explicit nullopt_t(int a) {}
+#else
+  /*! \brief dummy constructor */
+  constexpr explicit nullopt_t(int a) {}
+#endif
+};
+
+/*! Assign null to optional: optional<T> x = nullopt; */
+constexpr const nullopt_t nullopt = nullopt_t(0);
+
+/*!
+ * \brief c++17 compatible optional class.
+ *
+ * At any time an optional<T> instance either
+ * hold no value (string representation "None")
+ * or hold a value of type T.
+ */
+template<typename T>
+class optional {
+ public:
+  /*! \brief construct an optional object that contains no value */
+  optional() : is_none(true) {}
+  /*! \brief construct an optional object with value */
+  explicit optional(const T& value) {
+#pragma GCC diagnostic push
+#if __GNUC__ >= 6
+#pragma GCC diagnostic ignored "-Wmaybe-uninitialized"
+#endif
+    is_none = false;
+    new (&val) T(value);
+#pragma GCC diagnostic pop
+  }
+  /*! \brief construct an optional object with another optional object */
+  optional(const optional<T>& other) {
+#pragma GCC diagnostic push
+#if __GNUC__ >= 6
+#pragma GCC diagnostic ignored "-Wmaybe-uninitialized"
+#endif
+    is_none = other.is_none;
+    if (!is_none) {
+      new (&val) T(other.value());
+    }
+#pragma GCC diagnostic pop
+  }
+  /*! \brief deconstructor */
+  ~optional() {
+    if (!is_none) {
+      reinterpret_cast<T*>(&val)->~T();
+    }
+  }
+  /*! \brief swap two optional */
+  void swap(optional<T>& other) {
+    std::swap(val, other.val);
+    std::swap(is_none, other.is_none);
+  }
+  /*! \brief set this object to hold value
+   *  \param value the value to hold
+   *  \return return self to support chain assignment
+   */
+  optional<T>& operator=(const T& value) {
+    (optional<T>(value)).swap(*this);
+    return *this;
+  }
+  /*! \brief set this object to hold the same value with other
+   *  \param other the other object
+   *  \return return self to support chain assignment
+   */
+  optional<T>& operator=(const optional<T> &other) {
+    (optional<T>(other)).swap(*this);
+    return *this;
+  }
+  /*! \brief clear the value this object is holding.
+   *         optional<T> x = nullopt;
+   */
+  optional<T>& operator=(nullopt_t) {
+    (optional<T>()).swap(*this);
+    return *this;
+  }
+  /*! \brief non-const dereference operator */
+  T& operator*() {  // NOLINT(*)
+    return *reinterpret_cast<T*>(&val);
+  }
+  /*! \brief const dereference operator */
+  const T& operator*() const {
+    return *reinterpret_cast<const T*>(&val);
+  }
+  /*! \brief equal comparison */
+  bool operator==(const optional<T>& other) const {
+    return this->is_none == other.is_none &&
+           (this->is_none == true || this->value() == other.value());
+  }
+  /*! \brief return the holded value.
+   *         throws std::logic_error if holding no value
+   */
+  const T& value() const {
+    if (is_none) {
+      throw std::logic_error("bad optional access");
+    }
+    return *reinterpret_cast<const T*>(&val);
+  }
+  /*! \brief whether this object is holding a value */
+  explicit operator bool() const { return !is_none; }
+  /*! \brief whether this object is holding a value (alternate form). */
+  bool has_value() const { return operator bool(); }
+
+ private:
+  // whether this is none
+  bool is_none;
+  // on stack storage of value
+  typename std::aligned_storage<sizeof(T), alignof(T)>::type val;
+};
+
+/*! \brief serialize an optional object to string.
+ *
+ *  \code
+ *    dmlc::optional<int> x;
+ *    std::cout << x;  // None
+ *    x = 0;
+ *    std::cout << x;  // 0
+ *  \endcode
+ *
+ *  \param os output stream
+ *  \param t source optional<T> object
+ *  \return output stream
+ */
+template<typename T>
+std::ostream &operator<<(std::ostream &os, const optional<T> &t) {
+  if (t) {
+    os << *t;
+  } else {
+    os << "None";
+  }
+  return os;
+}
+
+/*! \brief parse a string object into optional<T>
+ *
+ *  \code
+ *    dmlc::optional<int> x;
+ *    std::string s1 = "1";
+ *    std::istringstream is1(s1);
+ *    s1 >> x;  // x == optional<int>(1)
+ *
+ *    std::string s2 = "None";
+ *    std::istringstream is2(s2);
+ *    s2 >> x;  // x == optional<int>()
+ *  \endcode
+ *
+ *  \param is input stream
+ *  \param t target optional<T> object
+ *  \return input stream
+ */
+template<typename T>
+std::istream &operator>>(std::istream &is, optional<T> &t) {
+  char buf[4];
+  std::streampos origin = is.tellg();
+  is.read(buf, 4);
+  if (is.fail() || buf[0] != 'N' || buf[1] != 'o' ||
+      buf[2] != 'n' || buf[3] != 'e') {
+    is.clear();
+    is.seekg(origin);
+    T x;
+    is >> x;
+    t = x;
+    if (std::is_integral<T>::value && !is.eof() && is.peek() == 'L') is.get();
+  } else {
+    t = nullopt;
+  }
+  return is;
+}
+/*! \brief specialization of '>>' istream parsing for optional<bool>
+ *
+ * Permits use of generic parameter FieldEntry<DType> class to create
+ * FieldEntry<optional<bool>> without explicit specialization.
+ *
+ *  \code
+ *    dmlc::optional<bool> x;
+ *    std::string s1 = "true";
+ *    std::istringstream is1(s1);
+ *    s1 >> x;  // x == optional<bool>(true)
+ *
+ *    std::string s2 = "None";
+ *    std::istringstream is2(s2);
+ *    s2 >> x;  // x == optional<bool>()
+ *  \endcode
+ *
+ *  \param is input stream
+ *  \param t target optional<bool> object
+ *  \return input stream
+ */
+inline std::istream &operator>>(std::istream &is, optional<bool> &t) {
+  // Discard initial whitespace
+  while (isspace(is.peek()))
+    is.get();
+  // Extract chars that might be valid into a separate string, stopping
+  // on whitespace or other non-alphanumerics such as ",)]".
+  std::string s;
+  while (isalnum(is.peek()))
+    s.push_back(is.get());
+
+  if (!is.fail()) {
+    std::transform(s.begin(), s.end(), s.begin(), ::tolower);
+    if (s == "1" || s == "true")
+      t = true;
+    else if (s == "0" || s == "false")
+      t = false;
+    else if (s == "none")
+      t = nullopt;
+    else
+      is.setstate(std::ios::failbit);
+  }
+
+  return is;
+}
+
+/*! \brief description for optional int */
+DMLC_DECLARE_TYPE_NAME(optional<int>, "int or None");
+/*! \brief description for optional bool */
+DMLC_DECLARE_TYPE_NAME(optional<bool>, "boolean or None");
+/*! \brief description for optional float */
+DMLC_DECLARE_TYPE_NAME(optional<float>, "float or None");
+/*! \brief description for optional double */
+DMLC_DECLARE_TYPE_NAME(optional<double>, "double or None");
+
+}  // namespace dmlc
+
+namespace std {
+/*! \brief std hash function for optional */
+template<typename T>
+struct hash<dmlc::optional<T> > {
+  /*!
+   * \brief returns hash of the optional value.
+   * \param val value.
+   * \return hash code.
+   */
+  size_t operator()(const dmlc::optional<T>& val) const {
+    std::hash<bool> hash_bool;
+    size_t res = hash_bool(val.has_value());
+    if (val.has_value()) {
+      res = dmlc::HashCombine(res, val.value());
+    }
+    return res;
+  }
+};
+}  // namespace std
+
+#endif  // DMLC_OPTIONAL_H_
diff --git a/darknet_drp_ros/include/dmlc/parameter.h b/darknet_drp_ros/include/dmlc/parameter.h
new file mode 100644
index 0000000..6c16e74
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/parameter.h
@@ -0,0 +1,1153 @@
+/*!
+ * Copyright (c) 2015 by Contributors
+ * \file parameter.h
+ * \brief Provide lightweight util to do parameter setup and checking.
+ */
+#ifndef DMLC_PARAMETER_H_
+#define DMLC_PARAMETER_H_
+
+#include <cstddef>
+#include <cstdlib>
+#include <cmath>
+#include <sstream>
+#include <limits>
+#include <map>
+#include <set>
+#include <typeinfo>
+#include <string>
+#include <vector>
+#include <algorithm>
+#include <utility>
+#include <stdexcept>
+#include <iostream>
+#include <iomanip>
+#include <cerrno>
+#include "./base.h"
+#include "./json.h"
+#include "./logging.h"
+#include "./type_traits.h"
+#include "./optional.h"
+#include "./strtonum.h"
+
+namespace dmlc {
+// this file is backward compatible with non-c++11
+/*! \brief Error throwed by parameter checking */
+struct ParamError : public dmlc::Error {
+  /*!
+   * \brief constructor
+   * \param msg error message
+   */
+  explicit ParamError(const std::string &msg)
+      : dmlc::Error(msg) {}
+};
+
+/*!
+ * \brief Get environment variable with default.
+ * \param key the name of environment variable.
+ * \param default_value the default value of environment vriable.
+ * \return The value received
+ */
+template<typename ValueType>
+inline ValueType GetEnv(const char *key,
+                        ValueType default_value);
+/*!
+ * \brief Set environment variable.
+ * \param key the name of environment variable.
+ * \param value the new value for key.
+ * \return The value received
+ */
+template<typename ValueType>
+inline void SetEnv(const char *key,
+                   ValueType value);
+
+/*! \brief internal namespace for parameter manangement */
+namespace parameter {
+// forward declare ParamManager
+class ParamManager;
+// forward declare FieldAccessEntry
+class FieldAccessEntry;
+// forward declare FieldEntry
+template<typename DType>
+class FieldEntry;
+// forward declare ParamManagerSingleton
+template<typename PType>
+struct ParamManagerSingleton;
+
+/*! \brief option in parameter initialization */
+enum ParamInitOption {
+  /*! \brief allow unknown parameters */
+  kAllowUnknown,
+  /*! \brief need to match exact parameters */
+  kAllMatch,
+  /*! \brief allow unmatched hidden field with format __*__ */
+  kAllowHidden
+};
+}  // namespace parameter
+/*!
+ * \brief Information about a parameter field in string representations.
+ */
+struct ParamFieldInfo {
+  /*! \brief name of the field */
+  std::string name;
+  /*! \brief type of the field in string format */
+  std::string type;
+  /*!
+   * \brief detailed type information string
+   *  This include the default value, enum constran and typename.
+   */
+  std::string type_info_str;
+  /*! \brief detailed description of the type */
+  std::string description;
+};
+
+/*!
+ * \brief Parameter is the base type every parameter struct should inherit from
+ * The following code is a complete example to setup parameters.
+ * \code
+ *   struct Param : public dmlc::Parameter<Param> {
+ *     float learning_rate;
+ *     int num_hidden;
+ *     std::string name;
+ *     // declare parameters in header file
+ *     DMLC_DECLARE_PARAMETER(Param) {
+ *       DMLC_DECLARE_FIELD(num_hidden).set_range(0, 1000);
+ *       DMLC_DECLARE_FIELD(learning_rate).set_default(0.01f);
+ *       DMLC_DECLARE_FIELD(name).set_default("hello");
+ *     }
+ *   };
+ *   // register it in cc file
+ *   DMLC_REGISTER_PARAMETER(Param);
+ * \endcode
+ *
+ *  After that, the Param struct will get all the functions defined in Parameter.
+ * \tparam PType the type of parameter struct
+ *
+ * \sa DMLC_DECLARE_FIELD, DMLC_REGISTER_PARAMETER, DMLC_DECLARE_PARAMETER
+ */
+template<typename PType>
+struct Parameter {
+ public:
+  /*!
+   * \brief initialize the parameter by keyword arguments.
+   *  This function will initialize the parameter struct, check consistency
+   *  and throw error if something wrong happens.
+   *
+   * \param kwargs map of keyword arguments, or vector of pairs
+   * \parma option The option on initialization.
+   * \tparam Container container type
+   * \throw ParamError when something go wrong.
+   */
+  template<typename Container>
+  inline void Init(const Container &kwargs,
+                   parameter::ParamInitOption option = parameter::kAllowHidden) {
+    PType::__MANAGER__()->RunInit(static_cast<PType*>(this),
+                                  kwargs.begin(), kwargs.end(),
+                                  NULL,
+                                  option);
+  }
+  /*!
+   * \brief initialize the parameter by keyword arguments.
+   *  This is same as Init, but allow unknown arguments.
+   *
+   * \param kwargs map of keyword arguments, or vector of pairs
+   * \tparam Container container type
+   * \throw ParamError when something go wrong.
+   * \return vector of pairs of unknown arguments.
+   */
+  template<typename Container>
+  inline std::vector<std::pair<std::string, std::string> >
+  InitAllowUnknown(const Container &kwargs) {
+    std::vector<std::pair<std::string, std::string> > unknown;
+    PType::__MANAGER__()->RunInit(static_cast<PType*>(this),
+                                  kwargs.begin(), kwargs.end(),
+                                  &unknown, parameter::kAllowUnknown);
+    return unknown;
+  }
+
+  /*!
+   * \brief Update the parameter by keyword arguments.  This is same as
+   * `InitAllowUnknown', but without setting not provided parameters to their default.
+   *
+   * \tparam Container container type
+   *
+   * \param kwargs map of keyword arguments, or vector of pairs
+   *
+   * \throw ParamError when something go wrong.
+   * \return vector of pairs of unknown arguments.
+   */
+  template <typename Container>
+  std::vector<std::pair<std::string, std::string> >
+  UpdateAllowUnknown(Container const& kwargs) {
+    std::vector<std::pair<std::string, std::string> > unknown;
+    PType::__MANAGER__()->RunUpdate(static_cast<PType *>(this), kwargs.begin(),
+                                    kwargs.end(), parameter::kAllowUnknown,
+                                    &unknown, nullptr);
+    return unknown;
+  }
+
+  /*!
+   * \brief Update the dict with values stored in parameter.
+   *
+   * \param dict The dictionary to be updated.
+   * \tparam Container container type
+   */
+  template<typename Container>
+  inline void UpdateDict(Container *dict) const {
+    PType::__MANAGER__()->UpdateDict(this->head(), dict);
+  }
+  /*!
+   * \brief Return a dictionary representation of the parameters
+   * \return A dictionary that maps key -> value
+   */
+  inline std::map<std::string, std::string> __DICT__() const {
+    std::vector<std::pair<std::string, std::string> > vec
+        = PType::__MANAGER__()->GetDict(this->head());
+    return std::map<std::string, std::string>(vec.begin(), vec.end());
+  }
+  /*!
+   * \brief Write the parameters in JSON format.
+   * \param writer JSONWriter used for writing.
+   */
+  inline void Save(dmlc::JSONWriter *writer) const {
+    writer->Write(this->__DICT__());
+  }
+  /*!
+   * \brief Load the parameters from JSON.
+   * \param reader JSONReader used for loading.
+   * \throw ParamError when something go wrong.
+   */
+  inline void Load(dmlc::JSONReader *reader) {
+    std::map<std::string, std::string> kwargs;
+    reader->Read(&kwargs);
+    this->Init(kwargs);
+  }
+  /*!
+   * \brief Get the fields of the parameters.
+   * \return List of ParamFieldInfo of each field.
+   */
+  inline static std::vector<ParamFieldInfo> __FIELDS__() {
+    return PType::__MANAGER__()->GetFieldInfo();
+  }
+  /*!
+   * \brief Print docstring of the parameter
+   * \return the printed docstring
+   */
+  inline static std::string __DOC__() {
+    std::ostringstream os;
+    PType::__MANAGER__()->PrintDocString(os);
+    return os.str();
+  }
+
+ protected:
+  /*!
+   * \brief internal function to allow declare of a parameter memember
+   * \param manager the parameter manager
+   * \param key the key name of the parameter
+   * \param ref the reference to the parameter in the struct.
+   */
+  template<typename DType>
+  inline parameter::FieldEntry<DType>& DECLARE(
+      parameter::ParamManagerSingleton<PType> *manager,
+      const std::string &key, DType &ref) { // NOLINT(*)
+    parameter::FieldEntry<DType> *e =
+        new parameter::FieldEntry<DType>();
+    e->Init(key, this->head(), ref);
+    manager->manager.AddEntry(key, e);
+    return *e;
+  }
+
+ private:
+  /*! \return Get head pointer of child structure */
+  inline PType *head() const {
+    return static_cast<PType*>(const_cast<Parameter<PType>*>(this));
+  }
+};
+
+//! \cond Doxygen_Suppress
+/*!
+ * \brief macro used to declare parameter
+ *
+ * Example:
+ * \code
+ *   struct Param : public dmlc::Parameter<Param> {
+ *     // declare parameters in header file
+ *     DMLC_DECLARE_PARAMETER(Param) {
+ *        // details of declarations
+ *     }
+ *   };
+ * \endcode
+ *
+ * This macro need to be put in a source file so that registration only happens once.
+ * Refer to example code in Parameter for details
+ *
+ * \param PType the name of parameter struct.
+ * \sa Parameter
+ */
+#define DMLC_DECLARE_PARAMETER(PType)                                   \
+  static ::dmlc::parameter::ParamManager *__MANAGER__();                \
+  inline void __DECLARE__(::dmlc::parameter::ParamManagerSingleton<PType> *manager) \
+
+/*!
+ * \brief macro to declare fields
+ * \param FieldName the name of the field.
+ */
+#define DMLC_DECLARE_FIELD(FieldName)  this->DECLARE(manager, #FieldName, FieldName)
+
+/*!
+ * \brief macro to declare alias of a fields
+ * \param FieldName the name of the field.
+ * \param AliasName the name of the alias, must be declared after the field is declared.
+ */
+#define DMLC_DECLARE_ALIAS(FieldName, AliasName)  manager->manager.AddAlias(#FieldName, #AliasName)
+
+/*!
+ * \brief Macro used to register parameter.
+ *
+ * This macro need to be put in a source file so that registeration only happens once.
+ * Refer to example code in Parameter for details
+ * \param PType the type of parameter struct.
+ * \sa Parameter
+ */
+#define DMLC_REGISTER_PARAMETER(PType)                                  \
+  ::dmlc::parameter::ParamManager *PType::__MANAGER__() {               \
+    static ::dmlc::parameter::ParamManagerSingleton<PType> inst(#PType); \
+    return &inst.manager;                                               \
+  }                                                                     \
+  static DMLC_ATTRIBUTE_UNUSED ::dmlc::parameter::ParamManager&         \
+  __make__ ## PType ## ParamManager__ =                                 \
+      (*PType::__MANAGER__())                                           \
+
+//! \endcond
+/*!
+ * \brief internal namespace for parameter management
+ * There is no need to use it directly in normal case
+ */
+namespace parameter {
+/*!
+ * \brief FieldAccessEntry interface to help manage the parameters
+ *  Each entry can be used to access one parameter in the Parameter struct.
+ *
+ *  This is an internal interface used that is used to manage parameters
+ */
+class FieldAccessEntry {
+ public:
+  FieldAccessEntry()
+      : has_default_(false), index_(0) {}
+  /*! \brief destructor */
+  virtual ~FieldAccessEntry() {}
+  /*!
+   * \brief set the default value.
+   * \param head the pointer to the head of the struct
+   * \throw error if no default is presented
+   */
+  virtual void SetDefault(void *head) const = 0;
+  /*!
+   * \brief set the parameter by string value
+   * \param head the pointer to the head of the struct
+   * \param value the value to be set
+   */
+  virtual void Set(void *head, const std::string &value) const = 0;
+  // check if value is OK
+  virtual void Check(void *head) const {}
+  /*!
+   * \brief get the string representation of value.
+   * \param head the pointer to the head of the struct
+   */
+  virtual std::string GetStringValue(void *head) const = 0;
+  /*!
+   * \brief Get field information
+   * \return the corresponding field information
+   */
+  virtual ParamFieldInfo GetFieldInfo() const = 0;
+
+ protected:
+  /*! \brief whether this parameter have default value */
+  bool has_default_;
+  /*! \brief positional index of parameter in struct */
+  size_t index_;
+  /*! \brief parameter key name */
+  std::string key_;
+  /*! \brief parameter type */
+  std::string type_;
+  /*! \brief description of the parameter */
+  std::string description_;
+  // internal offset of the field
+  ptrdiff_t offset_;
+  /*! \brief get pointer to parameter */
+  char* GetRawPtr(void* head) const {
+    return reinterpret_cast<char*>(head) + offset_;
+  }
+  /*!
+   * \brief print string representation of default value
+   * \parma os the stream to print the docstring to.
+   */
+  virtual void PrintDefaultValueString(std::ostream &os) const = 0;  // NOLINT(*)
+  // allow ParamManager to modify self
+  friend class ParamManager;
+};
+
+/*!
+ * \brief manager class to handle parameter structure for each type
+ *  An manager will be created for each parameter structure.
+ */
+class ParamManager {
+ public:
+  /*! \brief destructor */
+  ~ParamManager() {
+    for (size_t i = 0; i < entry_.size(); ++i) {
+      delete entry_[i];
+    }
+  }
+  /*!
+   * \brief find the access entry by parameter key
+   * \param key the key of the parameter.
+   * \return pointer to FieldAccessEntry, NULL if nothing is found.
+   */
+  inline FieldAccessEntry *Find(const std::string &key) const {
+    std::map<std::string, FieldAccessEntry*>::const_iterator it =
+        entry_map_.find(key);
+    if (it == entry_map_.end()) return NULL;
+    return it->second;
+  }
+  /*!
+   * \brief Set parameter by keyword arguments and default values.
+   * \param head head to the parameter field.
+   * \param begin begin iterator of original kwargs
+   * \param end end iterator of original kwargs
+   * \param unknown_args optional, used to hold unknown arguments
+   *          When it is specified, unknown arguments will be stored into here, instead of raise an error
+   * \tparam RandomAccessIterator iterator type
+   * \throw ParamError when there is unknown argument and unknown_args == NULL, or required argument is missing.
+   */
+  template<typename RandomAccessIterator>
+  inline void RunInit(void *head,
+                      RandomAccessIterator begin,
+                      RandomAccessIterator end,
+                      std::vector<std::pair<std::string, std::string> > *unknown_args,
+                      parameter::ParamInitOption option) const {
+    std::set<FieldAccessEntry*> selected_args;
+    RunUpdate(head, begin, end, option, unknown_args, &selected_args);
+    for (auto const& kv : entry_map_) {
+      if (selected_args.find(kv.second) == selected_args.cend()) {
+        kv.second->SetDefault(head);
+      }
+    }
+    for (std::map<std::string, FieldAccessEntry*>::const_iterator it = entry_map_.begin();
+         it != entry_map_.end(); ++it) {
+      if (selected_args.count(it->second) == 0) {
+        it->second->SetDefault(head);
+      }
+    }
+  }
+  /*!
+   * \brief Update parameters by keyword arguments.
+   *
+   * \tparam RandomAccessIterator iterator type
+   * \param head head to the parameter field.
+   * \param begin begin iterator of original kwargs
+   * \param end end iterator of original kwargs
+   * \param unknown_args optional, used to hold unknown arguments
+   *          When it is specified, unknown arguments will be stored into here, instead of raise an error
+   * \param selected_args The arguments used in update will be pushed into it, defaullt to nullptr.
+   * \throw ParamError when there is unknown argument and unknown_args == NULL, or required argument is missing.
+   */
+  template <typename RandomAccessIterator>
+  void RunUpdate(void *head,
+                 RandomAccessIterator begin,
+                 RandomAccessIterator end,
+                 parameter::ParamInitOption option,
+                 std::vector<std::pair<std::string, std::string> > *unknown_args,
+                 std::set<FieldAccessEntry*>* selected_args = nullptr) const {
+    for (RandomAccessIterator it = begin; it != end; ++it) {
+      if (FieldAccessEntry *e = Find(it->first)) {
+        e->Set(head, it->second);
+        e->Check(head);
+        if (selected_args) {
+          selected_args->insert(e);
+        }
+      } else {
+        if (unknown_args != NULL) {
+          unknown_args->push_back(*it);
+        } else {
+          if (option != parameter::kAllowUnknown) {
+            if (option == parameter::kAllowHidden &&
+                it->first.length() > 4 &&
+                it->first.find("__") == 0 &&
+                it->first.rfind("__") == it->first.length()-2) {
+              continue;
+            }
+            std::ostringstream os;
+            os << "Cannot find argument \'" << it->first << "\', Possible Arguments:\n";
+            os << "----------------\n";
+            PrintDocString(os);
+            throw dmlc::ParamError(os.str());
+          }
+        }
+      }
+    }
+  }
+  /*!
+   * \brief internal function to add entry to manager,
+   *  The manager will take ownership of the entry.
+   * \param key the key to the parameters
+   * \param e the pointer to the new entry.
+   */
+  inline void AddEntry(const std::string &key, FieldAccessEntry *e) {
+    e->index_ = entry_.size();
+    // TODO(bing) better error message
+    if (entry_map_.count(key) != 0) {
+      LOG(FATAL) << "key " << key << " has already been registered in " << name_;
+    }
+    entry_.push_back(e);
+    entry_map_[key] = e;
+  }
+  /*!
+   * \brief internal function to add entry to manager,
+   *  The manager will take ownership of the entry.
+   * \param key the key to the parameters
+   * \param e the pointer to the new entry.
+   */
+  inline void AddAlias(const std::string& field, const std::string& alias) {
+    if (entry_map_.count(field) == 0) {
+      LOG(FATAL) << "key " << field << " has not been registered in " << name_;
+    }
+    if (entry_map_.count(alias) != 0) {
+      LOG(FATAL) << "Alias " << alias << " has already been registered in " << name_;
+    }
+    entry_map_[alias] = entry_map_[field];
+  }
+  /*!
+   * \brief set the name of parameter manager
+   * \param name the name to set
+   */
+  inline void set_name(const std::string &name) {
+    name_ = name;
+  }
+  /*!
+   * \brief get field information of each field.
+   * \return field information
+   */
+  inline std::vector<ParamFieldInfo> GetFieldInfo() const {
+    std::vector<ParamFieldInfo> ret(entry_.size());
+    for (size_t i = 0; i < entry_.size(); ++i) {
+      ret[i] = entry_[i]->GetFieldInfo();
+    }
+    return ret;
+  }
+  /*!
+   * \brief Print readible docstring to ostream, add newline.
+   * \parma os the stream to print the docstring to.
+   */
+  inline void PrintDocString(std::ostream &os) const {  // NOLINT(*)
+    for (size_t i = 0; i < entry_.size(); ++i) {
+      ParamFieldInfo info = entry_[i]->GetFieldInfo();
+      os << info.name << " : " << info.type_info_str << '\n';
+      if (info.description.length() != 0) {
+        os << "    " << info.description << '\n';
+      }
+    }
+  }
+  /*!
+   * \brief Get internal parameters in vector of pairs.
+   * \param head the head of the struct.
+   * \param skip_default skip the values that equals default value.
+   * \return the parameter dictionary.
+   */
+  inline std::vector<std::pair<std::string, std::string> > GetDict(void * head) const {
+    std::vector<std::pair<std::string, std::string> > ret;
+    for (std::map<std::string, FieldAccessEntry*>::const_iterator
+            it = entry_map_.begin(); it != entry_map_.end(); ++it) {
+      ret.push_back(std::make_pair(it->first, it->second->GetStringValue(head)));
+    }
+    return ret;
+  }
+  /*!
+   * \brief Update the dictionary with values in parameter.
+   * \param head the head of the struct.
+   * \tparam Container The container type
+   * \return the parameter dictionary.
+   */
+  template<typename Container>
+  inline void UpdateDict(void * head, Container* dict) const {
+    for (std::map<std::string, FieldAccessEntry*>::const_iterator
+            it = entry_map_.begin(); it != entry_map_.end(); ++it) {
+      (*dict)[it->first] = it->second->GetStringValue(head);
+    }
+  }
+
+ private:
+  /*! \brief parameter struct name */
+  std::string name_;
+  /*! \brief positional list of entries */
+  std::vector<FieldAccessEntry*> entry_;
+  /*! \brief map from key to entry */
+  std::map<std::string, FieldAccessEntry*> entry_map_;
+};
+
+//! \cond Doxygen_Suppress
+
+// The following piece of code will be template heavy and less documented
+// singleton parameter manager for certain type, used for initialization
+template<typename PType>
+struct ParamManagerSingleton {
+  ParamManager manager;
+  explicit ParamManagerSingleton(const std::string &param_name) {
+    PType param;
+    manager.set_name(param_name);
+    param.__DECLARE__(this);
+  }
+};
+
+// Base class of FieldEntry
+// implement set_default
+template<typename TEntry, typename DType>
+class FieldEntryBase : public FieldAccessEntry {
+ public:
+  // entry type
+  typedef TEntry EntryType;
+  // implement set value
+  void Set(void *head, const std::string &value) const override {
+    std::istringstream is(value);
+    is >> this->Get(head);
+    if (!is.fail()) {
+      while (!is.eof()) {
+        int ch = is.get();
+        if (ch == EOF) {
+          is.clear(); break;
+        }
+        if (!isspace(ch)) {
+          is.setstate(std::ios::failbit); break;
+        }
+      }
+    }
+
+    if (is.fail()) {
+      std::ostringstream os;
+      os << "Invalid Parameter format for " << key_
+         << " expect " << type_ << " but value=\'" << value<< '\'';
+      throw dmlc::ParamError(os.str());
+    }
+  }
+
+  std::string GetStringValue(void *head) const override {
+    std::ostringstream os;
+    PrintValue(os, this->Get(head));
+    return os.str();
+  }
+  ParamFieldInfo GetFieldInfo() const override {
+    ParamFieldInfo info;
+    std::ostringstream os;
+    info.name = key_;
+    info.type = type_;
+    os << type_;
+    if (has_default_) {
+      os << ',' << " optional, default=";
+      PrintDefaultValueString(os);
+    } else {
+      os << ", required";
+    }
+    info.type_info_str = os.str();
+    info.description = description_;
+    return info;
+  }
+  // implement set head to default value
+  void SetDefault(void *head) const override {
+    if (!has_default_) {
+      std::ostringstream os;
+      os << "Required parameter " << key_
+         << " of " << type_ << " is not presented";
+      throw dmlc::ParamError(os.str());
+    } else {
+      this->Get(head) = default_value_;
+    }
+  }
+  // return reference of self as derived type
+  inline TEntry &self() {
+    return *(static_cast<TEntry*>(this));
+  }
+  // implement set_default
+  inline TEntry &set_default(const DType &default_value) {
+    default_value_ = default_value;
+    has_default_ = true;
+    // return self to allow chaining
+    return this->self();
+  }
+  // implement describe
+  inline TEntry &describe(const std::string &description) {
+    description_ = description;
+    // return self to allow chaining
+    return this->self();
+  }
+  // initialization function
+  inline void Init(const std::string &key,
+                   void *head, DType &ref) { // NOLINT(*)
+    this->key_ = key;
+    if (this->type_.length() == 0) {
+      this->type_ = dmlc::type_name<DType>();
+    }
+    this->offset_ = ((char*)&ref) - ((char*)head);  // NOLINT(*)
+  }
+
+ protected:
+  // print the value
+  virtual void PrintValue(std::ostream &os, DType value) const { // NOLINT(*)
+    os << value;
+  }
+  void PrintDefaultValueString(std::ostream &os) const override {  // NOLINT(*)
+    PrintValue(os, default_value_);
+  }
+  // get the internal representation of parameter
+  // for example if this entry corresponds field param.learning_rate
+  // then Get(&param) will return reference to param.learning_rate
+  inline DType &Get(void *head) const {
+    return *(DType*)this->GetRawPtr(head);  // NOLINT(*)
+  }
+  // default value of field
+  DType default_value_;
+};
+
+// parameter base for numeric types that have range
+template<typename TEntry, typename DType>
+class FieldEntryNumeric
+    : public FieldEntryBase<TEntry, DType> {
+ public:
+  FieldEntryNumeric()
+      : has_begin_(false), has_end_(false) {}
+  // implement set_range
+  virtual TEntry &set_range(DType begin, DType end) {
+    begin_ = begin; end_ = end;
+    has_begin_ = true; has_end_ = true;
+    return this->self();
+  }
+  // implement set_range
+  virtual TEntry &set_lower_bound(DType begin) {
+    begin_ = begin; has_begin_ = true;
+    return this->self();
+  }
+  // consistency check for numeric ranges
+  virtual void Check(void *head) const {
+    FieldEntryBase<TEntry, DType>::Check(head);
+    DType v = this->Get(head);
+    if (has_begin_ && has_end_) {
+      if (v < begin_ || v > end_) {
+        std::ostringstream os;
+        os << "value " << v << " for Parameter " << this->key_
+           << " exceed bound [" << begin_ << ',' << end_ <<']' << '\n';
+        os << this->key_ << ": " << this->description_;
+        throw dmlc::ParamError(os.str());
+      }
+    } else if (has_begin_ && v < begin_) {
+        std::ostringstream os;
+        os << "value " << v << " for Parameter " << this->key_
+           << " should be greater equal to " << begin_ << '\n';
+        os << this->key_ << ": " << this->description_;
+        throw dmlc::ParamError(os.str());
+    } else if (has_end_ && v > end_) {
+        std::ostringstream os;
+        os << "value " << v << " for Parameter " << this->key_
+           << " should be smaller equal to " << end_ << '\n';
+        os << this->key_ << ": " << this->description_;
+        throw dmlc::ParamError(os.str());
+    }
+  }
+
+ protected:
+  // whether it have begin and end range
+  bool has_begin_, has_end_;
+  // data bound
+  DType begin_, end_;
+};
+
+/*!
+ * \brief FieldEntry defines parsing and checking behavior of DType.
+ * This class can be specialized to implement specific behavior of more settings.
+ * \tparam DType the data type of the entry.
+ */
+template<typename DType>
+class FieldEntry :
+      public IfThenElseType<dmlc::is_arithmetic<DType>::value,
+                            FieldEntryNumeric<FieldEntry<DType>, DType>,
+                            FieldEntryBase<FieldEntry<DType>, DType> >::Type {
+};
+
+// specialize define for int(enum)
+template<>
+class FieldEntry<int>
+    : public FieldEntryNumeric<FieldEntry<int>, int> {
+ public:
+  // construct
+  FieldEntry<int>() : is_enum_(false) {}
+  // parent
+  typedef FieldEntryNumeric<FieldEntry<int>, int> Parent;
+  // override set
+  virtual void Set(void *head, const std::string &value) const {
+    if (is_enum_) {
+      std::map<std::string, int>::const_iterator it = enum_map_.find(value);
+      std::ostringstream os;
+      if (it == enum_map_.end()) {
+        os << "Invalid Input: \'" << value;
+        os << "\', valid values are: ";
+        PrintEnums(os);
+        throw dmlc::ParamError(os.str());
+      } else {
+        os << it->second;
+        Parent::Set(head, os.str());
+      }
+    } else {
+      Parent::Set(head, value);
+    }
+  }
+  virtual ParamFieldInfo GetFieldInfo() const {
+    if (is_enum_) {
+      ParamFieldInfo info;
+      std::ostringstream os;
+      info.name = key_;
+      info.type = type_;
+      PrintEnums(os);
+      if (has_default_) {
+        os << ',' << "optional, default=";
+        PrintDefaultValueString(os);
+      } else {
+        os << ", required";
+      }
+      info.type_info_str = os.str();
+      info.description = description_;
+      return info;
+    } else {
+      return Parent::GetFieldInfo();
+    }
+  }
+  // add enum
+  inline FieldEntry<int> &add_enum(const std::string &key, int value) {
+    if ((enum_map_.size() != 0 && enum_map_.count(key) != 0) || \
+        enum_back_map_.count(value) != 0) {
+      std::ostringstream os;
+      os << "Enum " << "(" << key << ": " << value << " exisit!" << ")\n";
+      os << "Enums: ";
+      for (std::map<std::string, int>::const_iterator it = enum_map_.begin();
+           it != enum_map_.end(); ++it) {
+        os << "(" << it->first << ": " << it->second << "), ";
+      }
+      throw dmlc::ParamError(os.str());
+    }
+    enum_map_[key] = value;
+    enum_back_map_[value] = key;
+    is_enum_ = true;
+    return this->self();
+  }
+
+ protected:
+  // enum flag
+  bool is_enum_;
+  // enum map
+  std::map<std::string, int> enum_map_;
+  // enum map
+  std::map<int, std::string> enum_back_map_;
+  // override print behavior
+  virtual void PrintDefaultValueString(std::ostream &os) const { // NOLINT(*)
+    os << '\'';
+    PrintValue(os, default_value_);
+    os << '\'';
+  }
+  // override print default
+  virtual void PrintValue(std::ostream &os, int value) const {  // NOLINT(*)
+    if (is_enum_) {
+      CHECK_NE(enum_back_map_.count(value), 0U)
+          << "Value not found in enum declared";
+      os << enum_back_map_.at(value);
+    } else {
+      os << value;
+    }
+  }
+
+
+ private:
+  inline void PrintEnums(std::ostream &os) const {  // NOLINT(*)
+    os << '{';
+    for (std::map<std::string, int>::const_iterator
+             it = enum_map_.begin(); it != enum_map_.end(); ++it) {
+      if (it != enum_map_.begin()) {
+        os << ", ";
+      }
+      os << "\'" << it->first << '\'';
+    }
+    os << '}';
+  }
+};
+
+
+// specialize define for optional<int>(enum)
+template<>
+class FieldEntry<optional<int> >
+    : public FieldEntryBase<FieldEntry<optional<int> >, optional<int> > {
+ public:
+  // construct
+  FieldEntry<optional<int> >() : is_enum_(false) {}
+  // parent
+  typedef FieldEntryBase<FieldEntry<optional<int> >, optional<int> > Parent;
+  // override set
+  virtual void Set(void *head, const std::string &value) const {
+    if (is_enum_ && value != "None") {
+      std::map<std::string, int>::const_iterator it = enum_map_.find(value);
+      std::ostringstream os;
+      if (it == enum_map_.end()) {
+        os << "Invalid Input: \'" << value;
+        os << "\', valid values are: ";
+        PrintEnums(os);
+        throw dmlc::ParamError(os.str());
+      } else {
+        os << it->second;
+        Parent::Set(head, os.str());
+      }
+    } else {
+      Parent::Set(head, value);
+    }
+  }
+  virtual ParamFieldInfo GetFieldInfo() const {
+    if (is_enum_) {
+      ParamFieldInfo info;
+      std::ostringstream os;
+      info.name = key_;
+      info.type = type_;
+      PrintEnums(os);
+      if (has_default_) {
+        os << ',' << "optional, default=";
+        PrintDefaultValueString(os);
+      } else {
+        os << ", required";
+      }
+      info.type_info_str = os.str();
+      info.description = description_;
+      return info;
+    } else {
+      return Parent::GetFieldInfo();
+    }
+  }
+  // add enum
+  inline FieldEntry<optional<int> > &add_enum(const std::string &key, int value) {
+    CHECK_NE(key, "None") << "None is reserved for empty optional<int>";
+    if ((enum_map_.size() != 0 && enum_map_.count(key) != 0) || \
+        enum_back_map_.count(value) != 0) {
+      std::ostringstream os;
+      os << "Enum " << "(" << key << ": " << value << " exisit!" << ")\n";
+      os << "Enums: ";
+      for (std::map<std::string, int>::const_iterator it = enum_map_.begin();
+           it != enum_map_.end(); ++it) {
+        os << "(" << it->first << ": " << it->second << "), ";
+      }
+      throw dmlc::ParamError(os.str());
+    }
+    enum_map_[key] = value;
+    enum_back_map_[value] = key;
+    is_enum_ = true;
+    return this->self();
+  }
+
+ protected:
+  // enum flag
+  bool is_enum_;
+  // enum map
+  std::map<std::string, int> enum_map_;
+  // enum map
+  std::map<int, std::string> enum_back_map_;
+  // override print behavior
+  virtual void PrintDefaultValueString(std::ostream &os) const { // NOLINT(*)
+    os << '\'';
+    PrintValue(os, default_value_);
+    os << '\'';
+  }
+  // override print default
+  virtual void PrintValue(std::ostream &os, optional<int> value) const {  // NOLINT(*)
+    if (is_enum_) {
+      if (!value) {
+        os << "None";
+      } else {
+        CHECK_NE(enum_back_map_.count(value.value()), 0U)
+            << "Value not found in enum declared";
+        os << enum_back_map_.at(value.value());
+      }
+    } else {
+      os << value;
+    }
+  }
+
+
+ private:
+  inline void PrintEnums(std::ostream &os) const {  // NOLINT(*)
+    os << "{None";
+    for (std::map<std::string, int>::const_iterator
+             it = enum_map_.begin(); it != enum_map_.end(); ++it) {
+      os << ", ";
+      os << "\'" << it->first << '\'';
+    }
+    os << '}';
+  }
+};
+
+// specialize define for string
+template<>
+class FieldEntry<std::string>
+    : public FieldEntryBase<FieldEntry<std::string>, std::string> {
+ public:
+  // parent class
+  typedef FieldEntryBase<FieldEntry<std::string>, std::string> Parent;
+  // override set
+  virtual void Set(void *head, const std::string &value) const {
+    this->Get(head) = value;
+  }
+  // override print default
+  virtual void PrintDefaultValueString(std::ostream &os) const {  // NOLINT(*)
+    os << '\'' << default_value_ << '\'';
+  }
+};
+
+// specialize define for bool
+template<>
+class FieldEntry<bool>
+    : public FieldEntryBase<FieldEntry<bool>, bool> {
+ public:
+  // parent class
+  typedef FieldEntryBase<FieldEntry<bool>, bool> Parent;
+  // override set
+  virtual void Set(void *head, const std::string &value) const {
+    std::string lower_case; lower_case.resize(value.length());
+    std::transform(value.begin(), value.end(), lower_case.begin(), ::tolower);
+    bool &ref = this->Get(head);
+    if (lower_case == "true") {
+      ref = true;
+    } else if (lower_case == "false") {
+      ref = false;
+    } else if (lower_case == "1") {
+      ref = true;
+    } else if (lower_case == "0") {
+      ref = false;
+    } else {
+      std::ostringstream os;
+      os << "Invalid Parameter format for " << key_
+         << " expect " << type_ << " but value=\'" << value<< '\'';
+      throw dmlc::ParamError(os.str());
+    }
+  }
+
+ protected:
+  // print default string
+  virtual void PrintValue(std::ostream &os, bool value) const {  // NOLINT(*)
+    os << static_cast<int>(value);
+  }
+};
+
+
+// specialize define for float. Uses stof for platform independent handling of
+// INF, -INF, NAN, etc.
+#if DMLC_USE_CXX11
+template <>
+class FieldEntry<float> : public FieldEntryNumeric<FieldEntry<float>, float> {
+ public:
+  // parent
+  typedef FieldEntryNumeric<FieldEntry<float>, float> Parent;
+  // override set
+  virtual void Set(void *head, const std::string &value) const {
+    size_t pos = 0;  // number of characters processed by dmlc::stof()
+    try {
+      this->Get(head) = dmlc::stof(value, &pos);
+    } catch (const std::invalid_argument &) {
+      std::ostringstream os;
+      os << "Invalid Parameter format for " << key_ << " expect " << type_
+         << " but value=\'" << value << '\'';
+      throw dmlc::ParamError(os.str());
+    } catch (const std::out_of_range&) {
+      std::ostringstream os;
+      os << "Out of range value for " << key_ << ", value=\'" << value << '\'';
+      throw dmlc::ParamError(os.str());
+    }
+    CHECK_LE(pos, value.length());  // just in case
+    if (pos < value.length()) {
+      std::ostringstream os;
+      os << "Some trailing characters could not be parsed: \'"
+         << value.substr(pos) << "\'";
+      throw dmlc::ParamError(os.str());
+    }
+  }
+
+ protected:
+  // print the value
+  virtual void PrintValue(std::ostream &os, float value) const {  // NOLINT(*)
+    os << std::setprecision(std::numeric_limits<float>::max_digits10) << value;
+  }
+};
+
+// specialize define for double. Uses stod for platform independent handling of
+// INF, -INF, NAN, etc.
+template <>
+class FieldEntry<double>
+    : public FieldEntryNumeric<FieldEntry<double>, double> {
+ public:
+  // parent
+  typedef FieldEntryNumeric<FieldEntry<double>, double> Parent;
+  // override set
+  virtual void Set(void *head, const std::string &value) const {
+    size_t pos = 0;  // number of characters processed by dmlc::stod()
+    try {
+      this->Get(head) = dmlc::stod(value, &pos);
+    } catch (const std::invalid_argument &) {
+      std::ostringstream os;
+      os << "Invalid Parameter format for " << key_ << " expect " << type_
+         << " but value=\'" << value << '\'';
+      throw dmlc::ParamError(os.str());
+    } catch (const std::out_of_range&) {
+      std::ostringstream os;
+      os << "Out of range value for " << key_ << ", value=\'" << value << '\'';
+      throw dmlc::ParamError(os.str());
+    }
+    CHECK_LE(pos, value.length());  // just in case
+    if (pos < value.length()) {
+      std::ostringstream os;
+      os << "Some trailing characters could not be parsed: \'"
+         << value.substr(pos) << "\'";
+      throw dmlc::ParamError(os.str());
+    }
+  }
+
+ protected:
+  // print the value
+  virtual void PrintValue(std::ostream &os, double value) const {  // NOLINT(*)
+    os << std::setprecision(std::numeric_limits<double>::max_digits10) << value;
+  }
+};
+#endif  // DMLC_USE_CXX11
+
+}  // namespace parameter
+//! \endcond
+
+// implement GetEnv
+template<typename ValueType>
+inline ValueType GetEnv(const char *key,
+                        ValueType default_value) {
+  const char *val = getenv(key);
+  // On some implementations, if the var is set to a blank string (i.e. "FOO="), then
+  // a blank string will be returned instead of NULL.  In order to be consistent, if
+  // the environment var is a blank string, then also behave as if a null was returned.
+  if (val == nullptr || !*val) {
+    return default_value;
+  }
+  ValueType ret;
+  parameter::FieldEntry<ValueType> e;
+  e.Init(key, &ret, ret);
+  e.Set(&ret, val);
+  return ret;
+}
+
+// implement SetEnv
+template<typename ValueType>
+inline void SetEnv(const char *key,
+                   ValueType value) {
+  parameter::FieldEntry<ValueType> e;
+  e.Init(key, &value, value);
+#ifdef _WIN32
+  _putenv_s(key, e.GetStringValue(&value).c_str());
+#else
+  setenv(key, e.GetStringValue(&value).c_str(), 1);
+#endif  // _WIN32
+}
+}  // namespace dmlc
+#endif  // DMLC_PARAMETER_H_
diff --git a/darknet_drp_ros/include/dmlc/recordio.h b/darknet_drp_ros/include/dmlc/recordio.h
new file mode 100644
index 0000000..6220780
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/recordio.h
@@ -0,0 +1,196 @@
+/*!
+ *  Copyright (c) 2015 by Contributors
+ * \file recordio.h
+ * \brief recordio that is able to pack binary data into a splittable
+ *   format, useful to exchange data in binary serialization,
+ *   such as binary raw data or protobuf
+ */
+#ifndef DMLC_RECORDIO_H_
+#define DMLC_RECORDIO_H_
+#include <cstring>
+#include <string>
+#include "./io.h"
+#include "./logging.h"
+
+namespace dmlc {
+/*!
+ * \brief writer of binary recordio
+ *  binary format for recordio
+ *  recordio format: magic lrecord data pad
+ *
+ *  - magic is magic number
+ *  - pad is simply a padding space to make record align to 4 bytes
+ *  - lrecord encodes length and continue bit
+ *     - data.length() = (lrecord & (1U<<29U - 1));
+ *     - cflag == (lrecord >> 29U) & 7;
+ *
+ *  cflag was used to handle (rare) special case when magic number
+ *  occured in the data sequence.
+ *
+ *  In such case, the data is splitted into multiple records by
+ *  the cells of magic number
+ *
+ *  (1) cflag == 0: this is a complete record;
+ *  (2) cflag == 1: start of a multiple-rec;
+ *      cflag == 2: middle of multiple-rec;
+ *      cflag == 3: end of multiple-rec
+ */
+class RecordIOWriter {
+ public:
+  /*!
+   * \brief magic number of recordio
+   * note: (kMagic >> 29U) & 7 > 3
+   * this ensures lrec will not be kMagic
+   */
+  static const uint32_t kMagic = 0xced7230a;
+  /*!
+   * \brief encode the lrecord
+   * \param cflag cflag part of the lrecord
+   * \param length length part of lrecord
+   * \return the encoded data
+   */
+  inline static uint32_t EncodeLRec(uint32_t cflag, uint32_t length) {
+    return (cflag << 29U) | length;
+  }
+  /*!
+   * \brief decode the flag part of lrecord
+   * \param rec the lrecord
+   * \return the flag
+   */
+  inline static uint32_t DecodeFlag(uint32_t rec) {
+    return (rec >> 29U) & 7U;
+  }
+  /*!
+   * \brief decode the length part of lrecord
+   * \param rec the lrecord
+   * \return the length
+   */
+  inline static uint32_t DecodeLength(uint32_t rec) {
+    return rec & ((1U << 29U) - 1U);
+  }
+  /*!
+   * \brief constructor
+   * \param stream the stream to be constructed
+   */
+  explicit RecordIOWriter(Stream *stream)
+      : stream_(stream), seek_stream_(dynamic_cast<SeekStream*>(stream)),
+        except_counter_(0) {
+    CHECK(sizeof(uint32_t) == 4) << "uint32_t needs to be 4 bytes";
+  }
+  /*!
+   * \brief write record to the stream
+   * \param buf the buffer of memory region
+   * \param size the size of record to write out
+   */
+  void WriteRecord(const void *buf, size_t size);
+  /*!
+   * \brief write record to the stream
+   * \param data the data to write out
+   */
+  inline void WriteRecord(const std::string &data) {
+    this->WriteRecord(data.c_str(), data.length());
+  }
+  /*!
+   * \return number of exceptions(occurance of magic number)
+   *   during the writing process
+   */
+  inline size_t except_counter(void) const {
+    return except_counter_;
+  }
+
+  /*! \brief tell the current position of the input stream */
+  inline size_t Tell(void) {
+    CHECK(seek_stream_ != NULL) << "The input stream is not seekable";
+    return seek_stream_->Tell();
+  }
+
+ private:
+  /*! \brief output stream */
+  Stream *stream_;
+  /*! \brief seekable stream */
+  SeekStream *seek_stream_;
+  /*! \brief counts the number of exceptions */
+  size_t except_counter_;
+};
+/*!
+ * \brief reader of binary recordio to reads in record from stream
+ * \sa RecordIOWriter
+ */
+class RecordIOReader {
+ public:
+  /*!
+   * \brief constructor
+   * \param stream the stream to be constructed
+   */
+  explicit RecordIOReader(Stream *stream)
+      : stream_(stream), seek_stream_(dynamic_cast<SeekStream*>(stream)),
+        end_of_stream_(false) {
+    CHECK(sizeof(uint32_t) == 4) << "uint32_t needs to be 4 bytes";
+  }
+  /*!
+   * \brief read next complete record from stream
+   * \param out_rec used to store output record in string
+   * \return true of read was successful, false if end of stream was reached
+   */
+  bool NextRecord(std::string *out_rec);
+
+  /*! \brief seek to certain position of the input stream */
+  inline void Seek(size_t pos) {
+    CHECK(seek_stream_ != NULL) << "The input stream is not seekable";
+    seek_stream_->Seek(pos);
+  }
+
+  /*! \brief tell the current position of the input stream */
+  inline size_t Tell(void) {
+    CHECK(seek_stream_ != NULL) << "The input stream is not seekable";
+    return seek_stream_->Tell();
+  }
+
+ private:
+  /*! \brief output stream */
+  Stream *stream_;
+  SeekStream *seek_stream_;
+  /*! \brief whether we are at end of stream */
+  bool end_of_stream_;
+};
+
+/*!
+ * \brief reader of binary recordio from Blob returned by InputSplit
+ *  This class divides the blob into several independent parts specified by caller,
+ *  and read from one segment.
+ *  The part reading can be used together with InputSplit::NextChunk for
+ *  multi-threaded parsing(each thread take a RecordIOChunkReader)
+ *
+ * \sa RecordIOWriter, InputSplit
+ */
+class RecordIOChunkReader {
+ public:
+  /*!
+   * \brief constructor
+   * \param chunk source data returned by InputSplit
+   * \param part_index which part we want to reado
+   * \param num_parts number of total segments
+   */
+  explicit RecordIOChunkReader(InputSplit::Blob chunk,
+                               unsigned part_index = 0,
+                               unsigned num_parts = 1);
+  /*!
+   * \brief read next complete record from stream
+   *   the blob contains the memory content
+   *   NOTE: this function is not threadsafe, use one
+   *   RecordIOChunkReader per thread
+   * \param out_rec used to store output blob, the header is already
+   *        removed and out_rec only contains the memory content
+   * \return true of read was successful, false if end was reached
+   */
+  bool NextRecord(InputSplit::Blob *out_rec);
+
+ private:
+  /*! \brief internal temporal data */
+  std::string temp_;
+  /*! \brief internal data pointer */
+  char *pbegin_, *pend_;
+};
+
+}  // namespace dmlc
+#endif  // DMLC_RECORDIO_H_
diff --git a/darknet_drp_ros/include/dmlc/registry.h b/darknet_drp_ros/include/dmlc/registry.h
new file mode 100644
index 0000000..249088b
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/registry.h
@@ -0,0 +1,310 @@
+/*!
+ *  Copyright (c) 2015 by Contributors
+ * \file registry.h
+ * \brief Registry utility that helps to build registry singletons.
+ */
+#ifndef DMLC_REGISTRY_H_
+#define DMLC_REGISTRY_H_
+
+#include <map>
+#include <string>
+#include <vector>
+#include "./base.h"
+#include "./logging.h"
+#include "./parameter.h"
+#include "./type_traits.h"
+
+namespace dmlc {
+/*!
+ * \brief Registry class.
+ *  Registry can be used to register global singletons.
+ *  The most commonly use case are factory functions.
+ *
+ * \tparam EntryType Type of Registry entries,
+ *     EntryType need to name a name field.
+ */
+template<typename EntryType>
+class Registry {
+ public:
+  /*! \return list of entries in the registry(excluding alias) */
+  inline static const std::vector<const EntryType*>& List() {
+    return Get()->const_list_;
+  }
+  /*! \return list all names registered in the registry, including alias */
+  inline static std::vector<std::string> ListAllNames() {
+    const std::map<std::string, EntryType*> &fmap = Get()->fmap_;
+    typename std::map<std::string, EntryType*>::const_iterator p;
+    std::vector<std::string> names;
+    for (p = fmap.begin(); p !=fmap.end(); ++p) {
+      names.push_back(p->first);
+    }
+    return names;
+  }
+  /*!
+   * \brief Find the entry with corresponding name.
+   * \param name name of the function
+   * \return the corresponding function, can be NULL
+   */
+  inline static const EntryType *Find(const std::string &name) {
+    const std::map<std::string, EntryType*> &fmap = Get()->fmap_;
+    typename std::map<std::string, EntryType*>::const_iterator p = fmap.find(name);
+    if (p != fmap.end()) {
+      return p->second;
+    } else {
+      return NULL;
+    }
+  }
+  /*!
+   * \brief Add alias to the key_name
+   * \param key_name The original entry key
+   * \param alias The alias key.
+   */
+  inline void AddAlias(const std::string& key_name,
+                       const std::string& alias) {
+    EntryType* e = fmap_.at(key_name);
+    if (fmap_.count(alias)) {
+      CHECK_EQ(e, fmap_.at(alias))
+          << "Trying to register alias " << alias << " for key " << key_name
+          << " but " << alias << " is already taken";
+    } else {
+      fmap_[alias] = e;
+    }
+  }
+  /*!
+   * \brief Internal function to register a name function under name.
+   * \param name name of the function
+   * \return ref to the registered entry, used to set properties
+   */
+  inline EntryType &__REGISTER__(const std::string& name) {
+    std::lock_guard<std::mutex> guard(registering_mutex);
+    if (fmap_.count(name) > 0) {
+      return *fmap_[name];
+    }
+    EntryType *e = new EntryType();
+    e->name = name;
+    fmap_[name] = e;
+    const_list_.push_back(e);
+    entry_list_.push_back(e);
+    return *e;
+  }
+  /*!
+   * \brief Internal function to either register or get registered entry
+   * \param name name of the function
+   * \return ref to the registered entry, used to set properties
+   */
+  inline EntryType &__REGISTER_OR_GET__(const std::string& name) {
+    if (fmap_.count(name) == 0) {
+      return __REGISTER__(name);
+    } else {
+      return *fmap_.at(name);
+    }
+  }
+  /*!
+   * \brief get a singleton of the Registry.
+   *  This function can be defined by DMLC_REGISTRY_ENABLE.
+   * \return get a singleton
+   */
+  static Registry *Get();
+
+ private:
+  /*! \brief list of entry types */
+  std::vector<EntryType*> entry_list_;
+  /*! \brief list of entry types */
+  std::vector<const EntryType*> const_list_;
+  /*! \brief map of name->function */
+  std::map<std::string, EntryType*> fmap_;
+  /*! \brief lock guarding the registering*/
+  std::mutex registering_mutex;
+  /*! \brief constructor */
+  Registry() {}
+  /*! \brief destructor */
+  ~Registry() {
+    for (size_t i = 0; i < entry_list_.size(); ++i) {
+      delete entry_list_[i];
+    }
+  }
+};
+
+/*!
+ * \brief Common base class for function registry.
+ *
+ * \code
+ *  // This example demonstrates how to use Registry to create a factory of trees.
+ *  struct TreeFactory :
+ *      public FunctionRegEntryBase<TreeFactory, std::function<Tree*()> > {
+ *  };
+ *
+ *  // in a independent cc file
+ *  namespace dmlc {
+ *  DMLC_REGISTRY_ENABLE(TreeFactory);
+ *  }
+ *  // register binary tree constructor into the registry.
+ *  DMLC_REGISTRY_REGISTER(TreeFactory, TreeFactory, BinaryTree)
+ *      .describe("Constructor of BinaryTree")
+ *      .set_body([]() { return new BinaryTree(); });
+ * \endcode
+ *
+ * \tparam EntryType The type of subclass that inheritate the base.
+ * \tparam FunctionType The function type this registry is registerd.
+ */
+template<typename EntryType, typename FunctionType>
+class FunctionRegEntryBase {
+ public:
+  /*! \brief name of the entry */
+  std::string name;
+  /*! \brief description of the entry */
+  std::string description;
+  /*! \brief additional arguments to the factory function */
+  std::vector<ParamFieldInfo> arguments;
+  /*! \brief Function body to create ProductType */
+  FunctionType body;
+  /*! \brief Return type of the function */
+  std::string return_type;
+
+  /*!
+   * \brief Set the function body.
+   * \param body Function body to set.
+   * \return reference to self.
+   */
+  inline EntryType &set_body(FunctionType body) {
+    this->body = body;
+    return this->self();
+  }
+  /*!
+   * \brief Describe the function.
+   * \param description The description of the factory function.
+   * \return reference to self.
+   */
+  inline EntryType &describe(const std::string &description) {
+    this->description = description;
+    return this->self();
+  }
+  /*!
+   * \brief Add argument information to the function.
+   * \param name Name of the argument.
+   * \param type Type of the argument.
+   * \param description Description of the argument.
+   * \return reference to self.
+   */
+  inline EntryType &add_argument(const std::string &name,
+                                 const std::string &type,
+                                 const std::string &description) {
+    ParamFieldInfo info;
+    info.name = name;
+    info.type = type;
+    info.type_info_str = info.type;
+    info.description = description;
+    arguments.push_back(info);
+    return this->self();
+  }
+  /*!
+   * \brief Append list if arguments to the end.
+   * \param args Additional list of arguments.
+   * \return reference to self.
+   */
+  inline EntryType &add_arguments(const std::vector<ParamFieldInfo> &args) {
+    arguments.insert(arguments.end(), args.begin(), args.end());
+    return this->self();
+  }
+  /*!
+  * \brief Set the return type.
+  * \param type Return type of the function, could be Symbol or Symbol[]
+  * \return reference to self.
+  */
+  inline EntryType &set_return_type(const std::string &type) {
+    return_type = type;
+    return this->self();
+  }
+
+ protected:
+  /*!
+   * \return reference of self as derived type
+   */
+  inline EntryType &self() {
+    return *(static_cast<EntryType*>(this));
+  }
+};
+
+/*!
+ * \def DMLC_REGISTRY_ENABLE
+ * \brief Macro to enable the registry of EntryType.
+ * This macro must be used under namespace dmlc, and only used once in cc file.
+ * \param EntryType Type of registry entry
+ */
+#define DMLC_REGISTRY_ENABLE(EntryType)                                 \
+  template<>                                                            \
+  Registry<EntryType > *Registry<EntryType >::Get() {                   \
+    static Registry<EntryType > inst;                                   \
+    return &inst;                                                       \
+  }                                                                     \
+
+/*!
+ * \brief Generic macro to register an EntryType
+ *  There is a complete example in FactoryRegistryEntryBase.
+ *
+ * \param EntryType The type of registry entry.
+ * \param EntryTypeName The typename of EntryType, must do not contain namespace :: .
+ * \param Name The name to be registered.
+ * \sa FactoryRegistryEntryBase
+ */
+#define DMLC_REGISTRY_REGISTER(EntryType, EntryTypeName, Name)          \
+  static DMLC_ATTRIBUTE_UNUSED EntryType & __make_ ## EntryTypeName ## _ ## Name ## __ = \
+      ::dmlc::Registry<EntryType>::Get()->__REGISTER__(#Name)           \
+
+/*!
+ * \brief (Optional) Declare a file tag to current file that contains object registrations.
+ *
+ *  This will declare a dummy function that will be called by register file to
+ *  incur a link dependency.
+ *
+ * \param UniqueTag The unique tag used to represent.
+ * \sa DMLC_REGISTRY_LINK_TAG
+ */
+#define DMLC_REGISTRY_FILE_TAG(UniqueTag)                                \
+  int __dmlc_registry_file_tag_ ## UniqueTag ## __() { return 0; }
+
+/*!
+ * \brief (Optional) Force link to all the objects registered in file tag.
+ *
+ *  This macro must be used in the same file as DMLC_REGISTRY_ENABLE and
+ *  in the same namespace as DMLC_REGISTRY_FILE_TAG
+ *
+ *  DMLC_REGISTRY_FILE_TAG and DMLC_REGISTRY_LINK_TAG are optional macros for registration.
+ *  They are used to encforce link of certain file into during static linking.
+ *
+ *  This is mainly used to solve problem during statically link a library which contains backward registration.
+ *  Specifically, this avoids the objects in these file tags to be ignored by compiler.
+ *
+ *  For dynamic linking, this problem won't occur as everything is loaded by default.
+ *
+ *  Use of this is optional as it will create an error when a file tag do not exist.
+ *  An alternative solution is always ask user to enable --whole-archieve during static link.
+ *
+ * \code
+ * // in file objective_registry.cc
+ * DMLC_REGISTRY_ENABLE(MyObjective);
+ * DMLC_REGISTRY_LINK_TAG(regression_op);
+ * DMLC_REGISTRY_LINK_TAG(rank_op);
+ *
+ * // in file regression_op.cc
+ * // declare tag of this file.
+ * DMLC_REGISTRY_FILE_TAG(regression_op);
+ * DMLC_REGISTRY_REGISTER(MyObjective, logistic_reg, logistic_reg);
+ * // ...
+ *
+ * // in file rank_op.cc
+ * // declare tag of this file.
+ * DMLC_REGISTRY_FILE_TAG(rank_op);
+ * DMLC_REGISTRY_REGISTER(MyObjective, pairwiserank, pairwiserank);
+ *
+ * \endcode
+ *
+ * \param UniqueTag The unique tag used to represent.
+ * \sa DMLC_REGISTRY_ENABLE, DMLC_REGISTRY_FILE_TAG
+ */
+#define DMLC_REGISTRY_LINK_TAG(UniqueTag)                                \
+  int __dmlc_registry_file_tag_ ## UniqueTag ## __();                   \
+  static int DMLC_ATTRIBUTE_UNUSED __reg_file_tag_ ## UniqueTag ## __ = \
+      __dmlc_registry_file_tag_ ## UniqueTag ## __();
+}  // namespace dmlc
+#endif  // DMLC_REGISTRY_H_
diff --git a/darknet_drp_ros/include/dmlc/serializer.h b/darknet_drp_ros/include/dmlc/serializer.h
new file mode 100644
index 0000000..4bede4a
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/serializer.h
@@ -0,0 +1,410 @@
+/*!
+ *  Copyright (c) 2015 by Contributors
+ * \file serializer.h
+ * \brief serializer template class that helps serialization.
+ *  This file do not need to be directly used by most user.
+ */
+#ifndef DMLC_SERIALIZER_H_
+#define DMLC_SERIALIZER_H_
+
+#include <vector>
+#include <string>
+#include <map>
+#include <set>
+#include <list>
+#include <deque>
+#include <utility>
+
+#include "./base.h"
+#include "./io.h"
+#include "./logging.h"
+#include "./type_traits.h"
+#include "./endian.h"
+
+#if DMLC_USE_CXX11
+#include <unordered_map>
+#include <unordered_set>
+#endif
+
+namespace dmlc {
+/*! \brief internal namespace for serializers */
+namespace serializer {
+/*!
+ * \brief generic serialization handler
+ * \tparam T the type to be serialized
+ * \tparam need_endian_swap Whether use little endian
+ */
+template<typename T>
+struct Handler;
+
+//! \cond Doxygen_Suppress
+/*!
+ * \brief Serializer that redirect calls by condition
+ * \tparam cond the condition
+ * \tparam Then the serializer used for then condition
+ * \tparam Else the serializer used for else condition
+ * \tparam Return the type of data the serializer handles
+ */
+template<bool cond, typename Then, typename Else, typename Return>
+struct IfThenElse;
+
+template<typename Then, typename Else, typename T>
+struct IfThenElse<true, Then, Else, T> {
+  inline static void Write(Stream *strm, const T &data) {
+    Then::Write(strm, data);
+  }
+  inline static bool Read(Stream *strm, T *data) {
+    return Then::Read(strm, data);
+  }
+};
+template<typename Then, typename Else, typename T>
+struct IfThenElse<false, Then, Else, T> {
+  inline static void Write(Stream *strm, const T &data) {
+    Else::Write(strm, data);
+  }
+  inline static bool Read(Stream *strm, T *data) {
+    return Else::Read(strm, data);
+  }
+};
+
+/*! \brief Serializer for POD(plain-old-data) data */
+template<typename T>
+struct NativePODHandler {
+  inline static void Write(Stream *strm, const T &data) {
+    strm->Write(&data, sizeof(T));
+  }
+  inline static bool Read(Stream *strm, T *dptr) {
+    return strm->Read((void*)dptr, sizeof(T)) == sizeof(T);  // NOLINT(*)
+  }
+};
+
+/*! \brief Serializer for arithmetic data, handle endianness */
+template<typename T>
+struct ArithmeticHandler {
+  inline static void Write(Stream *strm, const T &data) {
+    if (DMLC_IO_NO_ENDIAN_SWAP) {
+      strm->Write(&data, sizeof(T));
+    } else {
+      T copy = data;
+      ByteSwap(&copy, sizeof(T), 1);
+      strm->Write(&copy, sizeof(T));
+    }
+  }
+  inline static bool Read(Stream *strm, T *dptr) {
+    bool ret = strm->Read((void*)dptr, sizeof(T)) == sizeof(T);  // NOLINT(*)
+    if (!DMLC_IO_NO_ENDIAN_SWAP) {
+      ByteSwap(dptr, sizeof(T), 1);
+    }
+    return ret;
+  }
+};
+
+// serializer for class that have save/load function
+template<typename T>
+struct SaveLoadClassHandler {
+  inline static void Write(Stream *strm, const T &data) {
+    data.Save(strm);
+  }
+  inline static bool Read(Stream *strm, T *data) {
+    return data->Load(strm);
+  }
+};
+
+/*!
+ * \brief dummy class for undefined serialization.
+ *   This is used to generate error message when user tries to
+ *   serialize something that is not supported.
+ * \tparam T the type to be serialized
+ */
+template<typename T>
+struct UndefinedSerializerFor {
+};
+
+/*!
+ * \brief Serializer handler for std::vector<T> where T is POD type.
+ * \tparam T element type
+ */
+template<typename T>
+struct NativePODVectorHandler {
+  inline static void Write(Stream *strm, const std::vector<T> &vec) {
+    uint64_t sz = static_cast<uint64_t>(vec.size());
+    strm->Write<uint64_t>(sz);
+    if (sz != 0) {
+      strm->Write(&vec[0], sizeof(T) * vec.size());
+    }
+  }
+  inline static bool Read(Stream *strm, std::vector<T> *out_vec) {
+    uint64_t sz;
+    if (!strm->Read<uint64_t>(&sz)) return false;
+    size_t size = static_cast<size_t>(sz);
+    out_vec->resize(size);
+    if (sz != 0) {
+      size_t nbytes = sizeof(T) * size;
+      return strm->Read(&(*out_vec)[0], nbytes) == nbytes;
+    }
+    return true;
+  }
+};
+
+/*!
+ * \brief Serializer handler for std::vector<T> where T can be composed type
+ * \tparam T element type
+ */
+template<typename T>
+struct ComposeVectorHandler {
+  inline static void Write(Stream *strm, const std::vector<T> &vec) {
+    uint64_t sz = static_cast<uint64_t>(vec.size());
+    strm->Write<uint64_t>(sz);
+    strm->WriteArray(dmlc::BeginPtr(vec), vec.size());
+  }
+  inline static bool Read(Stream *strm, std::vector<T> *out_vec) {
+    uint64_t sz;
+    if (!strm->Read<uint64_t>(&sz)) return false;
+    size_t size = static_cast<size_t>(sz);
+    out_vec->resize(size);
+    return strm->ReadArray(dmlc::BeginPtr(*out_vec), size);
+  }
+};
+
+/*!
+ * \brief Serializer handler for std::basic_string<T> where T is POD type.
+ * \tparam T element type
+ */
+template<typename T>
+struct NativePODStringHandler {
+  inline static void Write(Stream *strm, const std::basic_string<T> &vec) {
+    uint64_t sz = static_cast<uint64_t>(vec.length());
+    strm->Write<uint64_t>(sz);
+    if (sz != 0) {
+      strm->Write(&vec[0], sizeof(T) * vec.length());
+    }
+  }
+  inline static bool Read(Stream *strm, std::basic_string<T> *out_vec) {
+    uint64_t sz;
+    if (!strm->Read<uint64_t>(&sz)) return false;
+    size_t size = static_cast<size_t>(sz);
+    out_vec->resize(size);
+    if (sz != 0) {
+      size_t nbytes = sizeof(T) * size;
+      return strm->Read(&(*out_vec)[0], nbytes) == nbytes;
+    }
+    return true;
+  }
+};
+
+/*! \brief Serializer for std::pair */
+template<typename TA, typename TB>
+struct PairHandler {
+  inline static void Write(Stream *strm, const std::pair<TA, TB> &data) {
+    Handler<TA>::Write(strm, data.first);
+    Handler<TB>::Write(strm, data.second);
+  }
+  inline static bool Read(Stream *strm, std::pair<TA, TB> *data) {
+    return Handler<TA>::Read(strm, &(data->first)) &&
+        Handler<TB>::Read(strm, &(data->second));
+  }
+};
+
+// set type handler that can handle most collection type case
+template<typename ContainerType, typename ElemType>
+struct CollectionHandler {
+  inline static void Write(Stream *strm, const ContainerType &data) {
+    // dump data to vector
+    std::vector<ElemType> vdata(data.begin(), data.end());
+    // serialize the vector
+    Handler<std::vector<ElemType> >::Write(strm, vdata);
+  }
+  inline static bool Read(Stream *strm, ContainerType *data) {
+    std::vector<ElemType> vdata;
+    if (!Handler<std::vector<ElemType> >::Read(strm, &vdata)) return false;
+    data->clear();
+    data->insert(vdata.begin(), vdata.end());
+    return true;
+  }
+};
+
+
+// handler that can handle most list type case
+// this type insert function takes additional iterator
+template<typename ListType>
+struct ListHandler {
+  inline static void Write(Stream *strm, const ListType &data) {
+    typedef typename ListType::value_type ElemType;
+    // dump data to vector
+    std::vector<ElemType> vdata(data.begin(), data.end());
+    // serialize the vector
+    Handler<std::vector<ElemType> >::Write(strm, vdata);
+  }
+  inline static bool Read(Stream *strm, ListType *data) {
+    typedef typename ListType::value_type ElemType;
+    std::vector<ElemType> vdata;
+    if (!Handler<std::vector<ElemType> >::Read(strm, &vdata)) return false;
+    data->clear();
+    data->insert(data->begin(), vdata.begin(), vdata.end());
+    return true;
+  }
+};
+
+//! \endcond
+
+/*!
+ * \brief generic serialization handler for type T
+ *
+ *  User can define specialization of this class to support
+ *  composite serialization of their own class.
+ *
+ * \tparam T the type to be serialized
+ */
+template<typename T>
+struct Handler {
+  /*!
+   * \brief write data to stream
+   * \param strm the stream we write the data.
+   * \param data the data obeject to be serialized
+   */
+  inline static void Write(Stream *strm, const T &data) {
+    IfThenElse<dmlc::is_arithmetic<T>::value,
+               ArithmeticHandler<T>,
+               IfThenElse<dmlc::is_pod<T>::value && DMLC_IO_NO_ENDIAN_SWAP,
+                          NativePODHandler<T>,
+                          IfThenElse<dmlc::has_saveload<T>::value,
+                                     SaveLoadClassHandler<T>,
+                                     UndefinedSerializerFor<T>, T>,
+                          T>,
+               T>
+        ::Write(strm, data);
+  }
+  /*!
+   * \brief read data to stream
+   * \param strm the stream to read the data.
+   * \param data the pointer to the data obeject to read
+   * \return whether the read is successful
+   */
+  inline static bool Read(Stream *strm, T *data) {
+    return
+    IfThenElse<dmlc::is_arithmetic<T>::value,
+               ArithmeticHandler<T>,
+               IfThenElse<dmlc::is_pod<T>::value && DMLC_IO_NO_ENDIAN_SWAP,
+                          NativePODHandler<T>,
+                          IfThenElse<dmlc::has_saveload<T>::value,
+                                     SaveLoadClassHandler<T>,
+                                     UndefinedSerializerFor<T>, T>,
+                          T>,
+               T>
+    ::Read(strm, data);
+  }
+};
+
+//! \cond Doxygen_Suppress
+template<typename T>
+struct Handler<std::vector<T> > {
+  inline static void Write(Stream *strm, const std::vector<T> &data) {
+    IfThenElse<dmlc::is_pod<T>::value && DMLC_IO_NO_ENDIAN_SWAP,
+               NativePODVectorHandler<T>,
+               ComposeVectorHandler<T>, std::vector<T> >
+    ::Write(strm, data);
+  }
+  inline static bool Read(Stream *strm, std::vector<T> *data) {
+    return IfThenElse<dmlc::is_pod<T>::value && DMLC_IO_NO_ENDIAN_SWAP,
+                      NativePODVectorHandler<T>,
+                      ComposeVectorHandler<T>,
+                      std::vector<T> >
+    ::Read(strm, data);
+  }
+};
+
+template<typename T>
+struct Handler<std::basic_string<T> > {
+  inline static void Write(Stream *strm, const std::basic_string<T> &data) {
+    IfThenElse<dmlc::is_pod<T>::value && (DMLC_IO_NO_ENDIAN_SWAP || sizeof(T) == 1),
+               NativePODStringHandler<T>,
+               UndefinedSerializerFor<T>,
+               std::basic_string<T> >
+    ::Write(strm, data);
+  }
+  inline static bool Read(Stream *strm, std::basic_string<T> *data) {
+    return IfThenElse<dmlc::is_pod<T>::value && (DMLC_IO_NO_ENDIAN_SWAP || sizeof(T) == 1),
+                      NativePODStringHandler<T>,
+                      UndefinedSerializerFor<T>,
+                      std::basic_string<T> >
+    ::Read(strm, data);
+  }
+};
+
+template<typename TA, typename TB>
+struct Handler<std::pair<TA, TB> > {
+  inline static void Write(Stream *strm, const std::pair<TA, TB> &data) {
+    IfThenElse<dmlc::is_pod<TA>::value &&
+               dmlc::is_pod<TB>::value &&
+               DMLC_IO_NO_ENDIAN_SWAP,
+               NativePODHandler<std::pair<TA, TB> >,
+               PairHandler<TA, TB>,
+               std::pair<TA, TB> >
+    ::Write(strm, data);
+  }
+  inline static bool Read(Stream *strm, std::pair<TA, TB> *data) {
+    return IfThenElse<dmlc::is_pod<TA>::value &&
+                      dmlc::is_pod<TB>::value &&
+                      DMLC_IO_NO_ENDIAN_SWAP,
+                      NativePODHandler<std::pair<TA, TB> >,
+                      PairHandler<TA, TB>,
+                      std::pair<TA, TB> >
+    ::Read(strm, data);
+  }
+};
+
+template<typename K, typename V>
+struct Handler<std::map<K, V> >
+    : public CollectionHandler<std::map<K, V>, std::pair<K, V> > {
+};
+
+template<typename K, typename V>
+struct Handler<std::multimap<K, V> >
+    : public CollectionHandler<std::multimap<K, V>, std::pair<K, V> > {
+};
+
+template<typename T>
+struct Handler<std::set<T> >
+    : public CollectionHandler<std::set<T>, T> {
+};
+
+template<typename T>
+struct Handler<std::multiset<T> >
+    : public CollectionHandler<std::multiset<T>, T> {
+};
+
+template<typename T>
+struct Handler<std::list<T> >
+    : public ListHandler<std::list<T> > {
+};
+
+template<typename T>
+struct Handler<std::deque<T> >
+    : public ListHandler<std::deque<T> > {
+};
+
+#if DMLC_USE_CXX11
+template<typename K, typename V>
+struct Handler<std::unordered_map<K, V> >
+    : public CollectionHandler<std::unordered_map<K, V>, std::pair<K, V> > {
+};
+
+template<typename K, typename V>
+struct Handler<std::unordered_multimap<K, V> >
+    : public CollectionHandler<std::unordered_multimap<K, V>, std::pair<K, V> > {
+};
+
+template<typename T>
+struct Handler<std::unordered_set<T> >
+    : public CollectionHandler<std::unordered_set<T>, T> {
+};
+
+template<typename T>
+struct Handler<std::unordered_multiset<T> >
+    : public CollectionHandler<std::unordered_multiset<T>, T> {
+};
+#endif
+//! \endcond
+}  // namespace serializer
+}  // namespace dmlc
+#endif  // DMLC_SERIALIZER_H_
diff --git a/darknet_drp_ros/include/dmlc/strtonum.h b/darknet_drp_ros/include/dmlc/strtonum.h
new file mode 100644
index 0000000..2ce10a8
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/strtonum.h
@@ -0,0 +1,737 @@
+/*!
+ * Copyright (c) 2015-2018 by Contributors
+ * \file strtonum.h
+ * \brief A faster implementation of strtof and strtod
+ */
+#ifndef DMLC_STRTONUM_H_
+#define DMLC_STRTONUM_H_
+
+#if DMLC_USE_CXX11
+#include <type_traits>
+#endif
+
+#include <string>
+#include <limits>
+#include <cstdint>
+#include "./base.h"
+#include "./logging.h"
+
+namespace dmlc {
+/*!
+ * \brief Inline implementation of isspace(). Tests whether the given character
+ *        is a whitespace letter.
+ * \param c Character to test
+ * \return Result of the test
+ */
+inline bool isspace(char c) {
+  return (c == ' ' || c == '\t' || c == '\r' || c == '\n' || c == '\f');
+}
+
+/*!
+ * \brief Inline implementation of isblank(). Tests whether the given character
+ *        is a space or tab character.
+ * \param c Character to test
+ * \return Result of the test
+ */
+inline bool isblank(char c) {
+  return (c == ' ' || c == '\t');
+}
+
+/*!
+ * \brief Inline implementation of isdigit(). Tests whether the given character
+ *        is a decimal digit
+ * \param c Character to test
+ * \return Result of the test
+ */
+inline bool isdigit(char c) {
+  return (c >= '0' && c <= '9');
+}
+
+/*!
+ * \brief Inline implementation of isalpha(). Tests whether the given character
+ *        is an alphabet letter
+ * \param c Character to test
+ * \return Result of the test
+ */
+inline bool isalpha(char c) {
+  static_assert(
+    static_cast<int>('A') == 65 && static_cast<int>('Z' - 'A') == 25,
+    "Only system with ASCII character set is supported");
+  return (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z');
+}
+
+/*!
+ * \brief Tests whether the given character is a valid letter in the string
+ *        representation of a floating-point value, i.e. decimal digits,
+ *        signs (+/-), decimal point (.), or exponent marker (e/E).
+ * \param c Character to test
+ * \return Result of the test
+ */
+inline bool isdigitchars(char c) {
+  return (c >= '0' && c <= '9')
+    || c == '+' || c == '-'
+    || c == '.'
+    || c == 'e' || c == 'E';
+}
+
+/*!
+ * \brief Maximum number of decimal digits dmlc::strtof() / dmlc::strtod()
+ *        will process. Trailing digits will be ignored.
+ */
+const int kStrtofMaxDigits = 19;
+
+/*!
+ * \brief Common implementation for dmlc::strtof() and dmlc::strtod()
+ * TODO: the current version does not support hex number
+ * \param nptr Beginning of the string that's to be converted into a
+ *             floating-point number
+ * \param endptr After the conversion, this pointer will be set to point one
+ *               past the last character used in the conversion.
+ * \return Converted floating-point value, in FloatType
+ * \tparam FloatType Type of floating-point number to be obtained. This must
+ *                   be either float or double.
+ * \tparam CheckRange Whether to check for overflow. If set to true, an out-
+ *                    of-range value will cause errno to be set to ERANGE and
+ *                    ParseFloat() to return HUGE_VAL / HUGE_VALF; otherwise,
+ *                    all out-of-range vlaues will be silently clipped.
+ */
+template <typename FloatType, bool CheckRange = false>
+inline FloatType ParseFloat(const char* nptr, char** endptr) {
+#if DMLC_USE_CXX11
+  static_assert(std::is_same<FloatType, double>::value
+                || std::is_same<FloatType, float>::value,
+               "ParseFloat is defined only for 'float' and 'double' types");
+  constexpr unsigned kMaxExponent
+    = (std::is_same<FloatType, double>::value ? 308U : 38U);
+  constexpr FloatType kMaxSignificandForMaxExponent
+    = static_cast<FloatType>(std::is_same<FloatType, double>::value
+                             ? 1.79769313486231570 : 3.402823466);
+    // If a floating-point value has kMaxExponent, what is
+    //   the largest possible significand value?
+  constexpr FloatType kMaxSignificandForNegMaxExponent
+    = static_cast<FloatType>(std::is_same<FloatType, double>::value
+                             ? 2.22507385850720139 : 1.175494351);
+    // If a floating-point value has -kMaxExponent, what is
+    //   the largest possible significand value?
+#else
+  const unsigned kMaxExponent
+    = (sizeof(FloatType) == sizeof(double) ? 308U : 38U);
+  const FloatType kMaxSignificandForMaxExponent
+    = static_cast<FloatType>(sizeof(FloatType) == sizeof(double)
+                             ? 1.79769313486231570 : 3.402823466);
+  const FloatType kMaxSignificandForNegMaxExponent
+    = static_cast<FloatType>(sizeof(FloatType) == sizeof(double)
+                             ? 2.22507385850720139 : 1.175494351);
+#endif
+
+  const char *p = nptr;
+  // Skip leading white space, if any. Not necessary
+  while (isspace(*p) ) ++p;
+
+  // Get sign, if any.
+  bool sign = true;
+  if (*p == '-') {
+    sign = false; ++p;
+  } else if (*p == '+') {
+    ++p;
+  }
+
+  // Handle INF and NAN
+  {
+    int i = 0;
+    // case-insensitive match for INF and INFINITY
+    while (i < 8 && static_cast<char>((*p) | 32) == "infinity"[i]) {
+      ++i; ++p;
+    }
+    if (i == 3 || i == 8) {
+      if (endptr) *endptr = (char*)p;  // NOLINT(*)
+      return sign ?  std::numeric_limits<FloatType>::infinity()
+                  : -std::numeric_limits<FloatType>::infinity();
+    } else {
+      p -= i;
+    }
+
+    // case-insensitive match for NAN
+    i = 0;
+    while (i < 3 && static_cast<char>((*p) | 32) == "nan"[i]) {
+      ++i; ++p;
+    }
+    if (i == 3) {
+      // Got NAN; check if the value is of form NAN(char_sequence)
+      if (*p == '(') {
+        ++p;
+        while (isdigit(*p) || isalpha(*p) || *p == '_') ++p;
+        CHECK_EQ(*p, ')') << "Invalid NAN literal";
+        ++p;
+      }
+      static_assert(std::numeric_limits<FloatType>::has_quiet_NaN,
+        "Only system with quiet NaN is supported");
+      if (endptr) *endptr = (char*)p;  // NOLINT(*)
+      return std::numeric_limits<FloatType>::quiet_NaN();
+    } else {
+      p -= i;
+    }
+  }
+
+  // Get digits before decimal point or exponent, if any.
+  uint64_t predec;  // to store digits before decimal point
+  for (predec = 0; isdigit(*p); ++p) {
+    predec = predec * 10ULL + static_cast<uint64_t>(*p - '0');
+  }
+  FloatType value = static_cast<FloatType>(predec);
+
+  // Get digits after decimal point, if any.
+  if (*p == '.') {
+    uint64_t pow10 = 1;
+    uint64_t val2 = 0;
+    int digit_cnt = 0;
+    ++p;
+    while (isdigit(*p)) {
+      if (digit_cnt < kStrtofMaxDigits) {
+        val2 = val2 * 10ULL + static_cast<uint64_t>(*p - '0');
+        pow10 *= 10ULL;
+      }  // when kStrtofMaxDigits is read, ignored following digits
+      ++p;
+      ++digit_cnt;
+    }
+    value += static_cast<FloatType>(
+        static_cast<double>(val2) / static_cast<double>(pow10));
+  }
+
+  // Handle exponent, if any.
+  if ((*p == 'e') || (*p == 'E')) {
+    ++p;
+    bool frac = false;
+    FloatType scale = static_cast<FloatType>(1.0f);
+    unsigned expon;
+    // Get sign of exponent, if any.
+    if (*p == '-') {
+      frac = true;
+      ++p;
+    } else if (*p == '+') {
+      ++p;
+    }
+    // Get digits of exponent, if any.
+    for (expon = 0; isdigit(*p); ++p) {
+      expon = expon * 10U + static_cast<unsigned>(*p - '0');
+    }
+    if (expon > kMaxExponent) {  // out of range, clip or raise error
+      if (CheckRange) {
+        errno = ERANGE;
+        if (endptr) *endptr = (char*)p;  // NOLINT(*)
+        return std::numeric_limits<FloatType>::infinity();
+      } else {
+        expon = kMaxExponent;
+      }
+    }
+    // handle edge case where exponent is exactly kMaxExponent
+    if (expon == kMaxExponent
+        && ((!frac && value > kMaxSignificandForMaxExponent)
+           || (frac && value < kMaxSignificandForNegMaxExponent))) {
+      if (CheckRange) {
+        errno = ERANGE;
+        if (endptr) *endptr = (char*)p;  // NOLINT(*)
+        return std::numeric_limits<FloatType>::infinity();
+      } else {
+        value = (frac ? kMaxSignificandForNegMaxExponent
+                 : kMaxSignificandForMaxExponent);
+      }
+    }
+    // Calculate scaling factor.
+    while (expon >= 8U) { scale *= static_cast<FloatType>(1E8f);  expon -= 8U; }
+    while (expon >  0U) { scale *= static_cast<FloatType>(10.0f); expon -= 1U; }
+    // Return signed and scaled floating point result.
+    value = frac ? (value / scale) : (value * scale);
+  }
+  // Consume 'f' suffix, if any
+  if (*p == 'f' || *p == 'F') {
+    ++p;
+  }
+
+  if (endptr) *endptr = (char*)p;  // NOLINT(*)
+  return sign ? value : - value;
+}
+
+/*!
+ * \brief A faster implementation of strtof(). See documentation of
+ *        std::strtof() for more information. Note that this function does not
+ *        check for overflow. Use strtof_check_range() to check for overflow.
+ * TODO: the current version does not support hex number
+ * TODO: the current version does not handle long decimals: you may only have
+ *       up to 19 digits after the decimal point, and you cannot have too many
+ *       digits before the decimal point either.
+ * \param nptr Beginning of the string that's to be converted into float
+ * \param endptr After the conversion, this pointer will be set to point one
+ *               past the last character used in the conversion.
+ * \return Converted floating-point value, in float type
+ */
+inline float strtof(const char* nptr, char** endptr) {
+  return ParseFloat<float>(nptr, endptr);
+}
+
+/*!
+ * \brief A faster implementation of strtof(). See documentation of
+ *        std::strtof() for more information. This function will check for
+ *        overflow. If the converted value is outside the range for the float
+ *        type, errno is set to ERANGE and HUGE_VALF is returned.
+ * TODO: the current version does not support hex number
+ * TODO: the current version does not handle long decimals: you may only have
+ *       up to 19 digits after the decimal point, and you cannot have too many
+ *       digits before the decimal point either.
+ * \param nptr Beginning of the string that's to be converted into float
+ * \param endptr After the conversion, this pointer will be set to point one
+ *               past the last character used in the conversion.
+ * \return Converted floating-point value, in float type
+ */
+inline float strtof_check_range(const char* nptr, char** endptr) {
+  return ParseFloat<float, true>(nptr, endptr);
+}
+
+/*!
+ * \brief A faster implementation of strtod(). See documentation of
+ *        std::strtof() for more information. Note that this function does not
+ *        check for overflow. Use strtod_check_range() to check for overflow.
+ * TODO: the current version does not support hex number
+ * TODO: the current version does not handle long decimals: you may only have
+ *       up to 19 digits after the decimal point, and you cannot have too many
+ *       digits before the decimal point either.
+ * \param nptr Beginning of the string that's to be converted into double
+ * \param endptr After the conversion, this pointer will be set to point one
+ *               past the last character used in the conversion.
+ * \return Converted floating-point value, in double type
+ */
+inline double strtod(const char* nptr, char** endptr) {
+  return ParseFloat<double>(nptr, endptr);
+}
+
+/*!
+ * \brief A faster implementation of strtod(). See documentation of
+ *        std::strtod() for more information. This function will check for
+ *        overflow. If the converted value is outside the range for the double
+ *        type, errno is set to ERANGE and HUGE_VAL is returned.
+ * TODO: the current version does not support hex number
+ * TODO: the current version does not handle long decimals: you may only have
+ *       up to 19 digits after the decimal point, and you cannot have too many
+ *       digits before the decimal point either.
+ * \param nptr Beginning of the string that's to be converted into double
+ * \param endptr After the conversion, this pointer will be set to point one
+ *               past the last character used in the conversion.
+ * \return Converted floating-point value, in float type
+ */
+inline double strtod_check_range(const char* nptr, char** endptr) {
+  return ParseFloat<double, true>(nptr, endptr);
+}
+
+/*!
+ * \brief A fast string-to-integer convertor, for signed integers
+ * TODO: the current version supports only base <= 10
+ * \param nptr Beginning of the string that's to be converted into a signed
+ *             integer
+ * \param endptr After the conversion, this pointer will be set to point one
+ *               past the last character used in the conversion.
+ * \param base Base to use for integer conversion
+ * \return Converted value, in SignedIntType
+ * \tparam SignedIntType Type of signed integer to be obtained.
+ */
+template <typename SignedIntType>
+inline SignedIntType ParseSignedInt(const char* nptr, char** endptr, int base) {
+#ifdef DMLC_USE_CXX11
+  static_assert(std::is_signed<SignedIntType>::value
+                && std::is_integral<SignedIntType>::value,
+                "ParseSignedInt is defined for signed integers only");
+#endif
+  CHECK(base <= 10 && base >= 2);
+  const char* p = nptr;
+  // Skip leading white space, if any. Not necessary
+  while (isspace(*p) ) ++p;
+
+  // Get sign if any
+  bool sign = true;
+  if (*p == '-') {
+    sign = false; ++p;
+  } else if (*p == '+') {
+    ++p;
+  }
+
+  SignedIntType value;
+  const SignedIntType base_val = static_cast<SignedIntType>(base);
+  for (value = 0; isdigit(*p); ++p) {
+    value = value * base_val + static_cast<SignedIntType>(*p - '0');
+  }
+
+  if (endptr) *endptr = (char*)p;  // NOLINT(*)
+  return sign ? value : - value;
+}
+
+/*!
+ * \brief A fast string-to-integer convertor, for unsigned integers
+ * TODO: the current version supports only base <= 10
+ * \param nptr Beginning of the string that's to be converted into an unsigned
+ *             integer
+ * \param endptr After the conversion, this pointer will be set to point one
+ *               past the last character used in the conversion.
+ * \param base Base to use for integer conversion
+ * \return Converted value, in UnsignedIntType
+ * \tparam UnsignedIntType Type of unsigned integer to be obtained.
+ */
+template <typename UnsignedIntType>
+inline UnsignedIntType ParseUnsignedInt(const char* nptr, char** endptr, int base) {
+#ifdef DMLC_USE_CXX11
+  static_assert(std::is_unsigned<UnsignedIntType>::value
+                && std::is_integral<UnsignedIntType>::value,
+                "ParseUnsignedInt is defined for unsigned integers only");
+#endif
+  CHECK(base <= 10 && base >= 2);
+  const char *p = nptr;
+  // Skip leading white space, if any. Not necessary
+  while (isspace(*p)) ++p;
+
+  // Get sign if any
+  bool sign = true;
+  if (*p == '-') {
+    sign = false; ++p;
+  } else if (*p == '+') {
+    ++p;
+  }
+
+  // we are parsing unsigned, so no minus sign should be found
+  CHECK_EQ(sign, true);
+
+  UnsignedIntType value;
+  const UnsignedIntType base_val = static_cast<UnsignedIntType>(base);
+  for (value = 0; isdigit(*p); ++p) {
+    value = value * base_val + static_cast<UnsignedIntType>(*p - '0');
+  }
+
+  if (endptr) *endptr = (char*)p; // NOLINT(*)
+  return value;
+}
+
+/*!
+ * \brief A faster implementation of strtoull(). See documentation of
+ *        std::strtoull() for more information. Note that this function does not
+ *        check for overflow.
+ * TODO: the current version supports only base <= 10
+ * \param nptr Beginning of the string that's to be converted into integer of
+ *             type unsigned long long
+ * \param endptr After the conversion, this pointer will be set to point one
+ *               past the last character used in the conversion.
+ * \param base Base to use for integer conversion
+ * \return Converted value, as unsigned 64-bit integer
+ */
+inline uint64_t strtoull(const char* nptr, char **endptr, int base) {
+  return ParseUnsignedInt<uint64_t>(nptr, endptr, base);
+}
+
+/*!
+ * \brief A faster implementation of atol(). See documentation of std::atol()
+ *        for more information. This function will use base 10. Note that this
+ *        function does not check for overflow.
+ * \param p Beginning of the string that's to be converted into integer of
+ *          type long
+ * \return Converted value, as long integer (width is system-dependent)
+ */
+inline long atol(const char* p) {  // NOLINT(*)
+  return ParseSignedInt<long>(p, 0, 10); // NOLINT(*)
+}
+
+/*!
+ * \brief A faster implementation of atof(). Unlike std::atof(), this function
+ *        returns float type. Note that this function does not check for overflow.
+ * TODO: the current version does not support hex number
+ * TODO: the current version does not handle long decimals: you may only have
+ *       up to 19 digits after the decimal point, and you cannot have too many
+ *       digits before the decimal point either.
+ * \param nptr Beginning of the string that's to be converted into float
+ * \return Converted value, in float type
+ */
+inline float atof(const char* nptr) {
+  return strtof(nptr, 0);
+}
+
+/*!
+ * \brief A faster implementation of stof(). See documentation of std::stof()
+ *        for more information. This function will test for overflow and
+ *        invalid arguments.
+ * TODO: the current version does not support hex number
+ * TODO: the current version does not handle long decimals: you may only have
+ *       up to 19 digits after the decimal point, and you cannot have too many
+ *       digits before the decimal point either.
+ * \param value The string to convert into float
+ * \param pos If not null, it will store the number of characters processed
+ * \return Converted value, in float type
+ * \throw std::out_of_range If the converted value would fall out of the range
+ *                          of the double type
+ * \throw std::invalid_argument If no conversion could be performed
+ */
+inline float stof(const std::string& value, size_t* pos = nullptr) {
+  const char* str_source = value.c_str();
+  char* endptr;
+  const float parsed_value = dmlc::strtof_check_range(str_source, &endptr);
+  if (errno == ERANGE && parsed_value == std::numeric_limits<float>::infinity()) {
+    throw std::out_of_range("Out of range value");
+  } else if (const_cast<const char*>(endptr) == str_source) {
+    throw std::invalid_argument("No conversion could be performed");
+  }
+  if (pos) {
+    *pos = static_cast<size_t>(const_cast<const char*>(endptr) - str_source);
+  }
+  return parsed_value;
+}
+
+/*!
+ * \brief A faster implementation of stod(). See documentation of std::stod()
+ *        for more information. This function will test for overflow and
+ *        invalid arguments.
+ * TODO: the current version does not support hex number
+ * TODO: the current version does not handle long decimals: you may only have
+ *       up to 19 digits after the decimal point, and you cannot have too many
+ *       digits before the decimal point either.
+ * \param value The string to convert into double
+ * \param pos If not null, it will store the number of characters processed
+ * \return Converted value, in double type
+ * \throw std::out_of_range If the converted value would fall out of the range
+ *                          of the double type
+ * \throw std::invalid_argument If no conversion could be performed
+ */
+inline double stod(const std::string& value, size_t* pos = nullptr) {
+  const char* str_source = value.c_str();
+  char* endptr;
+  const double parsed_value = dmlc::strtod_check_range(str_source, &endptr);
+  if (errno == ERANGE && parsed_value == std::numeric_limits<double>::infinity()) {
+    throw std::out_of_range("Out of range value");
+  } else if (const_cast<const char*>(endptr) == str_source) {
+    throw std::invalid_argument("No conversion could be performed");
+  }
+  if (pos) {
+    *pos = static_cast<size_t>(const_cast<const char*>(endptr) - str_source);
+  }
+  return parsed_value;
+}
+
+/*!
+ * \brief Interface class that defines a single method get() to convert
+ *        a string into type T. Define template specialization of this class
+ *        to define the conversion method for a particular type.
+ * \tparam Type of converted value
+ */
+template<typename T>
+class Str2T {
+ public:
+  /*!
+   * \brief Convert a string into type T
+   * \param begin Beginning of the string to convert
+   * \param end End of the string to convert
+   * \return Converted value, in type T
+   */
+  static inline T get(const char * begin, const char * end);
+};
+
+/*!
+ * \brief Convenience function for converting string into type T
+ * \param begin Beginning of the string to convert
+ * \param end End of the string to convert
+ * \return Converted value, in type T
+ * \tparam Type of converted value
+ */
+template<typename T>
+inline T Str2Type(const char * begin, const char * end) {
+  return Str2T<T>::get(begin, end);
+}
+
+/*!
+ * \brief Template specialization of Str2T<> interface for signed 32-bit integer
+ */
+template<>
+class Str2T<int32_t> {
+ public:
+  /*!
+   * \brief Convert a string into signed 32-bit integer
+   * \param begin Beginning of the string to convert
+   * \param end End of the string to convert
+   * \return Converted value, as signed 32-bit integer
+   */
+  static inline int32_t get(const char * begin, const char * end) {
+    return ParseSignedInt<int32_t>(begin, NULL, 10);
+  }
+};
+
+/*!
+ * \brief Template specialization of Str2T<> interface for unsigned 32-bit integer
+ */
+template<>
+class Str2T<uint32_t> {
+ public:
+  /*!
+   * \brief Convert a string into unsigned 32-bit integer
+   * \param begin Beginning of the string to convert
+   * \param end End of the string to convert
+   * \return Converted value, as unsigned 32-bit integer
+   */
+  static inline uint32_t get(const char* begin, const char* end) {
+    return ParseUnsignedInt<uint32_t>(begin, NULL, 10);
+  }
+};
+
+/*!
+ * \brief Template specialization of Str2T<> interface for signed 64-bit integer
+ */
+template<>
+class Str2T<int64_t> {
+ public:
+  /*!
+   * \brief Convert a string into signed 64-bit integer
+   * \param begin Beginning of the string to convert
+   * \param end End of the string to convert
+   * \return Converted value, as signed 64-bit integer
+   */
+  static inline int64_t get(const char * begin, const char * end) {
+    return ParseSignedInt<int64_t>(begin, NULL, 10);
+  }
+};
+
+/*!
+ * \brief Template specialization of Str2T<> interface for unsigned 64-bit integer
+ */
+template<>
+class Str2T<uint64_t> {
+ public:
+  /*!
+   * \brief Convert a string into unsigned 64-bit integer
+   * \param begin Beginning of the string to convert
+   * \param end End of the string to convert
+   * \return Converted value, as unsigned 64-bit integer
+   */
+  static inline uint64_t get(const char * begin, const char * end) {
+    return ParseUnsignedInt<uint64_t>(begin, NULL, 10);
+  }
+};
+
+/*!
+ * \brief Template specialization of Str2T<> interface for float type
+ */
+template<>
+class Str2T<float> {
+ public:
+  /*!
+   * \brief Convert a string into float
+   * \param begin Beginning of the string to convert
+   * \param end End of the string to convert
+   * \return Converted value, in float type
+   */
+  static inline float get(const char * begin, const char * end) {
+    return atof(begin);
+  }
+};
+
+/*!
+ * \brief Template specialization of Str2T<> interface for double type
+ */
+template<>
+class Str2T<double> {
+ public:
+  /*!
+   * \brief Convert a string into double
+   * \param begin Beginning of the string to convert
+   * \param end End of the string to convert
+   * \return Converted value, in double type
+   */
+  static inline double get(const char * begin, const char * end) {
+    return strtod(begin, 0);
+  }
+};
+
+/*!
+ * \brief Parse colon seperated pair v1[:v2]
+ * \param begin pointer to string
+ * \param end one past end of string
+ * \param endptr After conversion, will be set to one past of parsed string
+ * \param v1 first value in the pair
+ * \param v2 second value in the pair
+ * \return number of values parsed
+ * \tparam T1 type of v1
+ * \tparam T2 type of v2
+ */
+template<typename T1, typename T2>
+inline int ParsePair(const char * begin, const char * end,
+                     const char ** endptr, T1 &v1, T2 &v2) { // NOLINT(*)
+  const char * p = begin;
+  while (p != end && !isdigitchars(*p)) ++p;
+  if (p == end) {
+    *endptr = end;
+    return 0;
+  }
+  const char * q = p;
+  while (q != end && isdigitchars(*q)) ++q;
+  v1 = Str2Type<T1>(p, q);
+  p = q;
+  while (p != end && isblank(*p)) ++p;
+  if (p == end || *p != ':') {
+    // only v1
+    *endptr = p;
+    return 1;
+  }
+  p++;
+  while (p != end && !isdigitchars(*p)) ++p;
+  q = p;
+  while (q != end && isdigitchars(*q)) ++q;
+  *endptr = q;
+  v2 = Str2Type<T2>(p, q);
+  return 2;
+}
+
+/*!
+ * \brief Parse colon seperated triple v1:v2[:v3]
+ * \param begin pointer to string
+ * \param end one past end of string
+ * \param endptr After conversion, will be set to one past of parsed string
+ * \param v1 first value in the triple
+ * \param v2 second value in the triple
+ * \param v3 third value in the triple
+ * \return number of values parsed
+ * \tparam T1 type of v1
+ * \tparam T2 type of v2
+ * \tparam T3 type of v3
+ */
+template<typename T1, typename T2, typename T3>
+inline int ParseTriple(const char * begin, const char * end,
+                       const char ** endptr, T1 &v1, T2 &v2, T3 &v3) { // NOLINT(*)
+  const char * p = begin;
+  while (p != end && !isdigitchars(*p)) ++p;
+  if (p == end) {
+    *endptr = end;
+    return 0;
+  }
+  const char * q = p;
+  while (q != end && isdigitchars(*q)) ++q;
+  v1 = Str2Type<T1>(p, q);
+  p = q;
+  while (p != end && isblank(*p)) ++p;
+  if (p == end || *p != ':') {
+    // only v1
+    *endptr = p;
+    return 1;
+  }
+  p++;
+  while (p != end && !isdigitchars(*p)) ++p;
+  q = p;
+  while (q != end && isdigitchars(*q)) ++q;
+  v2 = Str2Type<T2>(p, q);
+  p = q;
+  while (p != end && isblank(*p)) ++p;
+  if (p == end || *p != ':') {
+    // only v1:v2
+    *endptr = p;
+    return 2;
+  }
+  p++;
+  while (p != end && !isdigitchars(*p)) ++p;
+  q = p;
+  while (q != end && isdigitchars(*q)) ++q;
+  *endptr = q;
+  v3 = Str2Type<T3>(p, q);
+  return 3;
+}
+}  // namespace dmlc
+
+#endif  // DMLC_STRTONUM_H_
diff --git a/darknet_drp_ros/include/dmlc/thread_group.h b/darknet_drp_ros/include/dmlc/thread_group.h
new file mode 100644
index 0000000..ced3ae0
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/thread_group.h
@@ -0,0 +1,808 @@
+/*!
+ * Copyright (c) 2017 by Contributors
+ * \file thread_group.h
+ * \brief Thread and synchronization primitives and lifecycle management
+ */
+#ifndef DMLC_THREAD_GROUP_H_
+#define DMLC_THREAD_GROUP_H_
+
+#include <dmlc/concurrentqueue.h>
+#include <dmlc/blockingconcurrentqueue.h>
+#include <dmlc/logging.h>
+#include <string>
+#include <mutex>
+#include <utility>
+#include <memory>
+#include <set>
+#include <thread>
+#include <unordered_set>
+#include <unordered_map>
+#if defined(DMLC_USE_CXX14) || __cplusplus > 201103L  /* C++14 */
+#include <shared_mutex>
+#endif
+#include <condition_variable>
+#ifdef __linux__
+#include <unistd.h>
+#include <sys/syscall.h>
+#endif
+
+namespace dmlc {
+
+/*!
+ * \brief Simple manual-reset event gate which remains open after signalled
+ */
+class ManualEvent {
+ public:
+  ManualEvent() : signaled_(false) {}
+
+  /*!
+   * \brief Wait for the object to become signaled.  If the object
+   * is already in the signaled state and reset() has not been called, then no wait will occur
+   */
+  void wait() {
+    std::unique_lock<std::mutex> lock(mutex_);
+    if (!signaled_) {
+      condition_variable_.wait(lock);
+    }
+  }
+
+  /*!
+   * \brief Set this object's state to signaled (wait() will release or pass through)
+   */
+  void signal() {
+    signaled_ = true;
+    std::unique_lock<std::mutex> lk(mutex_);
+    condition_variable_.notify_all();
+  }
+
+  /*!
+   * \brief Manually reset this object's state to unsignaled (wait() will block)
+   */
+  void reset() {
+    std::unique_lock<std::mutex> lk(mutex_);
+    signaled_ = false;
+  }
+
+ private:
+  /*! \brief Internal mutex to protect condition variable and signaled_ variable */
+  std::mutex mutex_;
+  /*! \brief Internal condition variable */
+  std::condition_variable condition_variable_;
+  /*! \brief lockfree signal state check */
+  std::atomic<bool> signaled_;
+};
+
+#if defined(DMLC_USE_CXX14) || __cplusplus > 201103L  /* C++14 */
+/*! \brief Mutex which can be read-locked and write-locked */
+using SharedMutex = std::shared_timed_mutex;
+/*! \brief Write lock, disallows both reads and writes */
+using WriteLock = std::unique_lock<SharedMutex>;
+/*! \brief Read lock, allows concurrent data reads */
+using ReadLock = std::shared_lock<SharedMutex>;
+#else
+/*! \brief Standard mutex for C++ < 14 */
+using SharedMutex = std::recursive_mutex;
+/*! \brief Standard unique lock for C++ < 14 */
+using WriteLock = std::unique_lock<SharedMutex>;
+/*! \brief Standard unique lock for C++ < 14 */
+using ReadLock = std::unique_lock<SharedMutex>;
+#endif
+
+/*!
+ * \brief Thread lifecycle management group
+ * \note See gtest unit tests Syc.* for a usage examples
+ */
+class ThreadGroup {
+ public:
+  /*!
+   * \brief Lifecycle-managed thread (used by ThreadGroup)
+   * \note See gtest unit tests Syc.* for a usage examples
+   */
+  class Thread {
+   public:
+    /*! \brief Shared pointer type for readability */
+    using SharedPtr = std::shared_ptr<Thread>;
+
+    /*!
+     * \brief Constructor
+     * \param threadName User-defined name of the thread. must be unique per ThreadGroup
+     * \param owner The ThreadGroup object managing the lifecycle of this thread
+     * \param thrd Optionally-assigned std::thread object associated with this Thread class
+     */
+    Thread(std::string threadName, ThreadGroup *owner, std::thread *thrd = nullptr)
+      : name_(std::move(threadName))
+        , thread_(thrd)
+        , ready_event_(std::make_shared<ManualEvent>())
+        , start_event_(std::make_shared<ManualEvent>())
+        , owner_(owner)
+        , shutdown_requested_(false)
+        , auto_remove_(false) {
+      CHECK_NOTNULL(owner);
+    }
+
+    /*!
+     * \brief Destructor with cleanup
+     */
+    virtual ~Thread() {
+      const bool self_delete = is_current_thread();
+      if (!self_delete) {
+        request_shutdown();
+        internal_join(true);
+      }
+      WriteLock guard(thread_mutex_);
+      if (thread_.load()) {
+        std::thread *thrd = thread_.load();
+        thread_ = nullptr;
+        if (self_delete) {
+          thrd->detach();
+        }
+        delete thrd;
+      }
+    }
+
+    /*!
+     * \brief Name of the thread
+     * \return Pointer to the thread name's string
+     * \note This shoul ndly be used as immediate for the sacope of the
+     *       shared pointer pointing to this object
+     */
+    const char *name() const {
+      return name_.c_str();
+    }
+
+    /*!
+     * \brief Launch the given Thread object
+     * \tparam StartFunction Function type for the thread 'main' function
+     * \tparam Args Arguments to pass to the thread 'main' function
+     * \param pThis Shared pointer for the managed thread to launch
+     * \param autoRemove if true, automatically remove this Thread object from the
+     *                   ThreadGroup owner upon exit
+     * \param start_function The Thread's 'main' function
+     * \param args Arguments to pass to the Thread's 'main' function
+     * \return true if the thread was successfully created and added to the ThreadGroup
+     *              If false is returned, the thread may have already been started, but if something
+     *              went wrong (ie duplicte thread name for the ThreadGroup), then request_shutdown()
+     *              will have been been called on the running thread
+     */
+    template<typename StartFunction, typename ...Args>
+    static bool launch(std::shared_ptr<Thread> pThis,
+                       bool autoRemove,
+                       StartFunction start_function,
+                       Args ...args);
+
+    /*!
+     * \brief Check if this class represents the currently running thread (self)
+     * \return true if the current running thread belongs to this class
+     */
+    bool is_current_thread() const {
+      ReadLock guard(thread_mutex_);
+      return thread_.load() ? (thread_.load()->get_id() == std::this_thread::get_id()) : false;
+    }
+
+    /*!
+     * \brief Signal to this thread that a thread shutdown/exit is requested.
+     * \note This is a candidate for overrise in a derived class which may trigger shutdown
+     *       by means other than a boolean (ie condition variable, SimpleManualkEvent, etc).
+     */
+    virtual void request_shutdown() {
+      shutdown_requested_ = true;
+    }
+
+    /*!
+     * \brief Check whether shutdown has been requested (request_shutdown() was called)
+     * \return true if shutdown was requested.
+     * \note This may be overriden to match an overriden to match an overriden 'request_shutdown()',
+     *       for instance.
+     */
+    virtual bool is_shutdown_requested() const {
+      return shutdown_requested_.load();
+    }
+
+    /*!
+     * \brief Check whether the thread is set to auto-remove itself from the ThreadGroup owner
+     *        when exiting
+     * \return true if the thread will auto-remove itself from the ThreadGroup owner
+     *        when exiting
+     */
+    bool is_auto_remove() const {
+      return auto_remove_;
+    }
+
+    /*!
+     * \brief Make the thread joinable (by removing the auto_remove flag)
+     * \warning Care should be taken not to cause a race condition between this call
+     *          and parallel execution of this thread auto-removing itself
+     */
+    void make_joinable() {
+      auto_remove_ = false;
+    }
+
+    /*!
+     * \brief Check whether the thread is joinable
+     * \return true if the thread is joinable
+     */
+    bool joinable() const {
+      if (thread_.load()) {
+        CHECK_EQ(auto_remove_, false);
+        // be checked by searching the group or exit event.
+        return thread_.load()->joinable();
+      }
+      return false;
+    }
+
+    /*!
+     * \brief Thread join
+     * \note join() may not be called on auto-remove threads
+     */
+    void join() {
+      internal_join(false);
+    }
+
+    /*!
+     * \brief Get this thread's id
+     * \return this thread's id
+     */
+    std::thread::id get_id() const {
+      return thread_.load()->get_id();
+    }
+
+   private:
+    /*!
+     * \brief Internal join function
+     * \param auto_remove_ok Whether to allow join on an auto-remove thread
+     */
+    void internal_join(bool auto_remove_ok) {
+      ReadLock guard(thread_mutex_);
+      // should be careful calling (or any function externally) this when in
+      // auto-remove mode
+      if (thread_.load() && thread_.load()->get_id() != std::thread::id()) {
+        std::thread::id someId;
+        if (!auto_remove_ok) {
+          CHECK_EQ(auto_remove_, false);
+        }
+        CHECK_NOTNULL(thread_.load());
+        if (thread_.load()->joinable()) {
+          thread_.load()->join();
+        } else {
+          LOG(WARNING) << "Thread " << name_ << " ( "
+                       << thread_.load()->get_id() << " ) not joinable";
+        }
+      }
+    }
+
+    /*!
+     * \brief Thread bootstrapping and teardown wrapper
+     * \tparam StartFunction Thread's "main" function
+     * \tparam Args Argument types to be passed to the start_function
+     * \param pThis Shared pointer to the Thread object to operate upon
+     * \param start_function Thread's "main" function (i.e. passed to launch())
+     * \param args Arguments to be passed to the start_function
+     * \return The thread's return code
+     */
+    template <typename StartFunction, typename ...Args>
+    static int entry_and_exit_f(std::shared_ptr<Thread> pThis,
+                                StartFunction start_function,
+                                Args... args);
+    /*! \brief Thread name */
+    std::string name_;
+    /*! \brief Shared mutex for some thread operations */
+    mutable SharedMutex thread_mutex_;
+    /*! \brief Pointer to the stl thread object */
+    std::atomic<std::thread *> thread_;
+    /*! \brief Signaled when the thread is started and ready to execute user code */
+    std::shared_ptr<ManualEvent> ready_event_;
+    /*! \brief Thread will block after setting ready_event_ until start_event_ is signaled */
+    std::shared_ptr<ManualEvent> start_event_;
+    /*! \brief The ThreadGroup ownber managing this thread's lifecycle */
+    ThreadGroup *owner_;
+    /*! \brief Flag to determine if shutdown was requested. */
+    std::atomic<bool> shutdown_requested_;
+    /*!
+     * \brief Whether to automatically remove this thread's object from the ThreadGroup when the
+     *        thread exists (perform its own cleanup)
+     */
+    std::atomic<bool> auto_remove_;
+  };
+
+  /*!
+   * \brief Constructor
+   */
+  inline ThreadGroup()
+    : evEmpty_(std::make_shared<ManualEvent>()) {
+    evEmpty_->signal();  // Starts out empty
+  }
+
+  /*!
+   * \brief Destructor, perform cleanup. All child threads will be exited when this
+   *        destructor completes
+   */
+  virtual ~ThreadGroup() {
+    request_shutdown_all();
+    join_all();
+  }
+
+  /*!
+   * \brief Check if the current thread a member if this ThreadGroup
+   * \return true if the current thread is a member of this thread group
+   * \note This lookup involved a linear search, so for a large number of threads,
+   *       is it not advised to call this function in a performance-sensitive area
+   */
+  inline bool is_this_thread_in() const {
+    std::thread::id id = std::this_thread::get_id();
+    ReadLock guard(m_);
+    for (auto it = threads_.begin(), end = threads_.end(); it != end; ++it) {
+      std::shared_ptr<Thread> thrd = *it;
+      if (thrd->get_id() == id)
+        return true;
+    }
+    return false;
+  }
+
+  /*!
+   * \brief Check if the current thread is a member of this ThreadGroup
+   * \param thrd The thread to search for
+   * \return true if the given thread is a member of this ThreadGroup
+   */
+  inline bool is_thread_in(std::shared_ptr<Thread> thrd) const {
+    if (thrd) {
+      std::thread::id id = thrd->get_id();
+      ReadLock guard(m_);
+      for (auto it = threads_.begin(), end = threads_.end(); it != end; ++it) {
+        std::shared_ptr<Thread> thrd = *it;
+        if (thrd->get_id() == id)
+          return true;
+      }
+      return false;
+    } else {
+      return false;
+    }
+  }
+
+  /*!
+   * \brief Add a Thread object to this thread group
+   * \param thrd The thread to add to this ThreadGroup object
+   * \return true if the given thread was added to this ThreadGroup
+   */
+  inline bool add_thread(std::shared_ptr<Thread> thrd) {
+    if (thrd) {
+      WriteLock guard(m_);
+      auto iter = name_to_thread_.find(thrd->name());
+      if (iter == name_to_thread_.end()) {
+        name_to_thread_.emplace(std::make_pair(thrd->name(), thrd));
+        CHECK_EQ(threads_.insert(thrd).second, true);
+        evEmpty_->reset();
+        return true;
+      }
+    }
+    return false;
+  }
+
+  /*!
+   * \brief Remove a Thread object from this thread group
+   * \param thrd The thread to remove from this ThreadGroup object
+   * \return true if the given thread was removed from this ThreadGroup
+   */
+  inline bool remove_thread(std::shared_ptr<Thread> thrd) {
+    if (thrd) {
+      WriteLock guard(m_);
+      auto iter = threads_.find(thrd);
+      if (iter != threads_.end()) {
+        name_to_thread_.erase(thrd->name());
+        threads_.erase(iter);
+        if (threads_.empty()) {
+          evEmpty_->signal();
+        }
+        return true;
+      }
+    }
+    return false;
+  }
+
+  /*!
+   * \brief Join all threads in this ThreadGroup
+   * \note While it is not valid to call 'join' on an auto-remove thread, this function will
+   *       wait for auto-remove threads to exit (waits for the ThreadGroup to become empty)
+   */
+  inline void join_all() {
+    CHECK_EQ(!is_this_thread_in(), true);
+    do {
+      std::unique_lock<std::mutex> lk(join_all_mtx_);
+      std::unordered_set<std::shared_ptr<Thread>> working_set;
+      {
+        ReadLock guard(m_);
+        for (auto iter = threads_.begin(), e_iter = threads_.end(); iter != e_iter; ++iter) {
+          if (!(*iter)->is_auto_remove()) {
+            working_set.emplace(*iter);
+          }
+        }
+      }
+      // Where possible, prefer to do a proper join rather than simply waiting for empty
+      // (easier to troubleshoot)
+      while (!working_set.empty()) {
+        std::shared_ptr<Thread> thrd;
+        thrd = *working_set.begin();
+        if (thrd->joinable()) {
+          thrd->join();
+        }
+        remove_thread(thrd);
+        working_set.erase(working_set.begin());
+        thrd.reset();
+      }
+      // Wait for auto-remove threads (if any) to complete
+    } while (0);
+    evEmpty_->wait();
+    CHECK_EQ(threads_.size(), 0);
+  }
+
+  /*!
+   * \brief Call request_shutdown() on all threads in this ThreadGroup
+   * \param make_all_joinable If true, remove all auto_remove flags from child threads
+   */
+  inline void request_shutdown_all(const bool make_all_joinable = true) {
+    std::unique_lock<std::mutex> lk(join_all_mtx_);
+    ReadLock guard(m_);
+    for (auto &thread : threads_) {
+      if (make_all_joinable) {
+        thread->make_joinable();
+      }
+      thread->request_shutdown();
+    }
+  }
+
+  /*!
+   * \brief Return the number of threads in this thread group
+   * \return Number of threads in this thread group
+   */
+  inline size_t size() const {
+    ReadLock guard(m_);
+    return threads_.size();
+  }
+
+  /*!
+   * \brief Check if the ThreadGroup is empty
+   * \return true if the ThreadGroup is empty
+   */
+  inline bool empty() const {
+    ReadLock guard(m_);
+    return threads_.size() == 0;
+  }
+
+  /*!
+   * \brief Create and launch a new Thread object which will be owned by this ThreadGroup
+   * \tparam StartFunction Function type for the thread 'main' function
+   * \tparam ThreadType managedThreadclass type (in case it's derived, for instance)
+   * \tparam Args Arguments to pass to the thread 'main' function
+   * \param threadName Name if the thread. Must be unique for a ThreadGroup object
+   * \param auto_remove If true, automatically remove this Thread object from the
+   *                    ThreadGroup owner upon exit
+   * \param start_function The Thread's 'main' function
+   * \param args Arguments to pass to the Thread's 'main' function
+   * \return true if the thread was successfully created and added to the ThreadGroup
+   *              If false is returned, the thread may have already been started, but if something
+   *              went wrong (ie duplicte thread name for the ThreadGroup), then request_shutdown()
+   *              will have been been called on the running thread
+   */
+  template<typename StartFunction, typename ThreadType = Thread, typename ...Args>
+  inline bool create(const std::string &threadName,
+                     bool auto_remove,
+                     StartFunction start_function,
+                     Args... args) {
+    typename ThreadType::SharedPtr newThread(new ThreadType(threadName, this));
+    return Thread::launch(newThread, auto_remove, start_function, args...);
+  }
+
+  /*!
+   * \brief Lookup Thread object by name
+   * \param name Name of the thread to look up
+   * \return A shared pointer to the Thread object
+   */
+  inline std::shared_ptr<Thread> thread_by_name(const std::string& name) {
+    ReadLock guard(m_);
+    auto iter = name_to_thread_.find(name);
+    if (iter != name_to_thread_.end()) {
+      return iter->second;
+    }
+    return nullptr;
+  }
+
+ private:
+  /*! \brief ThreadGroup synchronization mutex */
+  mutable SharedMutex m_;
+  /*! \brief join_all/auto_remove synchronization mutex */
+  mutable std::mutex join_all_mtx_;
+  /*! \brief Set of threads owned and managed by this ThreadGroup object */
+  std::unordered_set<std::shared_ptr<Thread>> threads_;
+  /*! \brief Manual event which is signaled when the thread group is empty */
+  std::shared_ptr<ManualEvent> evEmpty_;
+  /*! \brief name->thread mapping */
+  std::unordered_map<std::string, std::shared_ptr<Thread>> name_to_thread_;
+};
+
+/*!
+ * \brief Blocking queue thread class
+ * \tparam ObjectType Object type to queue
+ * \tparam quit_item Object value to signify queue shutdown (ie nullptr for pointer type is common)
+ * \note See gtest unit test Syc.ManagedThreadLaunchQueueThread for a usage example
+ */
+template<typename ObjectType, ObjectType quit_item>
+class BlockingQueueThread : public ThreadGroup::Thread {
+  using BQT = BlockingQueueThread<ObjectType, quit_item>;
+
+ public:
+  /*!
+   * \brief Constructor
+   * \param name Name for the blockin g queue thread. Must be unique for a specific ThreadGroup
+   * \param owner ThreadGroup lifecycle manafger/owner
+   * \param thrd Optionally attach an existing stl thread object
+   */
+  BlockingQueueThread(const std::string& name,
+                      dmlc::ThreadGroup *owner,
+                      std::thread *thrd = nullptr)
+    : ThreadGroup::Thread(std::move(name), owner, thrd)
+      , shutdown_in_progress_(false) {
+  }
+
+
+  /*!
+   * \brief Destructor
+   */
+  ~BlockingQueueThread() override {
+    // Call to parent first because we don't want to wait for the queue to empty
+    ThreadGroup::Thread::request_shutdown();
+    request_shutdown();
+  }
+
+  /*!
+   * \brief Signal the thread that a shutdown is desired
+   * \note Since consumer doesn't necessarily get items in order, we must wait for
+   *       the queue to empty.
+   *       This is generally a shutdown procedure and should not be called from
+   *       a performance-sensitive area
+   */
+  void request_shutdown() override {
+    shutdown_in_progress_ = true;
+    while (queue_->size_approx() > 0 && !ThreadGroup::Thread::is_shutdown_requested()) {
+      std::this_thread::sleep_for(std::chrono::milliseconds(1));
+    }
+    ThreadGroup::Thread::request_shutdown();
+    queue_->enqueue(quit_item);
+  }
+
+  /*!
+   * \brief Enqueue and item
+   * \param item The item to enqueue
+   */
+  void enqueue(const ObjectType& item) {
+    if (!shutdown_in_progress_) {
+      queue_->enqueue(item);
+    }
+  }
+
+  /*!
+   * \brief Get the approximate size of the queue
+   * \return The approximate size of the queue
+   */
+  size_t size_approx() const { return queue_->size_approx(); }
+
+  /*!
+   * \brief Launch to the 'run' function which will, in turn, call the class'
+   *        'run' function, passing it the given 'secondary_function'
+   *        for it to call as needed
+   * \tparam SecondaryFunction Type of the secondary function for 'run' override
+   *         to call as needed
+   * \param pThis Pointer to the managed thread to launch
+   * \param secondary_function secondary function for 'run' override to call as needed
+   * \return true if thread is launched successfully and added to the ThreadGroup
+   */
+  template<typename SecondaryFunction>
+  static bool launch_run(std::shared_ptr<BQT> pThis,
+                         SecondaryFunction secondary_function) {
+    return ThreadGroup::Thread::launch(pThis, true, [](std::shared_ptr<BQT> pThis,
+                                                       SecondaryFunction secondary_function) {
+                                         return pThis->run(secondary_function);
+                                       },
+                                       pThis, secondary_function);
+  }
+
+  /*!
+   * \brief Thread's main queue processing function
+   * \tparam OnItemFunction Function type to call when an item is dequeued
+   * \param on_item_function Function to call when an item is dequeued
+   * \return 0 if completed through a `quit_item`, nonzero if on_item_function requested an exit
+   */
+  template<typename OnItemFunction>
+  inline int run(OnItemFunction on_item_function) {
+    int rc = 0;
+    do {
+      ObjectType item;
+      queue_->wait_dequeue(item);
+      if (item == quit_item) {
+        break;
+      }
+      rc = on_item_function(item);
+      if (rc) {
+        break;
+      }
+    } while (true);
+    return rc;
+  }
+
+ private:
+  /*! \brief The blocking queue associated with this thread */
+  std::shared_ptr<dmlc::moodycamel::BlockingConcurrentQueue<ObjectType>> queue_ =
+    std::make_shared<dmlc::moodycamel::BlockingConcurrentQueue<ObjectType>>();
+  /*! \brief Whether shutdown request is in progress */
+  std::atomic<bool> shutdown_in_progress_;
+};
+
+/*!
+ * \brief Managed timer thread
+ * \tparam Duration Duration type (ie seconds, microseconds, etc)
+ */
+template<typename Duration>
+class TimerThread : public ThreadGroup::Thread {
+  using ThreadGroup::Thread::is_shutdown_requested;
+
+ public:
+  /*!
+   * \brief Constructor
+   * \param name Name of the timer thread
+   * \param owner ThreadGroup owner if the timer thread
+   */
+  TimerThread(const std::string& name, ThreadGroup *owner)
+    : Thread(name, owner) {
+  }
+
+  /*!
+   * \brief Destructor
+   */
+  ~TimerThread() override {
+    request_shutdown();
+  }
+
+  /*!
+   * \brief Launch to the 'run' function which will, in turn, call the class'
+   *        'run' function, passing it the given 'secondary_function'
+   *        for it to call as needed
+   * \tparam SecondaryFunction Type of the secondary function for 'run' override
+   *         to call as needed
+   * \param pThis Pointer to the managed thread to launch
+   * \param secondary_function secondary function for 'run' override to call as needed
+   * \return true if thread is launched successfully and added to the ThreadGroup
+   */
+  template<typename SecondaryFunction>
+  static bool launch_run(std::shared_ptr<TimerThread<Duration>> pThis,
+                         SecondaryFunction secondary_function) {
+    return ThreadGroup::Thread::launch(pThis, true, [](std::shared_ptr<TimerThread<Duration>> pThis,
+                                                       SecondaryFunction secondary_function) {
+                                         return pThis->run(secondary_function);
+                                       },
+                                       pThis, secondary_function);
+  }
+
+  /*!
+   * \brief Start a given timer thread
+   * \tparam Function Type of the timer function
+   * \param timer_thread Thread object to perform the timer events
+   * \param duration Duration between the end end of the timer function and the next timer event
+   * \param function Function to call when the timer expires
+   * \note Calling shutdown_requested() will cause the thread to exit the next time that the timer
+   *       expires.
+   */
+  template<typename Function>
+  static void start(std::shared_ptr<TimerThread> timer_thread,
+                    Duration duration,
+                    Function function) {
+    timer_thread->duration_ = duration;
+    launch_run(timer_thread, function);
+  }
+
+  /*!
+   * \brief Internal timer execution function
+   * \tparam OnTimerFunction Type of function to call each time the timer expires
+   * \param on_timer_function Function to call each time the timer expires
+   * \return Exit code of the thread
+   */
+  template<typename OnTimerFunction>
+  inline int run(OnTimerFunction on_timer_function) {
+    int rc = 0;
+    while (!is_shutdown_requested()) {
+      std::this_thread::sleep_for(duration_);
+      if (!is_shutdown_requested()) {
+        rc = on_timer_function();
+      }
+    }
+    return rc;
+  }
+
+ private:
+  Duration duration_;
+};
+
+/*
+ * Inline functions - see declarations for usage
+ */
+template <typename StartFunction, typename ...Args>
+inline int ThreadGroup::Thread::entry_and_exit_f(std::shared_ptr<Thread> pThis,
+                                                 StartFunction start_function,
+                                                 Args... args) {
+  int rc;
+  if (pThis) {
+    // Signal launcher that we're up and running
+    pThis->ready_event_->signal();
+    // Wait for launcher to be ready for us to start
+    pThis->start_event_->wait();
+    // Reset start_event_ for possible reuse
+    pThis->start_event_->reset();  // Reset in case it needs to be reused
+    // If we haven't been requested to shut down prematurely, then run the desired function
+    if (!pThis->is_shutdown_requested()) {
+      rc = start_function(args...);
+    } else {
+      rc = -1;
+    }
+    // If we're set up as auto-remove, then remove this thread from the thread group
+    if (pThis->is_auto_remove()) {
+      pThis->owner_->remove_thread(pThis);
+    }
+    // Release this thread shared pinter. May or may not be the last reference.
+    pThis.reset();
+  } else {
+    LOG(ERROR) << "Null pThis thread pointer";
+    rc = EINVAL;
+  }
+  return rc;
+}
+
+template<typename StartFunction, typename ...Args>
+inline bool ThreadGroup::Thread::launch(std::shared_ptr<Thread> pThis,
+                                        bool autoRemove,
+                                        StartFunction start_function,
+                                        Args ...args) {
+  WriteLock guard(pThis->thread_mutex_);
+  CHECK_EQ(!pThis->thread_.load(), true);
+  CHECK_NOTNULL(pThis->owner_);
+  // Set auto remove
+  pThis->auto_remove_ = autoRemove;
+  // Create the actual stl thread object
+  pThis->thread_ = new std::thread(Thread::template entry_and_exit_f<
+                                     StartFunction, Args...>,
+                                   pThis,
+                                   start_function,
+                                   args...);
+  // Attempt to add the thread to the thread group (after started, since in case
+  // something goes wrong, there's not a zombie thread in the thread group)
+  if (!pThis->owner_->add_thread(pThis)) {
+    pThis->request_shutdown();
+    LOG(ERROR) << "Duplicate thread name within the same thread group is not allowed";
+  }
+  // Wait for the thread to spin up
+  pThis->ready_event_->wait();
+  // Signal the thgread to continue (it will check its shutdown status)
+  pThis->start_event_->signal();
+  // Return if successful
+  return pThis->thread_.load() != nullptr;
+}
+
+/*!
+ * \brief Utility function to easily create a timer
+ * \tparam Duration Duration type (i.e. std::chrono::milliseconds)
+ * \tparam TimerFunction Function to call each time the timer expires
+ * \param timer_name Name of the timer. Must be unique per ThreadGroup object
+ * \param duration Duration of the timer between calls to timer_function
+ * \param owner ThreadGroup owner of the timer
+ * \param timer_function Function to call each time the timer expires
+ * \return true if the timer was successfully created
+ */
+template<typename Duration, typename TimerFunction>
+inline bool CreateTimer(const std::string& timer_name,
+                        const Duration& duration,
+                        ThreadGroup *owner,
+                        TimerFunction timer_function) {
+  std::shared_ptr<dmlc::TimerThread<Duration>> timer_thread =
+    std::make_shared<dmlc::TimerThread<Duration>>(timer_name, owner);
+  dmlc::TimerThread<Duration>::start(timer_thread, duration, timer_function);
+  return timer_thread != nullptr;
+}
+}  // namespace dmlc
+
+#endif  // DMLC_THREAD_GROUP_H_
diff --git a/darknet_drp_ros/include/dmlc/thread_local.h b/darknet_drp_ros/include/dmlc/thread_local.h
new file mode 100644
index 0000000..5caea4a
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/thread_local.h
@@ -0,0 +1,85 @@
+/*!
+ *  Copyright (c) 2015 by Contributors
+ * \file thread_local.h
+ * \brief Portable thread local storage.
+ */
+#ifndef DMLC_THREAD_LOCAL_H_
+#define DMLC_THREAD_LOCAL_H_
+
+#include <mutex>
+#include <memory>
+#include <vector>
+#include "./base.h"
+
+namespace dmlc {
+
+// macro hanlding for threadlocal variables
+#ifdef __GNUC__
+  #define MX_THREAD_LOCAL __thread
+#elif __STDC_VERSION__ >= 201112L
+  #define  MX_THREAD_LOCAL _Thread_local
+#elif defined(_MSC_VER)
+  #define MX_THREAD_LOCAL __declspec(thread)
+#endif
+
+#if DMLC_CXX11_THREAD_LOCAL == 0
+#pragma message("Warning: CXX11 thread_local is not formally supported")
+#endif
+
+/*!
+ * \brief A threadlocal store to store threadlocal variables.
+ *  Will return a thread local singleton of type T
+ * \tparam T the type we like to store
+ */
+template<typename T>
+class ThreadLocalStore {
+ public:
+  /*! \return get a thread local singleton */
+  static T* Get() {
+#if DMLC_CXX11_THREAD_LOCAL && DMLC_MODERN_THREAD_LOCAL == 1
+    static thread_local T inst;
+    return &inst;
+#else
+    static MX_THREAD_LOCAL T* ptr = nullptr;
+    if (ptr == nullptr) {
+      ptr = new T();
+      // Syntactic work-around for the nvcc of the initial cuda v10.1 release,
+      // which fails to compile 'Singleton()->' below. Fixed in v10.1 update 1.
+      (*Singleton()).RegisterDelete(ptr);
+    }
+    return ptr;
+#endif
+  }
+
+ private:
+  /*! \brief constructor */
+  ThreadLocalStore() {}
+  /*! \brief destructor */
+  ~ThreadLocalStore() {
+    for (size_t i = 0; i < data_.size(); ++i) {
+      delete data_[i];
+    }
+  }
+  /*! \return singleton of the store */
+  static ThreadLocalStore<T> *Singleton() {
+    static ThreadLocalStore<T> inst;
+    return &inst;
+  }
+  /*!
+   * \brief register str for internal deletion
+   * \param str the string pointer
+   */
+  void RegisterDelete(T *str) {
+    std::unique_lock<std::mutex> lock(mutex_);
+    data_.push_back(str);
+    lock.unlock();
+  }
+  /*! \brief internal mutex */
+  std::mutex mutex_;
+  /*!\brief internal data */
+  std::vector<T*> data_;
+};
+
+}  // namespace dmlc
+
+#endif  // DMLC_THREAD_LOCAL_H_
diff --git a/darknet_drp_ros/include/dmlc/threadediter.h b/darknet_drp_ros/include/dmlc/threadediter.h
new file mode 100644
index 0000000..6849371
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/threadediter.h
@@ -0,0 +1,512 @@
+/*!
+ *  Copyright (c) 2015 by Contributors
+ * \file threadediter.h
+ * \brief thread backed iterator that can be used to implement
+ *   general thread-based pipeline such as prefetch and pre-computation
+ * To use the functions in this header, C++11 is required
+ * \author Tianqi Chen
+ */
+#ifndef DMLC_THREADEDITER_H_
+#define DMLC_THREADEDITER_H_
+// defines DMLC_USE_CXX11
+#include "./base.h"
+// this code depends on c++11
+#if DMLC_ENABLE_STD_THREAD
+#include <condition_variable>
+#include <functional>
+#include <mutex>
+#include <queue>
+#include <atomic>
+#include <thread>
+#include <utility>
+#include <memory>
+#include "./data.h"
+#include "./logging.h"
+
+namespace dmlc {
+
+/*!
+ * \brief Wrapper class to manage std::thread; uses RAII pattern to automatically
+ *        join std::thread upon destruction
+ */
+class ScopedThread {
+ public:
+  /*!
+   * \brief constructor
+   * \param thread thread to manage
+   */
+  explicit ScopedThread(std::thread thread)
+      : thread_(std::move(thread)) {
+    if (!thread_.joinable()) {
+      throw std::logic_error("No thread");
+    }
+  }
+  // destructor: join upon destruction
+  virtual ~ScopedThread() {
+    thread_.join();
+  }
+  // copy assignment and construction are not allowed
+  ScopedThread(ScopedThread const&) = delete;
+  ScopedThread& operator=(ScopedThread const&) = delete;
+
+ private:
+  std::thread thread_;
+};
+
+/*!
+ * \brief a iterator that was backed by a thread
+ *  to pull data eagerly from a single producer into a bounded buffer
+ *  the consumer can pull the data at its own rate
+ *
+ * NOTE: thread concurrency cost time, make sure to store big blob of data in DType
+ *
+ * Usage example:
+ * \code
+ * ThreadedIter<DType> iter;
+ * iter.Init(&producer);
+ * // the following code can be in parallel
+ * DType *dptr;
+ * while (iter.Next(&dptr)) {
+ *   // do something on dptr
+ *   // recycle the space
+ *   iter.Recycle(&dptr);
+ * }
+ * \endcode
+ * \tparam DType the type of data blob we support
+ */
+template<typename DType>
+class ThreadedIter : public DataIter<DType> {
+ public:
+  /*!
+   * \brief producer class interface
+   *  that threaditer used as source to
+   *  preduce the content
+   */
+  class Producer {
+   public:
+    // virtual destructor
+    virtual ~Producer() = default;
+    /*! \brief reset the producer to beginning */
+    virtual void BeforeFirst(void) {
+      NotImplemented();
+    }
+    /*!
+     * \brief load the data content into DType,
+     * the caller can pass in NULL or an existing address
+     * when inout_dptr is NULL:
+     *    producer need to allocate a DType and fill the content
+     * when inout_dptr is specified
+     *    producer takes need to fill the content into address
+     *    specified inout_dptr, or delete the one and create a new one
+     *
+     * \param inout_dptr used to pass in the data holder cell
+     *        and return the address of the cell filled
+     * \return true if there is next record, false if we reach the end
+     */
+    virtual bool Next(DType **inout_dptr) = 0;
+  };
+  /*!
+   * \brief constructor
+   * \param max_capacity maximum capacity of the queue
+   */
+  explicit ThreadedIter(size_t max_capacity = 8)
+      : producer_(nullptr),
+        producer_thread_(nullptr),
+        max_capacity_(max_capacity),
+        nwait_consumer_(0),
+        nwait_producer_(0),
+        out_data_(NULL) {}
+  /*! \brief destructor */
+  virtual ~ThreadedIter(void) {
+    this->Destroy();
+  }
+  /*!
+   * \brief destroy all the related resources
+   *  this is equivalent to destructor, can be used
+   *  to destroy the threaditer when user think it is
+   *  appropriate, it is safe to call this multiple times
+   */
+  inline void Destroy(void);
+  /*!
+   * \brief set maximum capacity of the queue
+   * \param max_capacity maximum capacity of the queue
+   */
+  inline void set_max_capacity(size_t max_capacity) {
+    max_capacity_ = max_capacity;
+  }
+  /*!
+   * \brief initialize the producer and start the thread can only be
+   *   called once
+   * \param producer pointer to the producer
+   */
+  inline void Init(std::shared_ptr<Producer> producer);
+  /*!
+   * \brief initialize the producer and start the thread
+   *  pass in two function(closure) of producer to represent the producer
+   *  the beforefirst function is optional, and defaults to not implemented
+   *   NOTE: the closure must remain valid until the ThreadedIter destructs
+   * \param next the function called to get next element, see Producer.Next
+   * \param beforefirst the function to call to reset the producer, see Producer.BeforeFirst
+   */
+  inline void Init(std::function<bool(DType **)> next,
+                   std::function<void()> beforefirst = NotImplemented);
+  /*!
+   * \brief get the next data, this function is threadsafe
+   * \param out_dptr used to hold the pointer to the record
+   *  after the function call, the caller takes ownership of the pointer
+   *  the caller can call recycle to return ownership back to the threaditer
+   *  so that the pointer can be re-used
+   * \return true if there is next record, false if we reach the end
+   * \sa Recycle
+   */
+  inline bool Next(DType **out_dptr);
+  /*!
+   * \brief recycle the data cell, this function is threadsafe
+   * the threaditer can reuse the data cell for future data loading
+   * \param inout_dptr pointer to the dptr to recycle, after the function call
+   *        the content of inout_dptr will be set to NULL
+   */
+  inline void Recycle(DType **inout_dptr);
+
+  /*!
+   * \brief Rethrows exception which is set by the producer
+   */
+  inline void ThrowExceptionIfSet(void);
+
+  /*!
+   * \brief clears exception_ptr, called from Init
+   */
+  inline void ClearException(void);
+
+  /*!
+   * \brief adapt the iterator interface's Next
+   *  NOTE: the call to this function is not threadsafe
+   *  use the other Next instead
+   * \return true if there is next record, false if we reach the end
+   */
+  virtual bool Next(void) {
+    if (out_data_ != NULL) {
+      this->Recycle(&out_data_);
+    }
+    if (Next(&out_data_)) {
+      return true;
+    } else {
+      return false;
+    }
+  }
+  /*!
+   * \brief adapt the iterator interface's Value
+   *  NOTE: the call to this function is not threadsafe
+   *  use the other Next instead
+   */
+  virtual const DType &Value(void) const {
+    CHECK(out_data_ != NULL) << "Calling Value at beginning or end?";
+    return *out_data_;
+  }
+  /*! \brief set the iterator before first location */
+  virtual void BeforeFirst(void) {
+    ThrowExceptionIfSet();
+    std::unique_lock<std::mutex> lock(mutex_);
+    if (out_data_ != NULL) {
+      free_cells_.push(out_data_);
+      out_data_ = NULL;
+    }
+    if (producer_sig_.load(std::memory_order_acquire) == kDestroy)  return;
+
+    producer_sig_.store(kBeforeFirst, std::memory_order_release);
+    CHECK(!producer_sig_processed_.load(std::memory_order_acquire));
+    if (nwait_producer_ != 0) {
+      producer_cond_.notify_one();
+    }
+    CHECK(!producer_sig_processed_.load(std::memory_order_acquire));
+    // wait until the request has been processed
+    consumer_cond_.wait(lock, [this]() {
+        return producer_sig_processed_.load(std::memory_order_acquire);
+      });
+    producer_sig_processed_.store(false, std::memory_order_release);
+    bool notify = nwait_producer_ != 0 && !produce_end_;
+    lock.unlock();
+    // notify producer, in case they are waiting for the condition.
+    if (notify) producer_cond_.notify_one();
+    ThrowExceptionIfSet();
+  }
+
+ private:
+  /*! \brief not support BeforeFirst */
+  inline static void NotImplemented(void) {
+    LOG(FATAL) << "BeforeFirst is not supported";
+  }
+  /*! \brief signals send to producer */
+  enum Signal {
+    kProduce,
+    kBeforeFirst,
+    kDestroy
+  };
+  /*! \brief producer class */
+  // Producer *producer_owned_;
+  std::shared_ptr<Producer> producer_;
+
+  /*! \brief signal to producer */
+  std::atomic<Signal> producer_sig_;
+  /*! \brief whether the special signal other than kProduce is procssed */
+  std::atomic<bool> producer_sig_processed_;
+  /*! \brief thread that runs the producer */
+  std::unique_ptr<ScopedThread> producer_thread_;
+  /*! \brief whether produce ends */
+  std::atomic<bool> produce_end_;
+  /*! \brief maximum queue size */
+  size_t max_capacity_;
+  /*! \brief internal mutex */
+  std::mutex mutex_;
+  /*! brief internal mutex for exceptions */
+  std::mutex mutex_exception_;
+  /*! \brief number of consumer waiting */
+  unsigned nwait_consumer_;
+  /*! \brief number of producer waiting */
+  unsigned nwait_producer_;
+  /*! \brief conditional variable for producer thread */
+  std::condition_variable producer_cond_;
+  /*! \brief conditional variable for consumer threads */
+  std::condition_variable consumer_cond_;
+  /*! \brief the current output cell */
+  DType *out_data_;
+  /*! \brief internal queue of producer */
+  std::queue<DType*> queue_;
+  /*! \brief free cells that can be used */
+  std::queue<DType*> free_cells_;
+  /*! \brief holds a reference to iterator exception thrown in spawned threads */
+  std::exception_ptr iter_exception_{nullptr};
+};
+
+// implementation of functions
+template <typename DType> inline void ThreadedIter<DType>::Destroy(void) {
+  if (producer_thread_) {
+    {
+      // lock the mutex
+      std::lock_guard<std::mutex> lock(mutex_);
+      // send destroy signal
+      producer_sig_.store(kDestroy, std::memory_order_release);
+      if (nwait_producer_ != 0) {
+        producer_cond_.notify_one();
+      }
+    }
+    producer_thread_.reset(nullptr);
+  }
+  // end of critical region
+  // now the slave thread should exit
+  while (free_cells_.size() != 0) {
+    delete free_cells_.front();
+    free_cells_.pop();
+  }
+  while (queue_.size() != 0) {
+    delete queue_.front();
+    queue_.pop();
+  }
+  if (producer_ != NULL) {
+    producer_.reset();
+  }
+  if (out_data_ != NULL) {
+    delete out_data_;
+    out_data_ = NULL;
+  }
+}
+
+template<typename DType>
+inline void ThreadedIter<DType>::
+Init(std::shared_ptr<Producer> producer) {
+  CHECK(producer_ == NULL) << "can only call Init once";
+  auto next = [producer](DType **dptr) {
+      return producer->Next(dptr);
+  };
+  auto beforefirst = [producer]() {
+    producer->BeforeFirst();
+  };
+  this->Init(next, beforefirst);
+}
+
+template <typename DType>
+inline void ThreadedIter<DType>::Init(std::function<bool(DType **)> next,
+                                      std::function<void()> beforefirst) {
+  producer_sig_.store(kProduce, std::memory_order_release);
+  producer_sig_processed_.store(false, std::memory_order_release);
+  produce_end_.store(false, std::memory_order_release);
+  ClearException();
+  // procedure running in prodcuer
+  // run producer thread
+  auto producer_fun = [this, next, beforefirst]() {
+    while (true) {
+      try {
+        DType *cell = NULL;
+        {
+          // lockscope
+          std::unique_lock<std::mutex> lock(mutex_);
+          ++this->nwait_producer_;
+          producer_cond_.wait(lock, [this]() {
+            if (producer_sig_.load(std::memory_order_acquire) == kProduce) {
+              bool ret = !produce_end_.load(std::memory_order_acquire)
+                         && (queue_.size() < max_capacity_ ||
+                             free_cells_.size() != 0);
+              return ret;
+            } else {
+              return true;
+            }
+          });
+          --this->nwait_producer_;
+          if (producer_sig_.load(std::memory_order_acquire) == kProduce) {
+            if (free_cells_.size() != 0) {
+              cell = free_cells_.front();
+              free_cells_.pop();
+            }
+          } else if (producer_sig_.load(std::memory_order_acquire) == kBeforeFirst) {
+            // reset the producer
+            beforefirst();
+            // cleanup the queue
+            while (queue_.size() != 0) {
+              free_cells_.push(queue_.front());
+              queue_.pop();
+            }
+            // reset the state
+            produce_end_.store(false, std::memory_order_release);
+            producer_sig_processed_.store(true, std::memory_order_release);
+            producer_sig_.store(kProduce, std::memory_order_release);
+            // notify consumer that all the process as been done.
+            lock.unlock();
+            consumer_cond_.notify_all();
+            continue;
+          } else {
+            // destroy the thread
+            DCHECK(producer_sig_.load(std::memory_order_acquire) == kDestroy);
+            producer_sig_processed_.store(true, std::memory_order_release);
+            produce_end_.store(true, std::memory_order_release);
+            lock.unlock();
+            consumer_cond_.notify_all();
+            return;
+          }
+        }  // end of lock scope
+        // now without lock
+        produce_end_.store(!next(&cell), std::memory_order_release);
+        DCHECK(cell != NULL || produce_end_.load(std::memory_order_acquire));
+        bool notify;
+        {
+          // lockscope
+          std::lock_guard<std::mutex> lock(mutex_);
+          if (!produce_end_.load(std::memory_order_acquire)) {
+            queue_.push(cell);
+          } else {
+            if (cell != NULL)
+              free_cells_.push(cell);
+          }
+          // put things into queue
+          notify = nwait_consumer_ != 0;
+        }
+        if (notify)
+          consumer_cond_.notify_all();
+      } catch (std::exception &e) {
+        // Shouldn't throw exception in destructor
+        DCHECK(producer_sig_.load(std::memory_order_acquire) != kDestroy);
+        {
+          std::lock_guard<std::mutex> lock(mutex_exception_);
+          if (!iter_exception_) {
+            iter_exception_ = std::current_exception();
+          }
+        }
+        bool next_notify = false;
+        {
+          std::unique_lock<std::mutex> lock(mutex_);
+          if (producer_sig_.load(std::memory_order_acquire) == kBeforeFirst) {
+            while (queue_.size() != 0) {
+              free_cells_.push(queue_.front());
+              queue_.pop();
+            }
+            produce_end_.store(true, std::memory_order_release);
+            producer_sig_processed_.store(true, std::memory_order_release);
+            lock.unlock();
+            consumer_cond_.notify_all();
+          } else if (producer_sig_.load(std::memory_order_acquire) == kProduce) {
+            produce_end_.store(true, std::memory_order_release);
+            next_notify = nwait_consumer_ != 0;
+            lock.unlock();
+            if (next_notify)
+              consumer_cond_.notify_all();
+          }
+        }
+        return;
+      }
+    }
+  };
+  producer_thread_.reset(new ScopedThread{std::thread(producer_fun)});
+}
+
+template <typename DType>
+inline bool ThreadedIter<DType>::Next(DType **out_dptr) {
+  if (producer_sig_.load(std::memory_order_acquire) == kDestroy)
+    return false;
+  ThrowExceptionIfSet();
+  std::unique_lock<std::mutex> lock(mutex_);
+  CHECK(producer_sig_.load(std::memory_order_acquire) == kProduce)
+      << "Make sure you call BeforeFirst not inconcurrent with Next!";
+  ++nwait_consumer_;
+  consumer_cond_.wait(lock,
+                      [this]() { return queue_.size() != 0
+                                 || produce_end_.load(std::memory_order_acquire); });
+  --nwait_consumer_;
+  if (queue_.size() != 0) {
+    *out_dptr = queue_.front();
+    queue_.pop();
+    bool notify = nwait_producer_ != 0
+                  && !produce_end_.load(std::memory_order_acquire);
+    lock.unlock();
+    if (notify)
+      producer_cond_.notify_one();
+
+    ThrowExceptionIfSet();
+    return true;
+  } else {
+    CHECK(produce_end_.load(std::memory_order_acquire));
+    lock.unlock();
+
+    ThrowExceptionIfSet();
+    return false;
+  }
+}
+
+template <typename DType>
+inline void ThreadedIter<DType>::Recycle(DType **inout_dptr) {
+  bool notify;
+  ThrowExceptionIfSet();
+  {
+    std::lock_guard<std::mutex> lock(mutex_);
+    free_cells_.push(*inout_dptr);
+    *inout_dptr = NULL;
+    notify = nwait_producer_ != 0 && !produce_end_.load(std::memory_order_acquire);
+  }
+  if (notify)
+    producer_cond_.notify_one();
+  ThrowExceptionIfSet();
+}
+
+template <typename DType> inline void ThreadedIter<DType>::ThrowExceptionIfSet(void) {
+  std::exception_ptr tmp_exception{nullptr};
+  {
+    std::lock_guard<std::mutex> lock(mutex_exception_);
+    if (iter_exception_) {
+      tmp_exception = iter_exception_;
+    }
+  }
+  if (tmp_exception) {
+    try {
+      std::rethrow_exception(tmp_exception);
+    } catch (std::exception& exc) {
+      LOG(FATAL) << exc.what();
+    }
+  }
+}
+
+template <typename DType> inline void ThreadedIter<DType>::ClearException(void) {
+  std::lock_guard<std::mutex> lock(mutex_exception_);
+  iter_exception_ = nullptr;
+}
+
+}  // namespace dmlc
+#endif  // DMLC_USE_CXX11
+#endif  // DMLC_THREADEDITER_H_
diff --git a/darknet_drp_ros/include/dmlc/timer.h b/darknet_drp_ros/include/dmlc/timer.h
new file mode 100644
index 0000000..c97059f
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/timer.h
@@ -0,0 +1,49 @@
+/*!
+ *  Copyright (c) 2015 by Contributors
+ * \file timer.h
+ * \brief cross platform timer for timing
+ * \author Tianqi Chen
+ */
+#ifndef DMLC_TIMER_H_
+#define DMLC_TIMER_H_
+
+#include "base.h"
+
+#if DMLC_USE_CXX11
+#include <chrono>
+#endif
+
+#include <time.h>
+#ifdef __MACH__
+#include <mach/clock.h>
+#include <mach/mach.h>
+#endif
+#include "./logging.h"
+
+namespace dmlc {
+/*!
+ * \brief return time in seconds
+ */
+inline double GetTime(void) {
+  #if DMLC_USE_CXX11
+  return std::chrono::duration<double>(
+      std::chrono::high_resolution_clock::now().time_since_epoch()).count();
+  #elif defined __MACH__
+  clock_serv_t cclock;
+  mach_timespec_t mts;
+  host_get_clock_service(mach_host_self(), CALENDAR_CLOCK, &cclock);
+  CHECK(clock_get_time(cclock, &mts) == 0) << "failed to get time";
+  mach_port_deallocate(mach_task_self(), cclock);
+  return static_cast<double>(mts.tv_sec) + static_cast<double>(mts.tv_nsec) * 1e-9;
+  #else
+  #if defined(__unix__) || defined(__linux__)
+  timespec ts;
+  CHECK(clock_gettime(CLOCK_REALTIME, &ts) == 0) << "failed to get time";
+  return static_cast<double>(ts.tv_sec) + static_cast<double>(ts.tv_nsec) * 1e-9;
+  #else
+  return static_cast<double>(time(NULL));
+  #endif
+  #endif
+}
+}  // namespace dmlc
+#endif  // DMLC_TIMER_H_
diff --git a/darknet_drp_ros/include/dmlc/type_traits.h b/darknet_drp_ros/include/dmlc/type_traits.h
new file mode 100644
index 0000000..8c19816
--- /dev/null
+++ b/darknet_drp_ros/include/dmlc/type_traits.h
@@ -0,0 +1,192 @@
+/*!
+ *  Copyright (c) 2015 by Contributors
+ * \file type_traits.h
+ * \brief type traits information header
+ */
+#ifndef DMLC_TYPE_TRAITS_H_
+#define DMLC_TYPE_TRAITS_H_
+
+#include "./base.h"
+#if DMLC_USE_CXX11
+#include <type_traits>
+#endif
+#include <string>
+
+namespace dmlc {
+/*!
+ * \brief whether a type is pod type
+ * \tparam T the type to query
+ */
+template<typename T>
+struct is_pod {
+#if DMLC_USE_CXX11
+  /*! \brief the value of the traits */
+  static const bool value = std::is_pod<T>::value;
+#else
+  /*! \brief the value of the traits */
+  static const bool value = false;
+#endif
+};
+
+
+/*!
+ * \brief whether a type is integer type
+ * \tparam T the type to query
+ */
+template<typename T>
+struct is_integral {
+#if DMLC_USE_CXX11
+  /*! \brief the value of the traits */
+  static const bool value = std::is_integral<T>::value;
+#else
+  /*! \brief the value of the traits */
+  static const bool value = false;
+#endif
+};
+
+/*!
+ * \brief whether a type is floating point type
+ * \tparam T the type to query
+ */
+template<typename T>
+struct is_floating_point {
+#if DMLC_USE_CXX11
+  /*! \brief the value of the traits */
+  static const bool value = std::is_floating_point<T>::value;
+#else
+  /*! \brief the value of the traits */
+  static const bool value = false;
+#endif
+};
+
+/*!
+ * \brief whether a type is arithemetic type
+ * \tparam T the type to query
+ */
+template<typename T>
+struct is_arithmetic {
+#if DMLC_USE_CXX11
+  /*! \brief the value of the traits */
+  static const bool value = std::is_arithmetic<T>::value;
+#else
+  /*! \brief the value of the traits */
+  static const bool value = (dmlc::is_integral<T>::value ||
+                             dmlc::is_floating_point<T>::value);
+#endif
+};
+
+/*!
+ * \brief helper class to construct a string that represents type name
+ *
+ * Specialized this class to defined type name of custom types
+ *
+ * \tparam T the type to query
+ */
+template<typename T>
+struct type_name_helper {
+  /*!
+   * \return a string of typename.
+   */
+  static inline std::string value() {
+    return "";
+  }
+};
+
+/*!
+ * \brief the string representation of type name
+ * \tparam T the type to query
+ * \return a const string of typename.
+ */
+template<typename T>
+inline std::string type_name() {
+  return type_name_helper<T>::value();
+}
+
+/*!
+ * \brief whether a type have save/load function
+ * \tparam T the type to query
+ */
+template<typename T>
+struct has_saveload {
+  /*! \brief the value of the traits */
+  static const bool value = false;
+};
+
+/*!
+ * \brief template to select type based on condition
+ * For example, IfThenElseType<true, int, float>::Type will give int
+ * \tparam cond the condition
+ * \tparam Then the typename to be returned if cond is true
+ * \tparam Else typename to be returned if cond is false
+*/
+template<bool cond, typename Then, typename Else>
+struct IfThenElseType;
+
+/*! \brief macro to quickly declare traits information */
+#define DMLC_DECLARE_TRAITS(Trait, Type, Value)       \
+  template<>                                          \
+  struct Trait<Type> {                                \
+    static const bool value = Value;                  \
+  }
+
+/*! \brief macro to quickly declare traits information */
+#define DMLC_DECLARE_TYPE_NAME(Type, Name)            \
+  template<>                                          \
+  struct type_name_helper<Type> {                     \
+    static inline std::string value() {               \
+      return Name;                                    \
+    }                                                 \
+  }
+
+//! \cond Doxygen_Suppress
+// declare special traits when C++11 is not available
+#if DMLC_USE_CXX11 == 0
+DMLC_DECLARE_TRAITS(is_pod, char, true);
+DMLC_DECLARE_TRAITS(is_pod, int8_t, true);
+DMLC_DECLARE_TRAITS(is_pod, int16_t, true);
+DMLC_DECLARE_TRAITS(is_pod, int32_t, true);
+DMLC_DECLARE_TRAITS(is_pod, int64_t, true);
+DMLC_DECLARE_TRAITS(is_pod, uint8_t, true);
+DMLC_DECLARE_TRAITS(is_pod, uint16_t, true);
+DMLC_DECLARE_TRAITS(is_pod, uint32_t, true);
+DMLC_DECLARE_TRAITS(is_pod, uint64_t, true);
+DMLC_DECLARE_TRAITS(is_pod, float, true);
+DMLC_DECLARE_TRAITS(is_pod, double, true);
+
+DMLC_DECLARE_TRAITS(is_integral, char, true);
+DMLC_DECLARE_TRAITS(is_integral, int8_t, true);
+DMLC_DECLARE_TRAITS(is_integral, int16_t, true);
+DMLC_DECLARE_TRAITS(is_integral, int32_t, true);
+DMLC_DECLARE_TRAITS(is_integral, int64_t, true);
+DMLC_DECLARE_TRAITS(is_integral, uint8_t, true);
+DMLC_DECLARE_TRAITS(is_integral, uint16_t, true);
+DMLC_DECLARE_TRAITS(is_integral, uint32_t, true);
+DMLC_DECLARE_TRAITS(is_integral, uint64_t, true);
+
+DMLC_DECLARE_TRAITS(is_floating_point, float, true);
+DMLC_DECLARE_TRAITS(is_floating_point, double, true);
+
+#endif
+
+DMLC_DECLARE_TYPE_NAME(float, "float");
+DMLC_DECLARE_TYPE_NAME(double, "double");
+DMLC_DECLARE_TYPE_NAME(int, "int");
+DMLC_DECLARE_TYPE_NAME(int64_t, "long");
+DMLC_DECLARE_TYPE_NAME(uint32_t, "int (non-negative)");
+DMLC_DECLARE_TYPE_NAME(uint64_t, "long (non-negative)");
+DMLC_DECLARE_TYPE_NAME(std::string, "string");
+DMLC_DECLARE_TYPE_NAME(bool, "boolean");
+DMLC_DECLARE_TYPE_NAME(void*, "ptr");
+
+template<typename Then, typename Else>
+struct IfThenElseType<true, Then, Else> {
+  typedef Then Type;
+};
+
+template<typename Then, typename Else>
+struct IfThenElseType<false, Then, Else> {
+  typedef Else Type;
+};
+//! \endcond
+}  // namespace dmlc
+#endif  // DMLC_TYPE_TRAITS_H_
diff --git a/darknet_drp_ros/include/tvm/arith/analyzer.h b/darknet_drp_ros/include/tvm/arith/analyzer.h
new file mode 100644
index 0000000..885c23f
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/arith/analyzer.h
@@ -0,0 +1,682 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/arith/analyzer.h
+ * \brief Algebra expression simplifications.
+ */
+#ifndef TVM_ARITH_ANALYZER_H_
+#define TVM_ARITH_ANALYZER_H_
+
+#include <tvm/arith/int_set.h>
+#include <tvm/ir/expr.h>
+#include <tvm/support/with.h>
+
+#include <limits>
+#include <memory>
+#include <unordered_map>
+#include <vector>
+
+namespace tvm {
+/*! \brief namespace of arithmetic analysis. */
+namespace arith {
+//-------------------------------------------------------
+// Base integer analysis API.
+//
+// We have multiple type of analyzers to do relaxed
+// integer set analysis(bound analysis, modulo) and
+// equivalence checking and simplification.
+//
+// Importantly, each analyzer may need result from
+// another analyzer.
+//-------------------------------------------------------
+
+// Forward declare Analyzer
+class Analyzer;
+
+using tir::Var;
+
+enum DivMode {
+  /*! \brief Truncated division. */
+  kTruncDiv,
+  /*! \brief Floor division. */
+  kFloorDiv
+};
+
+/*!
+ * \brief Constant integer up and lower bound(inclusive).
+ *  Useful for value bound analysis.
+ *
+ *  set = [min_value, max_value]
+ */
+class ConstIntBoundNode : public Object {
+ public:
+  int64_t min_value;
+  int64_t max_value;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("min_value", &min_value);
+    v->Visit("max_value", &max_value);
+  }
+
+  bool SEqualReduce(const ConstIntBoundNode* other, SEqualReducer equal) const {
+    return equal(min_value, other->min_value) && equal(max_value, other->max_value);
+  }
+
+  /*! \brief Number to represent +inf */
+  static const constexpr int64_t kPosInf = std::numeric_limits<int64_t>::max();
+  /*!
+   * \brief Number to represent -inf
+   * \note We can make use the of fact that -kPosInf == kNegInf in the project.
+   */
+  static const constexpr int64_t kNegInf = -kPosInf;
+
+  static constexpr const char* _type_key = "arith.ConstIntBound";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ConstIntBoundNode, Object);
+};
+
+/*!
+ * \brief reference class to ConstIntBoundNode
+ * \sa ConstIntBoundNode
+ */
+class ConstIntBound : public ObjectRef {
+ public:
+  /*!
+   * \brief constructor by fields.
+   * \param min_value The mininum value.
+   * \param max_value The maximum value.
+   */
+  TVM_DLL ConstIntBound(int64_t min_value, int64_t max_value);
+
+  static const constexpr int64_t kPosInf = ConstIntBoundNode::kPosInf;
+  static const constexpr int64_t kNegInf = ConstIntBoundNode::kNegInf;
+  TVM_DEFINE_OBJECT_REF_METHODS(ConstIntBound, ObjectRef, ConstIntBoundNode);
+};
+
+/*!
+ * \brief Analyzer to get constant integer bound over expression.
+ */
+class ConstIntBoundAnalyzer {
+ public:
+  using BoundMapType = std::unordered_map<PrimExpr, ConstIntBound, ObjectPtrHash, ObjectPtrEqual>;
+  /*!
+   * \brief analyze the expr
+   * \param expr The expression of interest.
+   * \return the result of the analysis.
+   */
+  TVM_DLL ConstIntBound operator()(const PrimExpr& expr) const;
+
+  /*!
+   * \brief analyze the expr with the intermediate memorized to avoid redundant computation
+   * \param expr The expression of interest.
+   * \param bound The lookup table to store the intermediate results
+   * \return the result of the analysis.
+   */
+  TVM_DLL ConstIntBound operator()(const PrimExpr& expr, BoundMapType* bound);
+
+  /*!
+   * \brief Update constant int bound information of var.
+   *
+   * \param var The variable of interest.
+   * \param info The bound information.
+   * \param allow_override whether we allow override of existing information.
+   */
+  TVM_DLL void Update(const Var& var, const ConstIntBound& info, bool allow_override = false);
+  /*!
+   * \brief Bind variable to a range.
+   *
+   * \param var The variable.
+   * \param range The range we bind to.
+   * \param allow_override Whether we allow overriding an existing var's range.
+   */
+  TVM_DLL void Bind(const Var& var, const Range& range, bool allow_override = false);
+
+ private:
+  friend class Analyzer;
+  friend class ConstraintContext;
+  explicit ConstIntBoundAnalyzer(Analyzer* parent);
+  TVM_DLL ~ConstIntBoundAnalyzer();
+  /*!
+   * \brief Update the internal state to enter constraint.
+   * \param constraint A constraint expression.
+   *
+   * \return an exit function that must be called to cleanup the constraint can be nullptr.
+   */
+  std::function<void()> EnterConstraint(const PrimExpr& constraint);
+  struct Entry;
+  class Impl;
+  /*! \brief Internal impl */
+  Impl* impl_;
+};
+
+/*!
+ * \brief Range of a linear integer function.
+ *  Use to do specify the possible index values.
+ *
+ *  set = { coeff * x + base | x in Z }
+ *
+ *  When coeff != 0, it can also be written as
+ *  set = { n | n % coeff == base }
+ *
+ *  This is useful to decide if the index is dividable by certain value.
+ *  For example, if index = 0 + 4 x, then we know it can be divided by 4.
+ */
+class ModularSetNode : public Object {
+ public:
+  /*! \brief linear co-efficient */
+  int64_t coeff;
+  /*! \brief The base */
+  int64_t base;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("coeff", &coeff);
+    v->Visit("base", &base);
+  }
+
+  bool SEqualReduce(const ModularSetNode* other, SEqualReducer equal) const {
+    return equal(coeff, other->coeff) && equal(base, other->base);
+  }
+
+  static constexpr const char* _type_key = "arith.ModularSet";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ModularSetNode, Object);
+};
+
+/*!
+ * \brief reference of ModularSetNode
+ * \sa ModularSetNode
+ */
+class ModularSet : public ObjectRef {
+ public:
+  TVM_DLL ModularSet(int64_t coeff, int64_t base);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(ModularSet, ObjectRef, ModularSetNode);
+};
+
+/*!
+ * \brief Analyzer to get modular information over expression.
+ */
+class ModularSetAnalyzer {
+ public:
+  /*!
+   * \brief analyze the expr
+   * \param expr The expression of interest.
+   * \return the result of the analysis.
+   */
+  TVM_DLL ModularSet operator()(const PrimExpr& expr);
+  /*!
+   * \brief Update constant int bound information of var.
+   *
+   * \param var The variable of interest.
+   * \param info The bound information.
+   * \param allow_override whether we allow override of existing information.
+   */
+  TVM_DLL void Update(const Var& var, const ModularSet& info, bool allow_override = false);
+
+ private:
+  friend class Analyzer;
+  friend class ConstraintContext;
+  explicit ModularSetAnalyzer(Analyzer* parent);
+  TVM_DLL ~ModularSetAnalyzer();
+  /*!
+   * \brief Update the internal state to enter constraint.
+   * \param constraint A constraint expression.
+   *
+   * \return an exit function that must be called to cleanup the constraint can be nullptr.
+   */
+  std::function<void()> EnterConstraint(const PrimExpr& constraint);
+  struct Entry;
+  class Impl;
+  /*! \brief Internal impl */
+  Impl* impl_;
+};
+
+/*!
+ * \brief Rewrite-rule based simplifier.
+ */
+class RewriteSimplifier {
+ public:
+  /*!
+   * \brief analyze the expr
+   * \param expr The expression of interest.
+   * \return the result of the analysis.
+   */
+  TVM_DLL PrimExpr operator()(const PrimExpr& expr);
+
+  /*!
+   * \brief Update binding of var to a new expression.
+   *
+   * \param var The variable of interest.
+   * \param new_expr
+   * \param allow_override Whether we allow override of existing information.
+   */
+  TVM_DLL void Update(const Var& var, const PrimExpr& new_expr, bool allow_override = false);
+
+  /*!
+   * \brief Update the internal state to enter constraint.
+   * \param constraint A constraint expression.
+   *
+   * \return an exit function that must be called to cleanup the constraint can be nullptr.
+   */
+  TVM_DLL std::function<void()> EnterConstraint(const PrimExpr& constraint);
+
+  /*! \brief Flags to enable more computationally-intensive simplifications
+   *
+   * These simplifications may be required for specific schedules, but
+   * would impose too high a compile-time cost to enable by default.
+   * They can be enabled on an as-needed basis by calling
+   * `RewriteSimplifier::SetEnabledExtensions` prior to using
+   * `RewriteSimplifier::operator()`.
+   *
+   * Flags are defined as powers of two to allow future expansion.  To
+   * enable multiple extensions, a user should pass a bitwise OR of the
+   * flags for each desired extension.
+   */
+  enum Extension {
+    // No extensions enabled
+    kNone = 0,
+
+    /* When simplifying an inequality, attempt to use scope-based knowns.
+     *
+     * Example:
+     * if_then_else(i<j && j<k, i<k, false) => if_then_else(i<j && j<k, true, false)
+     */
+    kTransitivelyProveInequalities = (1 << 0),
+
+    /* When simplifying a boolean expression, convert to an AND of ORs
+     * (conjunctive normal form).
+     *
+     * Example:
+     *   (a && b) || c => (a || c) && (b || c)
+     */
+    kConvertBooleanToAndOfOrs = (1 << 1),
+
+    /* When simplifying a boolean AND or a boolean OR, simplify each
+     * branch under the assumption that the other branch does not
+     * already dominate the result.  That is, simplify each branch of
+     * (A && B) under the assumption that the other branch is true,
+     * and simplify each branch of (A || B) under the assumption that
+     * the other branch is false.
+     *
+     * Example:
+     *   (n < 10) && (n < 5) => (n < 10)
+     *   (n < 10) || (n < 5) => (n < 5)
+     */
+    kApplyConstraintsToBooleanBranches = (1 << 2),
+  };
+
+  /*! \brief Enable an optional extension or extensions
+   *
+   * \param flags A bitwise OR of all optional extensions that should
+   * be enabled.
+   */
+  TVM_DLL void SetEnabledExtensions(Extension flags);
+
+  /*! \brief Return the currently enabled extensions */
+  TVM_DLL Extension GetEnabledExtensions() const;
+
+ private:
+  friend class Analyzer;
+  friend class ConstraintContext;
+  friend class CanonicalSimplifier;
+  explicit RewriteSimplifier(Analyzer* parent);
+  TVM_DLL ~RewriteSimplifier();
+  class Impl;
+  /*! \brief Internal impl */
+  Impl* impl_;
+};
+
+/*!
+ * \brief Canonical-form based simplifier.
+ */
+class CanonicalSimplifier {
+ public:
+  /*!
+   * \brief analyze the expr
+   * \param expr The expression of interest.
+   * \return the result of the analysis.
+   */
+  TVM_DLL PrimExpr operator()(const PrimExpr& expr);
+
+  /*!
+   * \brief Update binding of var to a new expression.
+   *
+   * \param var The variable of interest.
+   * \param new_expr
+   * \param allow_override whether we allow override of existing information.
+   */
+  TVM_DLL void Update(const Var& var, const PrimExpr& new_expr, bool allow_override = false);
+
+ private:
+  friend class Analyzer;
+  friend class ConstraintContext;
+  explicit CanonicalSimplifier(Analyzer* parent);
+  TVM_DLL ~CanonicalSimplifier();
+  class Impl;
+  /*! \brief Internal impl */
+  Impl* impl_;
+};
+
+/*! \brief Structure for representing result of known
+ *
+ * Values are assigned to allow these flags to be used in bitwise
+ * operations.
+ */
+enum class CompareResult : int {
+  kInconsistent = 0,
+  kEQ = 1,
+  kLT = 2,
+  kLE = 3,
+  kGT = 4,
+  kGE = 5,
+  kNE = 6,
+  kUnknown = 7
+};
+
+inline constexpr CompareResult operator&(CompareResult lhs, CompareResult rhs) {
+  return CompareResult(static_cast<int>(lhs) & static_cast<int>(rhs));
+}
+inline constexpr CompareResult operator|(CompareResult lhs, CompareResult rhs) {
+  return CompareResult(static_cast<int>(lhs) | static_cast<int>(rhs));
+}
+
+/*!
+ * \brief Using previously specified knowns, compare the expressions provided
+ *
+ * Given known expressions [(a OP b), (b OP c), ..., (y OP z)], search
+ * for a known result for `(a OP z)`.
+ */
+class TransitiveComparisonAnalyzer {
+ public:
+  /* \brief Using previously specified knowns, compare the expressions provided
+   *
+   * \param lhs The left-hand side of the comparison
+   *
+   * \param rhs The right-hand side of the comparison
+   *
+   * \param propagate_inequalities If true, attempt to find a sequence
+   * of transitive inequalities that allow the lhs and rhs to be
+   * compared.  If false, only use the known comparison that have been
+   * directly provided.  Using `propagate_inequalities = false` is
+   * roughly equivalent to comparing against all known inequality
+   * expressions using `ExprDeepEqual`, but also allows for constant
+   * offsets on either side of the inequality.
+   *
+   * \return The most specific result that can be proven about the
+   * comparison.  If nothing can be proven, returns kUnknown.
+   */
+  TVM_DLL CompareResult TryCompare(const PrimExpr& lhs, const PrimExpr& rhs,
+                                   bool propagate_inequalities = true);
+
+  /*! \brief Bind a variable as being equal to a known expression
+   *
+   * \param var The variable of interest.
+   * \param expr The bound expression
+   * \param allow_override Whether to allow override of existing information.
+   */
+  TVM_DLL void Bind(const Var& var, const PrimExpr& expr, bool allow_override = false);
+
+  /*! \brief Bind a variable as being within a specified range
+   *
+   * \param var The variable of interest.
+   * \param range The known range
+   * \param allow_override Whether to allow override of existing information.
+   */
+  TVM_DLL void Bind(const Var& var, const Range& range, bool allow_override = false);
+
+  /*!
+   * \brief Update the internal state to enter constraint.
+   * \param constraint A constraint expression.
+   *
+   * \return an exit function that must be called to cleanup the constraint can be nullptr.
+   */
+  TVM_DLL std::function<void()> EnterConstraint(const PrimExpr& constraint);
+
+ private:
+  friend class Analyzer;
+  friend class ConstraintContext;
+  TransitiveComparisonAnalyzer();
+  TVM_DLL ~TransitiveComparisonAnalyzer();
+  class Impl;
+  /*! \brief Internal impl */
+  std::unique_ptr<Impl> impl_;
+};
+
+/*!
+ * \brief Constraint context.
+ *
+ * \code
+ *
+ *  Var("x");
+ *  arith::Analyzer analyzer;
+ *  {
+ *    With<arith::ConstraintContext> scope(&analyzer, x % 3 == 0);
+ *    ICHECK_EQ(analyzer.modular_set(x)->coeff, 3);
+ *  }
+ *  // constraint no longer in effect.
+ *  ICHECK_NE(analyzer.modular_set(x)->coeff, 3);
+ *
+ * \endcode
+ */
+class ConstraintContext {
+ private:
+  // declare friend to enable with.
+  friend class With<ConstraintContext>;
+  /*!
+   * \brief Construct a constraint context.
+   * \param analyzer The analyzer.
+   * \param constraint The constraint to be applied.
+   */
+  ConstraintContext(Analyzer* analyzer, PrimExpr constraint)
+      : analyzer_(analyzer), constraint_(constraint) {}
+  // enter the scope.
+  void EnterWithScope();
+  // exit the scope.
+  void ExitWithScope();
+  /*! \brief The analyzer */
+  Analyzer* analyzer_;
+  /*! \brief The constraint */
+  PrimExpr constraint_;
+  /*! \brief function to be called in recovery */
+  std::vector<std::function<void()>> recovery_functions_;
+};
+
+/*!
+ * \brief Integer set analyzer.
+ */
+class IntSetAnalyzer {
+ public:
+  /*!
+   * \brief Find a symbolic integer set that contains all possible values of
+   *        expr given the domain of each variables.
+   *
+   * \param expr The expression of interest.
+   * \param dom_map The domain map to indicate which variable to relax.
+   * \return the result of the analysis.
+   */
+  TVM_DLL IntSet operator()(const PrimExpr& expr, const Map<Var, IntSet>& dom_map);
+
+  /*!
+   * \brief Find a symbolic integer set that contains all possible
+   *        values of expr given the domain of each variables, using
+   *        the domain map defined by bound variables.
+   *
+   * \param expr The expression of interest.
+   * \return the result of the analysis.
+   */
+  TVM_DLL IntSet operator()(const PrimExpr& expr);
+
+  /*!
+   * \brief Update binding of var to a new expression.
+   *
+   * \param var The variable of interest.
+   * \param new_interval_set The set of allowed values for this var.
+   * \param allow_override whether we allow override of existing information.
+   */
+  TVM_DLL void Update(const Var& var, const IntSet& new_interval_set, bool allow_override = false);
+
+  /*!
+   * \brief Update binding of var to a new expression.
+   *
+   * \param var The variable of interest.
+   * \param new_range The range of allowed values for this var.
+   * \param allow_override whether we allow override of existing information.
+   */
+  TVM_DLL void Bind(const Var& var, const Range& new_range, bool allow_override = false);
+
+  std::function<void()> EnterConstraint(const PrimExpr& constraint);
+
+ private:
+  friend class Analyzer;
+  explicit IntSetAnalyzer(Analyzer* parent);
+  TVM_DLL ~IntSetAnalyzer();
+  class Impl;
+  /*! \brief Internal impl */
+  Impl* impl_;
+};
+
+/*!
+ * \brief Analyzer that contains bunch of sub-analyzers.
+ *
+ * Each sub-analyzer can make use of another sub-analyzer
+ * by weak reference of this.
+ *
+ * NOTE for sub-analyzer developers:
+ * If the analyzer uses memoization, we need to clear the internal
+ * cache when information about a Var has been overridden.
+ */
+class TVM_DLL Analyzer {
+ public:
+  /*
+   * Disable copy constructor.
+   */
+  Analyzer(const Analyzer&) = delete;
+  Analyzer& operator=(const Analyzer&) = delete;
+  /*! \brief sub-analyzer: const integer bound */
+  ConstIntBoundAnalyzer const_int_bound;
+  /*! \brief sub-analyzer: modular set */
+  ModularSetAnalyzer modular_set;
+  /*! \brief sub-analyzer rewrite simplify */
+  RewriteSimplifier rewrite_simplify;
+  /*! \brief sub-analyzer canonical simplify */
+  CanonicalSimplifier canonical_simplify;
+  /*! \brief sub-analyzer: int set */
+  IntSetAnalyzer int_set;
+  /*! \brief sub-analyzer transitive comparisons */
+  TransitiveComparisonAnalyzer transitive_comparisons;
+  /*! \brief constructor */
+  Analyzer();
+  /*!
+   * \brief Notify all the sub-analyzers that var
+   *        is created and binded to expr.
+   *
+   *  Each var can only be bound once.
+   *
+   * \param var The variable.
+   * \param expr The expression we bind to.
+   * \param allow_override Whether we allow overriding an existing var's
+   *        expression. This option should not be used if there is any dependency
+   *        between variables.
+   */
+  void Bind(const Var& var, const PrimExpr& expr, bool allow_override = false);
+  /*!
+   * \brief Notify all the sub-analyzers that var
+   *        is created and binded to a range.
+   *
+   *  Each var can only be binded once.
+   *
+   * \param var The variable.
+   * \param range The range we bind to.
+   * \param allow_override Whether we allow overriding an existing var's
+   *        expression. This option should not be used if there is any dependency
+   *        between variables.
+   */
+  void Bind(const Var& var, const Range& range, bool allow_override = false);
+  /*!
+   * \brief Bind all the vars in the Map
+   *
+   * \param variables The {variable -> range} map.
+   * \param allow_override Whether we allow overriding an existing var's
+   *        expression. This option should not be used if there is any dependency
+   *        between variables.
+   */
+  void Bind(const Map<Var, Range>& variables, bool allow_override = false);
+  /*!
+   * \brief Whether can we prove expr >= val.
+
+   *  Non-negative proof is very useful in integer analysis
+   *  to lower divisions and mods given difference in trunc and ceil mode.
+   *
+   * \param expr The expression.
+   * \param lower_bound The lower bound.
+   * \return Whether we can prove it.
+   *
+   * \note Analyzer will call into sub-analyzers to get the result.
+   */
+  bool CanProveGreaterEqual(const PrimExpr& expr, int64_t lower_bound);
+  /*!
+   * \brief Whether can we prove expr < val.
+
+   *  Non-negative proof is very useful in integer analysis
+   *  to lower divisions and mods given difference in trunc and ceil mode.
+   *
+   * \param expr The expression.
+   * \param upper_bound The upper bound.
+   * \return Whether we can prove it.
+   *
+   * \note Analyzer will call into sub-analyzers to get the result.
+   */
+  bool CanProveLess(const PrimExpr& expr, int64_t upper_bound);
+  /*!
+   * \brief Whether can we prove lhs == rhs.
+   *
+   * \param lhs The input lhs.
+   * \param rhs The input rhs.
+   * \return Whether we can prove lhs == rhs.
+   *
+   * \note Analyzer will call into sub-analyzers to get the result.
+   */
+  bool CanProveEqual(const PrimExpr& lhs, const PrimExpr& rhs);
+  /*!
+   * \brief Whether can we prove condition.
+   *
+   * \param cond The expression to be proved.
+   * \return The result.
+   *
+   * \note Analyzer will call into sub-analyzers to get the result.
+   */
+  bool CanProve(const PrimExpr& cond);
+  /*!
+   * \brief Simplify expr.
+   *
+   * \param expr The expression to be simplified.
+   * \param steps The simplification runs in the order of
+   *        rewrite_simplify (step 1) -> canonical_simplify (step 2) ->
+   *        rewrite_simplify (step 3) -> canonical_simplify (step 4) -> ...
+   *        param steps controls how many steps to run.
+   *        Default is 2, i.e., rewrite_simplify + canonical_simplify.
+   * \return The result.
+   *
+   * \note Analyzer will call into sub-analyzers to get the result.
+   */
+  PrimExpr Simplify(const PrimExpr& expr, int steps = 2);
+};
+
+}  // namespace arith
+}  // namespace tvm
+#endif  // TVM_ARITH_ANALYZER_H_
diff --git a/darknet_drp_ros/include/tvm/arith/bound.h b/darknet_drp_ros/include/tvm/arith/bound.h
new file mode 100644
index 0000000..cf84b9a
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/arith/bound.h
@@ -0,0 +1,85 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+/*!
+ * \file tvm/arith/bound.h
+ * \brief Bound deducers.
+ */
+#ifndef TVM_ARITH_BOUND_H_
+#define TVM_ARITH_BOUND_H_
+
+#include <tvm/arith/int_set.h>
+#include <tvm/ir/expr.h>
+#include <tvm/tir/expr.h>
+#include <tvm/tir/stmt.h>
+
+#include <unordered_map>
+
+namespace tvm {
+namespace arith {
+
+using tir::Region;
+using tir::Stmt;
+using tir::Var;
+using tir::VarNode;
+
+/*!
+ * \brief Deduce the bound of the target variable in a expression,
+ *  give the domain of each variables. Return undefined IntSet to
+ *  represent failure.
+ *
+ * \note The returned set may be smaller than set that
+ *       contains all possible values of v that satisfies the bound.
+ *
+ * \param v The target variable to be deduced.
+ * \param cond The conditional expression.
+ * \param hint_map The domain of variable, used to help deduce.
+ * \param relax_map The domain of each variable, used to relax the domain,
+ *        The deduce bound must implies e for all value in relax_map
+ * \return An integer set that always satisfies the condition.
+ */
+IntSet DeduceBound(PrimExpr v, PrimExpr cond, const Map<Var, IntSet>& hint_map,
+                   const Map<Var, IntSet>& relax_map);
+/*!
+ * \brief Same as DeduceBound with  unordered_map signature.
+ *
+ * \param v The target variable to be deduced.
+ * \param cond The conditional expression.
+ * \param hint_map The domain of variable, used to help deduce.
+ * \param relax_map The domain of each variable, used to relax the domain,
+ *        The deduce bound mush implies e for all value in relax_map
+ * \return An integer set that always satisfies the condition.
+ */
+IntSet DeduceBound(PrimExpr v, PrimExpr cond,
+                   const std::unordered_map<const VarNode*, IntSet>& hint_map,
+                   const std::unordered_map<const VarNode*, IntSet>& relax_map);
+
+/*!
+ * \brief Infer a regular domain that covers all the calls or provides within the given statement.
+ * \param body The given statement.
+ * \param buffer The buffer to check the access info.
+ * \param consider_loads If loads are considered.
+ * \param consider_stores If stores are considered.
+ * \return The domain that covers all the calls or provides within the given statement.
+ */
+Region DomainTouched(const Stmt& body, const tir::Buffer& buffer, bool consider_loads,
+                     bool consider_stores);
+
+}  // namespace arith
+}  // namespace tvm
+#endif  // TVM_ARITH_BOUND_H_
diff --git a/darknet_drp_ros/include/tvm/arith/int_set.h b/darknet_drp_ros/include/tvm/arith/int_set.h
new file mode 100644
index 0000000..60d7c53
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/arith/int_set.h
@@ -0,0 +1,324 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/arith/int_set.h
+ * \brief Integer set
+ */
+#ifndef TVM_ARITH_INT_SET_H_
+#define TVM_ARITH_INT_SET_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/tir/expr.h>
+
+#include <unordered_map>
+
+namespace tvm {
+namespace arith {
+
+using tir::IterVar;
+using tir::Var;
+using tir::VarNode;
+
+class Analyzer;
+
+//-----------------------------------------------
+// Integer set data structure.
+//
+// This is a API build on top of the base
+// integer analysis API to provide set analysis.
+//------------------------------------------------
+/*!
+ * \brief Sign type of an integer expression.
+ */
+enum SignType { kPositive, kNegative, kZero, kUnknown };
+
+/*!
+ * \brief Base class of all Integer set containers.
+ *        represent a set of integers in one dimension.
+ * \sa IntSet
+ */
+class IntSetNode : public Object {
+ public:
+  static constexpr const char* _type_key = "IntSet";
+  static constexpr bool _type_has_method_sequal_reduce = false;
+  TVM_DECLARE_BASE_OBJECT_INFO(IntSetNode, Object);
+};
+
+/*!
+ * \brief Managed reference to IntSetNode.
+ * \sa IntSetNode
+ */
+class IntSet : public ObjectRef {
+ public:
+  /*!
+   * \brief Find a range that covers the region.
+   * \param max_range The range to be covered.
+   * \return The covering range.
+   */
+  Range CoverRange(Range max_range) const;
+  /*! \return Lower bound of the set */
+  PrimExpr min() const;
+  /*! \return upper bound of the set */
+  PrimExpr max() const;
+  /*! \return The sign of the elements in the integer set */
+  SignType GetSignType() const;
+  /*! \return Whether the set represent nothing  */
+  bool IsNothing() const;
+  /*! \return Whether the set represent everything  */
+  bool IsEverything() const;
+  /*! \return Whether the set is a single point */
+  bool IsSinglePoint() const;
+  /*! \return Whether the set is proved to be bigger than 0 */
+  bool CanProvePositive() const;
+  /*! \return Whether the set is proved to be smaller than 0 */
+  bool CanProveNegative() const;
+  /*! \return Whether the set is proved to be smaller than or equal to 0 */
+  bool CanProveNonPositive() const;
+  /*! \return Whether the set is proved to be larger than or equal to 0 */
+  bool CanProveNonNegative() const;
+  /*! \return Whether the set has upper bound. */
+  bool HasUpperBound() const;
+  /*! \return Whether the set has lower bound. */
+  bool HasLowerBound() const;
+
+  /*!
+   * \brief The single point value, call only if IsSinglePoint is true
+   * \return The point value.
+   */
+  PrimExpr PointValue() const;
+  /*!
+   * \brief Try to match IntSet with range r.
+   *
+   * \note It is guanrateed that IntSet::FromRange(r).MatchRange(r) == true
+   * \return true if we can prove they are the same.
+   */
+  bool MatchRange(const tvm::Range& r) const;
+  /*! \return The set contains nothing */
+  static IntSet Nothing();
+  /*! \return The set contains everything */
+  static IntSet Everything();
+  /*!
+   * \brief construct a point set.
+   * \param point The point in the set.
+   * \return construct a single point set
+   */
+  static IntSet SinglePoint(PrimExpr point);
+  /*!
+   * \brief construct a integer set from vector expression.
+   * \param vec The vector expression, can also be single point.
+   * \return The result set containing the indices in the vector.
+   */
+  static IntSet Vector(PrimExpr vec);
+  /*!
+   * \brief Construct a set representing a range [min, min + extent).
+   * \param min The minimum of the range range
+   * \param extent The extent of the range.
+   * \return The constructed set.
+   */
+  static IntSet FromMinExtent(PrimExpr min, PrimExpr extent);
+  /*!
+   * \brief Construct a set representing a range.
+   * \param r The range
+   * \return The constructed set.
+   */
+  static IntSet FromRange(tvm::Range r);
+  /*!
+   * \brief Construct a set representing a interval.
+   * \param min The minimum value of the interval.
+   * \param max The maximum value of the interval.
+   * \return The constructed set.
+   */
+  static IntSet Interval(PrimExpr min, PrimExpr max);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(IntSet, ObjectRef, IntSetNode);
+};
+
+//-----------------------------------------------
+// Integer set legacy API.
+//------------------------------------------------
+/*!
+ * \brief Convert std::unordered_map<const VarNode*, IntSet> to Map<Var, IntSet>
+ *
+ * \param dom_map The domain map to convert.
+ * \return The converted map.
+ */
+Map<Var, IntSet> ConvertDomMap(const std::unordered_map<const VarNode*, IntSet>& dom_map);
+/*!
+ * \brief Find an symbolic integer set that contains all possible values of
+ *  e given the domain of each iteration variables.
+ *
+ * \param e The expression to be evaluated.
+ * \param dom_map The domain of each variable.
+ * \return An integer set that can cover all the possible values of e.
+ */
+IntSet EvalSet(PrimExpr e, const Map<IterVar, IntSet>& dom_map);
+/*!
+ * \brief Find an symbolic integer set that contains all possible values of
+ *  e given the domain of each variables.
+ *
+ * \param e The expression to be evaluated.
+ * \param dom_map The domain of each variable.
+ * \return An integer set that can cover all the possible values of e.
+ */
+IntSet EvalSet(PrimExpr e, const Map<Var, IntSet>& dom_map);
+/*!
+ * \brief Same as EvalSet, but takes unordered_map
+ *
+ * \param e The expression to be evaluated.
+ * \param dom_map The domain of each variable.
+ * \return An integer set that can cover all the possible values of e.
+ */
+IntSet EvalSet(PrimExpr e, const std::unordered_map<const tir::VarNode*, IntSet>& dom_map);
+/*!
+ * \brief Find an symbolic integer set that contains is union over
+ *  all the possible conditional values in dom_map.
+ *
+ * \param r The initial range.
+ * \param dom_map The domain of each variable.
+ * \return An integer set that can cover all the possible values.
+ */
+IntSet EvalSet(Range r, const Map<IterVar, IntSet>& dom_map);
+
+/*!
+ * \brief Find an symbolic integer set that contains is union over
+ *  all the possible conditional values in dom_map.
+ *
+ * \param s The initial set.
+ * \param dom_map The domain of each variable.
+ * \return An integer set that can cover all the possible values.
+ */
+IntSet EvalSet(IntSet s, const std::unordered_map<const VarNode*, IntSet>& dom_map);
+/*!
+ * \brief Same as EvalSet, but takes unordered_map
+ *
+ * \param r The range to be evaluated.
+ * \param dom_map The domain of each variable.
+ * \return An integer set that can cover all the possible values of e.
+ */
+IntSet EvalSet(Range r, const std::unordered_map<const VarNode*, IntSet>& dom_map);
+/*!
+ * \brief Same as EvalSet, but takes Array<Range>
+ *
+ * \param region The range to be evaluated.
+ * \param dom_map The domain of each variable.
+ * \return An array of integer sets that can cover all the possible values.
+ */
+Array<IntSet> EvalSet(const Array<Range>& region, const Map<Var, IntSet>& dom_map);
+/*! \brief Map from Expr to IntSet */
+using ExprIntSetMap = std::unordered_map<PrimExpr, IntSet, ObjectPtrHash, ObjectPtrEqual>;
+/*!
+ * \brief Find the integer set of every sub-expression, given the
+ *  domain of each iteration variables.
+ *
+ * \param e The expression to be evaluated.
+ * \param dom_map The domain of each variable.
+ * \return the map from the expression to its possible value.
+ */
+ExprIntSetMap EvalSetForEachSubExpr(PrimExpr e,
+                                    const std::unordered_map<const VarNode*, IntSet>& dom_map);
+
+/*!
+ * \brief Create a union set of all sets, possibly relaxed
+ * \param sets The sets to be combined
+ * \return the set after union
+ */
+IntSet Union(const Array<IntSet>& sets);
+
+/*!
+ * \brief The union of N-dimensional integer sets
+ * \param nd_int_sets A list of N-dimensional integer sets
+ * \return An N-dimensional integer set as the result of union
+ */
+Array<IntSet> UnionRegion(const Array<Array<IntSet>>& nd_int_sets);
+
+/*!
+ * \brief Create a lower-bound of union set, where some of the segments may be dropped
+ * \param sets The sets to be combined
+ * \return the set after union
+ */
+IntSet UnionLowerBound(const Array<IntSet>& sets);
+
+/*!
+ * \brief The union of N-dimensional integer sets
+ * \param nd_int_sets A list of N-dimensional integer sets
+ * \return An N-dimensional integer set as the result of union
+ */
+Array<IntSet> UnionRegionLowerBound(const Array<Array<IntSet>>& nd_int_sets);
+
+/*!
+ * \brief Create an intersected set of all sets
+ * \param sets The sets to be intersected
+ * \return the set after intersected
+ */
+IntSet Intersect(const Array<IntSet>& sets);
+
+/*!
+ * \brief Converts the Ranges to IntSets
+ * \param var_dom The ranges of variables
+ * \return The integer sets of the variables
+ */
+Map<Var, arith::IntSet> AsIntSet(const Map<Var, Range>& var_dom);
+
+/*!
+ * \brief Analyze the region with affine map, given the domain of variables and their predicate.
+ * The result should be strict, i.e. no region is discarded or relaxed.
+ * \param region The region to be analyzed
+ * \param var_dom The ranges of the variables
+ * \param predicate The predicate for the affine map
+ * \param analyzer The analyzer used
+ * \return NullOpt if the detection fails, or an array of arith::IntSet as the result of analysis
+ */
+TVM_DLL Optional<Array<IntSet>> EstimateRegionStrictBound(const Array<Range>& region,
+                                                          const Map<Var, Range>& var_dom,
+                                                          const PrimExpr& predicate,
+                                                          arith::Analyzer* analyzer);
+
+/*!
+ * \brief Analyze the region with affine map, given the domain of variables and their predicate.
+ * Some subregion may be discarded during the lower-bound analysis.
+ * \param region The region to be analyzed
+ * \param var_dom The ranges of the variables
+ * \param predicate The predicate for the affine map
+ * \param analyzer The analyzer used
+ * \return NullOpt if the detection fails, or an array of arith::IntSet as the result of analysis
+ */
+TVM_DLL Optional<Array<IntSet>> EstimateRegionLowerBound(const Array<Range>& region,
+                                                         const Map<Var, Range>& var_dom,
+                                                         const PrimExpr& predicate,
+                                                         arith::Analyzer* analyzer);
+
+/*!
+ * \brief Analyze the region with affine map, given the domain of variables and their predicate
+ * Relaxation of the region may be used in upper-bound analysis, i.e. some extra region may be added
+ * to the result.
+ * \param region The region to be analyzed
+ * \param var_dom The ranges of the variables
+ * \param predicate The predicate for the affine map
+ * \param analyzer The analyzer used
+ * \return an array of arith::IntSet as the result of analysis
+ */
+TVM_DLL Array<IntSet> EstimateRegionUpperBound(const Array<Range>& region,
+                                               const Map<Var, Range>& var_dom,
+                                               const PrimExpr& predicate,
+                                               arith::Analyzer* analyzer);
+
+}  // namespace arith
+}  // namespace tvm
+#endif  // TVM_ARITH_INT_SET_H_
diff --git a/darknet_drp_ros/include/tvm/arith/int_solver.h b/darknet_drp_ros/include/tvm/arith/int_solver.h
new file mode 100644
index 0000000..0ef74ce
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/arith/int_solver.h
@@ -0,0 +1,365 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/arith/int_solver.h
+ * \brief integer constraints data structures and solvers
+ */
+#ifndef TVM_ARITH_INT_SOLVER_H_
+#define TVM_ARITH_INT_SOLVER_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/tir/expr.h>
+#include <tvm/tir/op.h>
+
+#include <unordered_map>
+#include <utility>
+#include <vector>
+
+#include "analyzer.h"
+
+namespace tvm {
+namespace arith {
+
+using tir::IterVar;
+using tir::Var;
+using tir::VarNode;
+
+// According to experiments two best simplifications orders were can->rw and rw->can->rw,
+// but rw->can->rw is better for a couple of cases.
+// Also we should end with rw because it factors multipliers out.
+constexpr int kSimplifyRewriteCanonicalRewrite = 3;
+
+/*!
+ * \brief Represent integer grouped bounds which are classified into
+ *        lower bounds (inclusive), upper bounds (inclusive) and equalities.
+ *        It also contains coefficient as a multiplier for the bounds, i.e.,
+ *        coef * var >= lower
+ *        coef * var == equal
+ *        coef * var <= upper
+ * \sa IntGroupBounds
+ */
+class IntGroupBoundsNode : public Object {
+ public:
+  PrimExpr coef;
+  Array<PrimExpr> lower;
+  Array<PrimExpr> equal;
+  Array<PrimExpr> upper;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("coef", &coef);
+    v->Visit("lower", &lower);
+    v->Visit("equal", &equal);
+    v->Visit("upper", &upper);
+  }
+
+  bool SEqualReduce(const IntGroupBoundsNode* other, SEqualReducer eq) const {
+    return eq(coef, other->coef) && eq(lower, other->lower) && eq(equal, other->equal) &&
+           eq(upper, other->upper);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(coef);
+    hash_reduce(lower);
+    hash_reduce(equal);
+    hash_reduce(upper);
+  }
+
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const char* _type_key = "arith.IntGroupBounds";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IntGroupBoundsNode, Object);
+};
+
+/*!
+ * \brief Managed reference to IntGroupBoundsNode.
+ * \sa IntGroupBoundsNode
+ */
+class IntGroupBounds : public ObjectRef {
+ public:
+  /*!
+   * \brief Constructor by fields
+   * \param coef The coefficient. Must be integer.
+   *        coef * var >= lower
+   *        coef * var == equal
+   *        coef * var >= upper
+   * \param lower the lower bounds (include)
+   * \param equal equalities
+   * \param upper the upper bounds (include)
+   */
+  TVM_DLL IntGroupBounds(PrimExpr coef, Array<PrimExpr> lower, Array<PrimExpr> equal,
+                         Array<PrimExpr> upper);
+
+  /*!
+   * \brief Construct bounds from a range.
+   * \param r The range
+   * \return constructed bounds.
+   */
+  static IntGroupBounds FromRange(const Range& r);
+
+  /*!
+   * \brief Perform substitution on all components of the struct.
+   */
+  IntGroupBounds Substitute(const Map<Var, PrimExpr>& subst) const;
+
+  /*!
+   * \brief Find the best range from the grouped bounds.
+   * \param vranges_addl additional variable ranges that help infer the best range.
+   * \return The best range (has the least difference between the lower bound and upper bound).
+   *         undefined if (-inf, +inf).
+   */
+  Range FindBestRange(const Map<Var, Range>& vranges_addl = {}) const;
+
+  /*!
+   * \brief Combine the bounds with another range.
+   * \param r range to be combined.
+   * \return combined bounds.
+   */
+  IntGroupBounds operator+(const Range& r);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(IntGroupBounds, ObjectRef, IntGroupBoundsNode);
+};
+
+/*!
+ * \brief Represent integer constrains including (integer) variables, their ranges and
+ *        the relations between them (either equations or inequalities).
+ * \sa LinearSystem
+ */
+class IntConstraintsNode : public Object {
+ public:
+  // e.g., \alpha, \beta, must be integers
+  Array<Var> variables;
+  // e.g., 1 <= \alpha <= N, etc.
+  // it is absolutely ok to include ranges for parameters
+  // (variables that are not in this->variables) in this map
+  Map<Var, Range> ranges;
+  // linear equalities or inequalities
+  // e.g., A \alpha = \beta or A \alpha <= \beta
+  Array<PrimExpr> relations;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("variables", &variables);
+    v->Visit("ranges", &ranges);
+    v->Visit("relations", &relations);
+  }
+
+  bool SEqualReduce(const IntConstraintsNode* other, SEqualReducer equal) const {
+    return equal(variables, other->variables) && equal(ranges, other->ranges) &&
+           equal(relations, other->relations);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(variables);
+    hash_reduce(ranges);
+    hash_reduce(relations);
+  }
+
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const char* _type_key = "arith.IntConstraints";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IntConstraintsNode, Object);
+};
+
+/*!
+ * \brief Managed reference to IntConstraintsNode.
+ * \sa IntConstraintsNode
+ */
+class IntConstraints : public ObjectRef {
+ public:
+  /*!
+   * \brief Constructor by fields
+   * \param variables The variables in the constraints, must be integers.
+   * \param ranges    The ranges of the variables.
+   * \param relations The linear relations between the variables
+   *                  (either equations or inequalities)
+   */
+  TVM_DLL IntConstraints(Array<Var> variables, Map<Var, Range> ranges, Array<PrimExpr> relations);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(IntConstraints, ObjectRef, IntConstraintsNode);
+};
+
+/*!
+ * \brief We can have different set of variables to represent the same constraints.
+ *        For example, the following two systems are equivalent,
+ *        {a + b = 0 | a >= 0, b >= 0} and
+ *        {m - n = 0 | m >= 0, n <= 0}
+ *        This data structure represents the transformation
+ *        between two equivalent linear systems.
+ *        In the above example,
+ *        src        : {a + b = 0 | a >= 0, b >= 0}
+ *        dst        : {m - n = 0 | m >= 0, n <= 0}
+ *        src_to_dst : {a -> m, b -> -n}
+ *        dst_to_src : {m -> a, n -> -b}
+ * \sa IntConstraintsTransform
+ */
+class IntConstraintsTransformNode : public Object {
+ public:
+  IntConstraints src;
+  IntConstraints dst;
+  Map<Var, PrimExpr> src_to_dst;
+  Map<Var, PrimExpr> dst_to_src;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("src", &src);
+    v->Visit("dst", &dst);
+    v->Visit("src_to_dst", &src_to_dst);
+    v->Visit("dst_to_src", &dst_to_src);
+  }
+
+  bool SEqualReduce(const IntConstraintsTransformNode* other, SEqualReducer equal) const {
+    return equal(src, other->src) && equal(dst, other->dst) &&
+           equal(src_to_dst, other->src_to_dst) && equal(dst_to_src, other->dst_to_src);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(src);
+    hash_reduce(dst);
+    hash_reduce(src_to_dst);
+    hash_reduce(dst_to_src);
+  }
+
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const char* _type_key = "arith.IntConstraintsTransform";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IntConstraintsTransformNode, Object);
+};
+
+/*!
+ * \brief Managed reference to IntConstraintsTransformNode.
+ * \sa IntConstraintsTransformNode
+ */
+class IntConstraintsTransform : public ObjectRef {
+ public:
+  /*!
+   * \brief Constructor by fields
+   * \param src        source integer constraints, e.g., {a + b = 0 | a >= 0, b >= 0}
+   * \param dst        integer constraints equivalent to the source,
+   *                   e.g., {m - n = 0 | m >= 0, n <= 0}
+   * \param src_to_dst mapping from variables in the \p src to the variables in the \p dst,
+   *                   e.g., {a -> m, b -> -n}
+   * \param dst_to_src mapping from variables in the \p dst to the variables in the \p src,
+   *                   e.g., {m -> a, n -> -b}
+   */
+  TVM_DLL IntConstraintsTransform(IntConstraints src, IntConstraints dst,
+                                  Map<Var, PrimExpr> src_to_dst, Map<Var, PrimExpr> dst_to_src);
+
+  /*!
+   * \brief Chain-compose two IntConstraintsTransform together.
+   *        this->dst must be the same as other->src.
+   * @param other another IntConstraintsTransform whose src is same as this->dst.
+   * @return composed IntConstraintsTransform(this->src, other->dst)
+   *         with its variables and ranges are properly modified.
+   */
+  IntConstraintsTransform operator+(const IntConstraintsTransform& other) const;
+
+  TVM_DEFINE_OBJECT_REF_METHODS(IntConstraintsTransform, ObjectRef, IntConstraintsTransformNode);
+};
+
+typedef std::pair<Map<Var, IntGroupBounds>, Array<PrimExpr>> PartialSolvedInequalities;
+
+/*!
+ * \brief Obtain Smith Normal Form of linear equation A x = y.
+ *        Smith Normal Form of matrix A_{mxn} is S_{mxn} = U_{mxm} A_{mxn} V_{nxn},
+ *        in which S_{mxn} is diag(s1, s2, ..., sr, 0, ..., 0) and r is the rank of A.
+ *        NOTE: Although in standard Smith Normal Form the diagonal elements satisfy
+ *              s_i | s_{i+1} (| means divides), the implement here does not guarantee it.
+ *        TODO(yzhliu): From sergei-grechanik:
+ *          computing the proper Smith normal form may improve stability of automatic
+ * differentiation (generating the same gradient code for slightly different but equivalent input
+ * code U_{mxm} and V_{nxn} are invertible matrices. This function modifies \p S to be S_{mxn}, \p V
+ * to be V_{nxn}, \p y to be U_{mxm} y_{mx1} and \p x to be V^{-1} x. \param S  the original
+ * A_{mxn}, it will be modified to S_{mxn} \param V  an identity matrix, it will be modified to
+ * V_{nxn} \param x  the x in A x = y. it will be modified to V^{-1}_{nxn} x_{nx1} \param y  the y
+ * in A x = y. it will be modified to U_{mxm} y_{mx1}
+ */
+void SmithNormalFormDiag(std::vector<std::vector<int64_t>>* S, std::vector<std::vector<int64_t>>* V,
+                         std::vector<PrimExpr>* x, std::vector<PrimExpr>* y);
+
+/*!
+ * \brief Solve linear equations.
+ * \param system_to_solve the variables to solve, their ranges, and a list of equations.
+ * \return  A new linear system, with less variables (if \p system_to_solve is NOT of full rank),
+ *          or no variable (if \p system_to_solve is of full rank),
+ *          or an empty linear system (if \p system_to_solve is unsolvable).
+ *          It also provides the ranges of the variables in the new system,
+ *          as well as inequalities inferred from the \p system_to_solve.
+ *          You can get the mapping from the original variables to the solution via ret->src_to_dst.
+ */
+IntConstraintsTransform SolveLinearEquations(const IntConstraints& system_to_solve);
+
+/*!
+ * \brief Solve linear inequalities.
+ * \param system_to_solve the variables to solve, their ranges, and a list of inequalities.
+ *        The inequalities are rewritten using Fourier-Motzkin elimination.
+ *        This function takes an array of (in)equalities and an array of variables, and essentially
+ *        rewrites the (in)equalities into an array of (in)equalities of the following form,
+ *
+ *        x0 >= f0(x1, x2, ..., xn)
+ *        x0 <= g0(x1, x2, ..., xn)
+ *        x1 >= f1(x2, ..., xn)
+ *        x1 <= g1(x2, ..., xn)
+ *        ...
+ *        xn >= fn()  // just a constant
+ *        xn <= gn()  // just a constant
+ *
+ * \return A map of variables and their solved bounds,
+ *         and constrains that cannot be solved to bounds.
+ */
+PartialSolvedInequalities SolveLinearInequalities(const IntConstraints& system_to_solve);
+
+/*!
+ * \brief Combine the information into an array of (in)equalities.
+ * \param variables The variables in \p bounds.
+ *        It is used to determine the iteration order to avoid indeterministic results.
+ * \param bounds grouped boundary of the variables.
+ * \param relations other relations.
+ */
+Array<PrimExpr> AsConditions(const Array<Var>& variables, const Map<Var, IntGroupBounds>& bounds,
+                             const Array<PrimExpr>& relations);
+
+/*!
+ * \brief Solve linear inequalities and infer the range of each variable.
+ * \param system_to_solve the variables to solve, their ranges, and a list of inequalities.
+ * \return The result ranges for each variables.
+ *         The returned IntConstraints(variables, ranges, relations) contains,
+ *         1. variables  - the variables that have been solved.
+ *         2. ranges     - the best range of each variable.
+ *         3. relations  - constraints that cannot be transformed to
+ *                         Range will be stored in relations.
+ */
+IntConstraints SolveInequalitiesToRange(const IntConstraints& system_to_solve);
+
+/*!
+ * \brief Solve linear inequalities and deskew the ranges towards zero.
+ * \param system_to_solve the variables to solve, their ranges, and a list of inequalities.
+ * \return A transform (src IntConstraints -> dst IntConstraints)
+ *         from original variables to a set of new variables.
+ *         The ranges of new variables always start from zero,
+ *         their extents are solved from \p system_to_solve.
+ *         src IntConstraints is the same as \p system_to_solve.
+ *         dst IntConstraints(variables, ranges, relations) contains,
+ *         1. variables  - the variables that have been solved.
+ *         2. ranges     - the best range (start from zero) of each variable.
+ *         3. relations  - constraints that cannot be transformed to
+ *                         Range will be stored in relations.
+ *         Variable mapping can be obtained from
+ *         IntConstraintsTransform.src_to_dst and IntConstraintsTransform.dst_to_src.
+ */
+IntConstraintsTransform SolveInequalitiesDeskewRange(const IntConstraints& system_to_solve);
+
+}  // namespace arith
+}  // namespace tvm
+#endif  // TVM_ARITH_INT_SOLVER_H_
diff --git a/darknet_drp_ros/include/tvm/arith/iter_affine_map.h b/darknet_drp_ros/include/tvm/arith/iter_affine_map.h
new file mode 100644
index 0000000..0d8bd57
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/arith/iter_affine_map.h
@@ -0,0 +1,424 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/arith/iter_affine_map.h
+ * \brief Iterator quasi-affine mapping patterns.
+ *
+ *  This file defines a collection of mapping patterns
+ *  maps a collection of independent iterators to another
+ *  collection of independent iterators.
+ *
+ *  There are two main kinds of mapping patterns:
+ *
+ *  - Fuse: fuse a collection of iterators into a single one
+ *
+ *    domain(x0) = [0, 4), domain(x1) = [0, 3), domain(x2) = [0, 2)
+ *    fuse(x0, x1, x2): y = x2 * 12 + x1 * 4 + x0
+ *    domain(y) = [0, 24)
+ *
+ *  - Split: split an iterator into multiple ones
+ *
+ *    domain(x) = [0, 24)
+ *    split(x, 3, 12): [y0, y1, y2] = [x % 3, (x % 12) / 3, x / 12]
+ *    domain(y0) = [0, 3), domain(y1) = [0, 4), domain(y2) = [0, 2)
+ *
+ *  We use the name "(quasi)affine" to be consistent with
+ *  the terminology used in the polyhedral compilation.
+ *  Notably, fuse is an affine transformation,
+ *  while split corresponds to additional floordiv/mod operations
+ *  that can appear in quasi-affine transformations.
+ */
+#ifndef TVM_ARITH_ITER_AFFINE_MAP_H_
+#define TVM_ARITH_ITER_AFFINE_MAP_H_
+
+#include <tvm/arith/analyzer.h>
+#include <tvm/ir/diagnostic.h>
+#include <tvm/ir/expr.h>
+#include <tvm/tir/var.h>
+
+namespace tvm {
+namespace arith {
+
+/*!
+ * \brief Base class of all iter map expressions.
+ *
+ *  An IterMapExpr is a special expression to store
+ *  the result of IterMapDetection.
+ *  It should not appear in a legal TIR PrimFunc.
+ */
+class IterMapExprNode : public PrimExprNode {
+ public:
+  // overrides
+  void VisitAttrs(tvm::AttrVisitor* v) {}
+
+  static constexpr const char* _type_key = "arith.IterMapExpr";
+  static constexpr const uint32_t _type_child_slots = 3;
+  TVM_DECLARE_BASE_OBJECT_INFO(IterMapExprNode, PrimExprNode);
+};
+
+/*!
+ * \brief Managed reference to IterMapExprNode.
+ * \sa IterMapExprNode
+ */
+class IterMapExpr : public PrimExpr {
+ public:
+  TVM_DEFINE_OBJECT_REF_METHODS(IterMapExpr, PrimExpr, IterMapExprNode);
+};
+
+/*!
+ * \brief Mark the source as an iterator in [0, extent).
+ *
+ *  IterMark is used to mark source expression as a valid
+ *  iterator to make future analysis easy.
+ */
+class IterMarkNode : public Object {
+ public:
+  /*!
+   * \brief The source expression, can either be
+   *  a IterSumExpr or a Var.
+   */
+  PrimExpr source;
+  /*!
+   * \brief The extent of the iteration.
+   */
+  PrimExpr extent;
+
+  // overrides
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("source", &source);
+    v->Visit("extent", &extent);
+  }
+
+  bool SEqualReduce(const IterMarkNode* other, SEqualReducer equal) const {
+    equal->MarkGraphNode();
+    return equal(source, other->source) && equal(extent, other->extent);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce->MarkGraphNode();
+    hash_reduce(source);
+    hash_reduce(extent);
+  }
+
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  static constexpr const char* _type_key = "arith.IterMark";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IterMarkNode, Object);
+};
+
+/*!
+ * \brief Managed reference to IterMarkExprNode.
+ * \sa IterMarkExprNode
+ */
+class IterMark : public ObjectRef {
+ public:
+  /*!
+   * \brief constructor.
+   * \param source The source expression.
+   * \param extent The extent of the iterator.
+   */
+  TVM_DLL IterMark(PrimExpr source, PrimExpr extent);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(IterMark, ObjectRef, IterMarkNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(IterMarkNode);
+};
+
+/*!
+ * \brief Split of an iterator.
+ *
+ *  result = floormod(floordiv(source, lower_factor), extent) * scale
+ */
+class IterSplitExprNode : public IterMapExprNode {
+ public:
+  /*! \brief The source marked iterator. */
+  IterMark source;
+  /*! \brief The lower factor to split the source. */
+  PrimExpr lower_factor;
+  /*! \brief The extent of the split. */
+  PrimExpr extent;
+  /*! \brief Additional scale. */
+  PrimExpr scale;
+
+  // overrides
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("source", &source);
+    v->Visit("lower_factor", &lower_factor);
+    v->Visit("extent", &extent);
+    v->Visit("scale", &scale);
+  }
+
+  bool SEqualReduce(const IterSplitExprNode* other, SEqualReducer equal) const {
+    return equal(source, other->source) && equal(lower_factor, other->lower_factor) &&
+           equal(extent, other->extent) && equal(scale, other->scale);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(source);
+    hash_reduce(lower_factor);
+    hash_reduce(extent);
+    hash_reduce(scale);
+  }
+
+  static constexpr const char* _type_key = "arith.IterSplitExpr";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IterSplitExprNode, IterMapExprNode);
+};
+
+/*!
+ * \brief Managed reference to IterSplitExprNode.
+ * \sa IterSplitExprNode
+ */
+class IterSplitExpr : public IterMapExpr {
+ public:
+  /*!
+   * \brief constructor from just source.
+   * \param source The source expression.
+   */
+  TVM_DLL explicit IterSplitExpr(IterMark source);
+  /*!
+   * \brief constructor from just source.
+   * \param source The source expression.
+   * \param scale The additional scaling factor.
+   */
+  TVM_DLL explicit IterSplitExpr(IterMark source, PrimExpr scale);
+  /*!
+   * \brief constructor
+   * \param source The source expression.
+   * \param lower_factor The lower factor to split the source.
+   * \param extent The extent of the split.
+   * \param scale The additional scaling factor.
+   */
+  TVM_DLL explicit IterSplitExpr(IterMark source, PrimExpr lower_factor, PrimExpr extent,
+                                 PrimExpr scale);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(IterSplitExpr, IterMapExpr, IterSplitExprNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(IterSplitExprNode);
+};
+
+/*!
+ * \brief Fuse multiple iterators by summing them with scaling.
+ *
+ *  result = sum(args) + base
+ */
+class IterSumExprNode : public IterMapExprNode {
+ public:
+  /*! \brief The args to the sum. */
+  Array<IterSplitExpr> args;
+  /*! \brief The base offset. */
+  PrimExpr base;
+
+  // overrides
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("args", &args);
+    v->Visit("base", &base);
+  }
+
+  bool SEqualReduce(const IterSumExprNode* other, SEqualReducer equal) const {
+    return equal(args, other->args) && equal(base, other->base);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(args);
+    hash_reduce(base);
+  }
+
+  static constexpr const char* _type_key = "arith.IterSumExpr";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IterSumExprNode, IterMapExprNode);
+};
+
+/*!
+ * \brief Managed reference to IterSumExprNode.
+ * \sa IterSumExprNode
+ */
+class IterSumExpr : public IterMapExpr {
+ public:
+  /*!
+   * \brief constructor.
+   * \param args The args to the sum.
+   * \param base The base offset.
+   */
+  TVM_DLL IterSumExpr(Array<IterSplitExpr> args, PrimExpr base);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(IterSumExpr, IterMapExpr, IterSumExprNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(IterSumExprNode);
+};
+
+/*! \brief Mapping level for iterators. */
+enum IterMapLevel {
+  // Require the mapping to be bijective.
+  Bijective = 0,
+  // Require the mapping to be surjective.
+  Surjective = 1,
+  // No mapping safety check.
+  NoCheck = 3
+};
+
+/*!
+ * \brief Result of DetectIterMap.
+ */
+class IterMapResultNode : public Object {
+ public:
+  // The detected pattern if a match exists.
+  Array<IterSumExpr> indices;
+
+  // Any errors that occurred while converting the input indices.  If
+  // the array is empty, the conversion was successful.
+  Array<String> errors;
+
+  /*! \brief Boolean expression indicating if a specific value w
+   *
+   * `padding_predicate` evaluates to true for a set of indices that
+   * are outside the bounds of the provided index iterators, but
+   * inside the bounds of the returned index iterators.  This
+   * expression is in terms of the variables provided in
+   * `input_iters`.
+   */
+  PrimExpr padding_predicate;
+
+  // overrides
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("errors", &errors);
+    v->Visit("indices", &indices);
+    v->Visit("padding_predicate", &padding_predicate);
+  }
+
+  static constexpr const char* _type_key = "arith.IterMapResult";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IterMapResultNode, Object);
+};
+
+/*!
+ * \brief Managed reference to IterMapResultNode.
+ * \sa IterMapResultNode
+ */
+class IterMapResult : public ObjectRef {
+ public:
+  // constructor
+  IterMapResult() { data_ = make_object<IterMapResultNode>(); }
+
+  /*! \return mutable pointers to the node. */
+  IterMapResultNode* operator->() const { return static_cast<IterMapResultNode*>(get_mutable()); }
+};
+
+/*!
+ * \brief Detect if indices can be written as
+ *  [y_0 + c_0, y_1 + c_1, ..., y_n + c_n]
+ *
+ *  Here y = some-quasi-affine-iter-map(input_iters)
+ *  and c are symbolic constants.
+ *
+ *  We also requires that y_i and y_j to be independent for i != j.
+ *
+ *  For returned value rv, the following is always true:
+ *  - rv[i]->args.size() <=1: only one iterator per element.
+ *
+ * \param indices The indices to detect pattern for.
+ * \param input_iters Map from variable to iterator's range.
+ * \param predicate The predicate constraints on the input iterators
+ * \param check_level The iter mapping checking level.
+ * \param analyzer Analyzer used to get context information.
+ * \param simplify_trivial_iterators If true, iterators with extent of
+ *           1 will be replaced with a constant value.
+ *
+ * \return The detected iteration result.
+ * The return object's .indices is empty on failure.
+ */
+IterMapResult DetectIterMap(const Array<PrimExpr>& indices, const Map<Var, Range>& input_iters,
+                            const PrimExpr& predicate, IterMapLevel check_level,
+                            arith::Analyzer* analyzer, bool simplify_trivial_iterators = true);
+
+/*!
+ * \brief Use IterVarMap detector to rewrite and simplify the indices
+ *
+ * \param indices The indices to detect pattern for.
+ * \param input_iters Map from variable to iterator's range.
+ * \param input_pred The predicate constraints on the input iterators
+ * \param check_level The iter mapping checking level.
+ * \param simplify_trivial_iterators If true, iterators with unit extents are simplified
+ * \return The indices after rewrite
+ */
+Array<PrimExpr> IterMapSimplify(const Array<PrimExpr>& indices, const Map<Var, Range>& input_iters,
+                                const PrimExpr& input_pred, IterMapLevel check_level,
+                                bool simplify_trivial_iterators = true);
+
+/*!
+ * \brief Apply the inverse of the affine transformation to the outputs.
+ *
+ * Similar to the back-propagation, starting from the outputs, it visits the DAG of the expressions
+ * in reverse topology order and applies the inverse of the affine transformation until it reaches
+ * the input. The affine iter map is required to be bijective.
+ *
+ * For example, iter_map = [l0 // 16, l0 % 16], outputs = [output_0, output_1],
+ * the affine transformation specified by `iter_map` will be applied to `outputs` and the result
+ * will be {l0: ((output_0*16) + output_1)}.
+ *
+ * The range of `outputs` should be the same as the output range of the affine transmation.
+ *
+ * \sa DetectIterMap
+ *
+ * \param iter_map The bijective affine iter map.
+ * \param outputs The outputs of the affine transformation.
+ *
+ * \return The map from the input to the transformed result.
+ */
+Map<Var, PrimExpr> InverseAffineIterMap(const Array<IterSumExpr>& iter_map,
+                                        const Array<PrimExpr> outputs);
+
+/*!
+ * \brief Detect if bindings can be written as
+ * [a_0*e_0 + b_0 + c_0, a_1*e_1 + b_1, ..., a_n*e_n + b_n]
+ *
+ * where a = some-quasi-affine-iter-map(input_iters set_minus sub_iters)
+ *       b = some-quasi-affine-iter-map(sub_iters)
+ *       c is constant symbols
+ *       e is the extent of b
+ *
+ * For example, z*12 + y*3 + x + c = (z*4+y)*3 + x, if sub_iters={x}
+ *
+ * \param bindings The input bindings
+ * \param input_iters Map from variable to iterator's range.
+ * \param sub_iters Iterators of subspace.
+ * \param predicate The predicate constraints on the input iterators
+ * \param check_level The iter mapping checking level.
+ * \param analyzer Analyzer used to get context information.
+ * \param simplify_trivial_iterators If true, iterators with extent of
+ *           1 will be replaced with a constant value.
+ *
+ * \return The result list has length len(bindings) + 1
+        [0, len(bindings)): The iter map matching result. The inner list is of length 2.
+                            The first expr is the basis of the quotient space.
+                            The second expr is the basis of the subspace.
+        len(bindings): the predicate of outer space and inner space
+        Empty array if no match can be found.
+ */
+Array<Array<IterMark>> SubspaceDivide(const Array<PrimExpr>& bindings,
+                                      const Map<Var, Range>& input_iters,
+                                      const Array<Var>& sub_iters, const PrimExpr& predicate,
+                                      IterMapLevel check_level, arith::Analyzer* analyzer,
+                                      bool simplify_trivial_iterators = true);
+
+/*!
+ * \brief Given an expression that may contain IterMapExpr, transform it to normal PrimExpr.
+ * \param expr The input expression, which may contain IterMapExpr.
+ * \return The corresponding normal PrimExpr.
+ */
+PrimExpr NormalizeIterMapToExpr(const PrimExpr& expr);
+
+}  // namespace arith
+}  // namespace tvm
+#endif  // TVM_ARITH_ITER_AFFINE_MAP_H_
diff --git a/darknet_drp_ros/include/tvm/arith/pattern.h b/darknet_drp_ros/include/tvm/arith/pattern.h
new file mode 100644
index 0000000..5e1165d
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/arith/pattern.h
@@ -0,0 +1,54 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/arith/pattern.h
+ * \brief Expression pattern detectors.
+ */
+#ifndef TVM_ARITH_PATTERN_H_
+#define TVM_ARITH_PATTERN_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/tir/expr.h>
+
+namespace tvm {
+namespace arith {
+/*!
+ * \brief Detect if e can be rewritten as e = sum_{i=0}^{n-1} var[i] * coeff[i] + coeff[n]
+ *  Where coeff[i] and base are invariant of var[j] for all i and j.
+ *
+ * \param e The expression to be detected.
+ * \param vars List of variables to be used in detection.
+ * \return [coeff[i]] if it is possible, empty array if it is not.
+ */
+Array<PrimExpr> DetectLinearEquation(const PrimExpr& e, const Array<tir::Var>& vars);
+
+/*!
+ * \brief Detect if expression corresponds to clip bound of the vars
+ *
+ * \param e The expression to be detected.
+ * \param vars List of variables to be used in detection.
+ * \return concat([min_value[i], max_value[i]]), None is returned if there is no min or max value
+ *          return empty if the e does not match the pattern.
+ */
+Array<PrimExpr> DetectClipBound(const PrimExpr& e, const Array<tir::Var>& vars);
+
+}  // namespace arith
+}  // namespace tvm
+#endif  // TVM_ARITH_PATTERN_H_
diff --git a/darknet_drp_ros/include/tvm/auto_scheduler/auto_schedule.h b/darknet_drp_ros/include/tvm/auto_scheduler/auto_schedule.h
new file mode 100644
index 0000000..2d7e594
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/auto_scheduler/auto_schedule.h
@@ -0,0 +1,104 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/auto_scheduler/auto_schedule.h
+ * \brief The user interface of the auto scheduler.
+ */
+
+#ifndef TVM_AUTO_SCHEDULER_AUTO_SCHEDULE_H_
+#define TVM_AUTO_SCHEDULER_AUTO_SCHEDULE_H_
+
+#include <tvm/auto_scheduler/measure.h>
+#include <tvm/auto_scheduler/search_policy.h>
+
+#include <utility>
+
+namespace tvm {
+namespace auto_scheduler {
+
+/*! \brief Tuning and measurement options. */
+class TuningOptionsNode : public Object {
+ public:
+  /*! \brief The number of total measurement trials. */
+  int num_measure_trials;
+  /*! \brief Stops the tuning early if no improvement after n measurements. */
+  int early_stopping;
+  /*! \brief The number of programs to be measured at each search round. */
+  int num_measures_per_round;
+  /*! \brief Verbosity level. 0 for silent, 1 to output information during schedule searching. */
+  int verbose;
+  /*! \brief ProgramBuilder which builds the program */
+  ProgramBuilder builder;
+  /*! \brief ProgramRunner which runs the program and measures time costs */
+  ProgramRunner runner;
+  /*! \brief MeasureCallback functions to be called after each measure batch */
+  Optional<Array<MeasureCallback>> measure_callbacks;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("num_measure_trials", &num_measure_trials);
+    v->Visit("early_stopping", &early_stopping);
+    v->Visit("num_measures_per_round", &num_measures_per_round);
+    v->Visit("verbose", &verbose);
+    v->Visit("builder", &builder);
+    v->Visit("runner", &runner);
+    v->Visit("measure_callbacks", &measure_callbacks);
+  }
+
+  static constexpr const char* _type_key = "auto_scheduler.TuningOptions";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TuningOptionsNode, Object);
+};
+
+/*!
+ * \brief Managed reference to TuningOptionsNode.
+ * \sa TuningOptionsNode
+ */
+class TuningOptions : public ObjectRef {
+ public:
+  /*!
+   * \brief The constructor
+   * \param num_measure_trials The number of total measurement trials.
+   * \param early_stopping Stops the tuning early if no improvement after n measurements.
+   * \param num_measures_per_round The number of programs to be measured at each search round.
+   * \param verbose Verbosity level. 0 for silent, 1 to output information during schedule
+   * search.
+   * \param builder ProgramBuilder which builds the program.
+   * \param runner ProgramRunner which runs the program and measure time costs.
+   * \param measure_callbacks MeasureCallback functions to be called after each measure batch.
+   */
+  TuningOptions(int num_measure_trials, int early_stopping, int num_measures_per_round, int verbose,
+                ProgramBuilder builder, ProgramRunner runner,
+                Optional<Array<MeasureCallback>> measure_callbacks);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(TuningOptions, ObjectRef, TuningOptionsNode);
+};
+
+/*!
+ * \brief Run schedule search for a given compute declaration.
+ * \param search_policy The search policy.
+ * \param tuning_options Tuning and measurement options.
+ * \return A `te::schedule` and an Array of `te::Tensor` to be used in `tvm.lower` or
+ * `tvm.build`.
+ */
+TVM_DLL std::pair<te::Schedule, Array<te::Tensor>> AutoSchedule(SearchPolicy search_policy,
+                                                                TuningOptions tuning_options);
+}  // namespace auto_scheduler
+}  // namespace tvm
+
+#endif  // TVM_AUTO_SCHEDULER_AUTO_SCHEDULE_H_
diff --git a/darknet_drp_ros/include/tvm/auto_scheduler/compute_dag.h b/darknet_drp_ros/include/tvm/auto_scheduler/compute_dag.h
new file mode 100644
index 0000000..a87563e
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/auto_scheduler/compute_dag.h
@@ -0,0 +1,324 @@
+/*r
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/auto_scheduler/compute_dag.h
+ * \brief The auto-scheduler's computational graph and related program analyses.
+ *
+ * We convert a compute declaration described by `tvm.compute` (could be a single operator or a
+ * subgraph) to a ComputeDAG. It keeps the input/output tensors, all operations in the DAG, and
+ * some static analysis results for the DAG (e.g. the total float operation count, consumer/producer
+ * relations of operations, whether an operation stage should be tiled/compute inlined ...).
+ * These analyses can help the search policy to make decisions during the search.
+ * ComputeDAG is also responsible for the interaction between auto-scheduler's `LoopState` and
+ * TVM schedule (e.g. applying the `LoopState` transform steps to a TVM schedule, providing
+ * `LoopState` with extra information got from TVM schedule ...).
+ */
+
+#ifndef TVM_AUTO_SCHEDULER_COMPUTE_DAG_H_
+#define TVM_AUTO_SCHEDULER_COMPUTE_DAG_H_
+
+#include <tvm/auto_scheduler/loop_state.h>
+#include <tvm/runtime/c_runtime_api.h>
+#include <tvm/te/schedule.h>
+
+#include <unordered_map>
+#include <unordered_set>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+namespace auto_scheduler {
+
+/*! \brief Static analyzer for a ComputeDAG */
+class AccessAnalyzerNode : public Object {
+ public:
+  template <class T>
+  using OperationMap = std::unordered_map<te::Operation, T, ObjectPtrHash, ObjectPtrEqual>;
+
+  /*! \brief Map an operation to all operations it reads from.
+   * For each operation pair, use a two-dimensional array for multiple multi-dimensional accesses
+   * The inner vector represents the indices of multi-dimensional access.*/
+  OperationMap<OperationMap<std::vector<std::vector<PrimExpr>>>> read_from;
+  /*! \brief Map an operation to all operations it is read by.
+   * For each operation pair, use a two-dimensional array for multiple multi-dimensional accesses
+   * The inner vector represents the indices of multi-dimensional access.*/
+  OperationMap<OperationMap<std::vector<std::vector<PrimExpr>>>> read_by;
+  /*! \brief Store the number of common outer iterators for operation pairs that have
+   * read-write relations. */
+  OperationMap<OperationMap<int>> num_common_outer_iterators;
+  /*! \brief Store whether the operation is an op with only simple access.
+   *  (e.g., injective, broadcast and elementwise ops without reduction) */
+  OperationMap<bool> is_simple_access;
+  /*! \brief Store whether the operation is strictly inlineable
+   * (e.g., injective, broadcast and elementwise without reduction, branch or expensive operations)
+   */
+  OperationMap<bool> is_strictly_inlineable;
+  /*! \brief Store whether the operation needs multi-level tiling
+   * (e.g., computation-intensive ops with data reuse opportunity like matmul, conv2d) */
+  OperationMap<bool> needs_multi_level_tiling;
+  /*! \brief Store whether the operation is an output operation */
+  OperationMap<bool> is_output;
+  /*! \brief Store the topological order of operations */
+  Array<te::Operation> ops_topo_order;
+
+  static constexpr const char* _type_key = "auto_scheduler.AccessAnalyzer";
+  TVM_DECLARE_FINAL_OBJECT_INFO(AccessAnalyzerNode, Object);
+};
+
+/*!
+ * \brief Managed reference to AccessAnalyzerNode.
+ * \sa AccessAnalyzerNode
+ */
+class AccessAnalyzer : public ObjectRef {
+ public:
+  explicit AccessAnalyzer(const Array<te::Tensor>& tensors);
+
+  /*!
+   * \brief Return whether this operation is an op with simple access
+   * (e.g., injective, broadcast and elementwise ops without reduction)
+   * \param op The operation
+   */
+  TVM_DLL bool IsSimpleAccess(const te::Operation& op) const;
+
+  /*!
+   * \brief Return whether this operation is strictly inlineable
+   * (e.g., injective, broadcast and elementwise without reduction, branch or expensive operations)
+   * \param op The operation
+   */
+  TVM_DLL bool IsStrictlyInlineable(const te::Operation& op) const;
+
+  /*!
+   * \brief Return whether this operation needs multi-level tiling
+   * (e.g., computation-intensive ops with data reuse opportunity like matmul, conv2d)
+   * \param op The operation
+   */
+  TVM_DLL bool NeedsMultiLevelTiling(const te::Operation& op) const;
+
+  /*!
+   * \brief Return whether this operation is an output operation
+   * \param op The operation
+   */
+  TVM_DLL bool IsOutput(const te::Operation& op) const;
+
+  /*!
+   * \brief Get all consumers of an operation
+   * \param state The current loop state
+   * \param op The operation
+   * \return The set of consumers
+   * \note This function propagates the relation for inlined ops
+   */
+  TVM_DLL std::unordered_set<te::Operation, ObjectHash, ObjectEqual> GetConsumers(
+      const State& state, const te::Operation& op) const;
+
+  /*!
+   * \brief Get all producers of an operation
+   * \param state The current loop state
+   * \param op The operation
+   * \return The set of producers
+   * \note This function propagates the relation for inlined ops
+   */
+  TVM_DLL std::unordered_set<te::Operation, ObjectHash, ObjectEqual> GetProducers(
+      const State& state, const te::Operation& op) const;
+
+  /*!
+   * \brief Get all direct producers of an operation
+   * \param op The operation
+   * \return The set of direct producers
+   * \note This function DOES NOT propagate the relation for inlined ops
+   */
+  TVM_DLL std::unordered_set<te::Operation, ObjectHash, ObjectEqual> GetDirectProducers(
+      const te::Operation& op) const;
+
+  /*!
+   * \brief Get the number of common outer iterators.
+   * \param op The operation
+   * \param target_op The target operation
+   * \note This function propagates the relation for chains with multiple ops.
+   */
+  TVM_DLL int GetNumCommonOuterIterator(const te::Operation& op,
+                                        const te::Operation& target_op) const;
+
+  /*!
+   * \brief Return whether two operations are elementwise-matched
+   *  (e.g. conv2d and relu are elementwise-matched)
+   * \note This function propagates the relation for chains with multiple ops.
+   */
+  TVM_DLL bool ElementWiseMatch(const te::Operation& op, const te::Operation& target_op) const;
+
+  TVM_DEFINE_OBJECT_REF_METHODS(AccessAnalyzer, ObjectRef, AccessAnalyzerNode);
+};
+
+/*! \brief The auto-scheduler's computational graph and related program analyses. */
+class ComputeDAGNode : public Object {
+ public:
+  /*!
+   * \brief Input and output tensors.
+   * This is used as the input of `tvm.lower` or `tvm.build`.
+   */
+  Array<te::Tensor> tensors;
+  /*! \brief All used operations in topo order. */
+  Array<te::Operation> ops;
+  /*! \brief The number of float operations in this ComputeDAG. */
+  double flop_ct;
+  /*! \brief The initial state without any transform steps. */
+  State init_state;
+  /*! \brief The static read-write access analyzer. */
+  AccessAnalyzer access_analyzer;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("tensors", &tensors);
+    v->Visit("ops", &ops);
+    v->Visit("flop_ct", &flop_ct);
+    v->Visit("init_state", &init_state);
+    v->Visit("access_analyzer", &access_analyzer);
+  }
+
+  static constexpr const char* _type_key = "auto_scheduler.ComputeDAG";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ComputeDAGNode, Object);
+};
+
+/*!
+ * \brief Options for applying layout rewrite.
+ * This is an optimization to rewrite the layout of input tensors according to the schedule we get.
+ */
+enum class LayoutRewriteOption : int {
+  /*! \brief Do not perform layout rewrite. */
+  NoRewrite = 0,
+  /*! \brief Insert layout transformation stages for input placeholders in the compute DAG */
+  InsertTransformStage = 1,
+  /*!
+   * \brief Do not insert layout transformation stages and assume the input placeholders
+   * are pre-transformed.
+   * \note The lowered function with this option does not accept the origial input shapes,
+   * so this option must be used along with `AutoSchedulerLayoutRewrite` pass in Relay.
+   */
+  RewriteForPreTransformed = 2,
+};
+
+/*!
+ * \brief Managed reference to ComputeDAGNode.
+ * \sa ComputeDAGNode
+ */
+class ComputeDAG : public ObjectRef {
+ public:
+  /*! \brief Construct a DAG from a list of output tensors.
+   * \param tensors `te::Tensor`s for a compute declaration.
+   */
+  TVM_DLL explicit ComputeDAG(Array<te::Tensor> tensors);
+
+  /*! \brief Construct a DAG based on a schedule.
+   * \param sch `te::Schedule`s for a compute declaration.
+   */
+  TVM_DLL explicit ComputeDAG(const te::Schedule& sch);
+
+  /*!
+   * \brief Rewrite the layout of placeholder specified by attr `layout_free_placeholders`
+   * according to the loop nest derived with `transform_steps`.
+   * \param transform_steps Transform steps of a state.
+   * \param layout_rewrite Different options in layout rewrite.
+   * \return The updated ComputeDAG after layout rewrite.
+   */
+  ComputeDAG RewriteLayout(Array<Step>* transform_steps, LayoutRewriteOption layout_rewrite) const;
+
+  /*!
+   * \brief Apply the history transform steps to get a TVM schedule.
+   * \param transform_steps Transform steps of a state.
+   * \param stages The list of stages after applying the steps.
+   * Pass a valid pointer if this information needs to be used outside this function.
+   * \param stage_to_axes The map that stores all axes for one stage.
+   * Pass a valid pointer if this information needs to be used outside this function.
+   * \param layout_rewrite Rewrite the layout of placeholders specified by
+   * attr `layout_free_placeholders`.
+   * \return A `te.schedule` and the an Array of `te.Tensor` to be used in `tvm.lower`
+   * or `tvm.build`.
+   */
+  std::pair<te::Schedule, Array<te::Tensor>> ApplySteps(
+      const Array<Step>& transform_steps, Array<te::Stage>* stages = nullptr,
+      StageToAxesMap* stage_to_axes = nullptr,
+      LayoutRewriteOption layout_rewrite = LayoutRewriteOption::NoRewrite) const;
+
+  /*!
+   * \brief Print transform steps as equivalent python schedule API.
+   * This can be used for debugging.
+   * \param transform_steps Transform steps of a state.
+   * \return The Python schedule code.
+   */
+  String PrintStepsAsPython(const Array<Step>& transform_steps) const;
+
+  /*!
+   * \brief Print the compute DAG to a string. This is also used to generate the ComputeDAG hash.
+   * \param simple_mode Simple mode will only include the op names and brief compute.
+   * \return The ComputeDAG in a string.
+   */
+  String PrintDAG(bool simple_mode = false) const;
+
+  /*!
+   * \brief Fill the correct bound information for a given state by calling ir_pass::InferBound.
+   * The states can lose complete bound information after some transform steps (e.g., compute_at).
+   * We can call this function to infer and fill all the bound information.
+   * This function calls TVM InferBound pass internally to get the bound.
+   * The returned state of this function is guaranteed to have complete bound information.
+   * \param state The input state.
+   * \return The State with complete bound information
+   */
+  State InferBound(const State& state) const;
+
+  /*!
+   * \brief Fill the correct bound information for the given states by calling ir_pass::InferBound.
+   * The states can lose complete bound information after some transform steps (e.g., compute_at).
+   * We can call this function to infer and fill all the bound information.
+   * This function calls TVM InferBound pass internally to get the bound.
+   * The returned state of this function is guaranteed to have complete bound information.
+   * \param states The input states.
+   * \return The States with complete bound information.
+   * \note The returned array will contains empty State, if there're infer bound failure on some
+   * states.
+   */
+  Array<State> InferBound(const Array<State>& states) const;
+
+  /*!
+   * \brief Since some steps may change the ComputeDAG (e.g. CacheRead/CacheWrite), the initial
+   * ComputeDAG may not be up-to-date. This function replays the given transform steps from the
+   * initial state and returns an up-to-date ComputeDAG.
+   * \param steps The steps to be replayed. Usually we'll filter out the unused steps to speed up
+   * the replay process, since we only intend to get a ComputeDAG with the up-to-date op stage
+   * structure.
+   * \return The up-to-date ComputeDAG.
+   */
+  ComputeDAG ReplayAndGetDAG(const Array<Step>& steps) const;
+
+  static constexpr const char* layout_free_placeholders_key = "layout_free_placeholders";
+
+  TVM_DEFINE_OBJECT_REF_METHODS(ComputeDAG, ObjectRef, ComputeDAGNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(ComputeDAGNode);
+};
+
+/*!
+ *  \brief Get the orginal shape from a rewritten layout string.
+ *  \param rewritten_layout The layout after auto-scheduler's layout rewrite.
+ *  \param axis_names Specifiy the names of axes.
+ *  \return shape The original shape.
+ */
+Array<PrimExpr> GetShapeFromRewrittenLayout(String rewritten_layout, Array<String> axis_names);
+
+}  // namespace auto_scheduler
+}  // namespace tvm
+
+#endif  // TVM_AUTO_SCHEDULER_COMPUTE_DAG_H_
diff --git a/darknet_drp_ros/include/tvm/auto_scheduler/cost_model.h b/darknet_drp_ros/include/tvm/auto_scheduler/cost_model.h
new file mode 100644
index 0000000..a52c679
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/auto_scheduler/cost_model.h
@@ -0,0 +1,165 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file auto_scheduler/cost_model.h
+ * \brief Cost models that estimate the performance of programs
+ */
+
+#ifndef TVM_AUTO_SCHEDULER_COST_MODEL_H_
+#define TVM_AUTO_SCHEDULER_COST_MODEL_H_
+
+#include <tvm/auto_scheduler/compute_dag.h>
+#include <tvm/auto_scheduler/measure.h>
+#include <tvm/node/node.h>
+#include <tvm/runtime/packed_func.h>
+
+#include <vector>
+
+namespace tvm {
+namespace auto_scheduler {
+
+using runtime::PackedFunc;
+using runtime::TypedPackedFunc;
+
+/*! \brief The base class for cost model */
+class CostModelNode : public Object {
+ public:
+  /*!
+   * \brief Update the cost model according to new measurement results (training data).
+   * \param inputs The measure inputs
+   * \param results The measure results
+   */
+  virtual void Update(const Array<MeasureInput>& inputs, const Array<MeasureResult>& results) = 0;
+
+  /*!
+   * \brief Predict the scores of states
+   * \param task The search task of states
+   * \param states The input states
+   * \param scores The predicted scores for all states
+   */
+  virtual void Predict(const SearchTask& task, const Array<State>& states,
+                       std::vector<float>* scores) = 0;
+
+  /*!
+   * \brief Predict the scores of all stages in states. This is the breakdown version of `Predict`
+   * \param task The search task
+   * \param states The input states
+   * \param state_scores The predicted scores for all states
+   * \param stage_scores The predicted scores for all stages in all stages
+   */
+  virtual void PredictStages(const SearchTask& task, const Array<State>& states,
+                             std::vector<float>* state_scores,
+                             std::vector<std::vector<float>>* stage_scores) {
+    LOG(FATAL) << "Not implemented";
+  }
+
+  /*!
+   * \brief Default virtual destructor
+   */
+  virtual ~CostModelNode() {}
+
+  static constexpr const char* _type_key = "auto_scheduler.CostModel";
+  TVM_DECLARE_BASE_OBJECT_INFO(CostModelNode, Object);
+};
+
+/*!
+ * \brief Managed reference to CostModelNode.
+ * \sa CostModelNode
+ */
+class CostModel : public ObjectRef {
+ public:
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(CostModel, ObjectRef, CostModelNode);
+};
+
+/*! \brief The cost model returning random value for all predictions */
+class RandomModelNode : public CostModelNode {
+ public:
+  /*! \brief Pointer to a random number generator function */
+  const TypedPackedFunc<void(size_t, void*)>* random_number_func;
+
+  void Update(const Array<MeasureInput>& inputs, const Array<MeasureResult>& results) final;
+
+  void Predict(const SearchTask& task, const Array<State>& states,
+               std::vector<float>* scores) final;
+
+  static constexpr const char* _type_key = "auto_scheduler.RandomModel";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RandomModelNode, CostModelNode);
+};
+
+/*!
+ * \brief Managed reference to RandomModelNode.
+ * \sa RandomModelNode
+ */
+class RandomModel : public CostModel {
+ public:
+  RandomModel();
+  explicit RandomModel(::tvm::runtime::ObjectPtr<::tvm::runtime::Object> n) : CostModel(n) {}
+
+  RandomModelNode* operator->() const { return static_cast<RandomModelNode*>(data_.get()); }
+
+  TVM_DEFINE_DEFAULT_COPY_MOVE_AND_ASSIGN(RandomModel);
+  using ContainerType = RandomModelNode;
+};
+
+/*! \brief A wrapper for cost model defined by python code
+ *  This class will call functions defined in the python */
+class PythonBasedModelNode : public CostModelNode {
+ public:
+  /*! \brief Pointer to the update function in python */
+  PackedFunc update_func;
+  /*! \brief Pointer to the predict function in python */
+  PackedFunc predict_func;
+  /*! \brief Pointer to the predict function in python */
+  PackedFunc predict_stage_func;
+
+  void Update(const Array<MeasureInput>& inputs, const Array<MeasureResult>& results) final;
+
+  void Predict(const SearchTask& task, const Array<State>& states,
+               std::vector<float>* scores) final;
+
+  void PredictStages(const SearchTask& task, const Array<State>& states,
+                     std::vector<float>* state_scores,
+                     std::vector<std::vector<float>>* stage_scores) final;
+
+  static constexpr const char* _type_key = "auto_scheduler.PythonBasedModel";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PythonBasedModelNode, CostModelNode);
+};
+
+/*!
+ * \brief Managed reference to PythonBasedModelNode.
+ * \sa PythonBasedModelNode
+ */
+class PythonBasedModel : public CostModel {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param update_func The pointer to the update function defined in python
+   * \param predict_func The pointer to the prediction function defined in python
+   * \param predict_stage_func The pointer to the prediction function defined in python
+   */
+  PythonBasedModel(PackedFunc update_func, PackedFunc predict_func, PackedFunc predict_stage_func);
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(PythonBasedModel, CostModel, PythonBasedModelNode);
+};
+
+}  // namespace auto_scheduler
+}  // namespace tvm
+
+#endif  // TVM_AUTO_SCHEDULER_COST_MODEL_H_
diff --git a/darknet_drp_ros/include/tvm/auto_scheduler/feature.h b/darknet_drp_ros/include/tvm/auto_scheduler/feature.h
new file mode 100644
index 0000000..a8b88b7
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/auto_scheduler/feature.h
@@ -0,0 +1,124 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file auto_scheduler/feature.h
+ * \brief Feature extraction for the cost model.
+ * We extract one feature vector per BufferStoreNode statement in a TIR Stmt,
+ * so we call this feature as "per-store" feature.
+ * The cost model also does prediction for each BufferStoreNode statement and aggregates
+ * the predictions as the whole score for a TVM IR (Stmt).
+ *
+ * The feature specification is defined by `src/auto_scheduler/feature.cc:: FeatureSet`
+ */
+
+#ifndef TVM_AUTO_SCHEDULER_FEATURE_H_
+#define TVM_AUTO_SCHEDULER_FEATURE_H_
+
+#include <tvm/auto_scheduler/compute_dag.h>
+#include <tvm/auto_scheduler/measure.h>
+#include <tvm/tir/function.h>
+
+#include <string>
+#include <vector>
+
+namespace tvm {
+namespace auto_scheduler {
+
+/*!
+ * \brief Get per-store features from a TIR PrimFunc
+ * \param func The input lowered TIR PrimFunc
+ * \param cache_line_size The size of cache line in bytes
+ * \param max_n_bufs The maximum number of extracted buffers for one statement
+ * \param ret The returned feature vector
+ * \param log_scale Should the outputs be scaled by log2(1+x).
+ */
+void GetPerStoreFeature(const PrimFunc& func, int cache_line_size, int max_n_bufs,
+                        std::vector<float>* ret, bool log_scale = true);
+
+/*
+ * \brief Get the names of elements in the feature vector. Use this for debug and inspection.
+ * \param max_n_bufs The maximum number of extracted buffers for one statement
+ * \param ret The returned names.
+ */
+void GetPerStoreFeatureName(int max_n_bufs, std::vector<std::string>* ret);
+
+/*!
+ * \brief Get per-store feature from states of the same task
+ * \param states The input states
+ * \param task The same search task for all states
+ * \param skip_first_n_feature_extraction Skip feature extraction for the first n states
+ * \param max_n_bufs The maximum number of extracted buffers for one statement
+ * \param features The returned feature vector. The innermost vector contains the
+ * feature vectors for all BufferStoreNode statements
+ */
+void GetPerStoreFeaturesFromStates(const Array<State>& states, const SearchTask& task,
+                                   int skip_first_n_feature_extraction, int max_n_bufs,
+                                   std::vector<std::vector<float>>* features);
+
+/*!
+ * \brief Get per-store feature from states of different tasks
+ * \param states The input states
+ * \param tasks The search tasks corresponding to the input states
+ * \param skip_first_n_feature_extraction Skip feature extraction for the first n states
+ * \param max_n_bufs The maximum number of extracted buffers for one statement
+ * \param features The returned feature vector. The innermost vector contains the
+ * feature vectors for all BufferStoreNode statements
+ */
+void GetPerStoreFeaturesFromStates(const Array<State>& states, const std::vector<SearchTask>& tasks,
+                                   int skip_first_n_feature_extraction, int max_n_bufs,
+                                   std::vector<std::vector<float>>* features);
+
+/*!
+ * \brief Get per-store features from a log file
+ * \param filename The name of log file
+ * \param max_lines Only read the first n lines of the file
+ * \param max_n_bufs The maximum number of extracted buffers for one statement
+ * \param features The returned feature vector. The innermost vector contains the
+ * feature vectors for all BufferStoreNode statements
+ * \param normalized_throughputs The normalized throughputs for all states
+ * \param task_ids The task ids for all states
+ */
+void GetPerStoreFeaturesFromFile(const std::string& filename, int max_lines, int max_n_bufs,
+                                 std::vector<std::vector<float>>* features,
+                                 std::vector<float>* normalized_throughputs,
+                                 std::vector<int>* task_ids);
+
+/*!
+ * \brief Get per-store features from measurement input/result pairs
+ * \param inputs The measurement inputs
+ * \param results The measurement results
+ * \param skip_first_n_feature_extraction Skip feature extraction for the first n measurement pairs
+ * \param max_n_bufs The maximum number of extracted buffers for one statement
+ * \param features The returned feature vector. The innermost vector contains the
+ * feature vectors for all BufferStoreNode statements
+ * \param normalized_throughputs The normalized throughputs for all states
+ * \param task_ids The task ids for all states
+ */
+void GetPerStoreFeaturesFromMeasurePairs(const Array<MeasureInput>& inputs,
+                                         const Array<MeasureResult>& results,
+                                         int skip_first_n_feature_extraction, int max_n_bufs,
+                                         std::vector<std::vector<float>>* features,
+                                         std::vector<float>* normalized_throughputs,
+                                         std::vector<int>* task_ids);
+
+}  // namespace auto_scheduler
+}  // namespace tvm
+
+#endif  // TVM_AUTO_SCHEDULER_FEATURE_H_
diff --git a/darknet_drp_ros/include/tvm/auto_scheduler/loop_state.h b/darknet_drp_ros/include/tvm/auto_scheduler/loop_state.h
new file mode 100644
index 0000000..0ca14c4
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/auto_scheduler/loop_state.h
@@ -0,0 +1,482 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file auto_scheduler/loop_state.h
+ * \brief The definition of the "state" in the search.
+ *
+ * Each LoopState corresponds to a schedule for its ComputeDAG.
+ * A LoopState consists of: 1. a current loop structure; 2. a list of transformation steps used to
+ * construct the loop structure.
+ * The loop structure keeps a preview of how the schedule will finally look like after lowering the
+ * current state (e.g. number of iterators, the extent of each iterator, the compute_at locations
+ * ...).
+ * During the schedule search process, the loop structure can provide search policy with necessary
+ * information on how to manipulate the current state.
+ * The transform history is a sequence of `TransformStep` which will finally be mapped to TVM
+ * schedule primitives. The steps are also used for the serialization of a state.
+ *
+ * The LoopState can be seen as a lightweight loop structure IR specifically for schedule search.
+ * We don't use the existing TVM IR but to extend a new structure on it is because:
+ * 1. We want fast incremental change to the loop structures. The search policy needs to get the
+ * immediate loop structures update rather than after TVM lowering;
+ * 2. We want serializable transform history for replay, backtracking, and mutation;
+ * 3. We may create some macro schedule primitives that represent the combination of several
+ * TVM schedule primitives.
+ *
+ * When the search is finished, we will lower the state to TVM IR with TVM's schedule primitives.
+ * Since we share a lot of common objects during search, the transformation is implemented in
+ * copy on write style. All objects are immutable, which is similar to TVM IR.
+ */
+
+#ifndef TVM_AUTO_SCHEDULER_LOOP_STATE_H_
+#define TVM_AUTO_SCHEDULER_LOOP_STATE_H_
+
+#include <dmlc/common.h>
+#include <tvm/auto_scheduler/transform_step.h>
+
+#include <functional>
+#include <unordered_map>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+namespace auto_scheduler {
+
+using namespace tvm::tir;
+
+class ComputeDAG;
+
+/*! \brief The type of a stage. */
+enum class StageKind : int {
+  /*! \brief A placeholder stage. */
+  kPlaceholder = 0,
+  /*! \brief A compute stage. */
+  kCompute = 1
+};
+
+/*! \brief The type of compute location. */
+enum class ComputeAtKind : int {
+  /*! \brief Compute at root. */
+  kRoot = 0,
+  /*! \brief Compute inlined. */
+  kInlined = 1,
+  /*! \brief Compute at some iterator. */
+  kIter = 2,
+};
+
+/*! \brief Stage-level attributes. */
+struct StageAttributes {
+  /*! \brief The maximum steps for the pragma `auto_unroll_max_step`. */
+  int auto_unroll_max_step;
+  /*! \brief The storage offset for the schedule primitive `storage_align`. */
+  int storage_offset;
+};
+
+/*!
+ * \brief A op stage in the compute declaration.
+ * Similar to te::Stage in `include/tvm/te/schedule.h`.
+ */
+class StageNode : public Object {
+ public:
+  /*! \brief The operator of this stage */
+  te::Operation op;
+  /*! \brief The iterators in this stage. */
+  Array<Iterator> iters;
+  /*! \brief The type of this stage. */
+  StageKind op_type;
+  /*! \brief The compute location of this stage. */
+  ComputeAtKind compute_at;
+  /*! \brief Other stage-level attributes. */
+  StageAttributes attrs;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("op", &op);
+    v->Visit("iters", &iters);
+    v->Visit("op_type", &op_type);
+    v->Visit("compute_at", &compute_at);
+  }
+
+  static constexpr const char* _type_key = "auto_scheduler.Stage";
+  TVM_DECLARE_FINAL_OBJECT_INFO(StageNode, Object);
+};
+
+/*!
+ * \brief Managed reference to StageNode.
+ * \sa StageNode
+ */
+class Stage : public ObjectRef {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param op A `te::Operation`.
+   */
+  explicit Stage(te::Operation op);
+  /*!
+   * \brief The constructor.
+   * \param op The source operation
+   * \param op_type The stage type of this op.
+   * \param iters The iterators of this op.
+   * \param compute_at The compute at type of this op.
+   * \param attrs Other stage-level attributes.
+   */
+  Stage(te::Operation op, StageKind op_type, const Array<Iterator>& iters, ComputeAtKind compute_at,
+        StageAttributes attrs);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Stage, ObjectRef, StageNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(StageNode);
+};
+
+/*! \brief Use stage_id to represent a stage. */
+using StageKey = int;
+/*! \brief Use stage_id and iter_id to represent a iterator. */
+using IterKey = std::pair<int, int>;
+
+/*!
+ * \brief stores the compute_at relation between stages
+ * This stores a bi-directional mapping from stages and iter:
+ * 1. Stage to its attached iterator
+ * 2. Iterator to the stage attached to it
+ * You can use AttachMapNode::stage_to_attach_iter and AttachMapNode::iter_to_attached_stages
+ * to query the relations
+ */
+class AttachMapNode : public Object {
+ public:
+  struct IterKeyHash {
+    std::size_t operator()(const IterKey& k) const {
+      return ::dmlc::HashCombine(std::hash<int>()(k.first), std::hash<int>()(k.second));
+    }
+  };
+
+  /*! \brief A Map to store the mapping of stage to its attached iterator. */
+  std::unordered_map<StageKey, IterKey> stage_to_attach_iter;
+  /*! \brief A Map to store the mapping of iterator to the stages attached to it. */
+  std::unordered_map<IterKey, std::vector<StageKey>, IterKeyHash> iter_to_attached_stages;
+
+  static constexpr const char* _type_key = "auto_scheduler.AttachMap";
+  TVM_DECLARE_FINAL_OBJECT_INFO(AttachMapNode, Object);
+};
+
+/*!
+ * \brief Managed reference to AttachMapNode.
+ * \sa AttachMapNode
+ */
+class AttachMap : public ObjectRef {
+ public:
+  /*!
+   * \brief Process the stage/iterator mapping after compute at.
+   * \param stage_id The index of the source stage of computed at.
+   * \param target_stage_id The index of stage that this step will compute at to.
+   * \param target_iter_id The index of target iterator in the target stage.
+   */
+  void SetComputeAtIter(int stage_id, int target_stage_id, int target_iter_id);
+
+  /*!
+   * \brief Delete the entry of a specific stage. This is a public wrapper of `DeleteStageEntry`.
+   * \param stage_id The index of the stage to be deleted.
+   */
+  void DeleteStage(int stage_id);
+
+  /*!
+   * \brief Find the relations of original iterators in AttachMap, and update them with the new
+   * iterators. Both `stage_to_attach_iter` and `iter_to_attached_stages` will be updated.
+   * \param original_iters The original IterKey.
+   * \param new_iters The new IterKey for replacing the old ones.
+   */
+  void UpdateIters(const std::vector<IterKey>& original_iters,
+                   const std::vector<IterKey>& new_iters);
+
+  /*!
+   * \brief Traverse through `stage_to_attach_iter` and `iter_to_attached_stages` map, add offset
+   * to stage indexes that are larger than the start_id. Used for steps that insert new stages to
+   * ComputeDAG (e.g., CacheRead/CacheWrite step).
+   * \param start_id The index threshold. This function only adds offset for stages
+   * with indices larger then this threshold.
+   * \param offset The index offset to be added to the stage index.
+   * \return The updated AttachMap after applying stage index offset.
+   */
+  AttachMap ApplyStageIdOffset(int start_id, int offset = 1) const;
+
+  TVM_DEFINE_OBJECT_REF_METHODS(AttachMap, ObjectRef, AttachMapNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(AttachMapNode);
+
+ private:
+  /*!
+   * \brief Delete the entry of a specific stage. This will remove the items related to this
+   * stage in both `stage_to_attach_iter` and `iter_to_attached_stages` map.
+   * \param pnode A mutable pointer to AttachMapNode.
+   * \param stage_id The index of stage that will be removed from the map.
+   */
+  static void DeleteStageEntry(AttachMapNode* pnode, int stage_id);
+};
+
+/*!
+ * \brief A state in the search process.
+ * It consists of the current loop structure and a list of transformation steps used to construct
+ * it.
+ * Each State corresponds to a specific schedule for its ComputeDAG.
+ */
+class StateNode : public Object {
+ public:
+  /*! \brief Current stages and loop structures. */
+  Array<Stage> stages;
+  /*! \brief History transformation steps. */
+  Array<Step> transform_steps;
+  /*!
+   * \brief The attach relations of stages and iterators. This is used to track the compute at
+   * operation.
+   */
+  AttachMap attach_map;
+  /*! \brief The up-to-date ComputeDAG of this state. The default value is an empty NullOpt,
+   * meaning the dag of this state is the same as the original ComputeDAG in the SearchTask.
+   * Otherwise, the stored value is the up-to-date ComputeDAG for this state, meaning some steps
+   * (e.g., CacheReadStep/CacheWriteStep) have modified the ComputeDAG.
+   */
+  Optional<ObjectRef> current_compute_dag;
+  /*!
+   * \brief Indicate whether this state has unfilled tile sizes. A concrete state means that all
+   * tile sizes of the state is filled. Only concrete state can be apply to TVM schedule.
+   */
+  bool concrete;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("stages", &stages);
+    v->Visit("transform_steps", &transform_steps);
+    v->Visit("concrete", &concrete);
+  }
+
+  static constexpr const char* _type_key = "auto_scheduler.State";
+  TVM_DECLARE_FINAL_OBJECT_INFO(StateNode, Object);
+};
+
+/*!
+ * \brief Managed reference to StateNode.
+ * \sa StateNode
+ */
+class State : public ObjectRef {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param ops `te::Operation`s for a compute declaration.
+   */
+  explicit State(const Array<te::Operation>& ops);
+
+  /*!
+   * \brief Pretty-print the state to a human readable string.
+   * \param delete_trivial_loop True for skipping the trivial loops.
+   * (undefined or extent == 1, default set to True)
+   * \return The human readable string.
+   */
+  String ToStr(bool delete_trivial_loop = true) const;
+
+  /********** Step APIs working on a single stage **********/
+  /*!
+   * \brief The schedule primitive corresponding to `te::Stage::bind`.
+   * \param stage_id The index of the stage to be binded.
+   * \param it The iterator to be binded.
+   * \param thread_type The thread type.
+   * \return The new iterator after binding.
+   */
+  TVM_DLL Iterator bind(int stage_id, const Iterator& it, IteratorAnnotation thread_type);
+  /*!
+   * \brief The schedule primitive corresponding to `te::Stage::parallel`.
+   * \param stage_id The index of the stage to be paralleled.
+   * \param it The iterator to be paralleled.
+   * \return The new iterator after parallel.
+   */
+  TVM_DLL Iterator parallel(int stage_id, const Iterator& it);
+  /*!
+   * \brief The schedule primitive corresponding to `te::Stage::unroll`.
+   * \param stage_id The index of the stage to be unrolled.
+   * \param it The iterator to be unrolled.
+   * \param max_unroll The max unroll limit. Iterator with extent larger than this limit will be
+   * skipped.
+   * \return The new iterator after unroll.
+   */
+  TVM_DLL Iterator unroll(int stage_id, const Iterator& it, int max_unroll = -1);
+  /*!
+   * \brief The schedule primitive corresponding to `te::Stage::vectorize`.
+   * \param stage_id The index of the stage to be vectorized.
+   * \param it The iterator to be vectorized.
+   * \return The new iterator after vectorization.
+   */
+  TVM_DLL Iterator vectorize(int stage_id, const Iterator& it);
+  /*!
+   * \brief The schedule primitive corresponding to `te::Stage::fuse`.
+   * \param stage_id The index of the stage to be fused.
+   * \param iters The iterators to be fused.
+   * \return The iterator result after fuse.
+   * \note If the iterators to be fused have stages attached at them(by compute_at), the fused
+   * result will become the new attach point.
+   */
+  TVM_DLL Iterator fuse(int stage_id, const Array<Iterator>& iters);
+  /*!
+   * \brief The schedule primitive corresponding to `te.Stage.pragma`.
+   * \param stage_id The index of the stage to add pragma.
+   * \param it The iterator to add pragma.
+   * \param pragma_type The pragma string.
+   */
+  TVM_DLL void pragma(int stage_id, const Iterator& it, const String& pragma_type);
+  /*!
+   * \brief The schedule primitive corresponding to `te::Stage::reorder`.
+   * \param stage_id The index of the stage to be reordered.
+   * \param order The expected iterator order.
+   */
+  TVM_DLL void reorder(int stage_id, const Array<Iterator>& order);
+  /*!
+   * \brief The schedule primitive corresponding to `te::Stage::split`.
+   * \param stage_id The index of the stage to be split.
+   * \param it The iterator to be split.
+   * \param lengths The multiple split factors. Can be None to be filled by search policy.
+   * \param inner_to_outer Whether the factors go from inner to outer, or from outer to inner.
+   * \return The new iterator after splitting.
+   * \note If we do split on an iterator which has stages attached at it(by compute_at), the inner
+   * most iterator of split results will become the new attach point.
+   */
+  TVM_DLL Array<Iterator> split(int stage_id, const Iterator& it,
+                                const Array<Optional<Integer>>& lengths,
+                                bool inner_to_outer = true);
+  /*!
+   * \brief The schedule primitive similar to split, but uses split factors from previous steps.
+   * \param stage_id The index of the stage to be split.
+   * \param it The iterator to be split.
+   * \param src_step_id The index of the split step to be followed in the history.
+   * \param n_split The number of split level.
+   * \return The split new Iterators.
+   */
+  TVM_DLL Array<Iterator> follow_split(int stage_id, const Iterator& it, int src_step_id,
+                                       int n_split);
+  /*!
+   * \brief The schedule primitive similar to split, but uses split factors from
+   * fused previous steps.
+   * \param stage_id The index of the stage to be split.
+   * \param it The iterator to be split.
+   * \param src_step_ids The indices of the split steps to be followed in the history.
+   * \param level Use the length in this split level.
+   * \param factor_or_nparts True to use `factor` for split from inner to outer,
+      False to use `nparts` for split from outer to inner.
+   * \return The split new Iterators.
+   */
+  TVM_DLL Array<Iterator> follow_fused_split(int stage_id, const Iterator& it,
+                                             const Array<Integer>& src_step_ids, int level,
+                                             bool factor_or_nparts);
+  /*!
+   * \brief The schedule primitive corresponding to `te.Stage.storage_align`.
+   * \param stage_id The index of the stage to be aligned.
+   * \param it The iterator to be aligned.
+   * \param factor The factor in alignment specification.
+   * \param offset The offset in the alignment specification.
+   */
+  TVM_DLL void storage_align(int stage_id, const Iterator& it, int factor, int offset);
+
+  /********** Step APIs working on multiple stages **********/
+  /*!
+   * \brief The schedule primitive corresponding to `te::Stage::compute_at`.
+   * \param stage_id The index of the source stage of computed at.
+   * \param target_stage_id The index of stage that this step will compute at to.
+   * \param target_iter The indiex of the target iterator in the target stage.
+   * \note After compute_at, we need careful dependency analysis to compute the accurate bound
+   * information. However, it is relatively expensive and complicated, so we just fill "None" as
+   * bound for the newly created iterators.
+   * Call ComputeDAG::InferBound on the updated state if you need the complete bound information.
+   */
+  TVM_DLL void compute_at(int stage_id, int target_stage_id, const Iterator& target_iter);
+  /*!
+   * \brief The schedule primitive corresponding to `te::Stage::compute_inline`.
+   * \param stage_id The index of the stage to be marked compute inlined.
+   */
+  TVM_DLL void compute_inline(int stage_id);
+  /*!
+   * \brief The schedule primitive corresponding to `te::Stage::compute_root`.
+   * \param stage_id The index of the stage to be marked compute at root.
+   * \note After compute_root, we need careful dependency analysis to compute the accurate bound
+   * information. However, it is relatively expensive and complicated, so we just fill "None" as
+   * bound for the newly created iterators.
+   * Call ComputeDAG::InferBound on the updated state if you need the complete bound information.
+   */
+  TVM_DLL void compute_root(int stage_id);
+
+  /********** Step APIs adding new stages **********/
+  /*!
+   * \brief The schedule primitive corresponding to `te::Schedule::cache_read`.
+   * \param stage_id The index of the stage to be cache_read.
+   * \param scope_name The scope name of the newly added stage.
+   * \param reader_stage_ids The indices of reader stages.
+   * \param dag The original ComputeDAG of this state.
+   * \note Cache read step will add an extra stage to the original ComputeDAG (at the back of the
+   * target stage), an up-to-date ComputeDAG is stored in State's `current_compute_dag`.
+   */
+  TVM_DLL int cache_read(int stage_id, const String& scope_name,
+                         const Array<Integer>& reader_stage_ids, const ComputeDAG& dag);
+  /*!
+   * \brief The schedule primitive corresponding to `te::Schedule::cache_write`.
+   * \param stage_id The index of the stage to be cache_write.
+   * \param scope_name The scope name of the newly added stage.
+   * \param dag The original ComputeDAG of this state.
+   * \note Cache write step will add an extra stage to the original ComputeDAG (in the front of the
+   * target stage), an up-to-date ComputeDAG is stored in State's `current_compute_dag`.
+   * This step will cache write all output tensors of the target stage.
+   */
+  TVM_DLL int cache_write(int stage_id, const String& scope_name, const ComputeDAG& dag);
+  /*!
+   * \brief The schedule primitive corresponding to `te::Schedule::rfactor`.
+   * \param stage_id The index of the iterator to be factored.
+   * \param it The iterator to be factored.
+   * \param factor_iter_id The position where the new iterator is placed.
+   * \param dag The original ComputeDAG of this state.
+   * \note Rfactor step will add an extra stage to the original ComputeDAG (in the front of the
+   * target stage), an up-to-date ComputeDAG is stored in State's `current_compute_dag`.
+   */
+  TVM_DLL int rfactor(int stage_id, const Iterator& it, int factor_iter_id, const ComputeDAG& dag);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(State, ObjectRef, StateNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(StateNode);
+};
+
+}  // namespace auto_scheduler
+}  // namespace tvm
+
+// Hash and equal function for State
+namespace std {
+
+/*!
+ * \brief The equal_to function for auto_scheduler::State.
+ * This function checks the equality by looking at the lowered string format of states.
+ * If two states with different transform history have the same lowered string format,
+ * they will be considered being equal.
+ */
+template <>
+struct equal_to<::tvm::auto_scheduler::State> {
+  bool operator()(const ::tvm::auto_scheduler::State& lhs,
+                  const ::tvm::auto_scheduler::State& rhs) const {
+    return lhs.ToStr() == rhs.ToStr();
+  }
+};
+
+/*! \brief The hash function for auto_scheduler::State. */
+template <>
+struct hash<::tvm::auto_scheduler::State> {
+  std::size_t operator()(const ::tvm::auto_scheduler::State& state) const {
+    return tvm::runtime::ObjectHash()(state.ToStr());
+  }
+};
+
+}  // namespace std
+
+#endif  // TVM_AUTO_SCHEDULER_LOOP_STATE_H_
diff --git a/darknet_drp_ros/include/tvm/auto_scheduler/measure.h b/darknet_drp_ros/include/tvm/auto_scheduler/measure.h
new file mode 100644
index 0000000..8576468
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/auto_scheduler/measure.h
@@ -0,0 +1,542 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file auto_scheduler/measure.h
+ * \brief Distributed measurement infrastructure to measure the runtime costs of tensor programs.
+ * These functions are responsible for building the tvm module, uploading it to remote devices,
+ * recording the running time costs, and checking the correctness of the output.
+ *
+ * The measurement is separated into two steps: build and run.
+ * A builder builds the executable binary files and a runner runs the binary files to get the
+ * measurement results. The flow of data structures is
+ *
+ *                 `ProgramBuilder`                 `ProgramRunner`
+ * `MeasureInput` -----------------> `BuildResult` ----------------> `MeasureResult`
+ *
+ * The core functions is implemented in python to utilize python's multiprocessing
+ * and error handling (see also `python/tvm/auto_scheduler/measure.py`).
+ * This c++ file is just a wrapper for the python functions.
+ */
+
+#ifndef TVM_AUTO_SCHEDULER_MEASURE_H_
+#define TVM_AUTO_SCHEDULER_MEASURE_H_
+
+#include <tvm/auto_scheduler/loop_state.h>
+#include <tvm/auto_scheduler/search_task.h>
+
+#include <string>
+#include <unordered_map>
+#include <unordered_set>
+#include <utility>
+
+namespace tvm {
+namespace auto_scheduler {
+
+class SearchPolicy;
+class MeasureInput;
+class MeasureResult;
+
+/*! \brief The error code of one measurement */
+enum class MeasureErrorNO : int {
+  /*! \brief No error. */
+  kNoError = 0,
+  /*! \brief Errors happen when apply transform steps from init state. */
+  kInstantiationError = 1,
+  /*! \brief Errors happen when compiling code on host. (when build module) */
+  kCompileHostError = 2,
+  /*! \brief Errors happen when compiling code on device. (when load module) */
+  kCompileDeviceError = 3,
+  /*! \brief Errors happen when run program on device. */
+  kRuntimeDeviceError = 4,
+  /*! \brief Answer is wrong when compared to a reference output. */
+  kWrongAnswerError = 5,
+  /*! \brief Timeout during compilation. */
+  kBuildTimeoutError = 6,
+  /*! \brief Timeout during run. */
+  kRunTimeoutError = 7,
+  /*! \brief Unknown error. */
+  kUnknownError = 8,
+};
+
+// Inputs and results of one measurement
+
+/*! \brief Store the input of a measurement */
+class MeasureInputNode : public Object {
+ public:
+  /*! \brief The search task. */
+  SearchTask task;
+  /*! \brief The program state to be measured. */
+  State state;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("task", &task);
+    v->Visit("state", &state);
+  }
+
+  /*! \brief Do shallow copy. */
+  MeasureInput copy() const;
+
+  static constexpr const char* _type_key = "auto_scheduler.MeasureInput";
+  TVM_DECLARE_FINAL_OBJECT_INFO(MeasureInputNode, Object);
+};
+
+/*!
+ * \brief Managed reference to MeasureInputNode.
+ * \sa MeasureInputNode
+ */
+class MeasureInput : public ObjectRef {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param task The SearchTask of this measure.
+   * \param state The State to be measured.
+   */
+  MeasureInput(SearchTask task, State state);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(MeasureInput, ObjectRef, MeasureInputNode);
+};
+
+/*! \brief Store the result of a build. */
+class BuildResultNode : public Object {
+ public:
+  /*! \brief The filename of built binary file. */
+  String filename;
+  /*! \brief The arguments. */
+  Array<te::Tensor> args;
+  /*! \brief The error code. (0 means no error, see MeasureErrorNO) */
+  int error_no;
+  /*! \brief The error message if there is any error. */
+  String error_msg;
+  /*! \brief The time cost of build. */
+  double time_cost;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("filename", &filename);
+    v->Visit("args", &args);
+    v->Visit("error_no", &error_no);
+    v->Visit("error_msg", &error_msg);
+    v->Visit("time_cost", &time_cost);
+  }
+
+  static constexpr const char* _type_key = "auto_scheduler.BuildResult";
+  TVM_DECLARE_FINAL_OBJECT_INFO(BuildResultNode, Object);
+};
+
+/*!
+ * \brief Managed reference to BuildResultNode.
+ * \sa BuildResultNode
+ */
+class BuildResult : public ObjectRef {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param filename The filename of built binary file.
+   * \param args The arguments.
+   * \param error_no The error code.
+   * \param error_msg The error message if there is any error.
+   * \param time_cost The time cost of build.
+   */
+  BuildResult(String filename, Array<te::Tensor> args, int error_no, String error_msg,
+              double time_cost);
+  TVM_DEFINE_OBJECT_REF_METHODS(BuildResult, ObjectRef, BuildResultNode);
+};
+
+/*! \brief Store the results of a measurement. */
+class MeasureResultNode : public Object {
+ public:
+  /*! \brief The time costs of execution. */
+  Array<PrimExpr> costs;
+  /*! \brief The error code. (0 means no error, see MeasureErrorNO) */
+  int error_no;
+  /*! \brief The error message if there is any error. */
+  String error_msg;
+  /*! \brief The time cost of build and run. */
+  double all_cost;
+  /*! \brief The time stamps of this measurement. */
+  double timestamp;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("costs", &costs);
+    v->Visit("error_no", &error_no);
+    v->Visit("error_msg", &error_msg);
+    v->Visit("all_cost", &all_cost);
+    v->Visit("timestamp", &timestamp);
+  }
+
+  /*! \brief Do shallow copy. */
+  MeasureResult copy() const;
+
+  static constexpr const char* _type_key = "auto_scheduler.MeasureResult";
+  TVM_DECLARE_FINAL_OBJECT_INFO(MeasureResultNode, Object);
+};
+
+/*!
+ * \brief Managed reference to MeasureResultNode.
+ * \sa MeasureResultNode
+ */
+class MeasureResult : public ObjectRef {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param costs The time costs of execution.
+   * \param error_no The error code.
+   * \param error_msg The error message if there is any error.
+   * \param all_cost The time cost of build and run.
+   * \param timestamp The time stamps of this measurement.
+   */
+  MeasureResult(Array<PrimExpr> costs, int error_no, String error_msg, double all_cost,
+                double timestamp);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(MeasureResult, ObjectRef, MeasureResultNode);
+};
+
+/*! \brief Bass class of measurement callbacks */
+class MeasureCallbackNode : public Object {
+ public:
+  /*!
+   * \brief Callback function that will be called on measurement input/result pairs
+   * after each measurement batch.
+   * \param policy The current search policy.
+   * \param inputs An Array of MeasureInput.
+   * \param results An Array of MeasureResult.
+   */
+  virtual void Callback(const SearchPolicy& policy, const Array<MeasureInput>& inputs,
+                        const Array<MeasureResult>& results) = 0;
+  static constexpr const char* _type_key = "auto_scheduler.MeasureCallback";
+  TVM_DECLARE_BASE_OBJECT_INFO(MeasureCallbackNode, Object);
+};
+
+/*!
+ * \brief Managed reference to MeasureCallbackNode.
+ * \sa MeasureCallbackNode
+ */
+class MeasureCallback : public ObjectRef {
+ public:
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(MeasureCallback, ObjectRef, MeasureCallbackNode);
+};
+
+/*! \brief A wrapper for measure callback defined by python code
+ *  This class will call functions defined in the python */
+class PythonBasedMeasureCallbackNode : public MeasureCallbackNode {
+ public:
+  /*! \brief Pointer to the callback function in python */
+  PackedFunc callback_func;
+
+  void Callback(const SearchPolicy& policy, const Array<MeasureInput>& inputs,
+                const Array<MeasureResult>& results) final;
+  static constexpr const char* _type_key = "auto_scheduler.PythonBasedMeasureCallback";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PythonBasedMeasureCallbackNode, MeasureCallbackNode);
+};
+
+/*!
+ * \brief Managed reference to PythonBasedMeasureCallbackNode.
+ * \sa PythonBasedMeasureCallbackNode
+ */
+class PythonBasedMeasureCallback : public MeasureCallback {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param callback_func The pointer to the callback function defined in python
+   */
+  explicit PythonBasedMeasureCallback(PackedFunc callback_func);
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(PythonBasedMeasureCallback, MeasureCallback,
+                                        PythonBasedMeasureCallbackNode);
+};
+
+// The base class of ProgramBuilders and ProgramRunners.
+
+/*! \brief ProgramBuilder that builds the programs */
+class ProgramBuilderNode : public Object {
+ public:
+  /*! \brief The number of build processes to run in parallel */
+  int n_parallel;
+  /*! \brief Timeout of a build */
+  int timeout;
+
+  /*!
+   * \brief Build programs and return results.
+   * \param inputs An Array of MeasureInput.
+   * \param verbose Verbosity level. 0 for silent, 1 to output information during program
+   * building.
+   * \return An Array of MeasureResult.
+   */
+  virtual Array<BuildResult> Build(const Array<MeasureInput>& inputs, int verbose) = 0;
+
+  static constexpr const char* _type_key = "auto_scheduler.ProgramBuilder";
+  TVM_DECLARE_BASE_OBJECT_INFO(ProgramBuilderNode, Object);
+};
+
+/*!
+ * \brief Managed reference to ProgramBuilderNode.
+ * \sa ProgramBuilderNode
+ */
+class ProgramBuilder : public ObjectRef {
+ public:
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(ProgramBuilder, ObjectRef, ProgramBuilderNode);
+};
+
+/*! \brief ProgramRunner that runs the built programs and measure the time cost. */
+class ProgramRunnerNode : public Object {
+ public:
+  /*! \brief Timeout of a run. */
+  int timeout;
+  /*! \brief The number of times to run the generated code for taking average. */
+  int number;
+  /*! \brief The number of times to repeat the measurement. */
+  int repeat;
+  /*! \brief The minimum duration of one repeat in milliseconds. */
+  int min_repeat_ms;
+  /*! \brief The cool down interval between two measurements. */
+  double cooldown_interval;
+  /*! \brief Whether to flush cache on CPU between repeated measurements. */
+  bool enable_cpu_cache_flush;
+  /*! \brief Which device to run on if multiple are avaialble. */
+  int device;
+
+  /*!
+   * \brief Run measurement and return results.
+   * \param inputs An Array of MeasureInput.
+   * \param build_results An Array of BuildResult.
+   * \param verbose Verbosity level. 0 for silent, 1 to output information during program
+   * running.
+   * \return An Array of MeasureResult.
+   */
+  virtual Array<MeasureResult> Run(const Array<MeasureInput>& inputs,
+                                   const Array<BuildResult>& build_results, int verbose) = 0;
+
+  static constexpr const char* _type_key = "auto_scheduler.ProgramRunner";
+  TVM_DECLARE_BASE_OBJECT_INFO(ProgramRunnerNode, Object);
+};
+
+/*!
+ * \brief Managed reference to ProgramRunnerNode.
+ * \sa ProgramRunnerNode
+ */
+class ProgramRunner : public ObjectRef {
+ public:
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(ProgramRunner, ObjectRef, ProgramRunnerNode);
+};
+
+// Implementation of various builders and runners
+
+/*! \brief LocalBuilder use local CPU cores to build programs in parallel */
+class LocalBuilderNode : public ProgramBuilderNode {
+ public:
+  /*! \brief Build function. */
+  String build_func;
+
+  Array<BuildResult> Build(const Array<MeasureInput>& inputs, int verbose) final;
+
+  static constexpr const char* _type_key = "auto_scheduler.LocalBuilder";
+  TVM_DECLARE_FINAL_OBJECT_INFO(LocalBuilderNode, ProgramBuilderNode);
+};
+
+/*!
+ * \brief Managed reference to LocalBuilderNode.
+ * \sa LocalBuilderNode
+ */
+class LocalBuilder : public ProgramBuilder {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param timeout The timeout limit (in second) for each build thread.
+   * This will be used in a wrapper of the multiprocessing.Process.join().
+   * \param n_parallel The number of threads used to build in parallel.
+   * \param build_func The name of the registered build function.
+   */
+  LocalBuilder(int timeout, int n_parallel, const String& build_func);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(LocalBuilder, ProgramBuilder, LocalBuilderNode);
+};
+
+/*! \brief LocalRunner that uses local CPU/GPU to measure the time cost of programs */
+class LocalRunnerNode : public ProgramRunnerNode {
+ public:
+  Array<MeasureResult> Run(const Array<MeasureInput>& inputs,
+                           const Array<BuildResult>& build_results, int verbose) final;
+
+  static constexpr const char* _type_key = "auto_scheduler.LocalRunner";
+  TVM_DECLARE_FINAL_OBJECT_INFO(LocalRunnerNode, ProgramRunnerNode);
+};
+
+/*!
+ * \brief Managed reference to LocalRunnerNode.
+ * \sa LocalRunnerNode
+ */
+class LocalRunner : public ProgramRunner {
+ public:
+  /*!
+   * \brief The constructor. See the corresponding class in python/tvm/auto_scheduler/measure.py
+   * for more detailed parameter explanation.
+   * \param timeout The timeout limit (in second) for each run.
+   * This is used in a wrapper of the multiprocessing.Process.join().
+   * \param number The number of times to run the generated code for taking average.
+   * \param repeat The number of times to repeat the measurement.
+   * \param min_repeat_ms The minimum duration of one repeat in milliseconds.
+   * \param cooldown_interval The cool down interval between two measurements.
+   * \param enable_cpu_cache_flush Whether to flush cache on CPU between repeated measurements.
+   * \param device Which device to run on if multiple are available.
+   */
+  LocalRunner(int timeout, int number, int repeat, int min_repeat_ms, double cooldown_interval,
+              bool enable_cpu_cache_flush, int device);
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(LocalRunner, ProgramRunner, LocalRunnerNode);
+};
+
+/*!
+ * \brief RPCRunner that uses RPC call to measures the time cost of programs on remote devices.
+ * Or sometime we may need to use RPC even in local running to insulate the thread environment.
+ * (e.g. running CUDA programs)
+ */
+class RPCRunnerNode : public ProgramRunnerNode {
+ public:
+  /*! \brief The key of the device registered in the RPC tracker. */
+  String key;
+  /*! \brief The host address of the RPC Tracker. */
+  String host;
+  /*! \brief The port of the RPC Tracker. */
+  int port;
+  /*! \brief The priority of this run request, larger is more prior. */
+  int priority;
+  /*! \brief The number of tasks run in parallel. */
+  int n_parallel;
+
+  Array<MeasureResult> Run(const Array<MeasureInput>& inputs,
+                           const Array<BuildResult>& build_results, int verbose) final;
+
+  static constexpr const char* _type_key = "auto_scheduler.RPCRunner";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RPCRunnerNode, ProgramRunnerNode);
+};
+
+/*!
+ * \brief Managed reference to RPCRunnerNode.
+ * \sa RPCRunnerNode
+ */
+class RPCRunner : public ProgramRunner {
+ public:
+  /*!
+   * \brief The constructor. See the corresponding class in python/tvm/auto_scheduler/measure.py
+   * for more detailed parameter explanation.
+   * \param key The key of the device registered in the RPC tracker.
+   * \param host The host address of the RPC Tracker.
+   * \param port The port of RPC Tracker.
+   * \param priority The priority of this run request, larger is more prior.
+   * \param n_parallel The number of tasks run in parallel.
+   * \param timeout Timeout of a run.
+   * \param number The number of times to run the generated code for taking average.
+   * \param repeat The number of times to repeat the measurement.
+   * \param min_repeat_ms The minimum duration of one repeat in milliseconds.
+   * \param cooldown_interval The cool down interval between two measurements.
+   * \param enable_cpu_cache_flush Whether to flush cache on CPU between repeated measurements.
+   * \param device Which device to run on if multiple are available.
+   */
+  RPCRunner(const String& key, const String& host, int port, int priority, int n_parallel,
+            int timeout, int number, int repeat, int min_repeat_ms, double cooldown_interval,
+            bool enable_cpu_cache_flush, int device);
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(RPCRunner, ProgramRunner, RPCRunnerNode);
+};
+
+/*!
+ * \brief Measurer that measures the time costs of tvm programs
+ * This class combines ProgramBuilder and ProgramRunner, and provides a simpler API */
+class ProgramMeasurerNode : public Object {
+ public:
+  /*! \brief Measured programs counter. */
+  int ct;
+  /*! \brief Continuous error counter. */
+  int error_ct;
+  /*! \brief Workload key to best flops map. */
+  std::unordered_map<std::string, double> best_flops;
+  /*! \brief Workload key to best state map. */
+  std::unordered_map<std::string, State> best_state;
+  /*! \brief Workload key to best state's count index map. */
+  std::unordered_map<std::string, int> best_ct;
+  /*! \brief The set of workloads that have at least one valid schedule */
+  std::unordered_set<std::string> has_valid;
+  /*! \brief The ProgramBuilder to build each program. */
+  ProgramBuilder builder;
+  /*! \brief The ProgramRunner to measure each program. */
+  ProgramRunner runner;
+  /*! \brief MeasureCallback to be called after each measure batch. */
+  Optional<Array<MeasureCallback>> callbacks;
+  /*! \brief Verbosity level. 0 for silent, 1 to output information during program measuring. */
+  int verbose;
+  /*! \brief The number of allowed maximum continuous error before forcely stopping the tuning */
+  int max_continuous_error;
+
+  /*! \brief Reset book keeping variables */
+  void Reset();
+
+  /*!
+   * \brief Do measurement.
+   * \param task The current SearchTask.
+   * \param policy The current SearchPolicy.
+   * \param inputs The inputs of measurement.
+   * \param batch_size Number of programs to be measured in one batch.
+   * \return results The results of measurement.
+   */
+  Array<MeasureResult> Measure(const SearchTask& task, const SearchPolicy& policy,
+                               const Array<MeasureInput>& inputs, int batch_size = -1);
+  /*!
+   * \brief Do measurement silently.
+   * This API will not print the measure results to screen.
+   * \param task The current SearchTask.
+   * \param inputs The MeasureInputs.
+   * \param results A pointer to a MeasureResult Array, this is used as output.
+   */
+  void SilentMeasure(const SearchTask& task, const Array<MeasureInput>& inputs,
+                     Array<MeasureResult>* results);
+
+  /*! \brief The default max continuous error setting. */
+  static const int DEFAULT_MAX_CONTINUOUS_ERROR = 150;
+
+  static constexpr const char* _type_key = "auto_scheduler.ProgramMeasurer";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ProgramMeasurerNode, Object);
+};
+
+/*!
+ * \brief Managed reference to ProgramMeasurerNode.
+ * \sa ProgramMeasurerNode
+ */
+class ProgramMeasurer : public ObjectRef {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param builder The ProgramBuilder to build programs.
+   * \param runner The ProgramRunner to measure programs.
+   * \param callbacks MeasureCallback to be called after each measurement batch.
+   * \param verbose Verbosity level. 0 for silent, 1 to output information during program
+   * measuring.
+   * \param max_continuous_error The number of allowed maximum continuous error before
+   * forcely stopping the tuning.
+   */
+  ProgramMeasurer(ProgramBuilder builder, ProgramRunner runner,
+                  Optional<Array<MeasureCallback>> callbacks, int verbose,
+                  int max_continuous_error = -1);
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(ProgramMeasurer, ObjectRef, ProgramMeasurerNode);
+};
+
+}  // namespace auto_scheduler
+}  // namespace tvm
+
+#endif  // TVM_AUTO_SCHEDULER_MEASURE_H_
diff --git a/darknet_drp_ros/include/tvm/auto_scheduler/measure_record.h b/darknet_drp_ros/include/tvm/auto_scheduler/measure_record.h
new file mode 100644
index 0000000..c82ed07
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/auto_scheduler/measure_record.h
@@ -0,0 +1,140 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/auto_scheduler/measure_record.h
+ * \brief Json serialization format for dumping and loading measurement records.
+ */
+
+#ifndef TVM_AUTO_SCHEDULER_MEASURE_RECORD_H_
+#define TVM_AUTO_SCHEDULER_MEASURE_RECORD_H_
+
+#include <tvm/auto_scheduler/measure.h>
+
+#include <fstream>
+#include <string>
+#include <utility>
+
+namespace tvm {
+namespace auto_scheduler {
+
+const std::string AUTO_SCHEDULER_LOG_VERSION = "v0.6";  // NOLINT(*)
+
+/*! \brief Callback for logging the input and results of measurements to file */
+class RecordToFileNode : public MeasureCallbackNode {
+ public:
+  /*! \brief The name of output file. */
+  String filename;
+
+  void Callback(const SearchPolicy& policy, const Array<MeasureInput>& inputs,
+                const Array<MeasureResult>& results) final;
+
+  static constexpr const char* _type_key = "auto_scheduler.RecordToFile";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RecordToFileNode, MeasureCallbackNode);
+};
+
+/*!
+ * \brief Managed reference to RecordToFileNode.
+ * \sa RecordToFileNode
+ */
+class RecordToFile : public MeasureCallback {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param filename The name of output file
+   */
+  explicit RecordToFile(String filename);
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(RecordToFile, MeasureCallback, RecordToFileNode);
+};
+
+/*! \brief Log reader to load step logs from a file.*/
+class RecordReaderNode : public Object {
+ public:
+  /*! \brief The name of input file. */
+  String filename;
+  /*! \brief The reading file stream. */
+  std::ifstream infile;
+
+  ~RecordReaderNode();
+
+  /*!
+   * \brief Read next line in the log file.
+   * \param inp A pointer to a MeasureInputNode, this is used as output.
+   * \param res A pointer to a MeasureResultNode, this is used as output.
+   * \return Whether the read is successful. */
+  bool ReadNext(MeasureInputNode* inp, MeasureResultNode* res);
+
+  /*!
+   * \brief Read multiple lines from the log file.
+   * \param max_size The maximum number of lines. -1 means read all lines.
+   * \param skip_size Skip the first n lines.
+   * \return The MeasureInputs and MeasureResults loaded from the log file.
+   */
+  std::pair<Array<MeasureInput>, Array<MeasureResult>> ReadLines(int max_size = -1,
+                                                                 int skip_size = 0);
+
+  static constexpr const char* _type_key = "auto_scheduler.RecordReader";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RecordReaderNode, Object);
+
+ private:
+  /*! \brief A string storing the current line. */
+  std::string cur_line_;
+};
+
+/*!
+ * \brief Managed reference to RecordReaderNode.
+ * \sa RecordReaderNode
+ */
+class RecordReader : public ObjectRef {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param filename The name of input file
+   */
+  explicit RecordReader(String filename);
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(RecordReader, ObjectRef, RecordReaderNode);
+};
+
+/*!
+ * \brief Append measure records to an output stream.
+ * \param os A pointer to a output stream.
+ * \param inputs The MeasureInputs to be written.
+ * \param results The MeasureResults to be written.
+ * \param log_version The log version for the given record.
+ */
+void WriteMeasureRecords(std::ostream* os, const Array<MeasureInput>& inputs,
+                         const Array<MeasureResult>& results,
+                         const std::string log_version = AUTO_SCHEDULER_LOG_VERSION);
+
+/*!
+ * \brief Read one measure record from a string.
+ * \param str The record string to be parsed.
+ * \param inp A pointer to a MeasureInputNode used to store the return value.
+ * \param res A pointer to a MeasureResultNode used to store the return value.
+ * \param log_version A pointer to a string used to store the log version.
+ */
+void ReadMeasureRecord(const std::string& str, MeasureInputNode* inp, MeasureResultNode* res,
+                       std::string* log_version);
+
+}  // namespace auto_scheduler
+}  // namespace tvm
+
+#endif  // TVM_AUTO_SCHEDULER_MEASURE_RECORD_H_
diff --git a/darknet_drp_ros/include/tvm/auto_scheduler/search_policy.h b/darknet_drp_ros/include/tvm/auto_scheduler/search_policy.h
new file mode 100644
index 0000000..e433799
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/auto_scheduler/search_policy.h
@@ -0,0 +1,206 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/auto_scheduler/search_policy.h
+ * \brief The base class of search policies, including the abstract definition of search policy and
+ * other supporting data structures.
+ *
+ * \note How to add a new search policy.
+ * In design, there's no need for users to implement their own search policy, our formal search
+ * policy(will be brought later) should be enough to cover most use cases. Meanwhile, a custom rule
+ * mechanism will be provided to enable user-defined template search to serve the same functionality
+ * as the current AutoTVM template.
+ *
+ * This guide is for advanced uses who have special requirements.
+ * 1. The only function that must be implemented is Search(), which takes a task as input and
+ * returns the best states found.
+ * 2. Information about the compute declaration of ops/subgraphs can be acquired from SearchTask.
+ * This structure also contains some information about the target device. (e.g. knowing the width
+ * of the device vector unit, we can limit the max vectorize size during schedule search)
+ * 3. SearchCallback provides more flexibility to do extra affairs before/after the search process.
+ * 4. ProgramMeasurer provides a simple but useful api to help check the performance of states got
+ * during the search process.
+ */
+
+#ifndef TVM_AUTO_SCHEDULER_SEARCH_POLICY_H_
+#define TVM_AUTO_SCHEDULER_SEARCH_POLICY_H_
+
+#include <tvm/auto_scheduler/measure.h>
+#include <tvm/auto_scheduler/search_task.h>
+#include <tvm/node/node.h>
+
+#include <string>
+#include <unordered_set>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+namespace auto_scheduler {
+
+class ProgramMeasurer;
+class SearchPolicyNode;
+
+/*!
+ * \brief Callback function to be called by the search process.
+ * This interface allows to do extra initializations before schedule search or extra
+ * check during/after the schedule search.
+ */
+class SearchCallbackNode : public Object {
+ public:
+  /*!
+   * \brief Run the registered callback function.
+   * \param policy A pointer to a SearchPolicyNode.
+   */
+  virtual void Callback(SearchPolicyNode* policy) = 0;
+
+  static constexpr const char* _type_key = "auto_scheduler.SearchCallback";
+  TVM_DECLARE_BASE_OBJECT_INFO(SearchCallbackNode, Object);
+};
+
+/*!
+ * \brief Managed reference to SearchCallbackNode.
+ * \sa SearchCallbackNode
+ */
+class SearchCallback : public ObjectRef {
+ public:
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(SearchCallback, ObjectRef, SearchCallbackNode);
+};
+
+/*! \brief Preload measured states from a log file.
+ * This can resume the state of the search policy */
+class PreloadMeasuredStatesNode : public SearchCallbackNode {
+ public:
+  /*! \brief The name of the record log file. */
+  String filename;
+
+  void Callback(SearchPolicyNode* policy) final;
+
+  static constexpr const char* _type_key = "auto_scheduler.PreloadMeasuredStates";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PreloadMeasuredStatesNode, SearchCallbackNode);
+};
+
+/*!
+ * \brief Managed reference to PreloadMeasuredStatesNode.
+ * \sa PreloadMeasuredStatesNode
+ */
+class PreloadMeasuredStates : public SearchCallback {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param filename The name of the record log file.
+   */
+  explicit PreloadMeasuredStates(String filename);
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(PreloadMeasuredStates, SearchCallback,
+                                        PreloadMeasuredStatesNode);
+};
+
+/*! \brief Attribute keys of ops used for SearchPolicy. */
+struct SearchPolicyKey {
+  /*! \brief Always apply unroll to the inner most iterator of the specificed iterators. */
+  static constexpr const char* always_unroll_inner = "auto_scheduler_always_unroll_inner";
+  /*! \brief The specified iterators will be placed in the inner most tile without split. */
+  static constexpr const char* no_split_at_inner = "auto_scheduler_no_split_at_inner";
+  /*! \brief The specified iterators are indices of const tensors in "fake reduction". */
+  static constexpr const char* simplify_const_tensor_indices =
+      "auto_scheduler_simplify_const_tensor_indices";
+};
+
+/*!
+ * \brief The base class of search policies.
+ */
+class SearchPolicyNode : public Object {
+ public:
+  /*! \brief The current search task. */
+  SearchTask search_task;
+  /*!
+   * \brief Verbose level to control the screen output during schedule search.
+   * 0 for silent, 1 to output state & measure information during search process.
+   */
+  int verbose;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("search_task", &search_task);
+    v->Visit("verbose", &verbose);
+  }
+
+  /*!
+   * \brief Do schedule search for a task. Takes the SearchTask as input and returns the best state
+   * found during the search.
+   * \param num_measure_trials The number of total measurement trials.
+   * \param early_stopping Stops the tuning early if no improvement after n measurements.
+   * \param num_measures_per_round  The number of programs to be measured at each search round.
+   * \param measurer A ProgramMeasurer to build and measure programs
+   * \return The best state found.
+   */
+  virtual State Search(int num_measure_trials, int early_stopping, int num_measures_per_round,
+                       ProgramMeasurer measurer) = 0;
+
+  /*!
+   * \brief Continue the search by doing an additional search round.
+   * \param num_measure The number of measurements
+   * \param measurer The measurer to measure programs
+   * \return The measurement records for measurements in this search round
+   */
+  virtual std::pair<Array<MeasureInput>, Array<MeasureResult>> ContinueSearchOneRound(
+      int num_measure, ProgramMeasurer measurer) = 0;
+
+  /*!
+   * \brief Preload measured states from a log file to resume the state of the search policy.
+   * \param log_file The name of the record log file.
+   */
+  void PreloadMeasuredStates(const String& log_file);
+
+  /*!
+   * \brief Call SearchCallback with the current SearchPolicyNode
+   * \param callbacks SearchCallback to be called.
+   */
+  void RunCallbacks(const Array<SearchCallback>& callbacks);
+
+  static constexpr const char* _type_key = "auto_scheduler.SearchPolicy";
+  TVM_DECLARE_BASE_OBJECT_INFO(SearchPolicyNode, Object);
+
+ protected:
+  /*!
+   * \brief The set of already measured states.
+   * We store the string format of a state for redundancy check. This is used to make sure a
+   * measured state will never be measured again.
+   */
+  std::unordered_set<std::string> measured_states_set_;
+  /*! \brief The array of already measured states.
+   *  The good states can be used as the initial population in evolutionary search. */
+  std::vector<State> measured_states_vector_;
+  /*! \brief The throughputs of already measured states */
+  std::vector<float> measured_states_throughputs_;
+};
+
+/*!
+ * \brief Managed reference to SearchPolicyNode.
+ * \sa SearchPolicyNode
+ */
+class SearchPolicy : public ObjectRef {
+ public:
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(SearchPolicy, ObjectRef, SearchPolicyNode);
+};
+
+}  // namespace auto_scheduler
+}  // namespace tvm
+
+#endif  // TVM_AUTO_SCHEDULER_SEARCH_POLICY_H_
diff --git a/darknet_drp_ros/include/tvm/auto_scheduler/search_task.h b/darknet_drp_ros/include/tvm/auto_scheduler/search_task.h
new file mode 100644
index 0000000..efbc252
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/auto_scheduler/search_task.h
@@ -0,0 +1,171 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file auto_scheduler/search_task.h
+ * \brief Meta information and hardware parameters for a search task.
+ */
+
+#ifndef TVM_AUTO_SCHEDULER_SEARCH_TASK_H_
+#define TVM_AUTO_SCHEDULER_SEARCH_TASK_H_
+
+#include <tvm/auto_scheduler/compute_dag.h>
+#include <tvm/runtime/ndarray.h>
+#include <tvm/target/target.h>
+
+namespace tvm {
+namespace auto_scheduler {
+
+class HardwareParams;
+
+/*! \brief The parameters of target hardware used to guide the SearchPolicy. */
+class HardwareParamsNode : public Object {
+ public:
+  /*! \brief The number of cores. */
+  int num_cores;
+  /*! \brief The width of vector units in bytes. */
+  int vector_unit_bytes;
+  /*! \brief The size of cache line in bytes. */
+  int cache_line_bytes;
+
+  // GPU related parameters got from device query API
+  /*! \brief The max shared memory per block in bytes. */
+  int max_shared_memory_per_block;
+  /*! \brief The max local memory per block in bytes. */
+  int max_local_memory_per_block;
+  /*! \brief The max number of threads per block. */
+  int max_threads_per_block;
+  /*! \brief The max vthread extent. */
+  int max_vthread_extent;
+  /*! \brief The thread numbers of a warp. */
+  int warp_size;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("num_cores", &num_cores);
+    v->Visit("vector_unit_bytes", &vector_unit_bytes);
+    v->Visit("cache_line_bytes", &cache_line_bytes);
+    v->Visit("max_shared_memory_per_block", &max_shared_memory_per_block);
+    v->Visit("max_local_memory_per_block", &max_local_memory_per_block);
+    v->Visit("max_threads_per_block", &max_threads_per_block);
+    v->Visit("max_vthread_extent", &max_vthread_extent);
+    v->Visit("warp_size", &warp_size);
+  }
+
+  /*!
+   * \brief Get the default hardware params.
+   * \param target A `tvm.target`.
+   * \param target_host A `tvm.target` for host device.
+   * \return A HardwareParams object.
+   */
+  static HardwareParams GetDefaultHardwareParams(const Target& target, const Target& target_host);
+
+  static constexpr const char* _type_key = "auto_scheduler.HardwareParams";
+  TVM_DECLARE_FINAL_OBJECT_INFO(HardwareParamsNode, Object);
+};
+
+/*!
+ * \brief Managed reference to HardwareParamsNode.
+ * \sa HardwareParamsNode
+ */
+class HardwareParams : public ObjectRef {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param num_cores The number of cores.
+   * \param vector_unit_bytes The width of vector units in bytes.
+   * \param cache_line_bytes The size of cache line in bytes.
+   * \param max_shared_memory_per_block The max amount of shared memory per block for GPU.
+   * \param max_local_memory_per_block The max amount of local memory per block for GPU.
+   * \param max_threads_per_block The max number of threads per block for GPU.
+   * \param max_vthread_extent The max extent of vthread for GPU.
+   * \param warp_size The warp size for GPU
+   */
+  HardwareParams(int num_cores, int vector_unit_bytes, int cache_line_bytes,
+                 int max_shared_memory_per_block, int max_local_memory_per_block,
+                 int max_threads_per_block, int max_vthread_extent, int warp_size);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(HardwareParams, ObjectRef, HardwareParamsNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(HardwareParamsNode);
+};
+
+/*!
+ * \brief The computation information and hardware parameters for a specific schedule search task.
+ */
+class SearchTaskNode : public Object {
+ public:
+  /*! \brief The ComputeDAG for the compute declaration. */
+  ComputeDAG compute_dag;
+  /*! \brief The workload key for the compute declaration. */
+  String workload_key;
+  /*! \brief The description string of this task. */
+  String desc;
+  /*! \brief The target device of this search task. */
+  Target target;
+  /*! \brief The target host device of this search task. */
+  Target target_host;
+  /*! \brief Hardware parameters used in this search task. */
+  HardwareParams hardware_params;
+  /*! \brief The layout rewrite option used for measuring programs. */
+  LayoutRewriteOption layout_rewrite_option;
+  /*! \brief Names of some user defined input data used in program measuring. */
+  Array<String> task_input_names;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("compute_dag", &compute_dag);
+    v->Visit("workload_key", &workload_key);
+    v->Visit("desc", &desc);
+    v->Visit("target", &target);
+    v->Visit("target_host", &target_host);
+    v->Visit("hardware_params", &hardware_params);
+    v->Visit("layout_rewrite_option", &layout_rewrite_option);
+    v->Visit("task_input_names", &task_input_names);
+  }
+
+  static constexpr const char* _type_key = "auto_scheduler.SearchTask";
+  TVM_DECLARE_FINAL_OBJECT_INFO(SearchTaskNode, Object);
+};
+
+/*!
+ * \brief Managed reference to SearchTaskNode.
+ * \sa SearchTaskNode
+ */
+class SearchTask : public ObjectRef {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param compute_dag The ComputeDAG for the compute declaration.
+   * \param workload_key The workload key for the compute declaration.
+   * \param target The target device of this search task.
+   * \param target_host The target host device of this search task.
+   * \param hardware_params Hardware parameters used in this search task.
+   * \param layout_rewrite_option The layout rewrite option used for measuring programs.
+   * \param task_input_names Names of some user defined input data used in program measuring.
+   * \param desc The description string of this task.
+   */
+  SearchTask(ComputeDAG compute_dag, String workload_key, Target target, Target target_host,
+             Optional<HardwareParams> hardware_params, LayoutRewriteOption layout_rewrite_option,
+             Array<String> task_input_names, String desc = "");
+
+  TVM_DEFINE_OBJECT_REF_METHODS(SearchTask, ObjectRef, SearchTaskNode);
+};
+
+}  // namespace auto_scheduler
+}  // namespace tvm
+
+#endif  // TVM_AUTO_SCHEDULER_SEARCH_TASK_H_
diff --git a/darknet_drp_ros/include/tvm/auto_scheduler/transform_step.h b/darknet_drp_ros/include/tvm/auto_scheduler/transform_step.h
new file mode 100644
index 0000000..4cc1551
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/auto_scheduler/transform_step.h
@@ -0,0 +1,1197 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file auto_scheduler/transform_step.h
+ * \brief Transformation steps. These steps are used to manipulate `LoopState`.
+ *        They are similar to the schedule primitives in te::Stage.
+ *
+ * \note How to add a new transform step:
+ * Take fuse step for example:
+ * 1. Define class `FuseStepNode`, `FuseStep` in `transform_steps.h`, and implement its first
+ *    construction function `FuseStep::FuseStep()` in `transform_steps.cc`.
+ * 2. Implement `FuseStepNode::ApplyToSchedule()` and `FuseStepNode::PrintAsPythonAPI()`.
+ *    - In these two functions you need to lower this step with tvm's te schedule API
+ * 3. Implement `FuseStepNode::ApplyToState` and the state API `State::fuse`.
+ *    - In these two functions you need to incrementally update all data structures in State with
+ *      CopyOnWrite style.
+ * 4. Add your step to `StepApplyToState`, `StepApplyToSchedule`, and `StepPrintAsPythonAPI`.
+ * 5. Log record serialization support:
+ *    - Add `FuseStepNode::WriteToRecord` which takes a mutable JSONWriter pointer as input and
+ *      output the record to it.
+ *    - Add another construction function that takes a mutable JSONReader as input, this will get a
+ *      step record from the reader and create the step.
+ *    - Add the step implementation to `StepReadFromRecord`.
+ * 6. Add its corresponding Python API to `loop_state.py` with necessary unit tests. The test should
+ *    at lease cover two parts: the functional test and the record serialization test.
+ */
+
+#ifndef TVM_AUTO_SCHEDULER_TRANSFORM_STEP_H_
+#define TVM_AUTO_SCHEDULER_TRANSFORM_STEP_H_
+
+#include <dmlc/common.h>
+#include <dmlc/json.h>
+#include <tvm/node/node.h>
+#include <tvm/te/schedule.h>
+
+#include <vector>
+
+namespace tvm {
+namespace auto_scheduler {
+
+typedef Map<tvm::te::Stage, Array<tir::IterVar>, ObjectHash, ObjectEqual> StageToAxesMap;
+
+/*!
+ * \brief Update the current stage IterVar information to StageToAxesMap.
+ * \param stage The stage to be updated.
+ * \param stage_to_axes The map to be updated.
+ */
+void UpdateStageToAxesMap(const te::Stage& stage, StageToAxesMap* stage_to_axes);
+
+/*! \brief The type of an iterator. */
+enum class IteratorKind : int {
+  /*! \brief Spatial iterator. */
+  kSpatial = 0,
+  /*! \brief Reduction iterator. */
+  kReduction = 1,
+  /*! \brief Fused spatial and reduction iterator. */
+  kMixed = 2,
+  /*! \brief Special iterator. (e.g. virtual root iterator) */
+  kSpecial = 3
+};
+
+/*! \brief The type of an iterator's annotation. */
+enum class IteratorAnnotation : int {
+  /*! \brief This iterator has no annotation. */
+  kNone = 0,
+  /*! \brief This iterator has been unrolled. */
+  kUnroll = 1,
+  /*! \brief This iterator has been vectorized. */
+  kVectorize = 2,
+  /*! \brief This iterator has been paralleld. */
+  kParallel = 3,
+  /*! \brief This iterator has been bind to vthread. */
+  kVThread = 4,
+  /*! \brief This iterator has been bind to blockIdx.x. */
+  kBlockX = 5,
+  /*! \brief This iterator has been bind to threadIdx.x. */
+  kThreadX = 6,
+  /*! \brief This iterator has been bind to blockIdx.y. */
+  kBlockY = 7,
+  /*! \brief This iterator has been bind to threadIdx.y. */
+  kThreadY = 8,
+  /*! \brief This iterator has been bind to blockIdx.y. */
+  kBlockZ = 9,
+  /*! \brief This iterator has been bind to threadIdx.y. */
+  kThreadZ = 10,
+  /*! \brief This iterator has been mapped with a tensorize intrinsic. */
+  kTensorize = 11
+};
+
+extern const char* IteratorAnnotationString[];
+
+// forward declaration
+class Iterator;
+
+/*!
+ * \brief An iterator of a for-loop
+ * Similar to tvm::IterVar in `include/tvm/tir/expr.h`
+ */
+class IteratorNode : public Object {
+ public:
+  /*! \brief The name of this iterator. */
+  String name;
+  /*! \brief The range of this iterator. */
+  Range range;
+  /*! \brief The iterator type of this iterator. */
+  IteratorKind iter_kind;
+  /*! \brief The annotation type of this iterator. */
+  IteratorAnnotation annotation;
+  /*! The original iterators before fusion. */
+  std::vector<Iterator> orig_iters;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("name", &name);
+    v->Visit("range", &range);
+    v->Visit("iter_kind", &iter_kind);
+    v->Visit("annotation", &annotation);
+  }
+
+  static constexpr const char* _type_key = "auto_scheduler.Iterator";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IteratorNode, Object);
+};
+
+/*!
+ * \brief Managed reference to IteratorNode.
+ * \sa IteratorNode
+ */
+class Iterator : public ObjectRef {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param name The name of this iterator.
+   * \param range The range of this iterator.
+   * \param iter_kind The iterator type of this iterator.
+   * \param annotation The annotation type of this iterator.
+   * \param orig_iters The original iterators before fusion
+   */
+  Iterator(String name, Range range, IteratorKind iter_kind, IteratorAnnotation annotation,
+           const std::vector<Iterator>* orig_iters = nullptr);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Iterator, ObjectRef, IteratorNode);
+};
+
+/*!
+ * \brief The base class of transformation steps. Each step has its corresponding tvm.te
+ * schedule primitives.
+ */
+class StepNode : public Object {
+ public:
+  /*! \brief The index of the stage. */
+  int stage_id;
+
+  /*!
+   * \brief Serialize the current step record to JSONWriter.
+   * \param writer The output JSONWriter.
+   */
+  virtual void WriteToRecord(dmlc::JSONWriter* writer) const = 0;
+
+  static constexpr const char* _type_key = "auto_scheduler.Step";
+  TVM_DECLARE_BASE_OBJECT_INFO(StepNode, Object);
+};
+
+/*!
+ * \brief Managed reference to StepNode.
+ * \sa StepNode
+ */
+class Step : public ObjectRef {
+ public:
+  /*!
+   * \brief CopyOnWrite function for Step.
+   * This works almost the same as a normal ObjectRef.CopyOnWrite(), but can dispatch to different
+   * steps.
+   * \return A base StepNode pointer, need to cast to its real StepNode type before doing any
+   * modifications.
+   * \code
+   *
+   *  SplitStep ref;
+   *  StepNode* mutable_ref = ref.CopyOnWrite();
+   *  dynamic_cast<SplitStepNode*>(mutable_ref)->... = ...;
+   *
+   * \endcode
+   */
+  StepNode* CopyOnWrite();
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Step, ObjectRef, StepNode);
+};
+
+// Forward declaration
+class State;
+class ComputeDAG;
+
+/*!
+ * \brief Read a step record from JSONReader and create the corresponding step.
+ * \param reader The input JSONReader.
+ */
+Step StepReadFromRecord(dmlc::JSONReader* reader);
+
+/*!
+ * \brief Apply a general step to a State with runtime dynamic dispatching.
+ * \param step The step to be applied to State.
+ * \param state A mutable pointer to state, which will be updated.
+ * \param dag The original ComputeDAG of this state.
+ */
+void StepApplyToState(const Step& step, State* state, const ComputeDAG& dag);
+
+/*!
+ * \brief Apply a general step to tvm.schedule with runtime dynamic dispatching.
+ * \param step The step to be applied to tvm.schedule.
+ * \param stages The list of current stages
+ * \param stage_to_axes A map that maps stage ot all its iterators.
+ * \param schedule A mutable point to the current schedule
+ * \param transform_steps An array of all history transform steps.
+ */
+void StepApplyToSchedule(const Step& step, Array<te::Stage>* stages, StageToAxesMap* stage_to_axes,
+                         te::Schedule* schedule, const Array<Step>& transform_steps);
+
+/*!
+ * \brief Print a general step as equivalent python schedule API with runtime dynamic dispatching.
+ * \param step The step to be printed as python API.
+ * \param stages The list of current stages
+ * \param stage_to_axes A map that maps stage ot all its iterators.
+ * \param schedule A mutable point to the current schedule
+ * \param transform_steps An array of all history transform steps.
+ * \return Python schedule code.
+ */
+String StepPrintAsPythonAPI(const Step& step, Array<te::Stage>* stages,
+                            StageToAxesMap* stage_to_axes, te::Schedule* schedule,
+                            const Array<Step>& transform_steps);
+
+/********** Steps working on single stage **********/
+
+/*!
+ * \brief Annotation step that corresponds to vectorize, parallel, unroll and thread binding.
+ * (i.e. te::Stage::vectorize, te::Stage::parallel, te::Stage::vectorize, te::Stage::bind)
+ */
+class AnnotationStepNode : public StepNode {
+ public:
+  /*! \brief The index of the iterator to add annotation. */
+  int iter_id;
+  /*! \brief The annotation type of this step. */
+  IteratorAnnotation annotation;
+
+  void WriteToRecord(dmlc::JSONWriter* writer) const final;
+
+  /*!
+   * \brief Apply the current step to State.
+   * \param state A mutable pointer to state, which will be updated.
+   * \return The iterator result after annotate.
+   */
+  Iterator ApplyToState(State* state) const;
+
+  /*!
+   * \brief Apply the current step to tvm.schedule.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   */
+  void ApplyToSchedule(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes) const;
+
+  /*!
+   * \brief Print the current step as equivalent python schedule API.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \return Python schedule code.
+   */
+  String PrintAsPythonAPI(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes) const;
+
+  static constexpr const char* record_prefix_str = "AN";
+
+  static constexpr const char* _type_key = "auto_scheduler.AnnotationStep";
+  TVM_DECLARE_FINAL_OBJECT_INFO(AnnotationStepNode, StepNode);
+};
+
+/*!
+ * \brief Managed reference to AnnotationStepNode.
+ * \sa AnnotationStepNode
+ */
+class AnnotationStep : public Step {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param stage_id The index of the stage to add annotation.
+   * \param iter_id The index of the iterator to add annotation.
+   * \param ann The annotation type of this step.
+   */
+  AnnotationStep(int stage_id, int iter_id, IteratorAnnotation ann);
+
+  /*!
+   * \brief The constructor used to read a step record from JSONReader and create the
+   * corresponding step.
+   * \param reader The input JSONReader.
+   */
+  explicit AnnotationStep(dmlc::JSONReader* reader);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(AnnotationStep, Step, AnnotationStepNode);
+};
+
+/*! \brief Fuse step that corresponds to te::Stage::fuse */
+class FuseStepNode : public StepNode {
+ public:
+  /*! \brief The ids of iterators to fuse. */
+  Array<Integer> fused_ids;
+
+  void WriteToRecord(dmlc::JSONWriter* writer) const final;
+
+  /*!
+   * \brief Apply the current step to State.
+   * \param state A mutable pointer to state, which will be updated.
+   * \return The iterator result after fuse.
+   * \note If the iterators to be fused have stages attached at them(by compute_at), the fused
+   * result will become the new attach point.
+   */
+  Iterator ApplyToState(State* state) const;
+
+  /*!
+   * \brief Apply the current step to tvm.schedule.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \return The iterator result after fuse.
+   */
+  tir::IterVar ApplyToSchedule(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes) const;
+
+  /*!
+   * \brief Print the current step as equivalent python schedule API.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \return Python schedule code.
+   */
+  String PrintAsPythonAPI(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes) const;
+
+  static constexpr const char* record_prefix_str = "FU";
+
+  static constexpr const char* _type_key = "auto_scheduler.FuseStep";
+  TVM_DECLARE_FINAL_OBJECT_INFO(FuseStepNode, StepNode);
+};
+
+/*!
+ * \brief Managed reference to FuseStepNode.
+ * \sa FuseStepNode
+ */
+class FuseStep : public Step {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param stage_id The index of the stage to be fused.
+   * \param fused_ids The index of the iterators to be fused.
+   */
+  FuseStep(int stage_id, const Array<Integer>& fused_ids);
+
+  /*!
+   * \brief The constructor used to read a step record from JSONReader and create the
+   * corresponding step.
+   * \param reader The input JSONReader.
+   */
+  explicit FuseStep(dmlc::JSONReader* reader);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(FuseStep, Step, FuseStepNode);
+};
+
+/*! \brief Pragma step that corresponds to te::Stage::pragma */
+class PragmaStepNode : public StepNode {
+ public:
+  /*! \brief The index of the iterator to add pragma. */
+  int iter_id;
+  /*! \brief The pragma string. */
+  String pragma_type;
+
+  void WriteToRecord(dmlc::JSONWriter* writer) const final;
+
+  /*!
+   * \brief Apply the current step to State.
+   * \param state A mutable pointer to state, which will be updated.
+   */
+  void ApplyToState(State* state) const;
+
+  /*!
+   * \brief Apply the current step to tvm.schedule.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   */
+  void ApplyToSchedule(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes) const;
+
+  /*!
+   * \brief Print the current step as equivalent python schedule API.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \return Python schedule code.
+   */
+  String PrintAsPythonAPI(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes) const;
+
+  static constexpr const char* record_prefix_str = "PR";
+
+  static constexpr const char* _type_key = "auto_scheduler.PragmaStep";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PragmaStepNode, StepNode);
+};
+
+/*!
+ * \brief Managed reference to PragmaStepNode.
+ * \sa PragmaStepNode
+ */
+class PragmaStep : public Step {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param stage_id The index of the stage to be fused.
+   * \param iter_id The index of the iterator to add pragma.
+   * \param pragma_type The pragma string.
+   */
+  PragmaStep(int stage_id, int iter_id, String pragma_type);
+
+  /*!
+   * \brief The constructor used to read a step record from JSONReader and create the
+   * corresponding step.
+   * \param reader The input JSONReader.
+   */
+  explicit PragmaStep(dmlc::JSONReader* reader);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(PragmaStep, Step, PragmaStepNode);
+};
+
+/*! \brief Reorder step that corresponds to te::Stage::reorder */
+class ReorderStepNode : public StepNode {
+ public:
+  /*!
+   * \brief The iterator ids after reorder.
+   * This array should specify the order of all iterators.
+   */
+  Array<Integer> after_ids;
+
+  void WriteToRecord(dmlc::JSONWriter* writer) const final;
+
+  /*!
+   * \brief Apply the current step to State.
+   * \param state A mutable pointer to state, which will be updated.
+   */
+  void ApplyToState(State* state) const;
+
+  /*!
+   * \brief Apply the current step to tvm.schedule.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   */
+  void ApplyToSchedule(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes) const;
+
+  /*!
+   * \brief Print the current step as equivalent python schedule API.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \return Python schedule code.
+   */
+  String PrintAsPythonAPI(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes) const;
+
+  static constexpr const char* record_prefix_str = "RE";
+
+  static constexpr const char* _type_key = "auto_scheduler.ReorderStep";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ReorderStepNode, StepNode);
+};
+
+/*!
+ * \brief Managed reference to ReorderStepNode.
+ * \sa ReorderStepNode
+ */
+class ReorderStep : public Step {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param stage_id The index of the stage to be reordered.
+   * \param after_ids The expected indexes of the iterators after reorder.
+   */
+  ReorderStep(int stage_id, const Array<Integer>& after_ids);
+
+  /*!
+   * \brief The constructor used to read a step record from JSONReader and create the
+   * corresponding step.
+   * \param reader The input JSONReader.
+   */
+  explicit ReorderStep(dmlc::JSONReader* reader);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(ReorderStep, Step, ReorderStepNode);
+};
+
+/*!
+ * \brief Split step that corresponds to te::Stage::split with additional
+ *  support of multiple-level of factors
+ */
+class SplitStepNode : public StepNode {
+ public:
+  /*! \brief The id of the iter to split. */
+  int iter_id;
+  /*! \brief The extent length of the axis to split. */
+  Optional<PrimExpr> extent;
+  /*! \brief The split factors. */
+  Array<Optional<Integer>> lengths;
+  /*!
+   * \brief If true, the `lengths` denote the lengths of iterators
+   * from inner level to outer level
+   */
+  bool inner_to_outer;
+
+  void WriteToRecord(dmlc::JSONWriter* writer) const final;
+
+  /*!
+   * \brief Apply the current step to State.
+   * \param state A mutable pointer to state, which will be updated.
+   * \return The iterator results after split.
+   * \note If we do split on an iterator which has stages attached at it(by compute_at), the inner
+   * most iterator of split results will become the new attach point.
+   */
+  Array<Iterator> ApplyToState(State* state) const;
+
+  /*!
+   * \brief Apply the current step to tvm.schedule.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \return The iterator results after split.
+   */
+  Array<tir::IterVar> ApplyToSchedule(Array<te::Stage>* stages,
+                                      StageToAxesMap* stage_to_axes) const;
+
+  /*!
+   * \brief Print the current step as equivalent python schedule API.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \return Python schedule code.
+   */
+  String PrintAsPythonAPI(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes) const;
+
+  static constexpr const char* record_prefix_str = "SP";
+
+  static constexpr const char* _type_key = "auto_scheduler.SplitStep";
+  TVM_DECLARE_FINAL_OBJECT_INFO(SplitStepNode, StepNode);
+};
+
+/*!
+ * \brief Managed reference to SplitStepNode.
+ * \sa SplitStepNode
+ */
+class SplitStep : public Step {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param stage_id The index of the stage to be split.
+   * \param iter_id The index of the iterator to be split.
+   * \param extent The extent length of the axis to split.
+   * \param lengths The multiple split factors. Can be None to be filled by search policy.
+   * \param inner_to_outer The split direction.
+   */
+  SplitStep(int stage_id, int iter_id, Optional<PrimExpr> extent,
+            const Array<Optional<Integer>>& lengths, bool inner_to_outer);
+
+  /*!
+   * \brief The constructor used to read a step record from JSONReader and create the
+   * corresponding step.
+   * \param reader The input JSONReader.
+   */
+  explicit SplitStep(dmlc::JSONReader* reader);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(SplitStep, Step, SplitStepNode);
+};
+
+/*! \brief Similar to SplitStepNode, but uses split factors from another step
+ * (i.e. Follow another split step) */
+class FollowSplitStepNode : public StepNode {
+ public:
+  /*! \brief The id of the iter to be split. */
+  int iter_id;
+  /*! \brief The index of the split step to be followed in the history. */
+  int src_step_id;
+  /*! \brief The number of split level. */
+  int n_split;
+
+  void WriteToRecord(dmlc::JSONWriter* writer) const final;
+
+  /*!
+   * \brief Extract split lengths.
+   * \param transform_steps An array of history transform steps.
+   * \return The multiple split factors.
+   */
+  Array<Optional<Integer>> ExtractSplitLengths(const Array<Step>& transform_steps) const;
+
+  /*!
+   * \brief Apply the current step to State.
+   * \param state A mutable pointer to state, which will be updated.
+   * \return The iterator results after split.
+   */
+  Array<Iterator> ApplyToState(State* state) const;
+
+  /*!
+   * \brief Apply the current step to tvm.schedule.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \param transform_steps An array of history transform steps.
+   * \return The iterator results after split.
+   */
+  Array<tir::IterVar> ApplyToSchedule(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes,
+                                      const Array<Step>& transform_steps) const;
+
+  /*!
+   * \brief Print the current step as equivalent python schedule API.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \param transform_steps An array of history transform steps.
+   * \return Python schedule code.
+   */
+  String PrintAsPythonAPI(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes,
+                          const Array<Step>& transform_steps) const;
+
+  static constexpr const char* record_prefix_str = "FSP";
+
+  static constexpr const char* _type_key = "auto_scheduler.FollowSplitStep";
+  TVM_DECLARE_FINAL_OBJECT_INFO(FollowSplitStepNode, StepNode);
+};
+
+/*!
+ * \brief Managed reference to FollowSplitStepNode.
+ * \sa FollowSplitStepNode
+ */
+class FollowSplitStep : public Step {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param stage_id The index of the stage to be split.
+   * \param iter_id The index of the iterator to be split.
+   * \param src_step_id The index of the split step to be followed in the history.
+   * \param n_split The number of split level.
+   */
+  FollowSplitStep(int stage_id, int iter_id, int src_step_id, int n_split);
+
+  /*!
+   * \brief The constructor used to read a step record from JSONReader and create the
+   * corresponding step.
+   * \param reader The input JSONReader.
+   */
+  explicit FollowSplitStep(dmlc::JSONReader* reader);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(FollowSplitStep, Step, FollowSplitStepNode);
+};
+
+/*! \brief Similar to FollowSplitStep, but uses split factors from multiple steps.
+ *  \note This can be used for the split in cooperative fetching.
+ */
+class FollowFusedSplitStepNode : public StepNode {
+ public:
+  /*! \brief The id of the iter to split. */
+  int iter_id;
+  /*! \brief The indices of the split steps to be followed in the history. */
+  Array<Integer> src_step_ids;
+  /*! \brief  Use the length in this split level. */
+  int level;
+  /*! \brief If this is true, use factor. Otherwise, use nparts. */
+  bool factor_or_nparts;
+
+  void WriteToRecord(dmlc::JSONWriter* writer) const final;
+
+  /*!
+   * \brief Extract split length.
+   * \param transform_steps An array of history transform steps.
+   * \return Split factor.
+   */
+  Optional<Integer> ExtractSplitLength(const Array<Step>& transform_steps) const;
+
+  /*!
+   * \brief Apply the current step to State.
+   * \param state A mutable pointer to state, which will be updated.
+   * \return The iterator results after split.
+   */
+  Array<Iterator> ApplyToState(State* state) const;
+
+  /*!
+   * \brief Apply the current step to tvm.schedule.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \param transform_steps An array of history transform steps.
+   * \return The iterator results after split.
+   */
+  Array<tir::IterVar> ApplyToSchedule(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes,
+                                      const Array<Step>& transform_steps) const;
+
+  /*!
+   * \brief Print the current step as equivalent python schedule API.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \param transform_steps An array of history transform steps.
+   * \return Python schedule code.
+   */
+  String PrintAsPythonAPI(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes,
+                          const Array<Step>& transform_steps) const;
+
+  static constexpr const char* record_prefix_str = "FFSP";
+
+  static constexpr const char* _type_key = "auto_scheduler.FollowFusedSplitStep";
+  TVM_DECLARE_FINAL_OBJECT_INFO(FollowFusedSplitStepNode, StepNode);
+};
+
+/*!
+ * \brief Managed reference to FollowFusedSplitStepNode.
+ * \sa FollowFusedSplitStepNode
+ */
+class FollowFusedSplitStep : public Step {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param stage_id The index of the stage to be split.
+   * \param iter_id The index of the iterator to be split.
+   * \param src_step_ids An array of index for split step to be followed in the history.
+   * \param level Use the length in this split level.
+   * \param factor_or_nparts If this is true, use factor. Otherwise, use nparts.
+   */
+  FollowFusedSplitStep(int stage_id, int iter_id, const Array<Integer>& src_step_ids, int level,
+                       bool factor_or_nparts);
+
+  /*!
+   * \brief The constructor used to read a step record from JSONReader and create the
+   * corresponding step.
+   * \param reader The input JSONReader.
+   */
+  explicit FollowFusedSplitStep(dmlc::JSONReader* reader);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(FollowFusedSplitStep, Step, FollowFusedSplitStepNode);
+};
+
+/*! \brief Storage align step that corresponds to te::Stage::storage_align */
+class StorageAlignStepNode : public StepNode {
+ public:
+  /*! \brief The iterator to be aligned. */
+  int iter_id;
+  /*! \brief The factor in alignment specification. */
+  int factor;
+  /*! \brief The offset in the alignment specification. */
+  int offset;
+
+  void WriteToRecord(dmlc::JSONWriter* writer) const final;
+
+  /*!
+   * \brief Apply the current step to State.
+   * \param state A mutable pointer to State, which will be updated.
+   */
+  void ApplyToState(State* state) const;
+
+  /*!
+   * \brief Apply the current step to tvm.schedule.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   */
+  void ApplyToSchedule(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes) const;
+
+  /*!
+   * \brief Print the current step as equivalent python schedule API.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \return Python schedule code.
+   */
+  String PrintAsPythonAPI(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes) const;
+
+  static constexpr const char* record_prefix_str = "SA";
+
+  static constexpr const char* _type_key = "auto_scheduler.StorageAlignStep";
+  TVM_DECLARE_FINAL_OBJECT_INFO(StorageAlignStepNode, StepNode);
+};
+
+/*!
+ * \brief Managed reference to StorageAlignStepNode.
+ * \sa StorageAlignStepNode
+ */
+class StorageAlignStep : public Step {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param stage_id The index of the stage to be aligned.
+   * \param iter_id The index of the iterator to be aligned.
+   * \param factor The factor in alignment specification.
+   * \param offset The offset in the alignment specification.
+   */
+  StorageAlignStep(int stage_id, int iter_id, int factor, int offset);
+
+  /*!
+   * \brief The constructor used to read a step record from JSONReader and create the
+   * corresponding step.
+   * \param reader The input JSONReader.
+   */
+  explicit StorageAlignStep(dmlc::JSONReader* reader);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(StorageAlignStep, Step, StorageAlignStepNode);
+};
+
+/********** Steps working on multiple stages **********/
+
+/*! \brief Compute at step that corresponds to te::Stage::compute_at */
+class ComputeAtStepNode : public StepNode {
+ public:
+  /*! \brief The index of stage that this step will compute at to. */
+  int target_stage_id;
+  /*! \brief The index of iterator in target stage that this step will compute at to. */
+  int target_iter_id;
+
+  void WriteToRecord(dmlc::JSONWriter* writer) const final;
+
+  /*!
+   * \brief Apply the current step to State.
+   * \param state A mutable pointer to state, which will be updated.
+   * \note After compute_at, we need careful dependency analysis to compute the accurate bound
+   * information. However, it is relatively expensive and complicated, so we just fill "None" as
+   * bound for the newly created iterators.
+   * Call ComputeDAG::InferBound on the updated state if you need the complete bound information.
+   */
+  void ApplyToState(State* state) const;
+
+  /*!
+   * \brief Apply the current step to tvm.schedule.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   */
+  void ApplyToSchedule(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes) const;
+
+  /*!
+   * \brief Print the current step as equivalent python schedule API.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \return Python schedule code.
+   */
+  String PrintAsPythonAPI(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes) const;
+
+  static constexpr const char* record_prefix_str = "CA";
+
+  static constexpr const char* _type_key = "auto_scheduler.ComputeAtStep";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ComputeAtStepNode, StepNode);
+};
+
+/*!
+ * \brief Managed reference to ComputeAtStepNode.
+ * \sa ComputeAtStepNode
+ */
+class ComputeAtStep : public Step {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param stage_id The index of the source stage.
+   * \param target_stage_id The index of stage that this step will compute at to.
+   * \param target_iter_id The index of iterator in target stage that this step will compute at to.
+   */
+  ComputeAtStep(int stage_id, int target_stage_id, int target_iter_id);
+
+  /*!
+   * \brief The constructor used to read a step record from JSONReader and create the
+   * corresponding step.
+   * \param reader The input JSONReader.
+   */
+  explicit ComputeAtStep(dmlc::JSONReader* reader);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(ComputeAtStep, Step, ComputeAtStepNode);
+};
+
+/*! \brief Compute inline step that corresponds to te::Stage::compute_inline */
+class ComputeInlineStepNode : public StepNode {
+ public:
+  void WriteToRecord(dmlc::JSONWriter* writer) const final;
+
+  /*!
+   * \brief Apply the current step to State.
+   * \param state A mutable pointer to state, which will be updated.
+   */
+  void ApplyToState(State* state) const;
+
+  /*!
+   * \brief Apply the current step to tvm.schedule.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \return The iterator result after fuse.
+   */
+  void ApplyToSchedule(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes) const;
+
+  /*!
+   * \brief Print the current step as equivalent python schedule API.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \return Python schedule code.
+   */
+  String PrintAsPythonAPI(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes) const;
+
+  static constexpr const char* record_prefix_str = "CI";
+
+  static constexpr const char* _type_key = "auto_scheduler.ComputeInlineStep";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ComputeInlineStepNode, StepNode);
+};
+
+/*!
+ * \brief Managed reference to ComputeInlineStepNode.
+ * \sa ComputeInlineStepNode
+ */
+class ComputeInlineStep : public Step {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param stage_id The index of the stage to be marked compute inlined.
+   */
+  explicit ComputeInlineStep(int stage_id);
+
+  /*!
+   * \brief The constructor used to read a step record from JSONReader and create the
+   * corresponding step.
+   * \param reader The input JSONReader.
+   */
+  explicit ComputeInlineStep(dmlc::JSONReader* reader);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(ComputeInlineStep, Step, ComputeInlineStepNode);
+};
+
+/*! \brief Compute root step that corresponds to te::Stage::compute_root */
+class ComputeRootStepNode : public StepNode {
+ public:
+  void WriteToRecord(dmlc::JSONWriter* writer) const final;
+
+  /*!
+   * \brief Apply the current step to State.
+   * \param state A mutable pointer to state, which will be updated.
+   * \note After compute_root, we need careful dependency analysis to compute the accurate bound
+   * information. However, it is relatively expensive and complicated, so we just fill "None" as
+   * bound for the newly created iterators.
+   * Call ComputeDAG::InferBound on the updated state if you need the complete bound information.
+   */
+  void ApplyToState(State* state) const;
+
+  /*!
+   * \brief Apply the current step to tvm.schedule.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \return The iterator result after fuse.
+   */
+  void ApplyToSchedule(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes) const;
+
+  /*!
+   * \brief Print the current step as equivalent python schedule API.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \return Python schedule code.
+   */
+  String PrintAsPythonAPI(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes) const;
+
+  static constexpr const char* record_prefix_str = "CR";
+
+  static constexpr const char* _type_key = "auto_scheduler.ComputeRootStep";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ComputeRootStepNode, StepNode);
+};
+
+/*!
+ * \brief Managed reference to ComputeRootStepNode.
+ * \sa ComputeRootStepNode
+ */
+class ComputeRootStep : public Step {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param stage_id The index of the stage to be marked compute at root.
+   */
+  explicit ComputeRootStep(int stage_id);
+
+  /*!
+   * \brief The constructor used to read a step record from JSONReader and create the
+   * corresponding step.
+   * \param reader The input JSONReader.
+   */
+  explicit ComputeRootStep(dmlc::JSONReader* reader);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(ComputeRootStep, Step, ComputeRootStepNode);
+};
+
+/********** Steps adding new stages **********/
+
+/*!
+ * \brief Cache read step that corresponds to te::Schedule::cache_read.
+ * \note Cache read step adds an extra stage to the original ComputeDAG,
+ * an up-to-date ComputeDAG will be stored in State's `current_compute_dag`.
+ */
+class CacheReadStepNode : public StepNode {
+ public:
+  /*! \brief The scope name of the newly added read stage. (e.g., local, shared, global) */
+  String scope_name;
+  /*! \brief The indices of read stages. */
+  Array<Integer> reader_stage_ids;
+
+  void WriteToRecord(dmlc::JSONWriter* writer) const final;
+
+  /*!
+   * \brief Apply the current step to State.
+   * \param state A mutable pointer to state, which will be updated.
+   * \param dag The original ComputeDAG of this state.
+   * \return The index of the new added stage.
+   */
+  int ApplyToState(State* state, const ComputeDAG& dag) const;
+
+  /*!
+   * \brief Apply the current step to tvm.schedule.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \param schedule A mutable pointer to a te::Schedule.
+   * \return The output Tensor of the new added stage.
+   */
+  te::Tensor ApplyToSchedule(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes,
+                             te::Schedule* schedule) const;
+
+  /*!
+   * \brief Print the current step as equivalent python schedule API.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \param schedule A mutable pointer to a te::Schedule.
+   * \return Python schedule code.
+   */
+  String PrintAsPythonAPI(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes,
+                          te::Schedule* schedule) const;
+
+  static constexpr const char* record_prefix_str = "CHR";
+
+  static constexpr const char* _type_key = "auto_scheduler.CacheReadStep";
+  TVM_DECLARE_FINAL_OBJECT_INFO(CacheReadStepNode, StepNode);
+};
+
+/*!
+ * \brief Managed reference to CacheReadStepNode.
+ * \sa CacheReadStepNode
+ */
+class CacheReadStep : public Step {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param stage_id The index of the stage to be cache_read.
+   * \param scope_name The scope name of the newly added stage.
+   * \param reader_stage_ids The indices of reader stages.
+   */
+  CacheReadStep(int stage_id, String scope_name, const Array<Integer>& reader_stage_ids);
+
+  /*!
+   * \brief The constructor used to read a step record from JSONReader and create the
+   * corresponding step.
+   * \param reader The input JSONReader.
+   */
+  explicit CacheReadStep(dmlc::JSONReader* reader);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(CacheReadStep, Step, CacheReadStepNode);
+};
+
+/*!
+ * \brief Cache write step that corresponds to te::Schedule::cache_write.
+ * \note Cache write step will add an extra stage to the original ComputeDAG, a up-to-date
+ * ComputeDAG is stored in State's `current_compute_dag`.
+ * This step will cache write all output tensors of the target stage.
+ */
+class CacheWriteStepNode : public StepNode {
+ public:
+  /*! \brief The scope name of the newly added compute stage. (e.g. local, shared, global) */
+  String scope_name;
+
+  void WriteToRecord(dmlc::JSONWriter* writer) const final;
+
+  /*!
+   * \brief Apply the current step to State.
+   * \param state A mutable pointer to state, which will be updated.
+   * \param dag The original ComputeDAG of this state.
+   * \return The index of the new added stage.
+   */
+  int ApplyToState(State* state, const ComputeDAG& dag) const;
+
+  /*!
+   * \brief Apply the current step to tvm.schedule.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \param schedule A mutable pointer to a te::Schedule.
+   * \return The output Tensors of the new added stage.
+   */
+  Array<te::Tensor> ApplyToSchedule(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes,
+                                    te::Schedule* schedule) const;
+
+  /*!
+   * \brief Print the current step as equivalent python schedule API.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \param schedule A mutable pointer to a te::Schedule.
+   * \return Python schedule code.
+   */
+  String PrintAsPythonAPI(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes,
+                          te::Schedule* schedule) const;
+
+  static constexpr const char* record_prefix_str = "CHW";
+
+  static constexpr const char* _type_key = "auto_scheduler.CacheWriteStep";
+  TVM_DECLARE_FINAL_OBJECT_INFO(CacheWriteStepNode, StepNode);
+};
+
+/*!
+ * \brief Managed reference to CacheWriteStepNode.
+ * \sa CacheWriteStepNode
+ */
+class CacheWriteStep : public Step {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param stage_id The index of the stage to be cache_write.
+   * \param scope_name The scope name of the newly added stage.
+   */
+  CacheWriteStep(int stage_id, String scope_name);
+
+  /*!
+   * \brief The constructor used to read a step record from JSONReader and create the
+   * corresponding step.
+   * \param reader The input JSONReader.
+   */
+  explicit CacheWriteStep(dmlc::JSONReader* reader);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(CacheWriteStep, Step, CacheWriteStepNode);
+};
+
+/*! \brief Reduction factor step that corresponds to te::Schedule::rfactor */
+class RfactorStepNode : public StepNode {
+ public:
+  /*! \brief The index of the iterator to be factored. */
+  int iter_id;
+  /*! \brief The position where the new iterator is placed. */
+  int factor_iter_id;
+
+  void WriteToRecord(dmlc::JSONWriter* writer) const final;
+
+  /*!
+   * \brief Apply the current step to State.
+   * \param state A mutable pointer to State, which will be updated.
+   * \param dag The original ComputeDAG of this state.
+   * \return The index of the new added stage.
+   */
+  int ApplyToState(State* state, const ComputeDAG& dag) const;
+
+  /*!
+   * \brief Apply the current step to tvm.schedule.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \param schedule A mutable pointer to a te::Schedule.
+   * \return The output Tensors of the new added stage.
+   */
+  Array<te::Tensor> ApplyToSchedule(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes,
+                                    te::Schedule* schedule) const;
+
+  /*!
+   * \brief Print the current step as equivalent python schedule API.
+   * \param stages The list of current stages
+   * \param stage_to_axes A map that maps stage ot all its iterators.
+   * \param schedule A mutable pointer to a te::Schedule.
+   * \return Python schedule code.
+   */
+  String PrintAsPythonAPI(Array<te::Stage>* stages, StageToAxesMap* stage_to_axes,
+                          te::Schedule* schedule) const;
+
+  static constexpr const char* record_prefix_str = "RF";
+
+  static constexpr const char* _type_key = "auto_scheduler.RfactorStep";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RfactorStepNode, StepNode);
+};
+
+/*!
+ * \brief Managed reference to RfactorStepNode.
+ * \sa RfactorStepNode
+ */
+class RfactorStep : public Step {
+ public:
+  /*!
+   * \brief The constructor.
+   * \param stage_id The index of the stage to be factored.
+   * \param iter_id The index of the iterator to be factored.
+   * \param factor_iter_id The position where the new iterator is placed.
+   */
+  RfactorStep(int stage_id, int iter_id, int factor_iter_id);
+
+  /*!
+   * \brief The constructor used to read a step record from JSONReader and create the
+   * corresponding step.
+   * \param reader The input JSONReader.
+   */
+  explicit RfactorStep(dmlc::JSONReader* reader);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(RfactorStep, Step, RfactorStepNode);
+};
+
+}  // namespace auto_scheduler
+}  // namespace tvm
+
+#endif  // TVM_AUTO_SCHEDULER_TRANSFORM_STEP_H_
diff --git a/darknet_drp_ros/include/tvm/driver/driver_api.h b/darknet_drp_ros/include/tvm/driver/driver_api.h
new file mode 100644
index 0000000..fffcab4
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/driver/driver_api.h
@@ -0,0 +1,176 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/driver/driver_api.h
+ * \brief Compiler driver APIs to drive the compilation.
+ *
+ * This module provides end-to-end utils to drive the compilation process.
+ * We adopt the term "compiler driver" in common compiler infrastructures.
+ * Note that a compiler driver is different from "runtime drivers".
+ * Most of runtime related code are defined in the runtime folder instead.
+ */
+#ifndef TVM_DRIVER_DRIVER_API_H_
+#define TVM_DRIVER_DRIVER_API_H_
+
+#include <tvm/ir/global_var_supply.h>
+#include <tvm/ir/module.h>
+#include <tvm/ir/transform.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/support/with.h>
+#include <tvm/target/target.h>
+#include <tvm/te/schedule_pass.h>
+#include <tvm/tir/function.h>
+
+#include <string>
+#include <unordered_map>
+#include <unordered_set>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+using tvm::transform::Pass;
+
+/*!
+ * \brief Configures and returns the composite Pass for the fused module (pre split) that contains
+ * device and host code.
+ * \param mixed_mod The original mixed module.
+ * \param target The device Target.
+ * \return The composite Pass for the fused module.
+//  */
+TVM_DLL transform::Sequential MixedModulePassManager(IRModule mixed_mod, Target target);
+
+/*!
+ * \brief Configures and returns the composite Pass for the device Target after device/host from
+ * mixed module.
+ * \param mixed_mod The optimized mixed module.
+ * \param target The device Target.
+ * \return The composite Pass for the device module.
+ */
+TVM_DLL transform::Sequential DeviceModulePassManager(IRModule mixed_mod, Target target);
+
+/*!
+ * \brief Configures and returns the composite Pass for the host Target after device/host from mixed
+ * module.
+ * \param mixed_mod The optimized mixed module.
+ * \param target_host The host Target.
+ * \return The composite Pass for the host module.
+ */
+TVM_DLL transform::Sequential HostModulePassManager(IRModule mixed_mod, Target target_host);
+
+/*!
+ * \brief Lower an IRModule (optimize with it with the pass list defined in CreatePassList)
+ * \param mod The IRmodule to lower
+ * \param simple_mode Disables the loop partition pass. Defaults to false.
+ * \return The result module.
+ */
+TVM_DLL IRModule LowerModule(IRModule mod, bool simple_mode = false);
+
+/*!
+ * \brief Lower a primfunc and name (convert to IRModule, and optimize it with the pass list
+ * defined in CreatePassList)
+ * \param func The PrimFunc to lower
+ * \param name The name of the lowered function.
+ * \param simple_mode Disables the loop partition pass. Defaults to false.
+ * \return The result module.
+ */
+TVM_DLL IRModule LowerPrimFunc(tvm::tir::PrimFunc func, const std::string& name,
+                               bool simple_mode = false);
+
+/*!
+ * \brief Build an IRModule given a TE schedule, args and binds. This function also applies
+ * the lowering passes defined in CreatePassList.
+ * \param sch The TE schedule to lower.
+ * \param args The arguments to the function.
+ * \param name The name of the lowered function.
+ * \param binds Buffer assignments.
+ * \param global_var_supply The GlobalVarSupply to be used in the module.
+ * \param simple_mode Disables the loop partition pass. Defaults to false.
+ * \return The result module.
+ */
+
+TVM_DLL IRModule LowerSchedule(te::Schedule sch, const Array<te::Tensor>& args,
+                               const std::string& name,
+                               const std::unordered_map<te::Tensor, tir::Buffer>& binds,
+                               GlobalVarSupply global_var_supply, bool simple_mode = false);
+
+/*!
+ * \brief Build an IRModule given a TE schedule, args and binds. This function also applies
+ * the lowering passes defined in CreatePassList.
+ * \param sch The TE schedule to lower.
+ * \param args The arguments to the function (Array of Tensor, Buffer and Vars)
+ * \param name The name of the lowered function.
+ * \param binds Buffer assignments.
+ * \param global_var_supply The GlobalVarSupply to be used in the module.
+ * \param simple_mode Disables the loop partition pass. Defaults to false.
+ * \return The result module.
+ */
+TVM_DLL IRModule LowerSchedule(te::Schedule sch, const Array<ObjectRef>& args,
+                               const std::string& name,
+                               const std::unordered_map<te::Tensor, tir::Buffer>& binds,
+                               GlobalVarSupply global_var_supply, bool simple_mode = false);
+
+/*!
+ * \brief Create an IRModule out of a TE Schedule. It does not apply lowering passes. If you want
+ * to apply lowering passes as well, use LowerSchedule.
+ * \param sch The schedule
+ * \param args The arguments to the function.
+ * \param name The name of the lowered function.
+ * \param binds Buffer assignments.
+ * \param global_var_supply The GlobalVarSupply to be used in the module and when creating
+ * GlobalVars.
+ * \return The result module.
+ */
+IRModule ScheduleToModule(te::Schedule sch, const Array<ObjectRef>& args, const std::string& name,
+                          const std::unordered_map<te::Tensor, tir::Buffer>& binds,
+                          GlobalVarSupply global_var_supply);
+/*!
+ * \brief Build a device and host module for a specific target from an IRModule.
+ * \param funcs The functions to be built.
+ * \param target The target device to build for.
+ * \param target_host The target for building host code. To use the default, pass Target()
+ * \return The built module.
+ */
+TVM_DLL runtime::Module build(const IRModule& funcs, const Target& target,
+                              const Target& target_host);
+
+/*!
+ * \brief Build a device and host module for a specific target from a map
+ * contains target to IRModule. This function is used
+ * for heterogeneous build.
+ * \param input The map contains target to an IRModule.
+ * \param target_host The target for building host code. To use the default,
+ *        pass Target().
+ * \return The built module that contains code for different processors.
+ */
+TVM_DLL runtime::Module build(const Map<Target, IRModule>& input, const Target& target_host);
+
+/*!
+ * \brief Build a device and host module for a specific target from a map
+ * contains target to IRModule. This function is used
+ * for heterogeneous build.
+ * \param input The map contains target string to an  IRModule.
+ * \param target_host The target for building host code. To use the default,
+ *        pass Target().
+ * \return The built module that contains code for different processors.
+ */
+TVM_DLL runtime::Module build(const Map<String, IRModule>& input, const Target& target_host);
+}  // namespace tvm
+
+#endif  // TVM_DRIVER_DRIVER_API_H_
diff --git a/darknet_drp_ros/include/tvm/ir/adt.h b/darknet_drp_ros/include/tvm/ir/adt.h
new file mode 100644
index 0000000..50e9bcb
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/adt.h
@@ -0,0 +1,163 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/ir/adt.h
+ * \brief Algebraic data type definitions.
+ *
+ * We adopt relay's ADT definition as a unified class
+ * for decripting structured data.
+ */
+#ifndef TVM_IR_ADT_H_
+#define TVM_IR_ADT_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/ir/type.h>
+#include <tvm/node/node.h>
+#include <tvm/runtime/container/adt.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/runtime/object.h>
+
+#include <string>
+
+namespace tvm {
+
+/*!
+ * \brief ADT constructor.
+ * Constructors compare by pointer equality.
+ * \sa Constructor
+ */
+class ConstructorNode : public RelayExprNode {
+ public:
+  /*! \brief The name (only a hint) */
+  String name_hint;
+  /*! \brief Input to the constructor. */
+  Array<Type> inputs;
+  /*! \brief The datatype the constructor will construct. */
+  GlobalTypeVar belong_to;
+  /*! \brief Index in the table of constructors (set when the type is registered). */
+  mutable int32_t tag = -1;
+
+  ConstructorNode() {}
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("name_hint", &name_hint);
+    v->Visit("inputs", &inputs);
+    v->Visit("belong_to", &belong_to);
+    v->Visit("tag", &tag);
+    v->Visit("span", &span);
+    v->Visit("_checked_type_", &checked_type_);
+  }
+
+  bool SEqualReduce(const ConstructorNode* other, SEqualReducer equal) const {
+    // Use namehint for now to be consistent with the legacy relay impl
+    // TODO(tvm-team) revisit, need to check the type var.
+    return equal(name_hint, other->name_hint) && equal(inputs, other->inputs);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(name_hint);
+    hash_reduce(inputs);
+  }
+
+  static constexpr const char* _type_key = "relay.Constructor";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ConstructorNode, RelayExprNode);
+};
+
+/*!
+ * \brief Managed reference to ConstructorNode
+ * \sa ConstructorNode
+ */
+class Constructor : public RelayExpr {
+ public:
+  /*!
+   * \brief Constructor
+   * \param name_hint the name of the constructor.
+   * \param inputs The input types.
+   * \param belong_to The data type var the constructor will construct.
+   */
+  TVM_DLL Constructor(String name_hint, Array<Type> inputs, GlobalTypeVar belong_to);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Constructor, RelayExpr, ConstructorNode);
+};
+
+/*! \brief TypeData container node */
+class TypeDataNode : public TypeNode {
+ public:
+  /*!
+   * \brief The header is simply the name of the ADT.
+   * We adopt nominal typing for ADT definitions;
+   * that is, differently-named ADT definitions with same constructors
+   * have different types.
+   */
+  GlobalTypeVar header;
+  /*! \brief The type variables (to allow for polymorphism). */
+  Array<TypeVar> type_vars;
+  /*! \brief The constructors. */
+  Array<Constructor> constructors;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("header", &header);
+    v->Visit("type_vars", &type_vars);
+    v->Visit("constructors", &constructors);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const TypeDataNode* other, SEqualReducer equal) const {
+    return equal.DefEqual(header, other->header) && equal.DefEqual(type_vars, other->type_vars) &&
+           equal(constructors, other->constructors);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce.DefHash(header);
+    hash_reduce.DefHash(type_vars);
+    hash_reduce(constructors);
+  }
+
+  static constexpr const char* _type_key = "relay.TypeData";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TypeDataNode, TypeNode);
+};
+
+/*!
+ * \brief Stores all data for an Algebraic Data Type (ADT).
+ *
+ * In particular, it stores the handle (global type var) for an ADT
+ * and the constructors used to build it and is kept in the module. Note
+ * that type parameters are also indicated in the type data: this means that
+ * for any instance of an ADT, the type parameters must be indicated. That is,
+ * an ADT definition is treated as a type-level function, so an ADT handle
+ * must be wrapped in a TypeCall node that instantiates the type-level arguments.
+ * The kind checker enforces this.
+ */
+class TypeData : public Type {
+ public:
+  /*!
+   * \brief Constructor
+   * \param header the name of ADT.
+   * \param type_vars type variables.
+   * \param constructors constructors field.
+   */
+  TVM_DLL TypeData(GlobalTypeVar header, Array<TypeVar> type_vars, Array<Constructor> constructors);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(TypeData, Type, TypeDataNode);
+};
+
+}  // namespace tvm
+#endif  // TVM_IR_ADT_H_
diff --git a/darknet_drp_ros/include/tvm/ir/affine_type.h b/darknet_drp_ros/include/tvm/ir/affine_type.h
new file mode 100644
index 0000000..5726e9e
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/affine_type.h
@@ -0,0 +1,150 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/ir/affine_type.h
+ * \brief Quantized Tensor Types.
+ */
+#ifndef TVM_IR_AFFINE_TYPE_H_
+#define TVM_IR_AFFINE_TYPE_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/ir/type.h>
+
+namespace tvm {
+
+/*!
+ * \brief AffineType representation
+ * \sa AffineType
+ */
+class AffineTypeNode : public Object {
+ public:
+  /*!
+   * \brief Span that points to the original source code.
+   *        Reserved debug information.
+   */
+  mutable Span span;
+
+  static constexpr const char* _type_key = "AffineType";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_BASE_OBJECT_INFO(AffineTypeNode, Object);
+};
+
+/*!
+ * \brief Managed reference to AffineTypeNode.
+ * \sa AffineTypeNode
+ */
+class AffineType : public ObjectRef {
+ public:
+  TVM_DEFINE_OBJECT_REF_METHODS(AffineType, ObjectRef, AffineTypeNode);
+};
+
+/*!
+ * \brief TensorAffineType representation
+ * \sa TensorAffineType
+ *
+ *  This Type represents a quantized integer tensor that can be converted
+ *  back to real space via the x_real = scale * (x_quant - zero_point)
+ */
+class TensorAffineTypeNode : public AffineTypeNode {
+ public:
+  /*! \brief The scale of this type */
+  RelayExpr scale;
+  /*! \brief The zero point of this type */
+  RelayExpr zero_point;
+  /*! \brief The data type of this type */
+  DataType dtype;
+  /*! \brief The axis for per-channel quantization */
+  int axis;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("scale", &scale);
+    v->Visit("zero_point", &zero_point);
+    v->Visit("dtype", &dtype);
+    v->Visit("axis", &axis);
+  }
+
+  bool SEqualReduce(const TensorAffineTypeNode* other, SEqualReducer equal) const {
+    equal->MarkGraphNode();
+    return equal(scale, other->scale) && equal(zero_point, other->zero_point) &&
+           equal(dtype, other->dtype) && equal(axis, other->axis);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce->MarkGraphNode();
+    hash_reduce(scale);
+    hash_reduce(zero_point);
+    hash_reduce(dtype);
+    hash_reduce(axis);
+  }
+
+  static constexpr const char* _type_key = "TensorAffineType";
+  TVM_DECLARE_BASE_OBJECT_INFO(TensorAffineTypeNode, AffineTypeNode);
+};
+
+/*!
+ * \brief Managed reference to AffineTypes.
+ * \sa AffineTypeNode
+ */
+class TensorAffineType : public AffineType {
+ public:
+  TVM_DLL TensorAffineType(RelayExpr scale, RelayExpr zero_point, DataType dtype, int axis);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(TensorAffineType, AffineType, TensorAffineTypeNode);
+};
+
+/*!
+ * \brief TupleAffineType representation
+ * \sa TupleAffineType
+ */
+class TupleAffineTypeNode : public AffineTypeNode {
+ public:
+  /*! \brief The types of this tuple*/
+  Array<TensorAffineType> types;
+
+  void VisitAttrs(tvm::AttrVisitor* v) { v->Visit("types", &types); }
+
+  bool SEqualReduce(const TupleAffineTypeNode* other, SEqualReducer equal) const {
+    equal->MarkGraphNode();
+    return equal(types, other->types);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce->MarkGraphNode();
+    hash_reduce(types);
+  }
+
+  static constexpr const char* _type_key = "TupleAffineType";
+  TVM_DECLARE_BASE_OBJECT_INFO(TupleAffineTypeNode, AffineTypeNode);
+};
+
+/*!
+ * \brief Managed reference to TupleAffineTypes.
+ * \sa TupleAffineType
+ */
+class TupleAffineType : public AffineType {
+ public:
+  TVM_DLL TupleAffineType(Array<TensorAffineType> types);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(TupleAffineType, AffineType, TupleAffineTypeNode);
+};
+
+}  // namespace tvm
+#endif  // TVM_IR_AFFINE_TYPE_H_
diff --git a/darknet_drp_ros/include/tvm/ir/attrs.h b/darknet_drp_ros/include/tvm/ir/attrs.h
new file mode 100644
index 0000000..35afed7
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/attrs.h
@@ -0,0 +1,945 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+/*!
+ * \file tvm/ir/attrs.h
+ * \brief Helpers for attribute objects.
+ *
+ *  This module enables declaration of named attributes
+ *  which support default value setup and bound checking.
+ *
+ * \code
+ *   struct MyAttrs : public tvm::AttrsNode<MyAttrs> {
+ *     float learning_rate;
+ *     int num_hidden;
+ *     String name;
+ *     // declare attribute fields in header file
+ *     TVM_DECLARE_ATTRS(MyAttrs, "attrs.MyAttrs") {
+ *       TVM_ATTR_FIELD(num_hidden).set_lower_bound(1);
+ *       TVM_ATTR_FIELD(learning_rate).set_default(0.01f);
+ *       TVM_ATTR_FIELD(name).set_default("hello");
+ *     }
+ *   };
+ *   // register it in cc file
+ *   TVM_REGISTER_NODE_TYPE(MyAttrs);
+ * \endcode
+ *
+ * \sa AttrsNode, TVM_DECLARE_ATTRS, TVM_ATTR_FIELD
+ */
+#ifndef TVM_IR_ATTRS_H_
+#define TVM_IR_ATTRS_H_
+
+#include <dmlc/common.h>
+#include <tvm/ir/expr.h>
+#include <tvm/node/structural_equal.h>
+#include <tvm/node/structural_hash.h>
+#include <tvm/runtime/packed_func.h>
+
+#include <functional>
+#include <string>
+#include <type_traits>
+#include <unordered_map>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+/*!
+ * \brief Declare an attribute function.
+ * \param ClassName The name of the class.
+ * \param TypeKey The type key to be used by the TVM node system.
+ */
+#define TVM_DECLARE_ATTRS(ClassName, TypeKey)                    \
+  static constexpr const char* _type_key = TypeKey;              \
+  TVM_DECLARE_FINAL_OBJECT_INFO(ClassName, ::tvm::BaseAttrsNode) \
+  template <typename FVisit>                                     \
+  void _tvm_VisitAttrs(FVisit& _tvm_fvisit)  // NOLINT(*)
+
+/*!
+ * \brief Declare an attribute field.
+ * \param FieldName The field name.
+ */
+#define TVM_ATTR_FIELD(FieldName) _tvm_fvisit(#FieldName, &FieldName)
+
+/*!
+ * \brief Create a NodeRef type that represents null.
+ * \tparam TNodeRef the type to be created.
+ * \return A instance that will represent None.
+ */
+template <typename TObjectRef>
+inline TObjectRef NullValue() {
+  static_assert(TObjectRef::_type_is_nullable, "Can only get NullValue for nullable types");
+  return TObjectRef(ObjectPtr<Object>(nullptr));
+}
+
+template <>
+inline DataType NullValue<DataType>() {
+  return DataType(DataType::kHandle, 0, 0);
+}
+
+/*! \brief Error thrown during attribute checking. */
+struct AttrError : public Error {
+  /*!
+   * \brief constructor
+   * \param msg error message
+   */
+  explicit AttrError(std::string msg) : Error("AttributeError:" + msg) {}
+};
+
+/*!
+ * \brief Information about attribute fields in string representations.
+ */
+class AttrFieldInfoNode : public Object {
+ public:
+  /*! \brief name of the field */
+  String name;
+  /*! \brief type docstring information in str. */
+  String type_info;
+  /*! \brief detailed description of the type */
+  String description;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("name", &name);
+    v->Visit("type_info", &type_info);
+    v->Visit("description", &description);
+  }
+
+  static constexpr const char* _type_key = "AttrFieldInfo";
+  static constexpr bool _type_has_method_sequal_reduce = false;
+  static constexpr bool _type_has_method_shash_reduce = false;
+  TVM_DECLARE_FINAL_OBJECT_INFO(AttrFieldInfoNode, Object);
+};
+
+/*! \brief AttrFieldInfo */
+class AttrFieldInfo : public ObjectRef {
+ public:
+  TVM_DEFINE_OBJECT_REF_METHODS(AttrFieldInfo, ObjectRef, AttrFieldInfoNode);
+};
+
+/*!
+ * \brief Base class of all attribute class
+ * \note Do not subclass AttrBaseNode directly,
+ *       subclass AttrsNode instead.
+ * \sa AttrsNode
+ */
+class BaseAttrsNode : public Object {
+ public:
+  using TVMArgs = runtime::TVMArgs;
+  using TVMRetValue = runtime::TVMRetValue;
+  /*! \brief virtual destructor */
+  virtual ~BaseAttrsNode() {}
+  // visit function
+  virtual void VisitAttrs(AttrVisitor* v) {}
+  /*!
+   * \brief Initialize the attributes by sequence of arguments
+   * \param args The positional arguments in the form
+   *        [key0, value0, key1, value1, ..., key_n, value_n]
+   */
+  template <typename... Args>
+  inline void InitBySeq(Args&&... args);
+  /*!
+   * \brief Print readible docstring to ostream, add newline.
+   * \param os the stream to print the docstring to.
+   */
+  inline void PrintDocString(std::ostream& os) const;  // NOLINT(*)
+  /*!
+   * \brief Visit attributes that do not equal the default value.
+   *
+   * \note This is useful to extract fields for concise printing.
+   * \param v The visitor
+   */
+  TVM_DLL virtual void VisitNonDefaultAttrs(AttrVisitor* v) = 0;
+  /*!
+   * \brief Get the field information
+   * \return The fields in the Attrs.
+   */
+  TVM_DLL virtual Array<AttrFieldInfo> ListFieldInfo() const = 0;
+  /*!
+   * \brief Initialize the attributes by arguments.
+   * \param kwargs The key value pairs for initialization.
+   *        [key0, value0, key1, value1, ..., key_n, value_n]
+   * \param allow_unknown Whether allow additional unknown fields.
+   * \note This function throws when the required field is not present.
+   */
+  TVM_DLL virtual void InitByPackedArgs(const TVMArgs& kwargs, bool allow_unknown = false) = 0;
+
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  static constexpr const char* _type_key = "Attrs";
+  TVM_DECLARE_BASE_OBJECT_INFO(BaseAttrsNode, Object);
+};
+
+/*!
+ * \brief Managed reference to BaseAttrsNode.
+ * \sa AttrsNode, BaseAttrsNode
+ */
+class Attrs : public ObjectRef {
+ public:
+  TVM_DEFINE_OBJECT_REF_METHODS(Attrs, ObjectRef, BaseAttrsNode);
+};
+
+/*!
+ * \brief Specialized attribute type that is backed by a map.
+ *  The DictAttrsNode implements the Attrs behavior,
+ *  its fields are directly accessible via object.field_name
+ *  like other normal nodes.
+ */
+class DictAttrsNode : public BaseAttrsNode {
+ public:
+  /*! \brief internal attrs map */
+  Map<String, ObjectRef> dict;
+
+  bool SEqualReduce(const DictAttrsNode* other, SEqualReducer equal) const {
+    return equal(dict, other->dict);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const { hash_reduce(dict); }
+
+  // implementations
+  void VisitAttrs(AttrVisitor* v) final;
+  void VisitNonDefaultAttrs(AttrVisitor* v) final;
+  void InitByPackedArgs(const runtime::TVMArgs& args, bool allow_unknown) final;
+  Array<AttrFieldInfo> ListFieldInfo() const final;
+
+  // type info
+  static constexpr const char* _type_key = "DictAttrs";
+  TVM_DECLARE_FINAL_OBJECT_INFO(DictAttrsNode, BaseAttrsNode);
+};
+
+/*!
+ * \brief Managed reference to DictAttrsNode
+ * \sa DictAttrsNode.
+ */
+class DictAttrs : public Attrs {
+ public:
+  /*!
+   * \brief Consruct a Attrs backed by DictAttrsNode.
+   * \param dict The attributes.
+   * \return The dict attributes.
+   */
+  TVM_DLL explicit DictAttrs(Map<String, ObjectRef> dict);
+
+  // Utils for accessing attributes
+  // This needs to be on DictAttrs, not DictAttrsNode because we return the default
+  // value if DictAttrsNode is not defined.
+  /*!
+   * \brief Get a function attribute.
+   *
+   * \param attr_key The attribute key.
+   * \param default_value The default value if the key does not exist, defaults to nullptr.
+   *
+   * \return The result
+   *
+   * \tparam TOBjectRef the expected object type.
+   * \throw Error if the key exists but the value does not match TObjectRef
+   *
+   * \code
+   *
+   *  void GetAttrExample(const BaseFunc& f) {
+   *    auto value = f->attrs.GetAttr<Integer>("AttrKey", 0);
+   *  }
+   *
+   * \endcode
+   */
+  template <typename TObjectRef>
+  Optional<TObjectRef> GetAttr(
+      const std::string& attr_key,
+      Optional<TObjectRef> default_value = Optional<TObjectRef>(nullptr)) const {
+    static_assert(std::is_base_of<ObjectRef, TObjectRef>::value,
+                  "Can only call GetAttr with ObjectRef types.");
+    if (!defined()) return default_value;
+    const DictAttrsNode* node = this->as<DictAttrsNode>();
+
+    auto it = node->dict.find(attr_key);
+    if (it != node->dict.end()) {
+      return Downcast<Optional<TObjectRef>>((*it).second);
+    } else {
+      return default_value;
+    }
+  }
+  // variant that uses TObjectRef to enable implicit conversion to default value.
+  template <typename TObjectRef>
+  Optional<TObjectRef> GetAttr(const std::string& attr_key, TObjectRef default_value) const {
+    return GetAttr<TObjectRef>(attr_key, Optional<TObjectRef>(default_value));
+  }
+  /*!
+   * \brief Check whether the function has an non-zero integer attr.
+   *
+   * This function can be used to check whether an optional
+   * attribute mark(e.g. inline) exists.
+   *
+   * \param attr_key The key to the attribute.
+   * \return The check result.
+   *
+   * \code
+   *
+   *  void HasNonzeroAttrExample(const BaseFunc& f) {
+   *    if (f->HasNonzeroAttr(attr::kInline)) {
+   *      // inline the function.
+   *    }
+   *  }
+   *
+   * \endcode
+   */
+  bool HasNonzeroAttr(const std::string& attr_key) const {
+    return GetAttr<Integer>(attr_key, 0).value_or(0).IntValue() != 0;
+  }
+
+  TVM_DEFINE_OBJECT_REF_METHODS(DictAttrs, Attrs, DictAttrsNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(DictAttrsNode);
+};
+
+/*!
+ * \brief Create an Attr object with all default values.
+ * \tparam TAttrNode the type to be created.
+ * \return A instance that will represent None.
+ */
+template <typename TAttrs>
+inline TAttrs AttrsWithDefaultValues() {
+  static_assert(std::is_base_of<Attrs, TAttrs>::value, "Can only take attr nodes");
+  auto n = make_object<typename TAttrs::ContainerType>();
+  n->InitByPackedArgs(runtime::TVMArgs(nullptr, nullptr, 0), false);
+  return TAttrs(n);
+}
+
+/*!
+ * \brief Copy the function or module, but overrides
+ *        the attribute value key with the value.
+ *
+ * \param input The thing to annotate (BaseFunc or IRModule)
+ * \param attr_key The attribute key.
+ * \param attr_value The value attribute value.
+ *
+ * \tparam TFunc The corresponding function or module type.
+ *
+ * \returns The new function or module with updated attributes.
+ *
+ * \note This function performs copy on write optimization for func and module.
+ *       If we move a uniquely referenced func or module into WithAttr,
+ *       then no additional copy will be performed.
+ *
+ *       This is also why we make it as a function instead of a member function
+ *       and why we pass by value in the first argument.
+ *
+ * \code
+ *
+ *  // Recommended way to trigger copy on write
+ *  func = WithAttr(std::move(func), "key1", value1);
+ *  func = WithAttr(std::move(func), "key2", value2);
+ *
+ * \endcode
+ */
+template <typename TFunc>
+inline TFunc WithAttr(TFunc input, const std::string& attr_key, ObjectRef attr_value) {
+  using TNode = typename TFunc::ContainerType;
+  static_assert(TNode::_type_final, "Can only operate on the leaf nodes");
+  TNode* node = input.CopyOnWrite();
+  if (node->attrs.defined()) {
+    node->attrs.CopyOnWrite()->dict.Set(attr_key, attr_value);
+  } else {
+    Map<String, ObjectRef> dict = {{attr_key, attr_value}};
+    node->attrs = DictAttrs(dict);
+  }
+  return input;
+}
+
+/*!
+ * \brief Copy the function or module, but overrides the attributes with the entries from \p attrs.
+ *
+ * \param input The thing to annotate (BaseFunc or IRModule)
+ * \param attrs Key/values attributes to add to \p input.
+ *
+ * \tparam TFunc The corresponding function or module type.
+ *
+ * \returns The new function or module with updated attributes.
+ */
+template <typename TFunc>
+inline TFunc WithAttrs(TFunc input, Map<String, ObjectRef> attrs) {
+  using TNode = typename TFunc::ContainerType;
+  static_assert(TNode::_type_final, "Can only operate on the leaf nodes");
+  TNode* node = input.CopyOnWrite();
+  if (node->attrs.defined()) {
+    for (const auto& pair : attrs) {
+      node->attrs.CopyOnWrite()->dict.Set(pair.first, pair.second);
+    }
+  } else {
+    node->attrs = DictAttrs(std::move(attrs));
+  }
+  return input;
+}
+
+/*!
+ * \brief Copy the function or module, but removes the specified
+ *        attribute.
+ *
+ * \param input The thing to annotate (BaseFunc or IRModule)
+ * \param attr_key The attribute key.
+ *
+ * \tparam TFunc The corresponding function or module type.
+ *
+ * \returns The new function or module with removed attribute.
+ *
+ * \note This function performs copy on write optimization for func and module.
+ *       If we move a uniquely referenced func or module into WithoutAttr,
+ *       then no additional copy will be performed.
+ *
+ *       This is also why we make it as a function instead of a member function
+ *       and why we pass by value in the first argument.
+ *
+ * \code
+ *
+ *  // Recommended way to trigger copy on write
+ *  func = WithoutAttr(std::move(func), "key1");
+ *  func = WithoutAttr(std::move(func), "key2");
+ *
+ * \endcode
+ */
+template <typename TFunc>
+inline TFunc WithoutAttr(TFunc input, const std::string& attr_key) {
+  using TNode = typename TFunc::ContainerType;
+  static_assert(TNode::_type_final, "Can only operate on the leaf nodes");
+
+  if (input->attrs.defined()) {
+    TNode* node = input.CopyOnWrite();
+    node->attrs.CopyOnWrite()->dict.erase(attr_key);
+    if (node->attrs->dict.size() == 0) {
+      node->attrs = NullValue<DictAttrs>();
+    }
+  }
+  return input;
+}
+
+// Namespace containing detail implementations
+namespace detail {
+using runtime::TVMArgValue;
+
+// helper entry that does nothing in set_default/bound/describe calls.
+struct AttrNopEntry {
+  using TSelf = AttrNopEntry;
+
+  TSelf& describe(DMLC_ATTRIBUTE_UNUSED const char* str) { return *this; }
+  template <typename T>
+  TSelf& set_default(DMLC_ATTRIBUTE_UNUSED const T& value) {
+    return *this;
+  }
+  template <typename T>
+  TSelf& set_lower_bound(DMLC_ATTRIBUTE_UNUSED const T& begin) {
+    return *this;
+  }
+  template <typename T>
+  TSelf& set_upper_bound(DMLC_ATTRIBUTE_UNUSED const T& end) {
+    return *this;
+  }
+};
+
+// Wrapper for normal visitor.
+class AttrNormalVisitor {
+ public:
+  explicit AttrNormalVisitor(AttrVisitor* visitor) : visitor_(visitor) {}
+  template <typename T>
+  AttrNopEntry operator()(const char* key, T* value) {
+    visitor_->Visit(key, value);
+    return AttrNopEntry();
+  }
+
+ private:
+  AttrVisitor* visitor_;
+};
+
+class AttrsSEqualVisitor {
+ public:
+  bool result_{true};
+  // constructor
+  AttrsSEqualVisitor(const Object* lhs, const Object* rhs, const SEqualReducer& equal)
+      : lhs_(lhs), rhs_(rhs), equal_(equal) {}
+  template <typename T>
+  AttrNopEntry operator()(const char* key, T* lhs_value) {
+    if (!result_) return AttrNopEntry();
+    const T* rhs_value = reinterpret_cast<const T*>(
+        reinterpret_cast<const char*>(rhs_) +
+        (reinterpret_cast<const char*>(lhs_value) - reinterpret_cast<const char*>(lhs_)));
+    if (!equal_(*lhs_value, *rhs_value)) {
+      result_ = false;
+    }
+    return AttrNopEntry();
+  }
+
+ private:
+  const Object* lhs_;
+  const Object* rhs_;
+  const SEqualReducer& equal_;
+};
+
+class AttrsSHashVisitor {
+ public:
+  explicit AttrsSHashVisitor(const SHashReducer& hash_reducer) : hash_reducer_(hash_reducer) {}
+
+  template <typename T>
+  AttrNopEntry operator()(const char* key, T* value) {
+    hash_reducer_(*value);
+    return AttrNopEntry();
+  }
+
+ private:
+  const SHashReducer& hash_reducer_;
+};
+
+// helper entry that does initialization, set default.
+template <typename T>
+struct AttrInitEntry {
+  // The attributes
+  using TSelf = AttrInitEntry<T>;
+  // The type key
+  const char* type_key_;
+  // field name
+  const char* key_;
+  // internal value.
+  T* value_;
+  // whether the value is missing.
+  // NOTE: initialize to false so that the destructor does not throw unless
+  // AttrInitVisitor::operator() is committed to returning an instance of this class.
+  // It is expected not to set this to true until that is true.
+  bool value_missing_{false};
+
+  AttrInitEntry() = default;
+
+  AttrInitEntry(AttrInitEntry&& other) {
+    type_key_ = other.type_key_;
+    key_ = other.key_;
+    value_ = other.value_;
+    value_missing_ = other.value_missing_;
+    // avoid unexpected throw
+    other.value_missing_ = false;
+  }
+
+  // If the value is still missing in destruction time throw an error.
+  ~AttrInitEntry() DMLC_THROW_EXCEPTION {
+    if (value_missing_) {
+      std::ostringstream os;
+      os << type_key_ << ": Cannot find required field \'" << key_ << "\' during initialization. "
+         << "If the key is defined check that its type matches the declared type.";
+      throw AttrError(os.str());
+    }
+  }
+  // override fields.
+  // This function sets the lower bound of the attribute
+  TSelf& set_lower_bound(const T& begin) {
+    if (this->value_missing_) return *this;
+    const T& val = *value_;
+    if (begin > val) {
+      std::ostringstream os;
+      os << type_key_ << "." << key_ << ": "
+         << "value " << val << " is smaller than the lower bound " << begin;
+      throw AttrError(os.str());
+    }
+    return *this;
+  }
+  // This function sets the upper bound of the attribute
+  TSelf& set_upper_bound(const T& end) {
+    if (this->value_missing_) return *this;
+    const T& val = *value_;
+    if (val > end) {
+      std::ostringstream os;
+      os << type_key_ << "." << key_ << ": "
+         << "value " << val << " is bigger than the upper bound " << end;
+      throw AttrError(os.str());
+    }
+    return *this;
+  }
+  // set default when
+  TSelf& set_default(const T& value) {
+    if (!value_missing_) return *this;
+    *value_ = value;
+    value_missing_ = false;
+    return *this;
+  }
+  TSelf& describe(DMLC_ATTRIBUTE_UNUSED const char* str) { return *this; }
+};
+
+// Template function to allow smart conversion
+// from Expr types into the constants.
+template <typename T>
+inline void SetValue(T* ptr, const TVMArgValue& val) {
+  *ptr = val.operator T();
+}
+
+template <typename T>
+inline void SetIntValue(T* ptr, const TVMArgValue& val) {
+  if (val.type_code() == kDLInt) {
+    *ptr = static_cast<T>(val.value().v_int64);
+  } else {
+    IntImm expr = val;
+    *ptr = static_cast<T>(expr->value);
+  }
+}
+
+// Workaround for GCC8.1 / GCC8.2
+template <>
+inline void SetValue<DataType>(DataType* ptr, const TVMArgValue& val) {
+  *ptr = val.operator DataType();
+}
+
+template <>
+inline void SetValue<std::string>(std::string* ptr, const TVMArgValue& val) {
+  if (String::CanConvertFrom(val)) {
+    *ptr = val.operator std::string();
+  } else {
+    LOG(FATAL) << "Expect str";
+  }
+}
+
+template <>
+inline void SetValue<double>(double* ptr, const TVMArgValue& val) {
+  if (val.type_code() == kDLFloat || val.type_code() == kDLInt) {
+    *ptr = val.operator double();
+  } else {
+    ObjectRef expr = val;
+    ICHECK(expr.defined());
+    if (const IntImmNode* op = expr.as<IntImmNode>()) {
+      *ptr = static_cast<double>(op->value);
+    } else if (const FloatImmNode* op = expr.as<FloatImmNode>()) {
+      *ptr = static_cast<double>(op->value);
+    } else {
+      LOG(FATAL) << "Expect float value, but get " << expr->GetTypeKey();
+    }
+  }
+}
+template <>
+inline void SetValue<int>(int* ptr, const TVMArgValue& val) {
+  SetIntValue(ptr, val);
+}
+template <>
+inline void SetValue<int64_t>(int64_t* ptr, const TVMArgValue& val) {
+  SetIntValue(ptr, val);
+}
+template <>
+inline void SetValue<uint64_t>(uint64_t* ptr, const TVMArgValue& val) {
+  SetIntValue(ptr, val);
+}
+template <>
+inline void SetValue<bool>(bool* ptr, const TVMArgValue& val) {
+  SetIntValue(ptr, val);
+}
+
+// Visitor for value initialization
+template <typename FFind>
+class AttrInitVisitor {
+ public:
+  // Counter of number of matched attributes during visit.
+  // This is used to decide if there is additional unmatched attributes.
+  size_t hit_count_{0};
+  // constructor
+  AttrInitVisitor(const char* type_key, FFind ffind) : type_key_(type_key), ffind_(ffind) {}
+
+  template <typename T>
+  AttrInitEntry<T> operator()(const char* key, T* value) {
+    TVMArgValue val;
+    AttrInitEntry<T> opt;
+    opt.type_key_ = type_key_;
+    opt.key_ = key;
+    opt.value_ = value;
+    if (ffind_(key, &val)) {
+      SetValue(value, val);
+      opt.value_missing_ = false;
+      ++hit_count_;
+    } else {
+      opt.value_missing_ = true;
+    }
+#if defined(__GNUC__)
+#pragma GCC diagnostic ignored "-Wpragmas"
+#pragma GCC diagnostic ignored "-Wpessimizing-move"
+#endif
+    return std::move(opt);
+  }
+
+ private:
+  // the type key
+  const char* type_key_;
+  FFind ffind_;
+};
+
+template <typename FFind>
+inline AttrInitVisitor<FFind> CreateInitVisitor(const char* type_key, FFind ffind) {
+  return AttrInitVisitor<FFind>(type_key, ffind);
+}
+
+/*!
+ * \brief Helper struct to get the type name known to tvm.
+ * \tparam T the type we are interested in.
+ */
+template <typename T>
+struct TypeName {
+  static constexpr const char* value = T::ContainerType::_type_key;
+};
+
+template <>
+struct TypeName<int> {
+  static constexpr const char* value = "int";
+};
+
+template <>
+struct TypeName<int64_t> {
+  static constexpr const char* value = "int64";
+};
+
+template <>
+struct TypeName<uint64_t> {
+  static constexpr const char* value = "uint64_t";
+};
+
+template <>
+struct TypeName<DataType> {
+  static constexpr const char* value = "DataType";
+};
+
+template <>
+struct TypeName<std::string> {
+  static constexpr const char* value = "str";
+};
+
+template <>
+struct TypeName<bool> {
+  static constexpr const char* value = "bool";
+};
+
+template <>
+struct TypeName<void*> {
+  static constexpr const char* value = "handle";
+};
+
+template <>
+struct TypeName<double> {
+  static constexpr const char* value = "double";
+};
+
+class AttrDocEntry {
+ public:
+  using TSelf = AttrDocEntry;
+
+  explicit AttrDocEntry(ObjectPtr<AttrFieldInfoNode> info) : info_(info) {}
+  TSelf& describe(const char* str) {
+    info_->description = str;
+    return *this;
+  }
+  template <typename T>
+  TSelf& set_default(const T& value) {
+    std::ostringstream os;
+    os << info_->type_info << ", default=" << value;
+    info_->type_info = os.str();
+    return *this;
+  }
+  template <typename T>
+  TSelf& set_lower_bound(DMLC_ATTRIBUTE_UNUSED T begin) {
+    return *this;
+  }
+  template <typename T>
+  TSelf& set_upper_bound(DMLC_ATTRIBUTE_UNUSED T end) {
+    return *this;
+  }
+
+ private:
+  ObjectPtr<AttrFieldInfoNode> info_;
+};
+
+class AttrDocVisitor {
+ public:
+  template <typename T>
+  AttrDocEntry operator()(const char* key, T* v) {
+    ObjectPtr<AttrFieldInfoNode> info = make_object<AttrFieldInfoNode>();
+    info->name = key;
+    info->type_info = TypeName<T>::value;
+    fields_.push_back(AttrFieldInfo(info));
+    return AttrDocEntry(info);
+  }
+
+  Array<AttrFieldInfo> fields_;
+};
+
+class AttrExistVisitor {
+ public:
+  std::string key_;
+  bool exist_{false};
+
+  template <typename T>
+  AttrNopEntry operator()(const char* key, T* v) {
+    if (exist_) return AttrNopEntry();
+    if (key == key_) exist_ = true;
+    return AttrNopEntry();
+  }
+};
+
+template <typename T>
+struct AttrTriggerNonDefaultEntry {
+  using TSelf = AttrTriggerNonDefaultEntry<T>;
+  // constructor
+  AttrTriggerNonDefaultEntry(AttrVisitor* visitor, const char* key, T* data)
+      : visitor_(visitor), key_(key), data_(data) {}
+
+  ~AttrTriggerNonDefaultEntry() DMLC_THROW_EXCEPTION {
+    if (trigger_) {
+      visitor_->Visit(key_, data_);
+    }
+  }
+  TSelf& describe(DMLC_ATTRIBUTE_UNUSED const char* str) { return *this; }
+  TSelf& set_default(const T& value) {
+    if (tvm::StructuralEqual()(value, *data_)) {
+      trigger_ = false;
+    }
+    return *this;
+  }
+  TSelf& set_lower_bound(DMLC_ATTRIBUTE_UNUSED const T& begin) { return *this; }
+  TSelf& set_upper_bound(DMLC_ATTRIBUTE_UNUSED const T& end) { return *this; }
+
+ private:
+  AttrVisitor* visitor_;
+  const char* key_;
+  T* data_;
+  bool trigger_{true};
+};
+
+class AttrNonDefaultVisitor {
+ public:
+  explicit AttrNonDefaultVisitor(AttrVisitor* visitor) : visitor_(visitor) {}
+  template <typename T>
+  AttrTriggerNonDefaultEntry<T> operator()(const char* key, T* value) {
+    return AttrTriggerNonDefaultEntry<T>(visitor_, key, value);
+  }
+
+ private:
+  AttrVisitor* visitor_;
+};
+}  // namespace detail
+
+/*!
+ * \brief The base class of the all the
+ *  Use "curiously recurring template pattern".
+ *
+ * \tparam DerivedType The final attribute type.
+ */
+template <typename DerivedType>
+class AttrsNode : public BaseAttrsNode {
+ public:
+  void VisitAttrs(AttrVisitor* v) {
+    ::tvm::detail::AttrNormalVisitor vis(v);
+    self()->_tvm_VisitAttrs(vis);
+  }
+
+  void VisitNonDefaultAttrs(AttrVisitor* v) {
+    ::tvm::detail::AttrNonDefaultVisitor vis(v);
+    self()->_tvm_VisitAttrs(vis);
+  }
+
+  void InitByPackedArgs(const runtime::TVMArgs& args, bool allow_unknown) final {
+    ICHECK_EQ(args.size() % 2, 0);
+    const int kLinearSearchBound = 16;
+    int hit_count = 0;
+    // applies two strategies to lookup
+    if (args.size() < kLinearSearchBound) {
+      // linear search.
+      auto ffind = [&args](const char* key, runtime::TVMArgValue* val) {
+        for (int i = 0; i < args.size(); i += 2) {
+          ICHECK_EQ(args.type_codes[i], kTVMStr);
+          if (!std::strcmp(key, args.values[i].v_str)) {
+            *val = args[i + 1];
+            return true;
+          }
+        }
+        return false;
+      };
+      auto vis = ::tvm::detail::CreateInitVisitor(DerivedType::_type_key, ffind);
+      self()->_tvm_VisitAttrs(vis);
+      hit_count = vis.hit_count_;
+    } else {
+      // construct a map then do lookup.
+      std::unordered_map<std::string, runtime::TVMArgValue> kwargs;
+      for (int i = 0; i < args.size(); i += 2) {
+        ICHECK_EQ(args.type_codes[i], kTVMStr);
+        kwargs[args[i].operator std::string()] = args[i + 1];
+      }
+      auto ffind = [&kwargs](const char* key, runtime::TVMArgValue* val) {
+        auto it = kwargs.find(key);
+        if (it != kwargs.end()) {
+          *val = it->second;
+          return true;
+        }
+        return false;
+      };
+      auto vis = ::tvm::detail::CreateInitVisitor(DerivedType::_type_key, ffind);
+      self()->_tvm_VisitAttrs(vis);
+      hit_count = vis.hit_count_;
+    }
+    // error handling, slow path
+    if (hit_count * 2 != args.size() && !allow_unknown) {
+      for (int i = 0; i < args.size(); i += 2) {
+        ::tvm::detail::AttrExistVisitor visitor;
+        visitor.key_ = args[i].operator std::string();
+        self()->_tvm_VisitAttrs(visitor);
+        if (!visitor.exist_) {
+          std::ostringstream os;
+          os << DerivedType::_type_key << ": does not have field \'" << visitor.key_
+             << "\', Possible fields:\n";
+          os << "----------------\n";
+          this->PrintDocString(os);
+          throw AttrError(os.str());
+        }
+      }
+    }
+  }
+
+  bool SEqualReduce(const DerivedType* other, SEqualReducer equal) const {
+    DerivedType* pself = self();
+    ::tvm::detail::AttrsSEqualVisitor visitor(pself, other, equal);
+    self()->_tvm_VisitAttrs(visitor);
+    return visitor.result_;
+  }
+
+  void SHashReduce(SHashReducer hash_reducer) const {
+    ::tvm::detail::AttrsSHashVisitor visitor(hash_reducer);
+    self()->_tvm_VisitAttrs(visitor);
+  }
+
+  Array<AttrFieldInfo> ListFieldInfo() const final {
+    ::tvm::detail::AttrDocVisitor visitor;
+    self()->_tvm_VisitAttrs(visitor);
+    return visitor.fields_;
+  }
+
+ private:
+  DerivedType* self() const {
+    return const_cast<DerivedType*>(static_cast<const DerivedType*>(this));
+  }
+};
+
+template <typename... Args>
+inline void BaseAttrsNode::InitBySeq(Args&&... args) {
+  runtime::PackedFunc pf(
+      [this](const TVMArgs& args, TVMRetValue* rv) { this->InitByPackedArgs(args); });
+  pf(std::forward<Args>(args)...);
+}
+
+inline void BaseAttrsNode::PrintDocString(std::ostream& os) const {  // NOLINT(*)
+  Array<AttrFieldInfo> entry = this->ListFieldInfo();
+  for (AttrFieldInfo info : entry) {
+    os << info->name << " : " << info->type_info << '\n';
+    if (info->description.length() != 0) {
+      os << "    " << info->description << '\n';
+    }
+  }
+}
+
+}  // namespace tvm
+#endif  // TVM_IR_ATTRS_H_
diff --git a/darknet_drp_ros/include/tvm/ir/diagnostic.h b/darknet_drp_ros/include/tvm/ir/diagnostic.h
new file mode 100644
index 0000000..41130a5
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/diagnostic.h
@@ -0,0 +1,225 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file diagnostic.h
+ * \brief A new diagnostic interface for TVM error reporting.
+ *
+ */
+
+#ifndef TVM_IR_DIAGNOSTIC_H_
+#define TVM_IR_DIAGNOSTIC_H_
+
+#include <tvm/ir/module.h>
+#include <tvm/parser/source_map.h>
+
+#include <sstream>
+#include <string>
+
+namespace tvm {
+
+using tvm::parser::SourceMap;
+using tvm::runtime::TypedPackedFunc;
+
+/*! \brief The diagnostic level, controls the printing of the message. */
+enum class DiagnosticLevel : int {
+  kBug = 10,
+  kError = 20,
+  kWarning = 30,
+  kNote = 40,
+  kHelp = 50,
+};
+
+class DiagnosticBuilder;
+
+/*! \brief A compiler diagnostic. */
+class Diagnostic;
+
+/*! \brief A compiler diagnostic message. */
+class DiagnosticNode : public Object {
+ public:
+  /*! \brief The level. */
+  DiagnosticLevel level;
+  /*! \brief The span at which to report an error. */
+  Span span;
+  /*! \brief The diagnostic message. */
+  String message;
+
+  // override attr visitor
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("level", &level);
+    v->Visit("span", &span);
+    v->Visit("message", &message);
+  }
+
+  bool SEqualReduce(const DiagnosticNode* other, SEqualReducer equal) const {
+    return equal(this->level, other->level) && equal(this->span, other->span) &&
+           equal(this->message, other->message);
+  }
+
+  static constexpr const char* _type_key = "Diagnostic";
+  TVM_DECLARE_FINAL_OBJECT_INFO(DiagnosticNode, Object);
+};
+
+class Diagnostic : public ObjectRef {
+ public:
+  TVM_DLL Diagnostic(DiagnosticLevel level, Span span, const std::string& message);
+
+  static DiagnosticBuilder Bug(Span span);
+  static DiagnosticBuilder Error(Span span);
+  static DiagnosticBuilder Warning(Span span);
+  static DiagnosticBuilder Note(Span span);
+  static DiagnosticBuilder Help(Span span);
+
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(Diagnostic, ObjectRef, DiagnosticNode);
+};
+
+/*!
+ * \brief A wrapper around std::stringstream to build a diagnostic.
+ */
+class DiagnosticBuilder {
+ public:
+  /*! \brief The level. */
+  DiagnosticLevel level;
+
+  /*! \brief The source name. */
+  SourceName source_name;
+
+  /*! \brief The span of the diagnostic. */
+  Span span;
+
+  template <typename T>
+  DiagnosticBuilder& operator<<(const T& val) {  // NOLINT(*)
+    stream_ << val;
+    return *this;
+  }
+
+  DiagnosticBuilder() : level(DiagnosticLevel::kError), source_name(), span(Span()) {}
+
+  DiagnosticBuilder(const DiagnosticBuilder& builder)
+      : level(builder.level), source_name(builder.source_name), span(builder.span) {}
+
+  DiagnosticBuilder(DiagnosticLevel level, Span span) : level(level), span(span) {}
+
+  operator Diagnostic() { return Diagnostic(this->level, this->span, this->stream_.str()); }
+
+ private:
+  std::stringstream stream_;
+  friend class Diagnostic;
+};
+
+/*!
+ * \brief A diagnostic context for recording errors against a source file.
+ */
+class DiagnosticContext;
+
+/*! \brief Display diagnostics in a given display format.
+ *
+ * A diagnostic renderer is responsible for converting the
+ * raw diagnostics into consumable output.
+ *
+ * For example the terminal renderer will render a sequence
+ * of compiler diagnostics to std::out and std::err in
+ * a human readable form.
+ */
+class DiagnosticRendererNode : public Object {
+ public:
+  TypedPackedFunc<void(DiagnosticContext ctx)> renderer;
+
+  // override attr visitor
+  void VisitAttrs(AttrVisitor* v) {}
+
+  static constexpr const char* _type_key = "DiagnosticRenderer";
+  TVM_DECLARE_FINAL_OBJECT_INFO(DiagnosticRendererNode, Object);
+};
+
+class DiagnosticRenderer : public ObjectRef {
+ public:
+  TVM_DLL DiagnosticRenderer(TypedPackedFunc<void(DiagnosticContext ctx)> render);
+  TVM_DLL DiagnosticRenderer()
+      : DiagnosticRenderer(TypedPackedFunc<void(DiagnosticContext ctx)>()) {}
+
+  void Render(const DiagnosticContext& ctx);
+
+  DiagnosticRendererNode* operator->() {
+    ICHECK(get() != nullptr);
+    return static_cast<DiagnosticRendererNode*>(get_mutable());
+  }
+
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(DiagnosticRenderer, ObjectRef, DiagnosticRendererNode);
+};
+
+class DiagnosticContextNode : public Object {
+ public:
+  /*! \brief The Module to report against. */
+  IRModule module;
+
+  /*! \brief The set of diagnostics to report. */
+  Array<Diagnostic> diagnostics;
+
+  /*! \brief The renderer set for the context. */
+  DiagnosticRenderer renderer;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("module", &module);
+    v->Visit("diagnostics", &diagnostics);
+  }
+
+  bool SEqualReduce(const DiagnosticContextNode* other, SEqualReducer equal) const {
+    return equal(module, other->module) && equal(diagnostics, other->diagnostics);
+  }
+
+  static constexpr const char* _type_key = "DiagnosticContext";
+  TVM_DECLARE_FINAL_OBJECT_INFO(DiagnosticContextNode, Object);
+};
+
+class DiagnosticContext : public ObjectRef {
+ public:
+  TVM_DLL DiagnosticContext(const IRModule& module, const DiagnosticRenderer& renderer);
+  TVM_DLL static DiagnosticContext Default(const IRModule& source_map);
+
+  /*! \brief Emit a diagnostic.
+   * \param diagnostic The diagnostic to emit.
+   */
+  void Emit(const Diagnostic& diagnostic);
+
+  /*! \brief Emit a diagnostic and then immediately attempt to render all errors.
+   *
+   * \param diagnostic The diagnostic to emit.
+   *
+   * Note: this will raise an exception if you would like to instead continue execution
+   * use the Emit method instead.
+   */
+  void EmitFatal(const Diagnostic& diagnostic);
+
+  /*! \brief Render the errors and raise a DiagnosticError exception. */
+  void Render();
+
+  DiagnosticContextNode* operator->() {
+    ICHECK(get() != nullptr);
+    return static_cast<DiagnosticContextNode*>(get_mutable());
+  }
+
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(DiagnosticContext, ObjectRef, DiagnosticContextNode);
+};
+
+DiagnosticRenderer TerminalRenderer(std::ostream& ostream);
+
+}  // namespace tvm
+#endif  // TVM_IR_DIAGNOSTIC_H_
diff --git a/darknet_drp_ros/include/tvm/ir/env_func.h b/darknet_drp_ros/include/tvm/ir/env_func.h
new file mode 100644
index 0000000..386666a
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/env_func.h
@@ -0,0 +1,149 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/ir/env_func.h
+ * \brief Serializable global function used in IR.
+ */
+#ifndef TVM_IR_ENV_FUNC_H_
+#define TVM_IR_ENV_FUNC_H_
+
+#include <tvm/node/reflection.h>
+
+#include <string>
+#include <utility>
+
+namespace tvm {
+/*!
+ * \brief A serializable function backed by TVM's global environment.
+ *
+ * This is a wrapper to enable serializable global PackedFunc.
+ * An EnvFunc is saved by its name in the global registry
+ * under the assumption that the same function is registered during load.
+ * \sa EnvFunc
+ */
+class EnvFuncNode : public Object {
+ public:
+  /*! \brief Unique name of the global function */
+  String name;
+  /*! \brief The internal packed function */
+  runtime::PackedFunc func;
+  /*! \brief constructor */
+  EnvFuncNode() {}
+
+  void VisitAttrs(AttrVisitor* v) { v->Visit("name", &name); }
+
+  bool SEqualReduce(const EnvFuncNode* other, SEqualReducer equal) const {
+    // name uniquely identifies the env function.
+    return name == other->name;
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    // Name uniquely identifies the env function.
+    hash_reduce(name);
+  }
+
+  static constexpr const char* _type_key = "EnvFunc";
+  static constexpr bool _type_has_method_sequal_reduce = true;
+  static constexpr bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_FINAL_OBJECT_INFO(EnvFuncNode, Object);
+};
+
+/*!
+ * \brief Managed reference to EnvFuncNode.
+ * \sa EnvFuncNode
+ */
+class EnvFunc : public ObjectRef {
+ public:
+  EnvFunc() {}
+  explicit EnvFunc(ObjectPtr<Object> n) : ObjectRef(n) {}
+  /*! \return The internal global function pointer */
+  const EnvFuncNode* operator->() const { return static_cast<const EnvFuncNode*>(get()); }
+  /*!
+   * \brief Invoke the function.
+   * \param args The arguments
+   * \returns The return value.
+   */
+  template <typename... Args>
+  runtime::TVMRetValue operator()(Args&&... args) const {
+    const EnvFuncNode* n = operator->();
+    ICHECK(n != nullptr);
+    return n->func(std::forward<Args>(args)...);
+  }
+  /*!
+   * \brief Get a global function based on the name.
+   * \param name The name of the global function.
+   * \return The created global function.
+   * \note The function can be unique
+   */
+  TVM_DLL static EnvFunc Get(const String& name);
+  /*! \brief specify container node */
+  using ContainerType = EnvFuncNode;
+};
+
+/*!
+ * \brief Please refer to \ref TypedEnvFuncAnchor "TypedEnvFunc<R(Args..)>"
+ */
+template <typename FType>
+class TypedEnvFunc;
+
+/*!
+ * \anchor TypedEnvFuncAnchor
+ * \brief A typed version of EnvFunc.
+ * It is backed by a GlobalFuncNode internally.
+ *
+ * \tparam R The return value of the function.
+ * \tparam Args The argument signature of the function.
+ * \sa EnvFunc
+ */
+template <typename R, typename... Args>
+class TypedEnvFunc<R(Args...)> : public ObjectRef {
+ public:
+  /*! \brief short hand for this function type */
+  using TSelf = TypedEnvFunc<R(Args...)>;
+  TypedEnvFunc() {}
+  explicit TypedEnvFunc(ObjectPtr<Object> n) : ObjectRef(n) {}
+  /*!
+   * \brief Assign global function to a TypedEnvFunc
+   * \param other Another global function.
+   * \return reference to self.
+   */
+  TSelf& operator=(const EnvFunc& other) {
+    ObjectRef::operator=(other);
+    return *this;
+  }
+  /*! \return The internal global function pointer */
+  const EnvFuncNode* operator->() const { return static_cast<const EnvFuncNode*>(get()); }
+  /*!
+   * \brief Invoke the function.
+   * \param args The arguments
+   * \returns The return value.
+   */
+  R operator()(Args... args) const {
+    const EnvFuncNode* n = operator->();
+    ICHECK(n != nullptr);
+    return runtime::detail::typed_packed_call_dispatcher<R>::run(n->func,
+                                                                 std::forward<Args>(args)...);
+  }
+  /*! \brief specify container node */
+  using ContainerType = EnvFuncNode;
+};
+
+}  // namespace tvm
+#endif  // TVM_IR_ENV_FUNC_H_
diff --git a/darknet_drp_ros/include/tvm/ir/error.h b/darknet_drp_ros/include/tvm/ir/error.h
new file mode 100644
index 0000000..6ff6178
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/error.h
@@ -0,0 +1,185 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/ir/error.h
+ * \brief Utilities for error tracking and reporting.
+ */
+#ifndef TVM_IR_ERROR_H_
+#define TVM_IR_ERROR_H_
+
+#include <tvm/ir/module.h>
+#include <tvm/ir/span.h>
+
+#include <sstream>
+#include <string>
+#include <unordered_map>
+#include <vector>
+
+namespace tvm {
+/*!
+ * \brief A wrapper around std::stringstream to build error.
+ *
+ * Can be consumed by CompileError to construct an error.
+ *
+ * \code
+ *
+ * void ReportError(const CompileError& err);
+ *
+ * void Test(int number) {
+ *   // Use error reporter to construct an error.
+ *   ReportError(ErrorBuilder() << "This is an error number=" << number);
+ * }
+ *
+ * \endcode
+ */
+struct ErrorBuilder {
+ public:
+  template <typename T>
+  ErrorBuilder& operator<<(const T& val) {  // NOLINT(*)
+    stream_ << val;
+    return *this;
+  }
+
+ private:
+  std::stringstream stream_;
+  friend class CompileError;
+};
+
+/*!
+ * \brief Custom Error class to be thrown during compilation.
+ */
+class CompileError : public Error {
+ public:
+  /*! \brief Location of the error */
+  Span span;
+  /*!
+   * \brief construct error from message.
+   * \param msg The message
+   */
+  explicit CompileError(const std::string& msg) : Error(msg), span(nullptr) {}
+  /*!
+   * \brief construct error from error builder.
+   * \param err The error builder
+   */
+  CompileError(const ErrorBuilder& err) : Error(err.stream_.str()), span(nullptr) {}  // NOLINT(*)
+  /*!
+   * \brief copy constructor.
+   * \param other The other ereor.
+   */
+  CompileError(const CompileError& other) : Error(other.what()), span(other.span) {}  // NOLINT(*)
+  /*!
+   * \brief default constructor. */
+  CompileError() : Error(""), span(nullptr) {}
+};
+
+/*!
+ * \brief An abstraction around how errors are stored and reported.
+ * Designed to be opaque to users, so we can support a robust and simpler
+ * error reporting mode, as well as a more complex mode.
+ *
+ * The first mode is the most accurate: we report a Relay error at a specific
+ * Span, and then render the error message directly against a textual representation
+ * of the program, highlighting the exact lines in which it occurs. This mode is not
+ * implemented in this PR and will not work.
+ *
+ * The second mode is a general-purpose mode, which attempts to annotate the program's
+ * textual format with errors.
+ *
+ * The final mode represents the old mode, if we report an error that has no span or
+ * expression, we will default to throwing an exception with a textual representation
+ * of the error and no indication of where it occurred in the original program.
+ *
+ * The latter mode is not ideal, and the goal of the new error reporting machinery is
+ * to avoid ever reporting errors in this style.
+ */
+class ErrorReporter {
+ public:
+  /*! \brief default constructor. */
+  ErrorReporter() : errors_(), node_to_error_() {}
+
+  /*!
+   * \brief Report a CompileError.
+   *
+   * This API is useful for reporting spanned errors.
+   *
+   * \param err The error to report.
+   */
+  void Report(const CompileError& err) {
+    if (!err.span.defined()) {
+      throw err;
+    }
+
+    this->errors_.push_back(err);
+  }
+
+  /*!
+   * \brief Report an error against a program, using the full program
+   * error reporting strategy.
+   *
+   * This error reporting method requires the global function in which
+   * to report an error, the expression to report the error on,
+   * and the error object.
+   *
+   * \param global The global function in which the expression is contained.
+   * \param node The expression or type to report the error at.
+   * \param err The error message to report.
+   */
+  void ReportAt(const GlobalVar& global, const ObjectRef& node, std::stringstream& err) {
+    std::string err_msg = err.str();
+    this->ReportAt(global, node, CompileError(err_msg));
+  }
+
+  /*!
+   * \brief Report an error against a program, using the full program
+   * error reporting strategy.
+   *
+   * This error reporting method requires the global function in which
+   * to report an error, the expression to report the error on,
+   * and the error object.
+   *
+   * \param global The global function in which the expression is contained.
+   * \param node The expression or type to report the error at.
+   * \param err The error to report.
+   */
+  void ReportAt(const GlobalVar& global, const ObjectRef& node, const CompileError& err);
+
+  /*!
+   * \brief Render all reported errors and exit the program.
+   *
+   * This function should be used after executing a pass to render reported errors.
+   *
+   * It will build an error message from the set of errors, depending on the error
+   * reporting strategy.
+   *
+   * \param module The module to report errors on.
+   * \param use_color Controls whether to colorize the output.
+   */
+  void RenderErrors(const IRModule& module, bool use_color = true);
+
+  inline bool AnyErrors() { return errors_.size() != 0; }
+
+ private:
+  std::vector<CompileError> errors_;
+  std::unordered_map<ObjectRef, std::vector<size_t>, ObjectPtrHash, ObjectPtrEqual> node_to_error_;
+  std::unordered_map<ObjectRef, GlobalVar, ObjectPtrHash, ObjectPtrEqual> node_to_gv_;
+};
+
+}  // namespace tvm
+#endif  // TVM_IR_ERROR_H_
diff --git a/darknet_drp_ros/include/tvm/ir/expr.h b/darknet_drp_ros/include/tvm/ir/expr.h
new file mode 100644
index 0000000..bb4c468
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/expr.h
@@ -0,0 +1,813 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/ir/expr.h
+ * \brief Base expr nodes in TVM.
+ */
+#ifndef TVM_IR_EXPR_H_
+#define TVM_IR_EXPR_H_
+
+#include <tvm/ir/span.h>
+#include <tvm/ir/type.h>
+#include <tvm/node/node.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/runtime/object.h>
+
+#include <algorithm>
+#include <limits>
+#include <string>
+#include <type_traits>
+
+namespace tvm {
+
+using tvm::runtime::String;
+
+// Forward-declare VirtualDevice to avoid circular imports.
+class VirtualDevice;
+
+/*!
+ * \brief Base type of all the expressions.
+ * \sa Expr
+ */
+class BaseExprNode : public Object {
+ public:
+  /*!
+   * \brief Span that points to the original source code.
+   *        Reserved debug information.
+   */
+  mutable Span span;
+
+  static constexpr const char* _type_key = "BaseExpr";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  static constexpr const uint32_t _type_child_slots = 62;
+  TVM_DECLARE_BASE_OBJECT_INFO(BaseExprNode, Object);
+};
+
+/*!
+ * \brief Managed reference to BaseExprNode.
+ * \sa BaseExprNode
+ */
+class BaseExpr : public ObjectRef {
+ public:
+  TVM_DEFINE_OBJECT_REF_METHODS(BaseExpr, ObjectRef, BaseExprNode);
+};
+
+/*!
+ * \brief Base node of all primitive expressions.
+ *
+ *  A primitive expression deals with low-level
+ *  POD data types and handles without
+ *  doing life-cycle management for objects.
+ *
+ *  PrimExpr is used in the low-level code
+ *  optimizations and integer analysis.
+ *
+ * \sa PrimExpr
+ */
+class PrimExprNode : public BaseExprNode {
+ public:
+  /*!
+   * \brief The runtime data type of the primitive expression.
+   *
+   * runtime::DataType(dtype) provides coarse grained type information
+   * during compile time and runtime. It is eagerly built in
+   * PrimExpr expression construction and can be used for
+   * quick type checking.
+   *
+   * dtype is sufficient to decide the Type of the PrimExpr
+   * when it corresponds to POD value types such as i32.
+   *
+   * When dtype is DataType::Handle(), the expression could corresponds to
+   * a more fine-grained Type, and we can get the type by running lazy type inference.
+   */
+  DataType dtype;
+
+  static constexpr const char* _type_key = "PrimExpr";
+  static constexpr const uint32_t _type_child_slots = 38;
+  TVM_DECLARE_BASE_OBJECT_INFO(PrimExprNode, BaseExprNode);
+};
+
+/*!
+ * \brief Reference to PrimExprNode.
+ * \sa PrimExprNode
+ */
+class PrimExpr : public BaseExpr {
+ public:
+  /*!
+   * \brief construct from integer.
+   * \param value The value to be constructed.
+   */
+  TVM_DLL PrimExpr(int32_t value);  // NOLINT(*)
+  /*!
+   * \brief construct from float.
+   * \param value The value to be constructed.
+   */
+  TVM_DLL PrimExpr(float value);  // NOLINT(*)
+
+  /*! \return the data type of this expression. */
+  DataType dtype() const { return static_cast<const PrimExprNode*>(get())->dtype; }
+
+  TVM_DEFINE_OBJECT_REF_METHODS(PrimExpr, BaseExpr, PrimExprNode);
+
+ private:
+  // Internal function for conversion.
+  friend struct runtime::PackedFuncValueConverter<PrimExpr>;
+  TVM_DLL static PrimExpr FromObject_(ObjectRef ref);
+};
+
+/*!
+ * \brief add operator
+ *
+ * \param a left operand
+ * \param b right operand
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr operator+(PrimExpr a, PrimExpr b);
+
+/*!
+ * \brief subtraction operator
+ *
+ * \param a left operand
+ * \param b right operand
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr operator-(PrimExpr a, PrimExpr b);
+
+/*!
+ * \brief negation.
+ *
+ * \param a input.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr operator-(PrimExpr a);
+
+/*!
+ * \brief multiplication operator
+ *
+ * \param a left operand
+ * \param b right operand
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr operator*(PrimExpr a, PrimExpr b);
+
+/*!
+ * \brief division operator
+ *
+ * \param a left operand
+ * \param b right operand
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr operator/(PrimExpr a, PrimExpr b);
+
+/*!
+ * \brief left shift operator
+ *
+ * \param a left operand
+ * \param b right operand
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr operator<<(PrimExpr a, PrimExpr b);
+
+/*!
+ * \brief right shift operator
+ *
+ * \param a left operand
+ * \param b right operand
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr operator>>(PrimExpr a, PrimExpr b);
+
+/*!
+ * \brief greater
+ *
+ * \param a left operand
+ * \param b right operand
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr operator>(PrimExpr a, PrimExpr b);
+
+/*!
+ * \brief greater_equal
+ *
+ * \param a left operand
+ * \param b right operand
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr operator>=(PrimExpr a, PrimExpr b);
+
+/*!
+ * \brief less
+ *
+ * \param a left operand
+ * \param b right operand
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr operator<(PrimExpr a, PrimExpr b);
+
+/*!
+ * \brief less_equal
+ *
+ * \param a left operand
+ * \param b right operand
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr operator<=(PrimExpr a, PrimExpr b);
+
+/*!
+ * \brief equal
+ *
+ * \param a left operand
+ * \param b right operand
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr operator==(PrimExpr a, PrimExpr b);
+
+/*!
+ * \brief not_equal
+ *
+ * \param a left operand
+ * \param b right operand
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr operator!=(PrimExpr a, PrimExpr b);
+
+/*!
+ * \brief and
+ *
+ * \param a left operand
+ * \param b right operand
+ * \return The result expression.
+ * \note This operator does eager constant folding.
+ */
+TVM_DLL PrimExpr operator&&(PrimExpr a, PrimExpr b);
+
+/*!
+ * \brief or
+ *
+ * \param a left operand
+ * \param b right operand
+ * \return The result expression.
+ * \note This operator does eager constant folding.
+ */
+TVM_DLL PrimExpr operator||(PrimExpr a, PrimExpr b);
+
+/*!
+ * \brief not
+ *
+ * \param a left operand
+ * \return The result expression.
+ * \note This operator does eager constant folding.
+ */
+TVM_DLL PrimExpr operator!(PrimExpr a);
+
+/*!
+ * \brief take bitwise and of two values
+ *
+ * \param a left operand
+ * \param b right operand
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr operator&(PrimExpr a, PrimExpr b);
+
+/*!
+ * \brief take bitwise or of two values
+ *
+ * \param a left operand
+ * \param b right operand
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr operator|(PrimExpr a, PrimExpr b);
+
+/*!
+ * \brief take bitwise xor of two values
+ *
+ * \param a left operand
+ * \param b right operand
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr operator^(PrimExpr a, PrimExpr b);
+
+/*!
+ * \brief take bitwise negation of two values
+ *
+ * \param a the input expression.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr operator~(PrimExpr a);
+
+/*!
+ * \brief Base node of all non-primitive expressions.
+ *
+ * RelayExpr supports tensor types, functions and ADT as
+ * first class citizens. The life-cycle of the corresponding
+ * objects are implicitly managed by the language.
+ *
+ * \sa RelayExpr
+ */
+class RelayExprNode : public BaseExprNode {
+ public:
+  /*!
+   * \brief Stores the result of type inference(type checking).
+   *
+   * \note This can be undefined before type inference.
+   *       This value is discarded during serialization.
+   */
+  mutable Type checked_type_ = Type(nullptr);
+  /*!
+   * \return The checked_type
+   */
+  inline const Type& checked_type() const;
+  /*!
+   * \brief Check if the inferred(checked) type of the Expr
+   *  is backed by a TTypeNode and return it.
+   *
+   * \note This function will thrown an error if the node type
+   *       of this Expr is not TTypeNode.
+   *
+   * \return The corresponding TTypeNode pointer.
+   * \tparam The specific TypeNode we look for.
+   */
+  template <typename TTypeNode>
+  inline const TTypeNode* type_as() const;
+
+  /*!
+   * \brief The virtual device (VirtualDevice) for this node (the result of device planning).
+   * For first-order expressions (non functions), this describes where the result of evaluating the
+   * expression should be stored. Note that currently, all composite first-order values (tuples,
+   * references, ADTs) must be stored on the same virtual device. This means that it is not possible
+   * to store two tuple fields on different devices, so we only need one virtual device for these
+   * types.
+   *
+   * For expressions that have the function type, the virtual device describes where the result of
+   * the call to the function or closure is stored (instead of where the function itself is stored).
+   * For example, the virtual device of f = fn(x) { body } is the virtual device of f(y), not where
+   * the function itself is stored. Note that f(y)'s virtual device will be the same as the virtual
+   * device of body. For more details, see the documentation in
+   * src/relay/transforms/device_planner.cc.
+   *
+   * The VirtualDevice's Target field describes how the body of the function should be compiled.
+   *
+   * Set to VirtualDevice::FullyUnconstrained by default.
+   *
+   * \note Unfortunately, the type of virtual_device_ needs to be ObjectRef to avoid a circular
+   * import.
+   */
+  mutable ObjectRef virtual_device_;
+
+  /*!
+   * \return The virtual device (VirtualDevice).
+   * If the virtual device is not defined, returns VirtualDevice::FullyUnconstrained().
+   * Note that for function types, the virtual device is the device where the result of a
+   * call to the function is stored, not where the function itself lives.
+   * For example, the virtual device of f = fn(x) { body } is the virtual device of f(y), not where
+   * the function itself is stored. Note that f(y)'s virtual device will be the same as the virtual
+   * device of body.
+   *
+   * See the documentation of the virtual_device_ field (above) for more details.
+   */
+  VirtualDevice virtual_device() const;
+
+  static constexpr const char* _type_key = "RelayExpr";
+  static constexpr const uint32_t _type_child_slots = 22;
+  TVM_DECLARE_BASE_OBJECT_INFO(RelayExprNode, BaseExprNode);
+};
+
+/*!
+ * \brief Managed reference to RelayExprNode.
+ * \sa RelayExprNode
+ */
+class RelayExpr : public BaseExpr {
+ public:
+  TVM_DEFINE_OBJECT_REF_METHODS(RelayExpr, BaseExpr, RelayExprNode);
+};
+
+class GlobalVar;
+/*!
+ * \brief Global variable that lives in the top-level module.
+ *
+ * A GlobalVar only refers to function definitions.
+ * This is used to enable recursive calls between function.
+ *
+ * \sa GlobalVarNode
+ */
+class GlobalVarNode : public RelayExprNode {
+ public:
+  /*! \brief The name of the variable, this only acts as a hint. */
+  String name_hint;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("name_hint", &name_hint);
+    v->Visit("virtual_device_", &virtual_device_);
+    v->Visit("span", &span);
+    v->Visit("_checked_type_", &checked_type_);
+  }
+
+  bool SEqualReduce(const GlobalVarNode* other, SEqualReducer equal) const {
+    // name matters for global var.
+    return equal(name_hint, other->name_hint) && equal.FreeVarEqualImpl(this, other);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(name_hint);
+    hash_reduce.FreeVarHashImpl(this);
+  }
+
+  static constexpr const char* _type_key = "GlobalVar";
+  TVM_DECLARE_FINAL_OBJECT_INFO(GlobalVarNode, RelayExprNode);
+};
+
+/*!
+ * \brief Managed reference to GlobalVarNode.
+ * \sa GlobalVarNode
+ */
+class GlobalVar : public RelayExpr {
+ public:
+  TVM_DLL explicit GlobalVar(String name_hint, Type type = {}, Span span = {});
+
+  TVM_DEFINE_OBJECT_REF_METHODS(GlobalVar, RelayExpr, GlobalVarNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(GlobalVarNode);
+};
+
+// PrimExprs that are useful as runtime containers.
+//
+/*!
+ * \brief Constant integer literals in the program.
+ * \sa IntImm
+ */
+class IntImmNode : public PrimExprNode {
+ public:
+  /*! \brief the Internal value. */
+  int64_t value;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &dtype);
+    v->Visit("value", &value);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const IntImmNode* other, SEqualReducer equal) const {
+    return equal(dtype, other->dtype) && equal(value, other->value);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dtype);
+    hash_reduce(value);
+  }
+
+  static constexpr const char* _type_key = "IntImm";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IntImmNode, PrimExprNode);
+};
+
+/*!
+ * \brief Managed reference class to IntImmNode.
+ *
+ * \sa IntImmNode
+ */
+class IntImm : public PrimExpr {
+ public:
+  /*!
+   * \brief Constructor.
+   * \param dtype The data type of the value.
+   * \param value The internal value.
+   * \param span The location of this object in the source code.
+   */
+  TVM_DLL IntImm(DataType dtype, int64_t value, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(IntImm, PrimExpr, IntImmNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(IntImmNode);
+};
+
+/*!
+ * \brief Constant floating point literals in the program.
+ * \sa FloatImm
+ */
+class FloatImmNode : public PrimExprNode {
+ public:
+  /*! \brief The constant value content. */
+  double value;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &dtype);
+    v->Visit("value", &value);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const FloatImmNode* other, SEqualReducer equal) const {
+    return equal(dtype, other->dtype) && equal(value, other->value);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dtype);
+    hash_reduce(value);
+  }
+
+  static constexpr const char* _type_key = "FloatImm";
+  TVM_DECLARE_FINAL_OBJECT_INFO(FloatImmNode, PrimExprNode);
+};
+
+/*!
+ * \brief Managed reference class to FloatImmNode.
+ *
+ * \sa FloatImmNode
+ */
+class FloatImm : public PrimExpr {
+ public:
+  /*!
+   * \brief Constructor.
+   * \param dtype The data type of the value.
+   * \param value The internal value.
+   * \param span The location in the source code.
+   */
+  TVM_DLL FloatImm(DataType dtype, double value, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(FloatImm, PrimExpr, FloatImmNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(FloatImmNode);
+};
+
+/*!
+ * \brief Boolean constant.
+ *
+ *  This reference type is useful to add additional compile-time
+ *  type checks and helper functions for Integer equal comparisons.
+ */
+class Bool : public IntImm {
+ public:
+  explicit Bool(bool value, Span span = Span()) : IntImm(DataType::Bool(), value, span) {}
+  Bool operator!() const { return Bool((*this)->value == 0); }
+  operator bool() const { return (*this)->value != 0; }
+
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(Bool, IntImm, IntImmNode);
+};
+
+// Overload operators to make sure we have the most fine grained types.
+inline Bool operator||(const Bool& a, bool b) { return Bool(a.operator bool() || b); }
+inline Bool operator||(bool a, const Bool& b) { return Bool(a || b.operator bool()); }
+inline Bool operator||(const Bool& a, const Bool& b) {
+  return Bool(a.operator bool() || b.operator bool());
+}
+inline Bool operator&&(const Bool& a, bool b) { return Bool(a.operator bool() && b); }
+inline Bool operator&&(bool a, const Bool& b) { return Bool(a && b.operator bool()); }
+inline Bool operator&&(const Bool& a, const Bool& b) {
+  return Bool(a.operator bool() && b.operator bool());
+}
+
+inline bool operator==(const Bool& a, bool b) { return a.operator bool() == b; }
+inline bool operator==(bool a, const Bool& b) { return a == b.operator bool(); }
+inline bool operator==(const Bool& a, const Bool& b) {
+  return a.operator bool() == b.operator bool();
+}
+
+/*!
+ * \brief Container of constant int that adds more constructors.
+ *
+ * This is used to store and automate type check
+ * attributes that must be constant integer.
+ *
+ * \sa IntImm
+ */
+class Integer : public IntImm {
+ public:
+  Integer() {}
+  /*!
+   * \brief constructor from node.
+   */
+  explicit Integer(ObjectPtr<Object> node) : IntImm(node) {}
+  /*!
+   * \brief Construct integer from int value.
+   */
+  Integer(int value, Span span = Span()) : IntImm(DataType::Int(32), value, span) {}  // NOLINT(*)
+  /*!
+   * \brief Construct integer from int imm.
+   * \param other The other value.
+   */
+  Integer(IntImm other) : IntImm(std::move(other)) {}  // NOLINT(*)
+  /*!
+   * \brief Constructor from enum
+   * \tparam Enum The enum type.
+   * \param value The enum value.
+   */
+  template <typename Enum, typename = typename std::enable_if<std::is_enum<Enum>::value>::type>
+  explicit Integer(Enum value) : Integer(static_cast<int>(value)) {
+    static_assert(std::is_same<int, typename std::underlying_type<Enum>::type>::value,
+                  "declare enum to be enum int to use visitor");
+  }
+  /*!
+   * \brief Assign an expression to integer.
+   * \param other another expression.
+   */
+  Integer& operator=(const IntImm& other) {
+    data_ = ObjectRef::GetDataPtr<Object>(other);
+    return *this;
+  }
+  /*!
+   * \brief convert to int64_t
+   */
+  int64_t IntValue() const {
+    ICHECK(data_ != nullptr) << " Trying to reference a null Integer";
+    return (*this)->value;
+  }
+  // comparators
+  Bool operator==(int other) const {
+    if (data_ == nullptr) return Bool(false);
+    return Bool((*this)->value == other);
+  }
+  Bool operator!=(int other) const { return !(*this == other); }
+  template <typename Enum, typename = typename std::enable_if<std::is_enum<Enum>::value>::type>
+  Bool operator==(Enum other) const {
+    return *this == static_cast<int>(other);
+  }
+  template <typename Enum, typename = typename std::enable_if<std::is_enum<Enum>::value>::type>
+  Bool operator!=(Enum other) const {
+    return *this != static_cast<int>(other);
+  }
+};
+
+/*! \brief range over one dimension */
+class RangeNode : public Object {
+ public:
+  /*! \brief beginning of the node */
+  PrimExpr min;
+  /*! \brief the extend of range */
+  PrimExpr extent;
+  /*! \brief the location of this range in the source */
+  mutable Span span;
+  /*! \brief constructor */
+  RangeNode() {}
+  RangeNode(PrimExpr min, PrimExpr extent, Span span = Span())
+      : min(min), extent(extent), span(span) {}
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("min", &min);
+    v->Visit("extent", &extent);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const RangeNode* other, SEqualReducer equal) const {
+    return equal(min, other->min) && equal(extent, other->extent);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(min);
+    hash_reduce(extent);
+  }
+
+  static constexpr const char* _type_key = "Range";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_FINAL_OBJECT_INFO(RangeNode, Object);
+};
+
+/*! \brief Range constainer  */
+class Range : public ObjectRef {
+ public:
+  /*!
+   * \brief constructor by begin and end
+   * \param begin The begin of the range.
+   * \param end The end of the range.
+   * \param span The location of the Range in the source.
+   */
+  TVM_DLL Range(PrimExpr begin, PrimExpr end, Span span = Span());
+  /*!
+   * \brief construct a new range with min and extent
+   *  The corresponding constructor is removed,
+   *  because that is counter convention of tradition meaning
+   *  of range(begin, end)
+   *
+   * \param min The minimum range.
+   * \param extent The extent of the range.
+   * \param span The location of the Range in the source.
+   */
+  static Range FromMinExtent(PrimExpr min, PrimExpr extent, Span span = Span());
+  // declare range.
+  TVM_DEFINE_OBJECT_REF_METHODS(Range, ObjectRef, RangeNode);
+};
+
+// implementataions
+inline const Type& RelayExprNode::checked_type() const {
+  ICHECK(checked_type_.defined()) << "internal error: the type checker has "
+                                  << "not populated the checked_type "
+                                  << "field for " << GetRef<RelayExpr>(this);
+  return this->checked_type_;
+}
+
+template <typename TTypeNode>
+inline const TTypeNode* RelayExprNode::type_as() const {
+  static_assert(std::is_base_of<TypeNode, TTypeNode>::value,
+                "TType must be a special case of type");
+  ICHECK(checked_type_.defined())
+      << "Type inference for this Expr has not completed. Try to call infer_type pass.";
+  const TTypeNode* node = checked_type_.as<TTypeNode>();
+  ICHECK(node != nullptr) << "Expected type to be " << TTypeNode::_type_key << ", but get "
+                          << checked_type_->GetTypeKey();
+  return node;
+}
+
+}  // namespace tvm
+
+namespace tvm {
+namespace runtime {
+// common rule for RetValue and ArgValue
+template <>
+struct PackedFuncValueConverter<PrimExpr> {
+  static PrimExpr From(const TVMPODValue_& val) {
+    if (val.type_code() == kTVMNullptr) {
+      return PrimExpr(ObjectPtr<Object>(nullptr));
+    }
+    if (val.type_code() == kDLInt) {
+      int64_t value = val.operator int64_t();
+      if (value > std::numeric_limits<int>::max() || value < std::numeric_limits<int>::min()) {
+        return IntImm(runtime::DataType::Int(64), value);
+      }
+      return IntImm(runtime::DataType::Int(32), val.operator int());
+    }
+    if (val.type_code() == kDLFloat) {
+      return FloatImm(runtime::DataType::Float(32), val.operator double());
+    }
+
+    return PrimExpr::FromObject_(val.AsObjectRef<ObjectRef>());
+  }
+};
+
+template <>
+struct PackedFuncValueConverter<tvm::Integer> {
+  static tvm::Integer From(const TVMPODValue_& val) {
+    if (val.type_code() == kTVMNullptr) {
+      return Integer(ObjectPtr<Object>(nullptr));
+    }
+    if (val.type_code() == kTVMArgInt) {
+      return Integer(val.operator int());
+    }
+    return val.AsObjectRef<tvm::Integer>();
+  }
+};
+
+template <>
+struct PackedFuncValueConverter<tvm::Bool> {
+  static tvm::Bool From(const TVMPODValue_& val) {
+    if (val.type_code() == kTVMNullptr) {
+      return Bool(ObjectPtr<Object>(nullptr));
+    }
+    if (val.type_code() == kTVMArgInt) {
+      int v = val.operator int();
+      ICHECK(v == 0 || v == 1) << "ValueError: boolean value can only be 0 or 1, but get " << v;
+      return Bool(static_cast<bool>(v));
+    }
+    return val.AsObjectRef<tvm::Bool>();
+  }
+};
+
+}  // namespace runtime
+}  // namespace tvm
+#endif  // TVM_IR_EXPR_H_
diff --git a/darknet_drp_ros/include/tvm/ir/function.h b/darknet_drp_ros/include/tvm/ir/function.h
new file mode 100644
index 0000000..1493544
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/function.h
@@ -0,0 +1,195 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/ir/function.h
+ * \brief Function nodes.
+ */
+#ifndef TVM_IR_FUNCTION_H_
+#define TVM_IR_FUNCTION_H_
+
+#include <tvm/ir/attrs.h>
+#include <tvm/ir/expr.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/map.h>
+#include <tvm/runtime/container/string.h>
+
+#include <string>
+#include <type_traits>
+
+namespace tvm {
+
+/*!
+ * \brief Possible Calling conventions.
+ *
+ *  NOTE: The calling convention also implies
+ *  the way we implement the function during lowering.
+ */
+enum class CallingConv : int {
+  /*!
+   * \brief Default calling convention.
+   *
+   * - Uses the native calling convention of the target.
+   * - Implementation: specified by the native target.
+   */
+  kDefault = 0,
+  /*!
+   * \brief PackedFunc that exposes a CPackedFunc signature.
+   *
+   * - Calling by PackedFunc calling convention.
+   * - Implementation: Expose a function with the CPackedFunc signature.
+   */
+  kCPackedFunc = 1,
+  /*!
+   * \brief Device kernel launch
+   *
+   * - Call by PackedFunc calling convention.
+   * - Implementation: defined by device runtime(e.g. runtime/cuda)
+   */
+  kDeviceKernelLaunch = 2,
+};
+
+/*!
+ * \brief Base node of all functions.
+ *
+ * We support several variants of functions throughout the stack.
+ * All of the functions share the same type system(via checked_type)
+ * to support cross variant calls.
+ *
+ * \sa BaseFunc
+ */
+class BaseFuncNode : public RelayExprNode {
+ public:
+  /*! \brief Additional attributes storing the meta-data */
+  DictAttrs attrs;
+
+  /*!
+   * \brief Get a function attribute.
+   *
+   * \param attr_key The attribute key.
+   * \param default_value The default value if the key does not exist, defaults to nullptr.
+   *
+   * \return The result
+   *
+   * \tparam TOBjectRef the expected object type.
+   * \throw Error if the key exists but the value does not match TObjectRef
+   *
+   * \code
+   *
+   *  void GetAttrExample(const BaseFunc& f) {
+   *    auto value = f->GetAttr<Integer>("AttrKey", 0);
+   *  }
+   *
+   * \endcode
+   */
+  template <typename TObjectRef>
+  Optional<TObjectRef> GetAttr(
+      const std::string& attr_key,
+      Optional<TObjectRef> default_value = Optional<TObjectRef>(nullptr)) const {
+    return attrs.GetAttr(attr_key, default_value);
+  }
+  // variant that uses TObjectRef to enable implicit conversion to default value.
+  template <typename TObjectRef>
+  Optional<TObjectRef> GetAttr(const std::string& attr_key, TObjectRef default_value) const {
+    return GetAttr<TObjectRef>(attr_key, Optional<TObjectRef>(default_value));
+  }
+
+  /*!
+   * \brief Check whether the function has an non-zero integer attr.
+   *
+   * This function can be used to check whether an optional
+   * attribute mark(e.g. inline) exists.
+   *
+   * \param attr_key The key to the attribute.
+   * \return The check result.
+   *
+   * \code
+   *
+   *  void HasNonzeroAttrExample(const BaseFunc& f) {
+   *    if (f->HasNonzeroAttr(attr::kInline)) {
+   *      // inline the function.
+   *    }
+   *  }
+   *
+   * \endcode
+   */
+  bool HasNonzeroAttr(const std::string& attr_key) const { return attrs.HasNonzeroAttr(attr_key); }
+
+  static constexpr const char* _type_key = "BaseFunc";
+  static constexpr const uint32_t _type_child_slots = 2;
+  TVM_DECLARE_BASE_OBJECT_INFO(BaseFuncNode, RelayExprNode);
+};
+
+/*!
+ * \brief Managed reference to BaseFuncNode.
+ * \sa BaseFuncNode
+ */
+class BaseFunc : public RelayExpr {
+ public:
+  TVM_DEFINE_OBJECT_REF_METHODS(BaseFunc, RelayExpr, BaseFuncNode);
+};
+
+/*!
+ * \brief Generic attribute names that can be attached to any function.
+ *
+ * \sa tvm::tir::attr, tvm::relay::attr
+ */
+namespace attr {
+/*!
+ * \brief Indicates the special calling convention.
+ *
+ * Type: Integer
+ *
+ * \sa tvm::CallingConv
+ */
+constexpr const char* kCallingConv = "calling_conv";
+
+/*!
+ * \brief Compilation target of the function.
+ *
+ * Type: Target
+ *
+ * \sa tvm::Target
+ */
+constexpr const char* kTarget = "target";
+
+/*!
+ * \brief Global linker symbol of the function in generated code.
+ *
+ *  This option forces the code generator to name the
+ *  function with the given.
+ *
+ *  For example, we could set a global_symbol of a function
+ *  early to make sure that we can always refer to it by
+ *  the symbol name in the generated DLL.
+ *
+ *  We should not set the attribute for local functions,
+ *  so that the compiler can freely rename them.
+ *
+ *  A unique global symbol will be automatically assigned
+ *  to each function in the module before the target code
+ *  generation phase.
+ *
+ * Type: String
+ */
+constexpr const char* kGlobalSymbol = "global_symbol";
+
+}  // namespace attr
+}  // namespace tvm
+#endif  // TVM_IR_FUNCTION_H_
diff --git a/darknet_drp_ros/include/tvm/ir/global_var_supply.h b/darknet_drp_ros/include/tvm/ir/global_var_supply.h
new file mode 100644
index 0000000..276c64a
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/global_var_supply.h
@@ -0,0 +1,125 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/ir/global_var_supply.h
+ * \brief GlobalVarSupply that can be used to generate unique \class GlobalVar.
+ */
+#ifndef TVM_IR_GLOBAL_VAR_SUPPLY_H_
+#define TVM_IR_GLOBAL_VAR_SUPPLY_H_
+
+#include <string>
+#include <unordered_map>
+
+#include "tvm/ir/expr.h"
+#include "tvm/ir/module.h"
+#include "tvm/ir/name_supply.h"
+
+namespace tvm {
+
+/*!
+ * \brief GlobalVarSupply can be used to generate unique GlobalVars.
+ */
+class GlobalVarSupplyNode : public Object {
+ public:
+  /*!
+   * \brief Empty constructor. Will use an empty NameSupply.
+   */
+  GlobalVarSupplyNode() : GlobalVarSupplyNode(NameSupply("")) {}
+
+  /*!
+   * \brief Constructor.
+   * \param name_supply The NameSupply to use for generating the names of fresh GlobalVars.
+   * \param name_to_var_map An optional map.
+   */
+  explicit GlobalVarSupplyNode(NameSupply name_supply,
+                               std::unordered_map<std::string, GlobalVar> name_to_var_map = {});
+
+  /*!
+   * \brief Generates a unique GlobalVar from this supply.
+   * \param name The name from which the name of the GlobalVar is derived.
+   * \param add_prefix If set to true, then the prefix of the contained NameSupply will be prepended
+   * to the name. \return A unique GlobalVar.
+   */
+  GlobalVar FreshGlobal(String name, bool add_prefix = true);
+
+  /*!
+   * \brief Looks up for a GlobalVar with the given name in this supply.
+   * If no entry is found, creates one, places it in the cache and returns it.
+   * \param name The name of the GlobalVar to search for.
+   * \param add_prefix If set to true, the prefix of the contained NameSupply will be prepended to
+   * the name before performing the search. \return A cached GlobalVar.
+   */
+  GlobalVar UniqueGlobalFor(const String& name, bool add_prefix = true);
+
+  /*!
+   * \brief Reserves an existing GlobalVar with this supply.
+   * \param var The GlobalVar to be registered.
+   * \param allow_conflict Allow conflict with other GlobalVars that have the same name.
+   */
+  void ReserveGlobalVar(const GlobalVar& var, bool allow_conflict = false);
+
+  void VisitAttrs(AttrVisitor* v) {}
+
+  /*! \brief The NameSupply used to generate unique name hints to GlobalVars. */
+  NameSupply name_supply_;
+
+  static constexpr const char* _type_key = "GlobalVarSupply";
+  static constexpr const bool _type_has_method_sequal_reduce = false;
+  static constexpr const bool _type_has_method_shash_reduce = false;
+  TVM_DECLARE_FINAL_OBJECT_INFO(GlobalVarSupplyNode, Object);
+
+ private:
+  std::unordered_map<std::string, GlobalVar> name_to_var_map_;
+};
+
+/*!
+ * \brief Managed reference class to GlobalVarSupplyNode.
+ * \sa GlobalVarSupplyNode
+ */
+class GlobalVarSupply : public ObjectRef {
+ public:
+  /*!
+   * \brief Constructor.
+   * \param name_supply The NameSupply to be used when generating new GlobalVars.
+   * \param name_to_var_map An optional map.
+   */
+  TVM_DLL explicit GlobalVarSupply(const NameSupply& name_supply,
+                                   std::unordered_map<std::string, GlobalVar> name_to_var_map = {});
+
+  /*!
+   * \brief Constructs a supply from an array of IRModules. GlobalVars generated by this supply are
+   * guaranteed not to conflict with any GlobalVars that belong to the modules. \param modules Array
+   * of IRModules.
+   */
+  TVM_DLL explicit GlobalVarSupply(const Array<IRModule>& modules);
+
+  /*!
+   * \brief Constructs a GlobalVarSupply from an IRModule. GlobalVars generated by this supply are
+   * guaranteed not to conflict with GlobalVars that belong to the modules. \param module The
+   * IRModule.
+   */
+  TVM_DLL explicit GlobalVarSupply(const IRModule module);
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(GlobalVarSupply, ObjectRef, GlobalVarSupplyNode);
+};
+
+}  // namespace tvm
+
+#endif  // TVM_IR_GLOBAL_VAR_SUPPLY_H_
diff --git a/darknet_drp_ros/include/tvm/ir/instrument.h b/darknet_drp_ros/include/tvm/ir/instrument.h
new file mode 100644
index 0000000..1b9eb9c
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/instrument.h
@@ -0,0 +1,157 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/ir/instrument.h
+ *
+ * This file introduces a pass instrument infrastructure, inspired by LLVM and MLIR.
+ * It inserts instrumentation points around passes.
+ */
+#ifndef TVM_IR_INSTRUMENT_H_
+#define TVM_IR_INSTRUMENT_H_
+
+#include <tvm/node/reflection.h>
+#include <tvm/runtime/container/string.h>
+
+#include <utility>
+#include <vector>
+
+namespace tvm {
+
+class IRModule;
+
+// Forward class for PassInstrumentNode methods
+namespace transform {
+class PassInfo;
+}  // namespace transform
+
+namespace instrument {
+
+/*!
+ * \brief PassInstrumentNode forms an instrument implementation.
+ * It provides API for users to register callbacks at different instrumentation points.
+ *
+ * Within a PassContext, call sequence of a PassInstrument implementation is like:
+ *
+ *   with PassContext(instruments=[pi]):  # pi = a PassInstrument implementation
+ *       pi.EnterPassContext()
+ *
+ *       if pi.ShouldRun(Pass1):
+ *           pi.RunBeforePass()
+ *           Pass1()
+ *           pi.RunAfterPass()
+ *
+ *       if pi.ShouldRun(Pass2):
+ *           pi.RunBeforePass()
+ *           Pass2()
+ *           pi.RunAfterPass()
+ *
+ *       pi.ExitPassContext()
+ *
+ * `EnterPassContext` and `ExitPassContext` are only called once when entering/exiting a
+ * PassContext. `ShouldRun`, `RunBeforePass` and `RunAfterPass` are called multiple times depending
+ * on how many passes.
+ *
+ * If there are multiple pass instrumentations provided, the instrument points are the same.
+ * PassInstrument implementations' callbacks are called in order:
+ *
+ *   with PassContext(instruments=[pi1, pi2]):  # pi1, pi2 = two distinct PassInstrument impls
+ *       pi.EnterPassContext() for pi in instruments
+ *
+ *       should_run = all([pi.ShoudRun(Pass1) for pi in instruments)])
+ *       if (should_run)
+ *           pi.RunBeforePass() for pi in instruments
+ *           Pass1()
+ *           pi.RunAfterPass()  for pi in instruments
+ *
+ *       should_run = all([pi.ShouldRun(Pass2) for pi in instruments)])
+ *       if (should_run)
+ *           pi.RunBeforePass() for pi in instruments
+ *           Pass2()
+ *           pi.RunAfterPass() for pi in instruments
+ *
+ *       pi.ExitPassContext() for pi in instruments
+ *
+ * Note:
+ *   1. Assume there is no dependency between PassInstrument implementations in `instruments` .
+ *   2. `EnterPassContext` and `ExitPassContext` have `with` behavior (see PassContext and its FFI):
+ *        If there is any exception raised in `ShouldRun()`, `RunBeforePass()`, `RunAfterPass()` and
+ *        `Pass()`, `ExitPassContext()` is still called.
+ *   3. In mutiple PassInstrument instances scenario, callbacks are called in order:
+ *        If one throws exceptions, remainings will not be called.
+ *
+ * \sa PassInstrument
+ * \sa src/ir/transform.cc
+ */
+class PassInstrumentNode : public Object {
+ public:
+  /*! \brief Name of this pass instrument object. */
+  String name;
+
+  virtual ~PassInstrumentNode() {}
+
+  /*! \brief Instrument when entering PassContext. Called once within a PassContext. */
+  virtual void EnterPassContext() const = 0;
+
+  /*! \brief Instrument when exiting PassContext. Called once within a PassContext. */
+  virtual void ExitPassContext() const = 0;
+
+  /*!
+   * \brief Determine whether to run the pass or not. Called multiple times depend on number of
+   *        passes.
+   * \param mod The module that an optimization pass runs on.
+   * \param info The pass information.
+   *
+   * \return true to run the pass; false to skip the pass.
+   */
+  virtual bool ShouldRun(const IRModule& mod, const transform::PassInfo& info) const = 0;
+
+  /*!
+   * \brief Instrument before pass run. Called multiple times depend on number of passes.
+   * \param mod The module that an optimization pass runs on.
+   * \param info The pass information.
+   */
+  virtual void RunBeforePass(const IRModule& mod, const transform::PassInfo& info) const = 0;
+
+  /*!
+   * \brief Instrument after pass run. Called multiple time depend on number of passes.
+   * \param mod The module that an optimization pass runs on.
+   * \param info The pass information.
+   */
+  virtual void RunAfterPass(const IRModule& mod, const transform::PassInfo& info) const = 0;
+
+  void VisitAttrs(AttrVisitor* v) { v->Visit("name", &name); }
+
+  static constexpr const char* _type_key = "instrument.PassInstrument";
+  TVM_DECLARE_BASE_OBJECT_INFO(PassInstrumentNode, Object);
+};
+
+/*!
+ * \brief Managed reference class for PassInstrumentNode
+ * \sa PassInstrumentNode
+ */
+class PassInstrument : public ObjectRef {
+ public:
+  TVM_DEFINE_OBJECT_REF_METHODS(PassInstrument, ObjectRef, PassInstrumentNode);
+};
+
+}  // namespace instrument
+}  // namespace tvm
+
+#endif  // TVM_IR_INSTRUMENT_H_
diff --git a/darknet_drp_ros/include/tvm/ir/memory_pools.h b/darknet_drp_ros/include/tvm/ir/memory_pools.h
new file mode 100644
index 0000000..ebab13c
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/memory_pools.h
@@ -0,0 +1,361 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/ir/memory_pools.h
+ * \brief The object definition for relay.build argument type of memory pools
+ */
+#ifndef TVM_IR_MEMORY_POOLS_H_
+#define TVM_IR_MEMORY_POOLS_H_
+
+#include <tvm/runtime/registry.h>
+#include <tvm/target/target.h>
+
+struct TVMConstantInfo;
+namespace tvm {
+
+/*!
+ * \brief Describes a pool of memory accessible by one or more targets.
+ */
+struct PoolInfoNode : public Object {
+ public:
+  /*! \brief The name of the memory pool */
+  String pool_name;
+  /*! \brief The expected size hint to be used by the allocator.
+   * The size_hint_bytes is set to kUnrestrictedPoolSizeHint
+   * to indicate the pool is not size restricted.
+   */
+  Integer size_hint_bytes;
+  /*! \brief The clock frequency of the memory in Hz */
+  Integer clock_frequency_hz;
+  /*! \brief The read bandwidth in bytes/cycle */
+  Integer read_bandwidth_bytes_per_cycle;
+  /*! \brief The write bandwidth in bytes/cycle */
+  Integer write_bandwidth_bytes_per_cycle;
+  /*! \brief The read latency in cycles */
+  Integer read_latency_cycles;
+  /*! \brief The write latency in cycles */
+  Integer write_latency_cycles;
+  /*! \brief The burst length in bytes for each Target */
+  Map<Target, Integer> target_burst_bytes;
+  /*! \brief Whether pool is internally generated.
+   * The internal pools will be generated as part of
+   * the entry point code generation of the executor
+   */
+  bool is_internal = false;
+
+  /*! \brief The targets linked to the pool */
+  Array<Target> targets;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("pool_name", &pool_name);
+    v->Visit("targets", &targets);
+    v->Visit("size_hint_bytes", &size_hint_bytes);
+    v->Visit("clock_frequency_hz", &clock_frequency_hz);
+    v->Visit("read_bandwidth_bytes_per_cycle", &read_bandwidth_bytes_per_cycle);
+    v->Visit("write_bandwidth_bytes_per_cycle", &write_bandwidth_bytes_per_cycle);
+    v->Visit("read_latency_cycles", &read_latency_cycles);
+    v->Visit("write_latency_cycles", &write_latency_cycles);
+    v->Visit("target_burst_bytes", &target_burst_bytes);
+    v->Visit("is_internal", &is_internal);
+  }
+
+  bool SEqualReduce(const PoolInfoNode* other, SEqualReducer equal) const {
+    return equal(pool_name, other->pool_name) && equal(size_hint_bytes, other->size_hint_bytes) &&
+           equal(clock_frequency_hz, other->clock_frequency_hz) &&
+           equal(read_bandwidth_bytes_per_cycle, other->read_bandwidth_bytes_per_cycle) &&
+           equal(write_bandwidth_bytes_per_cycle, other->write_bandwidth_bytes_per_cycle) &&
+           equal(read_latency_cycles, other->read_latency_cycles) &&
+           equal(write_latency_cycles, other->write_latency_cycles) &&
+           equal(target_burst_bytes, other->target_burst_bytes) &&
+           equal(is_internal, other->is_internal);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(pool_name);
+    hash_reduce(size_hint_bytes);
+    hash_reduce(clock_frequency_hz);
+    hash_reduce(read_bandwidth_bytes_per_cycle);
+    hash_reduce(write_bandwidth_bytes_per_cycle);
+    hash_reduce(read_latency_cycles);
+    hash_reduce(write_latency_cycles);
+    hash_reduce(target_burst_bytes);
+    hash_reduce(is_internal);
+  }
+
+  static constexpr const char* _type_key = "ir.PoolInfo";
+  TVM_DECLARE_BASE_OBJECT_INFO(PoolInfoNode, Object);
+};
+
+/*!
+ * \brief The string parameter to indicate read and write access to a pool
+ * This needs to be kept in sync with PoolInfo.READ_WRITE_ACCESS in
+ * python/tvm/ir/memory_pools.py
+ */
+static constexpr const char* kTargetPoolReadWriteAccess = "rw";
+
+/*!
+ * \brief The string parameter to indicate read only access to a pool
+ * This needs to be kept in sync with PoolInfo.READ_ONLY_ACCESS in
+ * python/tvm/ir/memory_pools.py
+ */
+static constexpr const char* kTargetPoolReadOnlyAccess = "ro";
+
+/*! \brief The PoolSize is unrestricted for the memory planner */
+static const int kUnrestrictedPoolSizeHint = -1;
+
+/*! \brief The clock frequency is not known */
+static const int kUnknownClockFrequency = -1;
+
+/*! \brief The read bandwidth is not known */
+static const int kUnknownReadBandwidth = -1;
+
+/*! \brief The write bandwidth is not known */
+static const int kUnknownWriteBandwidth = -1;
+
+/*! \brief Base class for WorkspacePoolInfo and ConstantPoolInfo */
+class PoolInfo : public ObjectRef {
+ protected:
+  TVM_DLL PoolInfo(String pool_name, Integer size_hint_bytes = kUnrestrictedPoolSizeHint,
+                   Integer clock_frequency_hz = kUnknownClockFrequency,
+                   Integer read_bandwidth_bytes_per_cycle = kUnknownReadBandwidth,
+                   Integer write_bandwidth_bytes_per_cycle = kUnknownWriteBandwidth,
+                   Integer read_latency_cycles = 0, Integer write_latency_cycles = 0,
+                   Map<Target, Integer> target_burst_bytes = {}, Bool is_internal = Bool(false));
+
+ public:
+  TVM_DEFINE_OBJECT_REF_METHODS(PoolInfo, ObjectRef, PoolInfoNode);
+};
+
+/*!
+ * \brief Describes a pool of memory properties
+ */
+struct PoolInfoPropertiesNode : public Object {
+  /*! \brief The expected size hint to be used by the allocator.
+   * The size_hint_bytes is set to kUnrestrictedPoolSizeHint
+   * to indicate the pool is not size restricted.
+   */
+  Integer size_hint_bytes = kUnrestrictedPoolSizeHint;
+  /*! \brief The clock frequency of the memory in Hz */
+  Integer clock_frequency_hz = kUnknownClockFrequency;
+  /*! \brief The read bandwidth in bytes/cycle */
+  Integer read_bandwidth_bytes_per_cycle = kUnknownReadBandwidth;
+  /*! \brief The write bandwidth in bytes/cycle */
+  Integer write_bandwidth_bytes_per_cycle = kUnknownWriteBandwidth;
+  /*! \brief The read latency in cycles */
+  Integer read_latency_cycles = 0;
+  /*! \brief The write latency in cycles */
+  Integer write_latency_cycles = 0;
+  /*! \brief The burst length in bytes for each Target */
+  Map<Target, Integer> target_burst_bytes{};
+  /*! \brief Whether pool is internally generated.
+   * The internal pools will be generated as part of
+   * the entry point code generation of the executor
+   */
+  bool is_internal = false;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("size_hint_bytes", &size_hint_bytes);
+    v->Visit("clock_frequency_hz", &clock_frequency_hz);
+    v->Visit("read_bandwidth_bytes_per_cycle", &read_bandwidth_bytes_per_cycle);
+    v->Visit("write_bandwidth_bytes_per_cycle", &write_bandwidth_bytes_per_cycle);
+    v->Visit("read_latency_cycles", &read_latency_cycles);
+    v->Visit("write_latency_cycles", &write_latency_cycles);
+    v->Visit("target_burst_bytes", &target_burst_bytes);
+    v->Visit("is_internal", &is_internal);
+  }
+
+  bool SEqualReduce(const PoolInfoPropertiesNode* other, SEqualReducer equal) const {
+    return equal(size_hint_bytes, other->size_hint_bytes) &&
+           equal(clock_frequency_hz, other->clock_frequency_hz) &&
+           equal(read_bandwidth_bytes_per_cycle, other->read_bandwidth_bytes_per_cycle) &&
+           equal(write_bandwidth_bytes_per_cycle, other->write_bandwidth_bytes_per_cycle) &&
+           equal(read_latency_cycles, other->read_latency_cycles) &&
+           equal(write_latency_cycles, other->write_latency_cycles) &&
+           equal(target_burst_bytes, other->target_burst_bytes) &&
+           equal(is_internal, other->is_internal);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(size_hint_bytes);
+    hash_reduce(clock_frequency_hz);
+    hash_reduce(read_bandwidth_bytes_per_cycle);
+    hash_reduce(write_bandwidth_bytes_per_cycle);
+    hash_reduce(read_latency_cycles);
+    hash_reduce(write_latency_cycles);
+    hash_reduce(target_burst_bytes);
+    hash_reduce(is_internal);
+  }
+
+  static constexpr const char* _type_key = "ir.PoolInfoProperties";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PoolInfoPropertiesNode, Object);
+};
+
+class PoolInfoProperties : public ObjectRef {
+ public:
+  TVM_DLL PoolInfoProperties(Integer size_hint_bytes,
+                             Integer clock_frequency_hz = kUnknownClockFrequency,
+                             Integer read_bandwidth_bytes_per_cycle = kUnknownReadBandwidth,
+                             Integer write_bandwidth_bytes_per_cycle = kUnknownWriteBandwidth,
+                             Integer read_latency_cycles = 0, Integer write_latency_cycles = 0,
+                             Map<Target, Integer> target_burst_bytes = {},
+                             Bool is_internal = Bool(false));
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(PoolInfoProperties, ObjectRef, PoolInfoPropertiesNode);
+};
+
+/* \brief Represents RW memory area */
+struct WorkspacePoolInfoNode : public PoolInfoNode {
+  void VisitAttrs(tvm::AttrVisitor* v) { PoolInfoNode::VisitAttrs(v); }
+
+  bool SEqualReduce(const WorkspacePoolInfoNode* other, SEqualReducer equal) const {
+    return PoolInfoNode::SEqualReduce(other, equal);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const { PoolInfoNode::SHashReduce(hash_reduce); }
+
+  static constexpr const char* _type_key = "ir.WorkspacePoolInfo";
+  TVM_DECLARE_FINAL_OBJECT_INFO(WorkspacePoolInfoNode, PoolInfoNode);
+};
+
+class WorkspacePoolInfo : public PoolInfo {
+ public:
+  TVM_DLL WorkspacePoolInfo(
+      String pool_name, Array<Target> targets,
+      PoolInfoProperties properties = PoolInfoProperties(kUnrestrictedPoolSizeHint));
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(WorkspacePoolInfo, PoolInfo, WorkspacePoolInfoNode);
+};
+
+/*
+ * \brief The ConstantInfoNode contains numeric literal in RO pool
+ * Used to initialise RO memory in ConstantPoolInfo
+ */
+struct ConstantInfoNode : public Object {
+  String name_hint;
+  Integer byte_offset;
+  runtime::NDArray data;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("name_hint", &name_hint);
+    v->Visit("byte_offset", &byte_offset);
+    v->Visit("data", &data);
+  }
+
+  bool SEqualReduce(const ConstantInfoNode* other, SEqualReducer equal) const {
+    return equal(name_hint, other->name_hint) && equal(byte_offset, other->byte_offset) &&
+           equal(data, other->data);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(name_hint);
+    hash_reduce(byte_offset);
+    hash_reduce(data);
+  }
+
+  static constexpr const char* _type_key = "ir.ConstantInfo";
+  static constexpr bool _type_has_method_sequal_reduce = true;
+  static constexpr bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_FINAL_OBJECT_INFO(ConstantInfoNode, Object);
+};
+
+class ConstantInfo : public ObjectRef {
+ public:
+  TVM_DLL ConstantInfo(const struct ::TVMConstantInfo* data);
+  ConstantInfo(String name, Integer byte_offset, runtime::NDArray data);
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(ConstantInfo, ObjectRef, ConstantInfoNode);
+};
+
+/* \brief ConstantPoolInfoNode represents an RO memory area initialized with
+ * data from constant_info_array */
+struct ConstantPoolInfoNode : public PoolInfoNode {
+  Array<ConstantInfo> constant_info_array;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    PoolInfoNode::VisitAttrs(v);
+    v->Visit("constant_info_array", &constant_info_array);
+  }
+
+  bool SEqualReduce(const ConstantPoolInfoNode* other, SEqualReducer equal) const {
+    return PoolInfoNode::SEqualReduce(other, equal) &&
+           equal(constant_info_array, other->constant_info_array);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    PoolInfoNode::SHashReduce(hash_reduce);
+    hash_reduce(constant_info_array);
+  }
+
+  static constexpr const char* _type_key = "ir.ConstantPoolInfo";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ConstantPoolInfoNode, PoolInfoNode);
+};
+
+class ConstantPoolInfo : public PoolInfo {
+ public:
+  TVM_DLL ConstantPoolInfo(
+      String pool_name, Array<Target> targets, Array<ConstantInfo> constant_info_array,
+      PoolInfoProperties properties = PoolInfoProperties(kUnrestrictedPoolSizeHint));
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(ConstantPoolInfo, PoolInfo, ConstantPoolInfoNode);
+};
+
+/* \brief A container for WorkspacePoolInfo objects */
+struct WorkspaceMemoryPoolsNode : public Object {
+  Array<PoolInfo> pools;
+
+  void VisitAttrs(tvm::AttrVisitor* v) { v->Visit("pools", &pools); }
+
+  bool SEqualReduce(const WorkspaceMemoryPoolsNode* other, SEqualReducer equal) const {
+    return equal(pools, other->pools);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const { hash_reduce(pools); }
+
+  static constexpr const char* _type_key = "ir.WorkspaceMemoryPools";
+  TVM_DECLARE_FINAL_OBJECT_INFO(WorkspaceMemoryPoolsNode, Object);
+};
+
+class WorkspaceMemoryPools : public ObjectRef {
+ public:
+  TVM_DLL WorkspaceMemoryPools(Array<PoolInfo> pools);
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(WorkspaceMemoryPools, ObjectRef, WorkspaceMemoryPoolsNode);
+};
+
+/* \brief A container for ConstantPoolInfo objects */
+struct ConstantMemoryPoolsNode : public Object {
+  Array<ConstantPoolInfo> pools;
+
+  void VisitAttrs(tvm::AttrVisitor* v) { v->Visit("pools", &pools); }
+
+  bool SEqualReduce(const ConstantMemoryPoolsNode* other, SEqualReducer equal) const {
+    return equal(pools, other->pools);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const { hash_reduce(pools); }
+
+  static constexpr const char* _type_key = "ir.ConstantMemoryPools";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ConstantMemoryPoolsNode, Object);
+};
+
+class ConstantMemoryPools : public ObjectRef {
+ public:
+  TVM_DLL ConstantMemoryPools(Array<ConstantPoolInfo> pools);
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(ConstantMemoryPools, ObjectRef, ConstantMemoryPoolsNode);
+};
+
+}  // namespace tvm
+
+#endif  // TVM_IR_MEMORY_POOLS_H_
diff --git a/darknet_drp_ros/include/tvm/ir/module.h b/darknet_drp_ros/include/tvm/ir/module.h
new file mode 100644
index 0000000..7313b4f
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/module.h
@@ -0,0 +1,550 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/ir/module.h
+ * \brief IRModule that holds the functions and type definitions.
+ */
+#ifndef TVM_IR_MODULE_H_
+#define TVM_IR_MODULE_H_
+
+#include <tvm/ir/adt.h>
+#include <tvm/ir/expr.h>
+#include <tvm/ir/function.h>
+#include <tvm/ir/type.h>
+#include <tvm/parser/source_map.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/map.h>
+#include <tvm/runtime/container/string.h>
+
+#include <string>
+#include <unordered_map>
+#include <unordered_set>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+
+class IRModule;
+
+/*!
+ * \brief IRModule that holds functions and type definitions.
+ *
+ *  IRModule is the basic unit for all IR transformations across the stack.
+ *
+ *  Many operations require access to the global IRModule.
+ *  We pass the IRModule by value in a functional style as an explicit argument,
+ *  but we mutate the Module while optimizing programs.
+ * \sa IRModule
+ */
+class IRModuleNode : public Object {
+ public:
+  /*! \brief A map from ids to all global functions. */
+  Map<GlobalVar, BaseFunc> functions;
+  /*! \brief A map from global type vars to ADT type data. */
+  Map<GlobalTypeVar, TypeData> type_definitions;
+  /*! \brief The source map for the module. */
+  parser::SourceMap source_map;
+  /* \brief Additional attributes storing meta-data about the module. */
+  DictAttrs attrs;
+
+  /*!
+   * \brief Get a module attribute.
+   *
+   * \param attr_key The attribute key.
+   * \param default_value The default value if the key does not exist, defaults to nullptr.
+   *
+   * \return The result
+   *
+   * \tparam TOBjectRef the expected object type.
+   * \throw Error if the key exists but the value does not match TObjectRef
+   *
+   * \code
+   *
+   *  void GetAttrExample(const IRModule& mod) {
+   *    auto value = f->GetAttr<Integer>("AttrKey", 0);
+   *  }
+   *
+   * \endcode
+   */
+  template <typename TObjectRef>
+  Optional<TObjectRef> GetAttr(
+      const std::string& attr_key,
+      Optional<TObjectRef> default_value = Optional<TObjectRef>(nullptr)) const {
+    return attrs.GetAttr(attr_key, default_value);
+  }
+  // variant that uses TObjectRef to enable implicit conversion to default value.
+  template <typename TObjectRef>
+  Optional<TObjectRef> GetAttr(const std::string& attr_key, TObjectRef default_value) const {
+    return GetAttr<TObjectRef>(attr_key, Optional<TObjectRef>(default_value));
+  }
+
+  /*!
+   * \brief Check whether the module has an non-zero integer attr.
+   *
+   * This function can be used to check whether an optional
+   * attribute mark(e.g. inline) exists.
+   *
+   * \param attr_key The key to the attribute.
+   * \return The check result.
+   *
+   * \code
+   *
+   *  void HasNonzeroAttrExample(const IRModule& mod) {
+   *    if (mod->HasNonzeroAttr(attr::kInline)) {
+   *      // inline the function.
+   *    }
+   *  }
+   *
+   * \endcode
+   */
+  bool HasNonzeroAttr(const std::string& attr_key) const { return attrs.HasNonzeroAttr(attr_key); }
+
+  IRModuleNode() : source_map() {}
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("functions", &functions);
+    v->Visit("type_definitions", &type_definitions);
+    v->Visit("global_var_map_", &global_var_map_);
+    v->Visit("global_type_var_map_", &global_type_var_map_);
+    v->Visit("source_map", &source_map);
+    v->Visit("attrs", &attrs);
+  }
+
+  TVM_DLL bool SEqualReduce(const IRModuleNode* other, SEqualReducer equal) const;
+
+  TVM_DLL void SHashReduce(SHashReducer hash_reduce) const;
+
+  /*!
+   * \brief Add a function to the global environment.
+   * \param var The var of the global function.
+   * \param func The function.
+   * \param update Controls whether you can replace a definition in the
+   * environment.
+   */
+  TVM_DLL void Add(const GlobalVar& var, const BaseFunc& func, bool update = false);
+
+  /*!
+   * \brief Add a function to the global environment.
+   * \param var The name of the global function.
+   * \param func The function.
+   *
+   * It does not do type inference as Add does.
+   */
+  TVM_DLL void AddUnchecked(const GlobalVar& var, const BaseFunc& func);
+
+  /*!
+   * \brief Add a type-level definition to the global environment.
+   * \param var The var of the global type definition.
+   * \param type The ADT.
+   * \param update Controls whether you can replace a definition in the
+   * environment.
+   */
+  TVM_DLL void AddTypeDef(const GlobalTypeVar& var, const TypeData& type, bool update = false);
+
+  /*!
+   * \brief Add a type-level definition to the global environment.
+   * \param var The var of the global type definition.
+   * \param type The ADT.
+   * \param update Controls whether you can replace a definition in the
+   * environment.
+   *
+   * It does not do type checking as AddTypeDef does.
+   */
+  TVM_DLL void AddTypeDefUnchecked(const GlobalTypeVar& var, const TypeData& type,
+                                   bool update = false);
+
+  /*!
+   * \brief Update a function in the global environment.
+   * \param var The name of the global function to update.
+   * \param func The new function.
+   */
+  TVM_DLL void Update(const GlobalVar& var, const BaseFunc& func);
+
+  /*!
+   * \brief Update a type definition in the global environment.
+   * \param var The name of the global type definition to update.
+   * \param type The new ADT.
+   */
+  TVM_DLL void UpdateTypeDef(const GlobalTypeVar& var, const TypeData& type);
+
+  /*!
+   * \brief Remove a function from the global environment.
+   * \param var The name of the global function to update.
+   */
+  TVM_DLL void Remove(const GlobalVar& var);
+
+  /*!
+   * \brief Check if the global_var_map_ contains a global variable.
+   * \param name The variable name.
+   * \returns true if contains, otherise false.
+   */
+  TVM_DLL bool ContainGlobalVar(const String& name) const;
+
+  /*!
+   * \brief Check if the global_type_var_map_ contains a global type variable.
+   * \param name The variable name.
+   * \returns true if contains, otherise false.
+   */
+  TVM_DLL bool ContainGlobalTypeVar(const String& name) const;
+
+  /*!
+   * \brief Lookup a global function by its variable.
+   * \param str The unique string specifying the global variable.
+   * \returns The global variable.
+   */
+  TVM_DLL GlobalVar GetGlobalVar(const String& str) const;
+
+  /*!
+   * \brief Collect all global vars defined in this module.
+   * \returns An array of global vars
+   */
+  TVM_DLL Array<GlobalVar> GetGlobalVars() const;
+
+  /*!
+   * \brief Look up a global function by its name.
+   * \param str The unique string specifying the global variable.
+   * \returns The global variable.
+   */
+  TVM_DLL GlobalTypeVar GetGlobalTypeVar(const String& str) const;
+
+  /*!
+   * \brief Collect all global type vars defined in this module.
+   * \returns An array of global type vars
+   */
+  TVM_DLL Array<GlobalTypeVar> GetGlobalTypeVars() const;
+
+  /*!
+   * \brief Find constructor of ADT using name
+   * \param adt name of the ADT the constructor belongs to
+   * \param cons name of the constructor
+   * \returns Constructor of ADT, error if not found
+   */
+  TVM_DLL Constructor GetConstructor(const String& adt, const String& cons) const;
+
+  /*!
+   * \brief Look up a global function by its variable.
+   * \param var The global var to lookup.
+   * \returns The function named by the variable argument.
+   */
+  TVM_DLL BaseFunc Lookup(const GlobalVar& var) const;
+
+  /*!
+   * \brief Look up a global function by its string name
+   * \param name The name of the function.
+   * \returns The function named by the argument.
+   */
+  TVM_DLL BaseFunc Lookup(const String& name) const;
+
+  /*!
+   * \brief Look up a global type definition by its variable.
+   * \param var The var of the global type definition.
+   * \return The type definition.
+   */
+  TVM_DLL TypeData LookupTypeDef(const GlobalTypeVar& var) const;
+
+  /*!
+   * \brief Look up a global type definition by its name.
+   * \param var The name of the global type definition.
+   * \return The type definition.
+   */
+  TVM_DLL TypeData LookupTypeDef(const String& var) const;
+
+  /*!
+   * \brief Look up a constructor by its tag.
+   * \param tag The tag for the constructor.
+   * \return The constructor object.
+   */
+  TVM_DLL Constructor LookupTag(const int32_t tag);
+
+  /*!
+   * \brief Update the functions inside this environment by
+   *        functions in another environment.
+   * \param other The other environment.
+   */
+  TVM_DLL void Update(const IRModule& other);
+
+  /*!
+   * \brief Create a shallow copy of this IRModule.
+   * \returns The shallow copy of the IRModule.
+   */
+  TVM_DLL IRModule ShallowCopy();
+
+  /*!
+   * \brief Import Relay code from the file at path.
+   * \param path The path of the Relay code to import.
+   *
+   * \note The path resolution behavior is standard,
+   * if abosolute will be the absolute file, if
+   * relative it will be resovled against the current
+   * working directory.
+   */
+  TVM_DLL void Import(const String& path);
+
+  /*!
+   * \brief Import Relay code from the file at path, relative to the standard library.
+   * \param path The path of the Relay code to import.
+   */
+  TVM_DLL void ImportFromStd(const String& path);
+
+  /*!
+   * \brief Should Link Parameters into the module
+   * \return Whether the Executor is configured to execute with linked parameters (Default: false)
+   */
+  TVM_DLL Bool ShouldLinkParameters() const;
+
+  /*!
+   * \brief The set of imported files.
+   */
+  TVM_DLL std::unordered_set<String> Imports() const;
+
+  static constexpr const char* _type_key = "IRModule";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_FINAL_OBJECT_INFO(IRModuleNode, Object);
+
+ private:
+  /*! \brief Helper function for registering a typedef's constructors */
+  void RegisterConstructors(const GlobalTypeVar& var, const TypeData& type);
+
+  /*! \brief A map from string names to global variables that
+   * ensures global uniqueness.
+   */
+  Map<String, GlobalVar> global_var_map_;
+
+  /*! \brief A map from string names to global type variables (ADT names)
+   * that ensures global uniqueness.
+   */
+  Map<String, GlobalTypeVar> global_type_var_map_;
+
+  /*! \brief A map from constructor tags to constructor objects
+   * for convenient access
+   */
+  std::unordered_map<int32_t, Constructor> constructor_tag_map_;
+
+  /*! \brief The files previously imported, required to ensure
+      importing is idempotent for each module.
+   */
+  std::unordered_set<String> import_set_;
+  friend class IRModule;
+};
+
+/*!
+ * \brief Managed reference class to IRModuleNode.
+ * \sa IRModuleNode
+ */
+class IRModule : public ObjectRef {
+ public:
+  /*!
+   * \brief constructor
+   * \param functions Functions in the module.
+   * \param type_definitions Type definitions in the module.
+   * \param import_set Set of imported files in the module.
+   * \param map The module source map.
+   * \param attrs The module attributes.
+   */
+  TVM_DLL explicit IRModule(Map<GlobalVar, BaseFunc> functions,
+                            Map<GlobalTypeVar, TypeData> type_definitions = {},
+                            std::unordered_set<String> import_set = {}, parser::SourceMap map = {},
+                            DictAttrs attrs = {});
+
+  /*! \brief default constructor */
+  IRModule() : IRModule(Map<GlobalVar, BaseFunc>({})) {}
+  /*!
+   * \brief constructor
+   * \param n The object pointer.
+   */
+  explicit IRModule(ObjectPtr<Object> n) : ObjectRef(n) {}
+  /*! \return mutable pointers to the node. */
+  IRModuleNode* operator->() const {
+    auto* ptr = get_mutable();
+    ICHECK(ptr != nullptr);
+    return static_cast<IRModuleNode*>(ptr);
+  }
+
+  /*!
+   * \brief Constructs a module from a standalone expression \p expr.
+   *
+   * If \p expr is a function it will be bound directly. Otherwise a function over the free
+   * variables of \p expr (possibly none) with \p expr as body is created and bound.
+   *
+   * The function is bound to, in preference order:
+   *  - The "global_symbol" attribute of \p expr, if it is a function with that attribute.
+   *  - 'main'
+   *  - A unique name derived from 'main' if 'main' is already bound in \p global_funcs.
+   *
+   * Additional global functions and type definitions may be included in the result module.
+   *
+   * See also \p FromExpr.
+   *
+   * \param expr The expression to set as the main function to the module.
+   * \param global_funcs The global function map. Default empty.
+   * \param type_definitions The global type definition map. Default empty.
+   * \param import_set Set of external modules already imported. Default empty.
+   *
+   * \returns A module with \p expr set as the main function, and the global var to which
+   * \p expr was bound (typcially 'main').
+   *
+   * TODO(mbs): Does import_set and the bound global var need to be exposed via ffi?
+   */
+  static std::pair<IRModule, GlobalVar> FromExprInContext(
+      const RelayExpr& expr, const Map<GlobalVar, BaseFunc>& global_funcs = {},
+      const Map<GlobalTypeVar, TypeData>& type_definitions = {},
+      std::unordered_set<String> import_set = {});
+
+  /*!
+   * \brief As for \p FromExprInContext, but assuming \p expr is bound to 'main' and no
+   * imports.
+   */
+  TVM_DLL static IRModule FromExpr(const RelayExpr& expr,
+                                   const Map<GlobalVar, BaseFunc>& global_funcs = {},
+                                   const Map<GlobalTypeVar, TypeData>& type_definitions = {});
+
+  /*!
+   * \brief Parse text format source file into an IRModule.
+   * \param text A string of Relay source code.
+   * \param source_path The path to the source file.
+   * \return A Relay module.
+   */
+  TVM_DLL static IRModule FromText(const String& text, const String& source_path);
+
+  /*!
+   * \brief Create a shallow copy of an IRModule.
+   * \param mod The module to copy.
+   * \return The copied module.
+   */
+  IRModule ShallowCopyIRModule(IRModule mod);
+
+  /*! \brief Declare the container type. */
+  using ContainerType = IRModuleNode;
+
+  /*! \brief Declare whether Ref is nullable. */
+  static constexpr bool _type_is_nullable = false;
+
+  // allow copy on write.
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(IRModuleNode);
+};
+
+/*!
+ * \brief Pretty print a node for debug purposes.
+ *
+ * \param node The node to be printed.
+ * \return The text reperesentation.
+ * \note This function does not show version or meta-data.
+ *       Use AsText if you want to store the text.
+ * \sa AsText.
+ */
+TVM_DLL String PrettyPrint(const ObjectRef& node);
+
+/*!
+ * \brief Render the node as a string in the text format.
+ *
+ * \param node The node to be rendered.
+ * \param show_meta_data Whether to print meta data section.
+ * \param annotate An optional callback function for attaching
+ *        additional comment block to an expr.
+ *
+ * \note We support a limited set of IR nodes that are part of
+ *       relay IR and
+ *
+ * \sa PrettyPrint.
+ * \return The text representation.
+ */
+TVM_DLL String AsText(const ObjectRef& node, bool show_meta_data = true,
+                      runtime::TypedPackedFunc<String(ObjectRef)> annotate = nullptr);
+
+namespace attr {
+
+// Following are attributes for IRModule only.
+
+/*!
+ * \brief Name of the module
+ *
+ * Type: String
+ *
+ * \sa tvm::runtime::String
+ */
+constexpr const char* kModuleName = "mod_name";
+
+/*!
+ * \brief Executor targeted by the module
+ *
+ * Type: Executor
+ *
+ * \sa tvm::relay::Executor
+ */
+constexpr const char* kExecutor = "executor";
+
+/*!
+ * \brief Runtime target of the module
+ *
+ * Type: Runtime
+ *
+ * \sa tvm::relay::Runtime
+ */
+constexpr const char* kRuntime = "runtime";
+
+/*!
+ * \brief workspace memory pools of the module
+ *
+ * Type: WorkspaceMemoryPools
+ *
+ * \sa tvm::WorkspaceMemoryPools
+ */
+constexpr const char* kWorkspaceMemoryPools = "workspace_memory_pools";
+
+/*!
+ * \brief constant memory pools of the module
+ *
+ * Type: ConstantMemoryPools
+ *
+ * \sa tvm::ConstantMemoryPools
+ */
+constexpr const char* kConstantMemoryPools = "constant_memory_pools";
+
+/*
+ * \brief All the runtime::NDArrays extracted from PrimFunc tir::AllocateConst nodes. The
+ * node will record the index into this array. See also kConstNameToConstant below, which is
+ * the analog for Realy Functions.
+ *
+ * Type: Array<runtime::NDArray>
+ */
+constexpr const char* kConstants = "constants";
+
+/*!
+ * \brief All the runtime::Modules accumulated during compilation by external codegen. These
+ * modules must be either directly linked or captured in the final compilation artifact.
+ *
+ * Type: Array<runtime::Module>
+ */
+constexpr const char* kExternalMods = "external_mods";
+
+/*!
+ * \brief All the named runtime::NDArrays accumulated during compilation by external codegen.
+ * Generally the associated runtime::Module will indicate it requires bindings for these names,
+ * and during module initialization these bindings will be recovered from a ConstLoaderModule.
+ * See also kConstantsArray above, which is the analog for PrimFuncs.
+ *
+ * Type: Map<String, runtime::NDArray>
+ */
+constexpr const char* kConstNameToConstant = "const_name_to_constant";
+
+}  // namespace attr
+}  // namespace tvm
+#endif  // TVM_IR_MODULE_H_
diff --git a/darknet_drp_ros/include/tvm/ir/name_supply.h b/darknet_drp_ros/include/tvm/ir/name_supply.h
new file mode 100644
index 0000000..a85a6fe
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/name_supply.h
@@ -0,0 +1,123 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/ir/name_supply.h
+ * \brief NameSupply that can be used to generate unique variable names.
+ */
+#ifndef TVM_IR_NAME_SUPPLY_H_
+#define TVM_IR_NAME_SUPPLY_H_
+
+#include <string>
+#include <unordered_map>
+#include <utility>
+
+#include "tvm/ir/expr.h"
+
+namespace tvm {
+
+/*!
+ * \brief NameSupply can be used to generate unique names.
+ */
+class NameSupplyNode : public Object {
+ public:
+  /*!
+   * \brief Empty constructor. Needed by the TVM_REGISTER_NODE_TYPE macro.
+   */
+  NameSupplyNode() = default;
+
+  /*!
+   * \brief Constructor.
+   * \param prefix The prefix to be used with this NameSupply.
+   * \param name_map The map used to guarantee uniqueness.
+   */
+  NameSupplyNode(const String& prefix, std::unordered_map<std::string, int> name_map)
+      : prefix_(prefix), name_map(std::move(name_map)) {}
+
+  /*!
+   * \brief Generates a unique name from this NameSupply.
+   * \param name The name from which the generated name is derived.
+   * \param add_prefix If set to true, then the prefix of this NameSupply will be prepended to the
+   * name. \return A unique name.
+   */
+  String FreshName(const String& name, bool add_prefix = true);
+
+  /*!
+   * \brief Reserves an existing name with this NameSupply.
+   * \param name The name to be reserved.
+   * \param add_prefix If set to true, then the prefix of this NameSupply will be prepended to the
+   * name before reserving it. \return The name that was reserved with the NameSupply. It can be
+   * different if a prefix is added.
+   */
+  String ReserveName(const String& name, bool add_prefix = true);
+
+  /*!
+   * \brief Checks if this NameSupply already generated a name.
+   * \param name The name to check.
+   * \param add_prefix If set to true, then the prefix of this NameSupply will be prepended to the
+   * name before checking for it. \return True if the name has already been generated. False
+   * otherwise.
+   */
+  bool ContainsName(const String& name, bool add_prefix = true);
+
+  void VisitAttrs(AttrVisitor* v) {}
+
+  // Prefix for all GlobalVar names. It can be empty.
+  std::string prefix_;
+
+  static constexpr const char* _type_key = "NameSupply";
+  static constexpr const bool _type_has_method_sequal_reduce = false;
+  static constexpr const bool _type_has_method_shash_reduce = false;
+  TVM_DECLARE_FINAL_OBJECT_INFO(NameSupplyNode, Object);
+
+ private:
+  /*! \brief Helper function to add the NameSupply prefix to the name. */
+  String add_prefix_to_name(const String& name);
+
+  /*!
+   * \brief Function that will generate a unique name.
+   * \param name The name to be used as a base.
+   * \return A unique name.
+   */
+  std::string GetUniqueName(std::string name);
+
+  /*! \brief A map that is used to generate unique names. */
+  std::unordered_map<std::string, int> name_map;
+};
+
+/*!
+ * \brief Managed reference class to NameSupplyNode.
+ * \sa NameSupplyNode
+ */
+class NameSupply : public ObjectRef {
+ public:
+  /*!
+   * \brief Constructor.
+   * \param prefix The prefix to be used with this NameSupply.
+   * \param name_map An optional map.
+   */
+  TVM_DLL explicit NameSupply(const String& prefix,
+                              std::unordered_map<std::string, int> name_map = {});
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(NameSupply, ObjectRef, NameSupplyNode);
+};
+
+}  // namespace tvm
+
+#endif  // TVM_IR_NAME_SUPPLY_H_
diff --git a/darknet_drp_ros/include/tvm/ir/op.h b/darknet_drp_ros/include/tvm/ir/op.h
new file mode 100644
index 0000000..6e6b8be
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/op.h
@@ -0,0 +1,504 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/ir/op.h
+ * \brief Primitive operators(builtin intrinsics)
+ *        and registry for them.
+ */
+#ifndef TVM_IR_OP_H_
+#define TVM_IR_OP_H_
+
+#include <dmlc/registry.h>
+#include <tvm/ir/attrs.h>
+#include <tvm/ir/expr.h>
+#include <tvm/ir/type.h>
+#include <tvm/ir/type_relation.h>
+#include <tvm/node/attr_registry_map.h>
+#include <tvm/runtime/registry.h>
+
+#include <string>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+
+// forward declare name.
+template <typename>
+class OpAttrMap;
+
+// TODO(tvm-team): migrate low-level intrinsics to use Op
+/*!
+ * \brief Primitive Op(builtin intrinsics)
+ *
+ * This data structure stores the meta-data
+ * about primitive operators that can be invoked via Call.
+ *
+ * Low-level IR intrinsics(such as libc.expf) are also
+ * implemented via Op.
+ *
+ * \sa Op
+ */
+class OpNode : public RelayExprNode {
+ public:
+  /*! \brief name of the operator */
+  String name;
+  /*! \brief the type of the operator */
+  mutable FuncType op_type;
+  /*!
+   * \brief detailed description of the operator
+   *  This can be used to generate docstring automatically for the operator.
+   */
+  String description;
+  /* \brief Information of input arguments to the operator */
+  Array<AttrFieldInfo> arguments;
+  /*!
+   * \brief The type key of the attribute field
+   *  This can be empty, in which case it defaults to anything.
+   */
+  String attrs_type_key;
+  /*!
+   * \brief attribute type index,
+   * this field varies in each run and is not exposed to frontend.
+   */
+  uint32_t attrs_type_index{0};
+  /*!
+   * \brief number of input arguments to the operator,
+   * -1 means it is variable length
+   */
+  int32_t num_inputs = -1;
+  /*!
+   * \brief support level of the operator,
+   *  The lower the more priority it contains.
+   *  This is in analogies to BLAS levels.
+   */
+  int32_t support_level = 10;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("name", &name);
+    v->Visit("op_type", &op_type);
+    v->Visit("description", &description);
+    v->Visit("arguments", &arguments);
+    v->Visit("attrs_type_key", &attrs_type_key);
+    v->Visit("num_inputs", &num_inputs);
+    v->Visit("support_level", &support_level);
+  }
+
+  bool SEqualReduce(const OpNode* other, SEqualReducer equal) const {
+    // pointer equality is fine as there is only one op with the same name.
+    return this == other;
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    // Name uniquely identifies an Op.
+    hash_reduce(name);
+  }
+
+  /*!
+   * \brief Check that if current op is a "primtive operator".
+   * That is the arguments are all type variables, and there is a single
+   * type relation applied to the input and output types.
+   */
+  bool IsPrimitiveOp() const {
+    if (is_primitive_ != -1) return is_primitive_ != 0;
+    is_primitive_ = this->IsPrimitiveOp_() ? 1 : 0;
+    return is_primitive_ != 0;
+  }
+
+  static constexpr const char* _type_key = "Op";
+  TVM_DECLARE_FINAL_OBJECT_INFO(OpNode, RelayExprNode);
+
+ private:
+  /*! \return the internal attr registry index. */
+  uint32_t AttrRegistryIndex() const { return index_; }
+  /*! \brief repr to be printed in registry*/
+  std::string AttrRegistryName() const { return name; }
+
+  // friend class
+  template <typename>
+  friend class AttrRegistryMapContainerMap;
+  template <typename, typename>
+  friend class AttrRegistry;
+  friend class OpRegEntry;
+
+  friend bool IsPrimitiveOp(const RelayExpr&);
+  // Program internal unique index of operator.
+  // Used to help index the program.
+  uint32_t index_{0};
+  // whether this is a primitive op. -1 means unknown.
+  mutable int is_primitive_{-1};
+  // Internal function to compute if it is primitive op
+  bool IsPrimitiveOp_() const {
+    const auto& fn_ty = this->op_type;
+    ICHECK(fn_ty.get() != nullptr) << "op_type of " << this->name << " is not registered";
+    if (fn_ty->type_constraints.size() != 1) return false;
+    const TypeRelationNode* rel = fn_ty->type_constraints[0].as<TypeRelationNode>();
+    if (rel == nullptr) return false;
+    // validate if the type parameter matches up
+    for (size_t i = 0; i < fn_ty->type_params.size(); ++i) {
+      if (!fn_ty->type_params[i].same_as(rel->args[i])) return false;
+    }
+    return true;
+  }
+};
+
+/*!
+ * \brief Managed reference class to OpNode.
+ * \sa OpNode
+ */
+class Op : public RelayExpr {
+ public:
+  /*!
+   * \brief Get additional registered attribute about operators.
+   *  If nothing has been registered, an empty OpAttrMap will be returned.
+   * \param attr_name The name of the attribute.
+   * \return An OpAttrMap of specified attr_name.
+   * \tparam ValueType The type of the attribute.
+   */
+  template <typename ValueType>
+  inline static OpAttrMap<ValueType> GetAttrMap(const String& attr_name);
+  /*!
+   * \brief Checks if an attr map is present in the registry.
+   * \param attr_name The name of the attribute.
+   * \return bool True if the attr is present.
+   */
+  TVM_DLL static bool HasAttrMap(const String& attr_name);
+  /*!
+   * \brief Get an Op for a given operator name.
+   *  Will raise an error if the op has not been registered.
+   * \param op_name Name of the operator.
+   * \return Pointer to a Op, valid throughout program lifetime.
+   */
+  TVM_DLL static const Op& Get(const String& op_name);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Op, RelayExpr, OpNode)
+
+ private:
+  /*!
+   * \brief Get generic attrmap given attr name
+   * \param key The attribute key
+   * \return The attr map.
+   */
+  TVM_DLL static const AttrRegistryMapContainerMap<Op>& GetAttrMapContainer(const String& key);
+};
+
+/*!
+ * \brief Helper structure to register operators
+ * \sa TVM_REGISTER_OP
+ */
+class OpRegEntry {
+ public:
+  /*! \return the operator */
+  const Op& op() const { return op_; }
+  /*!
+   * \brief setter function during registration
+   *  Set the description of operator
+   * \param descr the description string.
+   * \return reference to self.
+   */
+  inline OpRegEntry& describe(const std::string& descr);  // NOLINT(*)
+  /*!
+   * \brief Add argument information to the function.
+   * \param name Name of the argument.
+   * \param type Type of the argument.
+   * \param description Description of the argument.
+   * \return reference to self.
+   */
+  inline OpRegEntry& add_argument(const std::string& name, const std::string& type,
+                                  const std::string& description);
+  /*!
+   * \brief Attach the type function corresponding to the return type.
+   * \param rel_name The type relation name to register.
+   * \param type_rel_func The backing relation function which can solve an arbitrary
+   * relation on variables.
+   * \return reference to self.
+   */
+  inline OpRegEntry& add_type_rel(
+      const std::string& rel_name,
+      runtime::TypedPackedFunc<bool(const Array<Type>&, int, const Attrs&, const TypeReporter&)>
+          type_rel_func);
+  /*!
+   * \brief Set the attrs type key and index to be AttrsType.
+   * \tparam AttrsType the attribute type to b set.
+   * \return reference to self.
+   */
+  template <typename AttrsType>
+  inline OpRegEntry& set_attrs_type();
+  /*!
+   * \brief Set the attrs type key and index to be AttrsType.
+   * \param key The attribute type key to be set.
+   * \return reference to self.
+   */
+  inline OpRegEntry& set_attrs_type_key(const String& key);
+  /*!
+   * \brief Set the num_inputs
+   * \param n The number of inputs to be set.
+   * \return reference to self.
+   */
+  inline OpRegEntry& set_num_inputs(int32_t n);  // NOLINT(*)
+  /*!
+   * \brief Set the support level of op.
+   * \param level The support level.
+   * \return reference to self.
+   */
+  inline OpRegEntry& set_support_level(int32_t level);  // NOLINT(*)
+  /*!
+   * \brief Register additional attributes to operator.
+   * \param attr_name The name of the attribute.
+   * \param value The value to be set.
+   * \param plevel The priority level of this set,
+   *  an higher priority level attribute
+   *  will replace lower priority level attribute.
+   *  Must be bigger than 0.
+   *
+   *  Cannot set with same plevel twice in the code.
+   *
+   * \tparam ValueType The type of the value to be set.
+   */
+  template <typename ValueType>
+  inline OpRegEntry& set_attr(const std::string& attr_name,  // NOLINT(*)
+                              const ValueType& value, int plevel = 10);
+
+  /*!
+   * \brief Resets an attr of the registry.
+   * \param attr_name The name of the attribute.
+   */
+  inline void reset_attr(const std::string& attr_name);
+
+  // set the name of the op to be the same as registry
+  inline OpRegEntry& set_name() {  // NOLINT(*)
+    if (get()->name.length() == 0) {
+      get()->name = name;
+    }
+    return *this;
+  }
+  /*!
+   * \brief Register or get a new entry.
+   * \param name The name of the operator.
+   * \return the corresponding entry.
+   */
+  TVM_DLL static OpRegEntry& RegisterOrGet(const String& name);
+
+ private:
+  template <typename, typename>
+  friend class AttrRegistry;
+  // the name
+  std::string name;
+  /*! \brief The operator */
+  Op op_;
+  // private constructor
+  TVM_DLL OpRegEntry(uint32_t reg_index);
+  // return internal pointer to op.
+  inline OpNode* get();
+  // update the attribute OpAttrMap
+  TVM_DLL void UpdateAttr(const String& key, runtime::TVMRetValue value, int plevel);
+};
+
+/*!
+ * \brief Map<Op,ValueType> used to store meta-information about Op.
+ * \tparam ValueType The type of the value stored in map.
+ */
+template <typename ValueType>
+class OpAttrMap : public AttrRegistryMap<Op, ValueType> {
+ public:
+  /*!
+   * \brief get the corresponding value element at op with default value.
+   * \param expr The key to the map
+   * \param def_value The default value when the key does not exist
+   *         or if expr is not an Op.
+   * \return the const reference to the content value.
+   */
+  inline ValueType get(const RelayExpr& expr, ValueType def_value) const;
+
+  using TParent = AttrRegistryMap<Op, ValueType>;
+  using TParent::count;
+  using TParent::get;
+  using TParent::operator[];
+
+ private:
+  friend class Op;
+  // constructor
+  explicit OpAttrMap(const AttrRegistryMapContainerMap<Op>& map) : TParent(map) {}
+};
+
+// internal macros to make
+#define TVM_OP_REGISTER_VAR_DEF static DMLC_ATTRIBUTE_UNUSED ::tvm::OpRegEntry& __make_##Op
+
+/*!
+ * \def TVM_REGISTER_OP
+ * \brief Register a new operator, or set attribute of the corresponding op.
+ *
+ * \param OpName The name of registry
+ *
+ * \code
+ *
+ *  TVM_REGISTER_OP("add")
+ *  .describe("add two inputs together")
+ *  .set_num_inputs(2)
+ *  .set_attr<OpKernel>("gpu_kernel", AddKernel);
+ *
+ * \endcode
+ */
+#define TVM_REGISTER_OP(OpName)                          \
+  TVM_STR_CONCAT(TVM_OP_REGISTER_VAR_DEF, __COUNTER__) = \
+      ::tvm::OpRegEntry::RegisterOrGet(OpName).set_name()
+
+// implementations
+
+template <typename ValueType>
+inline OpAttrMap<ValueType> Op::GetAttrMap(const String& key) {
+  return OpAttrMap<ValueType>(Op::GetAttrMapContainer(key));
+}
+
+inline OpNode* OpRegEntry::get() { return const_cast<OpNode*>(op_.operator->()); }
+
+inline OpRegEntry& OpRegEntry::describe(const std::string& descr) {  // NOLINT(*)
+  get()->description = descr;
+  return *this;
+}
+
+inline OpRegEntry& OpRegEntry::add_argument(const std::string& name, const std::string& type,
+                                            const std::string& description) {
+  auto n = make_object<AttrFieldInfoNode>();
+  n->name = name;
+  n->type_info = type;
+  n->description = description;
+  get()->arguments.push_back(AttrFieldInfo(n));
+  return *this;
+}
+
+inline OpRegEntry& OpRegEntry::add_type_rel(
+    const std::string& rel_name,
+    runtime::TypedPackedFunc<bool(const Array<Type>&, int, const Attrs&, const TypeReporter&)>
+        type_rel_func) {
+  auto func_name = std::string("tvm.relay.type_relation.") + rel_name;
+  TypeRelationFn env_type_rel_func;
+
+  if (runtime::Registry::Get(func_name)) {
+    auto env_func = EnvFunc::Get(func_name);
+    env_type_rel_func = env_func;
+  } else {
+    runtime::Registry::Register(func_name).set_body(type_rel_func.packed());
+    auto env_func = EnvFunc::Get(func_name);
+    env_type_rel_func = env_func;
+  }
+
+  Array<TypeVar> type_params;
+  Array<Type> arg_types;
+
+  // Add inputs.
+  std::string input_name_prefix = "in";
+  for (int i = 0; i < get()->num_inputs; i++) {
+    auto name = input_name_prefix + std::to_string(i);
+    auto param = TypeVar(name, TypeKind::kType);
+    type_params.push_back(param);
+    arg_types.push_back(param);
+  }
+
+  Array<Type> ty_call_args = arg_types;
+
+  // Add output type.
+  auto out_param = TypeVar("out", TypeKind::kType);
+  type_params.push_back(out_param);
+  // this will trigger copy on write.
+  ty_call_args.push_back(out_param);
+
+  // The attributes of primitive op is nullptr
+  //
+  // The attributes of primitive operator can vary at the call site.
+  // The type of sum is also dependent on Attrs being passed.
+  // So puting nullptr in the Attrs means that the operator is polymorphic on Attrs.
+  //
+  // A common example is sum(x, axis), where the choice of axis
+  // can affect the type of the function.
+  TypeConstraint type_rel =
+      TypeRelation(env_type_rel_func, ty_call_args, arg_types.size(), Attrs());
+
+  auto func_type = FuncType(arg_types, out_param, type_params, {type_rel});
+
+  get()->op_type = func_type;
+
+  return *this;
+}
+
+inline OpRegEntry& OpRegEntry::set_num_inputs(int32_t n) {  // NOLINT(*)
+  get()->num_inputs = n;
+  return *this;
+}
+
+template <typename AttrsType>
+inline OpRegEntry& OpRegEntry::set_attrs_type() {  // NOLINT(*)
+  get()->attrs_type_key = AttrsType::_type_key;
+  get()->attrs_type_index = AttrsType::RuntimeTypeIndex();
+  return *this;
+}
+
+inline OpRegEntry& OpRegEntry::set_attrs_type_key(const String& key) {  // NOLINT(*)
+  get()->attrs_type_key = key;
+  get()->attrs_type_index = Object::TypeKey2Index(key);
+  return *this;
+}
+
+inline OpRegEntry& OpRegEntry::set_support_level(int32_t n) {  // NOLINT(*)
+  get()->support_level = n;
+  return *this;
+}
+
+template <typename ValueType>
+inline OpRegEntry& OpRegEntry::set_attr(  // NOLINT(*)
+    const std::string& attr_name, const ValueType& value, int plevel) {
+  ICHECK_GT(plevel, 0) << "plevel in set_attr must be greater than 0";
+  runtime::TVMRetValue rv;
+  rv = value;
+  UpdateAttr(attr_name, rv, plevel);
+  return *this;
+}
+
+// member functions of OpAttrMap
+
+template <typename ValueType>
+inline ValueType OpAttrMap<ValueType>::get(const RelayExpr& expr, ValueType def_value) const {
+  ICHECK(expr.defined());
+  if (const OpNode* op = expr.as<OpNode>()) {
+    return this->map_.get(GetRef<Op>(op), def_value);
+  } else {
+    return def_value;
+  }
+}
+
+/*!
+ * \brief Check that an expression is a "primitive operator".
+ *
+ * Will return true if the expression is an operator which
+ * matches the form of primitive operators registered directly
+ * by the Relay codebase.
+ *
+ * That is the arguments are all type variables, and there is a single
+ * type relation applied to the input and output types.
+ *
+ * \param expr An expression.
+ * \return Whether the expression is primitive op.
+ */
+inline bool IsPrimitiveOp(const RelayExpr& expr) {
+  const auto* op = expr.as<OpNode>();
+  return op != nullptr && op->IsPrimitiveOp();
+}
+
+}  // namespace tvm
+#endif  // TVM_IR_OP_H_
diff --git a/darknet_drp_ros/include/tvm/ir/span.h b/darknet_drp_ros/include/tvm/ir/span.h
new file mode 100644
index 0000000..b53ca29
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/span.h
@@ -0,0 +1,126 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/ir/span.h
+ * \brief Span information for debugging purposes.
+ */
+#ifndef TVM_IR_SPAN_H_
+#define TVM_IR_SPAN_H_
+
+#include <tvm/node/node.h>
+#include <tvm/runtime/object.h>
+
+#include <string>
+
+namespace tvm {
+/*!
+ * \brief The source name in the Span
+ * \sa SourceNameNode, Span
+ */
+class SourceName;
+/*!
+ * \brief The name of a source fragment.
+ */
+class SourceNameNode : public Object {
+ public:
+  /*! \brief The source name. */
+  String name;
+  // override attr visitor
+  void VisitAttrs(AttrVisitor* v) { v->Visit("name", &name); }
+
+  static constexpr bool _type_has_method_sequal_reduce = true;
+
+  bool SEqualReduce(const SourceNameNode* other, SEqualReducer equal) const {
+    return equal(name, other->name);
+  }
+
+  static constexpr const char* _type_key = "SourceName";
+  TVM_DECLARE_FINAL_OBJECT_INFO(SourceNameNode, Object);
+};
+
+/*!
+ * \brief The source name of a file span.
+ * \sa SourceNameNode, Span
+ */
+class SourceName : public ObjectRef {
+ public:
+  /*!
+   * \brief Get an SourceName for a given operator name.
+   *  Will raise an error if the source name has not been registered.
+   * \param name Name of the operator.
+   * \return SourceName valid throughout program lifetime.
+   */
+  TVM_DLL static SourceName Get(const String& name);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(SourceName, ObjectRef, SourceNameNode);
+};
+
+/*!
+ * \brief Span information for debugging purposes
+ */
+class Span;
+/*!
+ * \brief Stores locations in frontend source that generated a node.
+ */
+class SpanNode : public Object {
+ public:
+  /*! \brief The source name. */
+  SourceName source_name;
+  /*! \brief The line number. */
+  int line;
+  /*! \brief The column offset. */
+  int column;
+  /*! \brief The end line number. */
+  int end_line;
+  /*! \brief The end column number. */
+  int end_column;
+
+  // override attr visitor
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("source_name", &source_name);
+    v->Visit("line", &line);
+    v->Visit("column", &column);
+    v->Visit("end_line", &end_line);
+    v->Visit("end_column", &end_column);
+  }
+  static constexpr bool _type_has_method_sequal_reduce = true;
+
+  bool SEqualReduce(const SpanNode* other, SEqualReducer equal) const {
+    return equal(source_name, other->source_name) && equal(line, other->line) &&
+           equal(column, other->column) && equal(end_line, other->end_line) &&
+           equal(end_column, other->end_column);
+  }
+
+  static constexpr const char* _type_key = "Span";
+  TVM_DECLARE_FINAL_OBJECT_INFO(SpanNode, Object);
+};
+
+class Span : public ObjectRef {
+ public:
+  TVM_DLL Span(SourceName source_name, int line, int end_line, int column, int end_column);
+
+  /*! \brief Merge two spans into one which captures the combined regions. */
+  TVM_DLL Span Merge(const Span& other) const;
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Span, ObjectRef, SpanNode);
+};
+
+}  // namespace tvm
+#endif  // TVM_IR_SPAN_H_
diff --git a/darknet_drp_ros/include/tvm/ir/tensor_type.h b/darknet_drp_ros/include/tvm/ir/tensor_type.h
new file mode 100644
index 0000000..7a70025
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/tensor_type.h
@@ -0,0 +1,127 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/ir/tensor_type.h
+ * \brief Polymorphic tensor types.
+ */
+#ifndef TVM_IR_TENSOR_TYPE_H_
+#define TVM_IR_TENSOR_TYPE_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/ir/type.h>
+
+namespace tvm {
+/*!
+ * \brief Base of all Tensor types
+ *  This container can hold TensorType or GenericTensorType.
+ * \sa BaseTensorType, TensorTypeNode
+ */
+class BaseTensorTypeNode : public TypeNode {
+ public:
+  static constexpr const char* _type_key = "relay.BaseTensorType";
+  static constexpr const uint32_t _type_child_slots = 1;
+  TVM_DECLARE_BASE_OBJECT_INFO(BaseTensorTypeNode, TypeNode);
+};
+
+/*!
+ * \brief Managed reference to BaseTensorTypeNode.
+ * \sa BaseTensorTypeNode.
+ */
+class BaseTensorType : public Type {
+ public:
+  TVM_DEFINE_OBJECT_REF_METHODS(BaseTensorType, Type, BaseTensorTypeNode);
+};
+
+/*!
+ * \brief This is the most commonly used type in relay.
+ *  TensorType have a fixed dimension, data type.
+ *
+ *  The elements of shape can be either IntImm(constant integer),
+ *  or any symbolic integer expression.
+ *  The symbolic integer allows generic shape inference in certain cases.
+ * \sa TensorType
+ */
+class TensorTypeNode : public BaseTensorTypeNode {
+ public:
+  /*!
+   * \brief The shape of the tensor,
+   *  represented by PrimExpr(tvm::Expr).
+   */
+  Array<PrimExpr> shape;
+  /*! \brief The content data type */
+  DataType dtype;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("shape", &shape);
+    v->Visit("dtype", &dtype);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const TensorTypeNode* other, SEqualReducer equal) const {
+    return equal(shape, other->shape) && equal(dtype, other->dtype);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(shape);
+    hash_reduce(dtype);
+  }
+
+  /*! \brief Return product of elements in the shape.
+   *  \return (d1 * d_2 ... * d_n) if shape is (d_1, d_2, ..., d_n) and 1 if shape size is zero.
+   */
+  TVM_DLL PrimExpr Size() const;
+
+  static constexpr const char* _type_key = "relay.TensorType";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TensorTypeNode, BaseTensorTypeNode);
+};
+
+/*!
+ * \brief Managed reference to TensorTypeNode.
+ * \sa TensorTypeNode.
+ */
+class TensorType : public Type {
+ public:
+  /*!
+   * \brief Constructor.
+   * \param shape The shape of the tensor.
+   * \param dtype The runtime dtype of the tensor's elements.
+   */
+  TVM_DLL TensorType(Array<PrimExpr> shape, DataType dtype);
+
+  /*!
+   * \brief Construct an scalar containing elements of dtype.
+   * \param dtype The runtime dtype of the tensor's elements.
+   * \return THe constructed type.
+   */
+  TVM_DLL static TensorType Scalar(DataType dtype);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(TensorType, Type, TensorTypeNode);
+};
+
+// The following fields contains advanced typing
+// Only keep the class name and reserved for future usage.
+class GenericTensorType;
+// stores a DataType.
+class GenericDataType;
+// stores a DataType.
+class GenericShape;
+
+}  // namespace tvm
+#endif  // TVM_IR_TENSOR_TYPE_H_
diff --git a/darknet_drp_ros/include/tvm/ir/transform.h b/darknet_drp_ros/include/tvm/ir/transform.h
new file mode 100644
index 0000000..febcca5
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/transform.h
@@ -0,0 +1,508 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/ir/transform.h
+ *
+ * This file implements a pass manager. The pass manager manages a sequence
+ * of IRModule -> IRModule transformation passes over a particlar unit of AST. The
+ * design is largely inspired from LLVM's pass manager and modern deep learning
+ * frameworks that perform tensor->tensor transformations.
+ *
+ * The responsibilities of a traditional compiler pass manager usually involves:
+ *  - Organizing the execution order of optimization passes though not
+ * necessarily in the optimal sequence.
+ *  - Collecting required analysis information and keep them up-to-date.
+ *  - Reducing the effort required to implement new passes for compiler
+ * developers, etc.
+ *
+ * Similar to LLVM's pass manager, we designed the Relay pass manager to work
+ * different granularity, i.e. module level, function level, and even sequential
+ * passe that contains a host of passes.
+ *
+ * However, we also extend the functionality of the traditional pass manager
+ * with the consideration of requirements/convention from deep learning
+ * frameworks, such as Pytorch and Gluon, etc. Each pass in the Relay pass
+ * manager performs the IRModule -> IRModule transformation. All
+ * different types of passes, including the sequential-level pass object, are
+ * essentially pass objects. This design, therefore, effectively provides users
+ * a consistent and convenient interface, i.e. Pass, to play with. It offers a
+ * means to ease the development and testing of Relay passes. For example, with
+ * the pass manager, external users will be able to have custom passes correctly
+ * scheduled without having to modify a single handcrafted pass order.
+ *
+ * In the future we need to describe constraints between passes. For example,
+ * we may want to preserve dependencies between different passes and validate
+ * them on the completion of a certain pass.
+ *
+ * We also need to store side information and import the error reporting system.
+ */
+#ifndef TVM_IR_TRANSFORM_H_
+#define TVM_IR_TRANSFORM_H_
+
+#include <tvm/ir/diagnostic.h>
+#include <tvm/ir/error.h>
+#include <tvm/ir/instrument.h>
+#include <tvm/ir/module.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/support/with.h>
+
+#include <string>
+#include <utility>
+
+namespace tvm {
+namespace transform {
+
+/*!
+ * \brief PassContextNode contains the information that a pass can rely on,
+ * such as analysis results.
+ * \sa PassContext
+ */
+class PassContextNode : public Object {
+ public:
+  /*! \brief The default optimization level. */
+  int opt_level{2};
+
+  /*! \brief The list of required passes. */
+  Array<String> required_pass;
+  /*! \brief The list of disabled passes. */
+  Array<String> disabled_pass;
+  /*! \brief The diagnostic context. */
+  mutable Optional<DiagnosticContext> diag_ctx;
+  /*! \brief Pass specific configurations. */
+  Map<String, ObjectRef> config;
+
+  /*! \brief A list of pass instrument implementations. */
+  Array<instrument::PassInstrument> instruments;
+
+  PassContextNode() = default;
+
+  /*!
+   * \brief Get a config value from the pass context.
+   *
+   * \param key The config key.
+   * \param default_value The default value if the key does not exist, defaults to nullptr.
+   *
+   * \return The result
+   *
+   * \tparam TOBjectRef the expected object type.
+   * \throw Error if the key exists but the value does not match TObjectRef.
+   */
+  template <typename TObjectRef>
+  Optional<TObjectRef> GetConfig(const std::string& key, Optional<TObjectRef> default_value =
+                                                             Optional<TObjectRef>(nullptr)) const {
+    static_assert(std::is_base_of<ObjectRef, TObjectRef>::value,
+                  "Can only call GetAttr with ObjectRef types.");
+    if (!config.defined()) return default_value;
+    auto it = config.find(key);
+    if (it != config.end()) {
+      return Downcast<Optional<TObjectRef>>((*it).second);
+    } else {
+      return default_value;
+    }
+  }
+  // variant that uses TObjectRef to enable implicit conversion to default value.
+  template <typename TObjectRef>
+  Optional<TObjectRef> GetConfig(const std::string& key, TObjectRef default_value) const {
+    return GetConfig<TObjectRef>(key, Optional<TObjectRef>(default_value));
+  }
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("opt_level", &opt_level);
+    v->Visit("required_pass", &required_pass);
+    v->Visit("disabled_pass", &disabled_pass);
+    v->Visit("instruments", &instruments);
+    v->Visit("config", &config);
+    v->Visit("diag_ctx", &diag_ctx);
+  }
+
+  static constexpr const char* _type_key = "transform.PassContext";
+  static constexpr bool _type_has_method_sequal_reduce = false;
+  TVM_DECLARE_FINAL_OBJECT_INFO(PassContextNode, Object);
+};
+
+/*!
+ * \brief PassContext that is used to configure the pass behavior.
+ *
+ * \code
+ *
+ *  auto new_ctx = PassContext::Create();
+ *  ctx->opt_level = 2;
+ *  With<PassContext> scope(ctx);
+ *  // pass context in effect.
+ *
+ * \endcode
+ * \sa PassContextNode
+ */
+class PassContext : public ObjectRef {
+ public:
+  PassContext() {}
+  explicit PassContext(ObjectPtr<Object> n) : ObjectRef(n) {}
+  /*!
+   * \brief const accessor.
+   * \return const access pointer.
+   */
+  const PassContextNode* operator->() const {
+    ICHECK(get() != nullptr);
+    return static_cast<const PassContextNode*>(get());
+  }
+  /*!
+   * \brief mutable accessor.
+   * \return mutable access pointer.
+   */
+  PassContextNode* operator->() {
+    ICHECK(get() != nullptr);
+    return static_cast<PassContextNode*>(get_mutable());
+  }
+
+  /*!
+   * \brief Construct a PassContext containing the default configurations.
+   * \return The new PassContext.
+   */
+  TVM_DLL static PassContext Create();
+  /*!
+   * \brief Get the default pass context in the current scope.
+   * \return The pass context.
+   */
+  TVM_DLL static PassContext Current();
+
+  /*!
+   * \brief Get all supported configuration names and metadata, registered within the PassContext.
+   * \return Map indexed by the config name, pointing to the metadata map as key-value
+   */
+  TVM_DLL static Map<String, Map<String, String>> ListConfigs();
+
+  /*!
+   * \brief Call instrument implementations' callbacks when entering PassContext.
+   *        The callbacks are called in order, and if one raises an exception, the rest will not be
+   *        called.
+   */
+  TVM_DLL void InstrumentEnterPassContext();
+
+  /*!
+   * \brief Call instrument implementations' callbacks when exiting PassContext.
+   *        The callbacks are called in order, and if one raises an exception, the rest will not be
+   *        called.
+   */
+  TVM_DLL void InstrumentExitPassContext();
+
+  /*!
+   * \brief Call instrument implementations' callbacks before a pass run.
+   *        The callbacks are called in order, and if one raises an exception, the rest will not be
+   *        called.
+   *
+   * \param mod The module that an optimization pass runs on.
+   * \param info The pass information.
+   *
+   * \return false: the pass is skipped; true: the pass runs.
+   */
+  TVM_DLL bool InstrumentBeforePass(const IRModule& mod, const PassInfo& info) const;
+
+  /*!
+   * \brief Call instrument implementations callbacks after a pass run.
+   *        The callbacks are called in order, and if one raises an exception, the rest will not be
+   *        called.
+   *
+   * \param mod The module that an optimization pass runs on.
+   * \param info The pass information.
+   */
+  TVM_DLL void InstrumentAfterPass(const IRModule& mod, const PassInfo& info) const;
+
+  /*!
+   * \brief Check whether a pass is enabled.
+   * \param info The pass information.
+   * \return true if the pass is enabled. Otherwise, false.
+   */
+  TVM_DLL bool PassEnabled(const PassInfo& info) const;
+
+  /*!
+   * \brief Register a valid configuration option and its ValueType for validation.
+   *
+   * \param key The configuration key.
+   * \tparam ValueType The value type to be registered
+   */
+  template <typename ValueType>
+  static uint32_t RegisterConfigOption(const char* key) {
+    using ValueNodeType = typename ValueType::ContainerType;
+    // NOTE: we could further update the function later.
+    uint32_t tindex = ValueNodeType::_GetOrAllocRuntimeTypeIndex();
+    RegisterConfigOption(key, tindex);
+    return tindex;
+  }
+
+  // accessor.
+  using ContainerType = PassContextNode;
+  class Internal;
+
+ private:
+  // The entry of a pass context scope.
+  TVM_DLL void EnterWithScope();
+  // The exit of a pass context scope.
+  TVM_DLL void ExitWithScope();
+  // Register configuration key value type.
+  TVM_DLL static void RegisterConfigOption(const char* key, uint32_t value_type_index);
+
+  // Classes to get the Python `with` like syntax.
+  friend class Internal;
+  friend class With<PassContext>;
+};
+
+#define TVM_PASS_CTX_CONFIG_VAR_DEF static TVM_ATTRIBUTE_UNUSED uint32_t __make_PassContext_tid
+
+/*!
+ * \brief Helper macro to register the object type to runtime.
+ *  Makes sure that the runtime type table is correctly populated.
+ *
+ *  Use this macro in the cc file for each terminal class.
+ */
+#define TVM_REGISTER_PASS_CONFIG_OPTION(Key, ValueType)      \
+  TVM_STR_CONCAT(TVM_PASS_CTX_CONFIG_VAR_DEF, __COUNTER__) = \
+      ::tvm::transform::PassContext::RegisterConfigOption<ValueType>(Key)
+
+/*!
+ * \brief Meta data that will be used to help optimization and analysis.
+ * \sa PassInfo
+ */
+class PassInfoNode : public Object {
+ public:
+  /*! \brief The minimal optimization level that this pass will be enabled. */
+  int opt_level;
+
+  /*! \brief The name of an optimization/analysis pass. */
+  String name;
+
+  /*! \brief The passes that are required to perform the current pass. */
+  Array<String> required;
+
+  PassInfoNode() = default;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("opt_level", &opt_level);
+    v->Visit("name", &name);
+    v->Visit("required", &required);
+  }
+
+  static constexpr const char* _type_key = "transform.PassInfo";
+  static constexpr bool _type_has_method_sequal_reduce = false;
+  TVM_DECLARE_FINAL_OBJECT_INFO(PassInfoNode, Object);
+};
+
+/*!
+ * \brief Managed reference class for PassInfoNode
+ * \sa PassInfoNode
+ */
+class PassInfo : public ObjectRef {
+ public:
+  /*!
+   * \brief Constructor
+   * \param opt_level The optimization level
+   * \param name Name of the pass.
+   * \param required  The passes that are required to perform the current pass.
+   */
+  TVM_DLL PassInfo(int opt_level, String name, Array<runtime::String> required);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(PassInfo, ObjectRef, PassInfoNode);
+};
+
+/*!
+ * \brief PassNode is the base type of differnt types of optimization passes.
+ * It is designed as a pure class and implemented by different pass subclasses
+ * at different granularity of Relay nodes.
+ */
+class PassNode : public Object {
+ public:
+  virtual ~PassNode() {}
+  /*!
+   * \brief Get the pass information/meta data. */
+  virtual PassInfo Info() const = 0;
+
+  /*!
+   * \brief Transform mod using the default PassContext in the current scope.
+   *
+   * \param mod The module that an optimization pass runs on.
+   *
+   * \return The transformed module.
+   */
+  IRModule operator()(IRModule mod) const {
+    return this->operator()(std::move(mod), PassContext::Current());
+  }
+
+  /*!
+   * \brief Transform mod using a functor under a given pass context.
+   *
+   * \param mod The module that an optimization pass runs on.
+   * \param pass_ctx The pass context that can provide information for the optimization.
+   *
+   * \return The transformed module.
+   */
+  virtual IRModule operator()(IRModule mod, const PassContext& pass_ctx) const = 0;
+
+  void VisitAttrs(AttrVisitor* v) {}
+
+  static constexpr const char* _type_key = "transform.Pass";
+  TVM_DECLARE_BASE_OBJECT_INFO(PassNode, Object);
+};
+
+class Pass : public ObjectRef {
+ public:
+  /*!
+   * \brief Transform mod using the default PassContext in the current scope.
+   *
+   * \code
+   *
+   * // If you do no longer need the input module
+   * // it is recommended to use std::move to move your input module.
+   * mod = pass(std::move(mod));
+   *
+   * \endcode
+   *
+   * \param mod The module that an optimization pass runs on.
+   *
+   * \return The transformed module.
+   */
+  IRModule operator()(IRModule mod) const;
+
+  /*!
+   * \brief Transform mod using a functor under a given pass context.
+   *
+   * \param mod The module that an optimization pass runs on.
+   * \param pass_ctx The pass context that can provide information for the optimization.
+   *
+   * \return The transformed module.
+   */
+  IRModule operator()(IRModule mod, const PassContext& pass_ctx) const;
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Pass, ObjectRef, PassNode);
+
+ private:
+  IRModule static AssertImmutableModule(const IRModule& mod, const PassNode* node,
+                                        const PassContext& pass_ctx);
+};
+
+/*!
+ * \brief The SequentialNode contains a set of passes that transform Relay
+ * programs from one AST to another semantically equivalent one.
+ *
+ * One example of this level of pass is that the pass manager needs to correctly
+ * perform a host of optimizations with a given optimization level and disabled
+ * passes.
+ */
+class SequentialNode : public PassNode {
+ public:
+  /* \brief The pass meta data.*/
+  PassInfo pass_info;
+
+  /*! \brief A list of passes that used to compose a sequential pass. */
+  tvm::Array<Pass> passes;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("pass_info", &pass_info);
+    v->Visit("passes", &passes);
+  }
+
+  /*!
+   * \brief Get the pass information/meta data.
+   */
+  PassInfo Info() const override { return pass_info; }
+
+  /*!
+   * \brief Resolve the pass dependency. It globs all required passes by
+   *        a given pass and executes them.
+   *
+   * \param mod The module that an optimization pass runs on.
+   *
+   * \return The updated module after resolving pass dependencies.
+   *
+   * TODO(zhiics) Build a dependency graph among the passes using provided
+   * metadata, i.e. required_passes. Likely, we can have a data structure, i.e.
+   * PassInfo, to store the relevant information including the parent passes.
+   */
+  void ResolveDependency(const IRModule& mod);
+
+  /*!
+   * \brief Perform optimizations on a series of passes. The aforementioned
+   *        typical pass manager jobs could be done by it. This function could
+   *        be overloaded to focus on different metrics, i.e. performance,
+   *        memory footprint, etc.
+   *
+   * \param mod The module that these passes are applied on.
+   * \param pass_ctx The context that these passes execute on.
+   *
+   * \return Return the updated module.
+   */
+  IRModule operator()(IRModule mod, const PassContext& pass_ctx) const final;
+
+  static constexpr const char* _type_key = "transform.Sequential";
+  TVM_DECLARE_FINAL_OBJECT_INFO(SequentialNode, PassNode);
+};
+
+class Sequential : public Pass {
+ public:
+  /*!
+   * \brief The constructor of `Sequential`.
+   *
+   * \param passes The passes to apply.
+   * \param pass_info The pass metadata.
+   */
+  TVM_DLL Sequential(Array<Pass> passes, PassInfo pass_info);
+
+  /*!
+   * \brief The constructor of `Sequential`.
+   *
+   * \param passes The passes to apply.
+   * \param name The name of a sequential pass. It's defaulted to "sequential".
+   *        This allows users to only provide a list of passes and execute them
+   *        under a given context.
+   */
+  TVM_DLL Sequential(Array<Pass> passes, String name = "sequential");
+
+  Sequential() = default;
+  explicit Sequential(ObjectPtr<Object> n) : Pass(n) {}
+
+  const SequentialNode* operator->() const;
+  using ContainerType = SequentialNode;
+};
+
+/*
+ * \brief Create a module pass.
+ *
+ * \param pass_func The packed function that contains the optimization.
+ * \param opt_level The optimization level of the module pass.
+ * \param name The name of the module pass.
+ * \param required The list of the passes that the module pass is dependent on.
+ *
+ * \return The created module pass.
+ */
+TVM_DLL Pass
+CreateModulePass(const runtime::TypedPackedFunc<IRModule(IRModule, PassContext)>& pass_func,
+                 int opt_level, String name, Array<runtime::String> required);
+
+/*!
+ * \brief A special trace pass that prints the header and IR to LOG(INFO).
+ * \param header The header to be attached to the output.
+ * \param show_meta_data Whether should we show meta data.
+ * \return The pass.
+ */
+TVM_DLL Pass PrintIR(String header = "", bool show_meta_data = false);
+
+}  // namespace transform
+}  // namespace tvm
+
+#endif  // TVM_IR_TRANSFORM_H_
diff --git a/darknet_drp_ros/include/tvm/ir/type.h b/darknet_drp_ros/include/tvm/ir/type.h
new file mode 100644
index 0000000..579061e
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/type.h
@@ -0,0 +1,563 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/ir/type.h
+ * \brief IR/AST nodes for the unified type system in TVM.
+ *
+ * We use Relay's type system as the unified type system
+ * throughout the stack.
+ *
+ * This file contains types that are common across IR variants.
+ *
+ * ## Relation between Type and runtime::DataType
+ *
+ * Besides Type, we also store a dtype field in the low-level PrimExpr.
+ * runtime::DataType(dtype) provides coarse grained type information
+ * during compile time and runtime. It is eagerly built in
+ * low-level expression construction and can be used for
+ * quick type checking in the low-level IR.
+ * For example, when an Expr's dtype is int32,
+ * we know for sure that its type is also int32.
+ *
+ * On the other hand, Type provides more fine grained information.
+ * For example, a low level expression can have DataType::Handle() as
+ * its dtype and MemRef[float32] as its type.
+ * Types are usually lazily constructed via type checking,
+ * so they may not readily be available during IR construction.
+ *
+ * The unified Type serves as a common bridge across IR dialects.
+ * For example, we require all the functions to have a type signature,
+ * which allow us to build cross dialect function calls.
+ */
+#ifndef TVM_IR_TYPE_H_
+#define TVM_IR_TYPE_H_
+
+#include <tvm/ir/span.h>
+#include <tvm/node/node.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/data_type.h>
+#include <tvm/runtime/object.h>
+
+#include <string>
+
+namespace tvm {
+
+/*!
+ * \brief Type is the base type of all types.
+ *
+ * Relay's type system contains following subclasses:
+ *
+ * - PrimType: type of primitive type values used in the low-level IR.
+ * - FuncType: type of a function.
+ * - TensorType: type of certain Tensor values in the expression.
+ *
+ * There are also advanced types to support generic(polymorphic types).
+ * \sa Type
+ */
+class TypeNode : public Object {
+ public:
+  /*!
+   * \brief Span that points to the original source code.
+   *        Reserved debug information.
+   */
+  mutable Span span;
+
+  static constexpr const char* _type_key = "Type";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  static constexpr const uint32_t _type_child_slots = 14;
+  TVM_DECLARE_BASE_OBJECT_INFO(TypeNode, Object);
+};
+
+/*!
+ * \brief Managed reference to TypeNode.
+ * \sa TypeNode
+ */
+class Type : public ObjectRef {
+ public:
+  TVM_DEFINE_OBJECT_REF_METHODS(Type, ObjectRef, TypeNode);
+};
+
+/*!
+ * \brief Primitive data types used in the low-level IR.
+ *
+ * PrimType represents POD-values and handles that are
+ * not automatically managed by the runtime.
+ *
+ * \sa PrimType
+ */
+class PrimTypeNode : public TypeNode {
+ public:
+  /*!
+   * \brief The corresponding dtype field.
+   */
+  runtime::DataType dtype;
+
+  void VisitAttrs(AttrVisitor* v) { v->Visit("dtype", &dtype); }
+
+  bool SEqualReduce(const PrimTypeNode* other, SEqualReducer equal) const {
+    return equal(dtype, other->dtype);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const { hash_reduce(dtype); }
+
+  static constexpr const char* _type_key = "PrimType";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PrimTypeNode, TypeNode);
+};
+
+/*
+ * \brief Managed reference to PrimTypeNode.
+ * \sa PrimTypeNode
+ */
+class PrimType : public Type {
+ public:
+  /*!
+   * \brief Constructor
+   * \param dtype The corresponding dtype.
+   */
+  TVM_DLL explicit PrimType(runtime::DataType dtype);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(PrimType, Type, PrimTypeNode);
+};
+
+/*!
+ * \brief Low-level raw pointer type.
+ *
+ *  PointerType represents type hints in the TIR to be
+ *  passed to the final code generator.
+ *
+ *  PointerType should not occur in the high-level analysis.
+ *
+ * \sa PointerType
+ */
+class PointerTypeNode : public TypeNode {
+ public:
+  /*!
+   * \brief The type of the element which the pointer points to.
+   */
+  Type element_type;
+  /*!
+   * \brief The storage scope of the pointer
+   */
+  String storage_scope;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("element_type", &element_type);
+    v->Visit("storage_scope", &storage_scope);
+  }
+
+  bool SEqualReduce(const PointerTypeNode* other, SEqualReducer equal) const {
+    // Make "global" equal to ""
+    String lhs_scope = storage_scope.empty() ? "global" : storage_scope;
+    String rhs_scope = other->storage_scope.empty() ? "global" : other->storage_scope;
+    return equal(element_type, other->element_type) && equal(lhs_scope, rhs_scope);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(element_type);
+    // Make "global" equal to ""
+    hash_reduce(storage_scope.empty() ? "global" : storage_scope);
+  }
+
+  static constexpr const char* _type_key = "PointerType";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PointerTypeNode, TypeNode);
+};
+
+/*
+ * \brief Managed reference to PointerTypeNode.
+ * \sa PointerTypeNode
+ */
+class PointerType : public Type {
+ public:
+  /*!
+   * \brief Constructor
+   * \param element_type The type of the element which the pointer points to.
+   * \param storage_scope The storage scope into which the pointer addresses
+   */
+  TVM_DLL explicit PointerType(Type element_type, String storage_scope = "");
+
+  TVM_DEFINE_OBJECT_REF_METHODS(PointerType, Type, PointerTypeNode);
+};
+
+/*! \brief Possible kinds of TypeVars. */
+enum TypeKind : int {
+  kType = 0,
+  /*! \brief Template variable in shape expression. */
+  kShapeVar = 1,
+  kBaseType = 2,
+  kConstraint = 4,
+  kAdtHandle = 5,
+  kTypeData = 6
+};
+
+/*!
+ * \brief Type parameter in functions.
+ *
+ * A type variable can be viewed as template parameter in c++ template function.
+ *
+ * For example, in the following pesudo code,
+ * the TypeVar of f is TypeVar("n", kind=kShapeVar).
+ * This function can take in a Tensor with shape=(3, 3) and
+ * returns a Tensor with shape=(9,)
+ *
+ * \code
+ *
+ *  template<i32 n>
+ *  f(x : Tensor[i32, (n, n)]) -> Tensor[i32, (n * n)]
+ *
+ * \endcode
+ * \sa TypeVar, TypeKind
+ */
+class TypeVarNode : public TypeNode {
+ public:
+  /*!
+   * \brief The name of the variable,
+   *  this only acts as a hint to the user,
+   *  and is not used for equality.
+   */
+  String name_hint;
+  /*! \brief The kind of type parameter */
+  TypeKind kind;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("name_hint", &name_hint);
+    v->Visit("kind", &kind);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const TypeVarNode* other, SEqualReducer equal) const {
+    return equal(kind, other->kind) && equal.FreeVarEqualImpl(this, other);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(kind);
+    hash_reduce.FreeVarHashImpl(this);
+  }
+
+  static constexpr const char* _type_key = "TypeVar";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TypeVarNode, TypeNode);
+};
+
+/*!
+ * \brief Managed reference to TypeVarNode
+ * \sa TypeVarNode
+ */
+class TypeVar : public Type {
+ public:
+  /*!
+   * \brief Constructor
+   * \param name_hint The name of the type var.
+   * \param kind The kind of the type var.
+   * \param span The span information.
+   */
+  TVM_DLL TypeVar(String name_hint, TypeKind kind, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(TypeVar, Type, TypeVarNode);
+};
+
+/*!
+ * \brief A global type variable that is used for defining new types or type aliases.
+ * \sa GlobalTypeVar
+ */
+class GlobalTypeVarNode : public TypeNode {
+ public:
+  /*!
+   * \brief The name of the variable,
+   *  this only acts as a hint to the user,
+   *  and is not used for equality.
+   */
+  String name_hint;
+  /*! \brief The kind of type parameter */
+  TypeKind kind;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("name_hint", &name_hint);
+    v->Visit("kind", &kind);
+  }
+
+  bool SEqualReduce(const GlobalTypeVarNode* other, SEqualReducer equal) const {
+    // name matters for now in global type var.
+    return equal(name_hint, other->name_hint) && equal.FreeVarEqualImpl(this, other);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(name_hint);
+    hash_reduce.FreeVarHashImpl(this);
+  }
+
+  static constexpr const char* _type_key = "GlobalTypeVar";
+  TVM_DECLARE_FINAL_OBJECT_INFO(GlobalTypeVarNode, TypeNode);
+};
+
+/*!
+ * \brief Managed reference to GlobalTypeVarNode
+ * \sa GlobalTypeVarNode
+ */
+class GlobalTypeVar : public Type {
+ public:
+  /*!
+   * \brief Constructor
+   * \param name_hint The name of the type var.
+   * \param kind The kind of the type var.
+   * \param span The span of the type.
+   */
+  TVM_DLL GlobalTypeVar(String name_hint, TypeKind kind, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(GlobalTypeVar, Type, GlobalTypeVarNode);
+};
+
+/*!
+ * \brief The type of tuple values.
+ * \sa TupleType
+ */
+class TupleTypeNode : public TypeNode {
+ public:
+  /*! \brief The type of each field in the tuple. */
+  Array<Type> fields;
+
+  TupleTypeNode() {}
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("fields", &fields);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const TupleTypeNode* other, SEqualReducer equal) const {
+    return equal(fields, other->fields);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const { hash_reduce(fields); }
+
+  static constexpr const char* _type_key = "TupleType";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TupleTypeNode, TypeNode);
+};
+
+/*!
+ * \brief Managed reference to TupleTypeNode.
+ * \sa TupleTypeNode.
+ */
+class TupleType : public Type {
+ public:
+  /*!
+   * \brief Constructor
+   * \param fields Fields in the tuple.
+   * \param span The span of the type.
+   */
+  TVM_DLL explicit TupleType(Array<Type> fields, Span span = Span());
+
+  /*!
+   * \brief Create an empty tuple type that constains nothing.
+   * \return A empty tuple type.
+   */
+  TVM_DLL TupleType static Empty();
+
+  TVM_DEFINE_OBJECT_REF_METHODS(TupleType, Type, TupleTypeNode);
+};
+
+/*!
+ * \return a type that represents void.
+ */
+inline Type VoidType() { return TupleType::Empty(); }
+
+/*!
+ * \brief Check whether the tyep represents void.
+ * \return The check result.
+ */
+inline bool IsVoidType(const Type& type) {
+  auto* n = type.as<TupleTypeNode>();
+  return n && n->fields.size() == 0;
+}
+
+/*!
+ * \brief Potential Constraints in a function.
+ * \sa TypeConstraint
+ */
+class TypeConstraintNode : public TypeNode {
+ public:
+  static constexpr const char* _type_key = "TypeConstraint";
+  static constexpr const uint32_t _type_child_slots = 1;
+  TVM_DECLARE_BASE_OBJECT_INFO(TypeConstraintNode, TypeNode);
+};
+
+/*!
+ * \brief Managed reference to TypeConstraintNode.
+ * \sa TypeConstraintNode, TypeRelation
+ */
+class TypeConstraint : public Type {
+ public:
+  TVM_DEFINE_OBJECT_REF_METHODS(TypeConstraint, Type, TypeConstraintNode);
+};
+
+/*!
+ * \brief Function type.
+ *
+ * We support polymorphic function type.
+ * This can be roughly viewed as template function in C++.
+ *
+ * \sa FuncType, TypeVar, TypeConstraint
+ */
+class FuncTypeNode : public TypeNode {
+ public:
+  /*! \brief type type of arguments */
+  Array<Type> arg_types;
+  /*! \brief The type of return value. */
+  Type ret_type;
+  // The following fields are used in polymorphic(template) functions
+  // For normal functions, the following two fields will be empty.
+  /*! \brief The type parameters of the function */
+  Array<TypeVar> type_params;
+  /*!
+   * \brief potential constraint the type need to obey
+   * \note this field is reserved for further purposes.
+   */
+  Array<TypeConstraint> type_constraints;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("arg_types", &arg_types);
+    v->Visit("ret_type", &ret_type);
+    v->Visit("type_params", &type_params);
+    v->Visit("type_constraints", &type_constraints);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const FuncTypeNode* other, SEqualReducer equal) const {
+    // type params first as they defines type vars.
+    return equal.DefEqual(type_params, other->type_params) && equal(arg_types, other->arg_types) &&
+           equal(ret_type, other->ret_type) && equal(type_constraints, other->type_constraints);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce.DefHash(type_params);
+    hash_reduce(arg_types);
+    hash_reduce(ret_type);
+    hash_reduce(type_constraints);
+  }
+
+  static constexpr const char* _type_key = "FuncType";
+  TVM_DECLARE_FINAL_OBJECT_INFO(FuncTypeNode, TypeNode);
+};
+
+/*!
+ * \brief Managed reference to FuncTypeNode.
+ * \sa FuncTypeNode
+ */
+class FuncType : public Type {
+ public:
+  /*!
+   * \brief Constructor
+   * \param arg_types The types of the arguments.
+   * \param ret_type The type of the return value.
+   * \param type_params The type parameters.
+   * \param type_constraints The type constraints.
+   * \param span The span information.
+   * \sa FuncTypeNode for more docs about these fields.
+   */
+  TVM_DLL FuncType(Array<Type> arg_types, Type ret_type, Array<TypeVar> type_params,
+                   Array<TypeConstraint> type_constraints, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(FuncType, Type, FuncTypeNode);
+};
+
+/*!
+ * \brief Intermediate values that is used to indicate incomplete type
+ *         during type inference.
+ *
+ * If we view the type relations as "computational graph of types",
+ * then IncompleteType represents intermediate values of the graph,
+ * TypeVar represents the input to the graph.
+ *
+ * \sa IncompleteType
+ */
+class IncompleteTypeNode : public TypeNode {
+ public:
+  /*! \brief kind of the type. */
+  TypeKind kind;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("kind", &kind);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const IncompleteTypeNode* other, SEqualReducer equal) const {
+    return equal(kind, other->kind) && equal.FreeVarEqualImpl(this, other);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const { hash_reduce(kind); }
+
+  static constexpr const char* _type_key = "IncompleteType";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IncompleteTypeNode, TypeNode);
+};
+
+/*!
+ * \brief Managed reference to IncompleteTypeNode.
+ * \sa IncompleteTypeNode
+ */
+class IncompleteType : public Type {
+ public:
+  /*!
+   * \brief Constructor.
+   * \param kind kind of the type.
+   * \param span The span information.
+   */
+  TVM_DLL explicit IncompleteType(TypeKind kind, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(IncompleteType, Type, IncompleteTypeNode);
+};
+
+/*!
+ * \brief Reference Type High-level Relay IR.
+ *
+ * \sa RelayRefType.
+ */
+class RelayRefTypeNode : public TypeNode {
+ public:
+  /*! \brief The type of value in the Reference. */
+  Type value;
+
+  RelayRefTypeNode() {}
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("value", &value);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const RelayRefTypeNode* other, SEqualReducer equal) const {
+    return equal(value, other->value);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const { hash_reduce(value); }
+
+  // Keep the relay prefix in the type as this type is specific
+  // to the relay itself.
+  static constexpr const char* _type_key = "relay.RefType";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RelayRefTypeNode, TypeNode);
+};
+
+/*!
+ * \brief Managed reference to RelayRefTypeNode.
+ * \sa RelayRefTypeNode.
+ */
+class RelayRefType : public Type {
+ public:
+  TVM_DLL explicit RelayRefType(Type value, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(RelayRefType, Type, RelayRefTypeNode);
+};
+}  // namespace tvm
+#endif  // TVM_IR_TYPE_H_
diff --git a/darknet_drp_ros/include/tvm/ir/type_functor.h b/darknet_drp_ros/include/tvm/ir/type_functor.h
new file mode 100644
index 0000000..11bf7d4
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/type_functor.h
@@ -0,0 +1,171 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/ir/type_functor.h
+ * \brief A way to defined arbitrary function signature with dispatch on types.
+ */
+#ifndef TVM_IR_TYPE_FUNCTOR_H_
+#define TVM_IR_TYPE_FUNCTOR_H_
+
+#include <tvm/node/functor.h>
+#include <tvm/relay/adt.h>
+#include <tvm/relay/expr.h>
+
+#include <string>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+
+template <typename FType>
+class TypeFunctor;
+
+// functions to be overriden.
+#define TYPE_FUNCTOR_DEFAULT \
+  { return VisitTypeDefault_(op, std::forward<Args>(args)...); }
+
+#define TVM_TYPE_FUNCTOR_DISPATCH(OP)                                                      \
+  vtable.template set_dispatch<OP>([](const ObjectRef& n, TSelf* self, Args... args) {     \
+    return self->VisitType_(static_cast<const OP*>(n.get()), std::forward<Args>(args)...); \
+  });
+
+template <typename R, typename... Args>
+class TypeFunctor<R(const Type& n, Args...)> {
+ private:
+  using TSelf = TypeFunctor<R(const Type& n, Args...)>;
+  using FType = tvm::NodeFunctor<R(const ObjectRef& n, TSelf* self, Args...)>;
+
+ public:
+  /*! \brief the result type of this functor */
+  using result_type = R;
+  /*! \brief virtual destructor */
+  virtual ~TypeFunctor() {}
+  /*!
+   * \brief Same as call.
+   * \param n The expression node.
+   * \param args Additional arguments.
+   * \return The result of the call
+   */
+  R operator()(const Type& n, Args... args) { return VisitType(n, std::forward<Args>(args)...); }
+  /*!
+   * \brief The functor call.
+   * \param n The expression node.
+   * \param args Additional arguments.
+   * \return The result of the call
+   */
+  virtual R VisitType(const Type& n, Args... args) {
+    ICHECK(n.defined());
+    static FType vtable = InitVTable();
+    return vtable(n, this, std::forward<Args>(args)...);
+  }
+  // Functions that can be overriden by subclass
+  virtual R VisitType_(const TensorTypeNode* op, Args... args) TYPE_FUNCTOR_DEFAULT;
+  virtual R VisitType_(const TypeVarNode* op, Args... args) TYPE_FUNCTOR_DEFAULT;
+  virtual R VisitType_(const TypeConstraintNode* op, Args... args) TYPE_FUNCTOR_DEFAULT;
+  virtual R VisitType_(const FuncTypeNode* op, Args... args) TYPE_FUNCTOR_DEFAULT;
+  virtual R VisitType_(const TypeRelationNode* op, Args... args) TYPE_FUNCTOR_DEFAULT;
+  virtual R VisitType_(const TupleTypeNode* op, Args... args) TYPE_FUNCTOR_DEFAULT;
+  virtual R VisitType_(const IncompleteTypeNode* op, Args... args) TYPE_FUNCTOR_DEFAULT;
+  virtual R VisitType_(const RelayRefTypeNode* op, Args... args) TYPE_FUNCTOR_DEFAULT;
+  virtual R VisitType_(const GlobalTypeVarNode* op, Args... args) TYPE_FUNCTOR_DEFAULT;
+  virtual R VisitType_(const TypeCallNode* op, Args... args) TYPE_FUNCTOR_DEFAULT;
+  virtual R VisitType_(const TypeDataNode* op, Args... args) TYPE_FUNCTOR_DEFAULT;
+  virtual R VisitType_(const PrimTypeNode* op, Args... args) TYPE_FUNCTOR_DEFAULT;
+  virtual R VisitType_(const PointerTypeNode* op, Args... args) TYPE_FUNCTOR_DEFAULT;
+  virtual R VisitTypeDefault_(const Object* op, Args...) {
+    LOG(FATAL) << "Do not have a default for " << op->GetTypeKey();
+    throw;  // unreachable, written to stop compiler warning
+  }
+
+ private:
+  // initialize the vtable.
+  static FType InitVTable() {
+    FType vtable;
+    // Set dispatch
+    TVM_TYPE_FUNCTOR_DISPATCH(TensorTypeNode);
+    TVM_TYPE_FUNCTOR_DISPATCH(TypeVarNode);
+    TVM_TYPE_FUNCTOR_DISPATCH(TypeConstraintNode);
+    TVM_TYPE_FUNCTOR_DISPATCH(FuncTypeNode);
+    TVM_TYPE_FUNCTOR_DISPATCH(TypeRelationNode);
+    TVM_TYPE_FUNCTOR_DISPATCH(TupleTypeNode);
+    TVM_TYPE_FUNCTOR_DISPATCH(IncompleteTypeNode);
+    TVM_TYPE_FUNCTOR_DISPATCH(RelayRefTypeNode);
+    TVM_TYPE_FUNCTOR_DISPATCH(GlobalTypeVarNode);
+    TVM_TYPE_FUNCTOR_DISPATCH(TypeCallNode);
+    TVM_TYPE_FUNCTOR_DISPATCH(TypeDataNode);
+    TVM_TYPE_FUNCTOR_DISPATCH(PrimTypeNode);
+    TVM_TYPE_FUNCTOR_DISPATCH(PointerTypeNode);
+    return vtable;
+  }
+};
+
+#undef TVM_TYPE_FUNCTOR_DISPATCH
+
+/*!
+ * \brief A type visitor that recursively visit types.
+ */
+class TVM_DLL TypeVisitor : public TypeFunctor<void(const Type& n)> {
+ public:
+  void VisitType_(const TypeVarNode* op) override;
+  void VisitType_(const IncompleteTypeNode* op) override;
+  void VisitType_(const TensorTypeNode* op) override;
+  void VisitType_(const FuncTypeNode* op) override;
+  void VisitType_(const TupleTypeNode* op) override;
+  void VisitType_(const TypeRelationNode* op) override;
+  void VisitType_(const RelayRefTypeNode* op) override;
+  void VisitType_(const GlobalTypeVarNode* op) override;
+  void VisitType_(const TypeCallNode* op) override;
+  void VisitType_(const TypeDataNode* op) override;
+  void VisitType_(const PrimTypeNode* op) override;
+  void VisitType_(const PointerTypeNode* op) override;
+};
+
+/*!
+ * \brief TypeMutator that mutates expressions.
+ */
+class TVM_DLL TypeMutator : public TypeFunctor<Type(const Type& n)> {
+ public:
+  Type VisitType(const Type& t) override;
+  Type VisitType_(const TypeVarNode* op) override;
+  Type VisitType_(const TensorTypeNode* op) override;
+  Type VisitType_(const IncompleteTypeNode* op) override;
+  Type VisitType_(const FuncTypeNode* op) override;
+  Type VisitType_(const TupleTypeNode* op) override;
+  Type VisitType_(const TypeRelationNode* type_rel) override;
+  Type VisitType_(const RelayRefTypeNode* op) override;
+  Type VisitType_(const GlobalTypeVarNode* op) override;
+  Type VisitType_(const TypeCallNode* op) override;
+  Type VisitType_(const TypeDataNode* op) override;
+  Type VisitType_(const PrimTypeNode* op) override;
+  Type VisitType_(const PointerTypeNode* op) override;
+
+ private:
+  Array<Type> MutateArray(Array<Type> arr);
+};
+
+/*!
+ * \brief Bind free type variables in the type.
+ * \param type The type to be updated.
+ * \param args_map The binding map.
+ */
+Type Bind(const Type& type, const Map<TypeVar, Type>& args_map);
+
+}  // namespace tvm
+#endif  // TVM_IR_TYPE_FUNCTOR_H_
diff --git a/darknet_drp_ros/include/tvm/ir/type_relation.h b/darknet_drp_ros/include/tvm/ir/type_relation.h
new file mode 100644
index 0000000..dd68617
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/ir/type_relation.h
@@ -0,0 +1,243 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/ir/type_relation.h
+ * \brief Type relation and function for type inference(checking).
+ */
+#ifndef TVM_IR_TYPE_RELATION_H_
+#define TVM_IR_TYPE_RELATION_H_
+
+#include <tvm/ir/attrs.h>
+#include <tvm/ir/diagnostic.h>
+#include <tvm/ir/env_func.h>
+#include <tvm/ir/module.h>
+#include <tvm/ir/type.h>
+#include <tvm/runtime/logging.h>
+
+namespace tvm {
+
+/*!
+ * \brief Type function application.
+ * \sa TypeCall
+ */
+class TypeCallNode : public TypeNode {
+ public:
+  /*!
+   * \brief The type-level function (ADT that takes type params).
+   */
+  Type func;
+  /*! \brief The arguments. */
+  Array<Type> args;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("func", &func);
+    v->Visit("args", &args);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const TypeCallNode* other, SEqualReducer equal) const {
+    return equal(func, other->func) && equal(args, other->args);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(func);
+    hash_reduce(args);
+  }
+
+  static constexpr const char* _type_key = "TypeCall";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TypeCallNode, TypeNode);
+};
+
+/*!
+ * \brief Managed reference to TypeCallNode.
+ * \sa TypeCallNode
+ */
+class TypeCall : public Type {
+ public:
+  /*!
+   * \brief Constructor
+   * \param func The type function to apply.
+   * \param args The arguments to the type function.
+   */
+  TVM_DLL TypeCall(Type func, Array<Type> args);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(TypeCall, Type, TypeCallNode);
+};
+
+/*!
+ * \brief reporter that reports back to the
+ *  type resolution information.
+ */
+class TypeReporterNode : public Object {
+ public:
+  /*! \brief virtual destructor */
+  virtual ~TypeReporterNode() {}
+  /*!
+   * \brief Create a type equality constraint.
+   *
+   *  The "assign direction" acts as a hint to the solver
+   *  showing that it is more likely to resolve dst by src.
+   *  But it is possible for the solver to resolve src by dst as well.
+   */
+  TVM_DLL virtual void Assign(const Type& dst, const Type& src) = 0;
+
+  /*!
+   * \brief assert shape expression comparison.
+   * \note Use assert only if any of the condition input is symbolic.
+   * \param cond The condition of operation.
+   * \return false if assertion can be proven to have failed
+   *      true if solver can still proceed.
+   */
+  TVM_DLL virtual bool Assert(const PrimExpr& cond) = 0;
+  /*!
+   * \brief assert shape expression equals each other.
+   * \param lhs The left operand.
+   * \param rhs The right operand.
+   * \return false if assertion can be proven to have failed
+   *      true if solver can still proceed.
+   */
+  TVM_DLL virtual bool AssertEQ(const PrimExpr& lhs, const PrimExpr& rhs) = 0;
+
+  /*!
+   * \brief Set the location at which to report unification errors.
+   * \param span The span at which to report the error.
+   */
+  TVM_DLL virtual void SetSpan(const Span& span) = 0;
+
+  TVM_DLL virtual Span GetSpan() = 0;
+
+  TVM_DLL virtual DiagnosticContext GetDiagCtx() = 0;
+
+  /*!
+   * \brief Retrieve the current global module.
+   * \return The global module.
+   */
+  TVM_DLL virtual IRModule GetModule() = 0;
+
+  // solver is not serializable.
+  void VisitAttrs(AttrVisitor* v) {}
+
+  static constexpr const char* _type_key = "TypeReporter";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TypeReporterNode, Object);
+};
+
+/*!
+ * \brief Container class of TypeReporter.
+ * \sa TypeReporterNode
+ */
+class TypeReporter : public ObjectRef {
+ public:
+  TypeReporter() {}
+  explicit TypeReporter(ObjectPtr<Object> n) : ObjectRef(n) {}
+  TypeReporterNode* operator->() const {
+    return const_cast<TypeReporterNode*>(static_cast<const TypeReporterNode*>(get()));
+  }
+  using ContainerType = TypeReporterNode;
+};
+
+/*!
+ * \brief User defined type constraint function.
+ *
+ * If the input type information can be used to fully decide
+ * the IncompleteTypes, then the function should call
+ * reporter.Assign to report the new types, and return true.
+ * Otherwise, the function should return false.
+ *
+ * \param args The arguments to the relation.
+ *   The types are stored in the form of
+ *   [input_type_0, input_type_1, ... input_type_n,
+ *    output_type_0, output_type_1, ... output_type_m]
+ *
+ * \param num_inputs Number of input types in the args.
+ * \param attrs The additional attributes of the operator.
+ * \param reporter The reporter to report solution to.
+ * \return false if This relation cannot be resolved.
+ *   true if this relation has been resolved.
+ */
+using TypeRelationFn = TypedEnvFunc<bool(const Array<Type>& args, int num_inputs,
+                                         const Attrs& attrs, const TypeReporter& reporter)>;
+
+/*!
+ * \brief User defined type relation, it is an input-output relation on types.
+ *
+ * TypeRelation is more generalized than type call as it allows inference
+ * of both inputs and outputs.
+ *
+ * \sa TypeRelation
+ */
+class TypeRelationNode : public TypeConstraintNode {
+ public:
+  /*!
+   * \brief The function on input and output variables which
+   *  this is not directly serializable,
+   *  need to be looked-up in the module.
+   */
+  TypeRelationFn func;
+  /*! \brief The type arguments to the type function. */
+  Array<Type> args;
+  /*! \brief Number of inputs arguments */
+  int num_inputs;
+  /*! \brief Attributes to the relation function */
+  Attrs attrs;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("func", &func);
+    v->Visit("args", &args);
+    v->Visit("num_inputs", &num_inputs);
+    v->Visit("attrs", &attrs);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const TypeRelationNode* other, SEqualReducer equal) const {
+    return equal(func, other->func) && equal(args, other->args) &&
+           equal(num_inputs, other->num_inputs) && equal(attrs, other->attrs);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(func);
+    hash_reduce(args);
+    hash_reduce(num_inputs);
+    hash_reduce(attrs);
+  }
+
+  static constexpr const char* _type_key = "TypeRelation";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TypeRelationNode, TypeConstraintNode);
+};
+
+/*!
+ * \brief Managed reference to TypeRelationNode.
+ * \sa TypeRelationNode
+ */
+class TypeRelation : public TypeConstraint {
+ public:
+  /*!
+   * \brief Constructor
+   * \param func The relation function.
+   * \param args The arguments to the type relation.
+   * \param num_inputs Number of inputs.
+   * \param attrs Attributes to the relation function.
+   * \sa TypeRelationNode for more docs about these fields.
+   */
+  TVM_DLL TypeRelation(TypeRelationFn func, Array<Type> args, int num_inputs, Attrs attrs);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(TypeRelation, TypeConstraint, TypeRelationNode);
+};
+}  // namespace tvm
+#endif  // TVM_IR_TYPE_RELATION_H_
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/arg_info.h b/darknet_drp_ros/include/tvm/meta_schedule/arg_info.h
new file mode 100644
index 0000000..ccf0931
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/meta_schedule/arg_info.h
@@ -0,0 +1,122 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_META_SCHEDULE_ARG_INFO_H_
+#define TVM_META_SCHEDULE_ARG_INFO_H_
+
+#include <tvm/ir/module.h>
+#include <tvm/node/node.h>
+#include <tvm/node/reflection.h>
+#include <tvm/runtime/container/shape_tuple.h>
+#include <tvm/runtime/data_type.h>
+#include <tvm/runtime/object.h>
+#include <tvm/tir/function.h>
+
+namespace tvm {
+namespace meta_schedule {
+
+/*! \brief The argument information. */
+class ArgInfoNode : public runtime::Object {
+ public:
+  static constexpr const char* _type_key = "meta_schedule.ArgInfo";
+  TVM_DECLARE_BASE_OBJECT_INFO(ArgInfoNode, runtime::Object);
+
+ public:
+  /*! \brief Default destructor. */
+  virtual ~ArgInfoNode() = default;
+  /*! \brief Converts the ArgInfo to its corresponding JSON representation. */
+  virtual ObjectRef AsJSON() const = 0;
+};
+
+/*!
+ * \brief Managed reference to ArgInfoNode
+ * \sa ArgInfoNode
+ */
+class ArgInfo : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief Parse the argument information from a JSON object.
+   * \param json_obj The json object to parse.
+   * \return The argument information parsed.
+   */
+  TVM_DLL static ArgInfo FromJSON(const ObjectRef& json_obj);
+  /*!
+   * \brief Extract a list of the argument information from PrimFunc.
+   * \param func The PrimFunc to get argument information from.
+   * \return An array of the argument information derived.
+   */
+  TVM_DLL static Array<ArgInfo, void> FromPrimFunc(const tir::PrimFunc& func);
+  /*!
+   * \brief Extract a list of the argument information from the entry func of an IRModule
+   * \param mod The IRModule to extract argument information from.
+   * \param remove_preproc Whether to remove the preprocessing blocks.
+   * \return An array of the argument information derived.
+   */
+  TVM_DLL static Array<ArgInfo, void> FromEntryFunc(const IRModule& mod, bool remove_preproc);
+
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(ArgInfo, runtime::ObjectRef, ArgInfoNode);
+
+ protected:
+  ArgInfo() = default;
+};
+
+/*! \brief The tensor argument information. */
+class TensorInfoNode : public ArgInfoNode {
+ public:
+  /*! \brief The data type of the tensor. */
+  runtime::DataType dtype;
+  /*! \brief The shape of the tensor. */
+  runtime::ShapeTuple shape;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("dtype", &dtype);
+    v->Visit("shape", &shape);
+  }
+
+  static constexpr const char* _type_key = "meta_schedule.TensorInfo";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TensorInfoNode, ArgInfoNode);
+
+ public:
+  ObjectRef AsJSON() const;
+};
+
+/*!
+ * \brief Managed reference to TensorInfoNode
+ * \sa TensorInfoNode
+ */
+class TensorInfo : public ArgInfo {
+ public:
+  /*!
+   * \brief Constructor of TensorInfo.
+   * \param dtype The data type of the tensor argument.
+   * \param shape The shape tuple of the tensor argument.
+   */
+  TVM_DLL explicit TensorInfo(runtime::DataType dtype, runtime::ShapeTuple shape);
+  /*!
+   * \brief Parse the argument information from a JSON object.
+   * \param json_obj The json object to parse.
+   * \return The argument information parsed.
+   */
+  TVM_DLL static TensorInfo FromJSON(const ObjectRef& json_obj);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(TensorInfo, ArgInfo, TensorInfoNode);
+};
+
+}  // namespace meta_schedule
+}  // namespace tvm
+
+#endif  // TVM_META_SCHEDULE_ARG_INFO_H_
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/builder.h b/darknet_drp_ros/include/tvm/meta_schedule/builder.h
new file mode 100644
index 0000000..e41dc90
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/meta_schedule/builder.h
@@ -0,0 +1,164 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_META_SCHEDULE_BUILDER_H_
+#define TVM_META_SCHEDULE_BUILDER_H_
+
+#include <tvm/ir/module.h>
+#include <tvm/node/reflection.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/map.h>
+#include <tvm/runtime/container/optional.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/runtime/ndarray.h>
+#include <tvm/runtime/object.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/target/target.h>
+
+namespace tvm {
+namespace meta_schedule {
+
+/*! \brief The builder's input, containing an IRModule and the target. */
+class BuilderInputNode : public runtime::Object {
+ public:
+  /*! \brief The IRModule to be built. */
+  IRModule mod;
+  /*! \brief The target to be built for. */
+  Target target;
+  /*! \brief Parameters for Relay build module. */
+  Optional<Map<String, runtime::NDArray>> params;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("mod", &mod);
+    v->Visit("target", &target);
+    v->Visit("params", &params);
+  }
+
+  static constexpr const char* _type_key = "meta_schedule.BuilderInput";
+  TVM_DECLARE_FINAL_OBJECT_INFO(BuilderInputNode, runtime::Object);
+};
+
+/*!
+ * \brief Managed reference to BuilderInputNode
+ * \sa BuilderInputNode
+ */
+class BuilderInput : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief Constructor of BuilderInput.
+   * \param mod The IRModule to be built.
+   * \param target The target to be built for.
+   * \param params Parameters for Relay build module.
+   */
+  TVM_DLL explicit BuilderInput(IRModule mod, Target target,
+                                Optional<Map<String, runtime::NDArray>> params = NullOpt);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(BuilderInput, runtime::ObjectRef, BuilderInputNode);
+};
+
+/*! \brief The builder's output, containing the artifact path or error message if any. */
+class BuilderResultNode : public runtime::Object {
+ public:
+  /*! \brief The path to the built artifact. */
+  Optional<String> artifact_path;
+  /*! \brief The error message if any. */
+  Optional<String> error_msg;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("artifact_path", &artifact_path);
+    v->Visit("error_msg", &error_msg);
+  }
+
+  static constexpr const char* _type_key = "meta_schedule.BuilderResult";
+  TVM_DECLARE_FINAL_OBJECT_INFO(BuilderResultNode, runtime::Object);
+};
+
+/*!
+ * \brief Managed reference to BuilderResultNode
+ * \sa BuilderResultNode
+ */
+class BuilderResult : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief Constructor of BuilderResult.
+   * \param artifact_path The path to the built artifact.
+   * \param error_msg The error message if any.
+   */
+  TVM_DLL explicit BuilderResult(Optional<String> artifact_path, Optional<String> error_msg);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(BuilderResult, runtime::ObjectRef, BuilderResultNode);
+};
+
+/*! \brief The abstract builder interface. */
+class BuilderNode : public runtime::Object {
+ public:
+  /*! \brief Default destructor */
+  virtual ~BuilderNode() = default;
+  /*!
+   * \brief Generate the build results from build inputs.
+   * \param build_inputs The inputs to be built.
+   * \return The build results.
+   */
+  virtual Array<BuilderResult> Build(const Array<BuilderInput>& build_inputs) = 0;
+  /*!
+   * \brief The function type of `Build` method.
+   * \param build_inputs The inputs to be built.
+   * \return The build results.
+   */
+  using FBuild = runtime::TypedPackedFunc<Array<BuilderResult>(const Array<BuilderInput>&)>;
+
+  static constexpr const char* _type_key = "meta_schedule.Builder";
+  TVM_DECLARE_BASE_OBJECT_INFO(BuilderNode, runtime::Object);
+};
+
+/*!
+ * \brief Managed reference to BuilderNode
+ * \sa BuilderNode
+ */
+class Builder : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief Create a builder with customized build method on the python-side.
+   * \param f_build The packed function to the `Build` function..
+   * \return The Builder created.
+   */
+  static Builder PyBuilder(BuilderNode::FBuild f_build);
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(Builder, runtime::ObjectRef, BuilderNode);
+};
+
+/*! \brief An abstract builder with customized build method on the python-side. */
+class PyBuilderNode : public BuilderNode {
+ public:
+  /*! \brief The packed function to the `Build` function. */
+  FBuild f_build;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    // `f_build` is not visited
+  }
+
+  Array<BuilderResult> Build(const Array<BuilderInput>& build_inputs) final {
+    ICHECK(f_build != nullptr) << "PyBuilder's Build method not implemented!";
+    return f_build(build_inputs);
+  }
+
+  static constexpr const char* _type_key = "meta_schedule.PyBuilder";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PyBuilderNode, BuilderNode);
+};
+
+}  // namespace meta_schedule
+}  // namespace tvm
+
+#endif  // TVM_META_SCHEDULE_BUILDER_H_
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/cost_model.h b/darknet_drp_ros/include/tvm/meta_schedule/cost_model.h
new file mode 100644
index 0000000..db0f896
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/meta_schedule/cost_model.h
@@ -0,0 +1,174 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+#ifndef TVM_META_SCHEDULE_COST_MODEL_H_
+#define TVM_META_SCHEDULE_COST_MODEL_H_
+
+#include <tvm/meta_schedule/arg_info.h>
+#include <tvm/meta_schedule/measure_candidate.h>
+#include <tvm/meta_schedule/runner.h>
+#include <tvm/node/reflection.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/runtime/object.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/tir/schedule/schedule.h>
+
+#include <vector>
+
+namespace tvm {
+namespace meta_schedule {
+
+class TuneContext;
+
+/*! \brief Cost model. */
+class CostModelNode : public runtime::Object {
+ public:
+  /*! \brief Virtual destructor. */
+  virtual ~CostModelNode() = default;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {}
+
+  /*!
+   * \brief Load the cost model from given file location.
+   * \param path The file path.
+   */
+  virtual void Load(const String& path) = 0;
+
+  /*!
+   * \brief Save the cost model to given file location.
+   * \param path The file path.
+   */
+  virtual void Save(const String& path) = 0;
+
+  /*!
+   * \brief Update the cost model given running results.
+   * \param context The tuning context.
+   * \param candidates The measure candidates.
+   * \param results The running results of the measure candidates.
+   */
+  virtual void Update(const TuneContext& context, const Array<MeasureCandidate>& candidates,
+                      const Array<RunnerResult>& results) = 0;
+
+  /*!
+   * \brief Predict the normalized score (the larger the better) of given measure candidates.
+   * \param context The tuning context.
+   * \param candidates The measure candidates.
+   * \return The predicted normalized score.
+   */
+  virtual std::vector<double> Predict(const TuneContext& context,
+                                      const Array<MeasureCandidate>& candidates) = 0;
+
+  static constexpr const char* _type_key = "meta_schedule.CostModel";
+  TVM_DECLARE_BASE_OBJECT_INFO(CostModelNode, Object);
+};
+
+/*! \brief The cost model with customized methods on the python-side. */
+class PyCostModelNode : public CostModelNode {
+ public:
+  /*!
+   * \brief Load the cost model from given file location.
+   * \param path The file path.
+   */
+  using FLoad = runtime::TypedPackedFunc<void(String)>;
+  /*!
+   * \brief Save the cost model to given file location.
+   * \param path The file path.
+   */
+  using FSave = runtime::TypedPackedFunc<void(String)>;
+  /*!
+   * \brief Update the cost model given running results.
+   * \param context The tuning context.
+   * \param candidates The measure candidates.
+   * \param results The running results of the measure candidates.
+   * \return Whether cost model was updated successfully.
+   */
+  using FUpdate = runtime::TypedPackedFunc<void(const TuneContext&, const Array<MeasureCandidate>&,
+                                                const Array<RunnerResult>&)>;
+  /*!
+   * \brief Predict the running results of given measure candidates.
+   * \param context The tuning context.
+   * \param candidates The measure candidates.
+   * \param p_addr The address to save the estimated running results.
+   */
+  using FPredict = runtime::TypedPackedFunc<void(const TuneContext&, const Array<MeasureCandidate>&,
+                                                 void* p_addr)>;
+  /*!
+   * \brief Get the cost model as string with name.
+   * \return The string representation of the cost model.
+   */
+  using FAsString = runtime::TypedPackedFunc<String()>;
+
+  /*! \brief The packed function to the `Load` function. */
+  FLoad f_load;
+  /*! \brief The packed function to the `Save` function. */
+  FSave f_save;
+  /*! \brief The packed function to the `Update` function. */
+  FUpdate f_update;
+  /*! \brief The packed function to the `Predict` function. */
+  FPredict f_predict;
+  /*! \brief The packed function to the `AsString` function. */
+  FAsString f_as_string;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    // `f_load` is not visited
+    // `f_save` is not visited
+    // `f_update` is not visited
+    // `f_predict` is not visited
+    // `f_as_string` is not visited
+  }
+
+  void Load(const String& path);
+  void Save(const String& path);
+  void Update(const TuneContext& context, const Array<MeasureCandidate>& candidates,
+              const Array<RunnerResult>& results);
+  std::vector<double> Predict(const TuneContext& context,
+                              const Array<MeasureCandidate>& candidates);
+
+  static constexpr const char* _type_key = "meta_schedule.PyCostModel";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PyCostModelNode, CostModelNode);
+};
+
+/*!
+ * \brief Managed reference to CostModelNode
+ * \sa CostModelNode
+ */
+class CostModel : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief Create a feature extractor with customized methods on the python-side.
+   * \param f_load The packed function of `Load`.
+   * \param f_save The packed function of `Save`.
+   * \param f_update The packed function of `Update`.
+   * \param f_predict The packed function of `Predict`.
+   * \param f_as_string The packed function of `AsString`.
+   * \return The feature extractor created.
+   */
+  TVM_DLL static CostModel PyCostModel(PyCostModelNode::FLoad f_load,        //
+                                       PyCostModelNode::FSave f_save,        //
+                                       PyCostModelNode::FUpdate f_update,    //
+                                       PyCostModelNode::FPredict f_predict,  //
+                                       PyCostModelNode::FAsString f_as_string);
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(CostModel, ObjectRef, CostModelNode);
+};
+
+}  // namespace meta_schedule
+}  // namespace tvm
+
+#endif  // TVM_META_SCHEDULE_COST_MODEL_H_
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/database.h b/darknet_drp_ros/include/tvm/meta_schedule/database.h
new file mode 100644
index 0000000..a1dd4a4
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/meta_schedule/database.h
@@ -0,0 +1,528 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_META_SCHEDULE_DATABASE_H_
+#define TVM_META_SCHEDULE_DATABASE_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/ir/module.h>
+#include <tvm/meta_schedule/arg_info.h>
+#include <tvm/node/reflection.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/runtime/object.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/target/target.h>
+#include <tvm/tir/schedule/schedule.h>
+#include <tvm/tir/schedule/trace.h>
+
+#include <memory>
+
+namespace tvm {
+namespace meta_schedule {
+
+class ModuleEquality;
+
+/*! \brief A workload, i.e. an IRModule and its structural hash. */
+class WorkloadNode : public runtime::Object {
+ public:
+  /*! \brief The type of structural hash */
+  using THashCode = size_t;
+  /*! \brief The workload's IRModule. */
+  IRModule mod;
+  /*! \brief The workload's structural hash. */
+  THashCode shash;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("mod", &mod);
+    // `shash` is not visited because TVM FFI doesn't support uint64_t
+  }
+
+  static constexpr const char* _type_key = "meta_schedule.Workload";
+  TVM_DECLARE_FINAL_OBJECT_INFO(WorkloadNode, runtime::Object);
+
+  /*!
+   * \brief Export the workload to a JSON string.
+   * \return An array containing the structural hash and the base64 json string.
+   */
+  ObjectRef AsJSON() const;
+};
+
+/*!
+ * \brief Managed reference to WorkloadNode.
+ *  \sa WorkloadNode
+ */
+class Workload : public runtime::ObjectRef {
+ public:
+  using THashCode = WorkloadNode::THashCode;
+  /*!
+   * \brief Constructor of Workload.
+   * \param mod The workload's IRModule.
+   */
+  TVM_DLL explicit Workload(IRModule mod);
+  /*!
+   * \brief Constructor of Workload.
+   * \param mod The workload's IRModule.
+   * \param shash The workload's structural hash.
+   */
+  TVM_DLL explicit Workload(IRModule mod, THashCode shash);
+  /*!
+   * \brief Create a workload from a json object.
+   * \param json_obj The json object.
+   * \return The created workload.
+   */
+  TVM_DLL static Workload FromJSON(const ObjectRef& json_obj);
+
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(Workload, runtime::ObjectRef, WorkloadNode);
+};
+
+/*! \brief The hash method for Workload */
+struct WorkloadHash {
+  size_t operator()(const Workload& a) const { return a->shash; }
+};
+
+/*! \brief The equality check for Workload */
+struct WorkloadEqual {
+  explicit WorkloadEqual(const ModuleEquality& mod_eq) : mod_eq_(mod_eq) {}
+
+  bool operator()(const Workload& a, const Workload& b) const;
+
+ private:
+  /*! \brief The module equality testing and hashing method */
+  const ModuleEquality& mod_eq_;
+};
+
+/*! \brief The class of measure candidates. */
+class MeasureCandidate;
+
+/*! \brief The class of tuning records. */
+class TuningRecordNode : public runtime::Object {
+ public:
+  /*! \brief The trace tuned. */
+  tir::Trace trace;
+  /*! \brief The workload. */
+  Workload workload{nullptr};
+  /*! \brief The profiling result in seconds. */
+  Optional<Array<FloatImm>> run_secs;
+  /*! \brief The target for tuning. */
+  Optional<Target> target;
+  /*! \brief The argument information. */
+  Optional<Array<ArgInfo>> args_info;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("trace", &trace);
+    v->Visit("workload", &workload);
+    v->Visit("run_secs", &run_secs);
+    v->Visit("target", &target);
+    v->Visit("args_info", &args_info);
+  }
+
+  static constexpr const char* _type_key = "meta_schedule.TuningRecord";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TuningRecordNode, runtime::Object);
+
+  /*! \brief Construct the measure candidate given the initial IR module and trace
+   * stored in the tuning record. */
+  MeasureCandidate AsMeasureCandidate() const;
+  /*!
+   * \brief Export the tuning record to a JSON string.
+   * \return An array containing the trace, running secs, serialized target, and
+   * argument information.
+   */
+  ObjectRef AsJSON() const;
+};
+
+/*!
+ * \brief The managed reference of TuningRecordNode.
+ * \sa TuningRecordNode
+ */
+class TuningRecord : public runtime::ObjectRef {
+ public:
+  /*!
+   \brief Constructor of a tuning record.
+   \param trace The trace of the tuning record.
+   \param workload The workload of the tuning record.
+   \param run_secs The running time of the tuning record.
+   \param target The target of the tuning record.
+   \param args_info The argument information of the tuning record.
+  */
+  TVM_DLL explicit TuningRecord(tir::Trace trace, Workload workload,
+                                Optional<Array<FloatImm>> run_secs, Optional<Target> target,
+                                Optional<Array<ArgInfo>> args_info);
+  /*!
+   * \brief Create a tuning record from a json object.
+   * \param json_obj The json object.
+   * \param workload The workload.
+   * \return The tuning record created.
+   */
+  TVM_DLL static TuningRecord FromJSON(const ObjectRef& json_obj, const Workload& workload);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(TuningRecord, runtime::ObjectRef, TuningRecordNode);
+};
+
+/* \brief The abstract interface of database. */
+class DatabaseNode : public runtime::Object {
+ public:
+  /*!
+   * \brief Constructor
+   * \param mod_eq_name A string to specify the module equality testing and hashing method.
+   *  It must be one of the followings:
+   *    - "structural": Use StructuralEqual/Hash
+   *    - "ignore-ndarray": Same as "structural", but ignore ndarray raw data during
+   *                        equality testing and hashing.
+   *    - "anchor-block": Apply equality testing and hashing on the anchor block extracted from a
+   *                      given module. The "ignore-ndarray" varint is used for the extracted blocks
+   *                      or in case no anchor block is found.
+   *                      For the definition of the anchor block, see tvm/tir/analysis.h.
+   */
+  explicit DatabaseNode(String mod_eq_name = "structural");
+
+  /*! \brief Default destructor */
+  virtual ~DatabaseNode();
+  /*!
+   * \brief Check if the database has the given workload.
+   * \param mod The IRModule to be searched for.
+   * \return Whether the database has the given workload.
+   */
+  virtual bool HasWorkload(const IRModule& mod) = 0;
+  /*!
+   * \brief Look up or add workload to the database if missing.
+   * \param mod The IRModule to be searched for or added.
+   * \return The workload corresponding to the given IRModule.
+   */
+  virtual Workload CommitWorkload(const IRModule& mod) = 0;
+  /*!
+   * \brief Add a tuning record to the database.
+   * \param record The tuning record to be added.
+   */
+  virtual void CommitTuningRecord(const TuningRecord& record) = 0;
+  /*!
+   * \brief Get the top K tuning records of given workload from the database.
+   * \param workload The workload to be searched for.
+   * \param top_k The number of top records to be returned.
+   * \return An array of top K tuning records for the given workload.
+   */
+  virtual Array<TuningRecord> GetTopK(const Workload& workload, int top_k) = 0;
+  /*!
+   * \brief Get all tuning records from the database.
+   * \return An Array of all the tuning records in the database.
+   */
+  virtual Array<TuningRecord> GetAllTuningRecords() = 0;
+  /*!
+   * \brief Get the size of the database.
+   * \return The size of the database.
+   */
+  virtual int64_t Size() = 0;
+  /*!
+   * \brief Query the best record of the given workload from the database.
+   * \param mod The IRModule to be searched for.
+   * \param target The target to be searched for.
+   * \param workload_name The name of the workload to be searched for.
+   * \return The best record of the given workload; NullOpt if not found.
+   */
+  virtual Optional<TuningRecord> QueryTuningRecord(const IRModule& mod, const Target& target,
+                                                   const String& workload_name);
+  /*!
+   * \brief Query the best schedule of the given workload from the database.
+   * \param mod The IRModule to be searched for.
+   * \param target The target to be searched for.
+   * \param workload_name The name of the workload to be searched for.
+   * \return The schedule in the best schedule of the given workload; NullOpt if not found.
+   */
+  virtual Optional<tir::Schedule> QuerySchedule(const IRModule& mod, const Target& target,
+                                                const String& workload_name);
+  /*!
+   * \brief Query the best IRModule of the given workload from the database.
+   * \param mod The IRModule to be searched for.
+   * \param target The target to be searched for.
+   * \param workload_name The name of the workload to be searched for.
+   * \return The IRModule in the best IRModule of the given workload; NullOpt if not found.
+   */
+  virtual Optional<IRModule> QueryIRModule(const IRModule& mod, const Target& target,
+                                           const String& workload_name);
+
+  /*! \brief Return a reference to the owned module equality method instance. */
+  const ModuleEquality& GetModuleEquality() const {
+    ICHECK(mod_eq_);
+    return *mod_eq_;
+  }
+
+  static constexpr const char* _type_key = "meta_schedule.Database";
+  TVM_DECLARE_BASE_OBJECT_INFO(DatabaseNode, runtime::Object);
+
+ private:
+  /*! \brief The module equality testing and hashing method */
+  std::unique_ptr<ModuleEquality> mod_eq_;
+};
+
+/*! \brief The database with customized methods on the python-side. */
+class PyDatabaseNode : public DatabaseNode {
+ public:
+  /*!
+   * \brief Constructor
+   * \param mod_eq_name A string to specify the module equality testing and hashing method.
+   *  It must be one of the followings:
+   *    - "structural": Use StructuralEqual/Hash
+   *    - "ignore-ndarray": Same as "structural", but ignore ndarray raw data during
+   *                        equality testing and hashing.
+   *    - "anchor-block": Apply equality testing and hashing on the anchor block extracted from a
+   *                      given module. The "ignore-ndarray" varint is used for the extracted blocks
+   *                      or in case no anchor block is found.
+   *                      For the definition of the anchor block, see tvm/tir/analysis.h.
+   */
+  explicit PyDatabaseNode(String mod_eq_name = "structural");
+
+  /*!
+   * \brief The function type of `HasWorkload` method.
+   * \param mod The IRModule to be searched for.
+   * \return Whether the database has the given workload.
+   */
+  using FHasWorkload = runtime::TypedPackedFunc<bool(const IRModule&)>;
+  /*!
+   * \brief The function type of `CommitWorkload` method.
+   * \param mod The IRModule to be searched for or added.
+   * \return The workload corresponding to the given IRModule.
+   */
+  using FCommitWorkload = runtime::TypedPackedFunc<Workload(const IRModule&)>;
+  /*!
+   * \brief The function type of `CommitTuningRecord` method.
+   * \param record The tuning record to be added.
+   */
+  using FCommitTuningRecord = runtime::TypedPackedFunc<void(const TuningRecord&)>;
+  /*!
+   * \brief The function type of `GetTopK` method.
+   * \param workload The workload to be searched for.
+   * \param top_k The number of top records to be returned.
+   * \return An array of top K tuning records for the given workload.
+   */
+  using FGetTopK = runtime::TypedPackedFunc<Array<TuningRecord>(const Workload&, int)>;
+  /*!
+   * \brief The function type of `GetAllTuningRecords` method.
+   * \return An Array of all the tuning records in the database.
+   */
+  using FGetAllTuningRecords = runtime::TypedPackedFunc<Array<TuningRecord>()>;
+  /*!
+   * \brief The function type of `QueryTuningRecord` method.
+   * \param mod The IRModule to be searched for.
+   * \param target The target to be searched for.
+   * \param workload_name The name of the workload to be searched for.
+   * \return The best record of the given workload; NullOpt if not found.
+   */
+  using FQueryTuningRecord = runtime::TypedPackedFunc<Optional<TuningRecord>(
+      const IRModule&, const Target&, const String&)>;
+  /*!
+   * \brief The function type of `QuerySchedule` method.
+   * \param mod The IRModule to be searched for.
+   * \param target The target to be searched for.
+   * \param workload_name The name of the workload to be searched for.
+   * \return The schedule in the best schedule of the given workload; NullOpt if not found.
+   */
+  using FQuerySchedule = runtime::TypedPackedFunc<Optional<tir::Schedule>(
+      const IRModule&, const Target&, const String&)>;
+  /*!
+   * \brief The function type of `QueryIRModule` method.
+   * \param mod The IRModule to be searched for.
+   * \param target The target to be searched for.
+   * \param workload_name The name of the workload to be searched for.
+   * \return The IRModule in the best IRModule of the given workload; NullOpt if not found.
+   */
+  using FQueryIRModule =
+      runtime::TypedPackedFunc<Optional<IRModule>(const IRModule&, const Target&, const String&)>;
+  /*!
+   * \brief The function type of `Size` method.
+   * \return The size of the database.
+   */
+  using FSize = runtime::TypedPackedFunc<int64_t()>;
+
+  /*! \brief The packed function to the `HasWorkload` function. */
+  FHasWorkload f_has_workload;
+  /*! \brief The packed function to the `CommitWorkload` function. */
+  FCommitWorkload f_commit_workload;
+  /*! \brief The packed function to the `CommitTuningRecord` function. */
+  FCommitTuningRecord f_commit_tuning_record;
+  /*! \brief The packed function to the `GetTopK` function. */
+  FGetTopK f_get_top_k;
+  /*! \brief The packed function to the `GetAllTuningRecords` function. */
+  FGetAllTuningRecords f_get_all_tuning_records;
+  /*! \brief The packed function to the `QueryTuningRecord` function. */
+  FQueryTuningRecord f_query_tuning_record;
+  /*! \brief The packed function to the `QuerySchedule` function. */
+  FQuerySchedule f_query_schedule;
+  /*! \brief The packed function to the `QueryIRModule` function. */
+  FQueryIRModule f_query_ir_module;
+  /*! \brief The packed function to the `Size` function. */
+  FSize f_size;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    // PackedFuncs are all not visited, because the reflection system doesn't take care of them,
+    // so it cannot be accessible on the python side. If there is such need from the future,
+    // we can then add corresponding accessor methods to help access on python.
+    // `f_has_workload` is not visited
+    // `f_commit_workload` is not visited
+    // `f_commit_tuning_record` is not visited
+    // `f_get_top_k` is not visited
+    // `f_get_all_tuning_records` is not visited
+    // `f_query_tuning_record` is not visited
+    // `f_query_schedule` is not visited
+    // `f_query_ir_module` is not visited
+    // `f_size` is not visited
+  }
+
+  bool HasWorkload(const IRModule& mod) final {
+    ICHECK(f_has_workload != nullptr) << "PyDatabase's HasWorkload method not implemented!";
+    return f_has_workload(mod);
+  }
+
+  Workload CommitWorkload(const IRModule& mod) final {
+    ICHECK(f_commit_workload != nullptr) << "PyDatabase's CommitWorkload method not implemented!";
+    return f_commit_workload(mod);
+  }
+
+  void CommitTuningRecord(const TuningRecord& record) final {
+    ICHECK(f_commit_tuning_record != nullptr)
+        << "PyDatabase's CommitTuningRecord method not implemented!";
+    f_commit_tuning_record(record);
+  }
+
+  Array<TuningRecord> GetTopK(const Workload& workload, int top_k) final {
+    ICHECK(f_get_top_k != nullptr) << "PyDatabase's GetTopK method not implemented!";
+    return f_get_top_k(workload, top_k);
+  }
+
+  Array<TuningRecord> GetAllTuningRecords() final {
+    ICHECK(f_get_all_tuning_records != nullptr)
+        << "PyDatabase's GetAllTuningRecords method not implemented!";
+    return f_get_all_tuning_records();
+  }
+
+  Optional<TuningRecord> QueryTuningRecord(const IRModule& mod, const Target& target,
+                                           const String& workload_name) final {
+    if (f_query_tuning_record == nullptr) {
+      return DatabaseNode::QueryTuningRecord(mod, target, workload_name);
+    } else {
+      return f_query_tuning_record(mod, target, workload_name);
+    }
+  }
+
+  Optional<tir::Schedule> QuerySchedule(const IRModule& mod, const Target& target,
+                                        const String& workload_name) final {
+    if (f_query_schedule == nullptr) {
+      return DatabaseNode::QuerySchedule(mod, target, workload_name);
+    } else {
+      return f_query_schedule(mod, target, workload_name);
+    }
+  }
+
+  Optional<IRModule> QueryIRModule(const IRModule& mod, const Target& target,
+                                   const String& workload_name) final {
+    if (f_query_ir_module == nullptr) {
+      return DatabaseNode::QueryIRModule(mod, target, workload_name);
+    } else {
+      return f_query_ir_module(mod, target, workload_name);
+    }
+  }
+
+  int64_t Size() final {
+    ICHECK(f_size != nullptr) << "PyDatabase's Size method not implemented!";
+    return f_size();
+  }
+
+  static constexpr const char* _type_key = "meta_schedule.PyDatabase";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PyDatabaseNode, DatabaseNode);
+};
+
+/*!
+ * \brief Managed reference to DatabaseNode.
+ * \sa DatabaseNode
+ */
+class Database : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief An in-memory database.
+   * \param mod_eq_name A string to specify the module equality testing and hashing method.
+   */
+  TVM_DLL static Database MemoryDatabase(String mod_eq_name = "structural");
+  /*!
+   * \brief A database for injecting handcrafted schedule functions.
+   * \param schedule_fn The function to do scheduling, which takes a TIR schedule,
+   * and returns a boolean indicating if the schedule is successful.
+   * \param mod_eq_name A string to specify the module equality testing and hashing method.
+   */
+  TVM_DLL static Database ScheduleFnDatabase(
+      runtime::TypedPackedFunc<bool(tir::Schedule)> schedule_fn, String mod_eq_name = "structural");
+  /*!
+   * \brief Create a default database that uses JSON file for tuning records.
+   * \param path_workload The path to the workload table.
+   * \param path_tuning_record The path to the database table.
+   * \param allow_missing Whether to create new file when the given path is not found.
+   * \param mod_eq_name A string to specify the module equality testing and hashing method.
+   */
+  TVM_DLL static Database JSONDatabase(String path_workload, String path_tuning_record,
+                                       bool allow_missing, String mod_eq_name = "structural");
+  /*!
+   * \brief A database composed of multiple databases, allowing users to guide IR rewriting using
+   * combined knowledge of those databases. To each query, it returns the best record among all the
+   * databases given.
+   * \param databases The list of databases to be combined.
+   * \return The combined database.
+   */
+  TVM_DLL static Database UnionDatabase(Array<Database, void> databases);
+  /*!
+   * \brief A database composed of multiple databases, allowing users to guide IR rewriting using
+   * combined knowledge of those databases. To each query, it returns the record from the first
+   * database that responds to the query.
+   * \param databases The database to be subsetted.
+   * \return The subsetted database.
+   */
+  TVM_DLL static Database OrderedUnionDatabase(Array<Database, void> databases);
+  /*!
+   * \brief Create a database with customized methods on the python-side.
+   * \param f_has_workload The packed function of `HasWorkload`.
+   * \param f_commit_workload The packed function of `CommitWorkload`.
+   * \param f_commit_tuning_record The packed function of `CommitTuningRecord`.
+   * \param f_get_top_k The packed function of `GetTopK`.
+   * \param f_get_all_tuning_records The packed function of `GetAllTuningRecords`.
+   * \param f_query_tuning_record The packed function of `QueryTuningRecord`.
+   * \param f_query_schedule The packed function of `QuerySchedule`.
+   * \param f_query_ir_module The packed function of `QueryIRModule`.
+   * \param f_size The packed function of `Size`.
+   * \param mod_eq_name A string to specify the module equality testing and hashing method.
+   * \return The created database.
+   */
+  TVM_DLL static Database PyDatabase(PyDatabaseNode::FHasWorkload f_has_workload,
+                                     PyDatabaseNode::FCommitWorkload f_commit_workload,
+                                     PyDatabaseNode::FCommitTuningRecord f_commit_tuning_record,
+                                     PyDatabaseNode::FGetTopK f_get_top_k,
+                                     PyDatabaseNode::FGetAllTuningRecords f_get_all_tuning_records,
+                                     PyDatabaseNode::FQueryTuningRecord f_query_tuning_record,
+                                     PyDatabaseNode::FQuerySchedule f_query_schedule,
+                                     PyDatabaseNode::FQueryIRModule f_query_ir_module,
+                                     PyDatabaseNode::FSize f_size,
+                                     String mod_eq_name = "structural");
+  /*! \return The current Database in the scope. */
+  static Optional<Database> Current();
+  /*! \brief Entering the scope of the context manager */
+  void EnterWithScope();
+  /*! \brief Exiting the scope of the context manager */
+  void ExitWithScope();
+
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(Database, runtime::ObjectRef, DatabaseNode);
+};
+
+}  // namespace meta_schedule
+}  // namespace tvm
+
+#endif  // TVM_META_SCHEDULE_DATABASE_H_
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/extracted_task.h b/darknet_drp_ros/include/tvm/meta_schedule/extracted_task.h
new file mode 100644
index 0000000..239bf0d
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/meta_schedule/extracted_task.h
@@ -0,0 +1,82 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_META_SCHEDULE_EXTRACTED_TASK_H_
+#define TVM_META_SCHEDULE_EXTRACTED_TASK_H_
+
+#include <tvm/ir/module.h>
+#include <tvm/node/reflection.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/runtime/object.h>
+#include <tvm/target/target.h>
+
+namespace tvm {
+namespace tir {
+class PrimFunc;
+}  // namespace tir
+namespace te {
+class Tensor;
+}  // namespace te
+}  // namespace tvm
+
+namespace tvm {
+namespace meta_schedule {
+
+/*! \brief A tuning task extracted from the high-level IR */
+class ExtractedTaskNode : public runtime::Object {
+ public:
+  /*! \brief The name of the task extracted */
+  String task_name;
+  /*! \brief The high-level IR */
+  IRModule mod;
+  /*! \brief Target */
+  Target target;
+  /*! \brief A list of low-level IRs that the high-level IR could potentially dispatch to */
+  Array<IRModule> dispatched;
+  /*! \brief Weight of the task */
+  int weight;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("task_name", &task_name);
+    v->Visit("mod", &mod);
+    v->Visit("target", &target);
+    v->Visit("dispatched", &dispatched);
+    v->Visit("weight", &weight);
+  }
+
+  static constexpr const char* _type_key = "meta_schedule.ExtractedTask";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ExtractedTaskNode, runtime::Object);
+};
+
+/*!
+ * \brief Managed reference to ExtractedTaskNode
+ * \sa ExtractedTaskNode
+ */
+class ExtractedTask : public runtime::ObjectRef {
+ public:
+  explicit ExtractedTask(String task_name, IRModule mod, Target target, Array<IRModule> dispatched,
+                         int weight);
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(ExtractedTask, runtime::ObjectRef,
+                                                    ExtractedTaskNode);
+};
+
+}  // namespace meta_schedule
+}  // namespace tvm
+
+#endif  // TVM_META_SCHEDULE_EXTRACTED_TASK_H_
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/feature_extractor.h b/darknet_drp_ros/include/tvm/meta_schedule/feature_extractor.h
new file mode 100644
index 0000000..4165e5e
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/meta_schedule/feature_extractor.h
@@ -0,0 +1,126 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+#ifndef TVM_META_SCHEDULE_FEATURE_EXTRACTOR_H_
+#define TVM_META_SCHEDULE_FEATURE_EXTRACTOR_H_
+
+#include <tvm/meta_schedule/measure_candidate.h>
+#include <tvm/node/reflection.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/runtime/ndarray.h>
+#include <tvm/runtime/object.h>
+#include <tvm/runtime/packed_func.h>
+
+namespace tvm {
+namespace meta_schedule {
+
+class TuneContext;
+
+/*! \brief Extractor for features from measure candidates for use in cost model. */
+class FeatureExtractorNode : public runtime::Object {
+ public:
+  /*! \brief Virtual destructor. */
+  virtual ~FeatureExtractorNode() = default;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {}
+
+  /*!
+   * \brief Extract features from the given measure candidate.
+   * \param context The tuning context for feature extraction.
+   * \param candidates The measure candidates to extract features from.
+   * \return The feature ndarray extracted.
+   */
+  virtual Array<tvm::runtime::NDArray> ExtractFrom(const TuneContext& context,
+                                                   const Array<MeasureCandidate>& candidates) = 0;
+
+  static constexpr const char* _type_key = "meta_schedule.FeatureExtractor";
+  TVM_DECLARE_BASE_OBJECT_INFO(FeatureExtractorNode, Object);
+};
+
+/*! \brief The feature extractor with customized methods on the python-side. */
+class PyFeatureExtractorNode : public FeatureExtractorNode {
+ public:
+  /*!
+   * \brief Extract features from the given measure candidate.
+   * \param context The tuning context for feature extraction.
+   * \param candidates The measure candidates to extract features from.
+   * \return The feature ndarray extracted.
+   */
+  using FExtractFrom = runtime::TypedPackedFunc<Array<tvm::runtime::NDArray>(
+      const TuneContext& context, const Array<MeasureCandidate>& candidates)>;
+  /*!
+   * \brief Get the feature extractor as string with name.
+   * \return The string of the feature extractor.
+   */
+  using FAsString = runtime::TypedPackedFunc<String()>;
+
+  /*! \brief The packed function to the `ExtractFrom` function. */
+  FExtractFrom f_extract_from;
+  /*! \brief The packed function to the `AsString` function. */
+  FAsString f_as_string;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    // `f_extract_from` is not visited
+    // `f_as_string` is not visited
+  }
+
+  Array<tvm::runtime::NDArray> ExtractFrom(const TuneContext& context,
+                                           const Array<MeasureCandidate>& candidates) final;
+
+  static constexpr const char* _type_key = "meta_schedule.PyFeatureExtractor";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PyFeatureExtractorNode, FeatureExtractorNode);
+};
+
+/*!
+ * \brief Managed reference to FeatureExtractorNode
+ * \sa FeatureExtractorNode
+ */
+class FeatureExtractor : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief Create a feature extractor that extracts features from each BufferStore
+   * \param buffers_per_store The number of buffers in each BufferStore; Pad or truncate if
+   * necessary.
+   * \param arith_intensity_curve_num_samples The number of samples used in the arithmetic intensity
+   * curve.
+   * \param cache_line_bytes The number of bytes in a cache line.
+   * \param extract_workload Whether to extract features in the workload in tuning context or not.
+   * \return The feature extractor created.
+   */
+  TVM_DLL static FeatureExtractor PerStoreFeature(int buffers_per_store = 5,
+                                                  int arith_intensity_curve_num_samples = 10,
+                                                  int cache_line_bytes = 64,
+                                                  bool extract_workload = false);
+  /*!
+   * \brief Create a feature extractor with customized methods on the python-side.
+   * \param f_extract_from The packed function of `ExtractFrom`.
+   * \param f_as_string The packed function of `AsString`.
+   * \return The feature extractor created.
+   */
+  TVM_DLL static FeatureExtractor PyFeatureExtractor(
+      PyFeatureExtractorNode::FExtractFrom f_extract_from,
+      PyFeatureExtractorNode::FAsString f_as_string);
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(FeatureExtractor, ObjectRef, FeatureExtractorNode);
+};
+
+}  // namespace meta_schedule
+}  // namespace tvm
+
+#endif  // TVM_META_SCHEDULE_FEATURE_EXTRACTOR_H_
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/measure_callback.h b/darknet_drp_ros/include/tvm/meta_schedule/measure_callback.h
new file mode 100644
index 0000000..30d1c2c
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/meta_schedule/measure_callback.h
@@ -0,0 +1,146 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+#ifndef TVM_META_SCHEDULE_MEASURE_CALLBACK_H_
+#define TVM_META_SCHEDULE_MEASURE_CALLBACK_H_
+
+#include <tvm/meta_schedule/builder.h>
+#include <tvm/meta_schedule/measure_candidate.h>
+#include <tvm/meta_schedule/runner.h>
+#include <tvm/meta_schedule/search_strategy.h>
+#include <tvm/meta_schedule/tune_context.h>
+#include <tvm/node/reflection.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/runtime/object.h>
+#include <tvm/runtime/packed_func.h>
+
+namespace tvm {
+namespace meta_schedule {
+
+class TaskScheduler;
+
+/*! \brief Rules to apply after measure results is available. */
+class MeasureCallbackNode : public runtime::Object {
+ public:
+  /*! \brief Virtual destructor. */
+  virtual ~MeasureCallbackNode() = default;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {}
+
+  /*!
+   * \brief Apply a measure callback rule with given arguments.
+   * \param task_scheduler The task scheduler.
+   * \param task_id The id of the task (tune context) to apply measure callbacks.
+   * \param measure_candidates The measure candidates.
+   * \param builder_results The builder results by building the measure candidates.
+   * \param runner_results The runner results by running the built measure candidates.
+   */
+  virtual void Apply(const TaskScheduler& task_scheduler,                //
+                     int task_id,                                        //
+                     const Array<MeasureCandidate>& measure_candidates,  //
+                     const Array<BuilderResult>& builder_results,        //
+                     const Array<RunnerResult>& runner_results) = 0;
+
+  static constexpr const char* _type_key = "meta_schedule.MeasureCallback";
+  TVM_DECLARE_BASE_OBJECT_INFO(MeasureCallbackNode, Object);
+};
+
+/*! \brief The measure callback with customized methods on the python-side. */
+class PyMeasureCallbackNode : public MeasureCallbackNode {
+ public:
+  /*!
+   * \brief Apply a measure callback to the given schedule.
+   * \param task_scheduler The task scheduler.
+   * \param tasks The list of tune context to process.
+   * \param measure_candidates The measure candidates.
+   * \param builds The builder results by building the measure candidates.
+   * \param results The runner results by running the built measure candidates.
+   * \return Whether the measure callback was successfully applied.
+   */
+  using FApply =
+      runtime::TypedPackedFunc<void(const TaskScheduler& task_scheduler,                //
+                                    int task_id,                                        //
+                                    const Array<MeasureCandidate>& measure_candidates,  //
+                                    const Array<BuilderResult>& builds,                 //
+                                    const Array<RunnerResult>& results)>;
+  /*!
+   * \brief Get the measure callback function as string with name.
+   * \return The string of the measure callback function.
+   */
+  using FAsString = runtime::TypedPackedFunc<String()>;
+
+  /*! \brief The packed function to the `Apply` function. */
+  FApply f_apply;
+  /*! \brief The packed function to the `AsString` function. */
+  FAsString f_as_string;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    // `f_apply` is not visited
+    // `f_as_string` is not visited
+  }
+
+  void Apply(const TaskScheduler& task_scheduler,                //
+             int task_id,                                        //
+             const Array<MeasureCandidate>& measure_candidates,  //
+             const Array<BuilderResult>& builds,                 //
+             const Array<RunnerResult>& results);
+
+  static constexpr const char* _type_key = "meta_schedule.PyMeasureCallback";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PyMeasureCallbackNode, MeasureCallbackNode);
+};
+
+/*!
+ * \brief Managed reference to MeasureCallbackNode
+ * \sa MeasureCallbackNode
+ */
+class MeasureCallback : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief Create a measure callback that adds the measurement results into the database
+   * \return The measure callback created.
+   */
+  TVM_DLL static MeasureCallback AddToDatabase();
+  /*!
+   * \brief Create a measure callback that removes the build artifacts from the disk
+   * \return The measure callback created.
+   */
+  TVM_DLL static MeasureCallback RemoveBuildArtifact();
+  /*!
+   * \brief Create a measure callback that updates the cost model with measurement result.
+   * \return The measure callback created.
+   */
+  TVM_DLL static MeasureCallback UpdateCostModel();
+  /*!
+   * \brief Create a measure callback with customized methods on the python-side.
+   * \param f_apply The packed function of `Apply`.
+   * \param f_as_string The packed function of `AsString`.
+   * \return The measure callback created.
+   */
+  TVM_DLL static MeasureCallback PyMeasureCallback(PyMeasureCallbackNode::FApply f_apply,
+                                                   PyMeasureCallbackNode::FAsString f_as_string);
+  /*! \brief The default list of measure callbacks. */
+  TVM_DLL static Array<MeasureCallback, void> Default();
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(MeasureCallback, ObjectRef, MeasureCallbackNode);
+};
+
+}  // namespace meta_schedule
+}  // namespace tvm
+
+#endif  // TVM_META_SCHEDULE_MEASURE_CALLBACK_H_
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/measure_candidate.h b/darknet_drp_ros/include/tvm/meta_schedule/measure_candidate.h
new file mode 100644
index 0000000..f7257b5
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/meta_schedule/measure_candidate.h
@@ -0,0 +1,67 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+#ifndef TVM_META_SCHEDULE_MEASURE_CANDIDATE_H_
+#define TVM_META_SCHEDULE_MEASURE_CANDIDATE_H_
+
+#include <tvm/meta_schedule/arg_info.h>
+#include <tvm/node/reflection.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/object.h>
+#include <tvm/tir/schedule/schedule.h>
+
+namespace tvm {
+namespace meta_schedule {
+
+/*! \brief The schedule (with input shapes) to be measured. */
+class MeasureCandidateNode : public runtime::Object {
+ public:
+  /*! \brief The schedule for measurement. */
+  tir::Schedule sch;
+  /*! \brief The argument information, e.g., (shape, dtype) for tensors. */
+  Array<ArgInfo> args_info;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("sch", &sch);
+    v->Visit("args_info", &args_info);
+  }
+
+  static constexpr const char* _type_key = "meta_schedule.MeasureCandidate";
+  TVM_DECLARE_FINAL_OBJECT_INFO(MeasureCandidateNode, Object);
+};
+
+/*!
+ * \brief Managed reference to MeasureCandidateNode.
+ * \sa MeasureCandidateNode
+ */
+class MeasureCandidate : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief Constructor of MeasureCandidate.
+   * \param sch The schedule for measurement.
+   * \param args_info The argument information, e.g., (shape, dtype) for tensors.
+   */
+  TVM_DLL MeasureCandidate(tir::Schedule sch, Array<ArgInfo> args_info);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(MeasureCandidate, ObjectRef, MeasureCandidateNode);
+};
+
+}  // namespace meta_schedule
+}  // namespace tvm
+
+#endif  // TVM_META_SCHEDULE_MEASURE_CANDIDATE_H_
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/mutator.h b/darknet_drp_ros/include/tvm/meta_schedule/mutator.h
new file mode 100644
index 0000000..4095d6c
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/meta_schedule/mutator.h
@@ -0,0 +1,181 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+#ifndef TVM_META_SCHEDULE_MUTATOR_H_
+#define TVM_META_SCHEDULE_MUTATOR_H_
+
+#include <tvm/node/reflection.h>
+#include <tvm/runtime/container/optional.h>
+#include <tvm/runtime/object.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/support/random_engine.h>
+#include <tvm/tir/schedule/schedule.h>
+#include <tvm/tir/schedule/trace.h>
+
+namespace tvm {
+namespace meta_schedule {
+
+class TuneContext;
+class Mutator;
+
+/*! \brief Mutator is designed to mutate the trace to explore the design space. */
+class MutatorNode : public runtime::Object {
+ public:
+  /*! \brief Virtual destructor. */
+  virtual ~MutatorNode() = default;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {}
+
+  /*!
+   * \brief Initialize the design space generator with tuning context.
+   * \param context The tuning context for initialization.
+   * \note This method is supposed to be called only once before every other method.
+   */
+  virtual void InitializeWithTuneContext(const TuneContext& context) = 0;
+
+  /*!
+   * \brief Apply the mutator function to the given trace.
+   * \param trace The given trace for mutation.
+   * \param rand_state The random state for mutation.
+   * \return None if mutator failed, otherwise return the mutated trace.
+   */
+  virtual Optional<tir::Trace> Apply(const tir::Trace& trace,
+                                     support::LinearCongruentialEngine::TRandState* rand_state) = 0;
+
+  /*!
+   * \brief Clone the mutator.
+   * \return The cloned mutator.
+   */
+  virtual Mutator Clone() const = 0;
+
+  static constexpr const char* _type_key = "meta_schedule.Mutator";
+  TVM_DECLARE_BASE_OBJECT_INFO(MutatorNode, Object);
+};
+
+/*!
+ * \brief Managed reference to MutatorNode
+ * \sa MutatorNode
+ */
+class Mutator : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief The function type of `InitializeWithTuneContext` method.
+   * \param context The tuning context for initialization.
+   */
+  using FInitializeWithTuneContext = runtime::TypedPackedFunc<void(const TuneContext&)>;
+  /*!
+   * \brief Apply the mutator function to the given trace.
+   * \param trace The given trace for mutation.
+   * \return None if mutator failed, otherwise return the mutated trace.
+   */
+  using FApply = runtime::TypedPackedFunc<Optional<tir::Trace>(
+      const tir::Trace&, support::LinearCongruentialEngine::TRandState rand_state)>;
+  /*!
+   * \brief Clone the mutator.
+   * \return The cloned mutator.
+   */
+  using FClone = runtime::TypedPackedFunc<Mutator()>;
+  /*!
+   * \brief Get the mutator as string with name.
+   * \return The string of the mutator.
+   */
+  using FAsString = runtime::TypedPackedFunc<String()>;
+  /*! \brief Create a Mutator that mutates the decision of instruction Sample-Perfect-Tile */
+  TVM_DLL static Mutator MutateTileSize();
+  /*!
+   * \brief Create a Mutator that mutates the parallel extent
+   * \param max_jobs_per_core The maximum number of parallel jobs per core.
+   * \return The created mutator.
+   */
+  TVM_DLL static Mutator MutateParallel(int64_t max_jobs_per_core);
+  /*!
+   * \brief Create a Mutator that mutates auto unroll step
+   * \return The mutator created
+   */
+  TVM_DLL static Mutator MutateUnroll();
+  /*!
+   * \brief Create a Mutator that mutates the outcome of SampleComputeLocation
+   * \return The mutator created
+   */
+  TVM_DLL static Mutator MutateComputeLocation();
+  /*!
+   * \brief Create a Mutator that mutates auto thread binding.
+   * \return The mutator created
+   */
+  TVM_DLL static Mutator MutateThreadBinding();
+  /*!
+   * \brief Create a mutator with customized methods on the python-side.
+   * \param f_initialize_with_tune_context The packed function of `InitializeWithTuneContext`.
+   * \param f_apply The packed function of `Apply`.
+   * \param f_clone The packed function of `Clone`.
+   * \param f_as_string The packed function of `AsString`.
+   * \return The mutator created.
+   */
+  TVM_DLL static Mutator PyMutator(FInitializeWithTuneContext f_initialize_with_tune_context,
+                                   FApply f_apply, FClone f_clone, FAsString f_as_string);
+  /*! \brief Create default mutators for LLVM */
+  TVM_DLL static Map<Mutator, FloatImm, void> DefaultLLVM();
+  /*! \brief Create default mutators for x86 VNNI */
+  TVM_DLL static Map<Mutator, FloatImm, void> DefaultVNNI();
+  /*! \brief Create default mutators for CUDA */
+  TVM_DLL static Map<Mutator, FloatImm, void> DefaultCUDA();
+  /*! \brief Create default mutators for CUDA with TensorCore */
+  TVM_DLL static Map<Mutator, FloatImm, void> DefaultCUDATensorCore();
+  /*! \brief Create default mutators for Hexagon */
+  TVM_DLL static Map<Mutator, FloatImm, void> DefaultHexagon();
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(Mutator, ObjectRef, MutatorNode);
+};
+
+/*! \brief The mutator with customized methods on the python-side. */
+class PyMutatorNode : public MutatorNode {
+ public:
+  using FInitializeWithTuneContext = Mutator::FInitializeWithTuneContext;
+  using FApply = Mutator::FApply;
+  using FClone = Mutator::FClone;
+  using FAsString = Mutator::FAsString;
+  /*! \brief The packed function to the `InitializeWithTuneContext` function. */
+  FInitializeWithTuneContext f_initialize_with_tune_context;
+  /*! \brief The packed function to the `Apply` function. */
+  FApply f_apply;
+  /*! \brief The packed function to the `Clone` function. */
+  FClone f_clone;
+  /*! \brief The packed function to the `AsString` function. */
+  FAsString f_as_string;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    // `f_initialize_with_tune_context` is not visited
+    // `f_apply` is not visited
+    // `f_clone` is not visited
+    // `f_as_string` is not visited
+  }
+
+  void InitializeWithTuneContext(const TuneContext& context) final;
+  Optional<tir::Trace> Apply(const tir::Trace& trace,
+                             support::LinearCongruentialEngine::TRandState* rand_state) final;
+  Mutator Clone() const final;
+
+  static constexpr const char* _type_key = "meta_schedule.PyMutator";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PyMutatorNode, MutatorNode);
+};
+
+}  // namespace meta_schedule
+}  // namespace tvm
+
+#endif  // TVM_META_SCHEDULE_MUTATOR_H_
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/postproc.h b/darknet_drp_ros/include/tvm/meta_schedule/postproc.h
new file mode 100644
index 0000000..76f8d71
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/meta_schedule/postproc.h
@@ -0,0 +1,206 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+#ifndef TVM_META_SCHEDULE_POSTPROC_H_
+#define TVM_META_SCHEDULE_POSTPROC_H_
+
+#include <tvm/node/reflection.h>
+#include <tvm/runtime/object.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/tir/schedule/schedule.h>
+
+namespace tvm {
+namespace meta_schedule {
+
+class TuneContext;
+class Postproc;
+
+/*!
+ * \brief Rules to apply a postprocessor to a schedule.
+ */
+class PostprocNode : public runtime::Object {
+ public:
+  /*! \brief Virtual destructor. */
+  virtual ~PostprocNode() = default;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {}
+
+  /*!
+   * \brief Initialize the design space generator with tuning context.
+   * \param context The tuning context for initialization.
+   * \note This method is supposed to be called only once before every other method.
+   */
+  virtual void InitializeWithTuneContext(const TuneContext& context) = 0;
+
+  /*!
+   * \brief Apply a postprocessor to the given schedule.
+   * \param sch The schedule to be post processed.
+   * \return Whether the postprocessor was successfully applied.
+   */
+  virtual bool Apply(const tir::Schedule& sch) = 0;
+
+  /*!
+   * \brief Clone the postprocessor.
+   * \return The cloned postprocessor.
+   */
+  virtual Postproc Clone() const = 0;
+
+  static constexpr const char* _type_key = "meta_schedule.Postproc";
+  TVM_DECLARE_BASE_OBJECT_INFO(PostprocNode, Object);
+};
+
+/*!
+ * \brief Managed reference to PostprocNode
+ * \sa PostprocNode
+ */
+class Postproc : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief The function type of `InitializeWithTuneContext` method.
+   * \param context The tuning context for initialization.
+   */
+  using FInitializeWithTuneContext = runtime::TypedPackedFunc<void(const TuneContext&)>;
+  /*!
+   * \brief Apply a postprocessor to the given schedule.
+   * \param sch The schedule to be post processed.
+   * \return Whether the postprocessor was successfully applied.
+   */
+  using FApply = runtime::TypedPackedFunc<bool(const tir::Schedule&)>;
+  /*!
+   * \brief Clone the postprocessor.
+   * \return The cloned postprocessor.
+   */
+  using FClone = runtime::TypedPackedFunc<Postproc()>;
+  /*!
+   * \brief Get the postprocessor function as string with name.
+   * \return The string of the postprocessor function.
+   */
+  using FAsString = runtime::TypedPackedFunc<String()>;
+  /*!
+   * \brief Create a postprocessor with customized methods on the python-side.
+   * \param f_initialize_with_tune_context The packed function of `InitializeWithTuneContext`.
+   * \param f_apply The packed function of `Apply`.
+   * \param f_clone The packed function of `Clone`.
+   * \param f_as_string The packed function of `AsString`.
+   * \return The postprocessor created.
+   */
+  TVM_DLL static Postproc PyPostproc(FInitializeWithTuneContext f_initialize_with_tune_context,  //
+                                     FApply f_apply,                                             //
+                                     FClone f_clone,                                             //
+                                     FAsString f_as_string);
+  /*!
+   * \brief Create a postprocessor that checks if all loops are static
+   * \return The postprocessor created
+   */
+  TVM_DLL static Postproc DisallowDynamicLoop();
+  /*!
+   * \brief Create a postprocessor that rewrites the cooperative fetch annotation to
+   * actual vectorized cooperative fetching in loop bindings.
+   * \return The postprocessor created.
+   */
+  TVM_DLL static Postproc RewriteCooperativeFetch();
+  /*!
+   * \brief Creates a postprocessor that applies parallelization, vectorization and auto unrolling
+   * according to the annotation of each block
+   * \return The postprocessor created
+   */
+  TVM_DLL static Postproc RewriteParallelVectorizeUnroll();
+  /*!
+   * \brief Create a postprocessor that rewrites reduction block by moving the init block out.
+   * \return The postprocessor created.
+   */
+  TVM_DLL static Postproc RewriteReductionBlock();
+  /*!
+   * \brief Create a postprocessor that adds thread binding to unbound blocks
+   * \param max_threadblocks The max number of threadblocks in the cuda device.
+   * \return The postprocessor created.
+   */
+  TVM_DLL static Postproc RewriteUnboundBlock(int max_threadblocks);
+  /*!
+   * \brief Create a postprocessor that applies tensorization to annotated blocks
+   * \param vectorize_init_loop Whether or not vectorize the initialization loop produced by
+   * DecomposeReduction
+   * \return The postprocessor created.
+   */
+  TVM_DLL static Postproc RewriteTensorize(bool vectorize_init_loop = false);
+  /*!
+   * \brief Creates a postprocessor that verifies if the GPU code is correct
+   * \return The postprocessor created
+   */
+  TVM_DLL static Postproc VerifyGPUCode();
+  /*!
+   * \brief Verifies that the VTCM usage of a given schedule is within the provided limit.
+   * \return The postprocessor created
+   */
+  TVM_DLL static Postproc VerifyVTCMLimit();
+  /*!
+   * \brief Creates a postprocessor that rewrites the layout of input tensor
+   * \note Weight layout rewrite is supported so far, activation layout rewrite will be added.
+   * \return The postprocessor created
+   */
+  TVM_DLL static Postproc RewriteLayout();
+  /*! \brief Create default postprocessors for LLVM */
+  TVM_DLL static Array<Postproc, void> DefaultLLVM();
+  /*! \brief Create default postprocessors for x86 VNNI */
+  TVM_DLL static Array<Postproc, void> DefaultVNNI();
+  /*! \brief Create default postprocessors for CUDA */
+  TVM_DLL static Array<Postproc, void> DefaultCUDA();
+  /*! \brief Create default postprocessors for CUDA with TensorCore */
+  TVM_DLL static Array<Postproc, void> DefaultCUDATensorCore();
+  /*! \brief Create default postprocessors for Hexagon */
+  TVM_DLL static Array<Postproc, void> DefaultHexagon();
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(Postproc, ObjectRef, PostprocNode);
+};
+
+/*! \brief The postprocessor with customized methods on the python-side. */
+class PyPostprocNode : public PostprocNode {
+ public:
+  using FInitializeWithTuneContext = Postproc::FInitializeWithTuneContext;
+  using FApply = Postproc::FApply;
+  using FClone = Postproc::FClone;
+  using FAsString = Postproc::FAsString;
+  /*! \brief The packed function to the `InitializeWithTuneContext` function. */
+  FInitializeWithTuneContext f_initialize_with_tune_context;
+  /*! \brief The packed function to the `Apply` function. */
+  FApply f_apply;
+  /*! \brief The packed function to the `Clone` function. */
+  FClone f_clone;
+  /*! \brief The packed function to the `AsString` function. */
+  FAsString f_as_string;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    // `f_initialize_with_tune_context` is not visited
+    // `f_apply` is not visited
+    // `f_clone` is not visited
+    // `f_as_string` is not visited
+  }
+
+  void InitializeWithTuneContext(const TuneContext& context) final;
+  bool Apply(const tir::Schedule& sch) final;
+  Postproc Clone() const final;
+
+  static constexpr const char* _type_key = "meta_schedule.PyPostproc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PyPostprocNode, PostprocNode);
+};
+
+}  // namespace meta_schedule
+}  // namespace tvm
+
+#endif  // TVM_META_SCHEDULE_POSTPROC_H_
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/profiler.h b/darknet_drp_ros/include/tvm/meta_schedule/profiler.h
new file mode 100644
index 0000000..0f6572c
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/meta_schedule/profiler.h
@@ -0,0 +1,103 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_META_SCHEDULE_PROFILER_H_
+#define TVM_META_SCHEDULE_PROFILER_H_
+
+#include <tvm/ir/module.h>
+#include <tvm/node/reflection.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/optional.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/runtime/object.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/target/target.h>
+
+#include <string>
+#include <unordered_map>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+namespace meta_schedule {
+
+class ScopedTimer {
+ public:
+  ~ScopedTimer() {
+    if (deferred_ != nullptr) {
+      deferred_();
+    }
+  }
+
+ private:
+  friend class Profiler;
+
+  explicit ScopedTimer(runtime::TypedPackedFunc<void()> deferred) : deferred_(deferred) {}
+  runtime::TypedPackedFunc<void()> deferred_;
+};
+
+/*! \brief A generic profiler */
+class ProfilerNode : public runtime::Object {
+ public:
+  /*! \brief The segments that are already profiled */
+  std::unordered_map<std::string, double> stats_sec;
+  /*! \brief Counter for the total time used */
+  runtime::PackedFunc total_timer;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    // `stats_sec` is not visited.
+    // `total_timer` is not visited.
+  }
+
+  static constexpr const char* _type_key = "meta_schedule.Profiler";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ProfilerNode, runtime::Object);
+
+ public:
+  /*! \brief Get the internal stats of the running time */
+  Map<String, FloatImm> Get() const;
+  /*! \brief Return a summary of profiling results as table format */
+  String Table() const;
+};
+
+/*!
+ * \brief Managed reference to ProfilerNode
+ * \sa ProfilerNode
+ */
+class Profiler : public runtime::ObjectRef {
+ public:
+  Profiler();
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(Profiler, runtime::ObjectRef, ProfilerNode);
+
+  /*! \brief Entering the scope of the context manager */
+  void EnterWithScope();
+  /*! \brief Exiting the scope of the context manager */
+  void ExitWithScope();
+  /*! \brief Returns the current profiler */
+  static Optional<Profiler> Current();
+  /*!
+   * \brief Profile the time usage in the given scope in the given name.
+   * \param name Name for the scope.
+   * \return A scope timer for time profiling.
+   */
+  static ScopedTimer TimedScope(String name);
+};
+
+}  // namespace meta_schedule
+}  // namespace tvm
+
+#endif  // TVM_META_SCHEDULE_PROFILER_H_
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/runner.h b/darknet_drp_ros/include/tvm/meta_schedule/runner.h
new file mode 100644
index 0000000..c095728
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/meta_schedule/runner.h
@@ -0,0 +1,234 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_META_SCHEDULE_RUNNER_H_
+#define TVM_META_SCHEDULE_RUNNER_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/meta_schedule/arg_info.h>
+#include <tvm/node/reflection.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/optional.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/runtime/object.h>
+#include <tvm/runtime/packed_func.h>
+
+namespace tvm {
+namespace meta_schedule {
+
+/*! \brief Runner's input containing path of artifact, type of device and argument info. */
+class RunnerInputNode : public runtime::Object {
+ public:
+  /*! \brief The path to the built artifact. */
+  String artifact_path;
+  /*! \brief The type of device. */
+  String device_type;
+  /*! \brief The argument information. */
+  Array<ArgInfo> args_info;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("artifact_path", &artifact_path);
+    v->Visit("device_type", &device_type);
+    v->Visit("args_info", &args_info);
+  }
+
+  static constexpr const char* _type_key = "meta_schedule.RunnerInput";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RunnerInputNode, runtime::Object);
+};
+
+/*!
+ * \brief Managed reference to RunnerInputNode
+ * \sa RunnerInputNode
+ */
+class RunnerInput : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief Constructor of RunnerInput
+   * \param artifact_path The path to the built artifact.
+   * \param device_type The type of device.
+   * \param args_info The argument information.
+   */
+  TVM_DLL explicit RunnerInput(String artifact_path, String device_type, Array<ArgInfo> args_info);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(RunnerInput, runtime::ObjectRef, RunnerInputNode);
+};
+
+/*! \brief Runner's output containing measurement result of MeasureCandidate or error msg if any. */
+class RunnerResultNode : public runtime::Object {
+ public:
+  /*! \brief The run time in seconds.*/
+  Optional<Array<FloatImm>> run_secs;
+  /*! \brief The error message, if any. */
+  Optional<String> error_msg;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("run_secs", &run_secs);
+    v->Visit("error_msg", &error_msg);
+  }
+
+  static constexpr const char* _type_key = "meta_schedule.RunnerResult";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RunnerResultNode, runtime::Object);
+};
+
+/*!
+ * \brief Managed reference to RunnerResultNode
+ * \sa RunnerResultNode
+ */
+class RunnerResult : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief Constructor
+   * \brief The run time in seconds.
+   * \brief The error message, if any.
+   */
+  TVM_DLL explicit RunnerResult(Optional<Array<FloatImm>> run_secs, Optional<String> error_msg);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(RunnerResult, runtime::ObjectRef, RunnerResultNode);
+};
+
+/*!
+ * \brief A class to asynchronously fetch runner's output.
+ * \note The API design is consistent with python's concurrent.futures.Future:
+ *  https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Future
+ */
+class RunnerFutureNode : public runtime::Object {
+ public:
+  /*!
+   * \brief The function type to check whether the runner has finished.
+   * \return Whether the runner's output is ready.
+   */
+  using FDone = runtime::TypedPackedFunc<bool()>;
+  /*!
+   * \brief The function type to fetch runner output if it is ready.
+   * \return The runner's output.
+   */
+  using FResult = runtime::TypedPackedFunc<RunnerResult()>;
+
+  /*! \brief The packed function to check whether the runner has finished. */
+  FDone f_done;
+  /*! \brief The packed function to fetch runner output if it is ready. */
+  FResult f_result;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    // `f_done` is not visited
+    // `f_result` is not visited
+  }
+
+  /*!
+   * \brief Check whether the runner has finished.
+   * \return A boolean indicating whether the runner has finished.
+   */
+  bool Done() const {
+    ICHECK(f_done != nullptr) << "PyRunnerFuture's Done method not implemented!";
+    return f_done();
+  }
+  /*!
+   * \brief Fetch the runner's output if it is ready.
+   * \return The runner's output.
+   */
+  RunnerResult Result() const {
+    ICHECK(f_result != nullptr) << "PyRunnerFuture's Result method not implemented!";
+    return f_result();
+  }
+
+  static constexpr const char* _type_key = "meta_schedule.RunnerFuture";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RunnerFutureNode, runtime::Object);
+};
+
+/*!
+ * \brief Managed reference to RunnerFutureNode
+ * \sa RunnerFutureNode
+ */
+class RunnerFuture : public runtime::ObjectRef {
+ public:
+  using FDone = RunnerFutureNode::FDone;
+  using FResult = RunnerFutureNode::FResult;
+
+  /*!
+   * \brief Constructor of RunnerFuture
+   * \param f_done The packed function to check whether the runner has finished.
+   * \param f_result The packed function to fetch runner output if it is ready.
+   */
+  TVM_DLL explicit RunnerFuture(FDone f_done, FResult f_result);
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(RunnerFuture, runtime::ObjectRef,
+                                                    RunnerFutureNode);
+};
+
+/*! \brief The abstract runner interface. */
+class RunnerNode : public runtime::Object {
+ public:
+  /*!
+   * \brief The function type to run the built artifacts and get runner futures.
+   * \param input The runner's inputs.
+   * \return The runner futures.
+   * \sa RunnerFuture
+   */
+  using FRun = runtime::TypedPackedFunc<Array<RunnerFuture>(Array<RunnerInput>)>;
+
+  /*! \brief Default destructor */
+  virtual ~RunnerNode() = default;
+
+  /*!
+   * \brief Run the built artifact and get runner futures.
+   * \param runner_inputs The runner's inputs.
+   * \return The runner futures.
+   */
+  virtual Array<RunnerFuture> Run(Array<RunnerInput> runner_inputs) = 0;
+
+  static constexpr const char* _type_key = "meta_schedule.Runner";
+  TVM_DECLARE_BASE_OBJECT_INFO(RunnerNode, runtime::Object);
+};
+
+/*!
+ * \brief Managed reference to RunnerNode
+ * \sa RunnerNode
+ */
+class Runner : public runtime::ObjectRef {
+ public:
+  using FRun = RunnerNode::FRun;
+
+  /*!
+   * \brief Create a runner with customized build method on the python-side.
+   * \param f_run The packed function to run the built artifacts and get runner futures.
+   * \return The runner created.
+   */
+  TVM_DLL static Runner PyRunner(FRun f_run);
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(Runner, runtime::ObjectRef, RunnerNode);
+};
+
+/*! \brief An abstract runner with customized build method on the python-side. */
+class PyRunnerNode : public RunnerNode {
+ public:
+  /*! \brief The packed function to run the built artifacts and get runner futures. */
+  FRun f_run;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    // `f_run` is not visited
+  }
+
+  Array<RunnerFuture> Run(Array<RunnerInput> runner_inputs) final {
+    ICHECK(f_run != nullptr) << "PyRunner's Run method not implemented!";
+    return f_run(runner_inputs);
+  }
+
+  static constexpr const char* _type_key = "meta_schedule.PyRunner";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PyRunnerNode, RunnerNode);
+};
+
+}  // namespace meta_schedule
+}  // namespace tvm
+
+#endif  // TVM_META_SCHEDULE_RUNNER_H_
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/schedule/cpu/.gitignore b/darknet_drp_ros/include/tvm/meta_schedule/schedule/cpu/.gitignore
new file mode 100644
index 0000000..e69de29
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/schedule/cuda/thread_bind.h b/darknet_drp_ros/include/tvm/meta_schedule/schedule/cuda/thread_bind.h
new file mode 100644
index 0000000..125d6dc
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/meta_schedule/schedule/cuda/thread_bind.h
@@ -0,0 +1,69 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_META_SCHEDULE_SCHEDULE_CUDA_THREAD_BIND_H_
+#define TVM_META_SCHEDULE_SCHEDULE_CUDA_THREAD_BIND_H_
+
+#include <tvm/tir/schedule/schedule.h>
+
+#include <algorithm>
+#include <limits>
+#include <utility>
+
+namespace tvm {
+namespace meta_schedule {
+
+/*!
+ * \brief Given candidates of thread_extents, make a sampler that use `sch->SampleCategorical`
+ * to return a random thread extent.
+ * \param sch The schedule
+ * \param thread_extents The candidate thread extents.
+ * \return A sampler that returns a random thread extent.
+ */
+std::function<tir::ExprRV(int64_t)> MakeFactorSampler(tir::Schedule sch,
+                                                      Array<Integer> thread_extents);
+
+/*!
+ * \brief Bind blockIdx.x and threadIdx.x to the given loop
+ * \param sch The schedule.
+ * \param loop The loop to be bound.
+ * \param max_threadblocks The maximum number of threadblocks allowed.
+ * \param max_threads_per_block The maximum number of threads allowed.
+ * \param get_factor A function that returns the tiling factor.
+ * \return The binded loops in the order of blockIdx.x, threadIdx.x, and the rest.
+ */
+Array<tir::LoopRV> BindSpatialLoop(tir::Schedule sch, tir::LoopRV loop,  //
+                                   int64_t max_threadblocks, int64_t max_threads_per_block,
+                                   std::function<tir::ExprRV(int64_t)> get_factor = nullptr);
+
+/*!
+ * \brief Bind the given block if it is not bound to blockIdx or threadIdx.
+ * \param sch The schedule.
+ * \param block The block to be bound.
+ * \param max_threadblocks The maximum number of threadblocks allowed.
+ * \param max_threads_per_block The maximum number of threads allowed.
+ * \param get_factor A function that returns the tiling factor.
+ */
+void BindBlockThreadIdx(tir::Schedule sch, tir::BlockRV block,  //
+                        int64_t max_threadblocks, int64_t max_threads_per_block,
+                        std::function<tir::ExprRV(int64_t max_extent)> get_factor = nullptr);
+
+}  // namespace meta_schedule
+}  // namespace tvm
+
+#endif  // TVM_META_SCHEDULE_SCHEDULE_CUDA_THREAD_BIND_H_
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/schedule/generic/winograd.h b/darknet_drp_ros/include/tvm/meta_schedule/schedule/generic/winograd.h
new file mode 100644
index 0000000..dc9b32f
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/meta_schedule/schedule/generic/winograd.h
@@ -0,0 +1,37 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_META_SCHEDULE_SCHEDULE_GENERIC_WINOGRAD_H_
+#define TVM_META_SCHEDULE_SCHEDULE_GENERIC_WINOGRAD_H_
+
+#include <tvm/tir/schedule/schedule.h>
+
+namespace tvm {
+namespace meta_schedule {
+
+/*!
+ * \brief Get the producer block of a given block.
+ * If there is a constant winograd transform matrix, inline it.
+ * \return The only producer block.
+ */
+tir::BlockRV GetWinogradProducerAndInlineConst(tir::Schedule sch, tir::BlockRV block);
+
+}  // namespace meta_schedule
+}  // namespace tvm
+
+#endif  // TVM_META_SCHEDULE_SCHEDULE_GENERIC_WINOGRAD_H_
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/schedule/x86/.gitignore b/darknet_drp_ros/include/tvm/meta_schedule/schedule/x86/.gitignore
new file mode 100644
index 0000000..e69de29
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/schedule_rule.h b/darknet_drp_ros/include/tvm/meta_schedule/schedule_rule.h
new file mode 100644
index 0000000..879dd07
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/meta_schedule/schedule_rule.h
@@ -0,0 +1,340 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+#ifndef TVM_META_SCHEDULE_SCHEDULE_RULE_H_
+#define TVM_META_SCHEDULE_SCHEDULE_RULE_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/node/reflection.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/map.h>
+#include <tvm/runtime/container/optional.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/runtime/object.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/tir/schedule/schedule.h>
+
+namespace tvm {
+namespace meta_schedule {
+
+class TuneContext;
+class ScheduleRule;
+
+/*! \brief Rules to modify a block in a schedule. */
+class ScheduleRuleNode : public runtime::Object {
+ public:
+  /*! \brief Virtual destructor. */
+  virtual ~ScheduleRuleNode() = default;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {}
+
+  /*!
+   * \brief Initialize the design space generator with tuning context.
+   * \param context The tuning context for initialization.
+   * \note This method is supposed to be called only once before every other method.
+   */
+  virtual void InitializeWithTuneContext(const TuneContext& context) = 0;
+
+  /*!
+   * \brief Apply a schedule rule to the specific block in the given schedule.
+   * \param sch The schedule to be modified.
+   * \param block The specific block to apply the schedule rule.
+   * \return The list of schedules generated by applying the schedule rule.
+   */
+  virtual runtime::Array<tir::Schedule> Apply(const tir::Schedule& sch,
+                                              const tir::BlockRV& block) = 0;
+
+  /*!
+   * \brief Deep clone the schedule rule.
+   * \return The cloned schedule rule.
+   */
+  virtual ScheduleRule Clone() const = 0;
+
+  static constexpr const char* _type_key = "meta_schedule.ScheduleRule";
+  TVM_DECLARE_BASE_OBJECT_INFO(ScheduleRuleNode, Object);
+};
+
+/*!
+ * \brief Managed reference to ScheduleRuleNode
+ * \sa ScheduleRuleNode
+ */
+class ScheduleRule : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief The function type of `InitializeWithTuneContext` method.
+   * \param context The tuning context for initialization.
+   */
+  using FInitializeWithTuneContext = runtime::TypedPackedFunc<void(const TuneContext&)>;
+  /*!
+   * \brief The function type of `Apply` method.
+   * \param sch The schedule to be modified.
+   * \param block The specific block to apply the schedule rule.
+   * \return The list of schedules generated by applying the schedule rule.
+   */
+  using FApply =
+      runtime::TypedPackedFunc<Array<tir::Schedule>(const tir::Schedule&, const tir::BlockRV&)>;
+  /*!
+   * \brief Get the schedule rule as string with name.
+   * \return The string of the schedule rule.
+   */
+  using FAsString = runtime::TypedPackedFunc<String()>;
+  /*!
+   * \brief The function type of `Clone` method.
+   * \return The cloned schedule rule.
+   */
+  using FClone = runtime::TypedPackedFunc<ScheduleRule()>;
+  /*!
+   * \brief Create a rule that applies customized rules registered using block attribute
+   * `schedule_rule`. The rule will be dispatched according to target keys.
+   * \return The created schedule rule.
+   */
+  TVM_DLL static ScheduleRule ApplyCustomRule();
+  /*! \brief Check if the rule is `ApplyCustomRule` */
+  TVM_DLL static bool IsApplyCustomRule(const ScheduleRule& rule);
+  /*!
+   * \brief Create an auto-inline rule that inlines spatial blocks if it satisfies some conditions
+   * \param into_producer If allows to inline a block into its producer
+   * \param into_consumer If allows to inline a block into its consumer
+   * \param inline_const_tensor Always inline constant tensors
+   * \param disallow_if_then_else Always disallow if-then-else-like constructs
+   * \param require_ordered Always require the read-to-write mapping to be ordered
+   * \param require_injective Always require the read-to-write mapping to be injective
+   * \param disallow_op The operators that are disallowed in auto inline
+   * \return The schedule rule created
+   */
+  TVM_DLL static ScheduleRule AutoInline(bool into_producer,          //
+                                         bool into_consumer,          //
+                                         bool inline_const_tensor,    //
+                                         bool disallow_if_then_else,  //
+                                         bool require_injective,      //
+                                         bool require_ordered,        //
+                                         Optional<Array<String>> disallow_op);
+
+  /*!
+   * \brief Inline blocks that produce a constant scalar. Such blocks get in the way of
+   * ReverseComputeInline during AutoInline, since they are also counted as a producer block
+   * unless they are inlined first. So it is recommended to run InlineConstantScalars before
+   * AutoInline.
+   * \return The schedule rule created
+   */
+  TVM_DLL static ScheduleRule InlineConstantScalars();
+
+  /*!
+   * \brief Create a mega rule: multi-level tiling with data reuse
+   * \param structure The tiling structure. Recommended:
+   * - 'SSRSRS' on CPU
+   * - 'SSSRRSRS' on GPU
+   * \param tile_binds For each level of tiles, which thread axis it is bound to. Recommended:
+   * - NullOpt on CPU
+   * - [blockIdx.x, vthread.x, threadIdx.x] on GPU
+   * \param max_innermost_factor The maximum size of the innermost factor. NullOpt means no limit
+   * \param vector_load_lens The length of vector lane in vectorized cooperative fetching.
+   * NullOpt means disable vectorization
+   * \param reuse_read Data reuse configuration for reading. NullOpt means no reuse.
+   * \param reuse_write Data reuse configuration for writing. NullOpt means no reuse.
+   * \param filter_fn A function that can be passed to overwrite the default condition for applying
+   * MultiLevelTiling to a block. Its signature must be (Schedule, BlockRV) -> bool.
+   * This is useful if there is a need to apply MultiLevelTiling to an operation / block which is
+   * ignored  by default. This function should return True for a block that should be tiled.
+   * \return The schedule rule created
+   */
+  TVM_DLL static ScheduleRule MultiLevelTiling(String structure,                             //
+                                               Optional<Array<String>> tile_binds,           //
+                                               Optional<Integer> max_innermost_factor,       //
+                                               Optional<Array<Integer>> vector_load_lens,    //
+                                               Optional<Map<String, ObjectRef>> reuse_read,  //
+                                               Optional<Map<String, ObjectRef>> reuse_write,
+                                               Optional<runtime::PackedFunc> filter_fn = NullOpt);
+
+  /*!
+   * \brief Extension of MultiLevelTiling for auto-tensorization with a single intrinsic.
+   * \param intrin_name The name of a tensor intrinsic, must be registered via
+   * TensorIntrin.register(...) beforehand
+   * \param structure The tiling structure. Recommended:
+   * - 'SSRSRS' on CPU
+   * - 'SSSRRSRS' on GPU
+   * \param tile_binds For each level of tiles, which thread axis it is bound to. Recommended:
+   * - NullOpt on CPU
+   * - [blockIdx.x, vthread.x, threadIdx.x] on GPU
+   * \param max_innermost_factor The maximum size of the innermost factor. NullOpt means no limit
+   * \param vector_load_lens The length of vector lane in vectorized cooperative fetching.
+   * NullOpt means disable vectorization
+   * \param reuse_read Data reuse configuration for reading. NullOpt means no reuse.
+   * \param reuse_write Data reuse configuration for writing. NullOpt means no reuse.
+   * \return The schedule rule created
+   */
+  TVM_DLL static ScheduleRule MultiLevelTilingWithIntrin(
+      String intrin_name, String structure, Optional<Array<String>> tile_binds,
+      Optional<Integer> max_innermost_factor, Optional<Array<Integer>> vector_load_lens,
+      Optional<Map<String, ObjectRef>> reuse_read, Optional<Map<String, ObjectRef>> reuse_write);
+
+  /*!
+   * \brief Extension of MultiLevelTiling for auto-tensorization with multiple groups of candidate
+   * tensor core intrinsics
+   * \param intrin_groups A list of groups of tensor core intrinsics. The map should contains key
+   * "init", "load_a", "load_b", "compute", "store", which represent the tensor intrin for
+   * initialization, loading operand A, loading operand B, tensor core computation, storing the
+   * result. The value of the map should be names of tensor intrinsics, must be registered via
+   * TensorIntrin.register(...) beforehand
+   * \param structure The tiling structure. Recommended:
+   * - 'SSSRRSRS' on GPU
+   * \param tile_binds For each level of tiles, which thread axis it is bound to. Recommended:
+   * - [blockIdx.y, blockIdx.x, threadIdx.y] on GPU
+   * \param max_innermost_factor The maximum size of the innermost factor. NullOpt means no limit
+   * \param vector_load_lens The length of vector lane in vectorized cooperative fetching.
+   * NullOpt means disable vectorization
+   * \param reuse_read Data reuse configuration for reading. NullOpt means no reuse.
+   * \param reuse_write Data reuse configuration for writing. NullOpt means no reuse.
+   * \param use_software_pipeline Whether use the software pipeline.
+   * \return The schedule rule created
+   */
+  TVM_DLL static ScheduleRule MultiLevelTilingTensorCore(
+      Array<Map<String, String>> intrin_groups, String structure,
+      Optional<Array<String>> tile_binds, Optional<Integer> max_innermost_factor,
+      Optional<Array<Integer>> vector_load_lens, Optional<Map<String, ObjectRef>> reuse_read,
+      Optional<Map<String, ObjectRef>> reuse_write, bool use_software_pipeline);
+
+  /*!
+   * \brief Extension of MultiLevelTiling for backends with wide vectors.
+   * The loop over the innermost spatial axis of the output buffer is always vectorized with the
+   * maximum vector length.
+   * \param structure The tiling structure. 'SSRSRS' is recommended.
+   * \param vector_length_in_bits The length of a vector register in bits.
+   * \param max_innermost_factor The maximum size of the innermost factor. NullOpt means no limit
+   * \param reuse_read Data reuse configuration for reading. NullOpt means no reuse.
+   * \param reuse_write Data reuse configuration for writing. NullOpt means no reuse.
+   * \return The schedule rule created
+   */
+  TVM_DLL static ScheduleRule MultiLevelTilingWideVector(
+      String structure, Integer vector_length_in_bits, Optional<Integer> max_innermost_factor,
+      Optional<Map<String, ObjectRef>> reuse_read, Optional<Map<String, ObjectRef>> reuse_write);
+
+  /*!
+   * \brief Create a rule: add-rfactor to some blocks if needed
+   * \param max_jobs_per_core The maximum number of jobs to be launched per CPU core. It sets the
+   * uplimit of CPU parallelism, i.e. `num_cores * max_jobs_per_core`. Use -1 to disable
+   * parallelism.
+   * \param max_innermost_factor The maximum size of the innermost factor. NullOpt means no limit
+   * \return The schedule rule created
+   */
+  TVM_DLL static ScheduleRule AddRFactor(int max_jobs_per_core,  //
+                                         Optional<Integer> max_innermost_factor);
+  /*!
+   * \brief Create a schedule rule which applies cross-thread reduction to some reduction blocks
+   * correspondingly when needed
+   * \param thread_extents Candidates of thread axis extent (values are required to be positive).
+   * \return The schedule rule created
+   */
+  TVM_DLL static ScheduleRule CrossThreadReduction(Array<Integer> thread_extents);
+  /*!
+   * \brief A rule that randomly select a compute-at location for a free block
+   * \return The schedule rule created
+   */
+  TVM_DLL static ScheduleRule RandomComputeLocation();
+  /*!
+   * \brief Mark parallelize, vectorize and unroll to the root block. The mark will be applied to
+   * each block in a follow-up post processor
+   * \param max_jobs_per_core The maximum number of jobs to be launched per CPU core. It sets the
+   * upper limit of CPU parallelism, i.e. `num_cores * max_jobs_per_core`. Use -1 to disable
+   * parallelism.
+   * \param max_vectorize_extent The maximum extent to be vectorized.
+   * It sets the upper limit of the hardware target vectorization. Use -1 to disable vectorization.
+   * \param unroll_max_steps The options of the maximum number of unroll steps to be done.
+   * Use an empty array to disable unroll.
+   * \param unroll_explicit Whether to explicitly unroll the loop, or just add an "unroll" pragma.
+   * \return The schedule rule created
+   */
+  TVM_DLL static ScheduleRule ParallelizeVectorizeUnroll(int max_jobs_per_core,            //
+                                                         int max_vectorize_extent,         //
+                                                         Array<Integer> unroll_max_steps,  //
+                                                         bool unroll_explicit);
+  /*!
+   * \brief Auto bind loops around the block to BlockIdx and ThreadIdx
+   * \param max_threadblocks The maximum number of threadblock on GPU
+   * \param thread_extents Candidates of thread axis extent.
+   * \param max_threads_per_block The maximum number of threads per block, if it is known
+   * when this schedule rule is created.
+   * \return The schedule rule created
+   */
+  TVM_DLL static ScheduleRule AutoBind(int max_threadblocks, Array<Integer> thread_extents,
+                                       int max_threads_per_block = -1);
+  /*!
+   * \brief Create a schedule rule with customized methods on the python-side.
+   * \param f_initialize_with_tune_context The packed function of `InitializeWithTuneContext`.
+   * \param f_apply The packed function of `Apply`.
+   * \param f_clone The packed function of `Clone`.
+   * \param f_as_string The packed function of `AsString`.
+   * \return The schedule rule created.
+   */
+  TVM_DLL static ScheduleRule PyScheduleRule(
+      FInitializeWithTuneContext f_initialize_with_tune_context,  //
+      FApply f_apply,                                             //
+      FClone f_clone,                                             //
+      FAsString f_as_string);
+
+  /*! \brief Create default schedule rules for LLVM */
+  TVM_DLL static Array<ScheduleRule, void> DefaultLLVM();
+  /*! \brief Create default schedule rules for x86 VNNI */
+  TVM_DLL static Array<ScheduleRule, void> DefaultVNNI();
+  /*! \brief Create default schedule rules for CUDA */
+  TVM_DLL static Array<ScheduleRule, void> DefaultCUDA();
+  /*! \brief Create default postprocessors for CUDA with TensorCore */
+  TVM_DLL static Array<ScheduleRule, void> DefaultCUDATensorCore();
+  /*! \brief Create default schedule rules for Hexagon */
+  TVM_DLL static Array<ScheduleRule, void> DefaultHexagon();
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(ScheduleRule, ObjectRef, ScheduleRuleNode);
+};
+
+/*! \brief The schedule rule with customized methods on the python-side. */
+class PyScheduleRuleNode : public ScheduleRuleNode {
+ public:
+  using FInitializeWithTuneContext = ScheduleRule::FInitializeWithTuneContext;
+  using FApply = ScheduleRule::FApply;
+  using FClone = ScheduleRule::FClone;
+  using FAsString = ScheduleRule::FAsString;
+
+  /*! \brief The packed function to the `InitializeWithTuneContext` function. */
+  FInitializeWithTuneContext f_initialize_with_tune_context;
+  /*! \brief The packed function to the `Apply` function. */
+  FApply f_apply;
+  /*! \brief The packed function to the `AsString` function. */
+  FAsString f_as_string;
+  /*! \brief The packed function to the `Clone` function. */
+  FClone f_clone;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    // `f_initialize_with_tune_context` is not visited
+    // `f_apply` is not visited
+    // `f_as_string` is not visited
+    // `f_clone` is not visited
+  }
+
+  void InitializeWithTuneContext(const TuneContext& context) final;
+  Array<tir::Schedule> Apply(const tir::Schedule& sch, const tir::BlockRV& block) final;
+  ScheduleRule Clone() const final;
+
+  static constexpr const char* _type_key = "meta_schedule.PyScheduleRule";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PyScheduleRuleNode, ScheduleRuleNode);
+};
+
+}  // namespace meta_schedule
+}  // namespace tvm
+
+#endif  // TVM_META_SCHEDULE_SCHEDULE_RULE_H_
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/search_strategy.h b/darknet_drp_ros/include/tvm/meta_schedule/search_strategy.h
new file mode 100644
index 0000000..3f44a24
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/meta_schedule/search_strategy.h
@@ -0,0 +1,269 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_META_SCHEDULE_SEARCH_STRATEGY_H_
+#define TVM_META_SCHEDULE_SEARCH_STRATEGY_H_
+
+#include <tvm/meta_schedule/arg_info.h>
+#include <tvm/meta_schedule/cost_model.h>
+#include <tvm/meta_schedule/database.h>
+#include <tvm/meta_schedule/measure_candidate.h>
+#include <tvm/meta_schedule/runner.h>
+#include <tvm/node/reflection.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/optional.h>
+#include <tvm/runtime/object.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/tir/schedule/schedule.h>
+
+namespace tvm {
+namespace meta_schedule {
+
+// Forward declaration
+class TuneContext;
+class SearchStrategy;
+
+/*!
+ * \brief The search strategy for measure candidates generation.
+ * \note The relationship between SearchStrategy and other classes are as follows:
+      ┌──────────────────────────────────────────────────────────────┐
+   ┌──┴───────────────────────────────────────────────────────────┐  │
+┌──┴────────────────── Tune Context ───────────────────────────┐  │  │
+│                ┌─────────────────────┐                       │  │  │
+│                │                     │   Generate            │  │  │
+│                │   Space Generator   ├──────────────┐        │  │  │
+│                │                     │              │        │  │  │
+│                └─────────────────────┘              ▼        │  │  │
+│                                                Design Space  │  │  │
+│                ┌─────────────────────┐              │        │  │  │
+│      Generate  │                     │   Pretuning  │        │  │  │
+│    ┌───────────┤   Search Strategy   │◄─────────────┘        │  │  │
+│    │           │                     │                       │  ├──┘
+│    │           └─────────────────────┘                       ├──┘
+└────┼─────────────────────────────────────────────────────────┘
+     │
+     │
+┌────┼──────────────── Managed By Task Scheduler ─────────────────────┐
+│    │                                 ┌───────────┐                  │
+│    │                      Send to    │           │  Send to         │
+│    ▼                  ┌─────────────►│  Builder  ├──────────┐       │
+│ Measure Candidate     │   Builder    │           │  Runner  │       │
+│    │                  │              └───────────┘          │       │
+│    │     ┌────────────┴────────┐                            │       │
+│    │     │                     │     ┌───────────┐          │       │
+│    └────►│   Task Scheduler    │     │           │          │       │
+│          │                     │     │  Runner   │◄─────────┘       │
+│          └─────────────────────┘     │           │                  │
+│                   ▲                  └─────┬─────┘                  │
+│                   │                        │                        │
+│                   └───  Runner Future ◄────┘                        │
+└─────────────────────────────────────────────────────────────────────┘
+*/
+class SearchStrategyNode : public runtime::Object {
+ public:
+  /*! \brief Virtual destructor */
+  virtual ~SearchStrategyNode() = default;
+
+  /*!
+   * \brief Initialize the search strategy with tuning context.
+   * \param context The tuning context for initialization.
+   * \note This method is supposed to be called only once before every other method.
+   */
+  virtual void InitializeWithTuneContext(const TuneContext& context) = 0;
+
+  /*!
+   * \brief Pre-tuning for the search strategy.
+   * \param max_trials The maximum number of trials.
+   * \param num_trials_per_iter The number of trials per iteration.
+   * \param design_spaces The design spaces used during tuning process.
+   * \param database The database used during tuning process.
+   * \param cost_model The cost model used during tuning process.
+   * \note Pre-tuning is supposed to be called before the tuning process and after the
+   *  initialization. Because the search strategy is stateful, we can always call pretuning
+   *  and reset the search strategy.
+   */
+  virtual void PreTuning(int max_trials, int num_trials_per_iter,
+                         const Array<tir::Schedule>& design_spaces,
+                         const Optional<Database>& database,
+                         const Optional<CostModel>& cost_model) = 0;
+
+  /*!
+   * \brief Post-tuning for the search strategy.
+   * \note Post-tuning is supposed to be called after the tuning process and before we reset the
+   *  search strategy with another pre-tuning. Post-tuning can be empty.
+   */
+  virtual void PostTuning() = 0;
+
+  /*!
+   * \brief Generate measure candidates from design spaces for measurement.
+   * \return The measure candidates generated, nullptr if finished.
+   */
+  virtual Optional<Array<MeasureCandidate>> GenerateMeasureCandidates() = 0;
+
+  /*!
+   * \brief Update the search strategy with measurement results.
+   * \param measure_candidates The candidates to be measured.
+   * \param results The measurement results from the runner.
+   */
+  virtual void NotifyRunnerResults(const Array<MeasureCandidate>& measure_candidates,
+                                   const Array<RunnerResult>& results) = 0;
+
+  /*!
+   * \brief Clone the search strategy.
+   * \return The cloned search strategy.
+   */
+  virtual SearchStrategy Clone() const = 0;
+
+  static constexpr const char* _type_key = "meta_schedule.SearchStrategy";
+  TVM_DECLARE_BASE_OBJECT_INFO(SearchStrategyNode, Object);
+};
+
+/*!
+ * \brief Managed reference to SearchStrategyNode.
+ * \sa SearchStrategyNode
+ */
+class SearchStrategy : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief The function type of `InitializeWithTuneContext` method.
+   * \param context The tuning context for initialization.
+   */
+  using FInitializeWithTuneContext = runtime::TypedPackedFunc<void(const TuneContext&)>;
+  /*!
+   * \brief The function type of `PreTuning` method.
+   */
+  using FPreTuning = runtime::TypedPackedFunc<void(
+      int max_trials, int num_trials_per_iter, const Array<tir::Schedule>&,
+      const Optional<Database>&, const Optional<CostModel>&)>;
+  /*! \brief The function type of `PostTuning` method. */
+  using FPostTuning = runtime::TypedPackedFunc<void()>;
+  /*!
+   * \brief The function type of `GenerateMeasureCandidates` method.
+   * \return The measure candidates generated, nullptr if finished.
+   */
+  using FGenerateMeasureCandidates = runtime::TypedPackedFunc<Optional<Array<MeasureCandidate>>()>;
+  /*!
+   * \brief The function type of `NotifyRunnerResults` method.
+   * \param results The measurement results from the runner.
+   */
+  using FNotifyRunnerResults =
+      runtime::TypedPackedFunc<void(const Array<MeasureCandidate>&, const Array<RunnerResult>&)>;
+  /*!
+   * \brief The function type of `Clone` method.
+   * \return The cloned search strategy.
+   */
+  using FClone = runtime::TypedPackedFunc<SearchStrategy()>;
+  /*!
+   * \brief Create a search strategy with customized methods on the python-side.
+   * \param f_initialize_with_tune_context The packed function of `InitializeWithTuneContext`.
+   * \param f_pre_tuning The packed function of `PreTuning`.
+   * \param f_post_tuning The packed function of `PostTuning`.
+   * \param f_generate_measure_candidates The packed function of `GenerateMeasureCandidates`.
+   * \param f_notify_runner_results The packed function of `NotifyRunnerResults`.
+   * \param f_clone The packed function of `Clone`.
+   * \return The search strategy created.
+   */
+  TVM_DLL static SearchStrategy PySearchStrategy(
+      FInitializeWithTuneContext f_initialize_with_tune_context,  //
+      FPreTuning f_pre_tuning,                                    //
+      FPostTuning f_post_tuning,                                  //
+      FGenerateMeasureCandidates f_generate_measure_candidates,   //
+      FNotifyRunnerResults f_notify_runner_results,               //
+      FClone f_clone);
+
+  /*!
+   * \brief Constructor of replay trace search strategy.
+   * \param max_fail_count The max number of failures during trace replaying.
+   */
+  TVM_DLL static SearchStrategy ReplayTrace(int max_fail_count);
+
+  /*! \brief Constructor of replay func search strategy. */
+  TVM_DLL static SearchStrategy ReplayFunc();
+
+  /*!
+   * \brief Constructor of evolutionary search strategy.
+   * \param population_size The initial sample population.
+   * \param init_measured_ratio The ratio of measures samples in initial population.
+   * \param init_min_unmeasured The minimal size of unmeasured population in the initial sampling.
+   * \param max_fail_count The max number of failure during initial sampling.
+   * \param genetic_num_iters The iterations to run the genetic algorithm.
+   * \param genetic_mutate_prob The probability of mutation.
+   * \param genetic_max_fail_count The maximum number to try evolving the given trace.
+   * \param eps_greedy The ratio to select samples in a greedy fashion via their predicted score.
+   */
+  TVM_DLL static SearchStrategy EvolutionarySearch(int population_size,         //
+                                                   double init_measured_ratio,  //
+                                                   int init_min_unmeasured,     //
+                                                   int max_fail_count,          //
+                                                   int genetic_num_iters,       //
+                                                   double genetic_mutate_prob,  //
+                                                   int genetic_max_fail_count,  //
+                                                   double eps_greedy);
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(SearchStrategy, ObjectRef, SearchStrategyNode);
+};
+
+/*! \brief The python side customizable class for measure candidate generation */
+class PySearchStrategyNode : public SearchStrategyNode {
+ public:
+  using FInitializeWithTuneContext = SearchStrategy::FInitializeWithTuneContext;
+  using FPreTuning = SearchStrategy::FPreTuning;
+  using FPostTuning = SearchStrategy::FPostTuning;
+  using FGenerateMeasureCandidates = SearchStrategy::FGenerateMeasureCandidates;
+  using FNotifyRunnerResults = SearchStrategy::FNotifyRunnerResults;
+  using FClone = SearchStrategy::FClone;
+
+  /*! \brief The packed function to the `InitializeWithTuneContext` method. */
+  FInitializeWithTuneContext f_initialize_with_tune_context;
+  /*! \brief The packed function to the `PreTuning` method. */
+  FPreTuning f_pre_tuning;
+  /*! \brief The packed function to the `PostTuning` method. */
+  FPostTuning f_post_tuning;
+  /*! \brief The packed function to the `GenerateMeasureCandidates` method. */
+  FGenerateMeasureCandidates f_generate_measure_candidates;
+  /*! \brief The packed function to the `NotifyRunnerResults` method. */
+  FNotifyRunnerResults f_notify_runner_results;
+  /*! \brief The packed function to the `Clone` method. */
+  FClone f_clone;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    // `f_initialize_with_tune_context` is not visited
+    // `f_pre_tuning` is not visited
+    // `f_post_tuning` is not visited
+    // `f_generate_measure_candidates` is not visited
+    // `f_notify_runner_results` is not visited
+    // `f_clone` is not visited
+  }
+
+  void InitializeWithTuneContext(const TuneContext& context) final;
+  void PreTuning(int max_trials, int num_trials_per_iter, const Array<tir::Schedule>& design_spaces,
+                 const Optional<Database>& database, const Optional<CostModel>& cost_model) final;
+  void PostTuning() final;
+  Optional<Array<MeasureCandidate>> GenerateMeasureCandidates() final;
+  void NotifyRunnerResults(const Array<MeasureCandidate>& measure_candidates,
+                           const Array<RunnerResult>& results);
+  SearchStrategy Clone() const final;
+
+  static constexpr const char* _type_key = "meta_schedule.PySearchStrategy";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PySearchStrategyNode, SearchStrategyNode);
+};
+
+}  // namespace meta_schedule
+}  // namespace tvm
+
+#endif  // TVM_META_SCHEDULE_SEARCH_STRATEGY_H_
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/space_generator.h b/darknet_drp_ros/include/tvm/meta_schedule/space_generator.h
new file mode 100644
index 0000000..f746eb8
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/meta_schedule/space_generator.h
@@ -0,0 +1,233 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_META_SCHEDULE_SPACE_GENERATOR_H_
+#define TVM_META_SCHEDULE_SPACE_GENERATOR_H_
+
+#include <tvm/ir/module.h>
+#include <tvm/meta_schedule/mutator.h>
+#include <tvm/meta_schedule/postproc.h>
+#include <tvm/meta_schedule/schedule_rule.h>
+#include <tvm/node/reflection.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/object.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/target/target.h>
+#include <tvm/tir/schedule/schedule.h>
+
+namespace tvm {
+namespace meta_schedule {
+
+// Forward declaration
+class TuneContext;
+class SpaceGenerator;
+
+/*!
+ * \brief The abstract class for design space generation.
+ * \note The relationship between SpaceGenerator and other classes are as follows:
+      ┌──────────────────────────────────────────────────────────────┐
+   ┌──┴───────────────────────────────────────────────────────────┐  │
+┌──┴────────────────── Tune Context ───────────────────────────┐  │  │
+│                ┌─────────────────────┐                       │  │  │
+│                │                     │   Generate            │  │  │
+│                │   Space Generator   ├──────────────┐        │  │  │
+│                │                     │              │        │  │  │
+│                └─────────────────────┘              ▼        │  │  │
+│                                                Design Space  │  │  │
+│                ┌─────────────────────┐              │        │  │  │
+│      Generate  │                     │   Pretuning  │        │  │  │
+│    ┌───────────┤   Search Strategy   │◄─────────────┘        │  │  │
+│    │           │                     │                       │  ├──┘
+│    │           └─────────────────────┘                       ├──┘
+└────┼─────────────────────────────────────────────────────────┘
+     │
+     │
+┌────┼──────────────── Managed By Task Scheduler ─────────────────────┐
+│    │                                 ┌───────────┐                  │
+│    │                      Send to    │           │  Send to         │
+│    ▼                  ┌─────────────►│  Builder  ├──────────┐       │
+│ Measure Candidate     │   Builder    │           │  Runner  │       │
+│    │                  │              └───────────┘          │       │
+│    │     ┌────────────┴────────┐                            │       │
+│    │     │                     │     ┌───────────┐          │       │
+│    └────►│   Task Scheduler    │     │           │          │       │
+│          │                     │     │  Runner   │◄─────────┘       │
+│          └─────────────────────┘     │           │                  │
+│                   ▲                  └─────┬─────┘                  │
+│                   │                        │                        │
+│                   └───  Runner Future ◄────┘                        │
+└─────────────────────────────────────────────────────────────────────┘
+*/
+class SpaceGeneratorNode : public runtime::Object {
+ public:
+  /*! \brief The schedule rules. */
+  Optional<Array<ScheduleRule>> sch_rules;
+  /*! \brief The postprocessors. */
+  Optional<Array<Postproc>> postprocs;
+  /*! \brief The probability of using certain mutator. */
+  Optional<Map<Mutator, FloatImm>> mutator_probs;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("sch_rules", &sch_rules);
+    v->Visit("postprocs", &postprocs);
+    v->Visit("mutator_probs", &mutator_probs);
+  }
+
+  /*! \brief Default destructor */
+  virtual ~SpaceGeneratorNode() = default;
+
+  /*!
+   * \brief Initialize the design space generator with tuning context.
+   * \param context The tuning context for initialization.
+   * \note This method is supposed to be called only once before every other method.
+   */
+  virtual void InitializeWithTuneContext(const TuneContext& context);
+
+  /*!
+   * \brief Generate design spaces given a module.
+   * \param mod The module used for design space generation.
+   * \return The generated design spaces, i.e., schedules.
+   */
+  virtual Array<tir::Schedule> GenerateDesignSpace(const IRModule& mod) = 0;
+
+  /*!
+   * \brief Clone the space generator.
+   * \return The cloned space generator.
+   */
+  virtual SpaceGenerator Clone() const = 0;
+
+  static constexpr const char* _type_key = "meta_schedule.SpaceGenerator";
+  TVM_DECLARE_BASE_OBJECT_INFO(SpaceGeneratorNode, Object);
+};
+
+/*!
+ * \brief Managed reference to SpaceGeneratorNode.
+ * \sa SpaceGeneratorNode
+ */
+class SpaceGenerator : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief The function type of `InitializeWithTuneContext` method.
+   * \param context The tuning context for initialization.
+   */
+  using FInitializeWithTuneContext = runtime::TypedPackedFunc<void(const TuneContext&)>;
+  /*!
+   * \brief The function type of `GenerateDesignSpace` method.
+   * \param mod The module used for design space generation.
+   * \return The generated design spaces, i.e., schedules.
+   */
+  using FGenerateDesignSpace = runtime::TypedPackedFunc<Array<tir::Schedule>(const IRModule&)>;
+  /*!
+   * \brief The function type of `Clone` method.
+   * \return The cloned space generator.
+   */
+  using FClone = runtime::TypedPackedFunc<SpaceGenerator()>;
+
+ protected:
+  SpaceGenerator() = default;
+
+ public:
+  /*!
+   * \brief Create a design space generator with customized methods on the python-side.
+   * \param sch_rules The schedule rules.
+   * \param postprocs The postprocessors.
+   * \param mutator_probs The probability of using certain mutator.
+   * \param f_initialize_with_tune_context The packed function of `InitializeWithTuneContext`.
+   * \param f_generate_design_space The packed function of `GenerateDesignSpace`.
+   * \param f_clone The packed function of `Clone`.
+   * \return The design space generator created.
+   */
+  TVM_DLL static SpaceGenerator PySpaceGenerator(
+      Optional<Array<ScheduleRule>> sch_rules, Optional<Array<Postproc>> postprocs,
+      Optional<Map<Mutator, FloatImm>> mutator_probs,
+      FInitializeWithTuneContext f_initialize_with_tune_context,
+      FGenerateDesignSpace f_generate_design_space, FClone f_clone);
+  /*!
+   * \brief Create a design space generator with customized schedule function.
+   * \param schedule_fn The schedule function, which can have the following signatures:
+   * 1) void(Schedule)
+   * 2) Schedule(Schedule)
+   * 3) Array<Schedule>(Schedule)
+   * \param sch_rules The schedule rules.
+   * \param postprocs The postprocessors.
+   * \param mutator_probs The probability of using certain mutator.
+   */
+  TVM_DLL static SpaceGenerator ScheduleFn(PackedFunc schedule_fn,
+                                           Optional<Array<ScheduleRule>> sch_rules,
+                                           Optional<Array<Postproc>> postprocs,
+                                           Optional<Map<Mutator, FloatImm>> mutator_probs);
+  /*!
+   * \brief Create a design space generator that is union of multiple design space generators.
+   * \param space_generators An array of design space generators to be unioned.
+   * \param sch_rules The schedule rules.
+   * \param postprocs The postprocessors.
+   * \param mutator_probs The probability of using certain mutator.
+   * \return The design space generator created.
+   */
+  TVM_DLL static SpaceGenerator SpaceGeneratorUnion(Array<SpaceGenerator, void> space_generators,
+                                                    Optional<Array<ScheduleRule>> sch_rules,
+                                                    Optional<Array<Postproc>> postprocs,
+                                                    Optional<Map<Mutator, FloatImm>> mutator_probs);
+  /*!
+   * \brief Create a design space generator that generates design spaces by applying schedule
+   * rules to blocks in post-DFS order.
+   * \param f_block_filter The filter function to filter blocks to be applied with schedule rules.
+   * \param sch_rules The schedule rules.
+   * \param postprocs The postprocessors.
+   * \param mutator_probs The probability of using certain mutator.
+   * \return The design space generator created.
+   */
+  TVM_DLL static SpaceGenerator PostOrderApply(runtime::PackedFunc f_block_filter,
+                                               Optional<Array<ScheduleRule>> sch_rules,
+                                               Optional<Array<Postproc>> postprocs,
+                                               Optional<Map<Mutator, FloatImm>> mutator_probs);
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(SpaceGenerator, ObjectRef, SpaceGeneratorNode);
+};
+
+/*! \brief The design space generator with customized methods on the python-side. */
+class PySpaceGeneratorNode : public SpaceGeneratorNode {
+ public:
+  using FInitializeWithTuneContext = SpaceGenerator::FInitializeWithTuneContext;
+  using FGenerateDesignSpace = SpaceGenerator::FGenerateDesignSpace;
+  using FClone = SpaceGenerator::FClone;
+  /*! \brief The packed function to the `InitializeWithTuneContext` function. */
+  FInitializeWithTuneContext f_initialize_with_tune_context;
+  /*! \brief The packed function to the `GenerateDesignSpace` function. */
+  FGenerateDesignSpace f_generate_design_space;
+  /*! \brief The packed function to the `Clone` function. */
+  FClone f_clone;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    SpaceGeneratorNode::VisitAttrs(v);
+    // `f_initialize_with_tune_context` is not visited
+    // `f_generate_design_space` is not visited
+    // `f_clone` is not visited
+  }
+
+  void InitializeWithTuneContext(const TuneContext& context) final;
+  Array<tir::Schedule> GenerateDesignSpace(const IRModule& mod) final;
+  SpaceGenerator Clone() const final;
+
+  static constexpr const char* _type_key = "meta_schedule.PySpaceGenerator";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PySpaceGeneratorNode, SpaceGeneratorNode);
+};
+
+}  // namespace meta_schedule
+}  // namespace tvm
+
+#endif  // TVM_META_SCHEDULE_SPACE_GENERATOR_H_
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/task_scheduler.h b/darknet_drp_ros/include/tvm/meta_schedule/task_scheduler.h
new file mode 100644
index 0000000..f4fc491
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/meta_schedule/task_scheduler.h
@@ -0,0 +1,297 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_META_SCHEDULE_TASK_SCHEDULER_H_
+#define TVM_META_SCHEDULE_TASK_SCHEDULER_H_
+
+#include <tvm/meta_schedule/builder.h>
+#include <tvm/meta_schedule/cost_model.h>
+#include <tvm/meta_schedule/measure_callback.h>
+#include <tvm/meta_schedule/runner.h>
+#include <tvm/meta_schedule/tune_context.h>
+#include <tvm/node/reflection.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/optional.h>
+#include <tvm/runtime/object.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/support/random_engine.h>
+
+#include <string>
+#include <vector>
+
+namespace tvm {
+namespace meta_schedule {
+
+class TaskRecordNode : public runtime::Object {
+ public:
+  /*! \brief The tune context of the task. */
+  TuneContext ctx{nullptr};
+  /*! \brief The weight of the task */
+  double task_weight{1.0};
+  /*! \brief The FLOP count of the task */
+  double flop{1.0};
+  /*! \brief Whether the tuning task has been stopped or finished. */
+  bool is_terminated = false;
+  /*! \brief Builder errors happens in the task */
+  int build_error_count = 0;
+  /*! \brief Runner errors happens in the task */
+  int run_error_count = 0;
+  /*! \brief The latency of each run, in milliseconds. */
+  std::vector<double> latency_ms = {};
+  /*! \brief The measure candidates. */
+  Optional<Array<MeasureCandidate>> measure_candidates = NullOpt;
+  /*! \brief The building results. */
+  Optional<Array<BuilderResult>> builder_results = NullOpt;
+  /*! \brief Packed functions to fetch the runner results asynchronously. */
+  Optional<Array<RunnerFuture>> runner_futures = NullOpt;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("ctx", &ctx);
+    v->Visit("task_weight", &task_weight);
+    v->Visit("flop", &flop);
+    v->Visit("is_terminated", &is_terminated);
+    v->Visit("build_error_count", &build_error_count);
+    v->Visit("run_error_count", &run_error_count);
+    // `latency_ms` is not visited
+    v->Visit("measure_candidates", &measure_candidates);
+    v->Visit("builder_results", &builder_results);
+    v->Visit("runner_futures", &runner_futures);
+  }
+
+  static constexpr const char* _type_key = "meta_schedule.TaskRecord";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TaskRecordNode, Object);
+};
+
+/*!
+ * \brief Managed reference to TaskRecordNode.
+ * \sa TaskRecordNode
+ */
+class TaskRecord : public runtime::ObjectRef {
+ public:
+  /*! \brief Constructor */
+  explicit TaskRecord(TuneContext task, double task_weight);
+
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(TaskRecord, ObjectRef, TaskRecordNode);
+};
+
+/*!
+ * \brief The abstract interface of task schedulers.
+ * \note The relationship between SpaceGenerator and other classes are as follows:
+      ┌──────────────────────────────────────────────────────────────┐
+   ┌──┴───────────────────────────────────────────────────────────┐  │
+┌──┴────────────────── Tune Context ───────────────────────────┐  │  │
+│                ┌─────────────────────┐                       │  │  │
+│                │                     │   Generate            │  │  │
+│                │   Space Generator   ├──────────────┐        │  │  │
+│                │                     │              │        │  │  │
+│                └─────────────────────┘              ▼        │  │  │
+│                                                Design Space  │  │  │
+│                ┌─────────────────────┐              │        │  │  │
+│      Generate  │                     │   Pretuning  │        │  │  │
+│    ┌───────────┤   Search Strategy   │◄─────────────┘        │  │  │
+│    │           │                     │                       │  ├──┘
+│    │           └─────────────────────┘                       ├──┘
+└────┼─────────────────────────────────────────────────────────┘
+     │
+     │
+┌────┼──────────────── Managed By Task Scheduler ─────────────────────┐
+│    │                                 ┌───────────┐                  │
+│    │                      Send to    │           │  Send to         │
+│    ▼                  ┌─────────────►│  Builder  ├──────────┐       │
+│ Measure Candidate     │   Builder    │           │  Runner  │       │
+│    │                  │              └───────────┘          │       │
+│    │     ┌────────────┴────────┐                            │       │
+│    │     │                     │     ┌───────────┐          │       │
+│    └────►│   Task Scheduler    │     │           │          │       │
+│          │                     │     │  Runner   │◄─────────┘       │
+│          └─────────────────────┘     │           │                  │
+│                   ▲                  └─────┬─────┘                  │
+│                   │                        │                        │
+│                   └───  Runner Future ◄────┘                        │
+└─────────────────────────────────────────────────────────────────────┘
+*/
+class TaskSchedulerNode : public runtime::Object {
+ public:
+  /*! \brief The tuning task's logging function. */
+  PackedFunc logger;
+  /*! \brief Records for each task */
+  Array<TaskRecord> tasks_;
+  /*! \brief The list of measure callbacks of the scheduler. */
+  Array<MeasureCallback> measure_callbacks_;
+  /*! \brief The database used in tuning */
+  Optional<Database> database_;
+  /*! \brief The cost model used in tuning */
+  Optional<CostModel> cost_model_;
+  /*! \brief The number of remaining tasks to be tuned. */
+  int remaining_tasks_;
+
+  /*! \brief The default destructor. */
+  virtual ~TaskSchedulerNode() = default;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    // `logger` is not visited
+    v->Visit("tasks_", &tasks_);
+    v->Visit("measure_callbacks_", &measure_callbacks_);
+    v->Visit("database_", &database_);
+    v->Visit("cost_model_", &cost_model_);
+    v->Visit("remaining_tasks_", &remaining_tasks_);
+  }
+
+  /*!
+   * \brief Fetch the next task id.
+   * \return The next task id.
+   */
+  virtual int NextTaskId() = 0;
+  /*!
+   * \brief Wait until the task is finished.
+   * \param task_id The task id to be joined.
+   * \return The results from the runner.
+   */
+  virtual Array<RunnerResult> JoinRunningTask(int task_id);
+  /*!
+   * \brief Jointly tune a given list of tasks.
+   * \param tasks The tasks to be tuned
+   * \param task_weights The weight of each task
+   * \param max_trials_global The maximum number of trials to be performed globally
+   * \param max_trials_per_task The maximum number of trials to be performed for each task
+   * \param num_trials_per_iter The number of trials to be performed in each iteration
+   * \param builder The MetaSchedule builder
+   * \param runner The MetaSchedule runner
+   * \param measure_callbacks The callbacks to be called after each measurement
+   * \param database The database used in tuning
+   * \param cost_model The cost model used in tuning
+   */
+  virtual void Tune(Array<TuneContext> tasks,                  //
+                    Array<FloatImm> task_weights,              //
+                    int max_trials_global,                     //
+                    int max_trials_per_task,                   //
+                    int num_trials_per_iter,                   //
+                    Builder builder,                           //
+                    Runner runner,                             //
+                    Array<MeasureCallback> measure_callbacks,  //
+                    Optional<Database> database,               //
+                    Optional<CostModel> cost_model);
+  /*!
+   * \brief Terminate a task
+   * \param task_id The id of the task to be terminated
+   */
+  void TerminateTask(int task_id);
+  /*!
+   * \brief Touch the task and update its status
+   * \param task_id The task id to be checked.
+   */
+  void TouchTask(int task_id);
+  /*! \brief Print out a human-readable format of the tuning statistics. */
+  void PrintTuningStatistics();
+
+  static constexpr const char* _type_key = "meta_schedule.TaskScheduler";
+  TVM_DECLARE_BASE_OBJECT_INFO(TaskSchedulerNode, Object);
+};
+
+class TaskScheduler;
+
+/*! \brief The task scheduler with customized methods on the python-side. */
+class PyTaskSchedulerNode : public TaskSchedulerNode {
+ public:
+  /*!
+   * \brief The function type of `NextTaskId` method.
+   * \return The next task id.
+   */
+  using FNextTaskId = runtime::TypedPackedFunc<int()>;
+  /*!
+   * \brief The function type of `JoinRunningTask` method.
+   * \param task_id The task id to be joined.
+   */
+  using FJoinRunningTask = runtime::TypedPackedFunc<Array<RunnerResult>(int)>;
+  /*! \brief The function type of `Tune` method. */
+  using FTune = runtime::TypedPackedFunc<void(Array<TuneContext> tasks,                  //
+                                              Array<FloatImm> task_weights,              //
+                                              int max_trials_global,                     //
+                                              int max_trials_per_task,                   //
+                                              int num_trials_per_iter,                   //
+                                              Builder builder,                           //
+                                              Runner runner,                             //
+                                              Array<MeasureCallback> measure_callbacks,  //
+                                              Optional<Database> database,               //
+                                              Optional<CostModel> cost_model)>;
+
+  /*! \brief The packed function to the `NextTaskId` function. */
+  FNextTaskId f_next_task_id;
+  /*! \brief The packed function to the `JoinRunningTask` function. */
+  FJoinRunningTask f_join_running_task;
+  /*! \brief The packed function to the `Tune` function. */
+  FTune f_tune;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    TaskSchedulerNode::VisitAttrs(v);
+    // `f_next_task_id` is not visited
+    // `f_join_running_task` is not visited
+    // `f_tune` is not visited
+  }
+
+  int NextTaskId() final;
+  Array<RunnerResult> JoinRunningTask(int task_id) final;
+  void Tune(Array<TuneContext> tasks, Array<FloatImm> task_weights, int max_trials_global,
+            int max_trials_per_task, int num_trials_per_iter, Builder builder, Runner runner,
+            Array<MeasureCallback> measure_callbacks, Optional<Database> database,
+            Optional<CostModel> cost_model) final;
+
+  static constexpr const char* _type_key = "meta_schedule.PyTaskScheduler";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PyTaskSchedulerNode, TaskSchedulerNode);
+};
+
+/*!
+ * \brief Managed reference to TaskSchedulerNode.
+ * \sa TaskSchedulerNode
+ */
+class TaskScheduler : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief Create a task scheduler that fetches tasks in a round-robin fashion.
+   * \param logger The tuning task's logging function.
+   * \return The task scheduler created.
+   */
+  TVM_DLL static TaskScheduler RoundRobin(PackedFunc logger);
+  /*!
+   * \brief Create a task scheduler that fetches tasks in a gradient based fashion.
+   * \param logger The tuning task's logging function.
+   * \param alpha The parameter alpha to control gradient computation.
+   * \param window_size The parameter to control backward window size.
+   * \param seed The random seed.
+   * \return The task scheduler created.
+   */
+  TVM_DLL static TaskScheduler GradientBased(PackedFunc logger, double alpha, int window_size,
+                                             support::LinearCongruentialEngine::TRandState seed);
+  /*!
+   * \brief Create a task scheduler with customized methods on the python-side.
+   * \param logger The tuning task's logging function.
+   * \param f_next_task_id The packed function of `NextTaskId`.
+   * \param f_join_running_task The packed function of `JoinRunningTask`.
+   * \param f_tune The packed function of `Tune`.
+   * \return The task scheduler created.
+   */
+  TVM_DLL static TaskScheduler PyTaskScheduler(
+      PackedFunc logger, PyTaskSchedulerNode::FNextTaskId f_next_task_id,
+      PyTaskSchedulerNode::FJoinRunningTask f_join_running_task, PyTaskSchedulerNode::FTune f_tune);
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(TaskScheduler, ObjectRef, TaskSchedulerNode);
+};
+
+}  // namespace meta_schedule
+}  // namespace tvm
+
+#endif  // TVM_META_SCHEDULE_TASK_SCHEDULER_H_
diff --git a/darknet_drp_ros/include/tvm/meta_schedule/tune_context.h b/darknet_drp_ros/include/tvm/meta_schedule/tune_context.h
new file mode 100644
index 0000000..15f3cba
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/meta_schedule/tune_context.h
@@ -0,0 +1,119 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_META_SCHEDULE_TUNE_CONTEXT_H_
+#define TVM_META_SCHEDULE_TUNE_CONTEXT_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/ir/module.h>
+#include <tvm/meta_schedule/builder.h>
+#include <tvm/meta_schedule/runner.h>
+#include <tvm/meta_schedule/search_strategy.h>
+#include <tvm/meta_schedule/space_generator.h>
+#include <tvm/node/reflection.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/map.h>
+#include <tvm/runtime/container/optional.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/runtime/object.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/support/random_engine.h>
+#include <tvm/target/target.h>
+
+namespace tvm {
+namespace meta_schedule {
+
+class TaskSchedulerNode;
+class MeasureCallback;
+class TuneContext;
+
+/*! \brief The auto tuning context. */
+class TuneContextNode : public runtime::Object {
+ public:
+  using TRandState = support::LinearCongruentialEngine::TRandState;
+
+  /*! \brief The workload to be tuned. */
+  Optional<IRModule> mod;
+  /*! \brief The target to be tuned for. */
+  Optional<Target> target;
+  /*! \brief The design space generator. */
+  Optional<SpaceGenerator> space_generator;
+  /*! \brief The search strategy. */
+  Optional<SearchStrategy> search_strategy;
+  /*! \brief The name of the tuning task. */
+  Optional<String> task_name;
+  /*! \brief The number of threads to be used. */
+  int num_threads;
+  /*! \brief The random state. */
+  TRandState rand_state;
+  /*! \brief The tuning task's logging function. t*/
+  PackedFunc logger;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("mod", &mod);
+    v->Visit("target", &target);
+    v->Visit("space_generator", &space_generator);
+    v->Visit("search_strategy", &search_strategy);
+    v->Visit("task_name", &task_name);
+    v->Visit("num_threads", &num_threads);
+    v->Visit("rand_state", &rand_state);
+    // `logger` is not visited
+  }
+  /*!
+   * \brief Initialize members that needs initialization with tune context.
+   */
+  void Initialize();
+  /*!
+   * \brief Clone the tune context.
+   * \return The cloned tune context.
+   */
+  TuneContext Clone() const;
+
+  static constexpr const char* _type_key = "meta_schedule.TuneContext";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TuneContextNode, Object);
+};
+
+/*!
+ * \brief Managed reference to TuneContextNode.
+ * \sa TuneContextNode
+ */
+class TuneContext : public runtime::ObjectRef {
+ public:
+  using TRandState = support::LinearCongruentialEngine::TRandState;
+  /*!
+   * \brief Constructor.
+   * \param mod The workload to be tuned.
+   * \param target The target to be tuned for.
+   * \param space_generator The design space generator.
+   * \param search_strategy The search strategy.
+   * \param task_name The name of the tuning task.
+   * \param num_threads The number of threads to be used.
+   * \param rand_state The random state.
+   * \param logger The tuning task's logging function.
+   */
+  TVM_DLL explicit TuneContext(Optional<IRModule> mod, Optional<Target> target,
+                               Optional<SpaceGenerator> space_generator,
+                               Optional<SearchStrategy> search_strategy, Optional<String> task_name,
+                               int num_threads, TRandState rand_state, PackedFunc logger);
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(TuneContext, ObjectRef, TuneContextNode);
+};
+
+}  // namespace meta_schedule
+}  // namespace tvm
+
+#endif  // TVM_META_SCHEDULE_TUNE_CONTEXT_H_
diff --git a/darknet_drp_ros/include/tvm/node/attr_registry_map.h b/darknet_drp_ros/include/tvm/node/attr_registry_map.h
new file mode 100644
index 0000000..c4b54ef
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/node/attr_registry_map.h
@@ -0,0 +1,134 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+/*!
+ * \file tvm/node/attr_registry_map.h
+ * \brief Attribute map used in registry.
+ */
+#ifndef TVM_NODE_ATTR_REGISTRY_MAP_H_
+#define TVM_NODE_ATTR_REGISTRY_MAP_H_
+
+#include <tvm/runtime/container/string.h>
+
+#include <utility>
+#include <vector>
+
+namespace tvm {
+
+/*!
+ * \brief Generic attribute map.
+ * \tparam KeyType the type of the key.
+ */
+template <typename KeyType>
+class AttrRegistryMapContainerMap {
+ public:
+  /*!
+   * \brief Check if the map has key.
+   * \param key The key to the map
+   * \return 1 if key is contained in map, 0 otherwise.
+   */
+  int count(const KeyType& key) const {
+    if (key.defined()) {
+      const uint32_t idx = key->AttrRegistryIndex();
+      return idx < data_.size() ? (data_[idx].second != 0) : 0;
+    } else {
+      return 0;
+    }
+  }
+  /*!
+   * \brief get the corresponding value element at key.
+   * \param key The key to the map
+   * \return the const reference to the content value.
+   */
+  const runtime::TVMRetValue& operator[](const KeyType& key) const {
+    ICHECK(key.defined());
+    const uint32_t idx = key->AttrRegistryIndex();
+    ICHECK(idx < data_.size() && data_[idx].second != 0)
+        << "Attribute " << attr_name_ << " has not been registered for " << key->name;
+    return data_[idx].first;
+  }
+  /*!
+   * \brief get the corresponding value element at key with default value.
+   * \param key The key to the map
+   * \param def_value The default value when the key does not exist.
+   * \return the const reference to the content value.
+   * \tparam ValueType The content value type.
+   */
+  template <typename ValueType>
+  ValueType get(const KeyType& key, ValueType def_value) const {
+    ICHECK(key.defined());
+    const uint32_t idx = key->AttrRegistryIndex();
+    if (idx < data_.size() && data_[idx].second != 0) {
+      return data_[idx].first;
+    } else {
+      return def_value;
+    }
+  }
+
+ private:
+  /*! \brief The name of the attr field */
+  String attr_name_;
+  /*! \brief The internal data. */
+  std::vector<std::pair<runtime::TVMRetValue, int>> data_;
+  /*! \brief The constructor */
+  AttrRegistryMapContainerMap() = default;
+  template <typename, typename>
+  friend class AttrRegistry;
+  friend class OpRegEntry;
+};
+
+/*!
+ * \brief Map<Key, ValueType> used to store meta-data.
+ * \tparam KeyType The type of the key
+ * \tparam ValueType The type of the value stored in map.
+ */
+template <typename KeyType, typename ValueType>
+class AttrRegistryMap {
+ public:
+  /*!
+   * \brief constructor
+   * \param map The internal map.
+   */
+  explicit AttrRegistryMap(const AttrRegistryMapContainerMap<KeyType>& map) : map_(map) {}
+  /*!
+   * \brief Check if the map has op as key.
+   * \param key The key to the map
+   * \return 1 if op is contained in map, 0 otherwise.
+   */
+  int count(const KeyType& key) const { return map_.count(key); }
+  /*!
+   * \brief get the corresponding value element at key.
+   * \param key The key to the map
+   * \return the const reference to the content value.
+   */
+  ValueType operator[](const KeyType& key) const { return map_[key]; }
+  /*!
+   * \brief get the corresponding value element at key with default value.
+   * \param key The key to the map
+   * \param def_value The default value when the key does not exist.
+   * \return the const reference to the content value.
+   */
+  ValueType get(const KeyType& key, ValueType def_value) const { return map_.get(key, def_value); }
+
+ protected:
+  /*! \brief The internal map field */
+  const AttrRegistryMapContainerMap<KeyType>& map_;
+};
+
+}  // namespace tvm
+#endif  // TVM_NODE_ATTR_REGISTRY_MAP_H_
diff --git a/darknet_drp_ros/include/tvm/node/functor.h b/darknet_drp_ros/include/tvm/node/functor.h
new file mode 100644
index 0000000..fa0ab55
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/node/functor.h
@@ -0,0 +1,176 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+/*!
+ * \file tvm/node/functor.h
+ * \brief Defines the Functor data structures.
+ */
+#ifndef TVM_NODE_FUNCTOR_H_
+#define TVM_NODE_FUNCTOR_H_
+
+#include <dmlc/logging.h>
+#include <tvm/runtime/object.h>
+
+#include <type_traits>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+
+using runtime::ObjectRef;
+
+/*!
+ * \brief A dynamically dispatched functor on the type of the first argument.
+ *
+ * This is a class that is useful to construct polymorphic dispatching
+ * base on the AST/IR node's type.
+ *
+ * \code
+ *   NodeFunctor<std::string (const ObjectRef& n, std::string prefix)> tostr;
+ *   tostr.set_dispatch<Add>([](const ObjectRef& op, std::string prefix) {
+ *     return prefix + "Add";
+ *   });
+ *   tostr.set_dispatch<IntImm>([](const ObjectRef& op, std::string prefix) {
+ *     return prefix + "IntImm"
+ *   });
+ *
+ *   Expr x = make_const(1);
+ *   Expr y = x + x;
+ *   // dispatch to IntImm, outputs "MyIntImm"
+ *   LOG(INFO) << tostr(x, "My");
+ *   // dispatch to IntImm, outputs "MyAdd"
+ *   LOG(INFO) << tostr(y, "My");
+ * \endcode
+ *
+ * \tparam FType function signiture
+ *  This type if only defined for FType with function signature
+ */
+template <typename FType>
+class NodeFunctor;
+
+template <typename R, typename... Args>
+class NodeFunctor<R(const ObjectRef& n, Args...)> {
+ private:
+  /*! \brief internal function pointer type */
+  typedef R (*FPointer)(const ObjectRef& n, Args...);
+  /*! \brief refer to itself. */
+  using TSelf = NodeFunctor<R(const ObjectRef& n, Args...)>;
+  /*! \brief internal function table */
+  std::vector<FPointer> func_;
+
+ public:
+  /*! \brief the result type of this functor */
+  using result_type = R;
+  /*!
+   * \brief Whether the functor can dispatch the corresponding Node
+   * \param n The node to be dispatched
+   * \return Whether dispatching function is registered for n's type.
+   */
+  bool can_dispatch(const ObjectRef& n) const {
+    uint32_t type_index = n->type_index();
+    return type_index < func_.size() && func_[type_index] != nullptr;
+  }
+  /*!
+   * \brief invoke the functor, dispatch on type of n
+   * \param n The Node argument
+   * \param args The additional arguments
+   * \return The result.
+   */
+  R operator()(const ObjectRef& n, Args... args) const {
+    ICHECK(can_dispatch(n)) << "NodeFunctor calls un-registered function on type "
+                            << n->GetTypeKey();
+    return (*func_[n->type_index()])(n, std::forward<Args>(args)...);
+  }
+  /*!
+   * \brief set the dispatcher for type TNode
+   * \param f The function to be set.
+   * \tparam TNode the type of Node to be dispatched.
+   * \return reference to self.
+   */
+  template <typename TNode>
+  TSelf& set_dispatch(FPointer f) {  // NOLINT(*)
+    uint32_t tindex = TNode::RuntimeTypeIndex();
+    if (func_.size() <= tindex) {
+      func_.resize(tindex + 1, nullptr);
+    }
+    ICHECK(func_[tindex] == nullptr) << "Dispatch for " << TNode::_type_key << " is already set";
+    func_[tindex] = f;
+    return *this;
+  }
+  /*!
+   * \brief unset the dispatcher for type TNode
+   *
+   * \tparam TNode the type of Node to be dispatched.
+   * \return reference to self.
+   */
+  template <typename TNode>
+  TSelf& clear_dispatch() {  // NOLINT(*)
+    uint32_t tindex = TNode::RuntimeTypeIndex();
+    ICHECK_LT(tindex, func_.size()) << "clear_dispatch: index out of range";
+    func_[tindex] = nullptr;
+    return *this;
+  }
+};
+
+#define TVM_REG_FUNC_VAR_DEF(ClsName) static TVM_ATTRIBUTE_UNUSED auto& __make_functor##_##ClsName
+
+/*!
+ * \brief Useful macro to set NodeFunctor dispatch in a global static field.
+ *
+ * \code
+ *  // Use NodeFunctor to implement ReprPrinter similar to Visitor Pattern.
+ *  // vtable allows easy patch of new Node types, without changing
+ *  // interface of ReprPrinter.
+ *
+ *  class ReprPrinter {
+ *   public:
+ *    std::ostream& stream;
+ *    // the dispatch function.
+ *    void print(Expr e) {
+ *      const static FType& f = *vtable();
+ *      f(e, this);
+ *    }
+ *
+ *    using FType = NodeFunctor<void (const ObjectRef&, ReprPrinter* )>;
+ *    // function to return global function table
+ *    static FType& vtable();
+ *  };
+ *
+ *  // in cpp/cc file
+ *  ReprPrinter::FType& ReprPrinter::vtable() { // NOLINT(*)
+ *    static FType inst; return inst;
+ *  }
+ *
+ *  TVM_STATIC_IR_FUNCTOR(ReprPrinter, vtable)
+ *  .set_dispatch<Add>([](const ObjectRef& ref, ReprPrinter* p) {
+ *    auto* n = static_cast<const Add*>(ref.get());
+ *    p->print(n->a);
+ *    p->stream << '+'
+ *    p->print(n->b);
+ *  });
+ *
+ *
+ * \endcode
+ *
+ * \param ClsName The name of the class
+ * \param FField The static function that returns a singleton of NodeFunctor.
+ */
+#define TVM_STATIC_IR_FUNCTOR(ClsName, FField) \
+  TVM_STR_CONCAT(TVM_REG_FUNC_VAR_DEF(ClsName), __COUNTER__) = ClsName::FField()
+}  // namespace tvm
+#endif  // TVM_NODE_FUNCTOR_H_
diff --git a/darknet_drp_ros/include/tvm/node/node.h b/darknet_drp_ros/include/tvm/node/node.h
new file mode 100644
index 0000000..ad4fb1e
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/node/node.h
@@ -0,0 +1,66 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+/*!
+ * \file tvm/node/node.h
+ * \brief Definitions and helper macros for IR/AST nodes.
+ *
+ *  The node folder contains base utilities for IR/AST nodes,
+ *  invariant of which specific language dialect.
+ *
+ *  We implement AST/IR nodes as sub-classes of runtime::Object.
+ *  The base class Node is just an alias of runtime::Object.
+ *
+ *  Besides the runtime type checking provided by Object,
+ *  node folder contains additional functionalities such as
+ *  reflection and serialization, which are important features
+ *  for building a compiler infra.
+ */
+#ifndef TVM_NODE_NODE_H_
+#define TVM_NODE_NODE_H_
+
+#include <tvm/node/reflection.h>
+#include <tvm/node/repr_printer.h>
+#include <tvm/node/structural_equal.h>
+#include <tvm/node/structural_hash.h>
+#include <tvm/runtime/c_runtime_api.h>
+#include <tvm/runtime/memory.h>
+#include <tvm/runtime/object.h>
+
+#include <string>
+#include <type_traits>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+
+using runtime::Downcast;
+using runtime::GetRef;
+using runtime::make_object;
+using runtime::Object;
+using runtime::ObjectPtr;
+using runtime::ObjectPtrEqual;
+using runtime::ObjectPtrHash;
+using runtime::ObjectRef;
+using runtime::PackedFunc;
+using runtime::TVMArgs;
+using runtime::TVMRetValue;
+using runtime::TypeIndex;
+
+}  // namespace tvm
+#endif  // TVM_NODE_NODE_H_
diff --git a/darknet_drp_ros/include/tvm/node/object_path.h b/darknet_drp_ros/include/tvm/node/object_path.h
new file mode 100644
index 0000000..35f947a
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/node/object_path.h
@@ -0,0 +1,285 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/node/object_path.h
+ * ObjectPath class that represents a path from a root object to one of its descendants
+ * via attribute access, array indexing etc.
+ */
+
+#ifndef TVM_NODE_OBJECT_PATH_H_
+#define TVM_NODE_OBJECT_PATH_H_
+
+#include <tvm/runtime/container/optional.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/runtime/object.h>
+
+#include <string>
+
+namespace tvm {
+
+using runtime::Object;
+using runtime::ObjectPtr;
+using runtime::ObjectRef;
+
+class ObjectPath;
+
+/*!
+ * \brief Path to an object from some root object.
+ *
+ * Motivation:
+ *
+ * Same IR node object can be referenced in several different contexts inside a larger IR object.
+ * For example, a variable could be referenced in several statements within a block.
+ *
+ * This makes it impossible to use an object pointer to uniquely identify a "location" within
+ * the larger IR object for error reporting purposes. The ObjectPath class addresses this problem
+ * by serving as a unique "locator".
+ */
+class ObjectPathNode : public Object {
+ public:
+  /*! \brief Get the parent path */
+  Optional<ObjectPath> GetParent() const;
+  /*!
+   * \brief Get the length of the path.
+   *
+   * For example, the path returned by `ObjectPath::Root()` has length 1.
+   */
+  int32_t Length() const;
+
+  /*!
+   * \brief Get a path prefix of the given length.
+   *
+   * Provided `length` must not exceed the `Length()` of this path.
+   */
+  ObjectPath GetPrefix(int32_t length) const;
+
+  /*!
+   * \brief Check if this path is a prefix of another path.
+   *
+   * The prefix is not strict, i.e. a path is considered a prefix of itself.
+   */
+  bool IsPrefixOf(const ObjectPath& other) const;
+
+  /*! \brief Check if two paths are equal. */
+  bool PathsEqual(const ObjectPath& other) const;
+
+  /*! \brief Extend this path with access to an object attribute. */
+  ObjectPath Attr(const char* attr_key) const;
+
+  /*! \brief Extend this path with access to an object attribute. */
+  ObjectPath Attr(Optional<String> attr_key) const;
+
+  /*! \brief Extend this path with access to an array element. */
+  ObjectPath ArrayIndex(int32_t index) const;
+
+  /*! \brief Extend this path with access to a missing array element. */
+  ObjectPath MissingArrayElement(int32_t index) const;
+
+  /*! \brief Extend this path with access to a map value. */
+  ObjectPath MapValue(ObjectRef key) const;
+
+  /*! \brief Extend this path with access to a missing map entry. */
+  ObjectPath MissingMapEntry() const;
+
+  static constexpr const char* _type_key = "ObjectPath";
+  TVM_DECLARE_BASE_OBJECT_INFO(ObjectPathNode, Object);
+
+ protected:
+  explicit ObjectPathNode(const ObjectPathNode* parent);
+
+  friend class ObjectPath;
+  friend std::string GetObjectPathRepr(const ObjectPathNode* node);
+
+  const ObjectPathNode* ParentNode() const;
+
+  /*! Compares just the last node of the path, without comparing the whole path. */
+  virtual bool LastNodeEqual(const ObjectPathNode* other) const = 0;
+
+  virtual std::string LastNodeString() const = 0;
+
+ private:
+  Optional<ObjectRef> parent_;
+  int32_t length_;
+};
+
+class ObjectPath : public ObjectRef {
+ public:
+  /*! \brief Create a path that represents the root object itself. */
+  static ObjectPath Root();
+
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(ObjectPath, ObjectRef, ObjectPathNode);
+};
+
+//-------------------------------------------------------------------------
+//-----   Concrete object path nodes   ------------------------------------
+//-------------------------------------------------------------------------
+
+// ----- Root -----
+
+class RootPathNode final : public ObjectPathNode {
+ public:
+  explicit RootPathNode();
+
+  static constexpr const char* _type_key = "RootPath";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RootPathNode, ObjectPathNode);
+
+ protected:
+  bool LastNodeEqual(const ObjectPathNode* other) const final;
+  std::string LastNodeString() const final;
+};
+
+class RootPath : public ObjectPath {
+ public:
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(RootPath, ObjectPath, RootPathNode);
+};
+
+// ----- Attribute access -----
+
+class AttributeAccessPathNode final : public ObjectPathNode {
+ public:
+  /*! \brief Name of the attribute being accessed. Must be a static string. */
+  String attr_key;
+
+  explicit AttributeAccessPathNode(const ObjectPathNode* parent, String attr_key);
+
+  static constexpr const char* _type_key = "AttributeAccessPath";
+  TVM_DECLARE_FINAL_OBJECT_INFO(AttributeAccessPathNode, ObjectPathNode);
+
+ protected:
+  bool LastNodeEqual(const ObjectPathNode* other) const final;
+  std::string LastNodeString() const final;
+};
+
+class AttributeAccessPath : public ObjectPath {
+ public:
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(AttributeAccessPath, ObjectPath,
+                                            AttributeAccessPathNode);
+};
+
+// ----- Unknown attribute access -----
+
+class UnknownAttributeAccessPathNode final : public ObjectPathNode {
+ public:
+  explicit UnknownAttributeAccessPathNode(const ObjectPathNode* parent);
+
+  static constexpr const char* _type_key = "UnknownAttributeAccessPath";
+  TVM_DECLARE_FINAL_OBJECT_INFO(UnknownAttributeAccessPathNode, ObjectPathNode);
+
+ protected:
+  bool LastNodeEqual(const ObjectPathNode* other) const final;
+  std::string LastNodeString() const final;
+};
+
+class UnknownAttributeAccessPath : public ObjectPath {
+ public:
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(UnknownAttributeAccessPath, ObjectPath,
+                                            UnknownAttributeAccessPathNode);
+};
+
+// ----- Array element access by index -----
+
+class ArrayIndexPathNode : public ObjectPathNode {
+ public:
+  /*! \brief Index of the array element that is being accessed. */
+  int32_t index;
+
+  explicit ArrayIndexPathNode(const ObjectPathNode* parent, int32_t index);
+
+  static constexpr const char* _type_key = "ArrayIndexPath";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ArrayIndexPathNode, ObjectPathNode);
+
+ protected:
+  bool LastNodeEqual(const ObjectPathNode* other) const final;
+  std::string LastNodeString() const final;
+};
+
+class ArrayIndexPath : public ObjectPath {
+ public:
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(ArrayIndexPath, ObjectPath, ArrayIndexPathNode);
+};
+
+// ----- Missing array element -----
+
+class MissingArrayElementPathNode : public ObjectPathNode {
+ public:
+  /*! \brief Index of the array element that is missing. */
+  int32_t index;
+
+  explicit MissingArrayElementPathNode(const ObjectPathNode* parent, int32_t index);
+
+  static constexpr const char* _type_key = "MissingArrayElementPath";
+  TVM_DECLARE_FINAL_OBJECT_INFO(MissingArrayElementPathNode, ObjectPathNode);
+
+ protected:
+  bool LastNodeEqual(const ObjectPathNode* other) const final;
+  std::string LastNodeString() const final;
+};
+
+class MissingArrayElementPath : public ObjectPath {
+ public:
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(MissingArrayElementPath, ObjectPath,
+                                            MissingArrayElementPathNode);
+};
+
+// ----- Map value -----
+
+class MapValuePathNode : public ObjectPathNode {
+ public:
+  /*! \brief Key of the map entry that is being accessed */
+  ObjectRef key;
+
+  explicit MapValuePathNode(const ObjectPathNode* parent, ObjectRef key);
+
+  static constexpr const char* _type_key = "MapValuePath";
+  TVM_DECLARE_FINAL_OBJECT_INFO(MapValuePathNode, ObjectPathNode);
+
+ protected:
+  bool LastNodeEqual(const ObjectPathNode* other) const final;
+  std::string LastNodeString() const final;
+};
+
+class MapValuePath : public ObjectPath {
+ public:
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(MapValuePath, ObjectPath, MapValuePathNode);
+};
+
+// ----- Missing map entry -----
+
+class MissingMapEntryPathNode : public ObjectPathNode {
+ public:
+  explicit MissingMapEntryPathNode(const ObjectPathNode* parent);
+
+  static constexpr const char* _type_key = "MissingMapEntryPath";
+  TVM_DECLARE_FINAL_OBJECT_INFO(MissingMapEntryPathNode, ObjectPathNode);
+
+ protected:
+  bool LastNodeEqual(const ObjectPathNode* other) const final;
+  std::string LastNodeString() const final;
+};
+
+class MissingMapEntryPath : public ObjectPath {
+ public:
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(MissingMapEntryPath, ObjectPath,
+                                            MissingMapEntryPathNode);
+};
+
+}  // namespace tvm
+
+#endif  // TVM_NODE_OBJECT_PATH_H_
diff --git a/darknet_drp_ros/include/tvm/node/reflection.h b/darknet_drp_ros/include/tvm/node/reflection.h
new file mode 100644
index 0000000..f547b5a
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/node/reflection.h
@@ -0,0 +1,414 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+/*!
+ * \file tvm/node/reflection.h
+ * \brief Reflection and serialization of compiler IR/AST nodes.
+ */
+#ifndef TVM_NODE_REFLECTION_H_
+#define TVM_NODE_REFLECTION_H_
+
+#include <tvm/node/structural_equal.h>
+#include <tvm/node/structural_hash.h>
+#include <tvm/runtime/c_runtime_api.h>
+#include <tvm/runtime/data_type.h>
+#include <tvm/runtime/memory.h>
+#include <tvm/runtime/ndarray.h>
+#include <tvm/runtime/object.h>
+#include <tvm/runtime/packed_func.h>
+
+#include <string>
+#include <type_traits>
+#include <vector>
+
+namespace tvm {
+
+using runtime::Object;
+using runtime::ObjectPtr;
+using runtime::ObjectRef;
+
+/*!
+ * \brief Visitor class to get the attributes of an AST/IR node.
+ *  The content is going to be called for each field.
+ *
+ *  Each objects that wants reflection will need to implement
+ *  a VisitAttrs function and call visitor->Visit on each of its field.
+ */
+class AttrVisitor {
+ public:
+  //! \cond Doxygen_Suppress
+  TVM_DLL virtual ~AttrVisitor() = default;
+  TVM_DLL virtual void Visit(const char* key, double* value) = 0;
+  TVM_DLL virtual void Visit(const char* key, int64_t* value) = 0;
+  TVM_DLL virtual void Visit(const char* key, uint64_t* value) = 0;
+  TVM_DLL virtual void Visit(const char* key, int* value) = 0;
+  TVM_DLL virtual void Visit(const char* key, bool* value) = 0;
+  TVM_DLL virtual void Visit(const char* key, std::string* value) = 0;
+  TVM_DLL virtual void Visit(const char* key, void** value) = 0;
+  TVM_DLL virtual void Visit(const char* key, DataType* value) = 0;
+  TVM_DLL virtual void Visit(const char* key, runtime::NDArray* value) = 0;
+  TVM_DLL virtual void Visit(const char* key, runtime::ObjectRef* value) = 0;
+  template <typename ENum, typename = typename std::enable_if<std::is_enum<ENum>::value>::type>
+  void Visit(const char* key, ENum* ptr) {
+    static_assert(std::is_same<int, typename std::underlying_type<ENum>::type>::value,
+                  "declare enum to be enum int to use visitor");
+    this->Visit(key, reinterpret_cast<int*>(ptr));
+  }
+  //! \endcond
+};
+
+/*!
+ * \brief Virtual function table to support IR/AST node reflection.
+ *
+ * Functions are stored in columnar manner.
+ * Each column is a vector indexed by Object's type_index.
+ */
+class ReflectionVTable {
+ public:
+  /*!
+   * \brief Visitor function.
+   * \note We use function pointer, instead of std::function
+   *       to reduce the dispatch overhead as field visit
+   *       does not need as much customization.
+   */
+  typedef void (*FVisitAttrs)(Object* self, AttrVisitor* visitor);
+  /*!
+   * \brief Equality comparison function.
+   */
+  typedef bool (*FSEqualReduce)(const Object* self, const Object* other, SEqualReducer equal);
+  /*!
+   * \brief Structural hash reduction function.
+   */
+  typedef void (*FSHashReduce)(const Object* self, SHashReducer hash_reduce);
+  /*!
+   * \brief creator function.
+   * \param repr_bytes Repr bytes to create the object.
+   *        If this is not empty then FReprBytes must be defined for the object.
+   * \return The created function.
+   */
+  typedef ObjectPtr<Object> (*FCreate)(const std::string& repr_bytes);
+  /*!
+   * \brief Function to get a byte representation that can be used to recover the object.
+   * \param node The node pointer.
+   * \return bytes The bytes that can be used to recover the object.
+   */
+  typedef std::string (*FReprBytes)(const Object* self);
+  /*!
+   * \brief Dispatch the VisitAttrs function.
+   * \param self The pointer to the object.
+   * \param visitor The attribute visitor.
+   */
+  inline void VisitAttrs(Object* self, AttrVisitor* visitor) const;
+  /*!
+   * \brief Get repr bytes if any.
+   * \param self The pointer to the object.
+   * \param repr_bytes The output repr bytes, can be null, in which case the function
+   *                   simply queries if the ReprBytes function exists for the type.
+   * \return Whether repr bytes exists
+   */
+  inline bool GetReprBytes(const Object* self, std::string* repr_bytes) const;
+  /*!
+   * \brief Dispatch the SEqualReduce function.
+   * \param self The pointer to the object.
+   * \param other The pointer to another object to be compared.
+   * \param equal The equality comparator.
+   * \return the result.
+   */
+  bool SEqualReduce(const Object* self, const Object* other, SEqualReducer equal) const;
+  /*!
+   * \brief Dispatch the SHashReduce function.
+   * \param self The pointer to the object.
+   * \param hash_reduce The hash reducer.
+   * \return the result.
+   */
+  void SHashReduce(const Object* self, SHashReducer hash_reduce) const;
+  /*!
+   * \brief Create an initial object using default constructor
+   *        by type_key and global key.
+   *
+   * \param type_key The type key of the object.
+   * \param repr_bytes Bytes representation of the object if any.
+   */
+  TVM_DLL ObjectPtr<Object> CreateInitObject(const std::string& type_key,
+                                             const std::string& repr_bytes = "") const;
+  /*!
+   * \brief Create an object by giving kwargs about its fields.
+   *
+   * \param type_key The type key.
+   * \param kwargs the arguments in format key1, value1, ..., key_n, value_n.
+   * \return The created object.
+   */
+  TVM_DLL ObjectRef CreateObject(const std::string& type_key, const runtime::TVMArgs& kwargs);
+  /*!
+   * \brief Create an object by giving kwargs about its fields.
+   *
+   * \param type_key The type key.
+   * \param kwargs The field arguments.
+   * \return The created object.
+   */
+  TVM_DLL ObjectRef CreateObject(const std::string& type_key, const Map<String, ObjectRef>& kwargs);
+  /*!
+   * \brief Get an field object by the attr name.
+   * \param self The pointer to the object.
+   * \param attr_name The name of the field.
+   * \return The corresponding attribute value.
+   * \note This function will throw an exception if the object does not contain the field.
+   */
+  TVM_DLL runtime::TVMRetValue GetAttr(Object* self, const String& attr_name) const;
+
+  /*!
+   * \brief List all the fields in the object.
+   * \return All the fields.
+   */
+  TVM_DLL std::vector<std::string> ListAttrNames(Object* self) const;
+
+  /*! \return The global singleton. */
+  TVM_DLL static ReflectionVTable* Global();
+
+  class Registry;
+  template <typename T, typename TraitName>
+  inline Registry Register();
+
+ private:
+  /*! \brief Attribute visitor. */
+  std::vector<FVisitAttrs> fvisit_attrs_;
+  /*! \brief Structural equal function. */
+  std::vector<FSEqualReduce> fsequal_reduce_;
+  /*! \brief Structural hash function. */
+  std::vector<FSHashReduce> fshash_reduce_;
+  /*! \brief Creation function. */
+  std::vector<FCreate> fcreate_;
+  /*! \brief ReprBytes function. */
+  std::vector<FReprBytes> frepr_bytes_;
+};
+
+/*! \brief Registry of a reflection table. */
+class ReflectionVTable::Registry {
+ public:
+  Registry(ReflectionVTable* parent, uint32_t type_index)
+      : parent_(parent), type_index_(type_index) {}
+  /*!
+   * \brief Set fcreate function.
+   * \param f The creator function.
+   * \return Reference to self.
+   */
+  Registry& set_creator(FCreate f) {  // NOLINT(*)
+    ICHECK_LT(type_index_, parent_->fcreate_.size());
+    parent_->fcreate_[type_index_] = f;
+    return *this;
+  }
+  /*!
+   * \brief Set bytes repr function.
+   * \param f The ReprBytes function.
+   * \return Reference to self.
+   */
+  Registry& set_repr_bytes(FReprBytes f) {  // NOLINT(*)
+    ICHECK_LT(type_index_, parent_->frepr_bytes_.size());
+    parent_->frepr_bytes_[type_index_] = f;
+    return *this;
+  }
+
+ private:
+  ReflectionVTable* parent_;
+  uint32_t type_index_;
+};
+
+#define TVM_REFLECTION_REG_VAR_DEF \
+  static TVM_ATTRIBUTE_UNUSED ::tvm::ReflectionVTable::Registry __make_reflection
+
+/*!
+ * \brief Directly register reflection VTable.
+ * \param TypeName The name of the type.
+ * \param TraitName A trait class that implements functions like VisitAttrs and SEqualReduce.
+ *
+ * \code
+ *
+ *  // Example SEQualReduce traits for runtime StringObj.
+ *
+ *  struct StringObjTrait {
+ *    static constexpr const std::nullptr_t VisitAttrs = nullptr;
+ *
+ *    static void SHashReduce(const runtime::StringObj* key, SHashReducer hash_reduce) {
+ *      hash_reduce->SHashReduceHashedValue(runtime::String::HashBytes(key->data, key->size));
+ *    }
+ *
+ *    static bool SEqualReduce(const runtime::StringObj* lhs,
+ *                             const runtime::StringObj* rhs,
+ *                             SEqualReducer equal) {
+ *      if (lhs == rhs) return true;
+ *      if (lhs->size != rhs->size) return false;
+ *      if (lhs->data != rhs->data) return true;
+ *      return std::memcmp(lhs->data, rhs->data, lhs->size) != 0;
+ *    }
+ *  };
+ *
+ *  TVM_REGISTER_REFLECTION_VTABLE(runtime::StringObj, StringObjTrait);
+ *
+ * \endcode
+ *
+ * \note This macro can be called in different place as TVM_REGISTER_OBJECT_TYPE.
+ *       And can be used to register the related reflection functions for runtime objects.
+ */
+#define TVM_REGISTER_REFLECTION_VTABLE(TypeName, TraitName) \
+  TVM_STR_CONCAT(TVM_REFLECTION_REG_VAR_DEF, __COUNTER__) = \
+      ::tvm::ReflectionVTable::Global()->Register<TypeName, TraitName>()
+
+/*!
+ * \brief Register a node type to object registry and reflection registry.
+ * \param TypeName The name of the type.
+ * \note This macro will call TVM_REGISTER_OBJECT_TYPE for the type as well.
+ */
+#define TVM_REGISTER_NODE_TYPE(TypeName)                                             \
+  TVM_REGISTER_OBJECT_TYPE(TypeName);                                                \
+  TVM_REGISTER_REFLECTION_VTABLE(TypeName, ::tvm::detail::ReflectionTrait<TypeName>) \
+      .set_creator([](const std::string&) -> ObjectPtr<Object> {                     \
+        return ::tvm::runtime::make_object<TypeName>();                              \
+      })
+
+// Implementation details
+namespace detail {
+
+template <typename T, bool = T::_type_has_method_visit_attrs>
+struct ImplVisitAttrs {
+  static constexpr const std::nullptr_t VisitAttrs = nullptr;
+};
+
+template <typename T>
+struct ImplVisitAttrs<T, true> {
+  static void VisitAttrs(T* self, AttrVisitor* v) { self->VisitAttrs(v); }
+};
+
+template <typename T, bool = T::_type_has_method_sequal_reduce>
+struct ImplSEqualReduce {
+  static constexpr const std::nullptr_t SEqualReduce = nullptr;
+};
+
+template <typename T>
+struct ImplSEqualReduce<T, true> {
+  static bool SEqualReduce(const T* self, const T* other, SEqualReducer equal) {
+    return self->SEqualReduce(other, equal);
+  }
+};
+
+template <typename T, bool = T::_type_has_method_shash_reduce>
+struct ImplSHashReduce {
+  static constexpr const std::nullptr_t SHashReduce = nullptr;
+};
+
+template <typename T>
+struct ImplSHashReduce<T, true> {
+  static void SHashReduce(const T* self, SHashReducer hash_reduce) {
+    self->SHashReduce(hash_reduce);
+  }
+};
+
+template <typename T>
+struct ReflectionTrait : public ImplVisitAttrs<T>,
+                         public ImplSEqualReduce<T>,
+                         public ImplSHashReduce<T> {};
+
+template <typename T, typename TraitName,
+          bool = std::is_null_pointer<decltype(TraitName::VisitAttrs)>::value>
+struct SelectVisitAttrs {
+  static constexpr const std::nullptr_t VisitAttrs = nullptr;
+};
+
+template <typename T, typename TraitName>
+struct SelectVisitAttrs<T, TraitName, false> {
+  static void VisitAttrs(Object* self, AttrVisitor* v) {
+    TraitName::VisitAttrs(static_cast<T*>(self), v);
+  }
+};
+
+template <typename T, typename TraitName,
+          bool = std::is_null_pointer<decltype(TraitName::SEqualReduce)>::value>
+struct SelectSEqualReduce {
+  static constexpr const std::nullptr_t SEqualReduce = nullptr;
+};
+
+template <typename T, typename TraitName>
+struct SelectSEqualReduce<T, TraitName, false> {
+  static bool SEqualReduce(const Object* self, const Object* other, SEqualReducer equal) {
+    return TraitName::SEqualReduce(static_cast<const T*>(self), static_cast<const T*>(other),
+                                   equal);
+  }
+};
+
+template <typename T, typename TraitName,
+          bool = std::is_null_pointer<decltype(TraitName::SHashReduce)>::value>
+struct SelectSHashReduce {
+  static constexpr const std::nullptr_t SHashReduce = nullptr;
+};
+
+template <typename T, typename TraitName>
+struct SelectSHashReduce<T, TraitName, false> {
+  static void SHashReduce(const Object* self, SHashReducer hash_reduce) {
+    return TraitName::SHashReduce(static_cast<const T*>(self), hash_reduce);
+  }
+};
+
+}  // namespace detail
+
+template <typename T, typename TraitName>
+inline ReflectionVTable::Registry ReflectionVTable::Register() {
+  uint32_t tindex = T::RuntimeTypeIndex();
+  if (tindex >= fvisit_attrs_.size()) {
+    fvisit_attrs_.resize(tindex + 1, nullptr);
+    fcreate_.resize(tindex + 1, nullptr);
+    frepr_bytes_.resize(tindex + 1, nullptr);
+    fsequal_reduce_.resize(tindex + 1, nullptr);
+    fshash_reduce_.resize(tindex + 1, nullptr);
+  }
+  // functor that implements the redirection.
+  fvisit_attrs_[tindex] = ::tvm::detail::SelectVisitAttrs<T, TraitName>::VisitAttrs;
+
+  fsequal_reduce_[tindex] = ::tvm::detail::SelectSEqualReduce<T, TraitName>::SEqualReduce;
+
+  fshash_reduce_[tindex] = ::tvm::detail::SelectSHashReduce<T, TraitName>::SHashReduce;
+
+  return Registry(this, tindex);
+}
+
+inline void ReflectionVTable::VisitAttrs(Object* self, AttrVisitor* visitor) const {
+  uint32_t tindex = self->type_index();
+  if (tindex >= fvisit_attrs_.size() || fvisit_attrs_[tindex] == nullptr) {
+    return;
+  }
+  fvisit_attrs_[tindex](self, visitor);
+}
+
+inline bool ReflectionVTable::GetReprBytes(const Object* self, std::string* repr_bytes) const {
+  uint32_t tindex = self->type_index();
+  if (tindex < frepr_bytes_.size() && frepr_bytes_[tindex] != nullptr) {
+    if (repr_bytes != nullptr) {
+      *repr_bytes = frepr_bytes_[tindex](self);
+    }
+    return true;
+  } else {
+    return false;
+  }
+}
+
+/*!
+ * \brief Given an object and an address of its attribute, return the key of the attribute.
+ * \return nullptr if no attribute with the given address exists.
+ */
+Optional<String> GetAttrKeyByAddress(const Object* object, const void* attr_address);
+
+}  // namespace tvm
+#endif  // TVM_NODE_REFLECTION_H_
diff --git a/darknet_drp_ros/include/tvm/node/repr_printer.h b/darknet_drp_ros/include/tvm/node/repr_printer.h
new file mode 100644
index 0000000..532425a
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/node/repr_printer.h
@@ -0,0 +1,75 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+/*!
+ * \file tvm/node/repr_printer.h
+ * \brief Printer class to print repr string of each AST/IR nodes.
+ */
+#ifndef TVM_NODE_REPR_PRINTER_H_
+#define TVM_NODE_REPR_PRINTER_H_
+
+#include <tvm/node/functor.h>
+
+#include <iostream>
+
+namespace tvm {
+/*! \brief A printer class to print the AST/IR nodes. */
+class ReprPrinter {
+ public:
+  /*! \brief The output stream */
+  std::ostream& stream;
+  /*! \brief The indentation level. */
+  int indent{0};
+
+  explicit ReprPrinter(std::ostream& stream)  // NOLINT(*)
+      : stream(stream) {}
+
+  /*! \brief The node to be printed. */
+  TVM_DLL void Print(const ObjectRef& node);
+  /*! \brief Print indent to the stream */
+  TVM_DLL void PrintIndent();
+  // Allow registration to be printer.
+  using FType = NodeFunctor<void(const ObjectRef&, ReprPrinter*)>;
+  TVM_DLL static FType& vtable();
+};
+
+/*!
+ * \brief Dump the node to stderr, used for debug purposes.
+ * \param node The input node
+ */
+TVM_DLL void Dump(const runtime::ObjectRef& node);
+
+/*!
+ * \brief Dump the node to stderr, used for debug purposes.
+ * \param node The input node
+ */
+TVM_DLL void Dump(const runtime::Object* node);
+
+}  // namespace tvm
+
+namespace tvm {
+namespace runtime {
+// default print function for all objects
+// provide in the runtime namespace as this is where objectref originally comes from.
+inline std::ostream& operator<<(std::ostream& os, const ObjectRef& n) {  // NOLINT(*)
+  ReprPrinter(os).Print(n);
+  return os;
+}
+}  // namespace runtime
+}  // namespace tvm
+#endif  // TVM_NODE_REPR_PRINTER_H_
diff --git a/darknet_drp_ros/include/tvm/node/serialization.h b/darknet_drp_ros/include/tvm/node/serialization.h
new file mode 100644
index 0000000..ac67594
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/node/serialization.h
@@ -0,0 +1,51 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * Utility functions for serialization.
+ * \file tvm/node/serialization.h
+ */
+#ifndef TVM_NODE_SERIALIZATION_H_
+#define TVM_NODE_SERIALIZATION_H_
+
+#include <tvm/runtime/c_runtime_api.h>
+#include <tvm/runtime/object.h>
+
+#include <string>
+
+namespace tvm {
+/*!
+ * \brief save the node as well as all the node it depends on as json.
+ *  This can be used to serialize any TVM object
+ *
+ * \return the string representation of the node.
+ */
+TVM_DLL std::string SaveJSON(const runtime::ObjectRef& node);
+
+/*!
+ * \brief Internal implementation of LoadJSON
+ * Load tvm Node object from json and return a shared_ptr of Node.
+ * \param json_str The json string to load from.
+ *
+ * \return The shared_ptr of the Node.
+ */
+TVM_DLL runtime::ObjectRef LoadJSON(std::string json_str);
+
+}  // namespace tvm
+#endif  // TVM_NODE_SERIALIZATION_H_
diff --git a/darknet_drp_ros/include/tvm/node/structural_equal.h b/darknet_drp_ros/include/tvm/node/structural_equal.h
new file mode 100644
index 0000000..371b8f9
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/node/structural_equal.h
@@ -0,0 +1,370 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+/*!
+ * \file tvm/node/structural_equal.h
+ * \brief Structural equality comparison.
+ */
+#ifndef TVM_NODE_STRUCTURAL_EQUAL_H_
+#define TVM_NODE_STRUCTURAL_EQUAL_H_
+
+#include <tvm/node/functor.h>
+#include <tvm/node/object_path.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/data_type.h>
+
+#include <string>
+
+namespace tvm {
+
+/*!
+ * \brief Equality definition of base value class.
+ */
+class BaseValueEqual {
+ public:
+  bool operator()(const double& lhs, const double& rhs) const {
+    // fuzzy float pt comparison
+    constexpr double atol = 1e-9;
+    if (lhs == rhs) return true;
+    double diff = lhs - rhs;
+    return diff > -atol && diff < atol;
+  }
+
+  bool operator()(const int64_t& lhs, const int64_t& rhs) const { return lhs == rhs; }
+  bool operator()(const uint64_t& lhs, const uint64_t& rhs) const { return lhs == rhs; }
+  bool operator()(const int& lhs, const int& rhs) const { return lhs == rhs; }
+  bool operator()(const bool& lhs, const bool& rhs) const { return lhs == rhs; }
+  bool operator()(const std::string& lhs, const std::string& rhs) const { return lhs == rhs; }
+  bool operator()(const DataType& lhs, const DataType& rhs) const { return lhs == rhs; }
+  template <typename ENum, typename = typename std::enable_if<std::is_enum<ENum>::value>::type>
+  bool operator()(const ENum& lhs, const ENum& rhs) const {
+    return lhs == rhs;
+  }
+};
+
+/*!
+ * \brief Pair of `ObjectPath`s, one for each object being tested for structural equality.
+ */
+class ObjectPathPairNode : public Object {
+ public:
+  ObjectPath lhs_path;
+  ObjectPath rhs_path;
+
+  ObjectPathPairNode(ObjectPath lhs_path, ObjectPath rhs_path);
+
+  static constexpr const char* _type_key = "ObjectPathPair";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ObjectPathPairNode, Object);
+};
+
+class ObjectPathPair : public ObjectRef {
+ public:
+  ObjectPathPair(ObjectPath lhs_path, ObjectPath rhs_path);
+
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(ObjectPathPair, ObjectRef, ObjectPathPairNode);
+};
+
+/*!
+ * \brief Content-aware structural equality comparator for objects.
+ *
+ *  The structural equality is recursively defined in the DAG of IR nodes via SEqual.
+ *  There are two kinds of nodes:
+ *
+ *  - Graph node: a graph node in lhs can only be mapped as equal to
+ *    one and only one graph node in rhs.
+ *  - Normal node: equality is recursively defined without the restriction
+ *    of graph nodes.
+ *
+ *  Vars(tir::Var, TypeVar) and non-constant relay expression nodes are graph nodes.
+ *  For example, it means that `%1 = %x + %y; %1 + %1` is not structurally equal
+ *  to `%1 = %x + %y; %2 = %x + %y; %1 + %2` in relay.
+ *
+ *  A var-type node(e.g. tir::Var, TypeVar) can be mapped as equal to another var
+ *  with the same type if one of the following condition holds:
+ *
+ *  - They appear in a same definition point(e.g. function argument).
+ *  - They points to the same VarNode via the same_as relation.
+ *  - They appear in a same usage point, and map_free_vars is set to be True.
+ */
+class StructuralEqual : public BaseValueEqual {
+ public:
+  // inheritate operator()
+  using BaseValueEqual::operator();
+  /*!
+   * \brief Compare objects via strutural equal.
+   * \param lhs The left operand.
+   * \param rhs The right operand.
+   * \return The comparison result.
+   */
+  TVM_DLL bool operator()(const ObjectRef& lhs, const ObjectRef& rhs) const;
+};
+
+/*!
+ * \brief A Reducer class to reduce the structural equality result of two objects.
+ *
+ * The reducer will call the SEqualReduce function of each objects recursively.
+ * Importantly, the reducer may not directly use recursive calls to resolve the
+ * equality checking. Instead, it can store the necessary equality conditions
+ * and check later via an internally managed stack.
+ */
+class SEqualReducer {
+ private:
+  struct PathTracingData;
+
+ public:
+  /*! \brief Internal handler that defines custom behaviors.. */
+  class Handler {
+   public:
+    /*!
+     * \brief Reduce condition to equality of lhs and rhs.
+     *
+     * \param lhs The left operand.
+     * \param rhs The right operand.
+     * \param map_free_vars Whether do we allow remap variables if possible.
+     * \param current_paths Optional paths to `lhs` and `rhs` objects, for error traceability.
+     *
+     * \return false if there is an immediate failure, true otherwise.
+     * \note This function may save the equality condition of (lhs == rhs) in an internal
+     *       stack and try to resolve later.
+     */
+    virtual bool SEqualReduce(const ObjectRef& lhs, const ObjectRef& rhs, bool map_free_vars,
+                              const Optional<ObjectPathPair>& current_paths) = 0;
+
+    /*!
+     * \brief Mark the comparison as failed, but don't fail immediately.
+     *
+     * This is useful for producing better error messages when comparing containers.
+     * For example, if two array sizes mismatch, it's better to mark the comparison as failed
+     * but compare array elements anyway, so that we could find the true first mismatch.
+     */
+    virtual void DeferFail(const ObjectPathPair& mismatch_paths) = 0;
+
+    /*!
+     * \brief Lookup the graph node equal map for vars that are already mapped.
+     *
+     *  This is an auxiliary method to check the Map<Var, Value> equality.
+     * \param lhs an lhs value.
+     *
+     * \return The corresponding rhs value if any, nullptr if not available.
+     */
+    virtual ObjectRef MapLhsToRhs(const ObjectRef& lhs) = 0;
+    /*!
+     * \brief Mark current comparison as graph node equal comparison.
+     */
+    virtual void MarkGraphNode() = 0;
+
+   protected:
+    using PathTracingData = SEqualReducer::PathTracingData;
+  };
+
+  /*! \brief default constructor */
+  SEqualReducer() = default;
+  /*!
+   * \brief Constructor with a specific handler.
+   * \param handler The equal handler for objects.
+   * \param tracing_data Optional pointer to the path tracing data.
+   * \param map_free_vars Whether or not to map free variables.
+   */
+  explicit SEqualReducer(Handler* handler, const PathTracingData* tracing_data, bool map_free_vars)
+      : handler_(handler), tracing_data_(tracing_data), map_free_vars_(map_free_vars) {}
+
+  /*!
+   * \brief Reduce condition to comparison of two attribute values.
+   * \param lhs The left operand.
+   * \param rhs The right operand.
+   * \return the immediate check result.
+   */
+  bool operator()(const double& lhs, const double& rhs) const;
+  bool operator()(const int64_t& lhs, const int64_t& rhs) const;
+  bool operator()(const uint64_t& lhs, const uint64_t& rhs) const;
+  bool operator()(const int& lhs, const int& rhs) const;
+  bool operator()(const bool& lhs, const bool& rhs) const;
+  bool operator()(const std::string& lhs, const std::string& rhs) const;
+  bool operator()(const DataType& lhs, const DataType& rhs) const;
+
+  template <typename ENum, typename = typename std::enable_if<std::is_enum<ENum>::value>::type>
+  bool operator()(const ENum& lhs, const ENum& rhs) const {
+    using Underlying = typename std::underlying_type<ENum>::type;
+    static_assert(std::is_same<Underlying, int>::value,
+                  "Enum must have `int` as the underlying type");
+    return EnumAttrsEqual(static_cast<int>(lhs), static_cast<int>(rhs), &lhs, &rhs);
+  }
+
+  /*!
+   * \brief Reduce condition to comparison of two objects.
+   * \param lhs The left operand.
+   * \param rhs The right operand.
+   * \return the immediate check result.
+   */
+  bool operator()(const ObjectRef& lhs, const ObjectRef& rhs) const;
+
+  /*!
+   * \brief Reduce condition to comparison of two objects.
+   *
+   * Like `operator()`, but with an additional `paths` parameter that specifies explicit object
+   * paths for `lhs` and `rhs`. This is useful for implementing SEqualReduce() methods for container
+   * objects like Array and Map, or other custom objects that store nested objects that are not
+   * simply attributes.
+   *
+   * Can only be called when `IsPathTracingEnabled()` is `true`.
+   *
+   * \param lhs The left operand.
+   * \param rhs The right operand.
+   * \param paths Object paths for `lhs` and `rhs`.
+   * \return the immediate check result.
+   */
+  bool operator()(const ObjectRef& lhs, const ObjectRef& rhs, const ObjectPathPair& paths) const {
+    ICHECK(IsPathTracingEnabled()) << "Path tracing must be enabled when calling this function";
+    return ObjectAttrsEqual(lhs, rhs, map_free_vars_, &paths);
+  }
+
+  /*!
+   * \brief Reduce condition to comparison of two definitions,
+   *        where free vars can be mapped.
+   *
+   *  Call this function to compare definition points such as function params
+   *  and var in a let-binding.
+   *
+   * \param lhs The left operand.
+   * \param rhs The right operand.
+   * \return the immediate check result.
+   */
+  bool DefEqual(const ObjectRef& lhs, const ObjectRef& rhs);
+
+  /*!
+   * \brief Reduce condition to comparison of two arrays.
+   * \param lhs The left operand.
+   * \param rhs The right operand.
+   * \return the immediate check result.
+   */
+  template <typename T>
+  bool operator()(const Array<T>& lhs, const Array<T>& rhs) const {
+    if (tracing_data_ == nullptr) {
+      // quick specialization for Array to reduce amount of recursion
+      // depth as array comparison is pretty common.
+      if (lhs.size() != rhs.size()) return false;
+      for (size_t i = 0; i < lhs.size(); ++i) {
+        if (!(operator()(lhs[i], rhs[i]))) return false;
+      }
+      return true;
+    }
+
+    // If tracing is enabled, fall back to the regular path
+    const ObjectRef& lhs_obj = lhs;
+    const ObjectRef& rhs_obj = rhs;
+    return (*this)(lhs_obj, rhs_obj);
+  }
+  /*!
+   * \brief Implementation for equality rule of var type objects(e.g. TypeVar, tir::Var).
+   * \param lhs The left operand.
+   * \param rhs The right operand.
+   * \return the result.
+   */
+  bool FreeVarEqualImpl(const runtime::Object* lhs, const runtime::Object* rhs) const {
+    // var need to be remapped, so it belongs to graph node.
+    handler_->MarkGraphNode();
+    // We only map free vars if they corresponds to the same address
+    // or map free_var option is set to be true.
+    return lhs == rhs || map_free_vars_;
+  }
+
+  /*! \return Get the internal handler. */
+  Handler* operator->() const { return handler_; }
+
+  /*! \brief Check if this reducer is tracing paths to the first mismatch. */
+  bool IsPathTracingEnabled() const { return tracing_data_ != nullptr; }
+
+  /*!
+   * \brief Get the paths of the currently compared objects.
+   *
+   * Can only be called when `IsPathTracingEnabled()` is true.
+   */
+  const ObjectPathPair& GetCurrentObjectPaths() const;
+
+  /*!
+   * \brief Specify the object paths of a detected mismatch.
+   *
+   * Can only be called when `IsPathTracingEnabled()` is true.
+   */
+  void RecordMismatchPaths(const ObjectPathPair& paths) const;
+
+ private:
+  bool EnumAttrsEqual(int lhs, int rhs, const void* lhs_address, const void* rhs_address) const;
+
+  bool ObjectAttrsEqual(const ObjectRef& lhs, const ObjectRef& rhs, bool map_free_vars,
+                        const ObjectPathPair* paths) const;
+
+  static void GetPathsFromAttrAddressesAndStoreMismatch(const void* lhs_address,
+                                                        const void* rhs_address,
+                                                        const PathTracingData* tracing_data);
+
+  template <typename T>
+  static bool CompareAttributeValues(const T& lhs, const T& rhs,
+                                     const PathTracingData* tracing_data);
+
+  /*! \brief Internal class pointer. */
+  Handler* handler_ = nullptr;
+  /*! \brief Pointer to the current path tracing context, or nullptr if path tracing is disabled. */
+  const PathTracingData* tracing_data_ = nullptr;
+  /*! \brief Whether or not to map free vars. */
+  bool map_free_vars_ = false;
+};
+
+/*! \brief The default handler for equality testing.
+ *
+ * Users can derive from this class and override the DispatchSEqualReduce method,
+ * to customize equality testing.
+ */
+class SEqualHandlerDefault : public SEqualReducer::Handler {
+ public:
+  SEqualHandlerDefault(bool assert_mode, Optional<ObjectPathPair>* first_mismatch);
+  virtual ~SEqualHandlerDefault();
+
+  bool SEqualReduce(const ObjectRef& lhs, const ObjectRef& rhs, bool map_free_vars,
+                    const Optional<ObjectPathPair>& current_paths) override;
+  void DeferFail(const ObjectPathPair& mismatch_paths) override;
+  ObjectRef MapLhsToRhs(const ObjectRef& lhs) override;
+  void MarkGraphNode() override;
+
+  /*!
+   * \brief The entry point for equality testing
+   * \param lhs The left operand.
+   * \param rhs The right operand.
+   * \param map_free_vars Whether or not to remap variables if possible.
+   * \return The equality result.
+   */
+  virtual bool Equal(const ObjectRef& lhs, const ObjectRef& rhs, bool map_free_vars);
+
+ protected:
+  /*!
+   * \brief The dispatcher for equality testing of intermediate objects
+   * \param lhs The left operand.
+   * \param rhs The right operand.
+   * \param map_free_vars Whether or not to remap variables if possible.
+   * \param current_paths Optional paths to `lhs` and `rhs` objects, for error traceability.
+   * \return The equality result.
+   */
+  virtual bool DispatchSEqualReduce(const ObjectRef& lhs, const ObjectRef& rhs, bool map_free_vars,
+                                    const Optional<ObjectPathPair>& current_paths);
+
+ private:
+  class Impl;
+  Impl* impl;
+};
+
+}  // namespace tvm
+#endif  // TVM_NODE_STRUCTURAL_EQUAL_H_
diff --git a/darknet_drp_ros/include/tvm/node/structural_hash.h b/darknet_drp_ros/include/tvm/node/structural_hash.h
new file mode 100644
index 0000000..8b8a403
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/node/structural_hash.h
@@ -0,0 +1,250 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+/*!
+ * \file tvm/node/structural_equal.h
+ * \brief Structural hash class.
+ */
+#ifndef TVM_NODE_STRUCTURAL_HASH_H_
+#define TVM_NODE_STRUCTURAL_HASH_H_
+
+#include <tvm/node/functor.h>
+#include <tvm/runtime/data_type.h>
+#include <tvm/runtime/ndarray.h>
+
+#include <functional>
+#include <string>
+
+namespace tvm {
+
+/*!
+ * \brief Hash definition of base value classes.
+ */
+class BaseValueHash {
+ public:
+  size_t operator()(const double& key) const { return std::hash<double>()(key); }
+
+  size_t operator()(const int64_t& key) const { return std::hash<int64_t>()(key); }
+
+  size_t operator()(const uint64_t& key) const { return std::hash<uint64_t>()(key); }
+
+  size_t operator()(const int& key) const { return std::hash<int>()(key); }
+
+  size_t operator()(const bool& key) const { return std::hash<bool>()(key); }
+
+  size_t operator()(const std::string& key) const { return std::hash<std::string>()(key); }
+
+  size_t operator()(const runtime::DataType& key) const {
+    return std::hash<int32_t>()(static_cast<int32_t>(key.code()) |
+                                (static_cast<int32_t>(key.bits()) << 8) |
+                                (static_cast<int32_t>(key.lanes()) << 16));
+  }
+
+  template <typename ENum, typename = typename std::enable_if<std::is_enum<ENum>::value>::type>
+  bool operator()(const ENum& key) const {
+    return std::hash<size_t>()(static_cast<size_t>(key));
+  }
+};
+
+/*!
+ * \brief Content-aware structural hasing.
+ *
+ *  The structural hash value is recursively defined in the DAG of IRNodes.
+ *  There are two kinds of nodes:
+ *
+ *  - Normal node: the hash value is defined by its content and type only.
+ *  - Graph node: each graph node will be assigned a unique index ordered by the
+ *    first occurence during the visit. The hash value of a graph node is
+ *    combined from the hash values of its contents and the index.
+ */
+class StructuralHash : public BaseValueHash {
+ public:
+  // inheritate operator()
+  using BaseValueHash::operator();
+  /*!
+   * \brief Compute structural hashing value for an object.
+   * \param key The left operand.
+   * \return The hash value.
+   */
+  TVM_DLL size_t operator()(const ObjectRef& key) const;
+};
+
+/*!
+ * \brief A Reducer class to reduce the structural hash value.
+ *
+ *  The reducer will call the SEqualHash function of each objects recursively.
+ *
+ *  A SEqualHash function will make a sequence of calls to the reducer to
+ *  indicate a sequence of child hash values that the reducer need to combine
+ *  inorder to obtain the hash value of the hash value of the parent object.
+ *
+ *  Importantly, the reducer may not directly use recursive calls
+ *  to compute the hash values of child objects directly.
+ *
+ *  Instead, it can store the necessary hash computing task into a stack
+ *  and reduce the result later.
+ */
+class SHashReducer {
+ public:
+  /*! \brief Internal handler that defines custom behaviors. */
+  class Handler {
+   public:
+    /*!
+     * \brief Append hashed_value to the current sequence of hashes.
+     *
+     * \param hashed_value The hashed value
+     */
+    virtual void SHashReduceHashedValue(size_t hashed_value) = 0;
+    /*!
+     * \brief Append hash value of key to the current sequence of hashes.
+     *
+     * \param key The object to compute hash from.
+     * \param map_free_vars Whether to map free variables by their occurence number.
+     */
+    virtual void SHashReduce(const ObjectRef& key, bool map_free_vars) = 0;
+    /*!
+     * \brief Apppend a hash value of free variable to the current sequence of hashes.
+     *
+     * \param var The var of interest.
+     * \param map_free_vars Whether to map free variables by their occurence number.
+     *
+     * \note If map_free_vars is set to be true,
+     *       internally the handler can maintain a counter to encode free variables
+     *       by their order of occurence. This helps to resolve variable
+     *       mapping of function parameters and let binding variables.
+     *
+     *       If map_free_vars is set to be false, the address of the variable will be used.
+     */
+    virtual void SHashReduceFreeVar(const runtime::Object* var, bool map_free_vars) = 0;
+    /*!
+     * \brief Lookup a hash value for key
+     *
+     * \param key The hash key.
+     * \param hashed_value the result hash value
+     *
+     * \return Whether there is already a pre-computed hash value.
+     */
+    virtual bool LookupHashedValue(const ObjectRef& key, size_t* hashed_value) = 0;
+    /*!
+     * \brief Mark current comparison as graph node in hashing.
+     *        Graph node hash will depends on the graph structure.
+     */
+    virtual void MarkGraphNode() = 0;
+  };
+
+  /*! \brief default constructor */
+  SHashReducer() = default;
+  /*!
+   * \brief Constructor with a specific handler.
+   * \param handler The equal handler for objects.
+   * \param map_free_vars Whether to map free variables.
+   */
+  explicit SHashReducer(Handler* handler, bool map_free_vars)
+      : handler_(handler), map_free_vars_(map_free_vars) {}
+  /*!
+   * \brief Push hash of key to the current sequence of hash values.
+   * \param key The key to be hashed.
+   */
+  template <typename T,
+            typename = typename std::enable_if<!std::is_base_of<ObjectRef, T>::value>::type>
+  void operator()(const T& key) const {
+    // handle normal values.
+    handler_->SHashReduceHashedValue(BaseValueHash()(key));
+  }
+  /*!
+   * \brief Push hash of key to the current sequence of hash values.
+   * \param key The key to be hashed.
+   */
+  void operator()(const ObjectRef& key) const { return handler_->SHashReduce(key, map_free_vars_); }
+  /*!
+   * \brief Push hash of key to the current sequence of hash values.
+   * \param key The key to be hashed.
+   * \note This function indicate key could contain var defintions.
+   */
+  void DefHash(const ObjectRef& key) const { return handler_->SHashReduce(key, true); }
+  /*!
+   * \brief Implementation for hash for a free var.
+   * \param var The variable.
+   * \return the result.
+   */
+  void FreeVarHashImpl(const runtime::Object* var) const {
+    handler_->SHashReduceFreeVar(var, map_free_vars_);
+  }
+
+  /*! \return Get the internal handler. */
+  Handler* operator->() const { return handler_; }
+
+ private:
+  /*! \brief Internal class pointer. */
+  Handler* handler_;
+  /*!
+   * \brief Whether or not to map free variables by their occurence
+   *        If the flag is false, then free variables will be mapped
+   *        by their in-memory address.
+   */
+  bool map_free_vars_;
+};
+
+/*! \brief The default handler for hash key computation
+ *
+ * Users can derive from this class and override the DispatchSHash method,
+ * to customize hashing.
+ */
+class SHashHandlerDefault : public SHashReducer::Handler {
+ public:
+  SHashHandlerDefault();
+  virtual ~SHashHandlerDefault();
+
+  void SHashReduceHashedValue(size_t hashed_value) override;
+  void SHashReduce(const ObjectRef& key, bool map_free_vars) override;
+  void SHashReduceFreeVar(const runtime::Object* var, bool map_free_vars) override;
+  bool LookupHashedValue(const ObjectRef& key, size_t* hashed_value) override;
+  void MarkGraphNode() override;
+
+  /*!
+   * \brief The entry point for hashing
+   * \param object The object to be hashed.
+   * \param map_free_vars Whether or not to remap variables if possible.
+   * \return The hash result.
+   */
+  virtual size_t Hash(const ObjectRef& object, bool map_free_vars);
+
+ protected:
+  /*!
+   * \brief The dispatcher for hashing of intermediate objects
+   * \param object An intermediate object to be hashed.
+   * \param map_free_vars Whether or not to remap variables if possible.
+   * \return The hash result.
+   */
+  virtual void DispatchSHash(const ObjectRef& object, bool map_free_vars);
+
+ private:
+  class Impl;
+  Impl* impl;
+};
+
+class SEqualReducer;
+struct NDArrayContainerTrait {
+  static constexpr const std::nullptr_t VisitAttrs = nullptr;
+  static void SHashReduce(const runtime::NDArray::Container* key, SHashReducer hash_reduce);
+  static bool SEqualReduce(const runtime::NDArray::Container* lhs,
+                           const runtime::NDArray::Container* rhs, SEqualReducer equal);
+};
+
+}  // namespace tvm
+#endif  // TVM_NODE_STRUCTURAL_HASH_H_
diff --git a/darknet_drp_ros/include/tvm/parser/parser.h b/darknet_drp_ros/include/tvm/parser/parser.h
new file mode 100644
index 0000000..0a73e1a
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/parser/parser.h
@@ -0,0 +1,53 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+#ifndef TVM_PARSER_PARSER_H_
+#define TVM_PARSER_PARSER_H_
+/*!
+ * \file include/tvm/parser/parser.h
+ * \brief A parser for TVM IR.
+ */
+#include <tvm/ir/module.h>
+#include <tvm/ir/transform.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/runtime/registry.h>
+
+#include <fstream>
+#include <string>
+
+namespace tvm {
+namespace parser {
+
+using MetaTable = Map<String, Array<ObjectRef>>;
+
+IRModule ParseModule(const std::string& file_name, const std::string& file_content,
+                     const Optional<IRModule>& init_module = Optional<IRModule>(),
+                     const MetaTable& init_meta_table = MetaTable());
+
+/*!
+ * \brief This pass pretty-prints mod then parses it back so as to establish spans and sources
+ * for all Relay sub-expressions. This improves error and debugging diagnostics downstream for
+ * modules constructed programaticaly rather than textually.
+ */
+transform::Pass AnnotateSpans();
+
+}  // namespace parser
+}  // namespace tvm
+
+#endif  // TVM_PARSER_PARSER_H_
diff --git a/darknet_drp_ros/include/tvm/parser/source_map.h b/darknet_drp_ros/include/tvm/parser/source_map.h
new file mode 100644
index 0000000..a160c22
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/parser/source_map.h
@@ -0,0 +1,119 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+/*!
+ * \file source_map.h
+ * \brief A map from source names to source code.
+ */
+#ifndef TVM_PARSER_SOURCE_MAP_H_
+#define TVM_PARSER_SOURCE_MAP_H_
+
+#include <tvm/ir/span.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/runtime/registry.h>
+
+#include <fstream>
+#include <string>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+namespace parser {
+
+/*! \brief A program source in any language.
+ *
+ * Could represent the source from an ML framework or a source
+ * representing a tvm::IRModule.
+ */
+class Source;
+
+class SourceNode : public Object {
+ public:
+  /*! \brief The source name. */
+  SourceName source_name;
+
+  /*! \brief The raw source. */
+  String source;
+
+  /*! \brief A mapping of line breaks into the raw source. */
+  std::vector<std::pair<int, int>> line_map;
+
+  // override attr visitor
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("source_name", &source_name);
+    v->Visit("source", &source);
+  }
+
+  static constexpr const char* _type_key = "Source";
+  TVM_DECLARE_FINAL_OBJECT_INFO(SourceNode, Object);
+};
+
+class Source : public ObjectRef {
+ public:
+  TVM_DLL Source(SourceName src_name, std::string source);
+  TVM_DLL tvm::String GetLine(int line);
+
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(Source, ObjectRef, SourceNode);
+};
+
+/*!
+ * \brief A mapping from a unique source name to source fragment.
+ */
+class SourceMap;
+/*!
+ * \brief Stores locations in frontend source that generated a node.
+ */
+class SourceMapNode : public Object {
+ public:
+  /*! \brief The source mapping. */
+  Map<SourceName, Source> source_map;
+
+  // override attr visitor
+  void VisitAttrs(AttrVisitor* v) { v->Visit("source_map", &source_map); }
+
+  bool SEqualReduce(const SourceMapNode* other, SEqualReducer equal) const {
+    return equal(source_map, other->source_map);
+  }
+
+  static constexpr const char* _type_key = "SourceMap";
+  TVM_DECLARE_FINAL_OBJECT_INFO(SourceMapNode, Object);
+};
+
+class SourceMap : public ObjectRef {
+ public:
+  TVM_DLL SourceMap(Map<SourceName, Source> source_map);
+
+  TVM_DLL SourceMap(std::initializer_list<std::pair<SourceName, Source>> source_map)
+      : SourceMap(Map<SourceName, Source>(source_map)) {}
+
+  TVM_DLL SourceMap() : SourceMap(Map<SourceName, Source>()) {}
+
+  void Add(const Source& source);
+
+  SourceMapNode* operator->() {
+    ICHECK(get() != nullptr);
+    return static_cast<SourceMapNode*>(get_mutable());
+  }
+
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(SourceMap, ObjectRef, SourceMapNode);
+};
+
+}  // namespace parser
+}  // namespace tvm
+
+#endif  // TVM_PARSER_SOURCE_MAP_H_
diff --git a/darknet_drp_ros/include/tvm/relay/adt.h b/darknet_drp_ros/include/tvm/relay/adt.h
new file mode 100644
index 0000000..cdb8e52
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/adt.h
@@ -0,0 +1,344 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/adt.h
+ * \brief Algebraic data types for Relay
+ */
+#ifndef TVM_RELAY_ADT_H_
+#define TVM_RELAY_ADT_H_
+
+#include <tvm/ir/adt.h>
+#include <tvm/ir/attrs.h>
+#include <tvm/relay/base.h>
+#include <tvm/relay/expr.h>
+#include <tvm/relay/type.h>
+
+#include <functional>
+#include <string>
+#include <utility>
+
+namespace tvm {
+namespace relay {
+
+using Constructor = tvm::Constructor;
+using ConstructorNode = tvm::ConstructorNode;
+
+using TypeData = tvm::TypeData;
+using TypeDataNode = tvm::TypeDataNode;
+
+/*! \brief Base type for declaring relay pattern. */
+class PatternNode : public RelayNode {
+ public:
+  static constexpr const char* _type_key = "relay.Pattern";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_BASE_OBJECT_INFO(PatternNode, Object);
+};
+
+/*!
+ * \brief Pattern is the base type for an ADT match pattern in Relay.
+ *
+ * Given an ADT value, a pattern might accept it and bind the pattern variable to some value
+ * (typically a subnode of the input or the input). Otherwise, the pattern rejects the value.
+ *
+ * ADT pattern matching thus takes a list of values and binds to the first that accepts the value.
+ */
+class Pattern : public ObjectRef {
+ public:
+  Pattern() {}
+  explicit Pattern(ObjectPtr<tvm::Object> p) : ObjectRef(p) {}
+
+  using ContainerType = PatternNode;
+};
+
+/*! \brief A wildcard pattern: Accepts all input and binds nothing. */
+class PatternWildcard;
+/*! \brief PatternWildcard container node */
+class PatternWildcardNode : public PatternNode {
+ public:
+  void VisitAttrs(tvm::AttrVisitor* v) { v->Visit("span", &span); }
+
+  bool SEqualReduce(const PatternNode* other, SEqualReducer equal) const { return true; }
+
+  void SHashReduce(SHashReducer hash_reduce) const {}
+
+  static constexpr const char* _type_key = "relay.PatternWildcard";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PatternWildcardNode, PatternNode);
+};
+
+class PatternWildcard : public Pattern {
+ public:
+  /* \brief Overload the default constructors. */
+  TVM_DLL PatternWildcard();
+  explicit PatternWildcard(ObjectPtr<Object> n) : Pattern(n) {}
+  /* \brief Copy constructor. */
+  PatternWildcard(const PatternWildcard& pat) : PatternWildcard(pat.data_) {}
+  /* \brief Move constructor. */
+  PatternWildcard(PatternWildcard&& pat) : PatternWildcard(std::move(pat.data_)) {}
+  /* \brief Copy assignment. */
+  PatternWildcard& operator=(const PatternWildcard& other) {
+    (*this).data_ = other.data_;
+    return *this;
+  }
+  /* \brief Move assignment. */
+  PatternWildcard& operator=(PatternWildcard&& other) {
+    (*this).data_ = std::move(other.data_);
+    return *this;
+  }
+
+  const PatternWildcardNode* operator->() const {
+    return static_cast<const PatternWildcardNode*>(get());
+  }
+
+  using ContainerType = PatternWildcardNode;
+};
+
+/*! \brief A var pattern. Accept all input and bind to a var. */
+class PatternVar;
+/*! \brief PatternVar container node */
+class PatternVarNode : public PatternNode {
+ public:
+  /*! \brief Variable that stores the matched value. */
+  tvm::relay::Var var;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("var", &var);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const PatternVarNode* other, SEqualReducer equal) const {
+    return equal.DefEqual(var, other->var);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const { hash_reduce.DefHash(var); }
+
+  static constexpr const char* _type_key = "relay.PatternVar";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PatternVarNode, PatternNode);
+};
+
+class PatternVar : public Pattern {
+ public:
+  /*!
+   * \brief Constructor
+   * \param var The var to construct a pattern
+   */
+  TVM_DLL explicit PatternVar(tvm::relay::Var var);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(PatternVar, Pattern, PatternVarNode);
+};
+
+/*! \brief A constructor pattern. Matches a value with the given constructor, binds recursively. */
+class PatternConstructor;
+/*! \brief PatternVar container node */
+class PatternConstructorNode : public PatternNode {
+ public:
+  /*! Constructor matched by the pattern. */
+  Constructor constructor;
+  /*! Sub-patterns to match against each input to the constructor. */
+  tvm::Array<Pattern> patterns;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("constructor", &constructor);
+    v->Visit("patterns", &patterns);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const PatternConstructorNode* other, SEqualReducer equal) const {
+    return equal(constructor, other->constructor) && equal(patterns, other->patterns);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(constructor);
+    hash_reduce(patterns);
+  }
+
+  static constexpr const char* _type_key = "relay.PatternConstructor";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PatternConstructorNode, PatternNode);
+};
+
+class PatternConstructor : public Pattern {
+ public:
+  /*!
+   * \brief Constructor
+   * \param constructor The constructor of a pattern
+   * \param patterns The sub-patterns for matching
+   */
+  TVM_DLL PatternConstructor(Constructor constructor, tvm::Array<Pattern> patterns);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(PatternConstructor, Pattern, PatternConstructorNode);
+};
+
+/*! \brief A tuple pattern. Matches a tuple, binds recursively. */
+class PatternTuple;
+/*! \brief PatternVar container node */
+class PatternTupleNode : public PatternNode {
+ public:
+  /* TODO(@jroesch): rename to field_pats */
+  /*! Sub-patterns to match against each value of the tuple. */
+  tvm::Array<Pattern> patterns;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("patterns", &patterns);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const PatternTupleNode* other, SEqualReducer equal) const {
+    return equal(patterns, other->patterns);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const { hash_reduce(patterns); }
+
+  static constexpr const char* _type_key = "relay.PatternTuple";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PatternTupleNode, PatternNode);
+};
+
+class PatternTuple : public Pattern {
+ public:
+  /*!
+   * \brief Constructor
+   * \param patterns The sub-patterns to match against each value of the tuple
+   */
+  TVM_DLL explicit PatternTuple(tvm::Array<Pattern> patterns);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(PatternTuple, Pattern, PatternTupleNode);
+};
+
+/*! \brief A clause in a match expression. */
+class Clause;
+/*! \brief Clause container node. */
+class ClauseNode : public Object {
+ public:
+  /*! \brief The pattern the clause matches. */
+  Pattern lhs;
+  /*! \brief The resulting value. */
+  Expr rhs;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("lhs", &lhs);
+    v->Visit("rhs", &rhs);
+  }
+
+  bool SEqualReduce(const ClauseNode* other, SEqualReducer equal) const {
+    return equal(lhs, other->lhs) && equal(rhs, other->rhs);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(lhs);
+    hash_reduce(rhs);
+  }
+
+  static constexpr const char* _type_key = "relay.Clause";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_FINAL_OBJECT_INFO(ClauseNode, Object);
+};
+
+class Clause : public ObjectRef {
+ public:
+  /*!
+   * \brief Constructor
+   * \param lhs The pattern matched by the clause.
+   * \param rhs The resulting value
+   */
+  TVM_DLL explicit Clause(Pattern lhs, Expr rhs);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Clause, ObjectRef, ClauseNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(ClauseNode);
+};
+
+/*!
+ * \brief Returns \p clause with the given properties. A null property denotes 'no change'.
+ * Returns \p clause if all properties are unchanged. Otherwise, returns a copy with the new
+ * fields.
+ */
+Clause WithFields(Clause clause, Optional<Pattern> opt_lhs = Optional<Pattern>(),
+                  Optional<Expr> opt_rhs = Optional<Expr>());
+
+/*! \brief ADT pattern matching exression. */
+class Match;
+/*! \brief Match container node. */
+class MatchNode : public ExprNode {
+ public:
+  /*! \brief The input being deconstructed. */
+  Expr data;
+
+  /*! \brief The match node clauses. */
+  tvm::Array<Clause> clauses;
+
+  /*! \brief Should this match be complete (cover all cases)?
+   *  If yes, the type checker will generate an error if there are any missing cases.
+   */
+  bool complete;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("data", &data);
+    v->Visit("clauses", &clauses);
+    v->Visit("complete", &complete);
+    v->Visit("virtual_device_", &virtual_device_);
+    v->Visit("span", &span);
+    v->Visit("_checked_type_", &checked_type_);
+  }
+
+  bool SEqualReduce(const MatchNode* other, SEqualReducer equal) const {
+    equal->MarkGraphNode();
+    return equal(data, other->data) && equal(clauses, other->clauses) &&
+           equal(complete, other->complete);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce->MarkGraphNode();
+    hash_reduce(data);
+    hash_reduce(clauses);
+    hash_reduce(complete);
+  }
+
+  static constexpr const char* _type_key = "relay.Match";
+  TVM_DECLARE_FINAL_OBJECT_INFO(MatchNode, ExprNode);
+};
+
+class Match : public Expr {
+ public:
+  /*!
+   * \brief Constructor
+   * \param data the input being deconstructed.
+   * \param clauses The clauses for matching.
+   * \param complete Indicate if this match is complete.
+   * \param span The span of the expression.
+   */
+  TVM_DLL Match(Expr data, tvm::Array<Clause> clauses, bool complete = true, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Match, RelayExpr, MatchNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(MatchNode);
+};
+
+/*!
+ * \brief Returns \p match with the given properties. A null property denotes 'no change'.
+ * Returns \p match if all properties are unchanged. Otherwise, returns a copy with the new
+ * fields.
+ */
+Match WithFields(Match match, Optional<Expr> opt_data = Optional<Expr>(),
+                 Optional<Array<Clause>> opt_clauses = Optional<Array<Clause>>(),
+                 Optional<Bool> opt_complete = Optional<Bool>(),
+                 Optional<Span> opt_span = Optional<Span>());
+
+}  // namespace relay
+}  // namespace tvm
+
+#endif  // TVM_RELAY_ADT_H_
diff --git a/darknet_drp_ros/include/tvm/relay/analysis.h b/darknet_drp_ros/include/tvm/relay/analysis.h
new file mode 100644
index 0000000..0f85587
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/analysis.h
@@ -0,0 +1,256 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/analysis.h
+ * \brief The set of Relay analysis passes written in C++.
+ */
+#ifndef TVM_RELAY_ANALYSIS_H_
+#define TVM_RELAY_ANALYSIS_H_
+
+#include <tvm/ir/module.h>
+#include <tvm/relay/adt.h>
+#include <tvm/relay/expr.h>
+#include <tvm/relay/function.h>
+#include <tvm/relay/type.h>
+#include <tvm/runtime/logging.h>
+
+#include <string>
+#include <unordered_map>
+
+namespace tvm {
+namespace relay {
+
+/*!
+ * \brief Check that types are well kinded by applying "kinding rules".
+ *
+ * This pass ensures we do not do things that violate the design of the
+ * type system when writing down types.
+ *
+ * For example tensors are not allowed to contain functions in Relay.
+ *
+ * We check this by ensuring the `dtype` field of a Tensor always contains
+ * a data type such as `int`, `float`, `uint`.
+ *
+ * \param t The type to check.
+ * \param mod The global module.
+ * \param diag_ctx The Diagnostic context.
+ *
+ * \return The kind of the passed type.
+ */
+TVM_DLL Kind KindCheck(const Type& t, const IRModule& mod,
+                       Optional<DiagnosticContext> diag_ctx = Optional<DiagnosticContext>());
+
+/*!
+ * \brief Check whether an expression is constant.
+ *
+ * If the inputs of an expression are all constant, it means the expression
+ * itself is constant also.
+ *
+ * \param e the expression.
+ *
+ * \return whether the expression is constant.
+ */
+TVM_DLL bool ConstantCheck(const Expr& e);
+
+/*!
+ * \brief Check whether an expression is in the basic block normal form.
+ *
+ * \param e the expression.
+ *
+ * \return whether the expression is in the basic block normal form.
+ */
+TVM_DLL bool BasicBlockNormalFormCheck(const Expr& e);
+
+/*!
+ * \brief Check that each Var is only bound once.
+ *
+ * For example, the expression `let x = 1 in let x = 2 in 3` bound x twice.
+ *
+ * `let f = (x -> x) in let g = (x -> x + 1) in f(g(2))` also bound x twice,
+ * although x is not shadowed.
+ *
+ * \param expr the expression to check.
+ * \param diag_ctx the diagnostic context
+ *
+ * \return true iff all Var in expr is bound at most once.
+ */
+TVM_DLL bool WellFormed(const Expr& expr,
+                        Optional<DiagnosticContext> diag_ctx = Optional<DiagnosticContext>());
+
+/*!
+ * \brief Get all bound variables from expression expr.
+ *
+ * Bound variables are all variables that are declared in the expr.
+ * They only have meaning inside that expr, and can only be used in it.
+ *
+ * \param expr the expression.
+ *
+ * \return List of bound vars, in the PostDFS order in the expression.
+ */
+TVM_DLL tvm::Array<Var> BoundVars(const Expr& expr);
+
+/*!
+ * \brief Get all bound variables from pattern pat.
+ *
+ * Bound variables are all variables that got bound by the pat.
+ * They only have meaning inside that expr, and can only be used in it.
+ *
+ * \param pat the Pattern.
+ *
+ * \return List of bound vars, in the PostDFS order in the expression.
+ */
+TVM_DLL tvm::Array<Var> BoundVars(const Pattern& pat);
+
+/*!
+ * \brief Get free type parameters from expression expr.
+ *
+ * Free variables are variables that are not bound by a
+ * let or a function parameter in the context.
+ *
+ * \param expr the expression.
+ *
+ * \return List of free vars, in the PostDFS order in the expression.
+ */
+TVM_DLL tvm::Array<Var> FreeVars(const Expr& expr);
+
+/*!
+ * \brief Get all variables from expression expr.
+ *
+ * \param expr the expression.
+ *
+ * \return List of all vars, in the PostDFS order in the expression.
+ */
+TVM_DLL tvm::Array<Var> AllVars(const Expr& expr);
+
+/*!
+ * \brief Get free TypeVars from expression expr.
+ *
+ * Free type parameters are type parameters that are not bound by a function
+ * type in the context.
+ *
+ * \param expr the expression.
+ * \param mod the module.
+ *
+ * \return List of free vars, in the PostDFS order visited by expr.
+ */
+TVM_DLL tvm::Array<TypeVar> FreeTypeVars(const Expr& expr, const IRModule& mod);
+
+/*!
+ * \brief Get free TypeVars from type t.
+ *
+ * Free type parameters are type parameters that are not bound by a function
+ * type in the context.
+ *
+ * \param t the type.
+ * \param mod the module.
+ *
+ * \return List of free type vars, in the PostDFS order visited by type.
+ */
+TVM_DLL tvm::Array<TypeVar> FreeTypeVars(const Type& t, const IRModule& mod);
+
+/*!
+ * \brief Get all bound type variables from expression expr.
+ *
+ * Bound variables are all type variables that are declared in the expr.
+ * They only have meaning inside that expr, and can only be used in it.
+ *
+ * \param expr the expression.
+ * \param mod the module.
+ *
+ * \return List of bound type vars, in the PostDFS order in the expression.
+ */
+TVM_DLL tvm::Array<TypeVar> BoundTypeVars(const Expr& expr, const IRModule& mod);
+
+/*!
+ * \brief Get all bound type variables from type t.
+ *
+ * Bound variables are all type variables that are declared in the type.
+ * They only have meaning inside that type, and can only be used in it.
+ *
+ * \param t the type
+ * \param mod the module.
+ *
+ * \return List of bound type vars, in the PostDFS order visited by type.
+ */
+TVM_DLL tvm::Array<TypeVar> BoundTypeVars(const Type& t, const IRModule& mod);
+
+/*!
+ * \brief Get all type variables in expression expr.
+ *
+ * \param expr the expression.
+ * \param mod the module.
+ *
+ * \return List of type vars, in the PostDFS order in the expression.
+ */
+TVM_DLL tvm::Array<TypeVar> AllTypeVars(const Expr& expr, const IRModule& mod);
+
+/*!
+ * \brief Get all type variables in type t.
+ *
+ * \param t the type.
+ * \param mod the module.
+ *
+ * \return List of type vars, in the PostDFS order visited by type.
+ */
+TVM_DLL tvm::Array<TypeVar> AllTypeVars(const Type& t, const IRModule& mod);
+
+/*!
+ * \brief Finds cases that the given match expression does not catch, if any.
+ *
+ * \param match the match expression to test
+ *
+ * \param mod The module used for accessing global type var definitions, can be None.
+ *
+ * \return Returns a list of cases (as patterns) that are not handled by the match
+ * expression.
+ */
+TVM_DLL Array<Pattern> UnmatchedCases(const Match& match, const IRModule& mod);
+
+/*!
+ * \brief Get reference counter of each internal ExprNode in body.
+ *
+ * \param body The body expression.
+ *
+ * \return The reference count mapping.
+ */
+TVM_DLL std::unordered_map<const Object*, size_t> GetExprRefCount(const Expr& body);
+
+/*!
+ * \brief Get the updated module for collecting calibration data.
+ *
+ * \param mod The module to be updated.
+ *
+ * \return The updated module.
+ */
+TVM_DLL IRModule GetCalibrateModule(IRModule mod);
+
+/*!
+ * \brief Get the output map between subgrpahs and its inputs/output.
+ *
+ * \param mod The module for running calibration.
+ *
+ * \return The mapping between a subgraph name and its postition in the output tuple.
+ */
+TVM_DLL Map<GlobalVar, Array<Integer>> GetCalibrateOutputMap(const IRModule& mod);
+
+}  // namespace relay
+}  // namespace tvm
+
+#endif  // TVM_RELAY_ANALYSIS_H_
diff --git a/darknet_drp_ros/include/tvm/relay/attrs/algorithm.h b/darknet_drp_ros/include/tvm/relay/attrs/algorithm.h
new file mode 100644
index 0000000..3652a09
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/attrs/algorithm.h
@@ -0,0 +1,97 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/attrs/vision.h
+ * \brief Auxiliary attributes for vision operators.
+ */
+#ifndef TVM_RELAY_ATTRS_ALGORITHM_H_
+#define TVM_RELAY_ATTRS_ALGORITHM_H_
+
+#include <tvm/ir/attrs.h>
+#include <tvm/relay/base.h>
+#include <tvm/relay/expr.h>
+
+#include <string>
+
+namespace tvm {
+namespace relay {
+
+/*! \brief Attributes used in argsort operators */
+struct ArgsortAttrs : public tvm::AttrsNode<ArgsortAttrs> {
+  int axis;
+  bool is_ascend;
+  DataType dtype;
+
+  TVM_DECLARE_ATTRS(ArgsortAttrs, "relay.attrs.ArgsortAttrs") {
+    TVM_ATTR_FIELD(axis).set_default(-1).describe(
+        "Axis along which to sort the input tensor."
+        "If not given, the flattened array is used.");
+    TVM_ATTR_FIELD(is_ascend).set_default(true).describe(
+        "Whether to sort in ascending or descending order."
+        "By default, sort in ascending order");
+    TVM_ATTR_FIELD(dtype)
+        .set_default(NullValue<DataType>())
+        .describe("DType of the output indices.");
+  }
+};
+
+struct TopKAttrs : public tvm::AttrsNode<TopKAttrs> {
+  Optional<Integer> k;
+  int axis;
+  bool is_ascend;
+  std::string ret_type;
+  DataType dtype;
+
+  TVM_DECLARE_ATTRS(TopKAttrs, "relay.attrs.TopkAttrs") {
+    TVM_ATTR_FIELD(k).describe("Number of top elements to select");
+    TVM_ATTR_FIELD(axis).set_default(-1).describe("Axis along which to sort the input tensor.");
+    TVM_ATTR_FIELD(ret_type).set_default("both").describe(
+        "The return type [both, values, indices]."
+        "both - return both top k data and indices."
+        "values - return top k data only."
+        "indices - return top k indices only.");
+    TVM_ATTR_FIELD(is_ascend).set_default(false).describe(
+        "Whether to sort in ascending or descending order."
+        "By default, sort in descending order");
+    TVM_ATTR_FIELD(dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Data type of the output indices.");
+  }
+};
+
+struct SearchSortedAttrs : public tvm::AttrsNode<SearchSortedAttrs> {
+  bool right;
+  DataType dtype;
+
+  TVM_DECLARE_ATTRS(SearchSortedAttrs, "relay.attrs.SearchSortedAttrs") {
+    TVM_ATTR_FIELD(right).set_default(false).describe(
+        "Controls which index is returned if a value lands exactly on one of sorted values. If "
+        " false, the index of the first suitable location found is given. If true, return the "
+        "last such index. If there is no suitable index, return either 0 or N (where N is the "
+        "size of the innermost dimension).");
+    TVM_ATTR_FIELD(dtype)
+        .set_default(DataType::Int(32))
+        .describe("Data type of the output indices.");
+  }
+};
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_ATTRS_ALGORITHM_H_
diff --git a/darknet_drp_ros/include/tvm/relay/attrs/annotation.h b/darknet_drp_ros/include/tvm/relay/attrs/annotation.h
new file mode 100644
index 0000000..1066416
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/attrs/annotation.h
@@ -0,0 +1,59 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/attrs/annotation.h
+ * \brief Attribute for annotation operators.
+ */
+#ifndef TVM_RELAY_ATTRS_ANNOTATION_H_
+#define TVM_RELAY_ATTRS_ANNOTATION_H_
+
+#include <tvm/ir/attrs.h>
+
+#include <string>
+
+namespace tvm {
+namespace relay {
+
+/*!
+ * \brief Annotate an expression to be cast into specific data type.
+ */
+struct CastHintAttrs : public tvm::AttrsNode<CastHintAttrs> {
+  DataType dtype;
+
+  TVM_DECLARE_ATTRS(CastHintAttrs, "relay.attrs.CastHintAttrs") {
+    TVM_ATTR_FIELD(dtype).describe("The data type denoted to be cast.");
+  }
+};
+
+/*!
+ * \brief Options for the operators used to annotate a compiler.
+ */
+struct CompilerAttrs : public tvm::AttrsNode<CompilerAttrs> {
+  /*! \brief A 3rd party compiler for code generation. */
+  std::string compiler;
+
+  TVM_DECLARE_ATTRS(CompilerAttrs, "relay.attrs.CompilerAttrs") {
+    TVM_ATTR_FIELD(compiler).describe("A 3rd party compiler used for code generation.");
+  }
+};
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_ATTRS_ANNOTATION_H_
diff --git a/darknet_drp_ros/include/tvm/relay/attrs/bitserial.h b/darknet_drp_ros/include/tvm/relay/attrs/bitserial.h
new file mode 100644
index 0000000..ed04c59
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/attrs/bitserial.h
@@ -0,0 +1,133 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/attrs/bitserial.h
+ * \brief Auxiliary attributes for bitserial operators.
+ */
+
+#ifndef TVM_RELAY_ATTRS_BITSERIAL_H_
+#define TVM_RELAY_ATTRS_BITSERIAL_H_
+
+#include <tvm/ir/attrs.h>
+#include <tvm/relay/base.h>
+
+#include <string>
+
+namespace tvm {
+namespace relay {
+
+/*! \brief Attributes used in bitpack operators */
+struct BitPackAttrs : public tvm::AttrsNode<BitPackAttrs> {
+  int bits;
+  int pack_axis;
+  int bit_axis;
+  DataType pack_type;
+  std::string name;
+
+  TVM_DECLARE_ATTRS(BitPackAttrs, "relay.attrs.BitPackAttrs") {
+    TVM_ATTR_FIELD(bits).set_default(1).describe("Number of bits to quantize with.");
+    TVM_ATTR_FIELD(pack_axis).set_default(1).describe(
+        "Axis that should be compressed, typically channels.");
+    TVM_ATTR_FIELD(bit_axis).set_default(-1).describe("New axis for packed bits.");
+    TVM_ATTR_FIELD(pack_type)
+        .set_default(NullValue<DataType>())
+        .describe("Type of int to pack bits into.");
+    TVM_ATTR_FIELD(name).set_default("BitPack").describe("Name of operation.");
+  }
+};
+
+/*! \brief Attribues used in bitserial convolution operators */
+struct BinaryConv2DAttrs : public tvm::AttrsNode<BinaryConv2DAttrs> {
+  Array<IndexExpr> strides;
+  Array<IndexExpr> padding;
+  IndexExpr channels;
+  Array<IndexExpr> kernel_size;
+  int activation_bits;
+  int weight_bits;
+  std::string data_layout;
+  std::string kernel_layout;
+  DataType pack_dtype;
+  DataType out_dtype;
+  bool unipolar;
+
+  TVM_DECLARE_ATTRS(BinaryConv2DAttrs, "relay.attrs.BinaryConv2DAttrs") {
+    TVM_ATTR_FIELD(strides)
+        .set_default(Array<IndexExpr>({1, 1}))
+        .describe("Specifies the strides of the convolution.");
+    TVM_ATTR_FIELD(padding)
+        .set_default(Array<IndexExpr>({0, 0}))
+        .describe(
+            "If padding is non-zero the input is implicitly zero-padded"
+            "on both sides for padding number of points.");
+    TVM_ATTR_FIELD(kernel_size)
+        .set_default(Array<IndexExpr>({3, 3}))
+        .describe("Specifies the dimensions of the convolution window.");
+    TVM_ATTR_FIELD(channels)
+        .set_default(NullValue<IndexExpr>())
+        .describe("Number of output channels, needed for shape inference.");
+    TVM_ATTR_FIELD(activation_bits)
+        .set_default(1)
+        .describe("Number of bits activation should be packed with.");
+    TVM_ATTR_FIELD(weight_bits)
+        .set_default(1)
+        .describe("Number of bits kernel should be packed with.");
+    TVM_ATTR_FIELD(data_layout)
+        .set_default("NCHW")
+        .describe("Dimension ordering of input data, can be 'NCHW' or NHWC'.");
+    TVM_ATTR_FIELD(kernel_layout)
+        .set_default("OIHW")
+        .describe("Dimension ordering of kernel data, can be 'OIHW' or HWIO'.");
+    TVM_ATTR_FIELD(pack_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Datatype to pack bits into.");
+    TVM_ATTR_FIELD(out_dtype).set_default(NullValue<DataType>()).describe("Output datatype.");
+    TVM_ATTR_FIELD(unipolar).set_default(true).describe(
+        "Whether to use unipolar or bipolar quantization.");
+  }
+};
+
+/*~ \brief Attributes for bitserial dense operator */
+struct BinaryDenseAttrs : public tvm::AttrsNode<BinaryDenseAttrs> {
+  IndexExpr units;
+  int data_bits;
+  int weight_bits;
+  DataType pack_dtype;
+  DataType out_dtype;
+  bool unipolar;
+
+  TVM_DECLARE_ATTRS(BinaryDenseAttrs, "relay.attrs.BinaryDenseAttrs") {
+    TVM_ATTR_FIELD(units).describe("Number of hidden units of the dense transformation.");
+    TVM_ATTR_FIELD(data_bits).set_default(1).describe(
+        "Number of bits to pack for incoming tensor.");
+    TVM_ATTR_FIELD(weight_bits)
+        .set_default(1)
+        .describe("Number of bits to pack for weight tensor.");
+    TVM_ATTR_FIELD(pack_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Datatype to pack bits into before computation.");
+    TVM_ATTR_FIELD(out_dtype).set_default(NullValue<DataType>()).describe("Output data type.");
+    TVM_ATTR_FIELD(unipolar).set_default(true).describe(
+        "Whether to use unipolar or bipolar quantization for inputs.");
+  }
+};
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_ATTRS_BITSERIAL_H_
diff --git a/darknet_drp_ros/include/tvm/relay/attrs/call.h b/darknet_drp_ros/include/tvm/relay/attrs/call.h
new file mode 100644
index 0000000..e0b347d
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/attrs/call.h
@@ -0,0 +1,50 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/attrs/call.h
+ * \brief Attribute for call_lowered operator.
+ */
+#ifndef TVM_RELAY_ATTRS_CALL_H_
+#define TVM_RELAY_ATTRS_CALL_H_
+
+#include <tvm/ir/attrs.h>
+
+#include <string>
+
+namespace tvm {
+namespace relay {
+
+/*!
+ * \brief Metadata for calls to TIR functions, useful for program analysis crossing Relay and TIR.
+ */
+struct CallLoweredAttrs : public tvm::AttrsNode<CallLoweredAttrs> {
+  /*! \brief Additional metadata attached to the call node. Should be replaced by explict fields. */
+  Map<String, ObjectRef> metadata;
+
+  TVM_DECLARE_ATTRS(CallLoweredAttrs, "relay.attrs.CallLoweredAttrs") {
+    TVM_ATTR_FIELD(metadata)
+        .describe("Metadata attached to the lowered function call.")
+        .set_default(Map<String, ObjectRef>());
+  }
+};
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_ATTRS_CALL_H_
diff --git a/darknet_drp_ros/include/tvm/relay/attrs/debug.h b/darknet_drp_ros/include/tvm/relay/attrs/debug.h
new file mode 100644
index 0000000..112228b
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/attrs/debug.h
@@ -0,0 +1,48 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/attrs/debug.h
+ * \brief Auxiliary attributes for debug operators.
+ */
+#ifndef TVM_RELAY_ATTRS_DEBUG_H_
+#define TVM_RELAY_ATTRS_DEBUG_H_
+
+#include <tvm/ir/attrs.h>
+#include <tvm/ir/env_func.h>
+
+#include <string>
+
+namespace tvm {
+namespace relay {
+
+/*!
+ * \brief Options for the debug operators.
+ */
+struct DebugAttrs : public tvm::AttrsNode<DebugAttrs> {
+  EnvFunc debug_func;
+
+  TVM_DECLARE_ATTRS(DebugAttrs, "relay.attrs.DebugAttrs") {
+    TVM_ATTR_FIELD(debug_func).describe("The function to use when debugging.");
+  }
+};
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_ATTRS_DEBUG_H_
diff --git a/darknet_drp_ros/include/tvm/relay/attrs/device_copy.h b/darknet_drp_ros/include/tvm/relay/attrs/device_copy.h
new file mode 100644
index 0000000..fe0534a
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/attrs/device_copy.h
@@ -0,0 +1,52 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/attrs/device_copy.h
+ * \brief Attribute for the device copy operator.
+ */
+#ifndef TVM_RELAY_ATTRS_DEVICE_COPY_H_
+#define TVM_RELAY_ATTRS_DEVICE_COPY_H_
+
+#include <tvm/ir/attrs.h>
+#include <tvm/target/virtual_device.h>
+
+#include <string>
+
+namespace tvm {
+namespace relay {
+
+/*!
+ * \brief Options for the device copy operators.
+ */
+struct DeviceCopyAttrs : public tvm::AttrsNode<DeviceCopyAttrs> {
+  VirtualDevice src_virtual_device = VirtualDevice::FullyUnconstrained();
+  VirtualDevice dst_virtual_device = VirtualDevice::FullyUnconstrained();
+
+  TVM_DECLARE_ATTRS(DeviceCopyAttrs, "relay.attrs.DeviceCopyAttrs") {
+    TVM_ATTR_FIELD(src_virtual_device)
+        .describe("The (virtual) device and scope where the op copies data from.");
+    TVM_ATTR_FIELD(dst_virtual_device)
+        .describe("The (virtual) device and scope where the op copies data to.");
+  }
+};
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_ATTRS_DEVICE_COPY_H_
diff --git a/darknet_drp_ros/include/tvm/relay/attrs/image.h b/darknet_drp_ros/include/tvm/relay/attrs/image.h
new file mode 100644
index 0000000..43510ea
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/attrs/image.h
@@ -0,0 +1,322 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/attrs/image.h
+ * \brief Auxiliary attributes for image operators.
+ */
+#ifndef TVM_RELAY_ATTRS_IMAGE_H_
+#define TVM_RELAY_ATTRS_IMAGE_H_
+
+#include <tvm/ir/attrs.h>
+#include <tvm/relay/base.h>
+
+#include <string>
+
+namespace tvm {
+namespace relay {
+
+/*! \brief Attributes used in image resize1d operator */
+struct Resize1DAttrs : public tvm::AttrsNode<Resize1DAttrs> {
+  Array<IndexExpr> size;
+  Array<FloatImm> roi;
+  std::string layout;
+  std::string method;
+  std::string coordinate_transformation_mode;
+  std::string rounding_method;
+  double cubic_alpha;
+  int cubic_exclude;
+  double extrapolation_value;
+  DataType out_dtype;
+
+  TVM_DECLARE_ATTRS(Resize1DAttrs, "relay.attrs.Resize1DAttrs") {
+    TVM_ATTR_FIELD(size).set_default(NullValue<Array<IndexExpr>>()).describe("Output Size.");
+    TVM_ATTR_FIELD(roi)
+        .set_default(NullValue<Array<FloatImm>>())
+        .describe("Region of Interest for coordinate transformation mode 'tf_crop_and_resize'");
+    TVM_ATTR_FIELD(layout).set_default("NCW").describe(
+        "Dimension ordering of input data. Can be 'NCW', 'NWC', etc."
+        "'N', 'C', 'W' stands for batch, channel and width"
+        "dimensions respectively. Resize is applied on the"
+        "'W' dimension.");
+    TVM_ATTR_FIELD(method).set_default("linear").describe(
+        "Specify the mode to use for scaling."
+        "nearest_neighbor -  Nearest Neighbor"
+        "linear - Linear Interpolation"
+        "cubic - Cubic Interpolation");
+    TVM_ATTR_FIELD(coordinate_transformation_mode)
+        .set_default("half_pixel")
+        .describe(
+            "Describes how to transform the coordinate in the resized tensor"
+            "to the coordinate in the original tensor."
+            "Refer to the ONNX Resize operator specification for details"
+            "Available options are half_pixel, align_corners and asymmetric");
+    TVM_ATTR_FIELD(rounding_method)
+        .set_default("round")
+        .describe(
+            "indicates how to find the \"nearest\" pixel in nearest_neighbor method"
+            "Available options are round, floor, and ceil.");
+    TVM_ATTR_FIELD(cubic_alpha)
+        .set_default(-0.5)
+        .describe("Spline Coefficient for cubic interpolation");
+    TVM_ATTR_FIELD(cubic_exclude)
+        .set_default(0)
+        .describe("Flag to exclude exterior of the image during cubic interpolation");
+    TVM_ATTR_FIELD(extrapolation_value)
+        .set_default(0.0)
+        .describe("Value to return when roi is outside of the image");
+    TVM_ATTR_FIELD(out_dtype).set_default(NullValue<DataType>()).describe("Output data type.");
+  }
+};
+
+/*! \brief Attributes used in image resize2d operator */
+struct Resize2DAttrs : public tvm::AttrsNode<Resize2DAttrs> {
+  Array<IndexExpr> size;
+  Array<FloatImm> roi;
+  std::string layout;
+  std::string method;
+  std::string coordinate_transformation_mode;
+  std::string rounding_method;
+  double cubic_alpha;
+  int cubic_exclude;
+  double extrapolation_value;
+  DataType out_dtype;
+
+  TVM_DECLARE_ATTRS(Resize2DAttrs, "relay.attrs.Resize2DAttrs") {
+    TVM_ATTR_FIELD(size).set_default(NullValue<Array<IndexExpr>>()).describe("Output Size.");
+    TVM_ATTR_FIELD(roi)
+        .set_default(NullValue<Array<FloatImm>>())
+        .describe("Region of Interest for coordinate transformation mode 'tf_crop_and_resize'");
+    TVM_ATTR_FIELD(layout).set_default("NCHW").describe(
+        "Dimension ordering of input data. Can be 'NCHW', 'NHWC', etc."
+        "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+        "dimensions respectively. Resize is applied on the 'H' and"
+        "'W' dimensions.");
+    TVM_ATTR_FIELD(method).set_default("linear").describe(
+        "Specify the mode to use for scaling."
+        "nearest_neighbor -  Nearest Neighbor"
+        "linear - Bilinear Interpolation"
+        "cubic - Bicubic Interpolation");
+    TVM_ATTR_FIELD(coordinate_transformation_mode)
+        .set_default("half_pixel")
+        .describe(
+            "Describes how to transform the coordinate in the resized tensor"
+            "to the coordinate in the original tensor."
+            "Refer to the ONNX Resize operator specification for details"
+            "Available options are half_pixel, align_corners and asymmetric");
+    TVM_ATTR_FIELD(rounding_method)
+        .set_default("round")
+        .describe(
+            "indicates how to find the \"nearest\" pixel in nearest_neighbor method"
+            "Available options are round, floor, and ceil.");
+    TVM_ATTR_FIELD(cubic_alpha)
+        .set_default(-0.5)
+        .describe("Spline Coefficient for Bicubic Interpolation");
+    TVM_ATTR_FIELD(cubic_exclude)
+        .set_default(0)
+        .describe("Flag to exclude exterior of the image during bicubic interpolation");
+    TVM_ATTR_FIELD(extrapolation_value)
+        .set_default(0.0)
+        .describe("Value to return when roi is outside of the image");
+    TVM_ATTR_FIELD(out_dtype).set_default(NullValue<DataType>()).describe("Output data type.");
+  }
+};
+
+/*! \brief Attributes used in image resize3d operator */
+struct Resize3DAttrs : public tvm::AttrsNode<Resize3DAttrs> {
+  Array<IndexExpr> size;
+  Array<FloatImm> roi;
+  std::string layout;
+  std::string method;
+  std::string coordinate_transformation_mode;
+  std::string rounding_method;
+  double cubic_alpha;
+  int cubic_exclude;
+  double extrapolation_value;
+  DataType out_dtype;
+
+  TVM_DECLARE_ATTRS(Resize3DAttrs, "relay.attrs.Resize3DAttrs") {
+    TVM_ATTR_FIELD(size).set_default(NullValue<Array<IndexExpr>>()).describe("Output Size.");
+    TVM_ATTR_FIELD(roi)
+        .set_default(NullValue<Array<FloatImm>>())
+        .describe("Region of Interest for coordinate transformation mode 'tf_crop_and_resize'");
+    TVM_ATTR_FIELD(layout).set_default("NCDHW").describe(
+        "Dimension ordering of input data. Can be 'NCDHW', 'NDHWC', etc."
+        "'N', 'C', 'D', 'H', 'W' stands for batch, channel, depth, height, and width"
+        "dimensions respectively. Resize3d is applied on the 'D', 'H' and"
+        "'W' dimensions.");
+    TVM_ATTR_FIELD(method).set_default("linear").describe(
+        "Specify the mode to use for scaling."
+        "nearest_neighbor -  Nearest Neighbor"
+        "linear - Trilinear Interpolation"
+        "cubic - Tricubic Interpolation");
+    TVM_ATTR_FIELD(coordinate_transformation_mode)
+        .set_default("half_pixel")
+        .describe(
+            "Describes how to transform the coordinate in the resized tensor"
+            "to the coordinate in the original tensor."
+            "Refer to the ONNX Resize operator specification for details"
+            "Available options are half_pixel, align_corners and asymmetric");
+    TVM_ATTR_FIELD(rounding_method)
+        .set_default("round")
+        .describe(
+            "indicates how to find the \"nearest\" pixel in nearest_neighbor method"
+            "Available options are round, floor, and ceil.");
+    TVM_ATTR_FIELD(cubic_alpha)
+        .set_default(-0.5)
+        .describe("Spline Coefficient for Tricubic Interpolation");
+    TVM_ATTR_FIELD(cubic_exclude)
+        .set_default(0)
+        .describe("Flag to exclude exterior of the image during tricubic interpolation");
+    TVM_ATTR_FIELD(extrapolation_value)
+        .set_default(0.0)
+        .describe("Value to return when roi is outside of the image");
+    TVM_ATTR_FIELD(out_dtype).set_default(NullValue<DataType>()).describe("Output data type.");
+  }
+};
+
+/*! \brief Attributes used in image crop_and_resize operator */
+struct CropAndResizeAttrs : public tvm::AttrsNode<CropAndResizeAttrs> {
+  Array<IndexExpr> crop_size;
+  std::string layout;
+  std::string method;
+  double extrapolation_value;
+  DataType out_dtype;
+
+  TVM_DECLARE_ATTRS(CropAndResizeAttrs, "relay.attrs.CropAndResizeAttrs") {
+    TVM_ATTR_FIELD(crop_size).set_default(NullValue<Array<IndexExpr>>()).describe("Target Size.");
+    TVM_ATTR_FIELD(layout).set_default("NCHW").describe(
+        "Dimension ordering of input data. Can be 'NCHW', 'NHWC', etc."
+        "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+        "dimensions respectively. Resize is applied on the 'H' and"
+        "'W' dimensions.");
+    TVM_ATTR_FIELD(method)
+        .set_default("bilinear")
+        .describe(
+            "Specify the mode to use for scaling."
+            "nearest_neighbor -  Nearest Neighbor"
+            "bilinear - Bilinear Interpolation");
+    TVM_ATTR_FIELD(extrapolation_value)
+        .set_default(0.0)
+        .describe("Specify value for extrapolation.");
+    TVM_ATTR_FIELD(out_dtype).set_default(NullValue<DataType>()).describe("Output data type.");
+  }
+};
+
+/*! \brief Attributes used in dilation operators */
+struct Dilation2DAttrs : public tvm::AttrsNode<Dilation2DAttrs> {
+  Array<IndexExpr> strides;
+  Array<IndexExpr> padding;
+  Array<IndexExpr> dilations;
+  std::string data_layout;
+  std::string kernel_layout;
+  DataType out_dtype;
+
+  TVM_DECLARE_ATTRS(Dilation2DAttrs, "relay.attrs.Dilation2DAttrs") {
+    TVM_ATTR_FIELD(strides)
+        .set_default(Array<IndexExpr>({1, 1}))
+        .describe("Specifies the strides of the sliding window. [stride_height, stride_width].");
+    TVM_ATTR_FIELD(padding)
+        .set_default(Array<IndexExpr>({0, 0}))
+        .describe(
+            "If padding is non-zero, then the input is implicitly zero-padded"
+            "Padding support both symmetric and asymmetric as"
+            "one int : same padding used on all sides"
+            "two int : bottom, right will use same padding as top, left"
+            "four int : padding width in the order of (top, left, bottom, right)");
+    TVM_ATTR_FIELD(dilations)
+        .set_default(Array<IndexExpr>({1, 1}))
+        .describe("Specifies the dilation rate to use. [dilation_height, dilation_width]");
+    TVM_ATTR_FIELD(data_layout)
+        .set_default("NCHW")
+        .describe(
+            "Dimension ordering of input data. Can be 'NCHW', 'NHWC', etc."
+            "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+            "dimensions respectively. Convolution is applied on the 'H' and"
+            "'W' dimensions.");
+    TVM_ATTR_FIELD(kernel_layout)
+        .set_default("IHW")
+        .describe(
+            "Dimension ordering of weight. Can be 'IHW', 'HWI', etc."
+            "'I', 'H', 'W' stands for input_channel, height, and width"
+            "dimensions respectively.");
+    TVM_ATTR_FIELD(out_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Output data type, set to explicit type under mixed precision setting");
+  }
+};
+
+/*! \brief Attributes used in image affine_grid operator */
+struct AffineGridAttrs : public tvm::AttrsNode<AffineGridAttrs> {
+  Array<IndexExpr> target_shape;
+
+  TVM_DECLARE_ATTRS(AffineGridAttrs, "relay.attrs.AffineGridAttrs") {
+    TVM_ATTR_FIELD(target_shape).describe("Specifies the output shape (H, W).");
+  }
+};
+
+/*! \brief Attributes used in image grid_sample operator */
+struct GridSampleAttrs : public tvm::AttrsNode<GridSampleAttrs> {
+  String method;
+  String layout;
+  String padding_mode;
+  bool align_corners;
+
+  TVM_DECLARE_ATTRS(GridSampleAttrs, "relay.attrs.GridSampleAttrs") {
+    TVM_ATTR_FIELD(method)
+        .set_default("bilinear")
+        .describe(
+            "Specify the mode to use for scaling."
+            "nearest - 2D or 3D Nearest Interpolation."
+            "bilinear - '2D Bilinear' or '3D Trilinear' Interpolation."
+            "bicubic - 2D Bicubic Interpolation.");
+    TVM_ATTR_FIELD(layout).set_default("NCHW").describe(
+        "Dimension ordering of input data. Can be 'NCHW', 'NCDHW', etc."
+        "'N', 'C', 'D', 'H', 'W' stands for batch, channel, depth, height, and width"
+        "dimensions respectively."
+        "2D Resize is applied on the 'H' and 'W' dimensions."
+        "3D Resize is applied on the 'D' and 'H' and 'W' dimensions.");
+    TVM_ATTR_FIELD(padding_mode)
+        .set_default("zeros")
+        .describe(
+            "If :attr:'grid' has values outside the range of '[-1, 1]', the corresponding"
+            "outputs are handled as defined by padding_mode. Options are"
+            "padding_mode='zeros': use '0' for out-of-bound grid locations,"
+            "padding_mode='border': use border values for out-of-bound grid locations"
+            "padding_mode='reflection': use values at locations reflected by"
+            "the border for out-of-bound grid locations. For location far away"
+            "from the border, it will keep being reflected until becoming in bound,"
+            "e.g., (normalized) pixel location 'x = -3.5' reflects by border '-1'"
+            "and becomes 'x' = 1.5, then reflects by border '1' and becomes"
+            "'x' = -0.5");
+    TVM_ATTR_FIELD(align_corners)
+        .set_default(true)
+        .describe(
+            "Geometrically, we consider the pixels of the"
+            "input as squares rather than points."
+            "If set to True, the extrema (-1 and 1) are considered as referring"
+            "to the center points of the input's corner pixels. If set to False, they"
+            "are instead considered as referring to the corner points of the input's corner"
+            "pixels, making the sampling more resolution agnostic.");
+  }
+};
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_ATTRS_IMAGE_H_
diff --git a/darknet_drp_ros/include/tvm/relay/attrs/memory.h b/darknet_drp_ros/include/tvm/relay/attrs/memory.h
new file mode 100644
index 0000000..07d6cc7
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/attrs/memory.h
@@ -0,0 +1,78 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/attrs/memory.h
+ * \brief Attributes for memory operators.
+ */
+#ifndef TVM_RELAY_ATTRS_MEMORY_H_
+#define TVM_RELAY_ATTRS_MEMORY_H_
+
+#include <tvm/ir/attrs.h>
+#include <tvm/relay/expr.h>
+#include <tvm/target/virtual_device.h>
+
+#include <string>
+#include <vector>
+
+namespace tvm {
+namespace relay {
+
+std::vector<TensorType> FlattenTupleType(const Type& type);
+std::vector<Expr> FromTupleType(const Type& type, const Expr& expr);
+Expr ToTupleType(const Type& t, const std::vector<Expr>& exprs);
+
+/*!
+ * \brief Options for allocating storage.
+ */
+struct AllocStorageAttrs : public tvm::AttrsNode<AllocStorageAttrs> {
+  DataType dtype;
+  VirtualDevice virtual_device = VirtualDevice::FullyUnconstrained();
+
+  TVM_DECLARE_ATTRS(AllocStorageAttrs, "relay.attrs.AllocStorageAttrs") {
+    TVM_ATTR_FIELD(dtype)
+        .describe("The dtype of the tensor to allocate.")
+        .set_default(DataType::Float(32, 1));
+    TVM_ATTR_FIELD(virtual_device).describe("The virtual device on which to allocate memory.");
+  }
+};
+
+/*!
+ * \brief Options for allocating tensors.
+ */
+struct AllocTensorAttrs : public tvm::AttrsNode<AllocTensorAttrs> {
+  Constant const_shape;
+  Array<IndexExpr> assert_shape;
+  DataType dtype;
+
+  TVM_DECLARE_ATTRS(AllocTensorAttrs, "relay.attrs.AllocTensorAttrs") {
+    TVM_ATTR_FIELD(dtype)
+        .describe("The dtype of the tensor to allocate.")
+        .set_default(DataType::Float(32, 1));
+    TVM_ATTR_FIELD(const_shape).describe("The shape of constant used to aid in type inference.");
+    TVM_ATTR_FIELD(assert_shape)
+        .describe(
+            "The shape to cast the return type of the allocation to, "
+            "used to specify the shape obtained via further analysis.");
+  }
+};
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_ATTRS_MEMORY_H_
diff --git a/darknet_drp_ros/include/tvm/relay/attrs/nn.h b/darknet_drp_ros/include/tvm/relay/attrs/nn.h
new file mode 100644
index 0000000..5ffc471
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/attrs/nn.h
@@ -0,0 +1,1591 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/attrs/nn.h
+ * \brief Auxiliary attributes for nn operators.
+ */
+#ifndef TVM_RELAY_ATTRS_NN_H_
+#define TVM_RELAY_ATTRS_NN_H_
+
+#include <tvm/ir/attrs.h>
+#include <tvm/relay/base.h>
+
+#include <string>
+
+namespace tvm {
+namespace relay {
+
+/*!
+ * \brief Add a 1D Tensor to an axis of a data.
+ *
+ * \note bias_add is a special add operator that is in nn
+ *   and enables automatic derivation of bias's shape.
+ *   You can directly use add for more generalized case.
+ */
+struct BiasAddAttrs : public tvm::AttrsNode<BiasAddAttrs> {
+  int axis;
+
+  TVM_DECLARE_ATTRS(BiasAddAttrs, "relay.attrs.BiasAddAttrs") {
+    TVM_ATTR_FIELD(axis).describe("The axis to add the bias").set_default(1);
+  }
+};
+
+/*! \brief Attributes used in 1D convolution operators */
+struct Conv1DAttrs : public tvm::AttrsNode<Conv1DAttrs> {
+  Array<IndexExpr> strides;
+  Array<IndexExpr> padding;
+  Array<IndexExpr> dilation;
+  int groups;
+  IndexExpr channels;
+  Array<IndexExpr> kernel_size;
+  tvm::String data_layout;
+  tvm::String kernel_layout;
+  tvm::String out_layout;
+  DataType out_dtype;
+
+  TVM_DECLARE_ATTRS(Conv1DAttrs, "relay.attrs.Conv1DAttrs") {
+    TVM_ATTR_FIELD(strides)
+        .set_default(Array<IndexExpr>({
+            1,
+        }))
+        .describe("Specifies the stride of the convolution.");
+    TVM_ATTR_FIELD(padding)
+        .set_default(Array<IndexExpr>({0, 0}))
+        .describe(
+            "If padding is non-zero, then the input is implicitly zero-padded"
+            "on both sides for padding number of points");
+    TVM_ATTR_FIELD(dilation)
+        .set_default(Array<IndexExpr>({
+            1,
+        }))
+        .describe("Specifies the dilation rate to use for dilated convolution.");
+    TVM_ATTR_FIELD(groups).set_default(1).describe(
+        "Currently unused but may be added in the future.");
+    TVM_ATTR_FIELD(channels)
+        .describe(
+            "The number of output channels in the convolution."
+            " If it is not set, inferred by shape of the weight.")
+        .set_default(NullValue<IndexExpr>());
+    TVM_ATTR_FIELD(kernel_size)
+        .describe("Specifies the dimensions of the convolution window.")
+        .set_default(NullValue<Array<IndexExpr>>());
+    TVM_ATTR_FIELD(data_layout)
+        .set_default("NCW")
+        .describe(
+            "Dimension ordering of input data. Can be 'NCW', 'NWC', etc."
+            "'N', 'C', 'W' stands for batch, channel, and width"
+            "dimensions respectively. Convolution is applied on the 'W'"
+            "dimension.");
+    TVM_ATTR_FIELD(kernel_layout)
+        .set_default("OIW")
+        .describe(
+            "Dimension ordering of weight. Can be 'OIW', or 'WIO', etc."
+            "'O', 'I', 'W' stands for num_filter, input_channel, and width"
+            "dimensions respectively.");
+    TVM_ATTR_FIELD(out_layout)
+        .set_default("")
+        .describe(
+            "Dimension ordering of output. Can be 'NCW', 'NWC', etc."
+            "'N', 'C', 'W' stands for batch, channel, and width"
+            "dimensions respectively. Default to be same as input layout.");
+
+    // use 0 bits to indicate none.
+    TVM_ATTR_FIELD(out_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Output data type, set to explicit type under mixed precision setting");
+  }
+};
+
+/*! \brief Attributes used in convolution operators */
+struct Conv2DAttrs : public tvm::AttrsNode<Conv2DAttrs> {
+  Array<IndexExpr> strides;
+  Array<IndexExpr> padding;
+  Array<IndexExpr> dilation;
+  int groups;
+  IndexExpr channels;
+  Array<IndexExpr> kernel_size;
+  tvm::String data_layout;
+  tvm::String kernel_layout;
+  tvm::String out_layout;
+  tvm::String auto_scheduler_rewritten_layout;   // The layout after auto-scheduler's layout rewrite
+  Array<PrimExpr> meta_schedule_original_shape;  // The original shape of the weights
+  DataType out_dtype;
+
+  TVM_DECLARE_ATTRS(Conv2DAttrs, "relay.attrs.Conv2DAttrs") {
+    TVM_ATTR_FIELD(strides)
+        .set_default(Array<IndexExpr>({1, 1}))
+        .describe("Specifies the strides of the convolution.");
+    TVM_ATTR_FIELD(padding)
+        .set_default(Array<IndexExpr>({0, 0}))
+        .describe(
+            "If padding is non-zero, then the input is implicitly zero-padded"
+            "Padding support both symmetric and asymmetric as"
+            "one int : same padding used on all sides"
+            "two int : bottom, right will use same padding as top, left"
+            "four int : padding width in the order of (top, left, bottom, right)");
+    TVM_ATTR_FIELD(dilation)
+        .set_default(Array<IndexExpr>({1, 1}))
+        .describe("Specifies the dilation rate to use for dilated convolution.");
+    TVM_ATTR_FIELD(groups).set_default(1).describe(
+        "Controls the connections between inputs and outputs."
+        "At groups=1, all inputs are convolved to all outputs."
+        "At groups=2, the operation becomes equivalent to having two convolution"
+        "layers side by side, each seeing half the input channels, and producing"
+        "half the output channels, and both subsequently concatenated.");
+    TVM_ATTR_FIELD(channels)
+        .describe(
+            "The number of output channels in the convolution."
+            " If it is not set, inferred by shape of the weight.")
+        .set_default(NullValue<IndexExpr>());
+    TVM_ATTR_FIELD(kernel_size)
+        .describe("Specifies the dimensions of the convolution window.")
+        .set_default(NullValue<Array<IndexExpr>>());
+    TVM_ATTR_FIELD(data_layout)
+        .set_default("NCHW")
+        .describe(
+            "Dimension ordering of input data. Can be 'NCHW', 'NHWC', etc."
+            "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+            "dimensions respectively. Convolution is applied on the 'H' and"
+            "'W' dimensions.");
+    TVM_ATTR_FIELD(kernel_layout)
+        .set_default("OIHW")
+        .describe(
+            "Dimension ordering of weight. Can be 'OIHW', 'OIHW16o16i', etc."
+            "'O', 'I', 'H', 'W' stands for num_filter, input_channel, height, and width"
+            "dimensions respectively.");
+    TVM_ATTR_FIELD(out_layout)
+        .set_default("")
+        .describe(
+            "Dimension ordering of output. Can be 'NCHW', 'NHWC', etc."
+            "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+            "dimensions respectively. Default to be same as input layout.");
+
+    // use 0 bits to indicate none.
+    TVM_ATTR_FIELD(out_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Output data type, set to explicit type under mixed precision setting");
+  }
+};
+
+/*! \brief Attributes used in winograd weight transformation operators */
+struct ConvWinogradWeightTransformAttrs : public tvm::AttrsNode<ConvWinogradWeightTransformAttrs> {
+  int tile_size;
+
+  TVM_DECLARE_ATTRS(ConvWinogradWeightTransformAttrs,
+                    "relay.attrs.ConvWinogradWeightTransformAttrs") {
+    TVM_ATTR_FIELD(tile_size).describe(
+        "Tile size of winograd. E.g. 2 for F(2x2, 3x3) and 4 for F(4x4, 3x3)");
+  }
+};
+
+/*! \brief Attributes used in gemm weight transformation operators */
+struct ConvGemmWeightTransformAttrs : public tvm::AttrsNode<ConvGemmWeightTransformAttrs> {
+  int tile_rows;
+  int tile_cols;
+
+  TVM_DECLARE_ATTRS(ConvGemmWeightTransformAttrs, "relay.attrs.ConvGemmWeightTransformAttrs") {
+    TVM_ATTR_FIELD(tile_rows).describe("Tile rows of the weight transformation for ConvGemm.");
+    TVM_ATTR_FIELD(tile_cols).describe("Tile columns of the weight transformation for ConvGemm.");
+  }
+};
+
+/*! \brief Attributes used in convolution operators with winograd algorithm */
+struct Conv2DWinogradAttrs : public tvm::AttrsNode<Conv2DWinogradAttrs> {
+  int tile_size;
+  Array<IndexExpr> strides;
+  Array<IndexExpr> padding;
+  Array<IndexExpr> dilation;
+  int groups;
+  IndexExpr channels;
+  Array<IndexExpr> kernel_size;
+  tvm::String data_layout;
+  tvm::String kernel_layout;
+  tvm::String out_layout;
+  tvm::String auto_scheduler_rewritten_layout;   // The layout after auto-scheduler's layout rewrite
+  Array<PrimExpr> meta_schedule_original_shape;  // The original shape of the weights
+  DataType out_dtype;
+
+  TVM_DECLARE_ATTRS(Conv2DWinogradAttrs, "relay.attrs.Conv2DWinogradAttrs") {
+    TVM_ATTR_FIELD(tile_size).describe(
+        "The tile size of winograd. E.g. 2 for F(2x2, 3x3) and 4 for F(4x4, 3x3)");
+    TVM_ATTR_FIELD(strides)
+        .set_default(Array<IndexExpr>({1, 1}))
+        .describe("Specifies the strides of the convolution.");
+    TVM_ATTR_FIELD(padding)
+        .set_default(Array<IndexExpr>({0, 0}))
+        .describe(
+            "If padding is non-zero, then the input is implicitly zero-padded"
+            "Padding support both symmetric and asymmetric as"
+            "one int : same padding used on all sides"
+            "two int : bottom, right will use same padding as top, left"
+            "four int : padding width in the order of (top, left, bottom, right)");
+    TVM_ATTR_FIELD(dilation)
+        .set_default(Array<IndexExpr>({1, 1}))
+        .describe("Specifies the dilation rate to use for dilated convolution.");
+    TVM_ATTR_FIELD(groups).set_default(1).describe(
+        "Controls the connections between inputs and outputs."
+        "At groups=1, all inputs are convolved to all outputs."
+        "At groups=2, the operation becomes equivalent to having two convolution"
+        "layers side by side, each seeing half the input channels, and producing"
+        "half the output channels, and both subsequently concatenated.");
+    TVM_ATTR_FIELD(channels)
+        .describe(
+            "The number of output channels in the convolution."
+            " If it is not set, inferred by shape of the weight.")
+        .set_default(NullValue<IndexExpr>());
+    TVM_ATTR_FIELD(kernel_size)
+        .describe("Specifies the dimensions of the convolution window.")
+        .set_default(NullValue<Array<IndexExpr>>());
+    TVM_ATTR_FIELD(data_layout)
+        .set_default("NCHW")
+        .describe(
+            "Dimension ordering of input data. Can be 'NCHW', 'NHWC', etc."
+            "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+            "dimensions respectively. Convolution is applied on the 'H' and"
+            "'W' dimensions.");
+    TVM_ATTR_FIELD(kernel_layout)
+        .set_default("OIHW")
+        .describe(
+            "Dimension ordering of weight. Can be 'OIHW', 'OIHW16o16i', etc."
+            "'O', 'I', 'H', 'W' stands for num_filter, input_channel, height, and width"
+            "dimensions respectively.");
+    TVM_ATTR_FIELD(out_layout)
+        .set_default("")
+        .describe(
+            "Dimension ordering of output. Can be 'NCHW', 'NHWC', etc."
+            "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+            "dimensions respectively. Default to be same as input layout.");
+
+    // use 0 bits to indicate none.
+    TVM_ATTR_FIELD(out_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Output data type, set to explicit type under mixed precision setting");
+  }
+};
+
+/*! \brief Attributes used in winograd weight transformation operators */
+struct Conv2DWinogradNNPACKWeightTransformAttrs
+    : public tvm::AttrsNode<Conv2DWinogradNNPACKWeightTransformAttrs> {
+  int convolution_algorithm;
+  DataType out_dtype;
+
+  TVM_DECLARE_ATTRS(Conv2DWinogradNNPACKWeightTransformAttrs,
+                    "relay.attrs.Conv2DWinogradNNPACKWeightTransformAttrs") {
+    TVM_ATTR_FIELD(convolution_algorithm)
+        .describe(
+            "The convolution algorithm for Winograd NNPACK. "
+            "E.g. tvm.contrib.nnpack.ConvolutionAlgorithm.WT_8x8 for WT_8x8, "
+            "tvm.contrib.nnpack.ConvolutionAlgorithm.WT_8x8_FP16 for WT_8x8_FP16");
+    TVM_ATTR_FIELD(out_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Output data type, set to explicit type under mixed precision setting");
+  }
+};
+
+/*! \brief Attributes used in convolution operators */
+struct Conv3DAttrs : public tvm::AttrsNode<Conv3DAttrs> {
+  Array<IndexExpr> strides;
+  Array<IndexExpr> padding;
+  Array<IndexExpr> dilation;
+  int groups;
+  IndexExpr channels;
+  Array<IndexExpr> kernel_size;
+  tvm::String data_layout;
+  tvm::String kernel_layout;
+  tvm::String out_layout;
+  tvm::String auto_scheduler_rewritten_layout;   // The layout after auto-scheduler's layout rewrite
+  Array<PrimExpr> meta_schedule_original_shape;  // The original shape of the weights
+  DataType out_dtype;
+
+  TVM_DECLARE_ATTRS(Conv3DAttrs, "relay.attrs.Conv3DAttrs") {
+    TVM_ATTR_FIELD(strides)
+        .set_default(Array<IndexExpr>({1, 1, 1}))
+        .describe("Specifies the strides of the convolution.");
+    TVM_ATTR_FIELD(padding)
+        .set_default(Array<IndexExpr>({0, 0, 0}))
+        .describe(
+            "If padding is non-zero, then the input is implicitly zero-padded"
+            "Padding support both symmetric and asymmetric as"
+            "one int : same padding used on all sides"
+            "three int : back, bottom, right will use same padding as front, top, left"
+            "six int : padding width in the order of (front, top, left, back, bottom,"
+            "right)");
+    TVM_ATTR_FIELD(dilation)
+        .set_default(Array<IndexExpr>({1, 1, 1}))
+        .describe("Specifies the dilation rate to use for dilated convolution.");
+    TVM_ATTR_FIELD(groups).set_default(1).describe(
+        "Controls the connections between inputs and outputs."
+        "At groups=1, all inputs are convolved to all outputs."
+        "At groups=2, the operation becomes equivalent to having two convolution"
+        "layers side by side, each seeing half the input channels, and producing"
+        "half the output channels, and both subsequently concatenated.");
+    TVM_ATTR_FIELD(channels)
+        .describe(
+            "The number of output channels in the convolution."
+            " If it is not set, inferred by shape of the weight.")
+        .set_default(NullValue<IndexExpr>());
+    TVM_ATTR_FIELD(kernel_size)
+        .describe("Specifies the dimensions of the convolution window.")
+        .set_default(NullValue<Array<IndexExpr>>());
+    TVM_ATTR_FIELD(data_layout)
+        .set_default("NCDHW")
+        .describe(
+            "Dimension ordering of input data. Can be 'NCDHW', 'NDHWC', etc."
+            "'N', 'C', 'D', 'H', 'W' stands for batch, channel, depth, height, and width"
+            "dimensions respectively. Convolution is applied on the 'D', 'H' and"
+            "'W' dimensions.");
+    TVM_ATTR_FIELD(kernel_layout)
+        .set_default("OIDHW")
+        .describe(
+            "Dimension ordering of weight. Can be 'OIDHW', 'OIDHW16o16i', etc."
+            "'O', 'I', 'D', 'H', 'W' stands for num_filter, input_channel, depth, height,"
+            "and width dimensions respectively.");
+    TVM_ATTR_FIELD(out_layout)
+        .set_default("")
+        .describe(
+            "Dimension ordering of output. Can be 'NCDHW', 'NDHWC', etc."
+            "'N', 'C', 'D', 'H', 'W' stands for batch, channel, depth, height, and width"
+            "dimensions respectively. Default to be same as input layout.");
+
+    // use 0 bits to indicate none.
+    TVM_ATTR_FIELD(out_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Output data type, set to explicit type under mixed precision setting");
+  }
+};
+
+/*! \brief Attributes used in transposed convolution operator */
+struct Conv3DTransposeAttrs : public tvm::AttrsNode<Conv3DTransposeAttrs> {
+  IndexExpr channels;
+  Array<IndexExpr> kernel_size;
+  Array<IndexExpr> strides;
+  Array<IndexExpr> padding;
+  Array<IndexExpr> output_padding;
+  Array<IndexExpr> dilation;
+  int groups;
+  tvm::String data_layout;
+  tvm::String kernel_layout;
+  tvm::String out_layout;
+  DataType out_dtype;
+
+  TVM_DECLARE_ATTRS(Conv3DTransposeAttrs, "relay.attrs.Conv3DTransposeAttrs") {
+    TVM_ATTR_FIELD(channels)
+        .set_default(NullValue<IndexExpr>())
+        .describe(
+            "The dimensionality of the output space"
+            "i.e. the number of output channels in the convolution.");
+    TVM_ATTR_FIELD(kernel_size)
+        .describe("The dimensions of the convolution window.")
+        .set_default(NullValue<Array<IndexExpr>>());
+    TVM_ATTR_FIELD(strides)
+        .set_default(Array<IndexExpr>({1, 1, 1}))
+        .describe("The strides of the convolution.");
+    TVM_ATTR_FIELD(output_padding)
+        .set_default(Array<IndexExpr>({0, 0, 0}))
+        .describe(
+            "Zero-padding added to one side of the output."
+            "Padding support both symmetric and asymmetric as"
+            "one int : same padding used on all sides"
+            "three int : front, bottom, right will use same padding as back, top, left"
+            "six int : padding width in the order of (front, top, left, back, bottom, right)");
+    TVM_ATTR_FIELD(padding)
+        .set_default(Array<IndexExpr>({0, 0, 0}))
+        .describe(
+            "If padding is non-zero, then the input is implicitly zero-padded"
+            "Padding support both symmetric and asymmetric as"
+            "one int : same padding used on all sides"
+            "three int : front, bottom, right will use same padding as back, top, left"
+            "six int : padding width in the order of (front, top, left, back, bottom, right)");
+    TVM_ATTR_FIELD(dilation)
+        .set_default(Array<IndexExpr>({1, 1, 1}))
+        .describe("Specifies the dilation rate to use for dilated convolution.");
+    TVM_ATTR_FIELD(groups).set_default(1).describe(
+        "Controls the connections between inputs and outputs."
+        "At groups=1, all inputs are convolved to all outputs."
+        "At groups=2, the operation becomes equivalent to having two convolution"
+        "layers side by side, each seeing half the input channels, and producing"
+        "half the output channels, and both subsequently concatenated.");
+    TVM_ATTR_FIELD(data_layout)
+        .set_default("NCDHW")
+        .describe(
+            "Dimension ordering of data. Can be 'NCDHW', 'NDHWC', etc."
+            "'N', 'C', 'D', 'H', 'W' stands for batch, channel, depth, height, and width"
+            "dimensions respectively. Convolution is applied on the 'D', 'H' and"
+            "'W' dimensions.");
+    TVM_ATTR_FIELD(kernel_layout)
+        .set_default("OIDHW")
+        .describe(
+            "Dimension ordering of data and weight. Can be 'OIDHW', 'OIDHW16o16i', etc."
+            "'O', 'I', 'D', 'H', 'W' stands for num_filter, input_channel, depth, height, and width"
+            "dimensions respectively.");
+    TVM_ATTR_FIELD(out_layout)
+        .set_default("")
+        .describe(
+            "Dimension ordering of output. Can be 'NCDHW', 'NDHWC', etc."
+            "'N', 'C', 'D', 'H', 'W' stands for batch, channel, depth, height, and width"
+            "dimensions respectively. Default to be same as input layout.");
+    TVM_ATTR_FIELD(out_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Output data type, set to explicit type under mixed precision setting");
+  }
+};
+
+/*! \brief Attributes used in 3d winograd convolution operators */
+struct Conv3DWinogradAttrs : public tvm::AttrsNode<Conv3DWinogradAttrs> {
+  int tile_size;
+  Array<IndexExpr> strides;
+  Array<IndexExpr> padding;
+  Array<IndexExpr> dilation;
+  int groups;
+  IndexExpr channels;
+  Array<IndexExpr> kernel_size;
+  std::string data_layout;
+  std::string kernel_layout;
+  std::string out_layout;
+  DataType out_dtype;
+
+  TVM_DECLARE_ATTRS(Conv3DWinogradAttrs, "relay.attrs.Conv3DWinogradAttrs") {
+    TVM_ATTR_FIELD(tile_size).describe(
+        "The tile size of winograd. E.g. 2 for F(2x2x2, 3x3x3) and 4 for F(4x4x4, 3x3x3)");
+    TVM_ATTR_FIELD(strides)
+        .set_default(Array<IndexExpr>({1, 1, 1}))
+        .describe("Specifies the strides of the convolution.");
+    TVM_ATTR_FIELD(padding)
+        .set_default(Array<IndexExpr>({0, 0, 0}))
+        .describe(
+            "If padding is non-zero, then the input is implicitly zero-padded"
+            "Padding support both symmetric and asymmetric as"
+            "one int : same padding used on all sides"
+            "three int : back, bottom, right will use same padding as front, top, left"
+            "six int : padding width in the order of (front, top, left, back, bottom,"
+            "right)");
+    TVM_ATTR_FIELD(dilation)
+        .set_default(Array<IndexExpr>({1, 1, 1}))
+        .describe("Specifies the dilation rate to use for dilated convolution.");
+    TVM_ATTR_FIELD(groups).set_default(1).describe(
+        "Controls the connections between inputs and outputs."
+        "At groups=1, all inputs are convolved to all outputs."
+        "At groups=2, the operation becomes equivalent to having two convolution"
+        "layers side by side, each seeing half the input channels, and producing"
+        "half the output channels, and both subsequently concatenated.");
+    TVM_ATTR_FIELD(channels)
+        .describe(
+            "The number of output channels in the convolution."
+            " If it is not set, inferred by shape of the weight.")
+        .set_default(NullValue<IndexExpr>());
+    TVM_ATTR_FIELD(kernel_size)
+        .describe("Specifies the dimensions of the convolution window.")
+        .set_default(NullValue<Array<IndexExpr>>());
+    TVM_ATTR_FIELD(data_layout)
+        .set_default("NCDHW")
+        .describe(
+            "Dimension ordering of input data. Can be 'NCDHW', 'NDHWC', etc."
+            "'N', 'C', 'D', 'H', 'W' stands for batch, channel, depth, height, and width"
+            "dimensions respectively. Convolution is applied on the 'D', 'H' and"
+            "'W' dimensions.");
+    TVM_ATTR_FIELD(kernel_layout)
+        .set_default("OIDHW")
+        .describe(
+            "Dimension ordering of weight. Can be 'OIDHW', 'OIDHW16o16i', etc."
+            "'O', 'I', 'D', 'H', 'W' stands for num_filter, input_channel, depth, height,"
+            "and width dimensions respectively.");
+    TVM_ATTR_FIELD(out_layout)
+        .set_default("")
+        .describe(
+            "Dimension ordering of output. Can be 'NCDHW', 'NDHWC', etc."
+            "'N', 'C', 'D', 'H', 'W' stands for batch, channel, depth, height, and width"
+            "dimensions respectively. Default to be same as input layout.");
+
+    // use 0 bits to indicate none.
+    TVM_ATTR_FIELD(out_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Output data type, set to explicit type under mixed precision setting");
+  }
+};
+
+/*! \brief Attributes used in softmax operators */
+struct SoftmaxAttrs : public tvm::AttrsNode<SoftmaxAttrs> {
+  int axis;
+
+  TVM_DECLARE_ATTRS(SoftmaxAttrs, "relay.attrs.SoftmaxAttrs") {
+    TVM_ATTR_FIELD(axis).set_default(-1).describe("The axis to sum over when computing softmax.");
+  }
+};
+
+/*! \brief Attributes used in transposed convolution operator */
+struct Conv2DTransposeAttrs : public tvm::AttrsNode<Conv2DTransposeAttrs> {
+  IndexExpr channels;
+  Array<IndexExpr> kernel_size;
+  Array<IndexExpr> strides;
+  Array<IndexExpr> padding;
+  Array<IndexExpr> output_padding;
+  Array<IndexExpr> dilation;
+  int groups;
+  std::string data_layout;
+  std::string kernel_layout;
+  std::string out_layout;
+  DataType out_dtype;
+
+  TVM_DECLARE_ATTRS(Conv2DTransposeAttrs, "relay.attrs.Conv2DTransposeAttrs") {
+    TVM_ATTR_FIELD(channels)
+        .set_default(NullValue<IndexExpr>())
+        .describe(
+            "The dimensionality of the output space"
+            "i.e. the number of output channels in the convolution.");
+    TVM_ATTR_FIELD(kernel_size)
+        .describe("The dimensions of the convolution window.")
+        .set_default(NullValue<Array<IndexExpr>>());
+    TVM_ATTR_FIELD(strides)
+        .set_default(Array<IndexExpr>({1, 1}))
+        .describe("The strides of the convolution.");
+    TVM_ATTR_FIELD(output_padding)
+        .set_default(Array<IndexExpr>({0, 0}))
+        .describe(
+            "Zero-padding added to one side of the output."
+            "Padding support both symmetric and asymmetric as"
+            "one int : same padding used on all sides"
+            "two int : bottom, right will use same padding as top, left"
+            "four int : padding width in the order of (top, left, bottom, right)");
+    TVM_ATTR_FIELD(padding)
+        .set_default(Array<IndexExpr>({0, 0}))
+        .describe(
+            "If padding is non-zero, then the input is implicitly zero-padded"
+            "Padding support both symmetric and asymmetric as"
+            "one int : same padding used on all sides"
+            "two int : bottom, right will use same padding as top, left"
+            "four int : padding width in the order of (top, left, bottom, right)");
+    TVM_ATTR_FIELD(dilation)
+        .set_default(Array<IndexExpr>({1, 1}))
+        .describe("Specifies the dilation rate to use for dilated convolution.");
+    TVM_ATTR_FIELD(groups).set_default(1).describe(
+        "Controls the connections between inputs and outputs."
+        "At groups=1, all inputs are convolved to all outputs."
+        "At groups=2, the operation becomes equivalent to having two convolution"
+        "layers side by side, each seeing half the input channels, and producing"
+        "half the output channels, and both subsequently concatenated.");
+    TVM_ATTR_FIELD(data_layout)
+        .set_default("NCHW")
+        .describe(
+            "Dimension ordering of data. Can be 'NCHW', 'NHWC', etc."
+            "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+            "dimensions respectively. Convolution is applied on the 'H' and"
+            "'W' dimensions.");
+    TVM_ATTR_FIELD(kernel_layout)
+        .set_default("OIHW")
+        .describe(
+            "Dimension ordering of data and weight. Can be 'OIHW', 'OIHW16o16i', etc."
+            "'O', 'I', 'H', 'W' stands for num_filter, input_channel, height, and width"
+            "dimensions respectively.");
+    TVM_ATTR_FIELD(out_layout)
+        .set_default("")
+        .describe(
+            "Dimension ordering of output. Can be 'NCHW', 'NHWC', etc."
+            "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+            "dimensions respectively. Default to be same as input layout.");
+    TVM_ATTR_FIELD(out_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Output data type, set to explicit type under mixed precision setting");
+  }
+};
+
+/*! \brief Attributes used in dilate operator */
+struct DilateAttrs : public tvm::AttrsNode<DilateAttrs> {
+  Array<IndexExpr> strides;
+  double dilation_value;
+
+  TVM_DECLARE_ATTRS(DilateAttrs, "relay.attrs.DilateAttrs") {
+    TVM_ATTR_FIELD(strides)
+        .set_default(Array<IndexExpr>({1, 1}))
+        .describe("Dilation stride on each dimension, 1 means no dilation.");
+    TVM_ATTR_FIELD(dilation_value).set_default(0.0).describe("Value used to dilate the input.");
+  }
+};
+
+/*! \brief Attributes used in 1D transposed convolution operator */
+struct Conv1DTransposeAttrs : public tvm::AttrsNode<Conv1DTransposeAttrs> {
+  IndexExpr channels;
+  Array<IndexExpr> kernel_size;
+  Array<IndexExpr> strides;
+  Array<IndexExpr> padding;
+  Array<IndexExpr> output_padding;
+  Array<IndexExpr> dilation;
+  int groups;
+  std::string data_layout;
+  std::string kernel_layout;
+  std::string out_layout;
+  DataType out_dtype;
+
+  TVM_DECLARE_ATTRS(Conv1DTransposeAttrs, "relay.attrs.Conv1DTransposeAttrs") {
+    TVM_ATTR_FIELD(channels)
+        .set_default(NullValue<IndexExpr>())
+        .describe(
+            "The dimensionality of the output space"
+            "i.e. the number of output channels in the convolution.");
+    TVM_ATTR_FIELD(kernel_size)
+        .describe("The dimensions of the convolution window.")
+        .set_default(NullValue<Array<IndexExpr>>());
+    TVM_ATTR_FIELD(strides)
+        .set_default(Array<IndexExpr>({1}))
+        .describe("The strides of the convolution.");
+    TVM_ATTR_FIELD(output_padding)
+        .set_default(Array<IndexExpr>({0}))
+        .describe("Zero-padding added to one side of the output.");
+    TVM_ATTR_FIELD(padding)
+        .set_default(Array<IndexExpr>({0}))
+        .describe(
+            "Symmetric or asymmetric padding."
+            "Single value: the input is implicitly zero-padded on both sides."
+            "Two values: padding[0] is used for left input padding, "
+            "padding[1] is used for right input padding,");
+    TVM_ATTR_FIELD(dilation)
+        .set_default(Array<IndexExpr>({1}))
+        .describe("Specifies the dilation rate to use for dilated convolution.");
+    TVM_ATTR_FIELD(groups).set_default(1).describe(
+        "Controls the connections between inputs and outputs."
+        "At groups=1, all inputs are convolved to all outputs."
+        "At groups=2, the operation becomes equivalent to having two convolution"
+        "layers side by side, each seeing half the input channels, and producing"
+        "half the output channels, and both subsequently concatenated.");
+    TVM_ATTR_FIELD(data_layout)
+        .set_default("NCW")
+        .describe(
+            "Dimension ordering of data. Can be 'NCW', 'NWC', etc."
+            "'N', 'C', 'W' stands for batch, channel, and width"
+            "dimensions respectively. Convolution is applied on the"
+            "'W' dimension.");
+    TVM_ATTR_FIELD(kernel_layout)
+        .set_default("OIW")
+        .describe(
+            "Dimension ordering of data and weight. Can be 'OIW', 'OIW16o16i', etc."
+            "'O', 'I', 'W' stands for num_filter, input_channel, and width"
+            "dimensions respectively.");
+    TVM_ATTR_FIELD(out_layout)
+        .set_default("")
+        .describe(
+            "Dimension ordering of output. Can be 'NCW', 'NWC', etc."
+            "'N', 'C', 'W' stands for batch, channel, and width"
+            "dimensions respectively. Default to be same as input layout.");
+    TVM_ATTR_FIELD(out_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Output data type, set to explicit type under mixed precision setting");
+  }
+};
+
+/*! \brief Attributes for max pool operator */
+struct MaxPool2DAttrs : public tvm::AttrsNode<MaxPool2DAttrs> {
+  Array<IndexExpr> pool_size;
+  Array<IndexExpr> strides;
+  Array<IndexExpr> padding;
+  Array<IndexExpr> dilation;
+  tvm::String layout;
+  tvm::String out_layout;
+  bool ceil_mode;
+
+  TVM_DECLARE_ATTRS(MaxPool2DAttrs, "relay.attrs.MaxPool2DAttrs") {
+    TVM_ATTR_FIELD(pool_size).describe("Size of the pooling windows.");
+    TVM_ATTR_FIELD(strides)
+        .set_default(Array<IndexExpr>({1, 1}))
+        .describe("Specifies the strides of the convolution.");
+    TVM_ATTR_FIELD(dilation)
+        .set_default(Array<IndexExpr>({1, 1}))
+        .describe("Specifies the dilation of the convolution.");
+    TVM_ATTR_FIELD(padding)
+        .set_default(Array<IndexExpr>({0, 0}))
+        .describe(
+            "If padding is non-zero, then the input is implicitly zero-padded"
+            "Padding support both symmetric and asymmetric as"
+            "one int : same padding used on all sides"
+            "two int : bottom, right will use same padding as top, left"
+            "four int : padding width in the order of (top, left, bottom, right)");
+    TVM_ATTR_FIELD(layout).set_default("NCHW").describe(
+        "Dimension ordering of input data. Can be 'NCHW', 'NHWC', etc."
+        "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+        "dimensions respectively. Pooling is applied on the 'H' and"
+        "'W' dimensions.");
+    TVM_ATTR_FIELD(out_layout)
+        .set_default("")
+        .describe(
+            "Dimension ordering of output data. Can be 'NCHW', 'NHWC', etc."
+            "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+            "dimensions respectively. Pooling is applied on the 'H' and"
+            "'W' dimensions.");
+    TVM_ATTR_FIELD(ceil_mode).set_default(false).describe(
+        "When true, will use ceil instead of floor to compute the output shape.");
+  }
+};
+
+/*! \brief Attributes for avg pool operator */
+struct AvgPool2DAttrs : public tvm::AttrsNode<AvgPool2DAttrs> {
+  Array<IndexExpr> pool_size;
+  Array<IndexExpr> strides;
+  Array<IndexExpr> padding;
+  Array<IndexExpr> dilation;
+  tvm::String layout;
+  tvm::String out_layout;
+  bool ceil_mode;
+  bool count_include_pad;
+
+  TVM_DECLARE_ATTRS(AvgPool2DAttrs, "relay.attrs.AvgPool2DAttrs") {
+    TVM_ATTR_FIELD(pool_size).describe("Size of the pooling windows.");
+    TVM_ATTR_FIELD(strides)
+        .set_default(Array<IndexExpr>({1, 1}))
+        .describe("Specifies the strides of the convolution.");
+    TVM_ATTR_FIELD(dilation)
+        .set_default(Array<IndexExpr>({1, 1}))
+        .describe("Specifies the dilation of the convolution.");
+    TVM_ATTR_FIELD(padding)
+        .set_default(Array<IndexExpr>({0, 0}))
+        .describe(
+            "If padding is non-zero, then the input is implicitly zero-padded"
+            "Padding support both symmetric and asymmetric as"
+            "one int : same padding used on all sides"
+            "two int : bottom, right will use same padding as top, left"
+            "four int : padding width in the order of (top, left, bottom, right)");
+    TVM_ATTR_FIELD(layout).set_default("NCHW").describe(
+        "Dimension ordering of input data. Can be 'NCHW', 'NHWC', etc."
+        "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+        "dimensions respectively. Pooling is applied on the 'H' and"
+        "'W' dimensions.");
+    TVM_ATTR_FIELD(out_layout)
+        .set_default("")
+        .describe(
+            "Dimension ordering of output data. Can be 'NCHW', 'NHWC', etc."
+            "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+            "dimensions respectively. Pooling is applied on the 'H' and"
+            "'W' dimensions.");
+    TVM_ATTR_FIELD(ceil_mode).set_default(false).describe(
+        "When true, will use ceil instead of floor to compute the output shape.");
+    TVM_ATTR_FIELD(count_include_pad)
+        .set_default(false)
+        .describe("When true, will include padding to compute the average");
+  }
+};
+
+/*! \brief Attributes for global pool operator */
+struct GlobalPool2DAttrs : public tvm::AttrsNode<GlobalPool2DAttrs> {
+  tvm::String layout;
+  tvm::String out_layout;
+
+  TVM_DECLARE_ATTRS(GlobalPool2DAttrs, "relay.attrs.GlobalPool2DAttrs") {
+    TVM_ATTR_FIELD(layout).set_default("NCHW").describe(
+        "Dimension ordering of input data. Can be 'NCHW', 'NHWC', etc."
+        "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+        "dimensions respectively. Pooling is applied on the 'H' and"
+        "'W' dimensions.");
+    TVM_ATTR_FIELD(out_layout)
+        .set_default("")
+        .describe(
+            "Dimension ordering of output data. Can be 'NCHW', 'NHWC', etc."
+            "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+            "dimensions respectively. Pooling is applied on the 'H' and"
+            "'W' dimensions.");
+  }
+};
+
+/*! \brief Attributes for 1d adaptive pool operator */
+struct AdaptivePool1DAttrs : public tvm::AttrsNode<AdaptivePool1DAttrs> {
+  Array<IndexExpr> output_size;
+  std::string layout;
+  tvm::String out_layout;
+
+  TVM_DECLARE_ATTRS(AdaptivePool1DAttrs, "relay.attrs.AdaptivePool1DAttrs") {
+    TVM_ATTR_FIELD(output_size).set_default(Array<IndexExpr>({})).describe("Output width.");
+    TVM_ATTR_FIELD(layout).set_default("NCW").describe(
+        "Dimension ordering of input data. Can be 'NCW', 'NWC', etc."
+        "'N', 'C', 'W' stands for batch, channel, and width"
+        "dimensions respectively. Pooling is applied on the"
+        "'W' dimension.");
+    TVM_ATTR_FIELD(out_layout)
+        .set_default("")
+        .describe(
+            "Dimension ordering of output data. Can be 'NCW', 'NWC', etc."
+            "'N', 'C', 'W' stands for batch, channel, and width"
+            "dimensions respectively. Pooling is applied on the"
+            "'W' dimension.");
+  }
+};
+
+/*! \brief Attributes for 2d adaptive pool operator */
+struct AdaptivePool2DAttrs : public tvm::AttrsNode<AdaptivePool2DAttrs> {
+  Array<IndexExpr> output_size;
+  std::string layout;
+  tvm::String out_layout;
+
+  TVM_DECLARE_ATTRS(AdaptivePool2DAttrs, "relay.attrs.AdaptivePool2DAttrs") {
+    TVM_ATTR_FIELD(output_size)
+        .set_default(Array<IndexExpr>({}))
+        .describe("Output height and width.");
+    TVM_ATTR_FIELD(layout).set_default("NCHW").describe(
+        "Dimension ordering of input data. Can be 'NCHW', 'NHWC', etc."
+        "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+        "dimensions respectively. Pooling is applied on the 'H' and"
+        "'W' dimensions.");
+    TVM_ATTR_FIELD(out_layout)
+        .set_default("")
+        .describe(
+            "Dimension ordering of output data. Can be 'NCHW', 'NHWC', etc."
+            "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+            "dimensions respectively. Pooling is applied on the 'H' and"
+            "'W' dimensions.");
+  }
+};
+
+/*! \brief Attributes for 3d adaptive pool operator */
+struct AdaptivePool3DAttrs : public tvm::AttrsNode<AdaptivePool3DAttrs> {
+  Array<IndexExpr> output_size;
+  std::string layout;
+  tvm::String out_layout;
+
+  TVM_DECLARE_ATTRS(AdaptivePool3DAttrs, "relay.attrs.AdaptivePool3DAttrs") {
+    TVM_ATTR_FIELD(output_size)
+        .set_default(Array<IndexExpr>({}))
+        .describe("Output depth, height and width.");
+    TVM_ATTR_FIELD(layout).set_default("NCDHW").describe(
+        "Dimension ordering of input data. Can be 'NCDHW', 'NDHWC', etc."
+        "'N', 'C', 'D', 'H', 'W' stands for batch, channel, depth, height, and width"
+        "dimensions respectively. Pooling is applied on 'D', 'H' and"
+        "'W' dimensions.");
+    TVM_ATTR_FIELD(out_layout)
+        .set_default("")
+        .describe(
+            "Dimension ordering of output data. Can be 'NCDHW', 'NDHWC', etc."
+            "'N', 'C', 'D', 'H', 'W' stands for batch, channel, depth, height, and width"
+            "dimensions respectively. Pooling is applied on 'D', 'H' and"
+            "'W' dimensions.");
+  }
+};
+
+/*! \brief Attributes for 1D max pool operator */
+struct MaxPool1DAttrs : public tvm::AttrsNode<MaxPool1DAttrs> {
+  Array<IndexExpr> pool_size;
+  Array<IndexExpr> strides;
+  Array<IndexExpr> dilation;
+  Array<IndexExpr> padding;
+  std::string layout;
+  tvm::String out_layout;
+  bool ceil_mode;
+
+  TVM_DECLARE_ATTRS(MaxPool1DAttrs, "relay.attrs.MaxPool1DAttrs") {
+    TVM_ATTR_FIELD(pool_size).describe("Size of the pooling windows.");
+    TVM_ATTR_FIELD(strides)
+        .set_default(Array<IndexExpr>({1}))
+        .describe("Specifies the strides of the convolution.");
+    TVM_ATTR_FIELD(dilation)
+        .set_default(Array<IndexExpr>({1}))
+        .describe("Specifies the dilation of the convolution.");
+    TVM_ATTR_FIELD(padding)
+        .set_default(Array<IndexExpr>({0}))
+        .describe(
+            "If padding is non-zero, then the input is implicitly zero-padded"
+            "Padding supports both symmetric and asymmetric as"
+            "one int : same padding used on each side"
+            "two int : indicates left padding, right padding");
+    TVM_ATTR_FIELD(layout).set_default("NCW").describe(
+        "Dimension ordering of input data. Can be 'NCW', 'NWC', etc."
+        "'N', 'C', 'W' stands for batch, channel, and width"
+        "dimensions respectively. Pooling is applied on the 'W' dimensions.");
+    TVM_ATTR_FIELD(out_layout)
+        .set_default("")
+        .describe(
+            "Dimension ordering of output data. Can be 'NCW', 'NWC', etc."
+            "'N', 'C', 'W' stands for batch, channel, and width"
+            "dimensions respectively. Pooling is applied on the 'W' dimensions.");
+    TVM_ATTR_FIELD(ceil_mode).set_default(false).describe(
+        "When true, will use ceil instead of floor to compute the output shape.");
+  }
+};
+
+/*! \brief Attributes for 1D avg pool operator */
+struct AvgPool1DAttrs : public tvm::AttrsNode<AvgPool1DAttrs> {
+  Array<IndexExpr> pool_size;
+  Array<IndexExpr> strides;
+  Array<IndexExpr> dilation;
+  Array<IndexExpr> padding;
+  std::string layout;
+  tvm::String out_layout;
+  bool ceil_mode;
+  bool count_include_pad;
+
+  TVM_DECLARE_ATTRS(AvgPool1DAttrs, "relay.attrs.AvgPool1DAttrs") {
+    TVM_ATTR_FIELD(pool_size).describe("Size of the pooling windows.");
+    TVM_ATTR_FIELD(strides)
+        .set_default(Array<IndexExpr>({1}))
+        .describe("Specifies the strides of the convolution.");
+    TVM_ATTR_FIELD(dilation)
+        .set_default(Array<IndexExpr>({1}))
+        .describe("Specifies the dilation of the convolution.");
+    TVM_ATTR_FIELD(padding)
+        .set_default(Array<IndexExpr>({0}))
+        .describe(
+            "If padding is non-zero, then the input is implicitly zero-padded"
+            "Padding supports both symmetric and asymmetric as"
+            "one int : same padding used on each side"
+            "two int : indicates left padding, right padding");
+    TVM_ATTR_FIELD(layout).set_default("NCW").describe(
+        "Dimension ordering of input data. Can be 'NCW', 'NHC', etc."
+        "'N', 'C', 'W' stands for batch, channel, and width"
+        "dimensions respectively. Pooling is applied on the 'W' dimension.");
+    TVM_ATTR_FIELD(out_layout)
+        .set_default("")
+        .describe(
+            "Dimension ordering of output data. Can be 'NCW', 'NHC', etc."
+            "'N', 'C', 'W' stands for batch, channel, and width"
+            "dimensions respectively. Pooling is applied on the 'W' dimension.");
+    TVM_ATTR_FIELD(ceil_mode).set_default(false).describe(
+        "When true, will use ceil instead of floor to compute the output shape.");
+    TVM_ATTR_FIELD(count_include_pad)
+        .set_default(false)
+        .describe("When true, will include padding to compute the average");
+  }
+};
+
+/*! \brief Attributes for 3D max pool operator */
+struct MaxPool3DAttrs : public tvm::AttrsNode<MaxPool3DAttrs> {
+  Array<IndexExpr> pool_size;
+  Array<IndexExpr> strides;
+  Array<IndexExpr> dilation;
+  Array<IndexExpr> padding;
+  std::string layout;
+  tvm::String out_layout;
+  bool ceil_mode;
+
+  TVM_DECLARE_ATTRS(MaxPool3DAttrs, "relay.attrs.MaxPool3DAttrs") {
+    TVM_ATTR_FIELD(pool_size).describe("Size of the pooling windows.");
+    TVM_ATTR_FIELD(strides)
+        .set_default(Array<IndexExpr>({1, 1, 1}))
+        .describe("Specifies the strides of the convolution.");
+    TVM_ATTR_FIELD(dilation)
+        .set_default(Array<IndexExpr>({1, 1, 1}))
+        .describe("Specifies the dilation of the convolution.");
+    TVM_ATTR_FIELD(padding)
+        .set_default(Array<IndexExpr>({0, 0, 0}))
+        .describe(
+            "If padding is non-zero, then the input is implicitly zero-padded"
+            "Padding support both symmetric and asymmetric as"
+            "one int : same padding used on all sides"
+            "three int : back, bottom, right will use same padding as front, top, left"
+            "six int : padding width in the order of (front, top, left, back, bottom, right)");
+    TVM_ATTR_FIELD(layout).set_default("NCDHW").describe(
+        "Dimension ordering of input data. Can be 'NCDHW', 'NDHWC', etc."
+        "'N', 'C', 'D', 'H', 'W' stands for batch, channel, depth, height, and width"
+        "dimensions respectively. Pooling is applied on the 'D', 'H' and"
+        "'W' dimensions.");
+    TVM_ATTR_FIELD(out_layout)
+        .set_default("")
+        .describe(
+            "Dimension ordering of output data. Can be 'NCDHW', 'NDHWC', etc."
+            "'N', 'C', 'D', 'H', 'W' stands for batch, channel, depth, height, and width"
+            "dimensions respectively. Pooling is applied on the 'D', 'H' and"
+            "'W' dimensions.");
+    TVM_ATTR_FIELD(ceil_mode).set_default(false).describe(
+        "When true, will use ceil instead of floor to compute the output shape.");
+  }
+};
+
+/*! \brief Attributes for 3D avg pool operator */
+struct AvgPool3DAttrs : public tvm::AttrsNode<AvgPool3DAttrs> {
+  Array<IndexExpr> pool_size;
+  Array<IndexExpr> strides;
+  Array<IndexExpr> dilation;
+  Array<IndexExpr> padding;
+  std::string layout;
+  tvm::String out_layout;
+  bool ceil_mode;
+  bool count_include_pad;
+
+  TVM_DECLARE_ATTRS(AvgPool3DAttrs, "relay.attrs.AvgPool3DAttrs") {
+    TVM_ATTR_FIELD(pool_size).describe("Size of the pooling windows.");
+    TVM_ATTR_FIELD(strides)
+        .set_default(Array<IndexExpr>({1, 1, 1}))
+        .describe("Specifies the strides of the convolution.");
+    TVM_ATTR_FIELD(dilation)
+        .set_default(Array<IndexExpr>({1, 1, 1}))
+        .describe("Specifies the dilation of the convolution.");
+    TVM_ATTR_FIELD(padding)
+        .set_default(Array<IndexExpr>({0, 0, 0}))
+        .describe(
+            "If padding is non-zero, then the input is implicitly zero-padded"
+            "Padding support both symmetric and asymmetric as"
+            "one int : same padding used on all sides"
+            "three int : back, bottom, right will use same padding as front, top, left"
+            "six int : padding width in the order of (front, top, left, back, bottom, right)");
+    TVM_ATTR_FIELD(layout).set_default("NCDHW").describe(
+        "Dimension ordering of input data. Can be 'NCDHW', 'NDHWC', etc."
+        "'N', 'C', 'D', 'H', 'W' stands for batch, channel, depth, height, and width"
+        "dimensions respectively. Pooling is applied on the 'D', 'H' and"
+        "'W' dimensions.");
+    TVM_ATTR_FIELD(out_layout)
+        .set_default("")
+        .describe(
+            "Dimension ordering of output data. Can be 'NCDHW', 'NDHWC', etc."
+            "'N', 'C', 'D', 'H', 'W' stands for batch, channel, depth, height, and width"
+            "dimensions respectively. Pooling is applied on the 'D', 'H' and"
+            "'W' dimensions.");
+    TVM_ATTR_FIELD(ceil_mode).set_default(false).describe(
+        "When true, will use ceil instead of floor to compute the output shape.");
+    TVM_ATTR_FIELD(count_include_pad)
+        .set_default(false)
+        .describe("When true, will include padding to compute the average");
+  }
+};
+
+/*! \brief Attributes for matmul operator */
+struct MatmulAttrs : public tvm::AttrsNode<MatmulAttrs> {
+  IndexExpr units;
+  DataType out_dtype;
+  bool transpose_a;
+  bool transpose_b;
+  // layout of B after auto-scheduler's layout rewrite
+  tvm::String auto_scheduler_rewritten_layout;
+  Array<PrimExpr> meta_schedule_original_shape;  // The original shape of the weights
+
+  TVM_DECLARE_ATTRS(MatmulAttrs, "relay.attrs.MatmulAttrs") {
+    TVM_ATTR_FIELD(units).describe("Number of hidden units of the dense transformation.");
+
+    // use 0 bits to indicate none.
+    TVM_ATTR_FIELD(out_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Output data type, set to explicit type under mixed precision setting");
+
+    TVM_ATTR_FIELD(transpose_a)
+        .set_default(false)
+        .describe("Whether the first input tensor is in transposed format.");
+
+    TVM_ATTR_FIELD(transpose_b)
+        .set_default(false)
+        .describe("Whether the second input tensor is in transposed format.");
+  }
+};
+
+/*! \brief Attributes for dense operator */
+struct DenseAttrs : public tvm::AttrsNode<DenseAttrs> {
+  IndexExpr units;
+  // layout of B after auto-scheduler's layout rewrite
+  tvm::String auto_scheduler_rewritten_layout;
+  Array<PrimExpr> meta_schedule_original_shape;  // The original shape of the weights
+  DataType out_dtype;
+
+  TVM_DECLARE_ATTRS(DenseAttrs, "relay.attrs.DenseAttrs") {
+    TVM_ATTR_FIELD(units).describe("Number of hidden units of the dense transformation.");
+
+    // use 0 bits to indicate none.
+    TVM_ATTR_FIELD(out_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Output data type, set to explicit type under mixed precision setting");
+  }
+};
+
+/*! \brief Attributes for dense_pack operator */
+struct DensePackAttrs : public tvm::AttrsNode<DensePackAttrs> {
+  IndexExpr units;
+  DataType out_dtype;
+  tvm::String weight_layout;
+
+  TVM_DECLARE_ATTRS(DensePackAttrs, "relay.attrs.DensePackAttrs") {
+    TVM_ATTR_FIELD(units).describe("Number of hidden units of the dense transformation.");
+
+    // use 0 bits to indicate none.
+    TVM_ATTR_FIELD(out_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Output data type, set to explicit type under mixed precision setting");
+    TVM_ATTR_FIELD(weight_layout)
+        .set_default("NC")
+        .describe("Dimension ordering of weight. Packed layouts, such as NC8n, are possible.");
+  }
+};
+
+/*! \brief Attributes for batch matmul operator. */
+struct BatchMatmulAttrs : public tvm::AttrsNode<BatchMatmulAttrs> {
+  DataType out_dtype;
+  bool transpose_a;
+  bool transpose_b;
+  tvm::String auto_scheduler_rewritten_layout;   // The layout after auto-scheduler's layout rewrite
+  Array<PrimExpr> meta_schedule_original_shape;  // The original shape of the weights
+
+  TVM_DECLARE_ATTRS(BatchMatmulAttrs, "relay.attrs.BatchMatmulAttrs") {
+    // use 0 bits to indicate none.
+    TVM_ATTR_FIELD(out_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Output data type, set to explicit type under mixed precision setting");
+
+    TVM_ATTR_FIELD(transpose_a)
+        .set_default(false)
+        .describe("Whether the first input tensor is in transposed format.");
+
+    TVM_ATTR_FIELD(transpose_b)
+        .set_default(false)
+        .describe("Whether the second input tensor is in transposed format.");
+  }
+};
+
+/*! \brief Attributes for sparse_dense operator */
+struct SparseDenseAttrs : public tvm::AttrsNode<SparseDenseAttrs> {
+  bool sparse_lhs;
+
+  TVM_DECLARE_ATTRS(SparseDenseAttrs, "relay.attrs.SparseDenseAttrs") {
+    TVM_ATTR_FIELD(sparse_lhs)
+        .set_default(false)
+        .describe(
+            "Indicate whether sparse matrix is multiplied on the right or the left. If true, then "
+            "the operation is S * D^T (D dense, S sparse). If false, the operation is D * S^T");
+  }
+};
+
+/*! \brief Attributes for sparse_transpose operator */
+struct SparseTransposeAttrs : public tvm::AttrsNode<SparseTransposeAttrs> {
+  TVM_DECLARE_ATTRS(SparseTransposeAttrs, "relay.attrs.SparseTransposeAttrs") {}
+};
+
+/*! \brief Attributes for sparse_dense operator */
+struct SparseConv2DAttrs : public tvm::AttrsNode<SparseConv2DAttrs> {
+  std::string layout;
+  Array<IndexExpr> kernel_size;
+
+  TVM_DECLARE_ATTRS(SparseConv2DAttrs, "relay.attrs.SparseConv2DAttrs") {
+    TVM_ATTR_FIELD(layout).set_default("NHWC").describe(
+        "Dimension ordering of input data. Can be 'NCHW', 'NHWC'"
+        "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+        "dimensions respectively.");
+    TVM_ATTR_FIELD(kernel_size)
+        .set_default(Array<IndexExpr>{1, 1})
+        .describe("Kernel size for SparseConv2D, 1x1 or 3x3. ");
+  }
+};
+
+/*! \brief Attributes for FIFO buffer operator */
+struct FIFOBufferAttrs : public tvm::AttrsNode<FIFOBufferAttrs> {
+  int axis;
+
+  TVM_DECLARE_ATTRS(FIFOBufferAttrs, "relay.attrs.FIFOBufferAttrs") {
+    TVM_ATTR_FIELD(axis).set_default(0);
+  }
+};
+
+/*! \brief Attributes for upsampling operator */
+struct UpSamplingAttrs : public tvm::AttrsNode<UpSamplingAttrs> {
+  double scale_h;
+  double scale_w;
+  tvm::String layout;
+  tvm::String method;
+  bool align_corners;
+
+  TVM_DECLARE_ATTRS(UpSamplingAttrs, "relay.attrs.UpSamplingAttrs") {
+    TVM_ATTR_FIELD(scale_h).describe("The upsampling factor for height");
+    TVM_ATTR_FIELD(scale_w).describe("The upsampling factor for width");
+    TVM_ATTR_FIELD(layout).set_default("NCHW").describe(
+        "Dimension ordering of input data. Can be 'NCHW', 'NHWC', etc."
+        "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+        "dimensions respectively. Upsampling is applied on the 'H' and"
+        "'W' dimensions.");
+    TVM_ATTR_FIELD(method)
+        .set_default("nearest_neighbor")
+        .describe(
+            "Specify the mode to use for scaling."
+            "nearest_neighbor -  Nearest Neighbor"
+            "bilinear - Bilinear Interpolation"
+            "bicubic - Bicubic Interpolation");
+    TVM_ATTR_FIELD(align_corners)
+        .set_default(false)
+        .describe("Should be true to preserve the values at the corner pixels");
+  }
+};
+
+/*! \brief Attributes for upsampling3d operator */
+struct UpSampling3DAttrs : public tvm::AttrsNode<UpSampling3DAttrs> {
+  double scale_d;
+  double scale_h;
+  double scale_w;
+  std::string layout;
+  std::string method;
+  std::string coordinate_transformation_mode;
+
+  TVM_DECLARE_ATTRS(UpSampling3DAttrs, "relay.attrs.UpSampling3DAttrs") {
+    TVM_ATTR_FIELD(scale_d).describe("The upsampling factor for depth");
+    TVM_ATTR_FIELD(scale_h).describe("The upsampling factor for height");
+    TVM_ATTR_FIELD(scale_w).describe("The upsampling factor for width");
+    TVM_ATTR_FIELD(layout).set_default("NCDHW").describe(
+        "Dimension ordering of input data. Can be 'NCDHW', 'NDHWC', etc."
+        "'N', 'C', 'D', 'H', 'W' stands for batch, channel, depth, height, and width"
+        "dimensions respectively. Upsampling is applied on the 'D', 'H' and"
+        "'W' dimensions.");
+    TVM_ATTR_FIELD(method)
+        .set_default("nearest_neighbor")
+        .describe(
+            "Specify the mode to use for scaling."
+            "nearest_neighbor -  Nearest Neighbor"
+            "trilinear - Trilinear Interpolation");
+    TVM_ATTR_FIELD(coordinate_transformation_mode)
+        .set_default("half_pixel")
+        .describe(
+            "Describes how to transform the coordinate in the resized tensor"
+            "to the coordinate in the original tensor."
+            "Refer to the ONNX Resize operator specification for details"
+            "Available options are half_pixel, align_corners and asymmetric");
+  }
+};
+
+/*! \brief Attributes used for the padding operator */
+struct PadAttrs : public tvm::AttrsNode<PadAttrs> {
+  Array<Array<Integer>> pad_width;
+  tvm::String pad_mode;
+
+  TVM_DECLARE_ATTRS(PadAttrs, "relay.attrs.PadAttrs") {
+    TVM_ATTR_FIELD(pad_width).describe(
+        "Number of values padded to the edges of each axis, "
+        "in the format of ((before_1, after_1), ..., (before_N, after_N))");
+    TVM_ATTR_FIELD(pad_mode)
+        .set_default("constant")
+        .describe(
+            "Padding type to use. \"constant\" pads with constant_value, "
+            "\"edge\" pads using the edge values of the input array, "
+            "\"reflect\" pads by reflecting values with respect to the edges.");
+  }
+};
+
+/*! \brief Attributes used for the MirrorPadding operator */
+struct MirrorPadAttrs : public tvm::AttrsNode<MirrorPadAttrs> {
+  std::string mode;
+  Array<Array<IndexExpr>> pad_width;
+
+  TVM_DECLARE_ATTRS(MirrorPadAttrs, "relay.attrs.MirrorPadAttrs") {
+    TVM_ATTR_FIELD(mode)
+        .set_default("SYMMETRIC")
+        .describe("Specifies how mirroring should be performed.");
+    TVM_ATTR_FIELD(pad_width).describe(
+        "Number of values padded to the edges of each axis, "
+        "in the format of ((before_1, after_1), ..., (before_N, after_N))");
+  }
+};
+
+/*! \brief Attributes for leaky relu operator */
+struct LeakyReluAttrs : public tvm::AttrsNode<LeakyReluAttrs> {
+  double alpha;
+
+  TVM_DECLARE_ATTRS(LeakyReluAttrs, "relay.attrs.LeakyReluAttrs") {
+    TVM_ATTR_FIELD(alpha).set_lower_bound(0.0).set_default(0.25).describe(
+        "Slope coefficient for the negative half axis.");
+  }
+};
+
+/*! \brief Attributes for prelu operator */
+struct PReluAttrs : public tvm::AttrsNode<PReluAttrs> {
+  int axis;
+
+  TVM_DECLARE_ATTRS(PReluAttrs, "relay.attrs.PReluAttrs") {
+    TVM_ATTR_FIELD(axis).set_default(1).describe(
+        "Specify which shape axis the channel is specified.");
+  }
+};
+
+/*! \brief Attributes used in dropout operator */
+struct DropoutAttrs : public tvm::AttrsNode<DropoutAttrs> {
+  double rate;
+  TVM_DECLARE_ATTRS(DropoutAttrs, "relay.attrs.DropoutAttrs") {
+    TVM_ATTR_FIELD(rate)
+        .describe("Fraction of the input that gets dropped out during training time")
+        .set_default(0.5);
+  }
+};  // struct DropoutAttrs
+
+/*! \brief Attributes used in batch_norm operator */
+struct BatchNormAttrs : public tvm::AttrsNode<BatchNormAttrs> {
+  int axis;
+  double epsilon;
+  bool center;
+  bool scale;
+
+  TVM_DECLARE_ATTRS(BatchNormAttrs, "relay.attrs.BatchNormAttrs") {
+    TVM_ATTR_FIELD(axis).describe("Specify which shape axis denotes the channel.").set_default(1);
+    TVM_ATTR_FIELD(epsilon)
+        .describe("Small float added to variance to avoid dividing by zero")
+        .set_default(1e-5);
+    TVM_ATTR_FIELD(center)
+        .describe("If True, add offset of beta to normalized tensor. If False, beta is ignored")
+        .set_default(true);
+    TVM_ATTR_FIELD(scale)
+        .describe(
+            "If True, multiply by gamma. If False, gamma is not used. "
+            "When the next layer is piecewise linear (also, e.g., nn.relu), "
+            "this can be disabled since the scaling will be done by the next layer.")
+        .set_default(true);
+  }
+};  // struct BatchNormAttrs
+
+/*! \brief Attributes used in instance_norm operator */
+struct InstanceNormAttrs : public tvm::AttrsNode<InstanceNormAttrs> {
+  int axis;
+  double epsilon;
+  bool center;
+  bool scale;
+
+  TVM_DECLARE_ATTRS(InstanceNormAttrs, "relay.attrs.InstanceNormAttrs") {
+    TVM_ATTR_FIELD(axis).describe("Specify which shape axis denotes the channel.").set_default(1);
+    TVM_ATTR_FIELD(epsilon)
+        .describe("Small float added to variance to avoid dividing by zero")
+        .set_default(1e-5);
+    TVM_ATTR_FIELD(center).set_default(true).describe(
+        "If true, add offset of beta to normalized tensor; "
+        "otherwise, beta is ignored.");
+    TVM_ATTR_FIELD(scale).set_default(true).describe(
+        "If true, multiply by gamma; otherwise, gamma is ignored.");
+  }
+};  // struct InstanceNormAttrs
+
+/*! \brief Attributes used in layer_norm operator */
+struct LayerNormAttrs : public tvm::AttrsNode<LayerNormAttrs> {
+  int axis;
+  double epsilon;
+  bool center;
+  bool scale;
+
+  TVM_DECLARE_ATTRS(LayerNormAttrs, "relay.attrs.LayerNormAttrs") {
+    TVM_ATTR_FIELD(axis).set_default(-1).describe("Specify which shape axis denotes the channel.");
+    TVM_ATTR_FIELD(epsilon).set_default(1e-5).describe(
+        "Small float added to variance to avoid dividing by zero");
+    TVM_ATTR_FIELD(center).set_default(true).describe(
+        "If true, add offset of beta to normalized tensor; "
+        "otherwise, beta is ignored.");
+    TVM_ATTR_FIELD(scale).set_default(true).describe(
+        "If true, multiply by gamma; otherwise, gamma is ignored.");
+  }
+};  // struct LayerNormAttrs
+
+/*! \brief Attributes used in group_norm operator */
+struct GroupNormAttrs : public tvm::AttrsNode<GroupNormAttrs> {
+  int num_groups;
+  int axis;
+  double epsilon;
+  bool center;
+  bool scale;
+
+  TVM_DECLARE_ATTRS(GroupNormAttrs, "relay.attrs.GroupNormAttrs") {
+    TVM_ATTR_FIELD(num_groups)
+        .set_default(0)
+        .describe("Specify number of groups to separate the channels into.");
+    TVM_ATTR_FIELD(axis).set_default(1).describe("Specify which shape axis denotes the channel.");
+    TVM_ATTR_FIELD(epsilon).set_default(1e-5).describe(
+        "Small float added to variance to avoid dividing by zero");
+    TVM_ATTR_FIELD(center).set_default(true).describe(
+        "If true, add offset of beta to normalized tensor; "
+        "otherwise, beta is ignored.");
+    TVM_ATTR_FIELD(scale).set_default(true).describe(
+        "If true, multiply by gamma; otherwise, gamma is ignored.");
+  }
+};  // struct GroupNormAttrs
+
+/*! \brief Attributes for LRN operator */
+struct LRNAttrs : public tvm::AttrsNode<LRNAttrs> {
+  int size;
+  int axis;
+  double bias;
+  double alpha;
+  double beta;
+
+  TVM_DECLARE_ATTRS(LRNAttrs, "relay.attrs.LRNAttrs") {
+    TVM_ATTR_FIELD(size).set_default(5).describe(
+        "The size of the local region to be considered for normalization.");
+    TVM_ATTR_FIELD(axis).set_default(1).describe("Axis of input data layout channel.");
+    TVM_ATTR_FIELD(bias).set_default(2).describe("The offset parameter to avoid division by 0.");
+    TVM_ATTR_FIELD(alpha).set_default(0.0001).describe("The scaling parameter.");
+    TVM_ATTR_FIELD(beta).set_default(0.75).describe("The exponent parameter.");
+  }
+};
+
+/*! \brief Attributes for L2Normalize operator */
+struct L2NormalizeAttrs : public tvm::AttrsNode<L2NormalizeAttrs> {
+  double eps;
+  Array<Integer> axis;
+
+  TVM_DECLARE_ATTRS(L2NormalizeAttrs, "relay.attrs.L2NormalizeAttrs") {
+    TVM_ATTR_FIELD(eps).describe("A lower bound value for the norm, to avoid division by 0.");
+    TVM_ATTR_FIELD(axis).describe("Axis over the normalization applied.");
+  }
+};
+
+/*! \brief Attributes for DeformableConv2D operator */
+struct DeformableConv2DAttrs : public tvm::AttrsNode<DeformableConv2DAttrs> {
+  Array<IndexExpr> strides;
+  Array<IndexExpr> padding;
+  Array<IndexExpr> dilation;
+  int deformable_groups;
+  int groups;
+  IndexExpr channels;
+  Array<IndexExpr> kernel_size;
+  std::string data_layout;
+  std::string kernel_layout;
+  std::string out_layout;
+  DataType out_dtype;
+
+  TVM_DECLARE_ATTRS(DeformableConv2DAttrs, "relay.attrs.DeformableConv2DAttrs") {
+    TVM_ATTR_FIELD(strides)
+        .set_default(Array<IndexExpr>({1, 1}))
+        .describe("Specifies the strides of the convolution.");
+    TVM_ATTR_FIELD(padding)
+        .set_default(Array<IndexExpr>({0, 0}))
+        .describe(
+            "If padding is non-zero, then the input is implicitly zero-padded"
+            "Padding support both symmetric and asymmetric as"
+            "one int : same padding used on all sides"
+            "two int : bottom, right will use same padding as top, left"
+            "four int : padding width in the order of (top, left, bottom, right)");
+    TVM_ATTR_FIELD(dilation)
+        .set_default(Array<IndexExpr>({1, 1}))
+        .describe("Specifies the dilation rate to use for dilated convolution.");
+    TVM_ATTR_FIELD(deformable_groups)
+        .set_default(1)
+        .describe(
+            "Controls the connections between inputs and offsets."
+            "Input channels are partitioned into multiple deformable groups. Offsets"
+            "are shared across input channels in the same deformable group.");
+    TVM_ATTR_FIELD(groups).set_default(1).describe(
+        "Controls the connections between inputs and outputs."
+        "At groups=1, all inputs are convolved to all outputs."
+        "At groups=2, the operation becomes equivalent to having two convolution"
+        "layers side by side, each seeing half the input channels, and producing"
+        "half the output channels, and both subsequently concatenated.");
+    TVM_ATTR_FIELD(channels)
+        .describe(
+            "The number of output channels in the convolution."
+            " If it is not set, inferred by shape of the weight.")
+        .set_default(NullValue<IndexExpr>());
+    TVM_ATTR_FIELD(kernel_size)
+        .describe("Specifies the dimensions of the convolution window.")
+        .set_default(NullValue<Array<IndexExpr>>());
+    TVM_ATTR_FIELD(data_layout)
+        .set_default("NCHW")
+        .describe(
+            "Dimension ordering of input data. Can be 'NCHW', 'NHWC', etc."
+            "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+            "dimensions respectively. Convolution is applied on the 'H' and"
+            "'W' dimensions.");
+    TVM_ATTR_FIELD(kernel_layout)
+        .set_default("OIHW")
+        .describe(
+            "Dimension ordering of weight. Can be 'OIHW', 'OIHW16o16i', etc."
+            "'O', 'I', 'H', 'W' stands for num_filter, input_channel, height, and width"
+            "dimensions respectively.");
+    TVM_ATTR_FIELD(out_layout)
+        .set_default("")
+        .describe(
+            "Dimension ordering of output. Can be 'NCHW', 'NHWC', etc."
+            "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+            "dimensions respectively. Default to be same as input layout.");
+
+    // use 0 bits to indicate none.
+    TVM_ATTR_FIELD(out_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Output data type, set to explicit type under mixed precision setting");
+  }
+};
+
+/*! \brief Attributes used in subpixel operators */
+struct SubPixelAttrs : public tvm::AttrsNode<SubPixelAttrs> {
+  int block_size;
+  std::string layout;
+  std::string mode;
+
+  TVM_DECLARE_ATTRS(SubPixelAttrs, "relay.attrs.SubPixelAttrs") {
+    TVM_ATTR_FIELD(block_size)
+        .describe("The size of subpixel blocks to compose or decompose.")
+        .set_default(1);
+    TVM_ATTR_FIELD(layout).set_default("NCHW").describe(
+        "Dimension ordering of input data. Can be 'NCHW', 'NHWC', etc."
+        "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+        "dimensions respectively.");
+    TVM_ATTR_FIELD(mode).set_default("DCR").describe(
+        "Indicates order in which channels are accessed. Must be one of"
+        "DCR or CDR.");
+  }
+};  // struct SubPixelAttrs
+
+/*! \brief Attributes used in correlation operators */
+struct CorrelationAttrs : public tvm::AttrsNode<CorrelationAttrs> {
+  int kernel_size;
+  int max_displacement;
+  int stride1;
+  int stride2;
+  Array<IndexExpr> padding;
+  bool is_multiply;
+  String layout;
+
+  TVM_DECLARE_ATTRS(CorrelationAttrs, "relay.attrs.CorrelationAttrs") {
+    TVM_ATTR_FIELD(kernel_size)
+        .describe("Kernel size for correlation, must be an odd number.")
+        .set_default(1);
+    TVM_ATTR_FIELD(max_displacement).describe("Max displacement of Correlation.").set_default(1);
+    TVM_ATTR_FIELD(stride1).describe("Stride for data1.").set_default(1);
+    TVM_ATTR_FIELD(stride2).describe("Stride for data2.").set_default(1);
+    TVM_ATTR_FIELD(padding)
+        .describe("Padding for data1 and data2.")
+        .set_default(Array<IndexExpr>{0, 0});
+    TVM_ATTR_FIELD(is_multiply)
+        .describe("Operation type is either multiplication or substraction.")
+        .set_default(true);
+    TVM_ATTR_FIELD(layout).set_default("NCHW").describe(
+        "Dimension ordering of input data. Can be 'NCHW', 'NHWC', etc."
+        "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+        "dimensions respectively.");
+  }
+};  // struct CorrelationAttrs
+
+/*! \brief Attributes used in SpaceToBatchND operator */
+struct SpaceToBatchNDAttrs : public tvm::AttrsNode<SpaceToBatchNDAttrs> {
+  Array<Integer> block_shape;
+  Array<Array<IndexExpr>> paddings;
+  double pad_value;
+
+  TVM_DECLARE_ATTRS(SpaceToBatchNDAttrs, "relay.attrs.SpaceToBatchNDAttrs") {
+    TVM_ATTR_FIELD(block_shape)
+        .set_default(Array<Integer>({1, 1}))
+        .describe("1-D containing block size for each spatial dimension.");
+    TVM_ATTR_FIELD(paddings).describe("2-D containing paddings for each spatial dimension.");
+    TVM_ATTR_FIELD(pad_value).set_default(0.0).describe("The value used for padding.");
+  }
+};  // struct SpaceToBatchNDAttrs
+
+/*! \brief Attributes used in BatchToSpaceND operator */
+struct BatchToSpaceNDAttrs : public tvm::AttrsNode<BatchToSpaceNDAttrs> {
+  Array<Integer> block_shape;
+  Array<Array<IndexExpr>> crops;
+
+  TVM_DECLARE_ATTRS(BatchToSpaceNDAttrs, "relay.attrs.BatchToSpaceNDAttrs") {
+    TVM_ATTR_FIELD(block_shape)
+        .set_default(Array<Integer>({1, 1}))
+        .describe("1-D containing block size for each spatial dimension.");
+    TVM_ATTR_FIELD(crops).describe("2-D containing amount to crop from spatial dimension.");
+  }
+};  // struct BatchToSpaceNDAttrs
+
+/*! \brief Attributes used in NLLLoss operator */
+struct NLLLossAttrs : public tvm::AttrsNode<NLLLossAttrs> {
+  std::string reduction;
+  int ignore_index;
+
+  TVM_DECLARE_ATTRS(NLLLossAttrs, "relay.attrs.NLLLossAttrs") {
+    TVM_ATTR_FIELD(reduction).set_default("mean").describe(
+        "The reduction method to apply to the output. Can be"
+        "'none', 'mean' or 'sum'.");
+    TVM_ATTR_FIELD(ignore_index).describe("The target value to ignore.");
+  }
+};  // struct NLLLossAttrs
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_ATTRS_NN_H_
diff --git a/darknet_drp_ros/include/tvm/relay/attrs/on_device.h b/darknet_drp_ros/include/tvm/relay/attrs/on_device.h
new file mode 100644
index 0000000..3facc3a
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/attrs/on_device.h
@@ -0,0 +1,106 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/attrs/on_device.h
+ * \brief Attribute for the "on_device" annotation (ie operator).
+ */
+#ifndef TVM_RELAY_ATTRS_ON_DEVICE_H_
+#define TVM_RELAY_ATTRS_ON_DEVICE_H_
+
+#include <tvm/ir/attrs.h>
+#include <tvm/target/virtual_device.h>
+
+#include <string>
+
+namespace tvm {
+namespace relay {
+
+/*!
+ * \brief Attributes for the "on_device" annotation (ie operator).
+ *
+ * The Relay call:
+ * \code
+ *   on_device(sub_expr, virtual_device=S)
+ * \endcode
+ * constrains \p sub_expr to execute and store its result on the \p VirtualDevice \p S.
+ * However the annotation itself may appear in an expression to be executed and stored on a
+ * different \p VirtualDevice. If so the compiler will automatically insert a "device_copy" call to
+ * mediate the transition between \p VirtualDevices.
+ *
+ * E.g.: Assuming %x and %y reside on the GPU and %z on the CPU then:
+ * \code
+ *   multiply(on_device(add(%x, %y), virtual_device=GPU), %z)
+ * \endcode
+ * indicates the \p add should execute on the GPU but the \p multiply should execute on the CPU.
+ * The compiler will rewrite this to:
+ * \code
+ *   multiply(device_copy(add(%x, %y), src_virtual_device=GPU, dst_virtual_device=CPU), %z)
+ * \endcode
+ *
+ * The \p constraint_body (default true) and \p constraint_result (default false) fields can be
+ * used by passes for finer-grained control over how the \p VirtualDevice constraint should be
+ * applied.
+ */
+struct OnDeviceAttrs : public tvm::AttrsNode<OnDeviceAttrs> {
+  /*!
+   * \brief The \p VirtualDevice to constraint to apply to the body, result, or both body and result
+   * of the "on_device" call.
+   */
+  VirtualDevice virtual_device = VirtualDevice::FullyUnconstrained();
+
+  /*!
+   * \brief If false (the default), the result of the "on_device" call is not constrained to be
+   * \p virtual_device.
+   */
+  bool constrain_result = false;
+
+  /*!
+   * \brief If true (the default), the body of the "on_device" call is constrained to be \p
+   * virtual_device.
+   */
+  bool constrain_body = true;
+
+  /*!
+   * \brief Returns true if both the body and result are constrained.
+   */
+  bool is_fixed() const { return constrain_result && constrain_body; }
+
+  /*!
+   * \brief Returns true only the body is constrained (the 'normal' case).
+   */
+  bool is_normal() const { return !constrain_result && constrain_body; }
+
+  TVM_DECLARE_ATTRS(OnDeviceAttrs, "relay.attrs.OnDeviceAttrs") {
+    TVM_ATTR_FIELD(virtual_device)
+        .describe("The (virtual) device to constrain to.")
+        .set_default(VirtualDevice::FullyUnconstrained());
+    TVM_ATTR_FIELD(constrain_result)
+        .describe("Whether the constraint applies to the overall expression")
+        .set_default(false);
+    TVM_ATTR_FIELD(constrain_body)
+        .describe("Whether the constraint applies to the body sub-expression.")
+        .set_default(true);
+  }
+};
+
+}  // namespace relay
+}  // namespace tvm
+
+#endif  // TVM_RELAY_ATTRS_ON_DEVICE_H_
diff --git a/darknet_drp_ros/include/tvm/relay/attrs/random.h b/darknet_drp_ros/include/tvm/relay/attrs/random.h
new file mode 100644
index 0000000..4bdac4c
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/attrs/random.h
@@ -0,0 +1,76 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/attrs/vision.h
+ * \brief Auxiliary attributes for random operators.
+ */
+#ifndef TVM_RELAY_ATTRS_RANDOM_H_
+#define TVM_RELAY_ATTRS_RANDOM_H_
+
+#include <tvm/ir/attrs.h>
+
+namespace tvm {
+namespace relay {
+
+struct ThreefryGenerateAttrs : public tvm::AttrsNode<ThreefryGenerateAttrs> {
+  Array<Integer> out_shape;
+
+  TVM_DECLARE_ATTRS(ThreefryGenerateAttrs, "relay.attrs.ThreefryGenerateAttrs") {
+    TVM_ATTR_FIELD(out_shape).describe("Shape of random numbers to generate");
+  }
+};
+
+struct UniformAttrs : public tvm::AttrsNode<UniformAttrs> {
+  Array<Integer> out_shape;
+  DataType out_dtype;
+
+  TVM_DECLARE_ATTRS(UniformAttrs, "relay.attrs.UniformAttrs") {
+    TVM_ATTR_FIELD(out_shape).describe("Shape of random numbers to generate");
+    TVM_ATTR_FIELD(out_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Data type of the generated numbers");
+  }
+};
+
+struct NormalAttrs : public tvm::AttrsNode<NormalAttrs> {
+  Array<Integer> out_shape;
+  DataType out_dtype;
+
+  TVM_DECLARE_ATTRS(NormalAttrs, "relay.attrs.NormalAttrs") {
+    TVM_ATTR_FIELD(out_shape).describe("Shape of random numbers to generate");
+    TVM_ATTR_FIELD(out_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Data type of the generated numbers");
+  }
+};
+
+struct MultinomialAttrs : public tvm::AttrsNode<MultinomialAttrs> {
+  Integer num_samples;
+
+  TVM_DECLARE_ATTRS(MultinomialAttrs, "relay.attrs.MultinomialAttrs") {
+    TVM_ATTR_FIELD(num_samples)
+        .set_default(1)
+        .describe("Number of samples to draw from the distribution.");
+  }
+};
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_ATTRS_RANDOM_H_
diff --git a/darknet_drp_ros/include/tvm/relay/attrs/reduce.h b/darknet_drp_ros/include/tvm/relay/attrs/reduce.h
new file mode 100644
index 0000000..d91b359
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/attrs/reduce.h
@@ -0,0 +1,132 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/attrs/reduce.h
+ * \brief Auxiliary attributes for reduce operators.
+ */
+#ifndef TVM_RELAY_ATTRS_REDUCE_H_
+#define TVM_RELAY_ATTRS_REDUCE_H_
+
+#include <tvm/ir/attrs.h>
+
+#include <string>
+
+namespace tvm {
+namespace relay {
+
+/*! \brief Attributes for Reduce operators */
+struct ReduceAttrs : public tvm::AttrsNode<ReduceAttrs> {
+  Array<Integer> axis;
+  bool keepdims;
+  bool exclude;
+
+  TVM_DECLARE_ATTRS(ReduceAttrs, "relay.attrs.ReduceAttrs") {
+    TVM_ATTR_FIELD(axis)
+        .set_default(NullValue<Array<Integer>>())
+        .describe(R"code(The axis or axes along which to perform the reduction.
+
+      The default, `axis=()`, will compute over all elements into a
+      scalar array with shape `(1,)`.
+
+      If `axis` is int, a reduction is performed on a particular axis.
+
+      If `axis` is a tuple of ints, a reduction is performed on all the axes
+      specified in the tuple.
+
+      If `exclude` is true, reduction will be performed on the axes that are
+      NOT in axis instead.)code");
+
+    TVM_ATTR_FIELD(keepdims).set_default(false).describe(
+        "If this is set to `True`, the reduced axes are left "
+        "in the result as dimension with size one.");
+    TVM_ATTR_FIELD(exclude).set_default(false).describe(
+        "Whether to perform reduction on axis that are NOT in axis instead.");
+  }
+};
+
+/*! \brief Attributes for Reduce operators which reduce by finding a single element. E.g. argmin */
+struct ArgReduceAttrs : public tvm::AttrsNode<ArgReduceAttrs> {
+  Array<Integer> axis;
+  bool keepdims;
+  bool select_last_index;
+  bool exclude;
+
+  TVM_DECLARE_ATTRS(ArgReduceAttrs, "relay.attrs.ArgReduceAttrs") {
+    TVM_ATTR_FIELD(axis)
+        .set_default(NullValue<Array<Integer>>())
+        .describe(R"code(The axis or axes along which to perform the reduction.
+
+      The default, `axis=()`, will compute over all elements into a
+      scalar array with shape `(1,)`.
+
+      If `axis` is int, a reduction is performed on a particular axis.
+
+      If `axis` is a tuple of ints, a reduction is performed on all the axes
+      specified in the tuple.
+
+      If `exclude` is true, reduction will be performed on the axes that are
+      NOT in axis instead.)code");
+
+    TVM_ATTR_FIELD(keepdims).set_default(false).describe(
+        "If this is set to `True`, the reduced axes are left "
+        "in the result as dimension with size one.");
+    TVM_ATTR_FIELD(select_last_index)
+        .set_default(false)
+        .describe(
+            "Whether to select the last index if the target element appears multiple times, else "
+            "select the first index which the target element appears");
+    TVM_ATTR_FIELD(exclude).set_default(false).describe(
+        "Whether to perform reduction on axis that are NOT in axis instead.");
+  }
+};
+
+struct VarianceAttrs : public tvm::AttrsNode<VarianceAttrs> {
+  Array<Integer> axis;
+  bool keepdims;
+  bool exclude;
+  bool unbiased;
+
+  TVM_DECLARE_ATTRS(VarianceAttrs, "relay.attrs.VarianceAttrs") {
+    TVM_ATTR_FIELD(axis)
+        .set_default(NullValue<Array<Integer>>())
+        .describe(R"code(The axis or axes along which to perform the reduction.
+
+      The default, `axis=()`, will compute over all elements into a
+      scalar array with shape `(1,)`.
+
+      If `axis` is int, a reduction is performed on a particular axis.
+
+      If `axis` is a tuple of ints, a reduction is performed on all the axes
+      specified in the tuple.
+
+      If `exclude` is true, reduction will be performed on the axes that are
+      NOT in axis instead.)code");
+
+    TVM_ATTR_FIELD(keepdims).set_default(false).describe(
+        "If this is set to `True`, the reduced axes are left "
+        "in the result as dimension with size one.");
+    TVM_ATTR_FIELD(exclude).set_default(false).describe(
+        "Whether to perform reduction on axis that are NOT in axis instead.");
+    TVM_ATTR_FIELD(unbiased).set_default(false).describe("Whether to use the unbiased estimation.");
+  }
+};
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_ATTRS_REDUCE_H_
diff --git a/darknet_drp_ros/include/tvm/relay/attrs/transform.h b/darknet_drp_ros/include/tvm/relay/attrs/transform.h
new file mode 100644
index 0000000..274a421
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/attrs/transform.h
@@ -0,0 +1,606 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/attrs/transform.h
+ * \brief Transform operators.
+ */
+#ifndef TVM_RELAY_ATTRS_TRANSFORM_H_
+#define TVM_RELAY_ATTRS_TRANSFORM_H_
+
+#include <tvm/ir/attrs.h>
+#include <tvm/relay/base.h>
+#include <tvm/relay/expr.h>
+#include <tvm/tir/index_map.h>
+
+#include <string>
+
+namespace tvm {
+namespace relay {
+
+/*! \brief Attributes used for the sliding_window operator */
+struct SlidingWindowAttrs : public tvm::AttrsNode<SlidingWindowAttrs> {
+  int axis;
+  Array<Integer> window_shape;
+  Array<Integer> strides;
+  TVM_DECLARE_ATTRS(SlidingWindowAttrs, "relay.attrs.SlidingWindowAttrs") {
+    TVM_ATTR_FIELD(axis).describe(
+        "What axis the sliding window begin forming over."
+        "Window will be slid over this axis and all following axes."
+        "The axis value determines the window shape (and thus, the"
+        "number of strides):"
+        "window shape and strides must both be of length"
+        "`data.ndim-axis`.");
+    TVM_ATTR_FIELD(window_shape)
+        .describe(
+            "The window shape to form over the input."
+            "Window shape must be of length `data.ndim-axis`.");
+    TVM_ATTR_FIELD(strides).describe(
+        "How to stride the window along each dimension."
+        "Strides must be of length `data.ndim-axis`.");
+  }
+};  // struct SlidingWindowAttrs
+
+/*! \brief data type cast */
+struct CastAttrs : public tvm::AttrsNode<CastAttrs> {
+  DataType dtype;
+
+  TVM_DECLARE_ATTRS(CastAttrs, "relay.attrs.CastAttrs") {
+    TVM_ATTR_FIELD(dtype).describe("Target data type");
+  }
+};  // struct CastAttrs.
+
+/*! \brief Attributes used in expand_dims operators */
+struct ExpandDimsAttrs : public tvm::AttrsNode<ExpandDimsAttrs> {
+  int axis;
+  int num_newaxis;
+
+  TVM_DECLARE_ATTRS(ExpandDimsAttrs, "relay.attrs.ExpandDimsAttrs") {
+    TVM_ATTR_FIELD(axis).describe(
+        "The axis at which the input array is expanded."
+        "Should lie in range `[-data.ndim - 1, data.ndim]`."
+        "If `axis < 0`, it is the first axis inserted;"
+        "If `axis >= 0`, it is the last axis inserted in Python's negative indexing.");
+    TVM_ATTR_FIELD(num_newaxis)
+        .describe("Number of axes to be inserted. Should be >= 0.")
+        .set_lower_bound(0)
+        .set_default(1);
+  }
+};  // struct ExpandDimsAttrs
+
+/*! \brief Attributes used in dynamic expand_dims operators */
+struct DynExpandDimsAttrs : public tvm::AttrsNode<DynExpandDimsAttrs> {
+  int num_newaxis;
+
+  TVM_DECLARE_ATTRS(DynExpandDimsAttrs, "relay.attrs.DynExpandDimsAttrs") {
+    TVM_ATTR_FIELD(num_newaxis)
+        .describe("Number of axes to be inserted. Should be >= 0.")
+        .set_lower_bound(0)
+        .set_default(1);
+  }
+};  // struct ExpandDimsAttrs
+
+/*! \brief Attributes used in concatenate operators */
+struct ConcatenateAttrs : public tvm::AttrsNode<ConcatenateAttrs> {
+  int axis;
+  TVM_DECLARE_ATTRS(ConcatenateAttrs, "relay.attrs.ConcatenateAttrs") {
+    TVM_ATTR_FIELD(axis)
+        .describe(
+            "The axis at which the input arrays are concatenated."
+            "Should lie in range `[-ndim, ndim)`.")
+        .set_default(0);
+  }
+};  // struct ConcatenateAttrs
+
+/*! \brief Attributes used in transpose operators */
+struct TransposeAttrs : public tvm::AttrsNode<TransposeAttrs> {
+  Array<Integer> axes;
+  TVM_DECLARE_ATTRS(TransposeAttrs, "relay.attrs.TransposeAttrs") {
+    TVM_ATTR_FIELD(axes).describe("The target axes order, reverse order if not specified.");
+  }
+};  // struct TransposeAttrs
+
+/*! \brief Attributes used in reshape operators */
+struct ReshapeAttrs : public tvm::AttrsNode<ReshapeAttrs> {
+  Array<Integer> newshape;
+  bool allowzero;
+  TVM_DECLARE_ATTRS(ReshapeAttrs, "relay.attrs.ReshapeAttrs") {
+    TVM_ATTR_FIELD(newshape).describe(
+        "The new shape. Should be compatible with the original shape.");
+    TVM_ATTR_FIELD(allowzero).set_default(0).describe(
+        "Whether to honor the value of zero in newshape.");
+  }
+};  // struct ReshapeAttrs
+
+/*! \brief Attributes used in MXNet-style reshape_like operators */
+struct ReshapeLikeAttrs : public tvm::AttrsNode<ReshapeLikeAttrs> {
+  int lhs_begin;
+  Integer lhs_end;  // can be None
+  int rhs_begin;
+  Integer rhs_end;  // can be None
+  TVM_DECLARE_ATTRS(ReshapeLikeAttrs, "relay.attrs.ReshapeLikeAttrs") {
+    TVM_ATTR_FIELD(lhs_begin).set_default(0).describe(
+        "The axis of the input where reshaping should begin.");
+    TVM_ATTR_FIELD(lhs_end)
+        .set_default(NullValue<Integer>())
+        .describe("The axis of the input where reshaping should end, exclusive.");
+    TVM_ATTR_FIELD(rhs_begin).set_default(0).describe(
+        "The axis of the shape_like tensor to begin taking dimensions from.");
+    TVM_ATTR_FIELD(rhs_end)
+        .set_default(NullValue<Integer>())
+        .describe("The axis of the shape_like tensor to end taking dimensions from, exclusive.");
+  }
+};  // struct ReshapeLikeAttrs
+
+struct ScatterAttrs : public tvm::AttrsNode<ScatterAttrs> {
+  Integer axis;
+
+  TVM_DECLARE_ATTRS(ScatterAttrs, "relay.attrs.ScatterAttrs") {
+    TVM_ATTR_FIELD(axis).set_default(0).describe("The axis over which to select values.");
+  }
+};
+
+struct ScatterAddAttrs : public tvm::AttrsNode<ScatterAddAttrs> {
+  Integer axis;
+
+  TVM_DECLARE_ATTRS(ScatterAddAttrs, "relay.attrs.ScatterAddAttrs") {
+    TVM_ATTR_FIELD(axis).set_default(0).describe("The axis over which to select values.");
+  }
+};
+
+struct ScatterNDAttrs : public tvm::AttrsNode<ScatterNDAttrs> {
+  String mode;
+
+  TVM_DECLARE_ATTRS(ScatterNDAttrs, "relay.attrs.ScatterNDAttrs") {
+    TVM_ATTR_FIELD(mode).describe(
+        "Accumulation mode of the scatter, either \"update\" or \"add\".");
+  }
+};
+
+struct GatherAttrs : public tvm::AttrsNode<GatherAttrs> {
+  Integer axis;
+
+  TVM_DECLARE_ATTRS(GatherAttrs, "relay.attrs.GatherAttrs") {
+    TVM_ATTR_FIELD(axis)
+        .set_default(NullValue<Integer>())
+        .describe("The axis over which to select values.");
+  }
+};
+
+struct GatherNDAttrs : public tvm::AttrsNode<GatherNDAttrs> {
+  Integer batch_dims;
+  Optional<Integer> index_rank;
+
+  TVM_DECLARE_ATTRS(GatherNDAttrs, "relay.attrs.GatherNDAttrs") {
+    TVM_ATTR_FIELD(batch_dims).set_default(Integer(0)).describe("The number of batch dimensions.");
+    TVM_ATTR_FIELD(index_rank)
+        .set_default(NullValue<Integer>())
+        .describe(
+            "The size of an indexing tuple, which is a fixed value. Only needed when the number of "
+            "indexting tuples is dynamic.");
+  }
+};
+
+struct TakeAttrs : public tvm::AttrsNode<TakeAttrs> {
+  Integer batch_dims;
+  Integer axis;
+  tvm::String mode;
+
+  TVM_DECLARE_ATTRS(TakeAttrs, "relay.attrs.TakeAttrs") {
+    TVM_ATTR_FIELD(batch_dims)
+        .set_default(0)
+        .describe("The batch_dims over which to select values.");
+    TVM_ATTR_FIELD(axis)
+        .set_default(NullValue<Integer>())
+        .describe("The axis over which to select values.");
+    TVM_ATTR_FIELD(mode).set_default("clip").describe(
+        "Specify how out-of-bound indices will behave."
+        "clip - clip to the range (default)"
+        "wrap - wrap around the indices"
+        "fast - no clip or wrap around (user must make sure indices are in-bound)");
+  }
+};
+
+/*! \brief Attributes that specify a tensor */
+struct InitOpAttrs : public tvm::AttrsNode<InitOpAttrs> {
+  Optional<Array<Integer>> shape;
+  DataType dtype;
+
+  TVM_DECLARE_ATTRS(InitOpAttrs, "relay.attrs.InitOpAttrs") {
+    TVM_ATTR_FIELD(shape).describe("Target shape.");
+    TVM_ATTR_FIELD(dtype).describe("Target data type.").set_default(NullValue<DataType>());
+  }
+};  // struct InitOpAttrs
+
+/*! \brief Attributes used in arange operators */
+struct ArangeAttrs : public tvm::AttrsNode<ArangeAttrs> {
+  Expr start;
+  Expr stop;
+  Expr step;
+  DataType dtype;
+
+  TVM_DECLARE_ATTRS(ArangeAttrs, "relay.attrs.ArangeAttrs") {
+    TVM_ATTR_FIELD(start).describe("Start of interval. The interval includes this value.");
+    TVM_ATTR_FIELD(stop).describe("Stop of interval. The interval does not include this value.");
+    TVM_ATTR_FIELD(step).describe("Spacing between values.");
+    TVM_ATTR_FIELD(dtype).describe("Target data type.");
+  }
+};  // struct ArangeAttrs
+
+/*! \brief Attributes used in meshgrid operators */
+struct MeshgridAttrs : public tvm::AttrsNode<MeshgridAttrs> {
+  std::string indexing;
+
+  TVM_DECLARE_ATTRS(MeshgridAttrs, "relay.attrs.MeshgridAttrs") {
+    TVM_ATTR_FIELD(indexing)
+        .describe(
+            "Indexing mode, either \"ij\" for matrix or \"xy\" for cartesian in which first two"
+            "dimensions are swapped.")
+        .set_default("ij");
+  }
+};  // struct MeshgridAttrs
+
+/*! \brief Attributes used in stack operators */
+struct StackAttrs : public tvm::AttrsNode<StackAttrs> {
+  Integer axis;
+  TVM_DECLARE_ATTRS(StackAttrs, "relay.attrs.StackAttrs") {
+    TVM_ATTR_FIELD(axis).set_default(0).describe(
+        "The axis in the result array along which the input arrays are stacked.");
+  }
+};  // struct StackAttrs
+
+/*! \brief Attributes used in repeat operators */
+struct RepeatAttrs : public tvm::AttrsNode<RepeatAttrs> {
+  Integer repeats;
+  Integer axis;
+  TVM_DECLARE_ATTRS(RepeatAttrs, "relay.attrs.RepeatAttrs") {
+    TVM_ATTR_FIELD(repeats).describe("The number of repetitions for each element.");
+    TVM_ATTR_FIELD(axis)
+        .set_default(NullValue<Integer>())
+        .describe(" The axis along which to repeat values.");
+  }
+};  // struct RepeatAttrs
+
+/*! \brief Attributes used in tile operators */
+struct TileAttrs : public tvm::AttrsNode<TileAttrs> {
+  Array<Integer> reps;
+  TVM_DECLARE_ATTRS(TileAttrs, "relay.attrs.TileAttrs") {
+    TVM_ATTR_FIELD(reps).describe(
+        "The number of times for repeating the tensor a."
+        "Each dim sizeof reps must be a positive integer.");
+  }
+};  // struct TileAttrs
+
+/*! \brief Attributes used in reverse operators */
+struct ReverseAttrs : public tvm::AttrsNode<ReverseAttrs> {
+  Integer axis;
+  TVM_DECLARE_ATTRS(ReverseAttrs, "relay.attrs.ReverseAttrs") {
+    TVM_ATTR_FIELD(axis)
+        .set_default(NullValue<Integer>())
+        .describe("The axis along which to reverse elements.");
+  }
+};  // struct ReverseAttrs
+
+/*! \brief Attributes used in reverse_sequence operators */
+struct ReverseSequenceAttrs : public tvm::AttrsNode<ReverseSequenceAttrs> {
+  Integer seq_axis;
+  Integer batch_axis;
+
+  TVM_DECLARE_ATTRS(ReverseSequenceAttrs, "relay.attrs.ReverseSequenceAttrs") {
+    TVM_ATTR_FIELD(seq_axis).set_default(1).describe(
+        "The seq axis along which to reverse elements.");
+    TVM_ATTR_FIELD(batch_axis)
+        .set_default(0)
+        .describe("The batch axis along which to slice the tensor.");
+  }
+};  // struct ReverseSequenceAttrs
+
+/*! \brief Attributes used in squeeze operators */
+struct SqueezeAttrs : public tvm::AttrsNode<SqueezeAttrs> {
+  // use axis to make the name numpy compatible.
+  Array<Integer> axis;
+
+  TVM_DECLARE_ATTRS(SqueezeAttrs, "relay.attrs.SqueezeAttrs") {
+    TVM_ATTR_FIELD(axis)
+        .describe(
+            "The axis to squeeze in the input tensor."
+            "If `axis = None`, all axis of dimension 1 get squeezed;"
+            "Else, the dimension in axes get squeezed."
+            "It is an error if an axis does not has dimension 1.")
+        .set_default(NullValue<Array<Integer>>());
+  }
+};  // struct SqueezeAttrs
+
+struct SplitAttrs : public tvm::AttrsNode<SplitAttrs> {
+  ObjectRef indices_or_sections;
+  int axis;
+
+  TVM_DECLARE_ATTRS(SplitAttrs, "relay.attrs.SplitAttrs") {
+    TVM_ATTR_FIELD(indices_or_sections)
+        .describe(
+            "Indices or sections to split into. Accepts an int or a tuple"
+            "If indices_or_sections is an integer, the input will be divided equally"
+            "along given axis. If such a split is not possible, an error is raised."
+            "If indices_or_sections is a tuple of sorted integers,"
+            "the entries indicate where along axis the array is split.");
+    TVM_ATTR_FIELD(axis).set_default(0).describe("the axis to be splitted.");
+  }
+};
+
+/*! \brief Attributes for StridedSlice operator */
+struct StridedSliceAttrs : public tvm::AttrsNode<StridedSliceAttrs> {
+  Optional<Array<Integer>> begin;
+  Optional<Array<Integer>> end;
+  Optional<Array<Integer>> strides;
+  tvm::String slice_mode;
+  Optional<Array<Integer>> axes;
+
+  TVM_DECLARE_ATTRS(StridedSliceAttrs, "relay.attrs.StridedSliceAttrs") {
+    TVM_ATTR_FIELD(begin).describe("Indices for begin of slice, begin index is also inclusive");
+    TVM_ATTR_FIELD(end).describe("Indices for end of slice, end index is exclusive");
+    TVM_ATTR_FIELD(strides).describe(
+        "Stride values of the slice, a stride can be negative, which causes a reverse slice.");
+    TVM_ATTR_FIELD(slice_mode)
+        .set_default("end")
+        .describe(
+            "The slice mode [end, size]."
+            "end - The default slice mode, ending indices for the slice."
+            "size - The input strides will be ignored, input end in this mode indicates the size"
+            "of a slice starting at the location specified by begin. If end[i] is -1,"
+            "all remaining elements in that dimension are included in the slice");
+    TVM_ATTR_FIELD(axes).describe(
+        "Axes along which slicing is applied. When it is specified, the length of begin, end, "
+        "strides, and axes must be equal.");
+  }
+};
+
+struct SliceLikeAttrs : public tvm::AttrsNode<SliceLikeAttrs> {
+  Array<Integer> axes;
+
+  TVM_DECLARE_ATTRS(SliceLikeAttrs, "relay.attrs.SliceLikeAttrs") {
+    TVM_ATTR_FIELD(axes).describe(
+        "List of axes on which input data will be sliced according to the "
+        "corresponding size of the second input. By default will slice "
+        "on all axes. Negative axes mean counting in reverse.");
+  }
+};
+
+/*! \brief Attributes for Clip operator */
+struct ClipAttrs : public tvm::AttrsNode<ClipAttrs> {
+  double a_min;
+  double a_max;
+
+  TVM_DECLARE_ATTRS(ClipAttrs, "relay.attrs.ClipAttrs") {
+    TVM_ATTR_FIELD(a_min).describe("The minimum clip value.");
+    TVM_ATTR_FIELD(a_max).describe("The maximum clip value.");
+  }
+};
+
+/*! \brief Attributes for FixedPointMultiply operator */
+struct FixedPointMultiplyAttrs : public tvm::AttrsNode<FixedPointMultiplyAttrs> {
+  int32_t multiplier;
+  int32_t shift;
+
+  TVM_DECLARE_ATTRS(FixedPointMultiplyAttrs, "relay.attrs.FixedPointMultiplyAttrs") {
+    TVM_ATTR_FIELD(multiplier)
+        .describe("Multiplier of a fixed floating point number described as multiplier*2^(shift)");
+    TVM_ATTR_FIELD(shift).describe(
+        "Shift of a fixed floating point number described as multiplier*2^(shift)");
+  }
+};
+
+/*! \brief Attributes for per channel/per axes FixedPointMultiply operator */
+struct FixedPointMultiplyPerAxisAttrs : public tvm::AttrsNode<FixedPointMultiplyPerAxisAttrs> {
+  bool is_lshift_required;
+  bool is_rshift_required;
+  Array<Integer> axes;
+
+  TVM_DECLARE_ATTRS(FixedPointMultiplyPerAxisAttrs, "relay.attrs.FixedPointMultiplyPerAxisAttrs") {
+    TVM_ATTR_FIELD(is_lshift_required)
+        .describe("Whether left shift is required in fixed point multiplication.")
+        .set_default(false);
+    TVM_ATTR_FIELD(is_rshift_required)
+        .describe("Whether right shift is required in fixed point multiplication.")
+        .set_default(false);
+    TVM_ATTR_FIELD(axes).describe("List of axes on which input data was quantized.");
+  }
+};
+
+/*! \brief Attributes for LayoutTransform operator */
+struct LayoutTransformAttrs : public tvm::AttrsNode<LayoutTransformAttrs> {
+  std::string src_layout;
+  std::string dst_layout;
+
+  TVM_DECLARE_ATTRS(LayoutTransformAttrs, "relay.attrs.LayoutTransformAttrs") {
+    TVM_ATTR_FIELD(src_layout).describe("The source layout of the tensor. (e.g. NCHW)");
+    TVM_ATTR_FIELD(dst_layout).describe("The destination layout of the tensor. (e.g. NCHW16c)");
+  }
+};
+
+/*! \brief Attributes for AutoSchedulerLayoutTransform operator */
+struct AutoSchedulerLayoutTransformAttrs
+    : public tvm::AttrsNode<AutoSchedulerLayoutTransformAttrs> {
+  std::string src_layout;
+  std::string dst_layout;
+
+  TVM_DECLARE_ATTRS(AutoSchedulerLayoutTransformAttrs,
+                    "relay.attrs.AutoSchedulerLayoutTransformAttrs") {
+    TVM_ATTR_FIELD(src_layout).describe("The source layout of the tensor. (e.g. 1N32C112H112W)");
+    TVM_ATTR_FIELD(dst_layout)
+        .describe("The destination layout of the tensor. (e.g. 1N2C112H112W16c)");
+  }
+};
+
+/*! \brief Attributes for MetaScheduleLayoutTransform operator */
+struct MetaScheduleLayoutTransformAttrs : public tvm::AttrsNode<MetaScheduleLayoutTransformAttrs> {
+  tir::IndexMap index_map;
+
+  TVM_DECLARE_ATTRS(MetaScheduleLayoutTransformAttrs,
+                    "relay.attrs.MetaScheduleLayoutTransformAttrs") {
+    TVM_ATTR_FIELD(index_map).describe(
+        "The order of the extents, for example, "
+        "let extents = [2, 3, 4], reorder = [0, 2, 1], and the shape of buffer A is (4, 6)"
+        "then A[i, j] will be first rewritten to "
+        "A[(6 * i + j) / 12, (6 * i + j) / 4 % 3 , (6 * i + j) % 4] according to the `extents`,"
+        "and then reordered to A[(6 * i + j) / 12, (6 * i + j) % 4 , (6 * i + j) / 4 % 3]"
+        "according to `reorder`");
+  }
+};
+
+/*! \brief Attributes for ShapeOf operator */
+struct ShapeOfAttrs : public tvm::AttrsNode<ShapeOfAttrs> {
+  DataType dtype;
+
+  TVM_DECLARE_ATTRS(ShapeOfAttrs, "relay.attrs.ShapeOfAttrs") {
+    TVM_ATTR_FIELD(dtype).describe("Target data type").set_default(NullValue<DataType>());
+  }
+};
+
+struct SequenceMaskAttrs : public tvm::AttrsNode<SequenceMaskAttrs> {
+  double mask_value;
+  int axis;
+
+  TVM_DECLARE_ATTRS(SequenceMaskAttrs, "relay.attrs.SequenceMaskAttrs") {
+    TVM_ATTR_FIELD(mask_value).set_default(0).describe("The masking value.");
+    TVM_ATTR_FIELD(axis).set_default(0).describe(
+        "The axis of the length dimension. Can only be 0 or 1.");
+  }
+};  // struct SequenceMaskAttrs.
+
+/*! \brief Attributes used in sparse_to_dense operator */
+struct SparseToDenseAttrs : public tvm::AttrsNode<SparseToDenseAttrs> {
+  Array<Integer> output_shape;
+
+  TVM_DECLARE_ATTRS(SparseToDenseAttrs, "relay.attrs.SparseToDenseAttrs") {
+    TVM_ATTR_FIELD(output_shape).describe("Shape of the dense output tensor");
+  }
+};  // struct SparseToDenseAttrs
+
+/*! \brief Attributes for ndarray_size operator */
+struct NdarraySizeAttrs : public tvm::AttrsNode<NdarraySizeAttrs> {
+  DataType dtype;
+
+  TVM_DECLARE_ATTRS(NdarraySizeAttrs, "relay.attrs.NdarraySizeAttrs") {
+    TVM_ATTR_FIELD(dtype).describe("Target data type").set_default(NullValue<DataType>());
+  }
+};
+
+/*! \brief Attributes used in one-hot operator */
+struct OneHotAttrs : public tvm::AttrsNode<OneHotAttrs> {
+  int depth;
+  int axis;
+  DataType dtype;
+
+  TVM_DECLARE_ATTRS(OneHotAttrs, "relay.attrs.OneHotAttrs") {
+    TVM_ATTR_FIELD(depth).set_default(1).describe("Depth of the one hot dimension.");
+    TVM_ATTR_FIELD(axis).set_default(-1).describe("Axis to fill.");
+    TVM_ATTR_FIELD(dtype).set_default(NullValue<DataType>()).describe("Output data type.");
+  }
+};  // struct OneHotAttrs
+
+/*! \brief Attributes used in matrix_set_diag operator */
+struct MatrixSetDiagAttrs : public tvm::AttrsNode<MatrixSetDiagAttrs> {
+  int k1;
+  int k2;
+  bool super_diag_right_align;
+  bool sub_diag_right_align;
+
+  TVM_DECLARE_ATTRS(MatrixSetDiagAttrs, "relay.attrs.MatrixSetDiagAttrs") {
+    TVM_ATTR_FIELD(k1).set_default(0).describe("Lower limit (included) of the range of diagonals.");
+    TVM_ATTR_FIELD(k2).set_default(0).describe("Upper limit (included) of the range of diagonals.");
+    TVM_ATTR_FIELD(super_diag_right_align)
+        .set_default(true)
+        .describe("Bool, true iff super-diagonal is right aligned (left-padded).");
+    TVM_ATTR_FIELD(sub_diag_right_align)
+        .set_default(false)
+        .describe("Bool, true iff sub-diagonal is right aligned (left-padded).");
+  }
+};  // struct MatrixSetDiagAttrs
+
+/*! \brief Attributes used in cumsum and cumprod operator */
+struct ScanopAttrs : public tvm::AttrsNode<ScanopAttrs> {
+  Integer axis;
+  DataType dtype;
+  Bool exclusive = Bool(false);
+  TVM_DECLARE_ATTRS(ScanopAttrs, "relay.attrs.ScanopAttrs") {
+    TVM_ATTR_FIELD(axis).describe("The axis to operate over").set_default(NullValue<Integer>());
+    TVM_ATTR_FIELD(dtype).describe("Output data type").set_default(NullValue<DataType>());
+
+    // Default is 0 which is "false"
+    TVM_ATTR_FIELD(exclusive)
+        .describe("The first element is not included")
+        .set_default(Bool(false));
+  }
+};  // struct ScanopAttrs
+
+/*! \brief Attributes used in unique operator */
+struct UniqueAttrs : public tvm::AttrsNode<UniqueAttrs> {
+  bool sorted;
+  bool return_counts;
+  TVM_DECLARE_ATTRS(UniqueAttrs, "relay.attrs.UniqueAttrs") {
+    TVM_ATTR_FIELD(sorted).describe("Whether the unique elements are sorted").set_default(true);
+    TVM_ATTR_FIELD(return_counts)
+        .describe("Whether to return an additional tensor with counts of each unique elements")
+        .set_default(false);
+  }
+};  // struct UniqueAttrs
+
+/*! \brief Attributes used in einsum operator */
+struct EinsumAttrs : public tvm::AttrsNode<EinsumAttrs> {
+  String equation;
+
+  TVM_DECLARE_ATTRS(EinsumAttrs, "relay.attrs.EinsumAttrs") {
+    TVM_ATTR_FIELD(equation).describe("The einsum expression string");
+  }
+};  // struct EinsumAttrs
+
+/*! \brief Attributes used in stft operator */
+struct StftAttrs : public tvm::AttrsNode<StftAttrs> {
+  int n_fft;
+  int hop_length;
+  int win_length;
+  bool normalized;
+  bool onesided;
+
+  TVM_DECLARE_ATTRS(StftAttrs, "relay.attrs.StftAttrs") {
+    TVM_ATTR_FIELD(n_fft).set_default(-1).describe("The size of Fourier transform");
+    TVM_ATTR_FIELD(hop_length)
+        .set_default(-1)
+        .describe("The distance between neighboring sliding window frames");
+    TVM_ATTR_FIELD(win_length).set_default(-1).describe("The size of window frame and STFT filter");
+    TVM_ATTR_FIELD(normalized)
+        .set_default(false)
+        .describe("Whether to return the normalized STFT results");
+    TVM_ATTR_FIELD(onesided).set_default(true).describe(
+        "Whether to return onesided result or fill with conjugate symmetry");
+  }
+};  // struct StftAttrs
+
+struct TriluAttrs : public tvm::AttrsNode<TriluAttrs> {
+  bool upper;
+
+  TVM_DECLARE_ATTRS(TriluAttrs, "relay.attrs.TriluAttrs") {
+    TVM_ATTR_FIELD(upper).set_default(true).describe(
+        "Whether to keep the upper or lower half of the diagonal.");
+  }
+};  // struct TriluAttrs
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_ATTRS_TRANSFORM_H_
diff --git a/darknet_drp_ros/include/tvm/relay/attrs/vision.h b/darknet_drp_ros/include/tvm/relay/attrs/vision.h
new file mode 100644
index 0000000..976304e
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/attrs/vision.h
@@ -0,0 +1,226 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/attrs/vision.h
+ * \brief Auxiliary attributes for vision operators.
+ */
+#ifndef TVM_RELAY_ATTRS_VISION_H_
+#define TVM_RELAY_ATTRS_VISION_H_
+
+#include <tvm/ir/attrs.h>
+#include <tvm/relay/base.h>
+
+#include <string>
+
+namespace tvm {
+namespace relay {
+
+/*! \brief Attributes used in multibox_prior operators */
+struct MultiBoxPriorAttrs : public tvm::AttrsNode<MultiBoxPriorAttrs> {
+  Array<IndexExpr> sizes;
+  Array<IndexExpr> ratios;
+  Array<IndexExpr> steps;
+  Array<IndexExpr> offsets;
+  bool clip;
+
+  TVM_DECLARE_ATTRS(MultiBoxPriorAttrs, "relay.attrs.MultiBoxPriorAttrs") {
+    TVM_ATTR_FIELD(sizes)
+        .set_default(Array<IndexExpr>({static_cast<float>(1.0)}))
+        .describe("List of sizes of generated MultiBoxPriores.");
+    TVM_ATTR_FIELD(ratios)
+        .set_default(Array<IndexExpr>({static_cast<float>(1.0)}))
+        .describe("List of aspect ratios of generated MultiBoxPriores.");
+    TVM_ATTR_FIELD(steps)
+        .set_default(Array<IndexExpr>({static_cast<float>(-1.0), static_cast<float>(-1.0)}))
+        .describe("Priorbox step across y and x, -1 for auto calculation.");
+    TVM_ATTR_FIELD(offsets)
+        .set_default(Array<IndexExpr>({static_cast<float>(0.5), static_cast<float>(0.5)}))
+        .describe("Priorbox center offsets, y and x respectively.");
+    TVM_ATTR_FIELD(clip).set_default(false).describe("Whether to clip out-of-boundary boxes.");
+  }
+};
+
+struct MultiBoxTransformLocAttrs : public tvm::AttrsNode<MultiBoxTransformLocAttrs> {
+  bool clip;
+  double threshold;
+  Array<IndexExpr> variances;
+
+  TVM_DECLARE_ATTRS(MultiBoxTransformLocAttrs, "relay.attrs.MultiBoxTransformLocAttrs") {
+    TVM_ATTR_FIELD(clip).set_default(true).describe("Clip out-of-boundary boxes.");
+    TVM_ATTR_FIELD(threshold).set_default(0.01).describe("Threshold to be a positive prediction.");
+    TVM_ATTR_FIELD(variances)
+        .set_default(Array<IndexExpr>({0.1f, 0.1f, 0.2f, 0.2f}))
+        .describe("Variances to be decoded from box regression output.");
+  }
+};
+
+/*! \brief Attributes used in get_valid_counts operator */
+struct GetValidCountsAttrs : public tvm::AttrsNode<GetValidCountsAttrs> {
+  Optional<FloatImm> score_threshold;
+  int id_index;
+  int score_index;
+
+  TVM_DECLARE_ATTRS(GetValidCountsAttrs, "relay.attrs.GetValidCountsAttrs") {
+    TVM_ATTR_FIELD(score_threshold).describe("Lower limit of score for valid bounding boxes.");
+    TVM_ATTR_FIELD(id_index).set_default(0).describe("Axis index of id.");
+    TVM_ATTR_FIELD(score_index).set_default(1).describe("Index of the scores/confidence of boxes.");
+  }
+};
+
+/*! \brief Attributes used in non_maximum_suppression operator */
+struct NonMaximumSuppressionAttrs : public tvm::AttrsNode<NonMaximumSuppressionAttrs> {
+  bool force_suppress;
+  int top_k;
+  int coord_start;
+  int score_index;
+  int id_index;
+  bool return_indices;
+  bool invalid_to_bottom;
+
+  TVM_DECLARE_ATTRS(NonMaximumSuppressionAttrs, "relay.attrs.NonMaximumSuppressionAttrs") {
+    TVM_ATTR_FIELD(force_suppress)
+        .set_default(false)
+        .describe("Suppress all detections regardless of class_id.");
+    TVM_ATTR_FIELD(top_k).set_default(-1).describe(
+        "Keep maximum top k detections before nms, -1 for no limit.");
+    TVM_ATTR_FIELD(coord_start)
+        .set_default(2)
+        .describe("Start index of the consecutive 4 coordinates.");
+    TVM_ATTR_FIELD(score_index).set_default(1).describe("Index of the scores/confidence of boxes.");
+    TVM_ATTR_FIELD(id_index).set_default(0).describe("Axis index of id.");
+    TVM_ATTR_FIELD(return_indices)
+        .set_default(true)
+        .describe("Whether to return box indices in input data.");
+    TVM_ATTR_FIELD(invalid_to_bottom)
+        .set_default(false)
+        .describe("Whether to move all invalid bounding boxes to the bottom.");
+  }
+};
+
+/*! \brief Attributes used in all_class_non_maximum_suppression operator */
+struct AllClassNonMaximumSuppressionAttrs
+    : public tvm::AttrsNode<AllClassNonMaximumSuppressionAttrs> {
+  std::string output_format;
+
+  TVM_DECLARE_ATTRS(AllClassNonMaximumSuppressionAttrs,
+                    "relay.attrs.AllClassNonMaximumSuppressionAttrs") {
+    TVM_ATTR_FIELD(output_format)
+        .set_default("onnx")
+        .describe(
+            "Output format, onnx or tensorflow. Returns outputs in a way that can be easily "
+            "consumed by each frontend.");
+  }
+};
+
+/*! \brief Attributes used in roi_align operators */
+struct ROIAlignAttrs : public tvm::AttrsNode<ROIAlignAttrs> {
+  Array<IndexExpr> pooled_size;
+  double spatial_scale;
+  int sample_ratio;
+  std::string layout;
+  std::string mode;
+  TVM_DECLARE_ATTRS(ROIAlignAttrs, "relay.attrs.ROIAlignAttrs") {
+    TVM_ATTR_FIELD(pooled_size).describe("Output size of roi align.");
+    TVM_ATTR_FIELD(spatial_scale)
+        .describe(
+            "Ratio of input feature map height (or w) to raw image height (or w). "
+            "Equals the reciprocal of total stride in convolutional layers, which should be "
+            "in range (0.0, 1.0]");
+    TVM_ATTR_FIELD(sample_ratio)
+        .set_default(-1)
+        .describe("Optional sampling ratio of ROI align, using adaptive size by default.");
+    TVM_ATTR_FIELD(layout).set_default("NCHW").describe(
+        "Dimension ordering of data and weight. Can be 'NCHW', 'NHWC', etc."
+        "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+        "dimensions respectively. Convolution is applied on the 'H' and"
+        "'W' dimensions.");
+    TVM_ATTR_FIELD(mode).set_default("avg").describe(
+        "Mode for ROI Align. Can be 'avg' or 'max'. The default mode is 'avg'.");
+  }
+};
+
+/*! \brief Attributes used in roi_pool operators */
+struct ROIPoolAttrs : public tvm::AttrsNode<ROIPoolAttrs> {
+  Array<IndexExpr> pooled_size;
+  double spatial_scale;
+  std::string layout;
+  TVM_DECLARE_ATTRS(ROIPoolAttrs, "relay.attrs.ROIPoolAttrs") {
+    TVM_ATTR_FIELD(pooled_size).describe("Output size of roi pool.");
+    TVM_ATTR_FIELD(spatial_scale)
+        .describe(
+            "Ratio of input feature map height (or w) to raw image height (or w). "
+            "Equals the reciprocal of total stride in convolutional layers, which should be "
+            "in range (0.0, 1.0]");
+    TVM_ATTR_FIELD(layout).set_default("NCHW").describe(
+        "Dimension ordering of data and weight. Can be 'NCHW', 'NHWC', etc."
+        "'N', 'C', 'H', 'W' stands for batch, channel, height, and width"
+        "dimensions respectively. Convolution is applied on the 'H' and"
+        "'W' dimensions.");
+  }
+};
+
+/*! \brief Attributes used in yolo reorg operators */
+struct YoloReorgAttrs : public tvm::AttrsNode<YoloReorgAttrs> {
+  Integer stride;
+
+  TVM_DECLARE_ATTRS(YoloReorgAttrs, "relay.attrs.YoloReorgAttrs") {
+    TVM_ATTR_FIELD(stride).set_default(1).describe("Stride value for yolo reorg");
+  }
+};
+
+/*! \brief Attributes used in proposal operators */
+struct ProposalAttrs : public tvm::AttrsNode<ProposalAttrs> {
+  Array<IndexExpr> scales;
+  Array<IndexExpr> ratios;
+  int feature_stride;
+  double threshold;
+  int rpn_pre_nms_top_n;
+  int rpn_post_nms_top_n;
+  int rpn_min_size;
+  bool iou_loss;
+
+  TVM_DECLARE_ATTRS(ProposalAttrs, "relay.attrs.ProposalAttrs") {
+    TVM_ATTR_FIELD(scales)
+        .set_default(Array<IndexExpr>({4.0f, 8.0f, 16.0f, 32.0f}))
+        .describe("Used to generate anchor windows by enumerating scales");
+    TVM_ATTR_FIELD(ratios)
+        .set_default(Array<IndexExpr>({0.5f, 1.0f, 2.0f}))
+        .describe("Used to generate anchor windows by enumerating ratios");
+    TVM_ATTR_FIELD(feature_stride)
+        .set_default(16)
+        .describe(
+            "The size of the receptive field each unit in the convolution layer of the rpn,"
+            "for example the product of all stride's prior to this layer.");
+    TVM_ATTR_FIELD(threshold).set_default(0.7).describe(
+        "IoU threshold of non-maximum suppresion (suppress boxes with IoU >= this threshold)");
+    TVM_ATTR_FIELD(rpn_pre_nms_top_n)
+        .set_default(6000)
+        .describe("Number of top scoring boxes to apply NMS. -1 to use all boxes");
+    TVM_ATTR_FIELD(rpn_post_nms_top_n)
+        .set_default(300)
+        .describe("Number of top scoring boxes to keep after applying NMS to RPN proposals");
+    TVM_ATTR_FIELD(rpn_min_size).set_default(16).describe("Minimum height or width in proposal");
+    TVM_ATTR_FIELD(iou_loss).set_default(false).describe("Usage of IoU Loss");
+  }
+};
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_ATTRS_VISION_H_
diff --git a/darknet_drp_ros/include/tvm/relay/attrs/vm.h b/darknet_drp_ros/include/tvm/relay/attrs/vm.h
new file mode 100644
index 0000000..7eb1008
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/attrs/vm.h
@@ -0,0 +1,58 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/attrs/vm.h
+ * \brief Attributes for Relay vm operators.
+ */
+#ifndef TVM_RELAY_ATTRS_VM_H_
+#define TVM_RELAY_ATTRS_VM_H_
+
+#include <tvm/ir/attrs.h>
+
+namespace tvm {
+namespace relay {
+
+/*!
+ * \brief Options for the shape function operator.
+ */
+struct ShapeFuncAttrs : public tvm::AttrsNode<ShapeFuncAttrs> {
+  Array<Integer> is_input;
+
+  TVM_DECLARE_ATTRS(ShapeFuncAttrs, "relay.attrs.ShapeFuncAttrs") {
+    TVM_ATTR_FIELD(is_input).describe(
+        "A bool indicating whether the shape function should"
+        "expect shape or input in each position.");
+  }
+};
+
+/*!
+ * \brief Attributes for VM reshape_tensor operator.
+ */
+struct ReshapeTensorAttrs : public tvm::AttrsNode<ReshapeTensorAttrs> {
+  Array<PrimExpr> newshape;
+
+  TVM_DECLARE_ATTRS(ReshapeTensorAttrs, "relay.attrs.ReshapeTensorAttrs") {
+    TVM_ATTR_FIELD(newshape).describe("The new shape of output tensor");
+  }
+};
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_ATTRS_VM_H_
diff --git a/darknet_drp_ros/include/tvm/relay/base.h b/darknet_drp_ros/include/tvm/relay/base.h
new file mode 100644
index 0000000..e94bd27
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/base.h
@@ -0,0 +1,126 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/base.h
+ * \brief Base classes for the Relay IR.
+ */
+#ifndef TVM_RELAY_BASE_H_
+#define TVM_RELAY_BASE_H_
+
+#include <tvm/ir/span.h>
+#include <tvm/node/node.h>
+#include <tvm/tir/expr.h>
+
+#include <string>
+#include <vector>
+
+namespace tvm {
+/*!
+ * \brief Relay: a high level functional IR for TVM.
+ *
+ * This namespace contains the abstract syntax tree, and other
+ * essential data structures for the Relay IR.
+ *
+ * You can find more about Relay by reading the language reference.
+ */
+namespace relay {
+
+#define RELAY_DEBUG(...)                                                \
+  {                                                                     \
+    auto fdebug = runtime::Registry::Get("relay.debug");                \
+    ICHECK(fdebug) << "Could not find Relay Python debugger function."; \
+    (*fdebug)("RELAY_DEBUG", __FILE__, __LINE__, __VA_ARGS__);          \
+  }
+
+#define RELAY_DEBUG_INTERP(...)                                         \
+  {                                                                     \
+    auto fdebug = runtime::Registry::Get("relay.debug_interp");         \
+    ICHECK(fdebug) << "Could not find Relay Python debugger function."; \
+    (*fdebug)("RELAY_DEBUG", __FILE__, __LINE__, __VA_ARGS__);          \
+  }
+
+/*!
+ * \brief Symbolic expression for tensor shape.
+ */
+using IndexExpr = ::tvm::PrimExpr;
+
+using SourceName = tvm::SourceName;
+using Span = tvm::Span;
+using SpanNode = tvm::SpanNode;
+
+/*!
+ * \brief This is the base node container of all relay structures.
+ */
+class RelayNode : public Object {
+ public:
+  /*! \brief The location of the program in a SourceFragment can be null,
+   * check with span.defined() */
+  mutable Span span;
+
+  static constexpr const char* _type_key = "relay.Node";
+  TVM_DECLARE_BASE_OBJECT_INFO(RelayNode, Object);
+};
+
+/*!
+ * \brief The unique identifier of variables.
+ *
+ * Id is like name to the variables,
+ * except that id is unique for each Var.
+ *
+ * \note Do not create Id directly, they are created in Var.
+ */
+class IdNode : public Object {
+ public:
+  /*!
+   * \brief The name of the variable,
+   *  this only acts as a hint to the user,
+   *  and is not used for equality.
+   */
+  String name_hint;
+
+  void VisitAttrs(tvm::AttrVisitor* v) { v->Visit("name_hint", &name_hint); }
+
+  bool SEqualReduce(const IdNode* other, SEqualReducer equal) const {
+    return equal.FreeVarEqualImpl(this, other);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const { hash_reduce.FreeVarHashImpl(this); }
+
+  static constexpr const char* _type_key = "relay.Id";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_FINAL_OBJECT_INFO(IdNode, Object);
+};
+
+class Id : public ObjectRef {
+ public:
+  /*!
+   * \brief The constructor
+   * \param name_hint The name of the variable.
+   */
+  TVM_DLL explicit Id(String name_hint);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Id, ObjectRef, IdNode);
+};
+
+}  // namespace relay
+}  // namespace tvm
+
+#endif  // TVM_RELAY_BASE_H_
diff --git a/darknet_drp_ros/include/tvm/relay/dataflow_matcher.h b/darknet_drp_ros/include/tvm/relay/dataflow_matcher.h
new file mode 100644
index 0000000..8dd5fbd
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/dataflow_matcher.h
@@ -0,0 +1,123 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/dataflow_matcher.h
+ * \brief A pattern matcher for matching dataflow properties.
+ */
+#ifndef TVM_RELAY_DATAFLOW_MATCHER_H_
+#define TVM_RELAY_DATAFLOW_MATCHER_H_
+
+#include <tvm/relay/dataflow_pattern.h>
+#include <tvm/relay/dataflow_pattern_functor.h>
+
+#include <string>
+#include <unordered_map>
+#include <utility>
+
+namespace tvm {
+namespace relay {
+
+class DFPatternCallback;
+/*!
+ * \brief Base type of all dataflow pattern callbacks.
+ * \sa DFPatternCallback
+ */
+class DFPatternCallbackNode : public Object {
+ public:
+  /*! \brief Pattern this callback matches */
+  DFPattern pattern;
+  /*! \brief Function to call when finding a matched expression */
+  PackedFunc function;
+  /*! \brief Require InferType to be run before the callback */
+  bool require_type;
+  /*! \brief Run the callback only once */
+  bool rewrite_once;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("pattern", &pattern);
+    v->Visit("require_type", &require_type);
+    v->Visit("rewrite_once", &rewrite_once);
+  }
+
+  static constexpr const char* _type_key = "DFPatternCallbackNode";
+  TVM_DECLARE_BASE_OBJECT_INFO(DFPatternCallbackNode, Object);
+};
+
+/*!
+ * \brief Managed reference to dataflow pattern callbacks.
+ * \sa DFPatternCallbackNode
+ */
+class DFPatternCallback : public ObjectRef {
+ public:
+  TVM_DLL DFPatternCallback(DFPattern pattern, PackedFunc callback, bool require_type,
+                            bool rewrite_once = false);
+  TVM_DEFINE_OBJECT_REF_METHODS(DFPatternCallback, ObjectRef, DFPatternCallbackNode);
+};
+
+/*!
+ * \brief Determine if a pattern matches an expression
+ *
+ * \param pattern The pattern to match
+ * \param expr The expression to match
+ *
+ * \return Return true if the pattern and the expression match, return false otherwise.
+ */
+bool MatchPattern(DFPattern pattern, Expr expr);
+
+/*!
+ * \brief Rewrite an expression based on some number of DFPatternCallbacks
+ *
+ * \param callbacks An array of DFPatternCallback Nodes
+ * \param expr The expression to rewrite
+ * \param mod The module that associates with the expr
+ *
+ * \return Return An Expr with every match of the pattern inside the callbacks rewritten by the
+ * functions inside the callbacks
+ */
+Expr RewritePatterns(Array<DFPatternCallback> callbacks, Expr expr, IRModule mod = IRModule());
+
+/*!
+ * \brief Partition all matches of a DFPattern inside an Expr into separate Function calls
+ *
+ * \param pattern The pattern to match
+ * \param expr The expression to patition
+ * \param attrs A set of parameter names and values to apply to the partitioned function
+ * \param check A callback function for checking more complicated properties of the matched
+ * expressions, returns true if the match is accepted and false otherwise
+ *
+ * \return Return the paritioned Expr.
+ */
+Expr PartitionPattern(DFPattern pattern, Expr expr, Map<String, ObjectRef> attrs, PackedFunc check);
+
+/*!
+ * \brief Infer the type of an expression.
+ *
+ * \param expr The expression to rewrite
+ *
+ * \return Return An Expr with unambiguous type information filled in, as well as it's
+ * checked type field populated with the result type.
+ *
+ */
+Expr InferType(const Expr& expr);
+
+}  // namespace relay
+}  // namespace tvm
+
+#endif  // TVM_RELAY_DATAFLOW_MATCHER_H_
diff --git a/darknet_drp_ros/include/tvm/relay/dataflow_pattern.h b/darknet_drp_ros/include/tvm/relay/dataflow_pattern.h
new file mode 100644
index 0000000..46abee5
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/dataflow_pattern.h
@@ -0,0 +1,542 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/dataflow_pattern.h
+ * \brief A pattern language for matching dataflow properties.
+ */
+#ifndef TVM_RELAY_DATAFLOW_PATTERN_H_
+#define TVM_RELAY_DATAFLOW_PATTERN_H_
+
+#include <tvm/relay/expr.h>
+#include <tvm/relay/type.h>
+
+#include <string>
+#include <vector>
+
+namespace tvm {
+namespace relay {
+
+/*!
+ * \brief Base type of all dataflow patterns.
+ * \sa DFPattern
+ */
+class DFPatternNode : public Object {
+ public:
+  static constexpr const char* _type_key = "DFPatternNode";
+  TVM_DECLARE_BASE_OBJECT_INFO(DFPatternNode, Object);
+};
+
+/*!
+ * \brief Managed reference to dataflow patterns.
+ * \sa DFPatternNode
+ */
+class DFPattern : public ObjectRef {
+ public:
+  /*! \brief Syntatic Sugar for creating a CallPattern */
+  DFPattern operator()(const std::vector<DFPattern>& args) const;
+  /*! \brief Syntatic Sugar for creating a CallPattern with an "add" op */
+  DFPattern operator+(const DFPattern& other) const;
+  /*! \brief Syntatic Sugar for creating a CallPattern with a "subtract" op */
+  DFPattern operator-(const DFPattern& other) const;
+  /*! \brief Syntatic Sugar for creating a CallPattern with a "multiply" op */
+  DFPattern operator*(const DFPattern& other) const;
+  /*! \brief Syntatic Sugar for creating a CallPattern with a "divide" op */
+  DFPattern operator/(const DFPattern& other) const;
+  /*! \brief Syntatic Sugar for creating an AltPattern */
+  DFPattern operator||(const DFPattern& other) const;
+  /*! \brief Syntatic Sugar for creating an Optional Pattern */
+  DFPattern Optional(const std::function<DFPattern(const DFPattern&)>& func) const;
+  /*! \brief Syntatic Sugar for creating an AttrPattern */
+  DFPattern HasAttr(const Map<String, ObjectRef>& attrs) const;
+  /*! \brief Syntatic Sugar for creating a TypePattern */
+  DFPattern HasType(const Type& type) const;
+  /*! \brief Syntatic Sugar for creating a DataTypePattern with a DataType */
+  DFPattern HasDtype(const DataType& dtype) const;
+  /*! \brief Syntatic Sugar for creating a DataTypePattern with a data type's name */
+  DFPattern HasDtype(const std::string& dtype) const;
+  /*! \brief Syntatic Sugar for creating a ShapePattern */
+  DFPattern HasShape(const Array<PrimExpr> shape) const;
+
+  TVM_DEFINE_OBJECT_REF_METHODS(DFPattern, ObjectRef, DFPatternNode);
+};
+
+/*!
+ * \brief Pattern for Relay Expression.
+ */
+class ExprPatternNode : public DFPatternNode {
+ public:
+  /*! \brief The expression to match. */
+  Expr expr;
+
+  void VisitAttrs(tvm::AttrVisitor* v) { v->Visit("expr", &expr); }
+
+  static constexpr const char* _type_key = "relay.dataflow_pattern.ExprPattern";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ExprPatternNode, DFPatternNode);
+};
+
+/*!
+ * \brief A pattern which matches a literal expression.
+ *
+ * \note Uses structural equality on expressions to check equality.
+ *
+ */
+class ExprPattern : public DFPattern {
+ public:
+  TVM_DLL explicit ExprPattern(Expr expr);
+  TVM_DEFINE_OBJECT_REF_METHODS(ExprPattern, DFPattern, ExprPatternNode);
+};
+
+/*!
+ * \brief A Pattern to Match a Relay Variable
+ */
+class VarPattern;
+/*! \brief Container for Var */
+class VarPatternNode : public DFPatternNode {
+ public:
+  /*!
+   * \brief The name of the Var (optional).
+   */
+  String name;
+
+  /*! \return The name hint of the variable */
+  const String& name_hint() const { return name; }
+
+  void VisitAttrs(tvm::AttrVisitor* v) { v->Visit("name", &name); }
+
+  static constexpr const char* _type_key = "relay.dataflow_pattern.VarPattern";
+  TVM_DECLARE_FINAL_OBJECT_INFO(VarPatternNode, DFPatternNode);
+};
+
+class VarPattern : public DFPattern {
+ public:
+  TVM_DLL VarPattern(String name_hint);
+  TVM_DEFINE_OBJECT_REF_METHODS(VarPattern, DFPattern, VarPatternNode);
+};
+
+/*!
+ * \brief A Pattern to Match a Relay Constant
+ */
+class ConstantPattern;
+/*! \brief Container for Constant */
+class ConstantPatternNode : public DFPatternNode {
+ public:
+  void VisitAttrs(tvm::AttrVisitor* v) {}
+
+  static constexpr const char* _type_key = "relay.dataflow_pattern.ConstantPattern";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ConstantPatternNode, DFPatternNode);
+};
+
+class ConstantPattern : public DFPattern {
+ public:
+  TVM_DEFINE_OBJECT_REF_METHODS(ConstantPattern, DFPattern, ConstantPatternNode);
+};
+
+/*!
+ * \brief Call corresponds to operator invocation.
+ *  Corresponds to the operator in computational graph terminology.
+ */
+class CallPattern;
+/*! \brief CallPattern container. */
+class CallPatternNode : public DFPatternNode {
+ public:
+  /*!
+   * \brief The operator(function) being invoked
+   *
+   *  - It can be relay::Op which corresponds to the primitive operators.
+   *  - It can also be user defined functions (Function, GlobalVar, Var).
+   */
+  DFPattern op;
+
+  /*! \brief The arguments(inputs) of the call */
+  tvm::Array<relay::DFPattern> args;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("op", &op);
+    v->Visit("args", &args);
+  }
+
+  static constexpr const char* _type_key = "relay.dataflow_pattern.CallPattern";
+  TVM_DECLARE_FINAL_OBJECT_INFO(CallPatternNode, DFPatternNode);
+};
+
+class CallPattern : public DFPattern {
+ public:
+  TVM_DLL CallPattern(DFPattern op, Array<DFPattern> args);
+  TVM_DEFINE_OBJECT_REF_METHODS(CallPattern, DFPattern, CallPatternNode);
+};
+
+/*!
+ * \brief Relay Function container
+ * \sa Function
+ */
+class FunctionPatternNode : public DFPatternNode {
+ public:
+  /*! \brief Function parameters */
+  tvm::Array<DFPattern> params;
+  /*!
+   * \brief
+   * The expression which represents the computation of the function,
+   * the expression may reference the parameters, and the type of it
+   * or sub-expressions may reference the type variables.
+   */
+  DFPattern body;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("params", &params);
+    v->Visit("body", &body);
+  }
+
+  static constexpr const char* _type_key = "relay.dataflow_pattern.FunctionPattern";
+  TVM_DECLARE_FINAL_OBJECT_INFO(FunctionPatternNode, DFPatternNode);
+};
+
+/*!
+ * \brief Managed reference to FunctionNode.
+ * \sa FunctionNode
+ */
+class FunctionPattern : public DFPattern {
+ public:
+  /*!
+   * \brief Constructor
+   * \param params The parameters of the function.
+   * \param body The body of the function.
+   */
+  TVM_DLL FunctionPattern(tvm::Array<DFPattern> params, DFPattern body);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(FunctionPattern, DFPattern, FunctionPatternNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(FunctionPatternNode);
+};
+
+/*! \brief A binding of a sub-network. */
+class LetPatternNode : public DFPatternNode {
+ public:
+  /*! \brief The variable we bind to */
+  DFPattern var;
+  /*! \brief The value we bind var to */
+  DFPattern value;
+  /*! \brief The body of the let binding */
+  DFPattern body;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("var", &var);
+    v->Visit("value", &value);
+    v->Visit("body", &body);
+  }
+
+  static constexpr const char* _type_key = "relay.dataflow_pattern.LetPattern";
+  TVM_DECLARE_FINAL_OBJECT_INFO(LetPatternNode, DFPatternNode);
+};
+
+/*!
+ * \brief Let binding that binds a local var
+ */
+class LetPattern : public DFPattern {
+ public:
+  /*!
+   * \brief The constructor
+   * \param var The variable that is bound to.
+   * \param value The value used to bind to the variable.
+   * \param body The body of the let binding.
+   */
+  TVM_DLL LetPattern(DFPattern var, DFPattern value, DFPattern body);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(LetPattern, DFPattern, LetPatternNode);
+};
+
+/*! \brief Tuple of multiple Exprs */
+class TuplePattern;
+/*! \brief Tuple container */
+class TuplePatternNode : public DFPatternNode {
+ public:
+  /*! \brief the fields of the tuple */
+  tvm::Array<DFPattern> fields;
+
+  void VisitAttrs(tvm::AttrVisitor* v) { v->Visit("fields", &fields); }
+
+  static constexpr const char* _type_key = "relay.dataflow_pattern.TuplePattern";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TuplePatternNode, DFPatternNode);
+};
+
+class TuplePattern : public DFPattern {
+ public:
+  TVM_DLL explicit TuplePattern(tvm::Array<DFPattern> fields);
+  TVM_DEFINE_OBJECT_REF_METHODS(TuplePattern, DFPattern, TuplePatternNode);
+};
+
+/*! \brief Get index-th field out of a tuple. */
+class TupleGetItemPattern;
+class TupleGetItemPatternNode : public DFPatternNode {
+ public:
+  /*! \brief The tuple Expression */
+  DFPattern tuple;
+  /*! \brief which value to get */
+  int index;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("tuple", &tuple);
+    v->Visit("index", &index);
+  }
+
+  static constexpr const char* _type_key = "relay.dataflow_pattern.TupleGetItemPattern";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TupleGetItemPatternNode, DFPatternNode);
+};
+
+class IfPatternNode : public DFPatternNode {
+ public:
+  DFPattern cond, true_branch, false_branch;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("cond", &cond);
+    v->Visit("true_branch", &true_branch);
+    v->Visit("false_branch", &false_branch);
+  }
+
+  static constexpr const char* _type_key = "relay.dataflow_pattern.IfPattern";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IfPatternNode, DFPatternNode);
+};
+
+class IfPattern : public DFPattern {
+ public:
+  TVM_DLL IfPattern(DFPattern cond, DFPattern then_clause, DFPattern else_clause);
+  TVM_DEFINE_OBJECT_REF_METHODS(IfPattern, DFPattern, IfPatternNode);
+};
+
+class TupleGetItemPattern : public DFPattern {
+ public:
+  TVM_DLL TupleGetItemPattern(DFPattern tuple, int index);
+  TVM_DEFINE_OBJECT_REF_METHODS(TupleGetItemPattern, DFPattern, TupleGetItemPatternNode);
+};
+
+class AltPattern;
+/*!
+ * \brief Pattern for Alternate Expressions.
+ */
+class AltPatternNode : public DFPatternNode {
+ public:
+  /*! \brief The left optional pattern. */
+  DFPattern left;
+  /*! \brief The right optional pattern. */
+  DFPattern right;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("left", &left);
+    v->Visit("right", &right);
+  }
+
+  static constexpr const char* _type_key = "relay.dataflow_pattern.AltPattern";
+  TVM_DECLARE_FINAL_OBJECT_INFO(AltPatternNode, DFPatternNode);
+};
+
+/*!
+ * \brief A pattern which matches either of two patterns
+ */
+class AltPattern : public DFPattern {
+ public:
+  TVM_DLL AltPattern(DFPattern left, DFPattern right);
+  TVM_DEFINE_OBJECT_REF_METHODS(AltPattern, DFPattern, AltPatternNode);
+};
+
+/*!
+ * \brief Wildcard Pattern.
+ */
+class WildcardPatternNode : public DFPatternNode {
+ public:
+  void VisitAttrs(tvm::AttrVisitor* v) {}
+
+  static constexpr const char* _type_key = "relay.dataflow_pattern.WildcardPattern";
+  TVM_DECLARE_FINAL_OBJECT_INFO(WildcardPatternNode, DFPatternNode);
+};
+
+/*!
+ * \brief A pattern which matches anything.
+ */
+class WildcardPattern : public DFPattern {
+ public:
+  TVM_DEFINE_OBJECT_REF_METHODS(WildcardPattern, DFPattern, WildcardPatternNode);
+};
+
+class TypePattern;
+/*!
+ * \brief Pattern for Types.
+ */
+class TypePatternNode : public DFPatternNode {
+ public:
+  /*! \brief The pattern. */
+  DFPattern pattern;
+  /*! \brief The type to match */
+  Type type;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("pattern", &pattern);
+    v->Visit("type", &type);
+  }
+
+  static constexpr const char* _type_key = "relay.dataflow_pattern.TypePattern";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TypePatternNode, DFPatternNode);
+};
+
+/*!
+ * \brief A pattern which matches a type in another pattern
+ */
+class TypePattern : public DFPattern {
+ public:
+  TVM_DLL TypePattern(DFPattern pattern, Type type);
+  TVM_DEFINE_OBJECT_REF_METHODS(TypePattern, DFPattern, TypePatternNode);
+};
+
+class ShapePattern;
+/*!
+ * \brief Pattern for Shapes.
+ */
+class ShapePatternNode : public DFPatternNode {
+ public:
+  /*! \brief The pattern. */
+  DFPattern pattern;
+  /*! \brief The type to match */
+  Array<PrimExpr> shape;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("pattern", &pattern);
+    v->Visit("shape", &shape);
+  }
+
+  static constexpr const char* _type_key = "relay.dataflow_pattern.ShapePattern";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ShapePatternNode, DFPatternNode);
+};
+
+/*!
+ * \brief A pattern which matches a type in another pattern
+ */
+class ShapePattern : public DFPattern {
+ public:
+  TVM_DLL ShapePattern(DFPattern pattern, Array<PrimExpr> type);
+  TVM_DEFINE_OBJECT_REF_METHODS(ShapePattern, DFPattern, ShapePatternNode);
+};
+
+class DataTypePattern;
+/*!
+ * \brief Pattern for Types.
+ */
+class DataTypePatternNode : public DFPatternNode {
+ public:
+  /*! \brief The pattern. */
+  DFPattern pattern;
+  /*! \brief The type to match */
+  DataType dtype;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("pattern", &pattern);
+    v->Visit("dtype", &dtype);
+  }
+
+  static constexpr const char* _type_key = "relay.dataflow_pattern.DataTypePattern";
+  TVM_DECLARE_FINAL_OBJECT_INFO(DataTypePatternNode, DFPatternNode);
+};
+
+/*!
+ * \brief A pattern which matches a type in another pattern
+ */
+class DataTypePattern : public DFPattern {
+ public:
+  TVM_DLL DataTypePattern(DFPattern pattern, DataType dtype);
+  TVM_DEFINE_OBJECT_REF_METHODS(DataTypePattern, DFPattern, DataTypePatternNode);
+};
+
+class AttrPattern;
+/*!
+ * \brief Pattern for Attributes.
+ */
+class AttrPatternNode : public DFPatternNode {
+ public:
+  /*! \brief The pattern. */
+  DFPattern pattern;
+  /*! \brief The attribute to match */
+  DictAttrs attrs;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("pattern", &pattern);
+    v->Visit("attrs", &attrs);
+  }
+
+  static constexpr const char* _type_key = "relay.dataflow_pattern.AttrPattern";
+  TVM_DECLARE_FINAL_OBJECT_INFO(AttrPatternNode, DFPatternNode);
+};
+
+/*!
+ * \brief A pattern which matches attributes in another pattern
+ */
+class AttrPattern : public DFPattern {
+ public:
+  TVM_DLL AttrPattern(DFPattern pattern, DictAttrs attrs);
+  TVM_DEFINE_OBJECT_REF_METHODS(AttrPattern, DFPattern, AttrPatternNode);
+};
+
+class DominatorPattern;
+/*!
+ * \brief Dominated Graph Pattern
+ * Pattern for fuzzy subgraphs where all outputs of the parent are used finally by the child, and
+ * every operation between the parent and the child matches the path.
+ */
+class DominatorPatternNode : public DFPatternNode {
+ public:
+  /*! \brief The parent. */
+  DFPattern parent;
+  /*! \brief The path. */
+  DFPattern path;
+  /*! \brief The child. */
+  DFPattern child;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("parent", &parent);
+    v->Visit("path", &path);
+    v->Visit("child", &child);
+  }
+
+  static constexpr const char* _type_key = "relay.dataflow_pattern.DominatorPattern";
+  TVM_DECLARE_FINAL_OBJECT_INFO(DominatorPatternNode, DFPatternNode);
+};
+
+/*!
+ * \brief A pattern which matches a variable length dominator path
+ */
+class DominatorPattern : public DFPattern {
+ public:
+  TVM_DLL DominatorPattern(DFPattern parent, DFPattern path, DFPattern child);
+  TVM_DEFINE_OBJECT_REF_METHODS(DominatorPattern, DFPattern, DominatorPatternNode);
+};
+
+/*! \brief Syntatic Sugar for creating a VarPattern with a name */
+DFPattern IsVar(const String& name);
+/*! \brief Syntatic Sugar for creating a ConstantPattern */
+DFPattern IsConstant();
+/*! \brief Syntatic Sugar for creating a WildcardPattern */
+DFPattern IsWildcard();
+/*! \brief Syntatic Sugar for creating a ExprPattern */
+DFPattern IsExpr(const Expr& expr);
+/*! \brief Syntatic Sugar for creating a ExprPattern base on an Op*/
+DFPattern IsOp(const String& op_name);
+/*! \brief Syntatic Sugar for creating a TuplePattern*/
+DFPattern IsTuple(const Array<DFPattern>& fields);
+/*! \brief Syntatic Sugar for creating a TupleGetItemPattern*/
+DFPattern IsTupleGetItem(const DFPattern tuple, int index = -1);
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_DATAFLOW_PATTERN_H_
diff --git a/darknet_drp_ros/include/tvm/relay/dataflow_pattern_functor.h b/darknet_drp_ros/include/tvm/relay/dataflow_pattern_functor.h
new file mode 100644
index 0000000..490cdc5
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/dataflow_pattern_functor.h
@@ -0,0 +1,164 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/dataflow_pattern_functor.h
+ * \brief A set of passes for operating on pattern graphs.
+ */
+#ifndef TVM_RELAY_DATAFLOW_PATTERN_FUNCTOR_H_
+#define TVM_RELAY_DATAFLOW_PATTERN_FUNCTOR_H_
+
+#include <tvm/relay/dataflow_pattern.h>
+
+#include <unordered_set>
+#include <utility>
+
+namespace tvm {
+namespace relay {
+
+/*!
+ * \brief A dynamical functor that dispatches on in the first DFPattern argument.
+ *
+ * \tparam FType function signature
+ *  This type is only defined for FType with function signature R(const DFPattern&,
+ * Args...)
+ */
+template <typename FType>
+class DFPatternFunctor;
+
+// functions to be overriden.
+#define DFPATTERN_FUNCTOR_DEFAULT \
+  { return VisitDFPatternDefault_(op, std::forward<Args>(args)...); }
+
+#define RELAY_DFPATTERN_FUNCTOR_DISPATCH(OP)                                                    \
+  vtable.template set_dispatch<OP>([](const ObjectRef& n, TSelf* self, Args... args) {          \
+    return self->VisitDFPattern_(static_cast<const OP*>(n.get()), std::forward<Args>(args)...); \
+  });
+
+template <typename R, typename... Args>
+class DFPatternFunctor<R(const DFPattern& n, Args...)> {
+ private:
+  using TSelf = DFPatternFunctor<R(const DFPattern& n, Args...)>;
+  using FType = tvm::NodeFunctor<R(const ObjectRef& n, TSelf* self, Args...)>;
+
+ public:
+  /*! \brief virtual destructor */
+  virtual ~DFPatternFunctor() {}
+  /*!
+   * \brief Same as call.
+   * \param n The expression node.
+   * \param args Additional arguments.
+   * \return The result of the call
+   */
+  R operator()(const DFPattern& n, Args... args) {
+    return VisitDFPattern(n, std::forward<Args>(args)...);
+  }
+  /*!
+   * \brief The functor call.
+   * \param n The expression node.
+   * \param args Additional arguments.
+   * \return The result of the call
+   */
+  virtual R VisitDFPattern(const DFPattern& n, Args... args) {
+    ICHECK(n.defined());
+    static FType vtable = InitVTable();
+    return vtable(n, this, std::forward<Args>(args)...);
+  }
+  // Functions that can be overriden by subclass
+  virtual R VisitDFPattern_(const AltPatternNode* op, Args... args) DFPATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitDFPattern_(const AttrPatternNode* op, Args... args) DFPATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitDFPattern_(const CallPatternNode* op, Args... args) DFPATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitDFPattern_(const ConstantPatternNode* op, Args... args) DFPATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitDFPattern_(const DataTypePatternNode* op, Args... args) DFPATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitDFPattern_(const DominatorPatternNode* op, Args... args) DFPATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitDFPattern_(const ExprPatternNode* op, Args... args) DFPATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitDFPattern_(const FunctionPatternNode* op, Args... args) DFPATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitDFPattern_(const IfPatternNode* op, Args... args) DFPATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitDFPattern_(const LetPatternNode* op, Args... args) DFPATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitDFPattern_(const ShapePatternNode* op, Args... args) DFPATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitDFPattern_(const TupleGetItemPatternNode* op,
+                            Args... args) DFPATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitDFPattern_(const TuplePatternNode* op, Args... args) DFPATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitDFPattern_(const TypePatternNode* op, Args... args) DFPATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitDFPattern_(const VarPatternNode* op, Args... args) DFPATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitDFPattern_(const WildcardPatternNode* op, Args... args) DFPATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitDFPatternDefault_(const Object* op, Args...) {
+    LOG(FATAL) << "Do not have a default for " << op->GetTypeKey();
+    throw;
+  }
+
+ private:
+  // initialize the vtable.
+  static FType InitVTable() {
+    FType vtable;
+    // Set dispatch
+    RELAY_DFPATTERN_FUNCTOR_DISPATCH(AltPatternNode);
+    RELAY_DFPATTERN_FUNCTOR_DISPATCH(AttrPatternNode);
+    RELAY_DFPATTERN_FUNCTOR_DISPATCH(CallPatternNode);
+    RELAY_DFPATTERN_FUNCTOR_DISPATCH(ConstantPatternNode);
+    RELAY_DFPATTERN_FUNCTOR_DISPATCH(DataTypePatternNode);
+    RELAY_DFPATTERN_FUNCTOR_DISPATCH(DominatorPatternNode);
+    RELAY_DFPATTERN_FUNCTOR_DISPATCH(ExprPatternNode);
+    RELAY_DFPATTERN_FUNCTOR_DISPATCH(FunctionPatternNode);
+    RELAY_DFPATTERN_FUNCTOR_DISPATCH(IfPatternNode);
+    RELAY_DFPATTERN_FUNCTOR_DISPATCH(LetPatternNode);
+    RELAY_DFPATTERN_FUNCTOR_DISPATCH(ShapePatternNode);
+    RELAY_DFPATTERN_FUNCTOR_DISPATCH(TupleGetItemPatternNode);
+    RELAY_DFPATTERN_FUNCTOR_DISPATCH(TuplePatternNode);
+    RELAY_DFPATTERN_FUNCTOR_DISPATCH(TypePatternNode);
+    RELAY_DFPATTERN_FUNCTOR_DISPATCH(VarPatternNode);
+    RELAY_DFPATTERN_FUNCTOR_DISPATCH(WildcardPatternNode);
+    return vtable;
+  }
+};
+
+/*!
+ * \brief A simple visitor wrapper around DFPatternFunctor.
+ *  Recursively visit the content.
+ *
+ *  DFPatternVisitor treats the Pattern as dataflow graph,and only visit each Expr node once.
+ */
+class DFPatternVisitor : public DFPatternFunctor<void(const DFPattern&)> {
+ public:
+  void VisitDFPattern(const DFPattern& pattern) override;
+  void VisitDFPattern_(const AltPatternNode* op) override;
+  void VisitDFPattern_(const AttrPatternNode* op) override;
+  void VisitDFPattern_(const CallPatternNode* op) override;
+  void VisitDFPattern_(const ConstantPatternNode* op) override;
+  void VisitDFPattern_(const DataTypePatternNode* op) override;
+  void VisitDFPattern_(const DominatorPatternNode* op) override;
+  void VisitDFPattern_(const ExprPatternNode* op) override;
+  void VisitDFPattern_(const FunctionPatternNode* op) override;
+  void VisitDFPattern_(const IfPatternNode* op) override;
+  void VisitDFPattern_(const LetPatternNode* op) override;
+  void VisitDFPattern_(const ShapePatternNode* op) override;
+  void VisitDFPattern_(const TupleGetItemPatternNode* op) override;
+  void VisitDFPattern_(const TuplePatternNode* op) override;
+  void VisitDFPattern_(const TypePatternNode* op) override;
+  void VisitDFPattern_(const VarPatternNode* op) override;
+  void VisitDFPattern_(const WildcardPatternNode* op) override;
+
+ protected:
+  // set of already-visited nodes
+  std::unordered_set<const Object*> visited_;
+};
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_DATAFLOW_PATTERN_FUNCTOR_H_
diff --git a/darknet_drp_ros/include/tvm/relay/executor.h b/darknet_drp_ros/include/tvm/relay/executor.h
new file mode 100644
index 0000000..858ba5c
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/executor.h
@@ -0,0 +1,277 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/executor.h
+ * \brief Object representation of Executor configuration and registry
+ */
+#ifndef TVM_RELAY_EXECUTOR_H_
+#define TVM_RELAY_EXECUTOR_H_
+
+#include <dmlc/registry.h>
+#include <tvm/ir/attrs.h>
+#include <tvm/ir/expr.h>
+#include <tvm/ir/type.h>
+#include <tvm/ir/type_relation.h>
+#include <tvm/node/attr_registry_map.h>
+#include <tvm/runtime/registry.h>
+
+#include <string>
+#include <unordered_map>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+
+template <typename, typename>
+class AttrRegistry;
+
+namespace relay {
+
+/*!
+ * \brief Executor information.
+ *
+ * This data structure stores the meta-data
+ * about executors which can be used to pass around information.
+ *
+ * \sa Executor
+ */
+class ExecutorNode : public Object {
+ public:
+  /*! \brief name of the Executor */
+  String name;
+  /* \brief Additional attributes storing meta-data about the Executor. */
+  DictAttrs attrs;
+
+  /*!
+   * \brief Should Link Parameters into the module
+   * \return Whether the Executor is configured to execute modules with linked parameters
+   */
+  Bool ShouldLinkParameters() const {
+    return name == "aot" || GetAttr<Bool>("link-params").value_or(Bool(false));
+  }
+
+  /*!
+   * \brief Get an attribute.
+   *
+   * \param attr_key The attribute key.
+   * \param default_value The default value if the key does not exist, defaults to nullptr.
+   *
+   * \return The result
+   *
+   * \tparam TObjectRef the expected object type.
+   * \throw Error if the key exists but the value does not match TObjectRef
+   *
+   * \code
+   *
+   *  void GetAttrExample(const Executor& executor) {
+   *    auto value = executor->GetAttr<Integer>("AttrKey", 0);
+   *  }
+   *
+   * \endcode
+   */
+  template <typename TObjectRef>
+  Optional<TObjectRef> GetAttr(
+      const std::string& attr_key,
+      Optional<TObjectRef> default_value = Optional<TObjectRef>(nullptr)) const {
+    return attrs.GetAttr(attr_key, default_value);
+  }
+  // variant that uses TObjectRef to enable implicit conversion to default value.
+  template <typename TObjectRef>
+  Optional<TObjectRef> GetAttr(const std::string& attr_key, TObjectRef default_value) const {
+    return GetAttr<TObjectRef>(attr_key, Optional<TObjectRef>(default_value));
+  }
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("name", &name);
+    v->Visit("attrs", &attrs);
+  }
+
+  bool SEqualReduce(const ExecutorNode* other, SEqualReducer equal) const {
+    return name == other->name && equal.DefEqual(attrs, other->attrs);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(name);
+    hash_reduce(attrs);
+  }
+
+  static constexpr const char* _type_key = "Executor";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_FINAL_OBJECT_INFO(ExecutorNode, Object);
+};
+
+/*!
+ * \brief Managed reference class to ExecutorNode.
+ * \sa ExecutorNode
+ */
+class Executor : public ObjectRef {
+ public:
+  /*!
+   * \brief Create a new Executor object using the registry
+   * \throws Error if name is not registered
+   * \param name The name of the executor.
+   * \param attrs Attributes for the executor.
+   * \return the new Executor object.
+   */
+  TVM_DLL static Executor Create(String name, Map<String, ObjectRef> attrs = {});
+
+  /*!
+   * \brief List all registered Executors
+   * \return the list of Executors
+   */
+  TVM_DLL static Array<String> ListExecutors();
+
+  /*!
+   * \brief List all options for a specific Executor
+   * \param name The name of the Executor
+   * \return Map of option name to type
+   */
+  TVM_DLL static Map<String, String> ListExecutorOptions(const String& name);
+
+  /*! \brief specify container node */
+  TVM_DEFINE_OBJECT_REF_METHODS(Executor, ObjectRef, ExecutorNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(ExecutorNode)
+
+ private:
+  /*!
+   * \brief Private Constructor
+   * \param name The executor name
+   * \param attrs Attributes to apply to this Executor node
+   */
+  TVM_DLL Executor(String name, DictAttrs attrs) {
+    auto n = make_object<ExecutorNode>();
+    n->name = std::move(name);
+    n->attrs = std::move(attrs);
+    data_ = std::move(n);
+  }
+};
+
+/*!
+ * \brief Helper structure to register Executors
+ * \sa TVM_REGISTER_EXECUTOR
+ */
+class ExecutorRegEntry {
+ public:
+  /*!
+   * \brief Register a valid configuration option and its ValueType for validation
+   * \param key The configuration key
+   * \tparam ValueType The value type to be registered
+   */
+  template <typename ValueType>
+  inline ExecutorRegEntry& add_attr_option(const String& key);
+
+  /*!
+   * \brief Register a valid configuration option and its ValueType for validation
+   * \param key The configuration key
+   * \param default_value The default value of the key
+   * \tparam ValueType The value type to be registered
+   */
+  template <typename ValueType>
+  inline ExecutorRegEntry& add_attr_option(const String& key, ObjectRef default_value);
+
+  /*!
+   * \brief Register or get a new entry.
+   * \param name The name of the operator.
+   * \return the corresponding entry.
+   */
+  TVM_DLL static ExecutorRegEntry& RegisterOrGet(const String& name);
+
+ private:
+  /*! \brief Internal storage of value types */
+  struct ValueTypeInfo {
+    std::string type_key;
+    uint32_t type_index;
+  };
+  std::unordered_map<std::string, ValueTypeInfo> key2vtype_;
+  /*! \brief A hash table that stores the default value of each attr */
+  std::unordered_map<String, ObjectRef> key2default_;
+
+  /*! \brief Index used for internal lookup of attribute registry */
+  uint32_t index_;
+
+  // the name
+  std::string name;
+
+  /*! \brief Return the index stored in attr registry */
+  uint32_t AttrRegistryIndex() const { return index_; }
+  /*! \brief Return the name stored in attr registry */
+  String AttrRegistryName() const { return name; }
+
+  /*! \brief private constructor */
+  explicit ExecutorRegEntry(uint32_t reg_index) : index_(reg_index) {}
+
+  // friend class
+  template <typename>
+  friend class AttrRegistryMapContainerMap;
+  template <typename, typename>
+  friend class tvm::AttrRegistry;
+  friend class Executor;
+};
+
+template <typename ValueType>
+inline ExecutorRegEntry& ExecutorRegEntry::add_attr_option(const String& key) {
+  ICHECK(!key2vtype_.count(key)) << "AttributeError: add_attr_option failed because '" << key
+                                 << "' has been set once";
+
+  using ValueNodeType = typename ValueType::ContainerType;
+  // NOTE: we could further update the function later.
+  uint32_t value_type_index = ValueNodeType::_GetOrAllocRuntimeTypeIndex();
+
+  ValueTypeInfo info;
+  info.type_index = value_type_index;
+  info.type_key = runtime::Object::TypeIndex2Key(value_type_index);
+  key2vtype_[key] = info;
+  return *this;
+}
+
+template <typename ValueType>
+inline ExecutorRegEntry& ExecutorRegEntry::add_attr_option(const String& key,
+                                                           ObjectRef default_value) {
+  add_attr_option<ValueType>(key);
+  key2default_[key] = default_value;
+  return *this;
+}
+
+// internal macros to make executor entries
+#define TVM_EXECUTOR_REGISTER_VAR_DEF \
+  static DMLC_ATTRIBUTE_UNUSED ::tvm::relay::ExecutorRegEntry& __make_##Executor
+
+/*!
+ * \def TVM_REGISTER_EXECUTOR
+ * \brief Register a new executor, or set attribute of the corresponding executor.
+ *
+ * \param ExecutorName The name of registry
+ *
+ * \code
+ *
+ *  TVM_REGISTER_EXECUTOR("aot")
+ *  .add_attr_option<String>("my_option");
+ *  .add_attr_option<String>("my_option_default", String("default"));
+ *
+ * \endcode
+ */
+#define TVM_REGISTER_EXECUTOR(ExecutorName)                    \
+  TVM_STR_CONCAT(TVM_EXECUTOR_REGISTER_VAR_DEF, __COUNTER__) = \
+      ::tvm::relay::ExecutorRegEntry::RegisterOrGet(ExecutorName)
+}  // namespace relay
+}  // namespace tvm
+
+#endif  // TVM_RELAY_EXECUTOR_H_
diff --git a/darknet_drp_ros/include/tvm/relay/expr.h b/darknet_drp_ros/include/tvm/relay/expr.h
new file mode 100644
index 0000000..bd094a7
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/expr.h
@@ -0,0 +1,834 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/expr.h
+ * \brief Relay expression language.
+ */
+#ifndef TVM_RELAY_EXPR_H_
+#define TVM_RELAY_EXPR_H_
+
+#include <tvm/ir/attrs.h>
+#include <tvm/ir/expr.h>
+#include <tvm/ir/module.h>
+#include <tvm/ir/op.h>
+#include <tvm/target/virtual_device.h>
+
+#include <functional>
+#include <stack>
+#include <string>
+#include <utility>
+
+#include "./base.h"
+#include "./type.h"
+
+namespace tvm {
+
+/*!
+ * \brief Returns \p global_var with the given properties. A null property denotes 'no change'.
+ * Returns \p global_var if all properties are unchanged. Otherwise, returns a copy with the new
+ * fields.
+ */
+GlobalVar WithFields(GlobalVar global_var, Optional<String> opt_name_hint = {},
+                     Optional<Type> opt_type = {}, Optional<VirtualDevice> opt_virtual_device = {},
+                     Optional<Span> opt_span = {});
+
+namespace relay {
+
+using Expr = tvm::RelayExpr;
+using ExprNode = tvm::RelayExprNode;
+using BaseFunc = tvm::BaseFunc;
+using BaseFuncNode = tvm::BaseFuncNode;
+using GlobalVar = tvm::GlobalVar;
+using GlobalVarNode = tvm::GlobalVarNode;
+using tvm::PrettyPrint;
+
+/*!
+ * \brief Constant tensor, backed by an NDArray on the cpu(0) device.
+ *
+ * \note Scalar constants are represented by rank-0 const tensor.
+ *  Constant folding are handled uniformly via Tensor types.
+ */
+class Constant;
+/*!
+ * \brief Constant tensor type.
+ */
+class ConstantNode : public ExprNode {
+ public:
+  /*! \brief The data of the tensor */
+  runtime::NDArray data;
+
+  /*! \return The corresponding tensor type of the data */
+  TensorType tensor_type() const;
+
+  /*! \return Whether it is scalar(rank-0 tensor) */
+  bool is_scalar() const { return data->ndim == 0; }
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("data", &data);
+    v->Visit("virtual_device_", &virtual_device_);
+    v->Visit("span", &span);
+    v->Visit("_checked_type_", &checked_type_);
+  }
+
+  bool SEqualReduce(const ConstantNode* other, SEqualReducer equal) const {
+    return equal(data, other->data);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const { hash_reduce(data); }
+
+  static constexpr const char* _type_key = "relay.Constant";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ConstantNode, ExprNode);
+};
+
+class Constant : public Expr {
+ public:
+  /*!
+   * \brief The constructor
+   * \param data The data of the constant tensor.
+   * \param span The source span of the expression.
+   */
+  TVM_DLL explicit Constant(runtime::NDArray data, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Constant, RelayExpr, ConstantNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(ConstantNode);
+};
+
+/*!
+ * \brief Returns \p constant with the given properties. A null property denotes 'no change'.
+ * Returns \p constant if all properties are unchanged. Otherwise, returns a copy with the new
+ * fields.
+ */
+Constant WithFields(Constant constant, Optional<runtime::NDArray> opt_data = {},
+                    Optional<VirtualDevice> opt_virtual_device = {}, Optional<Span> opt_span = {});
+
+/*! \brief Tuple of multiple Exprs */
+class Tuple;
+/*! \brief Tuple container */
+class TupleNode : public ExprNode {
+ public:
+  /*! \brief the fields of the tuple */
+  tvm::Array<relay::Expr> fields;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("fields", &fields);
+    v->Visit("virtual_device_", &virtual_device_);
+    v->Visit("span", &span);
+    v->Visit("_checked_type_", &checked_type_);
+  }
+
+  bool SEqualReduce(const TupleNode* other, SEqualReducer equal) const {
+    // specially handle empty tuple as a constant is not a graph node.
+    if (fields.size() == other->fields.size() && fields.size() == 0) {
+      return true;
+    } else {
+      equal->MarkGraphNode();
+      return equal(fields, other->fields);
+    }
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    if (fields.size() != 0) {
+      hash_reduce->MarkGraphNode();
+      hash_reduce(fields);
+    }
+  }
+
+  static constexpr const char* _type_key = "relay.Tuple";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TupleNode, ExprNode);
+};
+
+class Tuple : public Expr {
+ public:
+  /*!
+   * \brief The constructor
+   * \param fields The fields of a tuple.
+   * \param span The source span of the expression.
+   */
+  TVM_DLL explicit Tuple(tvm::Array<relay::Expr> fields, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Tuple, RelayExpr, TupleNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(TupleNode);
+};
+
+/*!
+ * \brief Returns \p tuple with the given properties. A null property denotes 'no change'.
+ * Returns \p tuple if all properties are unchanged. Otherwise, returns a copy with the new
+ * fields.
+ */
+Tuple WithFields(Tuple tuple, Optional<Array<Expr>> opt_fields = Optional<Array<Expr>>(),
+                 Optional<VirtualDevice> opt_virtual_device = Optional<VirtualDevice>(),
+                 Optional<Span> opt_span = Optional<Span>());
+
+/*!
+ * \brief Local variables used in the let expression.
+ *
+ * Its semantics are similar to tvm.Var node used in TVM's low level
+ * tensor expression language.
+ *
+ * \note Each Var is bind only once and is immutable.
+ */
+class Var;
+/*! \brief Container for Var */
+class VarNode : public ExprNode {
+ public:
+  /*!
+   * \brief The unique identifier of the Var.
+   *
+   * vid will be preserved for the same Var during type inference
+   * and other rewritings, while the VarNode might be recreated
+   * to attach additional information.
+   * This property can be used to keep track of parameter Var
+   * information across passes.
+   */
+  Id vid;
+  /*!
+   * \brief type annotaion of the variable.
+   * This field records user provided type annotation of the Var.
+   * This field is optional and can be None.
+   */
+  Type type_annotation;
+
+  /*! \return The name hint of the variable */
+  const String& name_hint() const { return vid->name_hint; }
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("vid", &vid);
+    v->Visit("type_annotation", &type_annotation);
+    v->Visit("virtual_device_", &virtual_device_);
+    v->Visit("span", &span);
+    v->Visit("_checked_type_", &checked_type_);
+  }
+
+  bool SEqualReduce(const VarNode* other, SEqualReducer equal) const {
+    equal->MarkGraphNode();
+    return equal(type_annotation, other->type_annotation) && equal(vid, other->vid) &&
+           equal(virtual_device_, other->virtual_device_);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce->MarkGraphNode();
+    hash_reduce(type_annotation);
+    hash_reduce(vid);
+  }
+
+  static constexpr const char* _type_key = "relay.Var";
+  TVM_DECLARE_FINAL_OBJECT_INFO(VarNode, ExprNode);
+};
+
+class Var : public Expr {
+ public:
+  /*!
+   * \brief The constructor
+   * \param name_hint The name hint of a variable.
+   * \param type_annotation The type annotation of a variable.
+   * \param span The source span of the expression.
+   */
+  TVM_DLL Var(String name_hint, Type type_annotation, Span span = Span())
+      : Var(Id(name_hint), type_annotation, span) {}
+
+  /*!
+   * \brief The constructor
+   * \param vid The unique id of a variable.
+   * \param type_annotation The type annotation of a variable.
+   * \param span The source span of the expression.
+   */
+  TVM_DLL Var(Id vid, Type type_annotation, Span span = Span());
+
+  /*!
+   * \brief Return a globally fresh name. Helps with debugging to follow the same
+   * variable between passes and sub-expressions.
+   *
+   * TODO(mbs): Replace with name creation w.r.t. scopes once available as part of
+   * name gen overhaul.
+   */
+  static Var GenSym(Type type_annotation = {}, Span span = {});
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Var, RelayExpr, VarNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(VarNode);
+};
+
+/*!
+ * \brief Returns \p vor with the given properties. A null property denotes 'no change'.
+ * Returns \p var if all properties are unchanged. Otherwise, returns a copy with the new
+ * fields.
+ */
+Var WithFields(Var var, Optional<Id> opt_vid = Optional<Id>(),
+               Optional<Type> opt_type_annotation = Optional<Type>(),
+               Optional<VirtualDevice> opt_virtual_device = Optional<VirtualDevice>(),
+               Optional<Span> opt_span = Optional<Span>());
+
+/*!
+ * \brief Call corresponds to operator invocation.
+ *  Corresponds to the operator in computational graph terminology.
+ */
+class Call;
+/*! \brief Call container. */
+class CallNode : public ExprNode {
+ protected:
+  // CallNode uses own deleter to indirectly call non-recursive destructor
+  Object::FDeleter saved_deleter_;
+  static void Deleter_(Object* ptr);
+
+ public:
+  /*!
+   * \brief The operator(function) being invoked
+   *
+   *  - It can be tvm::Op which corresponds to the primitive operators.
+   *  - It can also be user defined functions (Function, GlobalVar, Var).
+   */
+  Expr op;
+
+  /*! \brief The arguments(inputs) of the call */
+  tvm::Array<relay::Expr> args;
+
+  /*! \brief The additional attributes */
+  Attrs attrs;
+
+  /*!
+   * \brief The type arguments passed to polymorphic(template) function.
+   *
+   * This is the advance feature that is only used when the function is
+   * polymorphic. It is safe to be ignored in most cases. For example, in the
+   * following code, the type_args of addone call is [int].
+   *
+   * \code
+   *
+   * template<typename T>
+   * T addone(T a) { return a + 1; }
+   *
+   * void main() {
+   *   int x = addone<int>(10);
+   * }
+   *
+   * \endcode
+   */
+  tvm::Array<Type> type_args;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("op", &op);
+    v->Visit("args", &args);
+    v->Visit("attrs", &attrs);
+    v->Visit("type_args", &type_args);
+    v->Visit("virtual_device_", &virtual_device_);
+    v->Visit("span", &span);
+    v->Visit("_checked_type_", &checked_type_);
+  }
+
+  bool SEqualReduce(const CallNode* other, SEqualReducer equal) const {
+    // skip type_args check for primitive ops.
+    equal->MarkGraphNode();
+    return equal(op, other->op) && equal(args, other->args) && equal(attrs, other->attrs) &&
+           (IsPrimitiveOp(op) || equal(type_args, other->type_args));
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce->MarkGraphNode();
+    hash_reduce(op);
+    hash_reduce(args);
+    hash_reduce(attrs);
+    if (!IsPrimitiveOp(op)) {
+      hash_reduce(type_args);
+    }
+  }
+
+  static constexpr const char* _type_key = "relay.Call";
+  TVM_DECLARE_FINAL_OBJECT_INFO(CallNode, ExprNode);
+  template <typename>
+  friend class runtime::ObjAllocatorBase;
+  friend class Call;
+};
+
+class Call : public Expr {
+ public:
+  /*!
+   * \brief The destructor
+   */
+  ~Call();
+
+  /*!
+   * \brief The constructor
+   * \param op The operator will be invoked.
+   * \param args The arguments of the call.
+   * \param attrs The attributes of the call node.
+   * \param type_args The type arguments passed to a polymorphic function.
+   * \param span The source span of the expression.
+   */
+  TVM_DLL Call(Expr op, Array<Expr> args, Attrs attrs = Attrs(),
+               Array<Type> type_args = Array<Type>(), Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Call, RelayExpr, CallNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(CallNode);
+};
+
+/*!
+ * \brief Returns \p call with the given properties. A null property denotes 'no change'.
+ * Returns \p call if all properties are unchanged. Otherwise, returns a copy with the new
+ * fields.
+ */
+Call WithFields(Call call, Optional<Expr> opt_op = Optional<Expr>(),
+                Optional<Array<Expr>> opt_args = Optional<Array<Expr>>(),
+                Optional<Attrs> opt_attrs = Optional<Attrs>(),
+                Optional<Array<Type>> opt_type_args = Optional<Array<Type>>(),
+                Optional<VirtualDevice> opt_virtual_device = Optional<VirtualDevice>(),
+                Optional<Span> opt_span = Optional<Span>());
+
+/*!
+ * \brief Let binding that binds a local var and optionally a type annotation.
+ *
+ * \note Let is useful to transform the program to be A-normal form.
+ *  where each of the expression corresponds to a let binding.
+ *
+ *  For developers who are familar with the computational graph.
+ *  Each of the let can be viewed as a operator node in the computational graph.
+ *  Traversing the list of let bindings is similar to running
+ * PostDFS-order(topo-order) traversal on the computational graph.
+ */
+class Let;
+/*! \brief A binding of a sub-network. */
+class LetNode : public ExprNode {
+ protected:
+  // LetNode uses own deleter to indirectly call non-recursive destructor
+  Object::FDeleter saved_deleter_;
+  static void Deleter_(Object* ptr);
+
+ public:
+  /*! \brief The variable we bind to */
+  Var var;
+  /*! \brief The value we bind var to */
+  Expr value;
+  /*! \brief The body of the let binding */
+  Expr body;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("var", &var);
+    v->Visit("value", &value);
+    v->Visit("body", &body);
+    v->Visit("virtual_device_", &virtual_device_);
+    v->Visit("span", &span);
+    v->Visit("_checked_type_", &checked_type_);
+  }
+
+  bool SEqualReduce(const LetNode* other, SEqualReducer equal) const {
+    equal->MarkGraphNode();
+    return equal.DefEqual(var, other->var) && equal(value, other->value) &&
+           equal(body, other->body);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce->MarkGraphNode();
+    hash_reduce.DefHash(var);
+    hash_reduce(value);
+    hash_reduce(body);
+  }
+
+  static constexpr const char* _type_key = "relay.Let";
+  TVM_DECLARE_FINAL_OBJECT_INFO(LetNode, ExprNode);
+  template <typename>
+  friend class runtime::ObjAllocatorBase;
+  friend class Let;
+};
+
+class Let : public Expr {
+ public:
+  /*!
+   * \brief The destructor
+   */
+  ~Let();
+
+  /*!
+   * \brief The constructor
+   * \param var The variable that is bound to.
+   * \param value The value used to bind to the variable.
+   * \param body The body of the let binding.
+   * \param span The source span of the expression.
+   */
+  TVM_DLL Let(Var var, Expr value, Expr body, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Let, RelayExpr, LetNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(LetNode);
+};
+
+/*!
+ * \brief Returns \p let with the given properties. A null property denotes 'no change'.
+ * Returns \p let if all properties are unchanged. Otherwise, returns a copy with the new
+ * fields.
+ */
+Let WithFields(Let let, Optional<Var> opt_var = Optional<Var>(),
+               Optional<Expr> opt_value = Optional<Expr>(),
+               Optional<Expr> opt_body = Optional<Expr>(),
+               Optional<VirtualDevice> opt_virtual_device = Optional<VirtualDevice>(),
+               Optional<Span> opt_span = Optional<Span>());
+
+/*!
+ * \brief Condition expression
+ *
+ * Unlike traditional statement `if`s, the if evalutes
+ * to the result of the branch taken.
+ *
+ * let x = if (true) { 1 } else { 0 }; // x is 1
+ * let y = if (false) { 1 } else { 0 }; // y is 0
+ *
+ * \note This is similar to C's ternary operator.
+ */
+class If;
+/*! \brief container of If */
+class IfNode : public ExprNode {
+ public:
+  /*! \brief The condition */
+  Expr cond;
+  /*! \brief The expression evaluated when condition is true. */
+  Expr true_branch;
+  /*! \brief The expression evaluated when condition is false */
+  Expr false_branch;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("cond", &cond);
+    v->Visit("true_branch", &true_branch);
+    v->Visit("false_branch", &false_branch);
+    v->Visit("virtual_device_", &virtual_device_);
+    v->Visit("span", &span);
+    v->Visit("_checked_type_", &checked_type_);
+  }
+
+  bool SEqualReduce(const IfNode* other, SEqualReducer equal) const {
+    equal->MarkGraphNode();
+    return equal(cond, other->cond) && equal(true_branch, other->true_branch) &&
+           equal(false_branch, other->false_branch);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce->MarkGraphNode();
+    hash_reduce(cond);
+    hash_reduce(true_branch);
+    hash_reduce(false_branch);
+  }
+
+  static constexpr const char* _type_key = "relay.If";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IfNode, ExprNode);
+};
+
+class If : public Expr {
+ public:
+  /*!
+   * \brief The constructor
+   * \param cond The condition of a if node.
+   * \param true_branch The fall through branch
+   * \param false_branch The branch for execution when condition is false.
+   * \param span The source span of the expression.
+   */
+  TVM_DLL If(Expr cond, Expr true_branch, Expr false_branch, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(If, RelayExpr, IfNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(IfNode);
+};
+
+/*!
+ * \brief Returns \p if_expr with the given properties. A null property denotes 'no change'.
+ * Returns \p if_expr if all properties are unchanged. Otherwise, returns a copy with the new
+ * fields.
+ */
+If WithFields(If if_expr, Optional<Expr> opt_cond = Optional<Expr>(),
+              Optional<Expr> opt_true_branch = Optional<Expr>(),
+              Optional<Expr> opt_false_branch = Optional<Expr>(),
+              Optional<VirtualDevice> opt_virtual_device = Optional<VirtualDevice>(),
+              Optional<Span> opt_span = Optional<Span>());
+
+/*! \brief Get index-th field out of a tuple. */
+class TupleGetItem;
+class TupleGetItemNode : public ExprNode {
+ public:
+  /*! \brief The tuple Expression */
+  Expr tuple;
+  /*! \brief which value to get */
+  int index;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("tuple_value", &tuple);
+    v->Visit("index", &index);
+    v->Visit("virtual_device_", &virtual_device_);
+    v->Visit("span", &span);
+    v->Visit("_checked_type_", &checked_type_);
+  }
+
+  bool SEqualReduce(const TupleGetItemNode* other, SEqualReducer equal) const {
+    return equal(tuple, other->tuple) && equal(index, other->index);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(tuple);
+    hash_reduce(index);
+  }
+
+  static constexpr const char* _type_key = "relay.TupleGetItem";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TupleGetItemNode, ExprNode);
+};
+
+class TupleGetItem : public Expr {
+ public:
+  /*!
+   * \brief The constructor
+   * \param tuple The tuple to get an element from.
+   * \param index The index for extracting a value in the tuple.
+   * \param span The source span of the expression.
+   */
+  TVM_DLL TupleGetItem(Expr tuple, int index, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(TupleGetItem, RelayExpr, TupleGetItemNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(TupleGetItemNode);
+};
+
+/*!
+ * \brief Returns \p tuple_get_item with the given properties. A null property denotes 'no change'.
+ * Returns \p tuple_get_item if all properties are unchanged. Otherwise, returns a copy with the new
+ * fields.
+ */
+TupleGetItem WithFields(TupleGetItem tuple_get_item, Optional<Expr> opt_tuple = Optional<Expr>(),
+                        Optional<Integer> opt_index = Optional<Integer>(),
+                        Optional<VirtualDevice> opt_virtual_device = Optional<VirtualDevice>(),
+                        Optional<Span> opt_span = Optional<Span>());
+
+/*! \brief Create a new Reference out of initial value. */
+class RefCreate;
+class RefCreateNode : public ExprNode {
+ public:
+  /*! \brief The initial value of the Reference. */
+  Expr value;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("value", &value);
+    v->Visit("virtual_device_", &virtual_device_);
+    v->Visit("span", &span);
+    v->Visit("_checked_type_", &checked_type_);
+  }
+
+  bool SEqualReduce(const RefCreateNode* other, SEqualReducer equal) const {
+    equal->MarkGraphNode();
+    return equal(value, other->value);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce->MarkGraphNode();
+    hash_reduce(value);
+  }
+
+  static constexpr const char* _type_key = "relay.RefCreate";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RefCreateNode, ExprNode);
+};
+
+class RefCreate : public Expr {
+ public:
+  /*!
+   * \brief The constructor
+   * \param value The initial value of the reference.
+   * \param span The source span of the expression.
+   */
+  TVM_DLL explicit RefCreate(Expr value, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(RefCreate, RelayExpr, RefCreateNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(RefCreateNode);
+};
+
+/*!
+ * \brief Returns \p ref_create with the given properties. A null property denotes 'no change'.
+ * Returns \p ref_crete if all properties are unchanged. Otherwise, returns a copy with the new
+ * fields.
+ */
+RefCreate WithFields(RefCreate ref_create, Optional<Expr> opt_value = Optional<Expr>(),
+                     Optional<VirtualDevice> opt_virtual_device = Optional<VirtualDevice>(),
+                     Optional<Span> opt_span = Optional<Span>());
+
+/*! \brief Get value out of Reference. */
+class RefRead;
+class RefReadNode : public ExprNode {
+ public:
+  /*! \brief The Reference Expression. */
+  Expr ref;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("ref", &ref);
+    v->Visit("virtual_device_", &virtual_device_);
+    v->Visit("span", &span);
+    v->Visit("_checked_type_", &checked_type_);
+  }
+
+  bool SEqualReduce(const RefReadNode* other, SEqualReducer equal) const {
+    equal->MarkGraphNode();
+    return equal(ref, other->ref);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce->MarkGraphNode();
+    hash_reduce(ref);
+  }
+
+  static constexpr const char* _type_key = "relay.RefRead";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RefReadNode, ExprNode);
+};
+
+class RefRead : public Expr {
+ public:
+  /*!
+   * \brief The constructor
+   * \param ref The reference where to read data.
+   * \param span The source span of the expression.
+   */
+  TVM_DLL explicit RefRead(Expr ref, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(RefRead, RelayExpr, RefReadNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(RefReadNode);
+};
+
+/*!
+ * \brief Returns \p ref_read with the given properties. A null property denotes 'no change'.
+ * Returns \p ref_read if all properties are unchanged. Otherwise, returns a copy with the new
+ * fields.
+ */
+RefRead WithFields(RefRead ref_read, Optional<Expr> opt_ref = Optional<Expr>(),
+                   Optional<VirtualDevice> opt_virtual_device = Optional<VirtualDevice>(),
+                   Optional<Span> opt_span = Optional<Span>());
+
+/*! \brief Set value of Reference. The whole expression evaluates to an Empty Tuple. */
+class RefWrite;
+class RefWriteNode : public ExprNode {
+ public:
+  /*! \brief The Reference Expression. */
+  Expr ref;
+  /*! \brief The value to write into. */
+  Expr value;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("ref", &ref);
+    v->Visit("value", &value);
+    v->Visit("virtual_device_", &virtual_device_);
+    v->Visit("span", &span);
+    v->Visit("_checked_type_", &checked_type_);
+  }
+
+  bool SEqualReduce(const RefWriteNode* other, SEqualReducer equal) const {
+    equal->MarkGraphNode();
+    return equal(ref, other->ref) && equal(value, other->value);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce->MarkGraphNode();
+    hash_reduce(ref);
+    hash_reduce(value);
+  }
+
+  static constexpr const char* _type_key = "relay.RefWrite";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RefWriteNode, ExprNode);
+};
+
+class RefWrite : public Expr {
+ public:
+  /*!
+   * \brief The constructor
+   * \param ref The reference where data is write to.
+   * \param value The value to write.
+   * \param span The source span of the expression.
+   */
+  TVM_DLL RefWrite(Expr ref, Expr value, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(RefWrite, RelayExpr, RefWriteNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(RefWriteNode);
+};
+
+/*!
+ * \brief Returns \p ref_write with the given properties. A null property denotes 'no change'.
+ * Returns \p ref_write if all properties are unchanged. Otherwise, returns a copy with the new
+ * fields.
+ */
+RefWrite WithFields(RefWrite ref_write, Optional<Expr> opt_ref = Optional<Expr>(),
+                    Optional<Expr> opt_value = Optional<Expr>(),
+                    Optional<VirtualDevice> opt_virtual_device = Optional<VirtualDevice>(),
+                    Optional<Span> opt_span = Optional<Span>());
+
+/*!
+ * \brief Base class of the temporary expression.
+ *
+ * TempExprs are pass specific expression that can be
+ * useful to define intermediate result in the
+ * rewriting pass such as layout or type transformation.
+ *
+ * Subclass TempExprNode allows us to pattern match on
+ * specific kind of TempExpr and use them for expression rewriting.
+ *
+ * TempExpr should only be used within a pass,
+ */
+class TempExprNode : public ExprNode {
+ public:
+  /*! \brief virtual destructor */
+  virtual ~TempExprNode() {}
+  /*!
+   * \brief Convert the expression to a normal(non-temp) Expr.
+   * \return The corresponding normal(non-temp) expression.
+   */
+  virtual Expr Realize() const = 0;
+
+  static constexpr const char* _type_key = "relay.TempExpr";
+  static constexpr const bool _type_has_method_sequal_reduce = false;
+  static constexpr const bool _type_has_method_shash_reduce = false;
+  static constexpr const uint32_t _type_child_slots = 0;
+  TVM_DECLARE_BASE_OBJECT_INFO(TempExprNode, ExprNode);
+};
+
+class TempExpr : public Expr {
+ public:
+  TVM_DEFINE_OBJECT_REF_METHODS(TempExpr, RelayExpr, TempExprNode);
+};
+
+}  // namespace relay
+
+namespace runtime {
+
+template <>
+template <>
+inline ObjectPtr<relay::LetNode>
+ObjAllocatorBase<SimpleObjAllocator>::make_object<relay::LetNode>() {
+  using Derived = SimpleObjAllocator;
+  using T = relay::LetNode;
+  using Handler = typename Derived::template Handler<T>;
+  static_assert(std::is_base_of<Object, T>::value, "make can only be used to create Object");
+  T* ptr = Handler::New(static_cast<Derived*>(this));
+  ptr->type_index_ = T::RuntimeTypeIndex();
+  ptr->saved_deleter_ = Handler::Deleter();
+  ptr->deleter_ = relay::LetNode::Deleter_;
+  return ObjectPtr<T>(ptr);
+}
+
+template <>
+template <>
+inline ObjectPtr<relay::CallNode>
+ObjAllocatorBase<SimpleObjAllocator>::make_object<relay::CallNode>() {
+  using Derived = SimpleObjAllocator;
+  using T = relay::CallNode;
+  using Handler = typename Derived::template Handler<T>;
+  static_assert(std::is_base_of<Object, T>::value, "make can only be used to create Object");
+  T* ptr = Handler::New(static_cast<Derived*>(this));
+  ptr->type_index_ = T::RuntimeTypeIndex();
+  ptr->saved_deleter_ = Handler::Deleter();
+  ptr->deleter_ = relay::CallNode::Deleter_;
+  return ObjectPtr<T>(ptr);
+}
+
+}  // namespace runtime
+
+}  // namespace tvm
+#endif  // TVM_RELAY_EXPR_H_
diff --git a/darknet_drp_ros/include/tvm/relay/expr_functor.h b/darknet_drp_ros/include/tvm/relay/expr_functor.h
new file mode 100644
index 0000000..280a1f8
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/expr_functor.h
@@ -0,0 +1,517 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/expr_functor.h
+ * \brief A more powerful visitor which enables defining arbitrary function
+ * signatures with type based dispatch on first argument.
+ */
+#ifndef TVM_RELAY_EXPR_FUNCTOR_H_
+#define TVM_RELAY_EXPR_FUNCTOR_H_
+
+#include <tvm/ir/error.h>
+#include <tvm/node/functor.h>
+#include <tvm/relay/adt.h>
+#include <tvm/relay/expr.h>
+#include <tvm/relay/function.h>
+#include <tvm/relay/op.h>
+
+#include <deque>
+#include <string>
+#include <unordered_map>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+namespace relay {
+
+/*!
+ * \brief A dynamical functor that dispatches on in the first Expr argument.
+ *  You can use this as a more powerful Visitor, since it allows you to
+ *  define function signatures of Visit Function.
+ *
+ * \sa tvm/ir_functor.h
+ *
+ * \tparam FType function signiture
+ *  This type is only defined for FType with function signature R(const Expr&,
+ * Args...)
+ */
+template <typename FType>
+class ExprFunctor;
+
+// functions to be overriden.
+#define EXPR_FUNCTOR_DEFAULT \
+  { return VisitExprDefault_(op, std::forward<Args>(args)...); }
+
+#define RELAY_EXPR_FUNCTOR_DISPATCH(OP)                                                    \
+  vtable.template set_dispatch<OP>([](const ObjectRef& n, TSelf* self, Args... args) {     \
+    return self->VisitExpr_(static_cast<const OP*>(n.get()), std::forward<Args>(args)...); \
+  });
+
+template <typename R, typename... Args>
+class ExprFunctor<R(const Expr& n, Args...)> {
+ private:
+  using TSelf = ExprFunctor<R(const Expr& n, Args...)>;
+  using FType = tvm::NodeFunctor<R(const ObjectRef& n, TSelf* self, Args...)>;
+
+ public:
+  /*! \brief the result type of this functor */
+  using result_type = R;
+  /*! \brief virtual destructor */
+  virtual ~ExprFunctor() {}
+  /*!
+   * \brief Same as call.
+   * \param n The expression node.
+   * \param args Additional arguments.
+   * \return The result of the call
+   */
+  R operator()(const Expr& n, Args... args) { return VisitExpr(n, std::forward<Args>(args)...); }
+  /*!
+   * \brief The functor call.
+   * \param n The expression node.
+   * \param args Additional arguments.
+   * \return The result of the call
+   */
+  virtual R VisitExpr(const Expr& n, Args... args) {
+    ICHECK(n.defined()) << "Found null pointer node while traversing AST. The previous pass may "
+                           "have generated invalid data.";
+    static FType vtable = InitVTable();
+    return vtable(n, this, std::forward<Args>(args)...);
+  }
+  // Functions that can be overriden by subclass
+  virtual R VisitExpr_(const ConstantNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const TupleNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const VarNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const GlobalVarNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const FunctionNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const CallNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const LetNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const IfNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const OpNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const TupleGetItemNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const RefCreateNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const RefReadNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const RefWriteNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const ConstructorNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const MatchNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExprDefault_(const Object* op, Args...) {
+    LOG(FATAL) << "Do not have a default for " << op->GetTypeKey();
+    throw;
+  }
+
+ private:
+  // initialize the vtable.
+  static FType InitVTable() {
+    FType vtable;
+    // Set dispatch
+    RELAY_EXPR_FUNCTOR_DISPATCH(ConstantNode);
+    RELAY_EXPR_FUNCTOR_DISPATCH(TupleNode);
+    RELAY_EXPR_FUNCTOR_DISPATCH(VarNode);
+    RELAY_EXPR_FUNCTOR_DISPATCH(GlobalVarNode);
+    RELAY_EXPR_FUNCTOR_DISPATCH(FunctionNode);
+    RELAY_EXPR_FUNCTOR_DISPATCH(CallNode);
+    RELAY_EXPR_FUNCTOR_DISPATCH(LetNode);
+    RELAY_EXPR_FUNCTOR_DISPATCH(IfNode);
+    RELAY_EXPR_FUNCTOR_DISPATCH(OpNode);
+    RELAY_EXPR_FUNCTOR_DISPATCH(TupleGetItemNode);
+    RELAY_EXPR_FUNCTOR_DISPATCH(RefCreateNode);
+    RELAY_EXPR_FUNCTOR_DISPATCH(RefReadNode);
+    RELAY_EXPR_FUNCTOR_DISPATCH(RefWriteNode);
+    RELAY_EXPR_FUNCTOR_DISPATCH(ConstructorNode);
+    RELAY_EXPR_FUNCTOR_DISPATCH(MatchNode);
+    return vtable;
+  }
+};
+
+/*!
+ * \brief A simple visitor wrapper around ExprFunctor.
+ *  Recursively visit the content.
+ *
+ * ExprVisitor treats Expr as dataflow graph,
+ * and only visit each Expr node once.
+ */
+class ExprVisitor : public ::tvm::relay::ExprFunctor<void(const Expr& n)> {
+ public:
+  void VisitExpr(const Expr& expr) override;
+  void VisitExpr_(const VarNode* op) override;
+  void VisitExpr_(const GlobalVarNode* op) override;
+  void VisitExpr_(const ConstantNode* op) override;
+  void VisitExpr_(const TupleNode* op) override;
+  void VisitExpr_(const FunctionNode* op) override;
+  void VisitExpr_(const CallNode* op) override;
+  void VisitExpr_(const LetNode* op) override;
+  void VisitExpr_(const IfNode* op) override;
+  void VisitExpr_(const OpNode* op) override;
+  void VisitExpr_(const TupleGetItemNode* op) override;
+  void VisitExpr_(const RefCreateNode* op) override;
+  void VisitExpr_(const RefReadNode* op) override;
+  void VisitExpr_(const RefWriteNode* op) override;
+  void VisitExpr_(const ConstructorNode* op) override;
+  void VisitExpr_(const MatchNode* op) override;
+  virtual void VisitType(const Type& t);
+  virtual void VisitClause(const Clause& c);
+  virtual void VisitPattern(const Pattern& c);
+  virtual void VisitSpan(const Span& span);
+
+ protected:
+  // Internal visiting counter
+  std::unordered_map<const Object*, size_t> visit_counter_;
+};
+
+/*!
+ * \brief A wrapper around ExprFunctor which functionally updates the AST.
+ *
+ * ExprMutator treats Expr as dataflow graph, and only Mutate each Expr once.
+ * The mutated results are memoized in a map and reused so that
+ * local transformation on the dataflow preserves the graph structure.
+ */
+class ExprMutator : public ::tvm::relay::ExprFunctor<Expr(const Expr&)> {
+ public:
+  /*!
+   * \brief Mutate is alias for VisitExpr
+   * \return expr.
+   */
+  Expr Mutate(const Expr& expr) { return this->VisitExpr(expr); }
+  Expr VisitExpr(const Expr& expr) override;
+  Expr VisitExpr_(const VarNode* op) override;
+  Expr VisitExpr_(const ConstantNode* op) override;
+  Expr VisitExpr_(const GlobalVarNode* op) override;
+  Expr VisitExpr_(const OpNode* op) override;
+  Expr VisitExpr_(const TupleNode* op) override;
+  Expr VisitExpr_(const FunctionNode* op) override;
+  Expr VisitExpr_(const CallNode* call_node) override;
+  Expr VisitExpr_(const LetNode* op) override;
+  Expr VisitExpr_(const IfNode* op) override;
+  Expr VisitExpr_(const TupleGetItemNode* op) override;
+  Expr VisitExpr_(const RefCreateNode* op) override;
+  Expr VisitExpr_(const RefReadNode* op) override;
+  Expr VisitExpr_(const RefWriteNode* op) override;
+  Expr VisitExpr_(const ConstructorNode* op) override;
+  Expr VisitExpr_(const MatchNode* op) override;
+
+  /*!
+   * \brief Used to visit the types inside of expressions.
+   *
+   * Can be overloaded to transform the types in arbitrary
+   * ways, one way would be to define a sub-class of type
+   * visitor for types which transform them appropriately.
+   */
+  virtual Type VisitType(const Type& t);
+  virtual Clause VisitClause(const Clause& c);
+  virtual Pattern VisitPattern(const Pattern& c);
+
+ protected:
+  /*! \brief Internal map used for memoization. */
+  std::unordered_map<Expr, Expr, ObjectPtrHash, ObjectPtrEqual> memo_;
+};
+
+/*!
+ * \brief A wrapper around ExprVisitor which traverses the Dataflow Normal AST.
+ *
+ * MixedModeVisitor treats Expr as dataflow graph, and visits in post-DFS order
+ *
+ * MixedModeVisitor provides the same recursive API as ExprVisitor, and uses
+ * recursion to traverse most forms of the IR, but under the hood it expands nested dataflow regions
+ * of the graph and processes them iteratively to prevent stack overflows
+ */
+class MixedModeVisitor : public ::tvm::relay::ExprVisitor {
+ public:
+  using ::tvm::relay::ExprFunctor<void(const Expr& n)>::VisitExpr_;
+
+  /*! \brief The constructor of MixedModeVisitor
+   *  \param visit_limit The number of times to allow visitation to a node. Usually 1, ocassionally
+   * higher (i.e., 2 for dead code elimiation), limited to 10 as a sanity check.
+   */
+  explicit MixedModeVisitor(int visit_limit = 1);
+
+  using ExprVisitor::VisitExpr_;
+
+  /*!
+   * \brief VisitExpr is finalized to preserve call expansion of dataflow regions
+   */
+  void VisitExpr(const Expr& expr) final;
+  void VisitExpr_(const CallNode* op) override;
+  void VisitExpr_(const TupleNode* op) override;
+  void VisitExpr_(const TupleGetItemNode* op) override;
+
+ protected:
+  /*!
+   * \brief A function to apply when reaching a leaf of the graph non-recursively
+   */
+  virtual void VisitLeaf(const Expr& expr);
+  /*!
+   * \brief A function to determine if an expression has already been visited or needs to be
+   * re-visited
+   */
+  virtual bool CheckVisited(const Expr& expr);
+  /*!
+   * \brief The max number of times to visit a node
+   */
+  size_t visit_limit_;
+};
+
+/*! \brief Non-recursive DFS Graph Traversal for Custom Rewriting Passes
+ *
+ * MixedModeMutator treats Expr as dataflow graph, and only Rewrites each Expr once.
+ * The mutated results are memoized in a map and reused so that
+ * local transformation on the dataflow preserves the graph structure.
+ *
+ * MixedModeMutator provides the same recursive API as ExprMutator, and uses
+ * recursion to traverse most forms of the IR, but under the hood it expands nested dataflow regions
+ * of the graph and processes them iteratatively to prevent stack overflows
+ *
+ * Uses Rewrite_ API of ExprRewriter for a cleaner split between recrusive and non-recursive
+ * behavior.
+ */
+class MixedModeMutator : public ::tvm::relay::ExprMutator {
+ public:
+  using ::tvm::relay::ExprFunctor<Expr(const Expr&)>::VisitExpr_;
+
+  MixedModeMutator(bool pre = false) : pre_{pre} {};
+  Expr VisitExpr(const Expr& expr) final;
+
+  virtual Expr DispatchVisitExpr(const Expr& expr);
+  Expr VisitExpr_(const TupleNode* op) final { return Rewrite(op); };
+  Expr VisitExpr_(const CallNode* call_node) final { return Rewrite(call_node); };
+  Expr VisitExpr_(const TupleGetItemNode* op) final { return Rewrite(op); };
+  /*!
+   *  \brief Users should override Rewrite_ methods to implement their pass. Rewrite_ functions will
+   * be able to rewrite the op only with data about the original node `pre` and the same node with
+   * modified inputs `post` and should not recurse.
+   *
+   * \param pre The expression node before rewriting.
+   * \param post The expression with rewritten inputs.
+   */
+  virtual Expr Rewrite_(const TupleNode* pre, const Expr& post) { return post; }
+  virtual Expr Rewrite_(const CallNode* pre, const Expr& post) { return post; }
+  virtual Expr Rewrite_(const TupleGetItemNode* pre, const Expr& post) { return post; }
+
+ protected:
+  bool pre_;
+  /*! \brief Implement Rewrite API by calling ExprMutator's VisitExpr_(op) to get a `post` node with
+   * changed inputs.
+   */
+  template <typename T>
+  Expr Rewrite(const T* op) {
+    Expr post = ExprMutator::VisitExpr_(op);
+    return Rewrite_(op, post);
+  }
+
+  virtual void VisitLeaf(const Expr& expr);
+  virtual bool CheckVisited(const Expr& expr);
+};
+
+#define RELAY_EXPR_REWRITER_DISPATCH(OP)                                                   \
+  vtable.template set_dispatch<OP>([](const ObjectRef& n, TSelf* self, const Expr& post) { \
+    return self->Rewrite_(static_cast<const OP*>(n.get()), post);                          \
+  });
+
+#define EXPR_REWRITER_REWRITE_DEFAULT \
+  { return post; }
+
+/*! \brief A non-iterating Expression Rewriter
+ *
+ *  ExprRewriter provides a Rewrite interface for modifying graphs in Post-DFS order.
+ *
+ * The expectation is that ExprRewriter objects will be passed to PostOrderRewrite, which will
+ * non-recursively unroll the graph and call Rewriting on inputs. It will then pass the original
+ * node, called `pre`, and a node recreated with any alterned inputs, called `post`, to the
+ * ExprRewriter. The ExprRewriter can then use the information in those two nodes to do more complex
+ * graph rewriting.
+ */
+class ExprRewriter {
+ private:
+  using TSelf = ExprRewriter;
+  using FType = tvm::NodeFunctor<Expr(const ObjectRef& n, TSelf* self, const Expr& post)>;
+
+ public:
+  /*! \brief virtual destructor */
+  virtual ~ExprRewriter() {}
+  /*!
+   * \brief Same as call.
+   * \param pre The expression node before rewriting.
+   * \param post The expression node with rewritten inputs.
+   * \return The result of the call
+   */
+  Expr operator()(const Expr& pre, const Expr& post) { return Rewrite(pre, post); }
+  /*!
+   * \brief The functor call.
+   * \param pre The expression node before rewriting.
+   * \param post The expression node with rewritten inputs.
+   * \return The result of the call
+   */
+  virtual Expr Rewrite(const Expr& pre, const Expr& post) {
+    ICHECK(pre.defined());
+    static FType vtable = InitVTable();
+    return vtable(pre, this, post);
+  }
+  // Functions that can be overriden by subclass, should not recurse
+  virtual Expr Rewrite_(const VarNode* pre, const Expr& post) EXPR_REWRITER_REWRITE_DEFAULT;
+  virtual Expr Rewrite_(const GlobalVarNode* pre, const Expr& post) EXPR_REWRITER_REWRITE_DEFAULT;
+  virtual Expr Rewrite_(const ConstantNode* pre, const Expr& post) EXPR_REWRITER_REWRITE_DEFAULT;
+  virtual Expr Rewrite_(const TupleNode* pre, const Expr& post) EXPR_REWRITER_REWRITE_DEFAULT;
+  virtual Expr Rewrite_(const FunctionNode* pre, const Expr& post) EXPR_REWRITER_REWRITE_DEFAULT;
+  virtual Expr Rewrite_(const CallNode* pre, const Expr& post) EXPR_REWRITER_REWRITE_DEFAULT;
+  virtual Expr Rewrite_(const LetNode* pre, const Expr& post) EXPR_REWRITER_REWRITE_DEFAULT;
+  virtual Expr Rewrite_(const IfNode* pre, const Expr& post) EXPR_REWRITER_REWRITE_DEFAULT;
+  virtual Expr Rewrite_(const OpNode* pre, const Expr& post) EXPR_REWRITER_REWRITE_DEFAULT;
+  virtual Expr Rewrite_(const TupleGetItemNode* pre,
+                        const Expr& post) EXPR_REWRITER_REWRITE_DEFAULT;
+  virtual Expr Rewrite_(const RefCreateNode* pre, const Expr& post) EXPR_REWRITER_REWRITE_DEFAULT;
+  virtual Expr Rewrite_(const RefReadNode* pre, const Expr& post) EXPR_REWRITER_REWRITE_DEFAULT;
+  virtual Expr Rewrite_(const RefWriteNode* pre, const Expr& post) EXPR_REWRITER_REWRITE_DEFAULT;
+  virtual Expr Rewrite_(const ConstructorNode* pre, const Expr& post) EXPR_REWRITER_REWRITE_DEFAULT;
+  virtual Expr Rewrite_(const MatchNode* pre, const Expr& post) EXPR_REWRITER_REWRITE_DEFAULT;
+
+ private:
+  // initialize the vtable.
+  static FType InitVTable() {
+    FType vtable;
+    // Set dispatch
+    RELAY_EXPR_REWRITER_DISPATCH(ConstantNode);
+    RELAY_EXPR_REWRITER_DISPATCH(TupleNode);
+    RELAY_EXPR_REWRITER_DISPATCH(VarNode);
+    RELAY_EXPR_REWRITER_DISPATCH(GlobalVarNode);
+    RELAY_EXPR_REWRITER_DISPATCH(FunctionNode);
+    RELAY_EXPR_REWRITER_DISPATCH(CallNode);
+    RELAY_EXPR_REWRITER_DISPATCH(LetNode);
+    RELAY_EXPR_REWRITER_DISPATCH(IfNode);
+    RELAY_EXPR_REWRITER_DISPATCH(OpNode);
+    RELAY_EXPR_REWRITER_DISPATCH(TupleGetItemNode);
+    RELAY_EXPR_REWRITER_DISPATCH(RefCreateNode);
+    RELAY_EXPR_REWRITER_DISPATCH(RefReadNode);
+    RELAY_EXPR_REWRITER_DISPATCH(RefWriteNode);
+    RELAY_EXPR_REWRITER_DISPATCH(ConstructorNode);
+    RELAY_EXPR_REWRITER_DISPATCH(MatchNode);
+    return vtable;
+  }
+};
+
+/*! \brief Non-recursive DFS Graph Traversal for Custom Rewriting Passes
+ *
+ * PostOrderRewrite does a non-recursive traversal of the graph in Post-DFS order and calls the
+ * ExprRewriter's Rewrite functions on nodes once their inputs are rewritten. At each rewrite call,
+ * PostOrderRewrite provides the original node and the node with altered inputs for use by the
+ * ExprRewriter.
+ */
+Expr PostOrderRewrite(const Expr& expr, ExprRewriter* rewriter);
+
+/*!
+ * \brief recursively visit the ir in post DFS order node, apply fvisit
+ * Each node is guaranteed to be visited only once.
+ * \param node The ir to be visited.
+ * \param fvisit The visitor function to be applied.
+ */
+void PostOrderVisit(const Expr& node, std::function<void(const Expr&)> fvisit);
+
+/*!
+ * \brief A struct to keep info of traversed expr in ExpandDataflow function
+ */
+struct v_info {
+  explicit v_info(Expr node_) : node{node_} {}
+  v_info(Expr node_, bool children_expanded_)
+      : node{node_}, children_expanded{children_expanded_} {};
+  Expr node{};
+  bool children_expanded{false};
+};
+
+/*!
+ * \brief A function to iteratively traverse dataflow regions of a graph
+ *
+ * ExpandDataflow manually manages a stack and performs DFS to determine the processing
+ * order of nodes in an input graph.
+ *
+ * By default fexpand_expr implemented in a way that if it finds a dataflow node (Call, Tuple,
+ * TupleGetItem), it checks if the arguments to that node need to be processed via fcheck_visited.
+ * If so, the function pushes those arguments to the stack and continues iteratively to process
+ * the top of the stack. When it finds a node that doesn't match the dataflow types, or a node who's
+ * inputs have all been processed, it visits the current leaf via fvisit_leaf.
+ *
+ * This function should be used internally to other classes to implement mixed-mode traversals. The
+ * expectation is that fvisit_leaf will perform recursive analysis within mixed-mode traversal if it
+ * hits a non-dataflow node.
+ *
+ * fcheck_visited, fvisit_leaf and fexpand_expr are templated to encourage reusing.
+ */
+template <typename FCheckVisited, typename FVisitLeaf, typename FExpandExpr>
+void ExpandDataflow(Expr expr, FCheckVisited fcheck_visited, FVisitLeaf fvisit_leaf,
+                    FExpandExpr fexpand_expr) {
+  std::deque<v_info> stack;
+  auto fpush_to_stack = [&fcheck_visited, &stack](const Expr& expr) {
+    if (!fcheck_visited(expr)) {
+      stack.emplace_front(v_info(expr));
+    }
+  };
+
+  fpush_to_stack(expr);
+  while (stack.size() > 0) {
+    v_info* front = &stack.front();
+    if (fcheck_visited(front->node)) {
+      stack.pop_front();
+    } else if (front->children_expanded) {
+      fvisit_leaf(front->node);
+      // TODO(d-smirnov): this is for compatibility with current implementation of MixedModeVisitor
+      stack.pop_front();
+    } else {
+      front->children_expanded = true;
+      for (auto e : fexpand_expr(front->node)) {
+        fpush_to_stack(e);
+      }
+    }
+  }
+}
+
+template <typename FCheckVisited, typename FVisitLeaf>
+void ExpandDataflow(Expr expr, FCheckVisited fcheck_visited, FVisitLeaf fvisit_leaf) {
+  auto fexpand_expr = [](const Expr& expr) {
+    std::vector<Expr> result;
+    if (const CallNode* op = expr.as<CallNode>()) {
+      if (op->op == Op::Get("call_lowered")) {
+        // Ignore the intermediate tuple since this is purely a calling-convention detail
+        const auto* tuple_args = op->args[1].as<TupleNode>();
+        ICHECK(tuple_args)
+            << "Expected second arg to call_lowered to be a Tuple of input arguments.";
+        for (auto it = tuple_args->fields.rbegin(); it != tuple_args->fields.rend(); ++it) {
+          result.push_back(*it);
+        }
+        result.push_back(op->args[0]);
+      } else {
+        for (auto it = op->args.rbegin(); it != op->args.rend(); ++it) {
+          result.push_back(*it);
+        }
+      }
+      result.push_back(op->op);
+    } else if (const TupleNode* op = expr.as<TupleNode>()) {
+      for (auto it = op->fields.rbegin(); it != op->fields.rend(); ++it) {
+        result.push_back(*it);
+      }
+    } else if (const TupleGetItemNode* op = expr.as<TupleGetItemNode>()) {
+      result.push_back(op->tuple);
+    }
+    return result;
+  };
+  ExpandDataflow(expr, fcheck_visited, fvisit_leaf, fexpand_expr);
+}
+
+void ExpandANormalForm(const LetNode* op, std::function<void(const LetNode*)> pre_visit,
+                       std::function<void(const LetNode*)> post_visit);
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_EXPR_FUNCTOR_H_
diff --git a/darknet_drp_ros/include/tvm/relay/feature.h b/darknet_drp_ros/include/tvm/relay/feature.h
new file mode 100644
index 0000000..136dcfa
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/feature.h
@@ -0,0 +1,199 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/feature.h
+ * \brief Detect features used in Expr/Module.
+ */
+#ifndef TVM_RELAY_FEATURE_H_
+#define TVM_RELAY_FEATURE_H_
+
+#include <tvm/ir/module.h>
+#include <tvm/relay/expr.h>
+
+#include <bitset>
+#include <string>
+
+namespace tvm {
+namespace relay {
+
+/*! \brief Different kinds of relay feature a program might use. */
+enum Feature : int {
+  fVar = 0,
+  fGlobalVar = 1,
+  fConstant = 2,
+  fTuple = 3,
+  fTupleGetItem = 4,
+  fFunction = 5,
+  fOp = 6,
+  fCall = 7,
+  fLet = 8,
+  fIf = 9,
+  fRefCreate = 10,
+  fRefRead = 11,
+  fRefWrite = 12,
+  fConstructor = 13,
+  fMatch = 14,
+  /*! \brief Whether any non-atom fragment of the program is shared, making the program a graph. */
+  fGraph = 15,
+  /*! \brief Whether there is local fixpoint in the program. */
+  fLetRec = 16
+};
+
+constexpr size_t feature_count = 17;
+
+/*!
+ * \brief A finite set of Feature.
+ */
+class FeatureSet {
+ public:
+  FeatureSet(const FeatureSet&) = default;
+  /*! \brief A singleton set containing a single Feature. */
+  explicit FeatureSet(Feature ft) { bs_.set(static_cast<size_t>(ft)); }
+  explicit FeatureSet(const tvm::Array<tvm::Integer>& ft) {
+    for (Integer i : ft) {
+      *this += Feature(i.IntValue());
+    }
+  }
+  explicit operator Array<Integer>() const {
+    Array<Integer> ret;
+    for (size_t i = 0; i < feature_count; ++i) {
+      if (bs_[i]) {
+        ret.push_back(Integer(i));
+      }
+    }
+    return ret;
+  }
+  /*! \brief A set that contain all the Feature. */
+  static FeatureSet All() {
+    FeatureSet fs;
+    fs.bs_.flip();
+    return fs;
+  }
+  /*! \brief The empty set. Contain no Feature. */
+  static FeatureSet No() {
+    FeatureSet fs;
+    return fs;
+  }
+  template <typename T>
+  FeatureSet& operator+=(const T& rhs) {
+    bs_ |= FeatureSet(rhs).bs_;
+    return *this;
+  }
+  /*! \brief Set union. */
+  template <typename T>
+  FeatureSet operator+(const T& rhs) const {
+    FeatureSet fs(*this);
+    fs += rhs;
+    return fs;
+  }
+  template <typename T>
+  FeatureSet& operator-=(const T& rhs) {
+    bs_ &= ~(FeatureSet(rhs)).bs_;
+    return *this;
+  }
+  /*! \brief Set difference. */
+  template <typename T>
+  FeatureSet operator-(const T& rhs) const {
+    FeatureSet fs(*this);
+    fs -= rhs;
+    return fs;
+  }
+  /*!
+   * \brief Is this a subset of rhs?
+   *
+   * \param rhs another FeatureSet.
+   *
+   * \return true only if this is a subset of rhs.
+   */
+  bool is_subset_of(const FeatureSet& rhs) const { return ((*this) - rhs).bs_.none(); }
+
+  /*!
+   * \brief return a string representation.
+   */
+  std::string ToString() const;
+
+ private:
+  std::bitset<feature_count> bs_;
+  FeatureSet() = default;
+  explicit FeatureSet(const std::bitset<feature_count>& bs) : bs_(bs) {}
+};
+
+/*!
+ * \brief Calculate the feature of the program.
+ *
+ * \param expr The expression.
+ *
+ * \return The FeatureSet.
+ */
+FeatureSet DetectFeature(const RelayExpr& expr);
+
+/*!
+ * \brief Calculate the feature of the program.
+ *
+ * \param mod The module.
+ *
+ * \return The FeatureSet.
+ */
+FeatureSet DetectFeature(const IRModule& mod);
+
+/*!
+ * \brief Calculate the feature of the program.
+ *
+ * \param expr The expression.
+ * \param mod The module.
+ *
+ * \return The FeatureSet.
+ */
+inline FeatureSet DetectFeature(const Expr& expr, const IRModule& mod) {
+  return DetectFeature(expr) + DetectFeature(mod);
+}
+
+/*!
+ * \brief Check the feature of the program.
+ *
+ * \param expr The expression.
+ * \param fs The feature set of the program.
+ */
+void CheckFeature(const RelayExpr& expr, const FeatureSet& fs);
+
+/*!
+ * \brief Check the feature of the program.
+ *
+ * \param mod The module.
+ * \param fs The feature set of the program.
+ */
+void CheckFeature(const IRModule& mod, const FeatureSet& fs);
+
+/*!
+ * \brief Check the feature of the program.
+ *
+ * \param expr The expression.
+ * \param mod The module.
+ * \param fs The feature set of the program.
+ */
+inline void CheckFeature(const RelayExpr& expr, const IRModule& mod, const FeatureSet& fs) {
+  CheckFeature(expr, fs);
+  CheckFeature(mod, fs);
+}
+
+}  // namespace relay
+}  // namespace tvm
+
+#endif  // TVM_RELAY_FEATURE_H_
diff --git a/darknet_drp_ros/include/tvm/relay/function.h b/darknet_drp_ros/include/tvm/relay/function.h
new file mode 100644
index 0000000..874d4f2
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/function.h
@@ -0,0 +1,203 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/function.h
+ * \brief Relay Function.
+ */
+#ifndef TVM_RELAY_FUNCTION_H_
+#define TVM_RELAY_FUNCTION_H_
+
+#include <tvm/ir/function.h>
+#include <tvm/relay/expr.h>
+
+#include <string>
+
+namespace tvm {
+namespace relay {
+
+/*!
+ * \brief Relay Function container
+ * \sa Function
+ */
+class FunctionNode : public BaseFuncNode {
+ public:
+  /*! \brief Function parameters */
+  tvm::Array<Var> params;
+  /*!
+   * \brief
+   * The expression which represents the computation of the function,
+   * the expression may reference the parameters, and the type of it
+   * or sub-expressions may reference the type variables.
+   */
+  Expr body;
+  /*! \brief User annotated return type of the function. */
+  Type ret_type;
+  /*!
+   * \brief Type parameters of the function.
+   *  Enables the function to vary its type based on these.
+   *  This corresponds to template paramaters in c++'s terminology.
+   *
+   * \note This can be usually empty for non-polymorphic functions.
+   */
+  tvm::Array<TypeVar> type_params;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("params", &params);
+    v->Visit("body", &body);
+    v->Visit("ret_type", &ret_type);
+    v->Visit("type_params", &type_params);
+    v->Visit("attrs", &attrs);
+    v->Visit("virtual_device_", &virtual_device_);
+    v->Visit("span", &span);
+    v->Visit("_checked_type_", &checked_type_);
+  }
+
+  bool SEqualReduce(const FunctionNode* other, SEqualReducer equal) const {
+    // Important to make def equal first.
+    equal->MarkGraphNode();
+    return equal.DefEqual(params, other->params) &&
+           equal.DefEqual(type_params, other->type_params) && equal(ret_type, other->ret_type) &&
+           equal(attrs, other->attrs) && equal(body, other->body);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce->MarkGraphNode();
+    hash_reduce.DefHash(params);
+    hash_reduce.DefHash(type_params);
+    hash_reduce(ret_type);
+    hash_reduce(attrs);
+    hash_reduce(body);
+  }
+
+  /*!
+   * \brief Return the derived function annotation of this expression.
+   *
+   * \return The function type annotation.
+   * \note The function type annotation can contain IncompleteType.
+   */
+  TVM_DLL FuncType func_type_annotation() const;
+
+  static constexpr const char* _type_key = "relay.Function";
+  TVM_DECLARE_FINAL_OBJECT_INFO(FunctionNode, BaseFuncNode);
+};
+
+/*!
+ * \brief Managed reference to FunctionNode.
+ * \sa FunctionNode
+ */
+class Function : public BaseFunc {
+ public:
+  /*!
+   * \brief Constructor
+   * \param params The parameters of the function.
+   * \param body The body of the function.
+   * \param ret_type The return type of the function.
+   * \param ty_params The type parameters.
+   * \param attrs Additional function attributes.
+   * \param span The span of the function.
+   */
+  TVM_DLL Function(tvm::Array<Var> params, Expr body, Type ret_type, tvm::Array<TypeVar> ty_params,
+                   tvm::DictAttrs attrs = NullValue<DictAttrs>(), Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Function, BaseFunc, FunctionNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(FunctionNode);
+};
+
+/*!
+ * \brief Returns \p function with the given properties. A null property denotes 'no change'.
+ * Returns \p function if all properties are unchanged. Otherwise, returns a copy with the new
+ * fields.
+ */
+Function WithFields(Function function, Optional<Array<Var>> opt_params = Optional<Array<Var>>(),
+                    Optional<Expr> opt_body = Optional<Expr>(),
+                    Optional<Type> opt_ret_type = Optional<Type>(),
+                    Optional<Array<TypeVar>> opt_ty_params = Optional<Array<TypeVar>>(),
+                    Optional<DictAttrs> opt_attrs = Optional<DictAttrs>(),
+                    Optional<VirtualDevice> opt_virtual_device = Optional<VirtualDevice>(),
+                    Optional<Span> opt_span = Optional<Span>());
+
+/*
+ * \brief Returns the Relay FunctionNode represented by base_func if it should be optimized,
+ * otherwise returns nullptr.
+ *
+ * This means returns nullptr:
+ *  - For PrimFuncs, since not Relay Functions.
+ *  - For Functions marked for external compilation (with "Compiler").
+ *  - For Functions marked as already having an external definition (with "ExternalSymbol").
+ *  - For Functions marked as not to be optimized (with "SkipOptimization").
+ *
+ * TODO(mbs): Audit all enumerations of IRModule::functions to use this or some family of such.
+ */
+const FunctionNode* AsOptimizableFunctionNode(const BaseFunc& base_func);
+
+/*!
+ * \brief namespace of the attributes that can be attached to a relay::Function.
+ */
+namespace attr {
+
+/*!
+ * \brief Mark the function as representing a sub-graph which is to be lowered or compiled as
+ * a unit. For example, the function may represent a kernel which TVM will lower to a PrimFunc.
+ * If present should be bound to \p Integer(1). May be accompanied by "Compiler", see below.
+ * The function body should be considered opaque by Relay, and many passes simply ignore these
+ * functions.
+ *
+ * Type: Integer
+ */
+constexpr const char* kPrimitive = "Primitive";
+
+/*!
+ * \brief Mark the function as externally implemented, ie bound in a runtime::Module within the
+ * IRModule's "external_mods" attribute. If present should be bound to \p Integer(1). Generally
+ * the only attribute when present.
+ *
+ * Type: Integer
+ */
+constexpr const char* kExtern = "Extern";
+
+/*!
+ * \brief Indicates the name of the external codegen 'compiler' that should be used to lower
+ * or compile the function other than TVM's default lowering pipeline. The name may correspond
+ * to a TargetKind name. There may be a global function registered under 'relay.ext.{name}'.
+ *
+ * Type: String
+ */
+constexpr const char* kCompiler = "Compiler";
+
+/*! \brief Indicate if the function is a closure. */
+constexpr const char* kClosure = "Closure";
+/*! \brief Store a Var to parameter/Constant mapping on a Function. */
+constexpr const char* kParams = "__params__";
+/*! \brief Mark if the function should be avoided being optimized. */
+constexpr const char* kSkipOptimization = "SkipOptimization";
+/*! \brief Treat the function as a composite operator. */
+constexpr const char* kComposite = "Composite";
+/*! \brief Mark the function to be inlined. */
+constexpr const char* kInline = "Inline";
+/*! \brief Indicate the function was created by the Pattern Partitioning Pass. */
+constexpr const char* kPartitionedFromPattern = "PartitionedFromPattern";
+/*! \brief Mark the function as only composed of reshape operations. */
+constexpr const char* kReshapeOnly = "relay.reshape_only";
+
+}  // namespace attr
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_FUNCTION_H_
diff --git a/darknet_drp_ros/include/tvm/relay/interpreter.h b/darknet_drp_ros/include/tvm/relay/interpreter.h
new file mode 100644
index 0000000..f711072
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/interpreter.h
@@ -0,0 +1,197 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/interpreter.h
+ * \brief An interpreter for Relay.
+ *
+ * This file implements a simple reference interpreter for Relay programs.
+ * Given a Relay module, and a Relay expression it produces a value.
+ *
+ * The interpreter's values are a naive representation of the values that
+ * can be produced by a Relay program and are exposed via TVM's object
+ * protocol to Python for introspection and debugging.
+ *
+ * The interpreter's intent is to serve as a reference semantics for the Relay IR,
+ * as well as for debugging and testing.
+ */
+#ifndef TVM_RELAY_INTERPRETER_H_
+#define TVM_RELAY_INTERPRETER_H_
+
+#include <tvm/ir/module.h>
+#include <tvm/relay/expr.h>
+#include <tvm/runtime/container/closure.h>
+#include <tvm/runtime/object.h>
+#include <tvm/target/target.h>
+
+#include <unordered_set>
+
+namespace tvm {
+namespace relay {
+
+/*! \brief The container type of Closures used by the interpreter. */
+class InterpreterClosureObj : public runtime::ClosureObj {
+ public:
+  /*! \brief The set of free variables in the closure.
+   *
+   * These are the captured variables which are required for
+   * evaluation when we call the closure.
+   */
+  tvm::Map<Var, ObjectRef> env;
+  /*! \brief The function which implements the closure.
+   *
+   * \note May reference the variables contained in the env.
+   */
+  Function func;
+
+  InterpreterClosureObj() {}
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("env", &env);
+    v->Visit("func", &func);
+  }
+
+  static constexpr const char* _type_key = "interpreter.Closure";
+  TVM_DECLARE_FINAL_OBJECT_INFO(InterpreterClosureObj, runtime::ClosureObj);
+};
+
+class InterpreterClosure : public runtime::Closure {
+ public:
+  TVM_DLL InterpreterClosure(tvm::Map<Var, ObjectRef> env, Function func);
+  TVM_DEFINE_OBJECT_REF_METHODS(InterpreterClosure, runtime::Closure, InterpreterClosureObj);
+};
+
+/*! \brief The container type of RecClosure. */
+class RecClosureObj : public Object {
+ public:
+  /*! \brief The closure. */
+  InterpreterClosure clos;
+  /*! \brief variable the closure bind to. */
+  Var bind;
+
+  RecClosureObj() {}
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("clos", &clos);
+    v->Visit("bind", &bind);
+  }
+
+  static constexpr const char* _type_key = "interpreter.RecClosure";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RecClosureObj, Object);
+};
+
+class RecClosure : public ObjectRef {
+ public:
+  TVM_DLL RecClosure(InterpreterClosure clos, Var bind);
+  TVM_DEFINE_OBJECT_REF_METHODS(RecClosure, ObjectRef, RecClosureObj);
+};
+
+struct RefValueObj : Object {
+  mutable ObjectRef value;
+
+  RefValueObj() {}
+
+  void VisitAttrs(tvm::AttrVisitor* v) { v->Visit("value", &value); }
+
+  static constexpr const char* _type_key = "relay.RefValue";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RefValueObj, Object);
+};
+
+class RefValue : public ObjectRef {
+ public:
+  TVM_DLL RefValue(ObjectRef val);
+  TVM_DEFINE_OBJECT_REF_METHODS(RefValue, ObjectRef, RefValueObj);
+};
+
+struct ConstructorValueObj : Object {
+  int32_t tag;
+
+  tvm::Array<ObjectRef> fields;
+
+  /*! \brief Optional field tracking ADT constructor. */
+  Constructor constructor;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("tag", &tag);
+    v->Visit("fields", &fields);
+    v->Visit("constructor", &constructor);
+  }
+
+  static constexpr const char* _type_key = "relay.ConstructorValue";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ConstructorValueObj, Object);
+};
+
+class ConstructorValue : public ObjectRef {
+ public:
+  TVM_DLL ConstructorValue(int32_t tag, tvm::Array<ObjectRef> fields, Constructor construtor = {});
+
+  TVM_DEFINE_OBJECT_REF_METHODS(ConstructorValue, ObjectRef, ConstructorValueObj);
+};
+
+/*!
+ * \brief Returns a packed function over Relay expressions which will evaluate \p expr
+ * applied to those arguments, where \p expr is w.r.t. the definitions in \p mod.
+ *
+ * This function is intended to support the Python 'debug' executor.
+ *
+ * The given \p expr should have function type. The given \p mod may be empty or
+ * undefined if \p expr is self-contained. Relay arguments passed to the result
+ * packed function must be constants, references, or constructors/tuples over such.
+ * As much work as possible is done while constructing the result packed function, and
+ * that function may be reasonably efficiently applied multiple times without redoing
+ * unnecessary work.
+ *
+ * Primitives are lowered and compiled to packed functions for execution on \p device
+ * with properties given by \p target. All other Relay constructs are interpreted.
+ *
+ * The interpreter is intended to be a 'reference' implementation of the Relay semantics
+ * for testing and interactive use. It is not intended to be particularly efficient.
+ *
+ * \param mod A module containing definitions which can be referenced from
+ * \p expr. May be empty or undefined.
+ * \param expr An expression of function type to evaluate. May reference definitions from \p mod.
+ * \param device The device on which all primitives will be executed.
+ * \param target The compiler target flag for compiling primitives.
+ * \return A packed function that takes an array of Relay expressions and returns the
+ * result of applying \p expr to those arguments.
+ */
+TypedPackedFunc<ObjectRef(Array<Expr>)> EvalFunction(IRModule mod, Expr expr, Device device,
+                                                     Target target);
+
+/*!
+ * \brief Evaluates \p expr and returns its result.
+ *
+ * This function is intended to support TVM constant evaluation.
+ *
+ * \param expr An expression to evaluate.
+ * \param type_definitions Global type definitions which \p expr may references.
+ * \param import_set Already imported external modules.
+ * \param device The device on which all primitives will be executed.
+ * \param target The compiler target flag for compiling primitives.
+ * \param attrs Attributes for the expression to be evaluated with
+ * @return The object representing the result.
+ */
+ObjectRef Eval(Expr expr, Map<GlobalTypeVar, TypeData> type_definitions,
+               std::unordered_set<String> import_set, Device device, Target target,
+               Map<String, ObjectRef> attrs = {});
+
+}  // namespace relay
+}  // namespace tvm
+
+#endif  // TVM_RELAY_INTERPRETER_H_
diff --git a/darknet_drp_ros/include/tvm/relay/op.h b/darknet_drp_ros/include/tvm/relay/op.h
new file mode 100644
index 0000000..1284515
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/op.h
@@ -0,0 +1,41 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/op.h
+ * \brief Primitive operators(builtin intrinsics).
+ */
+#ifndef TVM_RELAY_OP_H_
+#define TVM_RELAY_OP_H_
+
+#include <tvm/ir/op.h>
+#include <tvm/relay/expr.h>
+#include <tvm/relay/type.h>
+
+namespace tvm {
+namespace relay {
+
+using Op = tvm::Op;
+using OpNode = tvm::OpNode;
+
+#define RELAY_REGISTER_OP(OpName) TVM_REGISTER_OP(OpName)
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_OP_H_
diff --git a/darknet_drp_ros/include/tvm/relay/op_attr_types.h b/darknet_drp_ros/include/tvm/relay/op_attr_types.h
new file mode 100644
index 0000000..97a3d5e
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/op_attr_types.h
@@ -0,0 +1,234 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/op_attr_types.h
+ * \brief The Expr and related elements in DataFlow construction.
+ */
+#ifndef TVM_RELAY_OP_ATTR_TYPES_H_
+#define TVM_RELAY_OP_ATTR_TYPES_H_
+
+#include <tvm/relay/expr.h>
+#include <tvm/relay/type.h>
+#include <tvm/target/generic_func.h>
+#include <tvm/target/target.h>
+#include <tvm/te/schedule.h>
+#include <tvm/te/tensor.h>
+#include <tvm/tir/data_layout.h>
+
+#include <string>
+
+namespace tvm {
+namespace relay {
+
+using tir::BijectiveLayoutNode;
+using tir::Layout;
+using tir::LayoutAxis;
+
+/*! \brief operator pattern used in graph fusion */
+enum OpPatternKind {
+  // Elementwise operation
+  kElemWise = 0,
+  // Broadcasting operator, can always map output axis to the input in order.
+  // for example :code:`out[i, ax1, j, ax2] = input[i, j]`.
+  // Note that the axis need to be in order so transpose is not a bcast operator.
+  kBroadcast = 1,
+  // Injective operator, can always injectively map output axis to a single input axis.
+  // All injective operator can still be safely fused to injective and reduction.
+  kInjective = 2,
+  // Communicative reduction operator.
+  kCommReduce = 3,
+  // Complex operation, can still fuse elemwise operations into its output.
+  // but cannot chain another complex op
+  kOutEWiseFusable = 4,
+  // The pattern for tuple nodes. Can fuse into subsequent injective ops,
+  // but treated specially
+  kTuple = 7,
+  // Opaque operation, cannot fuse anything.
+  kOpaque = 8
+};
+
+/*! \brief the operator pattern */
+using TOpPattern = int;
+
+/*!
+ * \brief Whether operator is stateful or contain internal state.
+ *
+ * All the primitive ops we registered so far are pure.
+ * This attribute is left for potential future compatible reasons.
+ * We can always work around the stateful ops by adding an additional
+ * handle argument and return it.
+ */
+using TOpIsStateful = bool;
+
+/*!
+ * \brief Mark the operator as non-computational.
+ */
+using TNonComputational = bool;
+
+/*!
+ * \brief Mark the operator as reshape op of its first input
+ *        and can be turned into a nop when the first input and output
+ *        shares the same piece of memory.
+ */
+using TReshapeOp = bool;
+
+/*!
+ * \brief Mark the operator whether output shape is data dependent.
+ */
+using TShapeDataDependent = Array<Integer>;
+
+/*!
+ * \brief Computation description interface.
+ *
+ * \note This function have a special convention
+ *  for functions with tuple input/output.
+ *
+ *  So far we restrict tuple support to the following case:
+ *  - Function which takes a single tuple as input.
+ *  - Function which outputs a single tuple.
+ *
+ *  In both cases, the tuple is flattened as array.
+ *
+ * \param attrs The attribute of the primitive
+ * \param inputs The input tensors.
+ * \param out_type The output type information
+ &                 these are always placeholders.
+ * \return The output compute description of the operator.
+ */
+using FTVMCompute = runtime::TypedPackedFunc<Array<te::Tensor>(
+    const Attrs& attrs, const Array<te::Tensor>& inputs, const Type& out_type)>;
+
+/*!
+ * \brief Build the computation schedule for
+ *  op whose root is at current op.
+ *
+ * \param attrs The attribute of the node.
+ * \param outs The output tensors.
+ * \param target The build target.
+ * \return schedule The computation schedule.
+ */
+using FTVMSchedule = runtime::TypedPackedFunc<te::Schedule(
+    const Attrs& attrs, const Array<te::Tensor>& outs, const Target& target)>;
+
+/*!
+ * \brief Generate the strategy of operators. This function is a generic
+ * function and can be re-defined for different targets.
+ *
+ * The function signature of generic function is:
+ *   OpStrategy(const Attrs& attrs, const Array<Tensor>& inputs,
+ *              const Type& out_type, const Target& target)
+ */
+using FTVMStrategy = GenericFunc;
+
+/*!
+ * \brief Alternate the layout of operators or replace the
+ *  operator with other expressions. This function will be invoked
+ *  in AlterOpLayout pass.
+ * \param attrs The attribute of the original node.
+ * \param args The input symbols of the original node.
+ * \param tinfos An array of placeholders, use for getting the inferred shape
+ *               and dtype of the inputs.
+ * \return new_expr The modified expression.
+ */
+using FTVMAlterOpLayout =
+    runtime::TypedPackedFunc<Expr(const Attrs& attrs, const Array<Expr>& args,
+                                  const Array<te::Tensor>& tinfos, const Type& out_type)>;
+
+/*!
+ * \brief Convert the layout of operators or replace the
+ *  operator with other expressions. This function will be invoked
+ *  in ConvertLayout pass.
+ * \param attrs The attribute of the original node.
+ * \param inputs The input symbols of the original node.
+ * \param tinfos An array of placeholders, use for getting the inferred shape
+ *               and dtype of the inputs.
+ * \param desired_layouts Specify an array of desired layouts for each input.
+ *                        For example a conv2d op: Array("NHWC", "OHWI"), this
+ *                        specifies the desired layout for data then kernel.
+ * \return new_expr The modified expression.
+ */
+using FTVMConvertOpLayout = runtime::TypedPackedFunc<Expr(
+    const Attrs& attrs, const Array<Expr>& args, const Array<te::Tensor>& tinfos,
+    const Array<String>& desired_layouts)>;
+/*!
+ * \brief Legalizes an expression with another expression. This function will be
+ *  invoked in Legalize pass. It is a target-dependent pass.
+ * \param attrs The attribute of the original node.
+ * \param args The input symbols of the original node.
+ * \param arg_types An array of placeholders, use for getting the inferred shape
+ *               and dtype of the inputs.
+ * \return new_expr The modified expression.
+ */
+using FTVMLegalize = runtime::TypedPackedFunc<Expr(const Attrs& attrs, const Array<Expr>& args,
+                                                   const Array<tvm::relay::Type>& arg_types)>;
+
+/*!
+ * \brief Annotates an expression to indicate if an op should be compiled using
+ * the given compiler/target.
+ * \param expr The original expr.
+ * \return true if this op should be registered to invoke a specific compiler
+ * for codegen, otherwise, false.
+ */
+using FTVMAnnotateTarget = runtime::TypedPackedFunc<bool(const Expr& expr)>;
+
+/*!
+ * \brief Forward rewriting rule for a specific op.
+ *
+ * \param ref_call The reference old call type to be rewritten.
+ *                 We can make use of the op and type information.
+ * \param new_args The new arguments (some of them could be TempExpr).
+ * \param ctx  Optional context information about ref_call.
+ * \return The rewriten result call, can also return nullptr,
+ *         which indicate the rewriter should use the default fallback
+ *         rule that realizes all its input and compose the call.
+ *
+ * \note When we register the function, we can register
+ *       a different signature with ctx to be a specific node type.
+ */
+using FForwardRewrite = runtime::TypedPackedFunc<Expr(
+    const Call& ref_call, const Array<Expr>& new_args, const ObjectRef& ctx)>;
+
+/*!
+ * \brief Gradient for a specific op.
+ *
+ * \param orig_call the original Expr.
+ * \param output_grad the gradient of the Expr.
+ * \return the gradient for each parameters.
+ */
+using FPrimalGradient =
+    runtime::TypedPackedFunc<tvm::Array<Expr>(const Expr& orig_call, const Expr& output_grad)>;
+
+/*!
+ * \brief The codegeneration strategy for dynamic dimensions.
+ */
+enum AnyCodegenStrategy {
+  /*! \brief The default strategy of using completely variable dimensions. */
+  kVariableDimensions
+};
+
+/*! \brief A runtime representation of shape. */
+using Shape = Array<IndexExpr>;
+
+using FShapeFunc = runtime::TypedPackedFunc<Array<te::Tensor>(
+    const Attrs& attrs, const Array<te::Tensor>& inputs, const Array<IndexExpr>& out_ndims)>;
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_OP_ATTR_TYPES_H_
diff --git a/darknet_drp_ros/include/tvm/relay/op_strategy.h b/darknet_drp_ros/include/tvm/relay/op_strategy.h
new file mode 100644
index 0000000..c578536
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/op_strategy.h
@@ -0,0 +1,161 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/op_strategy.h
+ * \brief The Relay operator Strategy and related data structure.
+ */
+
+#ifndef TVM_RELAY_OP_STRATEGY_H_
+#define TVM_RELAY_OP_STRATEGY_H_
+
+#include <tvm/relay/expr.h>
+#include <tvm/relay/op_attr_types.h>
+#include <tvm/target/target.h>
+#include <tvm/te/schedule.h>
+#include <tvm/te/tensor.h>
+
+#include <string>
+
+namespace tvm {
+namespace relay {
+
+/*!
+ * \brief Operator implementation that includes compute and schedule function.
+ */
+class OpImplementationNode : public Object {
+ public:
+  /*! \brief Compute function */
+  FTVMCompute fcompute;
+  /*! \brief Schedule function */
+  FTVMSchedule fschedule;
+  /*! \brief Name of the implementation */
+  String name;
+  /*! \brief Priority level */
+  int plevel;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("name", &name);
+    v->Visit("plevel", &plevel);
+  }
+
+  static constexpr const char* _type_key = "relay.OpImplementation";
+  TVM_DECLARE_FINAL_OBJECT_INFO(OpImplementationNode, Object);
+};
+
+/*!
+ * \brief Operator implementation class.
+ */
+class OpImplementation : public ObjectRef {
+ public:
+  /*!
+   * \brief Invoke the operator compute function.
+   * \param attrs The attribute of the primitive
+   * \param inputs The input tensors.
+   * \param out_type The output type information.
+   * \return The output compute description of the operator.
+   */
+  TVM_DLL Array<te::Tensor> Compute(const Attrs& attrs, const Array<te::Tensor>& inputs,
+                                    const Type& out_type);
+  /*!
+   * \brief Build the computation schedule.
+   * \param attrs The attribute of the node.
+   * \param outs The output tensors.
+   * \param target The build target.
+   * \return The computation schedule.
+   */
+  TVM_DLL te::Schedule Schedule(const Attrs& attrs, const Array<te::Tensor>& outs,
+                                const Target& target);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(OpImplementation, ObjectRef, OpImplementationNode);
+};
+
+/*!
+ * \brief Specialized implementations for operators under certain conditions.
+ */
+class OpSpecializationNode : public Object {
+ public:
+  /*! \brief List of implementations. */
+  Array<OpImplementation> implementations;
+  /*! \brief Condition to enable the specialization.
+   *    Could be undefined to represent generic case. */
+  te::SpecializedCondition condition;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("condition", &condition);
+    v->Visit("implementations", &implementations);
+  }
+
+  static constexpr const char* _type_key = "relay.OpSpecialization";
+  TVM_DECLARE_FINAL_OBJECT_INFO(OpSpecializationNode, ExprNode);
+};
+
+/*!
+ * \brief Operator specialization class.
+ */
+class OpSpecialization : public ObjectRef {
+ public:
+  /*!
+   * \brief Add an implementation.
+   * \param fcompute Compute function
+   * \param fschedule Schedule function
+   * \param name Name of the implementation
+   * \param plevel Priority level of the implementation
+   */
+  TVM_DLL void AddImplementation(FTVMCompute fcompute, FTVMSchedule fschedule, String name,
+                                 int plevel);
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(OpSpecialization, ObjectRef, OpSpecializationNode);
+};
+
+/*!
+ * \brief Operator strategy to choose implementation.
+ */
+class OpStrategyNode : public Object {
+ public:
+  /*! \brief List of operator specializations. */
+  Array<OpSpecialization> specializations;
+
+  void VisitAttrs(tvm::AttrVisitor* v) { v->Visit("specializations", &specializations); }
+
+  static constexpr const char* _type_key = "relay.OpStrategy";
+  TVM_DECLARE_FINAL_OBJECT_INFO(OpStrategyNode, ExprNode);
+};
+
+/*!
+ * \brief Operator strategy class.
+ */
+class OpStrategy : public ObjectRef {
+ public:
+  /*!
+   * \brief Add an implementation.
+   * \param fcompute Compute function
+   * \param fschedule Schedule function
+   * \param name Name of the implementation
+   * \param plevel Priority level of the implementation
+   */
+  TVM_DLL void AddImplementation(FTVMCompute fcompute, FTVMSchedule fschedule, String name,
+                                 int plevel);
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(OpStrategy, ObjectRef, OpStrategyNode);
+};
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_OP_STRATEGY_H_
diff --git a/darknet_drp_ros/include/tvm/relay/pattern_functor.h b/darknet_drp_ros/include/tvm/relay/pattern_functor.h
new file mode 100644
index 0000000..711d832
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/pattern_functor.h
@@ -0,0 +1,166 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/pattern_functor.h
+ * \brief A more powerful visitor on ADT patterns that enables defining
+ * arbitrary function signatures with type-based dispatch on first argument.
+ */
+#ifndef TVM_RELAY_PATTERN_FUNCTOR_H_
+#define TVM_RELAY_PATTERN_FUNCTOR_H_
+
+#include <tvm/ir/error.h>
+#include <tvm/node/functor.h>
+
+#include <string>
+#include <unordered_map>
+#include <utility>
+
+#include "./adt.h"
+#include "./expr.h"
+#include "./op.h"
+
+namespace tvm {
+namespace relay {
+
+/*!
+ * \brief A dynamical functor on ADT patterns that dispatches on its first argument.
+ *  You can use this as a more powerful visitor, since it allows you to
+ *  define the types of further arguments to VisitPattern.
+ *
+ * \sa tvm/ir_functor.h
+ *
+ * \tparam FType function signiture
+ *  This type is only defined for FType with function signature R(const Pattern&,
+ * Args...)
+ */
+template <typename FType>
+class PatternFunctor;
+
+// functions to be overriden.
+#define PATTERN_FUNCTOR_DEFAULT \
+  { return VisitPatternDefault_(op, std::forward<Args>(args)...); }
+
+#define RELAY_PATTERN_FUNCTOR_DISPATCH(OP)                                                    \
+  vtable.template set_dispatch<OP>([](const ObjectRef& n, TSelf* self, Args... args) {        \
+    return self->VisitPattern_(static_cast<const OP*>(n.get()), std::forward<Args>(args)...); \
+  });
+
+template <typename R, typename... Args>
+class PatternFunctor<R(const Pattern& n, Args...)> {
+ private:
+  using TSelf = PatternFunctor<R(const Pattern& n, Args...)>;
+  using FType = tvm::NodeFunctor<R(const ObjectRef& n, TSelf* self, Args...)>;
+
+ public:
+  /*! \brief the result type of this functor */
+  using result_type = R;
+  /*! \brief virtual destructor */
+  virtual ~PatternFunctor() {}
+  /*!
+   * \brief Same as call.
+   * \param n The expression node.
+   * \param args Additional arguments.
+   * \return The result of the call
+   */
+  R operator()(const Pattern& n, Args... args) {
+    return VisitPattern(n, std::forward<Args>(args)...);
+  }
+  /*!
+   * \brief The functor call.
+   * \param n The expression node.
+   * \param args Additional arguments.
+   * \return The result of the call
+   */
+  virtual R VisitPattern(const Pattern& n, Args... args) {
+    ICHECK(n.defined());
+    static FType vtable = InitVTable();
+    return vtable(n, this, std::forward<Args>(args)...);
+  }
+  // Functions that can be overriden by subclass
+  virtual R VisitPattern_(const PatternWildcardNode* op, Args... args) PATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitPattern_(const PatternVarNode* op, Args... args) PATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitPattern_(const PatternConstructorNode* op, Args... args) PATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitPattern_(const PatternTupleNode* op, Args... args) PATTERN_FUNCTOR_DEFAULT;
+  virtual R VisitPatternDefault_(const Object* op, Args...) {
+    LOG(FATAL) << "Do not have a default for " << op->GetTypeKey();
+    throw;
+  }
+
+ private:
+  // initialize the vtable.
+  static FType InitVTable() {
+    FType vtable;
+    // Set dispatch
+    RELAY_PATTERN_FUNCTOR_DISPATCH(PatternWildcardNode);
+    RELAY_PATTERN_FUNCTOR_DISPATCH(PatternVarNode);
+    RELAY_PATTERN_FUNCTOR_DISPATCH(PatternConstructorNode);
+    RELAY_PATTERN_FUNCTOR_DISPATCH(PatternTupleNode);
+    return vtable;
+  }
+};
+
+/*! \brief A simple visitor wrapper around PatternFunctor.
+ *
+ * Exposes two visitors with default traversal strategies, one
+ * which doesn't compute a result but can mutate internal state,
+ * and another which functionally builds a new pattern.
+ */
+class PatternVisitor : public ::tvm::relay::PatternFunctor<void(const Pattern& n)> {
+ public:
+  void VisitPattern_(const PatternWildcardNode* op) override;
+  void VisitPattern_(const PatternVarNode* op) override;
+  void VisitPattern_(const PatternConstructorNode* op) override;
+  void VisitPattern_(const PatternTupleNode* op) override;
+  virtual void VisitType(const Type& t);
+  virtual void VisitVar(const Var& v);
+  virtual void VisitConstructor(const Constructor& c);
+};
+
+/*! \brief A wrapper around ExprFunctor which functionally updates the AST.
+ *
+ * ExprMutator uses memoization and self return in order to amortize
+ * the cost of using functional updates.
+ */
+class PatternMutator : public ::tvm::relay::PatternFunctor<Pattern(const Pattern&)> {
+ public:
+  Pattern Mutate(const Pattern& pat);
+  Pattern VisitPattern_(const PatternWildcardNode* op) override;
+  Pattern VisitPattern_(const PatternVarNode* op) override;
+  Pattern VisitPattern_(const PatternConstructorNode* op) override;
+  Pattern VisitPattern_(const PatternTupleNode* op) override;
+  /*! \brief Used to visit the types inside of patterns.
+   *
+   * Can be overloaded to transform the types in arbitrary
+   * ways, one way would be to define a sub-class of type
+   * visitor for types which transform them appropriately.
+   */
+  virtual Type VisitType(const Type& t);
+  /*! \brief Used to visit the vars inside of patterns. */
+  virtual Var VisitVar(const Var& v);
+  /*! \brief Used to visit the vars inside of patterns. */
+  virtual Constructor VisitConstructor(const Constructor& c);
+
+ private:
+  std::unordered_map<Var, Var, ObjectPtrHash, ObjectPtrEqual> var_map_;
+};
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_PATTERN_FUNCTOR_H_
diff --git a/darknet_drp_ros/include/tvm/relay/qnn/attrs.h b/darknet_drp_ros/include/tvm/relay/qnn/attrs.h
new file mode 100644
index 0000000..64b2dc2
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/qnn/attrs.h
@@ -0,0 +1,131 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/qnn/attrs.h
+ * \brief Auxiliary attributes for qnn operators.
+ */
+#ifndef TVM_RELAY_QNN_ATTRS_H_
+#define TVM_RELAY_QNN_ATTRS_H_
+
+#include <tvm/ir/attrs.h>
+
+#include <string>
+
+namespace tvm {
+namespace relay {
+namespace qnn {
+
+/*! \brief Attribute for requantize operator */
+struct RequantizeAttrs : public tvm::AttrsNode<RequantizeAttrs> {
+  int axis;
+  std::string rounding;
+  std::string compute_dtype;
+  DataType out_dtype;
+
+  TVM_DECLARE_ATTRS(RequantizeAttrs, "relay.attrs.RequantizeAttrs") {
+    TVM_ATTR_FIELD(axis)
+        .describe(
+            "The output channel axis for channel wise quantization. Default value is -1,"
+            "which corresponds to the last axis.")
+        .set_default(-1);
+    TVM_ATTR_FIELD(rounding).set_default("None").describe(
+        "Defines the rounding direction when the value is midway between"
+        "two representable values. There are two supported modes - UPWARD"
+        "or TONEAREST. Both modes behave exactly same except at the"
+        "midpoints between the two representable values. At the midpoint,"
+        "UPWARD rounds towards positive infinity (for example -1.5 will be"
+        "rounded to -1). TONEAREST is the standard rounding where the"
+        "value is rounded away from zero at midpoints (for example, -1.5"
+        "rounds to -2). More context can be found at following gblic manual"
+        "https://www.gnu.org/software/libc/manual/html_node/Rounding.html.");
+    TVM_ATTR_FIELD(compute_dtype)
+        .set_default("None")
+        .describe(
+            "Specifies the data type used during requantize. Supported "
+            "options: \"int64\", \"float32\", \"float64\"");
+    TVM_ATTR_FIELD(out_dtype)
+        .set_default(NullValue<DataType>())
+        .describe("Output data type, set to explicit type under mixed precision setting");
+  }
+};
+
+/*! \brief Attribute for quantize operator */
+struct QuantizeAttrs : public tvm::AttrsNode<QuantizeAttrs> {
+  DataType out_dtype;
+  int axis;
+
+  TVM_DECLARE_ATTRS(QuantizeAttrs, "relay.attrs.QuantizeAttrs") {
+    TVM_ATTR_FIELD(out_dtype).describe("Output data type, can be one of [int8 or uint8].");
+    TVM_ATTR_FIELD(axis)
+        .describe(
+            "The output channel axis for channel wise quantization. Default value is -1,"
+            "which corresponds to the last axis.")
+        .set_default(-1);
+  }
+};
+
+struct SimulatedQuantizeAttrs : public tvm::AttrsNode<SimulatedQuantizeAttrs> {
+  int axis;
+
+  TVM_DECLARE_ATTRS(SimulatedQuantizeAttrs, "relay.attrs.SimulatedQuantizeAttrs") {
+    TVM_ATTR_FIELD(axis)
+        .describe(
+            "The output channel axis for channel wise quantization. Default value is -1,"
+            "which corresponds to the last axis.")
+        .set_default(-1);
+  }
+};
+
+/*! \brief Attribute for dequantize operator */
+struct DequantizeAttrs : public tvm::AttrsNode<DequantizeAttrs> {
+  int axis;
+
+  TVM_DECLARE_ATTRS(DequantizeAttrs, "relay.attrs.DequantizeAttrs") {
+    TVM_ATTR_FIELD(axis)
+        .describe(
+            "The channel axis for channel wise dequantization. Default value is -1,"
+            "which corresponds to the last axis.")
+        .set_default(-1);
+  }
+};
+
+/*! \brief Attribute for broadcast operator */
+struct BroadcastAttrs : public tvm::AttrsNode<BroadcastAttrs> {
+  int lhs_axis;
+  int rhs_axis;
+
+  TVM_DECLARE_ATTRS(BroadcastAttrs, "relay.attrs.BroadcastAttrs") {
+    TVM_ATTR_FIELD(lhs_axis)
+        .describe(
+            "The channel axis for channel wise broadcast. Default value is -1,"
+            "which corresponds to the last axis.")
+        .set_default(-1);
+    TVM_ATTR_FIELD(rhs_axis)
+        .describe(
+            "The channel axis for channel wise broadcast. Default value is -1,"
+            "which corresponds to the last axis.")
+        .set_default(-1);
+  }
+};
+
+}  // namespace qnn
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_QNN_ATTRS_H_
diff --git a/darknet_drp_ros/include/tvm/relay/qnn/transform.h b/darknet_drp_ros/include/tvm/relay/qnn/transform.h
new file mode 100644
index 0000000..d1f07c9
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/qnn/transform.h
@@ -0,0 +1,60 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/qnn/transform.h
+ *
+ * This file implements a pass manager for QNN ops using Relay Pass manager.
+ */
+#ifndef TVM_RELAY_QNN_TRANSFORM_H_
+#define TVM_RELAY_QNN_TRANSFORM_H_
+
+#include <tvm/relay/transform.h>
+#include <tvm/runtime/c_runtime_api.h>
+
+namespace tvm {
+namespace relay {
+
+using relay::transform::Pass;
+
+namespace qnn {
+namespace transform {
+
+/*!
+ * \brief Legalizes a QNN expr. Contains specifically two types of Legalizations. First,
+ * converts/Lowers an expression containing QNN ops to an expression containing only core Relay ops.
+ * Each QNN op is lowered to a sequence of exisiting Relay ops. This is a target-independent pass.
+ * One can register the lowering/transformation function for this op using FTVMQnnCanonicalize
+ * attr_name for FTVMLegalize op attribute. Second, as opposed to Relay Legalize, this one legalizes
+ * only QNN ops. One can register a transformation/legalization function for an op by using the
+ * FTVMQnnLegalize attr_name for FTVMLegalize op attribute. The isolation of QNN and Relay Legalize
+ * gives us separation of concerns, leading to a better software practice. The legalization can be
+ * configured to happen per target.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass Legalize();
+
+}  // namespace transform
+
+}  // namespace qnn
+}  // namespace relay
+}  // namespace tvm
+
+#endif  // TVM_RELAY_QNN_TRANSFORM_H_
diff --git a/darknet_drp_ros/include/tvm/relay/runtime.h b/darknet_drp_ros/include/tvm/relay/runtime.h
new file mode 100644
index 0000000..10e124b
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/runtime.h
@@ -0,0 +1,276 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/runtime.h
+ * \brief Object representation of Runtime configuration and registry
+ */
+#ifndef TVM_RELAY_RUNTIME_H_
+#define TVM_RELAY_RUNTIME_H_
+
+#include <dmlc/registry.h>
+#include <tvm/ir/attrs.h>
+#include <tvm/ir/expr.h>
+#include <tvm/ir/type.h>
+#include <tvm/ir/type_relation.h>
+#include <tvm/node/attr_registry_map.h>
+#include <tvm/runtime/registry.h>
+
+#include <string>
+#include <unordered_map>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+
+template <typename, typename>
+class AttrRegistry;
+
+namespace relay {
+
+/*! \brief Value used with Runtime::name to indicate the C++ runtime. */
+static constexpr const char* kTvmRuntimeCpp = "cpp";
+
+/*! \brief Value used with Runtime::name to indicate the C runtime. */
+static constexpr const char* kTvmRuntimeCrt = "crt";
+
+/*!
+ * \brief Runtime information.
+ *
+ * This data structure stores the meta-data
+ * about Runtimes which can be used to pass around information.
+ *
+ * \sa Runtime
+ */
+class RuntimeNode : public Object {
+ public:
+  /*! \brief name of the Runtime */
+  String name;
+  /* \brief Additional attributes storing meta-data about the Runtime. */
+  DictAttrs attrs;
+
+  /*!
+   * \brief Get an attribute.
+   *
+   * \param attr_key The attribute key.
+   * \param default_value The default value if the key does not exist, defaults to nullptr.
+   *
+   * \return The result
+   *
+   * \tparam TObjectRef the expected object type.
+   * \throw Error if the key exists but the value does not match TObjectRef
+   *
+   * \code
+   *
+   *  void GetAttrExample(const Runtime& runtime) {
+   *    auto value = runtime->GetAttr<Integer>("AttrKey", 0);
+   *  }
+   *
+   * \endcode
+   */
+  template <typename TObjectRef>
+  Optional<TObjectRef> GetAttr(
+      const std::string& attr_key,
+      Optional<TObjectRef> default_value = Optional<TObjectRef>(nullptr)) const {
+    return attrs.GetAttr(attr_key, default_value);
+  }
+  // variant that uses TObjectRef to enable implicit conversion to default value.
+  template <typename TObjectRef>
+  Optional<TObjectRef> GetAttr(const std::string& attr_key, TObjectRef default_value) const {
+    return GetAttr<TObjectRef>(attr_key, Optional<TObjectRef>(default_value));
+  }
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("name", &name);
+    v->Visit("attrs", &attrs);
+  }
+
+  bool SEqualReduce(const RuntimeNode* other, SEqualReducer equal) const {
+    return name == other->name && equal.DefEqual(attrs, other->attrs);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(name);
+    hash_reduce(attrs);
+  }
+
+  static constexpr const char* _type_key = "Runtime";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_FINAL_OBJECT_INFO(RuntimeNode, Object);
+};
+
+/*!
+ * \brief Managed reference class to RuntimeNode.
+ * \sa RuntimeNode
+ */
+class Runtime : public ObjectRef {
+ public:
+  Runtime() = default;
+
+  /*!
+   * \brief Create a new Runtime object using the registry
+   * \throws Error if name is not registered
+   * \param name The name of the Runtime.
+   * \param attrs Attributes for the Runtime.
+   * \return the new Runtime object.
+   */
+  TVM_DLL static Runtime Create(String name, Map<String, ObjectRef> attrs = {});
+
+  /*!
+   * \brief List all registered Runtimes
+   * \return the list of Runtimes
+   */
+  TVM_DLL static Array<String> ListRuntimes();
+
+  /*!
+   * \brief List all options for a specific Runtime
+   * \param name The name of the Runtime
+   * \return Map of option name to type
+   */
+  TVM_DLL static Map<String, String> ListRuntimeOptions(const String& name);
+
+  /*! \brief specify container node */
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(Runtime, ObjectRef, RuntimeNode);
+
+ private:
+  /*!
+   * \brief Private Constructor
+   * \param name The Runtime name
+   * \param attrs Attributes to apply to this Runtime node
+   */
+  TVM_DLL Runtime(String name, DictAttrs attrs) {
+    auto n = make_object<RuntimeNode>();
+    n->name = std::move(name);
+    n->attrs = std::move(attrs);
+    data_ = std::move(n);
+  }
+};
+
+/*!
+ * \brief Helper structure to register Runtimes
+ * \sa TVM_REGISTER_Runtime
+ */
+class RuntimeRegEntry {
+ public:
+  /*!
+   * \brief Register a valid configuration option and its ValueType for validation
+   * \param key The configuration key
+   * \tparam ValueType The value type to be registered
+   */
+  template <typename ValueType>
+  inline RuntimeRegEntry& add_attr_option(const String& key);
+
+  /*!
+   * \brief Register a valid configuration option and its ValueType for validation
+   * \param key The configuration key
+   * \param default_value The default value of the key
+   * \tparam ValueType The value type to be registered
+   */
+  template <typename ValueType>
+  inline RuntimeRegEntry& add_attr_option(const String& key, ObjectRef default_value);
+
+  /*!
+   * \brief Register or get a new entry.
+   * \param name The name of the operator.
+   * \return the corresponding entry.
+   */
+  TVM_DLL static RuntimeRegEntry& RegisterOrGet(const String& name);
+
+ private:
+  /*! \brief Internal storage of value types */
+  struct ValueTypeInfo {
+    std::string type_key;
+    uint32_t type_index;
+  };
+  std::unordered_map<std::string, ValueTypeInfo> key2vtype_;
+  /*! \brief A hash table that stores the default value of each attr */
+  std::unordered_map<String, ObjectRef> key2default_;
+
+  /*! \brief Index used for internal lookup of attribute registry */
+  uint32_t index_;
+
+  // the name
+  std::string name;
+
+  /*! \brief Return the index stored in attr registry */
+  uint32_t AttrRegistryIndex() const { return index_; }
+  /*! \brief Return the name stored in attr registry */
+  String AttrRegistryName() const { return name; }
+
+  /*! \brief private constructor */
+  explicit RuntimeRegEntry(uint32_t reg_index) : index_(reg_index) {}
+
+  // friend class
+  template <typename>
+  friend class AttrRegistryMapContainerMap;
+  template <typename, typename>
+  friend class tvm::AttrRegistry;
+  friend class Runtime;
+};
+
+template <typename ValueType>
+inline RuntimeRegEntry& RuntimeRegEntry::add_attr_option(const String& key) {
+  ICHECK(!key2vtype_.count(key)) << "AttributeError: add_attr_option failed because '" << key
+                                 << "' has been set once";
+
+  using ValueNodeType = typename ValueType::ContainerType;
+  // NOTE: we could further update the function later.
+  uint32_t value_type_index = ValueNodeType::_GetOrAllocRuntimeTypeIndex();
+
+  ValueTypeInfo info;
+  info.type_index = value_type_index;
+  info.type_key = runtime::Object::TypeIndex2Key(value_type_index);
+  key2vtype_[key] = info;
+  return *this;
+}
+
+template <typename ValueType>
+inline RuntimeRegEntry& RuntimeRegEntry::add_attr_option(const String& key,
+                                                         ObjectRef default_value) {
+  add_attr_option<ValueType>(key);
+  key2default_[key] = default_value;
+  return *this;
+}
+
+// internal macros to make Runtime entries
+#define TVM_RUNTIME_REGISTER_VAR_DEF \
+  static DMLC_ATTRIBUTE_UNUSED ::tvm::relay::RuntimeRegEntry& __make_##Runtime
+
+/*!
+ * \def TVM_REGISTER_RUNTIME
+ * \brief Register a new Runtime, or set attribute of the corresponding Runtime.
+ *
+ * \param RuntimeName The name of registry
+ *
+ * \code
+ *
+ *  TVM_REGISTER_RUNTIME("c")
+ *  .add_attr_option<String>("my_option");
+ *  .add_attr_option<String>("my_option_default", String("default"));
+ *
+ * \endcode
+ */
+#define TVM_REGISTER_RUNTIME(RuntimeName)                     \
+  TVM_STR_CONCAT(TVM_RUNTIME_REGISTER_VAR_DEF, __COUNTER__) = \
+      ::tvm::relay::RuntimeRegEntry::RegisterOrGet(RuntimeName)
+}  // namespace relay
+}  // namespace tvm
+
+#endif  // TVM_RELAY_RUNTIME_H_
diff --git a/darknet_drp_ros/include/tvm/relay/transform.h b/darknet_drp_ros/include/tvm/relay/transform.h
new file mode 100644
index 0000000..cdea8e8
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/transform.h
@@ -0,0 +1,716 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/transform.h
+ * \brief Relay specific transformation passes.
+ */
+#ifndef TVM_RELAY_TRANSFORM_H_
+#define TVM_RELAY_TRANSFORM_H_
+
+#include <tvm/ir/transform.h>
+#include <tvm/relay/attrs/transform.h>
+#include <tvm/relay/expr.h>
+#include <tvm/relay/function.h>
+#include <tvm/relay/op.h>
+#include <tvm/relay/op_attr_types.h>
+#include <tvm/target/compilation_config.h>
+#include <tvm/target/target.h>
+#include <tvm/target/virtual_device.h>
+
+#include <string>
+
+namespace tvm {
+namespace relay {
+namespace transform {
+
+using Pass = tvm::transform::Pass;
+using PassNode = tvm::transform::PassNode;
+using PassInfo = tvm::transform::PassInfo;
+using PassInfoNode = tvm::transform::PassInfoNode;
+using PassContext = tvm::transform::PassContext;
+using PassContextNode = tvm::transform::PassContextNode;
+using Sequential = tvm::transform::Sequential;
+
+/*
+ * \brief Create a function pass.
+ *
+ * \param pass_func The packed function that contains the optimization.
+ * \param opt_level The optimization level of the function pass.
+ * \param name The name of the function pass.
+ * \param required The list of the passes that the function pass is dependent on.
+ *
+ * \return The created function pass.
+ */
+TVM_DLL Pass CreateFunctionPass(
+    const runtime::TypedPackedFunc<Function(Function, IRModule, PassContext)>& pass_func,
+    int opt_level, String name, tvm::Array<String> required);
+
+/*! \brief Remove let-bound expressions which do not effect the program result.
+ *
+ * This pass will remove let bindings which are not referenced. If inline_once is True,
+ * let bindings which are only referenced once will also be inlined.
+ *
+ * For example, this pass should turn `let a = 1; 2` into `2`,
+ * as the value of the expression does not depend on a.
+ *
+ * As another example, `let a = 1; a` will be optimized into 1 if inline_once is True.
+ *
+ * If ignore_purity is False, possibly side-effecting expressions (such as memory allocation,
+ * random number generation, reading/writing references, or calls to primitive or external
+ * functions) are never elided or inlined. This is sound, but ignore_purity can be set to True
+ * to suppress this check.
+ *
+ * The analysis is fairly conservative, for example it assumes all local functions
+ * may be called more than once, any functions passed as arguments have side effects,
+ * and so on.
+ *
+ * \param inline_once whether or not to inline bindings used exactly once.
+ * \param ignore_purity whether to ignore whether expressions have side-effects
+ *
+ * \return the pass.
+ */
+TVM_DLL Pass DeadCodeElimination(bool inline_once = false, bool ignore_purity = false);
+
+/*!
+ * \brief Convert all expressions of TensorType into GradCell,
+ * an algebraic data type defined in gradient.rly.
+ *
+ * This will delay or decrease memory usage. All calls to
+ * ones, ones_like, zeros, zeros_like will not immediately instantiate a tensor in memory,
+ * rather only instantiate if needed. It also defines + and * operation
+ * between GradCell types which can increase performance when using
+ * zero-filled or one-filled tensors, which is the case in reverse mode ad.
+ *
+ * \return the pass
+ */
+TVM_DLL Pass LazyGradientInit();
+
+/*!
+ * \brief Fold constant expressions.
+ *
+ *  Because of backward compatibility reason it skips QNN primitives from folding by default.
+ *  There are some transformation passes like FakeQuantizationToInteger, which requires to keep QNN
+ *  primitives for constant subgraphs. Uncontrolled constant folding of QNN primitives may break
+ *  applicability of FakeQuantizationToInteger. We suggest to use FoldConstant pass with none
+ *  default fold_qnn=True value only when all other QNN sensitive passes were already applied.
+ *
+ * \param fold_qnn Whether to fold constants for QNN operations.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass FoldConstant(bool fold_qnn = false);
+
+/*!
+ * \brief Split function with huge number of arguments to smaller pieces.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass SplitArgs(int max_function_args);
+
+/*!
+ * \brief Fuse operations into expr into separate functions.
+ *
+ * \param fuse_opt_level Optimization level. If it is -1 it will be inferred from pass context.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass FuseOps(int fuse_opt_level = -1);
+
+/*!
+ * \brief The inverse operation of FuseOps. It transforms a fused program returned by
+ * FuseOps into the program before FuseOps. (i.e. x == DefuseOps(FuseOps(x)))
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass DefuseOps();
+
+/*!
+ * \brief Rewrite the annotated program.
+ *
+ * \param fallback_device The fallback device which is the default device for
+ *                        operators without annotation.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass RewriteAnnotatedOps(int fallback_device);
+
+/*!
+ * \brief Turn an expression to Basic Block Normal Form.
+ *
+ * We define a block as a group of expressions implied by the scope structure.
+ *
+ * Each graph node can only belong to a single block.
+ *
+ * For any value that is being used in multiple blocks, it has to be referred
+ * by a Var which is defined in a block, whose scope is the least common ancestor
+ * of blocks this value is used.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass ToBasicBlockNormalForm();
+
+/*!
+ * \brief turn a dataflow graph into Administrative Normal Form, or A-Normal Form (ANF).
+ *
+ * It will turn an expression that is in a graph form (with sharing implicit),
+ * to an expression with explicit sharing (A-Normal Form).
+ *
+ * The scope of the root expression is the global scope.
+ *
+ * The scope of any non root expression is the least common ancestor of all it's scope.
+ *
+ * Values are ordered by post-DFS order in each scope.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass ToANormalForm();
+
+/*!
+ * \brief ToANormalForm but on incomplete graph.
+ *
+ * \param expr the graph.
+ *
+ * \return The transformed program.
+ */
+TVM_DLL Expr ToANormalForm(const Expr& expr);
+
+/*!
+ * \brief Turn an expression into continuation passing style(CPS).
+ *
+ * CPS mean that every function will, instead of returning the result directly,
+ * be passed down an extra function (called the continuation) as argument,
+ * and pass the result to the continuation instead.
+ *
+ * Thus, every function call has to be passed an extra argument
+ * that represent the rest of the computation (Hence the name of continuation).
+ *
+ * Similarly, all other compute will be wrapped and call the continuation as well.
+ *
+ * \return the pass.
+ */
+TVM_DLL Pass ToCPS();
+
+/*!
+ * \brief Remove let binding and directly share via pointer instead.
+ *
+ * It will remove all let binding,
+ * and turn all of the variable bound by let into direct pointer reference.
+ *
+ * \return the expression in graph normal form.
+ */
+TVM_DLL Pass ToGraphNormalForm();
+
+/*!
+ * \brief Aggressive constant propagation/constant folding/inlining.
+ *
+ * It will do as much computation in compile time as possible.
+ * It has two benefit: remove runtime overhead, and allow more optimization (typically fusion).
+ * As a side effect, code size will explode.
+ *
+ * \return the optimized expression.
+ */
+TVM_DLL Pass PartialEval();
+
+/*!
+ * \brief Simplify certain operators during inference. For example, the result
+ * of a batch norm which is indexed at tuple index 0 will be unpacked into a
+ * number of simplified operators.
+ *
+ * \return The Pass.
+ */
+TVM_DLL Pass SimplifyInference();
+
+/*!
+ * \brief Replaces non linear activation functions with their fast but approximate counterparts.
+ *
+ * \return The Pass.
+ */
+TVM_DLL Pass FastMath();
+
+/*!
+ * \brief Find Dynamic ops and make them static
+ *
+ * Searches the graph for dynamic ops. If the dynamic inputs to those ops are constants, it replaces
+ * them with static ops and re-performs type inference and constant folding. The pass repeats
+ * itself until the graph stops changing or we run too many iterations.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass DynamicToStatic();
+
+/*!
+ * \brief Infer the type of an expression.
+ *
+ * The result of type checking is a new expression with unambiguous
+ * type information filled in, as well as it's checked type field
+ * populated with the result type.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass InferType();
+
+/*!
+ * \brief Infer the type of an expression, reusing existing type information.
+ *
+ * The result of type checking is a new expression with unambiguous
+ * type information filled in for the given node only. The local
+ * version can use existing type information populated throughout
+ * the expression and assumes this information is correct. The local
+ * version also avoids examining large amounts of the graph assuming
+ * type information is filled in properly which makes it much faster if we
+ * iteratively call type inference.
+ *
+ * \return The type of the expression.
+ */
+TVM_DLL Type InferTypeLocal(const Expr& expr);
+
+/*!
+ * \brief Search and eliminate common subexpression. For example, if there are
+ * two expressions evaluated to an identical value, a single variable is created
+ * and these two expressions are replaced by this variable.
+ *
+ * \param fskip The callback argument that allows to skip certain expressions.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass EliminateCommonSubexpr(runtime::PackedFunc fskip = nullptr);
+
+/*!
+ * \brief Combine parallel 2d convolutions into a single convolution if the
+ * number of branches of this conv2d operator is not less than
+ * `min_num_branch`.
+ *
+ * \param min_num_branches The minimun number of branches.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass CombineParallelConv2D(uint64_t min_num_branches = 3);
+
+/*!
+ * \brief Combine parallel dense ops into a single batch_matmul if the
+ * number of branches of this dense operator is not less than
+ * `min_num_branch`.
+ *
+ * \param min_num_branches The minimun number of branches.
+ * \param to_batch_matmul Whether to combine parallel dense ops to batch matmul.
+ *                        If set false, combine dense ops to single dense op.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass CombineParallelDense(uint64_t min_num_branches = 3, bool to_batch_matmul = true);
+
+/*!
+ * \brief Combine parallel batch_matmul ops into a single batch_matmul
+ *  if the number of branches of this dense operator is not less than
+ * `min_num_branch`.
+ *
+ * \param min_num_branches The minimun number of branches.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass CombineParallelBatchMatmul(uint64_t min_num_branches = 3);
+
+/*!
+ * \brief Backward fold axis scaling into weights of conv/dense operators.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass BackwardFoldScaleAxis();
+
+/*!
+ * \brief Forward fold axis scaling into weights of conv/dense operators.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass ForwardFoldScaleAxis();
+
+/*!
+ * \brief A sequential pass that executes ForwardFoldScaleAxis and
+ * BackwardFoldScaleAxis passes.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass FoldScaleAxis();
+
+/*!
+ * \brief Canonicalize some operators to the simplified operators. For example,
+ * bias_add can be canonicalized to expand_dims and broadcast_add.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass CanonicalizeOps();
+
+/*!
+ * \brief Alternate the layouts of operators or replace primitive operators
+ * with other expressions.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass AlterOpLayout();
+
+/*!
+ * \brief Do layout rewrite according to the tile structure created by auto-scheduler.
+ * \return The pass
+ */
+TVM_DLL Pass AutoSchedulerLayoutRewrite();
+
+/*!
+ * \brief Do layout rewrite according to the tile structure created by meta-schedule.
+ * \return The pass
+ */
+TVM_DLL Pass MetaScheduleLayoutRewrite();
+
+/*!
+ * \brief Given a dest layout, this pass transforms the expr such that most of the ops input data
+ * layout is changed to the dest layout. In ideal situation, there are only 2 layout transforms, one
+ * at the start and one at the end.
+ *
+ * This pass is not a part of relay.build and is expected to be called between framework-relay
+ * parser and relay.build call. This is very helpful for hardware backends that support/prefer only
+ * type of data layout.
+ *
+ * RFC - https://discuss.tvm.ai/t/layout-conversion-pass/4009
+ *
+ * This pass uses most of the AlterOpLayout and InferCorrectLayout infrastructure. We can define new
+ * layouts for conv2d ops for now. Most of the other operators try to adapt to their input layout
+ * using the InferCorrectLayout infrastructure.
+ *
+ * \param desired_layouts Specify mapping of op_name to array of desired layouts for each input.
+ *                        For example: Map("nn.conv2d", Array("NHWC", "OHWI")),
+ *                        this specifies the desired layout for data then kernel for nn.conv2d.
+ * \return The pass.
+ */
+TVM_DLL Pass ConvertLayout(const Map<String, Array<String>>& desired_layouts);
+
+/*!
+ * \brief Legalizes an expr with another expression.
+ * \param legalize_map_attr_name The Op's attr name which corresponds to the legalize rule function.
+ * One can collect and isolate similar type of legalize transformations using this param. For
+ * example, transformations that only apply to Dialects can be isolated into a FTVMDialectLegalize
+ * string. This pass calls only those transformations that have been registered using the supplied
+ * legalize_map_attr_name.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass Legalize(const String& legalize_map_attr_name = "FTVMLegalize");
+
+/*!
+ * \brief Canonicalize cast expressions to make operator fusion more efficient.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass CanonicalizeCast();
+
+/*!
+ * \brief Add abstraction over a constructor or global variable bound to a function.
+ *
+ * For example: `square` is transformed to
+ * `fn (%x: int32) -> int32 { square(x) }`.
+ *
+ * See https://en.wikipedia.org/wiki/Lambda_calculus#%CE%B7-conversion
+ * for more details.
+ *
+ * \param expand_constructor Whether to expand constructors.
+ * \param expand_global_var Whether to expand global variables.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass EtaExpand(bool expand_constructor, bool expand_global_var);
+
+/*!
+ * \brief Partition a Relay program into regions that can be executed on
+ * different backends.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass PartitionGraph();
+
+/*!
+ * \brief Inline the global functions marked as `inline` in a given Relay
+ * IRModule.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass Inline();
+
+/*!
+ * \brief Remove the unused functions in the Relay IRModule.
+ *
+ * \param entry_functions The entry functions used to search the functions that
+ *        are being used.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass RemoveUnusedFunctions(Array<runtime::String> entry_functions);
+
+/*!
+ * \brief Simplify the Relay expression.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass SimplifyExpr();
+
+/*!
+ * \brief Run any custom passes registered under "RelayToTIR" attributes on TargetKinds.
+ *
+ * This pass looks for inline, let-bound or global functions which have a "Compiler" attribute.
+ * If the attribute value corresponds to a TargetKind with a "RelayToTIR" attribute, then the
+ * 'custom' pass bound to that attribute is run (at most once) on the IRModule as a whole.
+ *
+ * If, in addition, the \p config has a Target with a matching TargetKind, that Target is set
+ * as the 'current' target before the custom pass is executed. In this way it is possible
+ * for custom passes to pick up target options which may guide how they transform the IRModule.
+ * (Those targets are referred to as 'extern codegen targets' elsewhere).
+ *
+ * A typical custom pass will:
+ *  - Find calls to "Compiler" attributes functions with matching compiler name.
+ *  - Lower those function to TIR PrimFuncs.
+ *  - Bind those functions into the IRModule under the the functions' "global_symbol" attribute.
+ *  - Replace all calls to those functions with 'call_lowered' to the matching global.
+ * Care should be taken to handle multiple calls to the same function.
+ * See src/relay/backend/contrib/example_target_hooks/relay_to_tir.cc for an example custom pass.
+ *
+ * It is also possible (despite the pass and attribute names!) for the custom pass to proceed
+ * directly to a runtime::Module, which can be attached to the output IRModules "external_mods"
+ * attribute (taking care not to clobber any existing modules). In this case the flow is as above,
+ * except:
+ *  - The runtime::Module must contain a binding for each compiled function under their
+ *    "global_symbol" (ie runtime::Module::ImplementsFunction should return true).
+ *  - A Relay Function must be bound (or re-bound) into the result IRModule, again with the same
+ *    "global_symbol", but with only the "Extern" attribute set to Integer(1). The function body
+ *    should be the original function body. In this way we always have a TVM definition matching
+ *    every global function name.
+ *
+ * There are many existing runtime::Modules, ranging from source to object to dynamic libaries to
+ * entirely custom implementations. Some of those may require additional compilation using
+ * 'export_library' on the final build artifact.
+ *
+ * The OutlineCompilerFunctionsWithExistingGlobalSymbols and MarkCompilerFunctionsAsExtern utility
+ * passes can be used by custom passes to take care of some of the boilerplate.
+ *
+ * TODO(mbs): Rename PreLoweringTargetHooks?
+ *
+ * \param config All available targets.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass RelayToTIRTargetHook(CompilationConfig config);
+
+/*!
+ * \brief A pass for manifesting explicit memory allocations and rewriting
+ * specific dialects.
+ *
+ * \param cpu_virtual_device VirtualDevice for computations and data which must reside on a CPU,
+ * such as shapes and shape functions.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass ManifestAlloc(VirtualDevice cpu_virtual_device);
+
+/*!
+ * \brief A pass for manifesting variable lifetimes by inserting kill operations when variables
+ * become dead. This pass should be run after ManifestAlloc, and should not be run more than once.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass ManifestLifetimes();
+
+/*!
+ * \brief Uses existing "on_device" and "device_copy" CallNodes to infer the \p VirtualDevice on
+ * which every Relay sub-expression should run and the result stored. Captures the result of that
+ * analysis using new "on_device" and "device_copy" CallNodes.
+ *
+ * See tvm::relay::transform::{LexicalOnDeviceMixin,DeviceAwareExprVisitor,DeviceAwareExprMutator}
+ * for help recovering the device for an arbitrary sub-expression in downstream transformations.
+ *
+ * \param config Describes the targets and default \p VirtualDevice for all primitive operators and
+ * host sub-expressions.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass PlanDevices(CompilationConfig config);
+
+/*!
+ * \brief This transform flattens atrous convolution, which corresponds to the sequence of
+ * operations: "space_to_batch_nd"->"conv2d"->"batch_to_space_nd" and convert them into subgraphs
+ * with a convolution with the modified "dilation" and recalculated "padding" parameters.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass FlattenAtrousConv();
+
+/*!
+ * \brief Annotates the minimum required memory of each primitive function callsite by analyzing
+ * the liveness of the input/output tensors at each function callsite and calculating the total
+ * amount of memory these tensors require. This is added as a "used_memory" annotation to the
+ * function in question as a list of the number of bytes for each callsite. In addition, the
+ * containing function is annotated with an "io_used_memory" annotation which refers to the total
+ * memory required for the IO tensors.
+ *
+ * Note: This pass does not support dynamic shapes, it is the users responsibility to check this
+ * pass isn't applied where dynamic shapes may be input.
+ */
+TVM_DLL Pass AnnotateUsedMemory();
+
+/*!
+ * \brief Captures the post-dfs index and dominator post-dfs index of (most) expression nodes in
+ * their span, in the form "index:<post-dfs index>:<dominator post-dfs index>". This is useful for
+ * debugging since a) it helps identify pretty-printed sub-expressions within the overall model
+ * and b) the indexes are heavily used by Collage for its compact representation of sub-graphs.
+ *
+ * Note that Op and Constructor nodes are not changed even though they are assigned an
+ * post-dfs index.
+ */
+TVM_DLL Pass CapturePostDfsIndexInSpans();
+
+/*!
+ * \brief Calls device dependent memory scope analysis pass, collects mapping of desirable
+ * expr->memory_scope and annotates expressions by VirtualDevice with required memory_scope
+ */
+TVM_DLL Pass AnnotateMemoryScope(CompilationConfig config);
+
+/*!
+ * \brief Removes non-fused reshapes after lowering the graph.
+ * InferType() cannot be invoked after calling this pass as it removes reshapes from the call
+ * graph. Many targets only need buffer addresses irrespective of the shapes of them. This makes
+ * reshapes symbolic once the graph has been lowered. Reshape removal results into smaller code
+ * size and reduced buffer allocations. It opens up opportunities of operator fusion in the target
+ * backend. Thus, consequently, it improves the performance of the inference.
+ */
+TVM_DLL Pass RemoveStandaloneReshapes();
+
+}  // namespace transform
+
+/*!
+ * \brief Bind the free variables to a Relay expression. This is a helper
+ * function usually called by other pass functions to help optimizations.
+ * If any free variables are introduced into a function, those are added
+ * to the functoin parameters.
+ * Additionally this may change the order of parameters if you map a variable
+ * to a variable.
+ *
+ * \param expr The input expression.
+ * \param binds The variable to expression map that will be used to help the
+ *        binding.
+ *
+ * \return The updated expression.
+ */
+TVM_DLL Expr Bind(const Expr& expr, const tvm::Map<Var, Expr>& binds);
+
+/*!
+ * \brief Substitute variables with new variables (including function parameters) in a function.
+ * This is a helper function usually called by other pass functions to help optimizations.
+ * Expects all values in the bind map to be Vars.
+ *
+ * \param func The input function.
+ * \param binds The variable to expression map that will be used to help the
+ *        binding.
+ *
+ * \return The updated expression.
+ */
+TVM_DLL Function SubstituteBoundVars(const Function& func, const tvm::Map<Var, Expr>& binds);
+
+/*!
+ * \brief Apply rewrite rules to rewrite the expr in post DFS order. This
+ * function is used as a helper function to rewrtie an expression in a pass.
+ *
+ * \param expr The expression.
+ * \param rewrite_map_attr_name The Op's attr name which corresponds to the rewrite
+ *                              rule function.
+ * \param fcontext Additional callback to provide context argument for each call node.
+ * \param fmulti_ref_trigger Transformation function to be called when
+ *                           an Expr consumed by multiple callers.
+ * \return The rewritten expression.
+ */
+TVM_DLL Expr ForwardRewrite(const Expr& expr, const String& rewrite_map_attr_name,
+                            std::function<ObjectRef(const Call&)> fcontext = nullptr,
+                            std::function<Expr(const Expr&)> fmulti_ref_trigger = nullptr);
+
+/*!
+ * \brief Apply rewrite rules to rewrite the expr in post DFS order. This
+ * function is used as a helper function to rewrtie an expression in a pass.
+ *
+ * \param expr The expression.
+ * \param rewrite_func The rewrite func that will apply to all operators.
+ * \param fcontext Additional callback to provide context argument for each call node.
+ * \param fmulti_ref_trigger Transformation function to be called when
+ *                           an Expr consumed by multiple callers.
+ *
+ * \return The rewritten expression.
+ */
+TVM_DLL Expr ForwardRewrite(const Expr& expr, const FForwardRewrite& rewrite_func,
+                            std::function<ObjectRef(const Call&)> fcontext = nullptr,
+                            std::function<Expr(const Expr&)> fmulti_ref_trigger = nullptr);
+
+/*!
+ * \brief Rewrite the annotated program.
+ *
+ * \param expr The expression.
+ * \param fallback_device The fallback device which is the default device for
+ *                        operators without annotation.
+ *
+ * \return The updated program.
+ */
+TVM_DLL Expr RewriteAnnotatedOps(const Expr& expr, int fallback_device);
+
+/*!
+ * \brief Turn an expression into continuation passing style(CPS).
+ *
+ * CPS mean that every function will, instead of returning the result directly,
+ * be passed down an extra function (called the continuation) as argument,
+ * and pass the result to the continuation instead.
+ *
+ * Thus, every function call has to be passed an extra argument
+ * that represent the rest of the computation (Hence the name of continuation).
+ *
+ * Similarly, all other compute will be wrapped and call the continuation as well.
+ *
+ * \param f the function.
+ * \param mod the module.
+ *
+ * \return the converted Function.
+ */
+TVM_DLL Function ToCPS(const Function& f, const IRModule& mod);
+
+/*!
+ * \brief Remove the continuation argument of a CPS function.
+ *
+ * Note that this only transform the type back into un-CPS form
+ * when there is no higher order input/output.
+ *
+ * \param f the function.
+ *
+ * \return the converted Function.
+ */
+TVM_DLL Function UnCPS(const Function& f);
+
+/*!
+ * \brief Deduplicate the bound variables and type variables in the expression.
+ *
+ * \param e the expression.
+ *
+ * \return the deduplicated expression.
+ */
+TVM_DLL Expr DeDup(const Expr& e);
+
+}  // namespace relay
+}  // namespace tvm
+
+#endif  // TVM_RELAY_TRANSFORM_H_
diff --git a/darknet_drp_ros/include/tvm/relay/type.h b/darknet_drp_ros/include/tvm/relay/type.h
new file mode 100644
index 0000000..a388c82
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/relay/type.h
@@ -0,0 +1,75 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/relay/type.h
+ * \brief Relay typed AST nodes.
+ */
+#ifndef TVM_RELAY_TYPE_H_
+#define TVM_RELAY_TYPE_H_
+
+#include <tvm/ir/attrs.h>
+#include <tvm/ir/env_func.h>
+#include <tvm/ir/tensor_type.h>
+#include <tvm/ir/type.h>
+#include <tvm/ir/type_relation.h>
+#include <tvm/runtime/registry.h>
+#include <tvm/tir/expr.h>
+
+#include <string>
+
+#include "base.h"
+
+namespace tvm {
+namespace relay {
+
+// namespace update for backward compact
+// will be removed later.
+using AnyNode = tvm::tir::AnyNode;
+using Any = tvm::tir::Any;
+using Kind = TypeKind;
+using Type = tvm::Type;
+using TypeNode = tvm::TypeNode;
+using TypeVar = tvm::TypeVar;
+using TypeVarNode = tvm::TypeVarNode;
+using GlobalTypeVar = tvm::GlobalTypeVar;
+using GlobalTypeVarNode = tvm::GlobalTypeVarNode;
+using TupleType = tvm::TupleType;
+using TupleTypeNode = tvm::TupleTypeNode;
+using TypeConstraint = tvm::TypeConstraint;
+using TypeConstraintNode = tvm::TypeConstraintNode;
+using FuncType = tvm::FuncType;
+using FuncTypeNode = tvm::FuncTypeNode;
+using IncompleteType = tvm::IncompleteType;
+using IncompleteTypeNode = tvm::IncompleteTypeNode;
+using RelayRefType = tvm::RelayRefType;
+using RelayRefTypeNode = tvm::RelayRefTypeNode;
+using TensorType = tvm::TensorType;
+using TensorTypeNode = tvm::TensorTypeNode;
+using TypeCall = tvm::TypeCall;
+using TypeCallNode = tvm::TypeCallNode;
+using TypeRelation = tvm::TypeRelation;
+using TypeRelationNode = tvm::TypeRelationNode;
+using TypeRelationFn = tvm::TypeRelationFn;
+using TypeReporter = tvm::TypeReporter;
+using TypeReporterNode = tvm::TypeReporterNode;
+
+}  // namespace relay
+}  // namespace tvm
+#endif  // TVM_RELAY_TYPE_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/builtin_fp16.h b/darknet_drp_ros/include/tvm/runtime/builtin_fp16.h
new file mode 100644
index 0000000..5b54583
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/builtin_fp16.h
@@ -0,0 +1,39 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file builtin_fp16.h
+ * \brief Functions for conversion between fp32 and fp16
+ */
+#ifndef TVM_RUNTIME_BUILTIN_FP16_H_
+#define TVM_RUNTIME_BUILTIN_FP16_H_
+
+#include <tvm/runtime/c_runtime_api.h>
+
+#include <cstdint>
+
+extern "C" {
+TVM_DLL uint16_t __gnu_f2h_ieee(float);
+TVM_DLL float __gnu_h2f_ieee(uint16_t);
+TVM_DLL uint16_t __truncsfhf2(float v);
+TVM_DLL uint16_t __truncdfhf2(double v);
+TVM_DLL float __extendhfsf2(uint16_t v);
+}
+
+#endif  // TVM_RUNTIME_BUILTIN_FP16_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/c_backend_api.h b/darknet_drp_ros/include/tvm/runtime/c_backend_api.h
new file mode 100644
index 0000000..8fde594
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/c_backend_api.h
@@ -0,0 +1,172 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/c_backend_api.h
+ * \brief TVM runtime backend API.
+ *
+ *  The functions defined in this header are intended to be
+ *  used by compiled tvm operators, usually user do not need to use these
+ *  function directly.
+ */
+#ifndef TVM_RUNTIME_C_BACKEND_API_H_
+#define TVM_RUNTIME_C_BACKEND_API_H_
+
+#include <tvm/runtime/c_runtime_api.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/*!
+ * \brief Signature for backend functions exported as DLL.
+ *
+ * \param args The arguments
+ * \param type_codes The type codes of the arguments
+ * \param num_args Number of arguments.
+ * \param out_ret_value The output value of the return value.
+ * \param out_ret_tcode The output type code of the return value.
+ * \param resource_handle Pointer to associated resource.
+ *
+ * \return 0 if success, -1 if failure happens, set error via TVMAPISetLastError.
+ */
+typedef int (*TVMBackendPackedCFunc)(TVMValue* args, int* type_codes, int num_args,
+                                     TVMValue* out_ret_value, int* out_ret_tcode,
+                                     void* resource_handle);
+
+/*!
+ * \brief Backend function for modules to get function
+ *  from its environment mod_node (its imports and global function).
+ *  The user do should not call TVMFuncFree on func.
+ *
+ * \param mod_node The module handle.
+ * \param func_name The name of the function.
+ * \param out The result function.
+ * \return 0 when no error is thrown, -1 when failure happens
+ */
+TVM_DLL int TVMBackendGetFuncFromEnv(void* mod_node, const char* func_name, TVMFunctionHandle* out);
+
+/*!
+ * \brief Backend function to register system-wide library symbol.
+ *
+ * \param name The name of the symbol
+ * \param ptr The symbol address.
+ * \return 0 when no error is thrown, -1 when failure happens
+ */
+TVM_DLL int TVMBackendRegisterSystemLibSymbol(const char* name, void* ptr);
+
+/*!
+ * \brief Backend function to allocate temporal workspace.
+ *
+ * \note The result allocated space is ensured to be aligned to kTempAllocaAlignment.
+ *
+ * \param nbytes The size of the space requested.
+ * \param device_type The device type which the space will be allocated.
+ * \param device_id The device id which the space will be allocated.
+ * \param dtype_code_hint The type code of the array elements. Only used in
+ * certain backends such as OpenGL.
+ * \param dtype_bits_hint The type bits of the array elements. Only used in
+ * certain backends such as OpenGL.
+ * \return nullptr when error is thrown, a valid ptr if success
+ */
+TVM_DLL void* TVMBackendAllocWorkspace(int device_type, int device_id, uint64_t nbytes,
+                                       int dtype_code_hint, int dtype_bits_hint);
+
+/*!
+ * \brief Backend function to free temporal workspace.
+ *
+ * \param ptr The result allocated space pointer.
+ * \param device_type The device type which the space will be allocated.
+ * \param device_id The device id which the space will be allocated.
+ * \return 0 when no error is thrown, -1 when failure happens
+ *
+ * \sa TVMBackendAllocWorkspace
+ */
+TVM_DLL int TVMBackendFreeWorkspace(int device_type, int device_id, void* ptr);
+
+/*!
+ * \brief Backend function to register execution environment(e.g. python)
+ *        specific C APIs.
+ *
+ * \note  We only register the C API function when absolutely necessary (e.g. when signal handler
+ *  cannot trap back into python). In most cases we should use the PackedFunc FFI.
+ *
+ * \param name The name of the symbol
+ * \param ptr The symbol address.
+ * \return 0 when no error is thrown, -1 when failure happens
+ */
+TVM_DLL int TVMBackendRegisterEnvCAPI(const char* name, void* ptr);
+
+/*!
+ * \brief Environment for TVM parallel task.
+ */
+typedef struct {
+  /*!
+   * \brief Auxiliary used for synchronization
+   */
+  void* sync_handle;
+  /*! \brief total amount of task */
+  int32_t num_task;
+} TVMParallelGroupEnv;
+
+/*!
+ * \brief The callback function to execute a parallel lambda
+ * \param task_id the task id of the function.
+ * \param penv The parallel environment backs the execution.
+ * \param cdata The supporting closure data.
+ */
+typedef int (*FTVMParallelLambda)(int task_id, TVMParallelGroupEnv* penv, void* cdata);
+
+/*!
+ * \brief Backend function for running parallel jobs.
+ *
+ * \param flambda The parallel function to be launched.
+ * \param cdata The closure data.
+ * \param num_task Number of tasks to launch, can be 0, means launch
+ *           with all available threads.
+ *
+ * \return 0 when no error is thrown, -1 when failure happens
+ */
+TVM_DLL int TVMBackendParallelLaunch(FTVMParallelLambda flambda, void* cdata, int num_task);
+
+/*!
+ * \brief BSP barrrier between parallel threads
+ * \param task_id the task id of the function.
+ * \param penv The parallel environment backs the execution.
+ * \return 0 when no error is thrown, -1 when failure happens
+ */
+TVM_DLL int TVMBackendParallelBarrier(int task_id, TVMParallelGroupEnv* penv);
+
+/*!
+ * \brief Simple static initialization function.
+ *  Run f once and set handle to be not null.
+ *  This function is mainly used for test purpose.
+ *
+ * \param handle A global address to indicate f
+ * \param f The function to be run
+ * \param cdata The closure data to pass to the function.
+ * \param nbytes Number of bytes in the closure data.
+ * \return 0 when no error is thrown, -1 when failure happens
+ */
+TVM_DLL int TVMBackendRunOnce(void** handle, int (*f)(void*), void* cdata, int nbytes);
+
+#ifdef __cplusplus
+}  // TVM_EXTERN_C
+#endif
+#endif  // TVM_RUNTIME_C_BACKEND_API_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/c_runtime_api.h b/darknet_drp_ros/include/tvm/runtime/c_runtime_api.h
new file mode 100644
index 0000000..1ee0331
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/c_runtime_api.h
@@ -0,0 +1,678 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*
+ * \file tvm/runtime/c_runtime_api.h
+ * \brief TVM runtime library.
+ *
+ *  The philosophy of TVM project is to customize the compilation
+ *  stage to generate code that can used by other projects transparently.
+ *  So this is a minimum runtime code gluing, and some limited
+ *  memory management code to enable quick testing.
+ *
+ *  The runtime API is independent from TVM compilation stack and can
+ *  be linked via libtvm_runtime.
+ *
+ *  The common flow is:
+ *   - Use TVMFuncListGlobalNames to get global function name
+ *   - Use TVMFuncCall to call these functions.
+ *
+ *  Possible return values of the API functions:
+ *  * 0: success
+ *  * -1: the error can be retrieved through TVMGetLastError.
+ *  * -2: a frontend error occurred and recorded in the frontend.
+ */
+#ifndef TVM_RUNTIME_C_RUNTIME_API_H_
+#define TVM_RUNTIME_C_RUNTIME_API_H_
+
+// Macros to do weak linking
+#ifdef _MSC_VER
+#define TVM_WEAK __declspec(selectany)
+#else
+#define TVM_WEAK __attribute__((weak))
+#endif
+
+#ifdef __EMSCRIPTEN__
+#include <emscripten/emscripten.h>
+#define TVM_DLL EMSCRIPTEN_KEEPALIVE
+#endif
+
+#ifndef TVM_DLL
+#ifdef _WIN32
+#ifdef TVM_EXPORTS
+#define TVM_DLL __declspec(dllexport)
+#else
+#define TVM_DLL __declspec(dllimport)
+#endif
+#else
+#define TVM_DLL __attribute__((visibility("default")))
+#endif
+#endif
+
+// TVM version
+#define TVM_VERSION "0.11.1"
+
+// TVM Runtime is DLPack compatible.
+#include <dlpack/dlpack.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+#include <stddef.h>
+#include <stdint.h>
+
+/*! \brief type of array index. */
+typedef int64_t tvm_index_t;
+
+/*! \brief Extension device types in TVM
+ *
+ * Additional enumerators to supplement those provided by
+ * DLPack's `DLDeviceType` enumeration.
+ *
+ * MAINTAINERS NOTE #1: We need to ensure that the two devices
+ * are identified by the same integer.
+ * Currently this requires manual verification.
+ * Discussed here: https://github.com/dmlc/dlpack/issues/111
+ * As of DLPack v0.7, the highest-valued enumerator in
+ * `DLDeviceType` is kDLHexagon = 16.
+ *
+ * MAINTAINERS NOTE #2: As of DLPack v0.7, the definition for
+ * `DLDeviceType` specifies an underlying storage type of
+ * `int32_t`.  That guarantees a variable of type
+ * `DLDeviceType` is capable of holding any integers provided
+ * by *either* of these enumerations.
+ *
+ * However, the `int32_t` specification only applies when the
+ * header file is compiled as C++, and this header file is also
+ * meant to work as C code.  So the unspecified storage type
+ * could be a latent bug when compiled as C.
+ */
+#ifdef __cplusplus
+typedef enum : int32_t {
+#else
+typedef enum {
+#endif
+  // To help avoid accidental conflicts between `DLDeviceType`
+  // and this enumeration, start numbering the new enumerators
+  // a little higher than (currently) seems necessary.
+  kDLAOCL = 32,
+  kDLSDAccel = 33,
+  kOpenGL = 34,
+  kDLMicroDev = 35,
+  kDLDrpAi = 36,
+  TVMDeviceExtType_End,  // sentinel value
+} TVMDeviceExtType;
+
+#ifdef __cplusplus
+// Some other parts of TVM hardcode the integer identifier for
+// some DLPack / TVM devices, rather then using the symbolic
+// enumerator.   E.g., `2` rather than `kDLCUDA`.
+// These asserts should alert us when that mapping breaks.
+#define TVM_HARCODED_INTEGER_CHANGED_MSG                                                          \
+  "Change in compile-time integer.  Make sure hardcoded uses of this integer throughout TVM are " \
+  "updated."
+static_assert(kDLCPU == 1, TVM_HARCODED_INTEGER_CHANGED_MSG);
+static_assert(kDLCUDA == 2, TVM_HARCODED_INTEGER_CHANGED_MSG);
+static_assert(kDLCUDAHost == 3, TVM_HARCODED_INTEGER_CHANGED_MSG);
+static_assert(kDLOpenCL == 4, TVM_HARCODED_INTEGER_CHANGED_MSG);
+static_assert(kDLVulkan == 7, TVM_HARCODED_INTEGER_CHANGED_MSG);
+static_assert(kDLMetal == 8, TVM_HARCODED_INTEGER_CHANGED_MSG);
+static_assert(kDLVPI == 9, TVM_HARCODED_INTEGER_CHANGED_MSG);
+static_assert(kDLROCM == 10, TVM_HARCODED_INTEGER_CHANGED_MSG);
+static_assert(kDLROCMHost == 11, TVM_HARCODED_INTEGER_CHANGED_MSG);
+static_assert(kDLExtDev == 12, TVM_HARCODED_INTEGER_CHANGED_MSG);
+static_assert(kDLCUDAManaged == 13, TVM_HARCODED_INTEGER_CHANGED_MSG);
+static_assert(kDLOneAPI == 14, TVM_HARCODED_INTEGER_CHANGED_MSG);
+static_assert(kDLWebGPU == 15, TVM_HARCODED_INTEGER_CHANGED_MSG);
+static_assert(kDLHexagon == 16, TVM_HARCODED_INTEGER_CHANGED_MSG);
+
+static_assert(kDLAOCL == 32, TVM_HARCODED_INTEGER_CHANGED_MSG);
+static_assert(kDLSDAccel == 33, TVM_HARCODED_INTEGER_CHANGED_MSG);
+static_assert(kOpenGL == 34, TVM_HARCODED_INTEGER_CHANGED_MSG);
+static_assert(kDLMicroDev == 35, TVM_HARCODED_INTEGER_CHANGED_MSG);
+static_assert(kDLDrpAi == 36, TVM_HARCODED_INTEGER_CHANGED_MSG);
+#undef TVM_HARCODED_INTEGER_CHANGED_MSG
+#endif
+
+/*!
+ * \brief The type code in used and only used in TVM FFI for argument passing.
+ *
+ * DLPack consistency:
+ * 1) kTVMArgInt is compatible with kDLInt
+ * 2) kTVMArgFloat is compatible with kDLFloat
+ * 3) kDLUInt is not in ArgTypeCode, but has a spared slot
+ *
+ * Downstream consistency:
+ * The kDLInt, kDLUInt, kDLFloat are kept consistent with the original ArgType code
+ *
+ * It is only used in argument passing, and should not be confused with
+ * DataType::TypeCode, which is DLPack-compatible.
+ *
+ * \sa tvm::runtime::DataType::TypeCode
+ */
+typedef enum {
+  kTVMArgInt = kDLInt,
+  kTVMArgFloat = kDLFloat,
+  kTVMOpaqueHandle = 3U,
+  kTVMNullptr = 4U,
+  kTVMDataType = 5U,
+  kDLDevice = 6U,
+  kTVMDLTensorHandle = 7U,
+  kTVMObjectHandle = 8U,
+  kTVMModuleHandle = 9U,
+  kTVMPackedFuncHandle = 10U,
+  kTVMStr = 11U,
+  kTVMBytes = 12U,
+  kTVMNDArrayHandle = 13U,
+  kTVMObjectRValueRefArg = 14U,
+  // Extension codes for other frameworks to integrate TVM PackedFunc.
+  // To make sure each framework's id do not conflict, use first and
+  // last sections to mark ranges.
+  // Open an issue at the repo if you need a section of code.
+  kTVMExtBegin = 15U,
+  kTVMNNVMFirst = 16U,
+  kTVMNNVMLast = 20U,
+  // The following section of code is used for non-reserved types.
+  kTVMExtReserveEnd = 64U,
+  kTVMExtEnd = 128U,
+} TVMArgTypeCode;
+
+/*! \brief the array handle */
+typedef DLTensor* TVMArrayHandle;
+
+/*!
+ * \brief Union type of values
+ *  being passed through API and function calls.
+ */
+typedef union {
+  int64_t v_int64;
+  double v_float64;
+  void* v_handle;
+  const char* v_str;
+  DLDataType v_type;
+  DLDevice v_device;
+} TVMValue;
+
+/*!
+ * \brief Byte array type used to pass in byte array
+ *  When kTVMBytes is used as data type.
+ */
+typedef struct {
+  const char* data;
+  size_t size;
+} TVMByteArray;
+
+/*! \brief Handle to TVM runtime modules. */
+typedef void* TVMModuleHandle;
+/*! \brief Handle to packed function handle. */
+typedef void* TVMFunctionHandle;
+/*! \brief Handle to hold return value. */
+typedef void* TVMRetValueHandle;
+/*!
+ * \brief The stream that is specific to device
+ * can be NULL, which indicates the default one.
+ */
+typedef void* TVMStreamHandle;
+/*! \brief Handle to Object. */
+typedef void* TVMObjectHandle;
+
+/*!
+ * \brief Used for implementing C API function.
+ *  Set last error message before return.
+ * \param msg The error message to be set.
+ */
+TVM_DLL void TVMAPISetLastError(const char* msg);
+
+/*!
+ * \brief return str message of the last error
+ *  all function in this file will return 0 when success
+ *  and nonzero when an error occurred,
+ *  TVMGetLastError can be called to retrieve the error
+ *
+ *  this function is threadsafe and can be called by different thread
+ *  \return error info
+ */
+TVM_DLL const char* TVMGetLastError(void);
+/*!
+ * \brief Load module from file.
+ * \param file_name The file name to load the module from.
+ * \param format The format of the module.
+ * \param out The result module
+ *
+ * \return 0 when success, nonzero when failure happens
+ * \note The resulting module do not contain import relation.
+ *  It can be reconstructed by TVMModImport.
+ */
+TVM_DLL int TVMModLoadFromFile(const char* file_name, const char* format, TVMModuleHandle* out);
+
+/*!
+ * \brief Add dep to mod's dependency.
+ *  This allows functions in this module to use modules.
+ *
+ * \param mod The module handle.
+ * \param dep The dependent module to be imported.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMModImport(TVMModuleHandle mod, TVMModuleHandle dep);
+
+/*!
+ * \brief Get function from the module.
+ * \param mod The module handle.
+ * \param func_name The name of the function.
+ * \param query_imports Whether to query imported modules
+ * \param out The result function, can be NULL if it is not available.
+ * \return 0 when no error is thrown, nonzero when failure happens
+ */
+TVM_DLL int TVMModGetFunction(TVMModuleHandle mod, const char* func_name, int query_imports,
+                              TVMFunctionHandle* out);
+
+/*!
+ * \brief Free the Module
+ * \param mod The module to be freed.
+ *
+ * \note This may not free up the module's resources.
+ *  If there is active TVMFunctionHandle uses the module
+ *  Or if this module is imported by another active module.
+ *
+ *  The all functions remains valid until TVMFuncFree is called.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMModFree(TVMModuleHandle mod);
+
+/*!
+ * \brief Free the function when it is no longer needed.
+ * \param func The function handle
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMFuncFree(TVMFunctionHandle func);
+
+/*!
+ * \brief Call a Packed TVM Function.
+ *
+ * \param func node handle of the function.
+ * \param arg_values The arguments
+ * \param type_codes The type codes of the arguments
+ * \param num_args Number of arguments.
+ *
+ * \param ret_val The return value.
+ * \param ret_type_code the type code of return value.
+ *
+ * \return 0 when success, nonzero when failure happens
+ * \note TVM calls always exchanges with type bits=64, lanes=1
+ *
+ * \note API calls always exchanges with type bits=64, lanes=1
+ *   If API call returns container handles (e.g. FunctionHandle)
+ *   these handles should be managed by the front-end.
+ *   The front-end need to call free function (e.g. TVMFuncFree)
+ *   to free these handles.
+ */
+TVM_DLL int TVMFuncCall(TVMFunctionHandle func, TVMValue* arg_values, int* type_codes, int num_args,
+                        TVMValue* ret_val, int* ret_type_code);
+
+/*!
+ * \brief Set the return value of TVMPackedCFunc.
+ *
+ *  This function is called by TVMPackedCFunc to set the return value.
+ *  When this function is not called, the function returns null by default.
+ *
+ * \param ret The return value handle, pass by ret in TVMPackedCFunc
+ * \param value The value to be returned.
+ * \param type_code The type of the value to be returned.
+ * \param num_ret Number of return values, for now only 1 is supported.
+ */
+TVM_DLL int TVMCFuncSetReturn(TVMRetValueHandle ret, TVMValue* value, int* type_code, int num_ret);
+
+/*!
+ * \brief Inplace translate callback argument value to return value.
+ *  This is only needed for non-POD arguments.
+ *
+ * \param value The value to be translated.
+ * \param code The type code to be translated.
+ * \note This function will do a shallow copy when necessary.
+ *
+ * \return 0 when success, nonzero when failure happens.
+ */
+TVM_DLL int TVMCbArgToReturn(TVMValue* value, int* code);
+
+/*!
+ * \brief C type of packed function.
+ *
+ * \param args The arguments
+ * \param type_codes The type codes of the arguments
+ * \param num_args Number of arguments.
+ * \param ret The return value handle.
+ * \param resource_handle The handle additional resouce handle from front-end.
+ * \return 0 if success, -1 if failure happens, set error via TVMAPISetLastError.
+ * \sa TVMCFuncSetReturn
+ */
+typedef int (*TVMPackedCFunc)(TVMValue* args, int* type_codes, int num_args, TVMRetValueHandle ret,
+                              void* resource_handle);
+
+/*!
+ * \brief C callback to free the resource handle in C packed function.
+ * \param resource_handle The handle additional resouce handle from front-end.
+ */
+typedef void (*TVMPackedCFuncFinalizer)(void* resource_handle);
+
+/*!
+ * \brief Signature for extension function declarer.
+ *
+ *  TVM call this function to get the extension functions
+ *  The declarer will call register_func to register function and their name.
+ *
+ * \param register_func_handle The register function
+ * \return 0 if success, -1 if failure happens
+ */
+typedef int (*TVMExtensionFuncDeclarer)(TVMFunctionHandle register_func_handle);
+
+/*!
+ * \brief Wrap a TVMPackedCFunc to become a FunctionHandle.
+ *
+ * The resource_handle will be managed by TVM API, until the function is no longer used.
+ *
+ * \param func The packed C function.
+ * \param resource_handle The resource handle from front-end, can be NULL.
+ * \param fin The finalizer on resource handle when the FunctionHandle get freed, can be NULL
+ * \param out the result function handle.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMFuncCreateFromCFunc(TVMPackedCFunc func, void* resource_handle,
+                                   TVMPackedCFuncFinalizer fin, TVMFunctionHandle* out);
+
+/*!
+ * \brief Register the function to runtime's global table.
+ *
+ * The registered function then can be pulled by the backend by the name.
+ *
+ * \param name The name of the function.
+ * \param f The function to be registered.
+ * \param override Whether allow override already registered function.
+ */
+TVM_DLL int TVMFuncRegisterGlobal(const char* name, TVMFunctionHandle f, int override);
+
+/*!
+ * \brief Get a global function.
+ *
+ * \param name The name of the function.
+ * \param out the result function pointer, NULL if it does not exist.
+ *
+ * \note The function handle of global function is managed by TVM runtime,
+ *  So TVMFuncFree is should not be called when it get deleted.
+ */
+TVM_DLL int TVMFuncGetGlobal(const char* name, TVMFunctionHandle* out);
+
+/*!
+ * \brief List all the globally registered function name
+ * \param out_size The number of functions
+ * \param out_array The array of function names.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMFuncListGlobalNames(int* out_size, const char*** out_array);
+
+/*!
+ * \brief Remove a global function.
+ * \param name The name of the function.
+ */
+TVM_DLL int TVMFuncRemoveGlobal(const char* name);
+
+// Array related apis for quick proptyping
+/*!
+ * \brief Allocate a nd-array's memory,
+ *  including space of shape, of given spec.
+ *
+ * \param shape The shape of the array, the data content will be copied to out
+ * \param ndim The number of dimension of the array.
+ * \param dtype_code The type code of the dtype
+ * \param dtype_bits The number of bits of dtype
+ * \param dtype_lanes The number of lanes in the dtype.
+ * \param device_type The device type.
+ * \param device_id The device id.
+ * \param out The output handle.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMArrayAlloc(const tvm_index_t* shape, int ndim, int dtype_code, int dtype_bits,
+                          int dtype_lanes, int device_type, int device_id, TVMArrayHandle* out);
+
+/*!
+ * \brief Free the TVM Array.
+ * \param handle The array handle to be freed.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMArrayFree(TVMArrayHandle handle);
+
+/*!
+ * \brief Copy array data from CPU byte array.
+ * \param handle The array handle.
+ * \param data the data pointer
+ * \param nbytes The number of bytes to copy.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMArrayCopyFromBytes(TVMArrayHandle handle, void* data, size_t nbytes);
+
+/*!
+ * \brief Copy array data to CPU byte array.
+ * \param handle The array handle.
+ * \param data the data pointer
+ * \param nbytes The number of bytes to copy.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMArrayCopyToBytes(TVMArrayHandle handle, void* data, size_t nbytes);
+
+/*!
+ * \brief Copy the array, both from and to must be valid during the copy.
+ * \param from The array to be copied from.
+ * \param to The target space.
+ * \param stream The stream where the copy happens, can be NULL.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMArrayCopyFromTo(TVMArrayHandle from, TVMArrayHandle to, TVMStreamHandle stream);
+
+/*!
+ * \brief Produce an array from the DLManagedTensor that shares data memory
+ * with the DLManagedTensor.
+ * \param from The source DLManagedTensor.
+ * \param out The output array handle.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMArrayFromDLPack(DLManagedTensor* from, TVMArrayHandle* out);
+
+/*!
+ * \brief Produce a DLMangedTensor from the array that shares data memory with
+ * the array.
+ * \param from The source array.
+ * \param out The DLManagedTensor handle.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMArrayToDLPack(TVMArrayHandle from, DLManagedTensor** out);
+
+/*!
+ * \brief Delete (free) a DLManagedTensor's data.
+ * \param dltensor Pointer to the DLManagedTensor.
+ */
+TVM_DLL void TVMDLManagedTensorCallDeleter(DLManagedTensor* dltensor);
+
+/*!
+ * \brief Create a new runtime stream.
+ *
+ * \param device_type The device type.
+ * \param device_id The device id.
+ * \param out The new stream handle.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMStreamCreate(int device_type, int device_id, TVMStreamHandle* out);
+
+/*!
+ * \brief Free a created stream handle.
+ *
+ * \param device_type The device type.
+ * \param device_id The device id.
+ * \param stream The stream to be freed.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMStreamFree(int device_type, int device_id, TVMStreamHandle stream);
+
+/*!
+ * \brief Set the runtime stream of current thread to be stream.
+ *  The subsequent calls to the same device_type
+ *  will use the setted stream handle.
+ *  The specific type of stream is runtime device dependent.
+ *
+ * \param device_type The device type.
+ * \param device_id The device id.
+ * \param handle The stream handle.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMSetStream(int device_type, int device_id, TVMStreamHandle handle);
+
+/*!
+ * \brief Wait until all computations on stream completes.
+ *
+ * \param device_type The device type.
+ * \param device_id The device id.
+ * \param stream The stream to be synchronized.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMSynchronize(int device_type, int device_id, TVMStreamHandle stream);
+
+/*!
+ * \brief Synchronize two streams of execution.
+ *
+ * \param device_type The device type.
+ * \param device_id The device id.
+ * \param src The source stream to synchronize.
+ * \param dst The destination stream to synchronize.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMStreamStreamSynchronize(int device_type, int device_id, TVMStreamHandle src,
+                                       TVMStreamHandle dst);
+
+/*!
+ * \brief Get the type_index from an object.
+ *
+ * \param obj The object handle.
+ * \param out_tindex the output type index.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMObjectGetTypeIndex(TVMObjectHandle obj, unsigned* out_tindex);
+
+/*!
+ * \brief Convert type key to type index.
+ * \param type_key The key of the type.
+ * \param out_tindex the corresponding type index.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMObjectTypeKey2Index(const char* type_key, unsigned* out_tindex);
+
+/*!
+ * \brief Convert type index to type key.
+ * \param tindex The type index.
+ * \param out_type_key The output type key.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMObjectTypeIndex2Key(unsigned tindex, char** out_type_key);
+
+/*!
+ * \brief Increase the reference count of an object.
+ *
+ * \param obj The object handle.
+ * \note Internally we increase the reference counter of the object.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMObjectRetain(TVMObjectHandle obj);
+
+/*!
+ * \brief Free the object.
+ *
+ * \param obj The object handle.
+ * \note Internally we decrease the reference counter of the object.
+ *       The object will be freed when every reference to the object are removed.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMObjectFree(TVMObjectHandle obj);
+
+/*!
+ * \brief Free a TVMByteArray returned from TVMFuncCall, and associated memory.
+ * \param arr The TVMByteArray instance.
+ * \return 0 on success, -1 on failure.
+ */
+TVM_DLL int TVMByteArrayFree(TVMByteArray* arr);
+
+/*!
+ * \brief Allocate a data space on device.
+ * \param dev The device to perform operation.
+ * \param nbytes The number of bytes in memory.
+ * \param alignment The alignment of the memory.
+ * \param type_hint The type of elements. Only needed by certain backends such
+ *                   as nbytes & alignment are sufficient for most backends.
+ * \param out_data The allocated device pointer.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMDeviceAllocDataSpace(DLDevice dev, size_t nbytes, size_t alignment,
+                                    DLDataType type_hint, void** out_data);
+
+/*!
+ * \brief Allocate a data space on device with special memory scope.
+ * \note The memory could use a special multi-dimensional memory layout.
+ *       That is why we pass shape and dtype instead of raw number of bytes.
+ * \param dev The device to perform operation.
+ * \param ndim The number of dimension of the tensor.
+ * \param shape The shape of the tensor.
+ * \param dtype The type of elements.
+ * \param mem_scope The memory scope of the tensor,
+ *        can be nullptr, which indicate the default global DRAM
+ * \param out_data The allocated device pointer.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMDeviceAllocDataSpaceWithScope(DLDevice dev, int ndim, const int64_t* shape,
+                                             DLDataType dtype, const char* mem_scope,
+                                             void** out_data);
+
+/*!
+ * \brief Free a data space on device.
+ * \param dev The device to perform operation.
+ * \param ptr The data space.
+ * \return 0 when success, nonzero when failure happens
+ */
+TVM_DLL int TVMDeviceFreeDataSpace(DLDevice dev, void* ptr);
+
+/*!
+ * \brief Copy data from one place to another.
+ * \note This API is designed to support special memory with shape dependent layout.
+ *       We pass in DLTensor* with shape information to support these cases.
+ * \param from The source tensor.
+ * \param to The target tensor.
+ * \param stream Optional stream object.
+ * \return 0 when success, nonzero when failure happens.
+ */
+TVM_DLL int TVMDeviceCopyDataFromTo(DLTensor* from, DLTensor* to, TVMStreamHandle stream);
+
+/*!
+ * \brief Check that an object is derived from another.
+ * \param child_type_index The type index of the derived type.
+ * \param parent_type_index The type index of the parent type.
+ * \param is_derived A boolean representing whether this predicate holds.
+ * \return 0 when success, nonzero when failure happens.
+ */
+TVM_DLL int TVMObjectDerivedFrom(uint32_t child_type_index, uint32_t parent_type_index,
+                                 int* is_derived);
+
+#ifdef __cplusplus
+}  // TVM_EXTERN_C
+#endif
+#endif  // TVM_RUNTIME_C_RUNTIME_API_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/container/adt.h b/darknet_drp_ros/include/tvm/runtime/container/adt.h
new file mode 100644
index 0000000..20c4f79
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/container/adt.h
@@ -0,0 +1,146 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/container/adt.h
+ * \brief Runtime ADT container types.
+ */
+#ifndef TVM_RUNTIME_CONTAINER_ADT_H_
+#define TVM_RUNTIME_CONTAINER_ADT_H_
+
+#include <utility>
+#include <vector>
+
+#include "./base.h"
+
+namespace tvm {
+namespace runtime {
+
+/*! \brief An object representing a structure or enumeration. */
+class ADTObj : public Object, public InplaceArrayBase<ADTObj, ObjectRef> {
+ public:
+  /*! \brief The tag representing the constructor used. */
+  int32_t tag;
+  /*! \brief Number of fields in the ADT object. */
+  uint32_t size;
+  // The fields of the structure follows directly in memory.
+
+  static constexpr const uint32_t _type_index = TypeIndex::kRuntimeADT;
+  static constexpr const char* _type_key = "runtime.ADT";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ADTObj, Object);
+
+ private:
+  /*!
+   * \return The number of elements in the array.
+   */
+  size_t GetSize() const { return size; }
+
+  /*!
+   * \brief Initialize the elements in the array.
+   *
+   * \tparam Iterator Iterator type of the array.
+   * \param begin The begin iterator.
+   * \param end The end iterator.
+   */
+  template <typename Iterator>
+  void Init(Iterator begin, Iterator end) {
+    size_t num_elems = std::distance(begin, end);
+    this->size = 0;
+    auto it = begin;
+    for (size_t i = 0; i < num_elems; ++i) {
+      InplaceArrayBase::EmplaceInit(i, *it++);
+      // Only increment size after the initialization succeeds
+      this->size++;
+    }
+  }
+
+  friend class ADT;
+  friend InplaceArrayBase<ADTObj, ObjectRef>;
+};
+
+/*! \brief reference to algebraic data type objects. */
+class ADT : public ObjectRef {
+ public:
+  /*!
+   * \brief construct an ADT object reference.
+   * \param tag The tag of the ADT object.
+   * \param fields The fields of the ADT object.
+   * \return The constructed ADT object reference.
+   */
+  ADT(int32_t tag, std::vector<ObjectRef> fields) : ADT(tag, fields.begin(), fields.end()){};
+
+  /*!
+   * \brief construct an ADT object reference.
+   * \param tag The tag of the ADT object.
+   * \param begin The begin iterator to the start of the fields array.
+   * \param end The end iterator to the end of the fields array.
+   * \return The constructed ADT object reference.
+   */
+  template <typename Iterator>
+  ADT(int32_t tag, Iterator begin, Iterator end) {
+    size_t num_elems = std::distance(begin, end);
+    auto ptr = make_inplace_array_object<ADTObj, ObjectRef>(num_elems);
+    ptr->tag = tag;
+    ptr->Init(begin, end);
+    data_ = std::move(ptr);
+  }
+
+  /*!
+   * \brief construct an ADT object reference.
+   * \param tag The tag of the ADT object.
+   * \param init The initializer list of fields.
+   * \return The constructed ADT object reference.
+   */
+  ADT(int32_t tag, std::initializer_list<ObjectRef> init) : ADT(tag, init.begin(), init.end()){};
+
+  /*!
+   * \brief Access element at index.
+   *
+   * \param idx The array index
+   * \return const ObjectRef
+   */
+  const ObjectRef& operator[](size_t idx) const { return operator->()->operator[](idx); }
+
+  /*!
+   * \brief Return the ADT tag.
+   */
+  int32_t tag() const { return operator->()->tag; }
+
+  /*!
+   * \brief Return the number of fields.
+   */
+  size_t size() const { return operator->()->size; }
+
+  /*!
+   * \brief Construct a tuple object.
+   *
+   * \tparam Args Type params of tuple feilds.
+   * \param args Tuple fields.
+   * \return ADT The tuple object reference.
+   */
+  template <typename... Args>
+  static ADT Tuple(Args&&... args) {
+    return ADT(0, std::forward<Args>(args)...);
+  }
+
+  TVM_DEFINE_OBJECT_REF_METHODS(ADT, ObjectRef, ADTObj);
+};
+}  // namespace runtime
+}  // namespace tvm
+#endif  // TVM_RUNTIME_CONTAINER_ADT_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/container/array.h b/darknet_drp_ros/include/tvm/runtime/container/array.h
new file mode 100644
index 0000000..1b735e7
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/container/array.h
@@ -0,0 +1,860 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/container/array.h
+ * \brief Runtime Array container types.
+ */
+#ifndef TVM_RUNTIME_CONTAINER_ARRAY_H_
+#define TVM_RUNTIME_CONTAINER_ARRAY_H_
+
+#include <algorithm>
+#include <memory>
+#include <type_traits>
+#include <utility>
+#include <vector>
+
+#include "./base.h"
+#include "./optional.h"
+
+namespace tvm {
+namespace runtime {
+
+/*! \brief array node content in array */
+class ArrayNode : public Object, public InplaceArrayBase<ArrayNode, ObjectRef> {
+ public:
+  /*! \return The size of the array */
+  size_t size() const { return this->size_; }
+
+  /*!
+   * \brief Read i-th element from array.
+   * \param i The index
+   * \return the i-th element.
+   */
+  const ObjectRef at(int64_t i) const { return this->operator[](i); }
+
+  /*! \return begin constant iterator */
+  const ObjectRef* begin() const { return static_cast<ObjectRef*>(InplaceArrayBase::AddressOf(0)); }
+
+  /*! \return end constant iterator */
+  const ObjectRef* end() const { return begin() + size_; }
+
+  /*! \brief Release reference to all the elements */
+  void clear() { ShrinkBy(size_); }
+
+  /*!
+   * \brief Set i-th element of the array in-place
+   * \param i The index
+   * \param item The value to be set
+   */
+  void SetItem(int64_t i, ObjectRef item) { this->operator[](i) = std::move(item); }
+
+  /*!
+   * \brief Constructs a container and copy from another
+   * \param cap The capacity of the container
+   * \param from Source of the copy
+   * \return Ref-counted ArrayNode requested
+   */
+  static ObjectPtr<ArrayNode> CopyFrom(int64_t cap, ArrayNode* from) {
+    int64_t size = from->size_;
+    ICHECK_GE(cap, size) << "ValueError: not enough capacity";
+    ObjectPtr<ArrayNode> p = ArrayNode::Empty(cap);
+    ObjectRef* write = p->MutableBegin();
+    ObjectRef* read = from->MutableBegin();
+    // To ensure exception safety, size is only incremented after the initialization succeeds
+    for (int64_t& i = p->size_ = 0; i < size; ++i) {
+      new (write++) ObjectRef(*read++);
+    }
+    return p;
+  }
+
+  /*!
+   * \brief Constructs a container and move from another
+   * \param cap The capacity of the container
+   * \param from Source of the move
+   * \return Ref-counted ArrayNode requested
+   */
+  static ObjectPtr<ArrayNode> MoveFrom(int64_t cap, ArrayNode* from) {
+    int64_t size = from->size_;
+    ICHECK_GE(cap, size) << "ValueError: not enough capacity";
+    ObjectPtr<ArrayNode> p = ArrayNode::Empty(cap);
+    ObjectRef* write = p->MutableBegin();
+    ObjectRef* read = from->MutableBegin();
+    // To ensure exception safety, size is only incremented after the initialization succeeds
+    for (int64_t& i = p->size_ = 0; i < size; ++i) {
+      new (write++) ObjectRef(std::move(*read++));
+    }
+    from->size_ = 0;
+    return p;
+  }
+
+  /*!
+   * \brief Constructs a container with n elements. Each element is a copy of val
+   * \param n The size of the container
+   * \param val The init value
+   * \return Ref-counted ArrayNode requested
+   */
+  static ObjectPtr<ArrayNode> CreateRepeated(int64_t n, const ObjectRef& val) {
+    ObjectPtr<ArrayNode> p = ArrayNode::Empty(n);
+    ObjectRef* itr = p->MutableBegin();
+    for (int64_t& i = p->size_ = 0; i < n; ++i) {
+      new (itr++) ObjectRef(val);
+    }
+    return p;
+  }
+
+  static constexpr const uint32_t _type_index = TypeIndex::kRuntimeArray;
+  static constexpr const char* _type_key = "Array";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ArrayNode, Object);
+
+ private:
+  /*! \return Size of initialized memory, used by InplaceArrayBase. */
+  size_t GetSize() const { return this->size_; }
+
+  /*! \return begin mutable iterator */
+  ObjectRef* MutableBegin() const {
+    return static_cast<ObjectRef*>(InplaceArrayBase::AddressOf(0));
+  }
+
+  /*! \return end mutable iterator */
+  ObjectRef* MutableEnd() const { return MutableBegin() + size_; }
+
+  /*!
+   * \brief Create an ArrayNode with the given capacity.
+   * \param n Required capacity
+   * \return Ref-counted ArrayNode requested
+   */
+  static ObjectPtr<ArrayNode> Empty(int64_t n = kInitSize) {
+    ICHECK_GE(n, 0);
+    ObjectPtr<ArrayNode> p = make_inplace_array_object<ArrayNode, ObjectRef>(n);
+    p->capacity_ = n;
+    p->size_ = 0;
+    return p;
+  }
+
+  /*!
+   * \brief Inplace-initialize the elements starting idx from [first, last)
+   * \param idx The starting point
+   * \param first Begin of iterator
+   * \param last End of iterator
+   * \tparam IterType The type of iterator
+   * \return Self
+   */
+  template <typename IterType>
+  ArrayNode* InitRange(int64_t idx, IterType first, IterType last) {
+    ObjectRef* itr = MutableBegin() + idx;
+    for (; first != last; ++first) {
+      ObjectRef ref = *first;
+      new (itr++) ObjectRef(std::move(ref));
+    }
+    return this;
+  }
+
+  /*!
+   * \brief Move elements from right to left, requires src_begin > dst
+   * \param dst Destination
+   * \param src_begin The start point of copy (inclusive)
+   * \param src_end The end point of copy (exclusive)
+   * \return Self
+   */
+  ArrayNode* MoveElementsLeft(int64_t dst, int64_t src_begin, int64_t src_end) {
+    ObjectRef* from = MutableBegin() + src_begin;
+    ObjectRef* to = MutableBegin() + dst;
+    while (src_begin++ != src_end) {
+      *to++ = std::move(*from++);
+    }
+    return this;
+  }
+
+  /*!
+   * \brief Move elements from left to right, requires src_begin < dst
+   * \param dst Destination
+   * \param src_begin The start point of move (inclusive)
+   * \param src_end The end point of move (exclusive)
+   * \return Self
+   */
+  ArrayNode* MoveElementsRight(int64_t dst, int64_t src_begin, int64_t src_end) {
+    ObjectRef* from = MutableBegin() + src_end;
+    ObjectRef* to = MutableBegin() + (src_end - src_begin + dst);
+    while (src_begin++ != src_end) {
+      *--to = std::move(*--from);
+    }
+    return this;
+  }
+
+  /*!
+   * \brief Enlarges the size of the array
+   * \param delta Size enlarged, should be positive
+   * \param val Default value
+   * \return Self
+   */
+  ArrayNode* EnlargeBy(int64_t delta, const ObjectRef& val = ObjectRef(nullptr)) {
+    ObjectRef* itr = MutableEnd();
+    while (delta-- > 0) {
+      new (itr++) ObjectRef(val);
+      ++size_;
+    }
+    return this;
+  }
+
+  /*!
+   * \brief Shrinks the size of the array
+   * \param delta Size shrinked, should be positive
+   * \return Self
+   */
+  ArrayNode* ShrinkBy(int64_t delta) {
+    ObjectRef* itr = MutableEnd();
+    while (delta-- > 0) {
+      (--itr)->ObjectRef::~ObjectRef();
+      --size_;
+    }
+    return this;
+  }
+
+  /*! \brief Number of elements used */
+  int64_t size_;
+
+  /*! \brief Number of elements allocated */
+  int64_t capacity_;
+
+  /*! \brief Initial size of ArrayNode */
+  static constexpr int64_t kInitSize = 4;
+
+  /*! \brief Expansion factor of the Array */
+  static constexpr int64_t kIncFactor = 2;
+
+  // CRTP parent class
+  friend InplaceArrayBase<ArrayNode, ObjectRef>;
+
+  // Reference class
+  template <typename, typename>
+  friend class Array;
+
+  // To specialize make_object<ArrayNode>
+  friend ObjectPtr<ArrayNode> make_object<>();
+};
+
+/*! \brief Helper struct for type-checking
+ *
+ * is_valid_iterator<T,IterType>::value will be true if IterType can
+ * be dereferenced into a type that can be stored in an Array<T>, and
+ * false otherwise.
+ */
+template <typename T, typename IterType>
+struct is_valid_iterator
+    : std::bool_constant<std::is_base_of_v<
+          T, std::remove_cv_t<std::remove_reference_t<decltype(*std::declval<IterType>())>>>> {};
+
+template <typename T, typename IterType>
+struct is_valid_iterator<Optional<T>, IterType> : is_valid_iterator<T, IterType> {};
+
+template <typename T, typename IterType>
+inline constexpr bool is_valid_iterator_v = is_valid_iterator<T, IterType>::value;
+
+/*!
+ * \brief Array, container representing a contiguous sequence of ObjectRefs.
+ *
+ *  Array implements in-place copy-on-write semantics.
+ *
+ * As in typical copy-on-write, a method which would typically mutate the array
+ * instead opaquely copies the underlying container, and then acts on its copy.
+ *
+ * If the array has reference count equal to one, we directly update the
+ * container in place without copying. This is optimization is sound because
+ * when the reference count is equal to one this reference is guranteed to be
+ * the sole pointer to the container.
+ *
+ *
+ * operator[] only provides const access, use Set to mutate the content.
+ * \tparam T The content ObjectRef type.
+ */
+template <typename T,
+          typename = typename std::enable_if<std::is_base_of<ObjectRef, T>::value>::type>
+class Array : public ObjectRef {
+ public:
+  using value_type = T;
+  // constructors
+  /*!
+   * \brief default constructor
+   */
+  Array() { data_ = ArrayNode::Empty(); }
+
+  /*!
+   * \brief move constructor
+   * \param other source
+   */
+  Array(Array<T>&& other) : ObjectRef() {  // NOLINT(*)
+    data_ = std::move(other.data_);
+  }
+
+  /*!
+   * \brief copy constructor
+   * \param other source
+   */
+  Array(const Array<T>& other) : ObjectRef() {  // NOLINT(*)
+    data_ = other.data_;
+  }
+
+  /*!
+   * \brief constructor from pointer
+   * \param n the container pointer
+   */
+  explicit Array(ObjectPtr<Object> n) : ObjectRef(n) {}
+
+  /*!
+   * \brief Constructor from iterator
+   * \param first begin of iterator
+   * \param last end of iterator
+   * \tparam IterType The type of iterator
+   */
+  template <typename IterType>
+  Array(IterType first, IterType last) {
+    static_assert(is_valid_iterator_v<T, IterType>,
+                  "IterType cannot be inserted into a tvm::Array<T>");
+    Assign(first, last);
+  }
+
+  /*!
+   * \brief constructor from initializer list
+   * \param init The initializer list
+   */
+  Array(std::initializer_list<T> init) {  // NOLINT(*)
+    Assign(init.begin(), init.end());
+  }
+
+  /*!
+   * \brief constructor from vector
+   * \param init The vector
+   */
+  Array(const std::vector<T>& init) {  // NOLINT(*)
+    Assign(init.begin(), init.end());
+  }
+
+  /*!
+   * \brief Constructs a container with n elements. Each element is a copy of val
+   * \param n The size of the container
+   * \param val The init value
+   */
+  explicit Array(const size_t n, const T& val) { data_ = ArrayNode::CreateRepeated(n, val); }
+
+  /*!
+   * \brief move assign operator
+   * \param other The source of assignment
+   * \return reference to self.
+   */
+  Array<T>& operator=(Array<T>&& other) {
+    data_ = std::move(other.data_);
+    return *this;
+  }
+
+  /*!
+   * \brief copy assign operator
+   * \param other The source of assignment
+   * \return reference to self.
+   */
+  Array<T>& operator=(const Array<T>& other) {
+    data_ = other.data_;
+    return *this;
+  }
+
+ public:
+  // iterators
+  struct ValueConverter {
+    using ResultType = T;
+    static T convert(const ObjectRef& n) { return DowncastNoCheck<T>(n); }
+  };
+
+  using iterator = IterAdapter<ValueConverter, const ObjectRef*>;
+  using reverse_iterator = ReverseIterAdapter<ValueConverter, const ObjectRef*>;
+
+  /*! \return begin iterator */
+  iterator begin() const { return iterator(GetArrayNode()->begin()); }
+
+  /*! \return end iterator */
+  iterator end() const { return iterator(GetArrayNode()->end()); }
+
+  /*! \return rbegin iterator */
+  reverse_iterator rbegin() const {
+    // ArrayNode::end() is never nullptr
+    return reverse_iterator(GetArrayNode()->end() - 1);
+  }
+
+  /*! \return rend iterator */
+  reverse_iterator rend() const {
+    // ArrayNode::begin() is never nullptr
+    return reverse_iterator(GetArrayNode()->begin() - 1);
+  }
+
+ public:
+  // const methods in std::vector
+  /*!
+   * \brief Immutably read i-th element from array.
+   * \param i The index
+   * \return the i-th element.
+   */
+  const T operator[](int64_t i) const {
+    ArrayNode* p = GetArrayNode();
+    ICHECK(p != nullptr) << "ValueError: cannot index a null array";
+    ICHECK(0 <= i && i < p->size_)
+        << "IndexError: indexing " << i << " on an array of size " << p->size_;
+    return DowncastNoCheck<T>(*(p->begin() + i));
+  }
+
+  /*! \return The size of the array */
+  size_t size() const {
+    ArrayNode* p = GetArrayNode();
+    return p == nullptr ? 0 : GetArrayNode()->size_;
+  }
+
+  /*! \return The capacity of the array */
+  size_t capacity() const {
+    ArrayNode* p = GetArrayNode();
+    return p == nullptr ? 0 : GetArrayNode()->capacity_;
+  }
+
+  /*! \return Whether array is empty */
+  bool empty() const { return size() == 0; }
+
+  /*! \return The first element of the array */
+  const T front() const {
+    ArrayNode* p = GetArrayNode();
+    ICHECK(p != nullptr) << "ValueError: cannot index a null array";
+    ICHECK_GT(p->size_, 0) << "IndexError: cannot index an empty array";
+    return DowncastNoCheck<T>(*(p->begin()));
+  }
+
+  /*! \return The last element of the array */
+  const T back() const {
+    ArrayNode* p = GetArrayNode();
+    ICHECK(p != nullptr) << "ValueError: cannot index a null array";
+    ICHECK_GT(p->size_, 0) << "IndexError: cannot index an empty array";
+    return DowncastNoCheck<T>(*(p->end() - 1));
+  }
+
+ public:
+  // mutation in std::vector, implements copy-on-write
+
+  /*!
+   * \brief push a new item to the back of the list
+   * \param item The item to be pushed.
+   */
+  void push_back(const T& item) {
+    ArrayNode* p = CopyOnWrite(1);
+    p->EmplaceInit(p->size_++, item);
+  }
+
+  /*!
+   * \brief Insert an element into the given position
+   * \param position An iterator pointing to the insertion point
+   * \param val The element to insert
+   */
+  void insert(iterator position, const T& val) {
+    ICHECK(data_ != nullptr) << "ValueError: cannot insert a null array";
+    int64_t idx = std::distance(begin(), position);
+    int64_t size = GetArrayNode()->size_;
+    auto addr = CopyOnWrite(1)                               //
+                    ->EnlargeBy(1)                           //
+                    ->MoveElementsRight(idx + 1, idx, size)  //
+                    ->MutableBegin();
+    new (addr + idx) ObjectRef(val);
+  }
+
+  /*!
+   * \brief Insert a range of elements into the given position
+   * \param position An iterator pointing to the insertion point
+   * \param first The begin iterator of the range
+   * \param last The end iterator of the range
+   */
+  template <typename IterType>
+  void insert(iterator position, IterType first, IterType last) {
+    static_assert(is_valid_iterator_v<T, IterType>,
+                  "IterType cannot be inserted into a tvm::Array<T>");
+
+    if (first == last) {
+      return;
+    }
+    ICHECK(data_ != nullptr) << "ValueError: cannot insert a null array";
+    int64_t idx = std::distance(begin(), position);
+    int64_t size = GetArrayNode()->size_;
+    int64_t numel = std::distance(first, last);
+    CopyOnWrite(numel)
+        ->EnlargeBy(numel)
+        ->MoveElementsRight(idx + numel, idx, size)
+        ->InitRange(idx, first, last);
+  }
+
+  /*! \brief Remove the last item of the list */
+  void pop_back() {
+    ICHECK(data_ != nullptr) << "ValueError: cannot pop_back because array is null";
+    int64_t size = GetArrayNode()->size_;
+    ICHECK_GT(size, 0) << "ValueError: cannot pop_back because array is empty";
+    CopyOnWrite()->ShrinkBy(1);
+  }
+
+  /*!
+   * \brief Erase an element on the given position
+   * \param position An iterator pointing to the element to be erased
+   */
+  void erase(iterator position) {
+    ICHECK(data_ != nullptr) << "ValueError: cannot erase a null array";
+    int64_t st = std::distance(begin(), position);
+    int64_t size = GetArrayNode()->size_;
+    ICHECK(0 <= st && st < size) << "ValueError: cannot erase at index " << st
+                                 << ", because Array size is " << size;
+    CopyOnWrite()                             //
+        ->MoveElementsLeft(st, st + 1, size)  //
+        ->ShrinkBy(1);
+  }
+
+  /*!
+   * \brief Erase a given range of elements
+   * \param first The begin iterator of the range
+   * \param last The end iterator of the range
+   */
+  void erase(iterator first, iterator last) {
+    if (first == last) {
+      return;
+    }
+    ICHECK(data_ != nullptr) << "ValueError: cannot erase a null array";
+    int64_t size = GetArrayNode()->size_;
+    int64_t st = std::distance(begin(), first);
+    int64_t ed = std::distance(begin(), last);
+    ICHECK_LT(st, ed) << "ValueError: cannot erase array in range [" << st << ", " << ed << ")";
+    ICHECK(0 <= st && st <= size && 0 <= ed && ed <= size)
+        << "ValueError: cannot erase array in range [" << st << ", " << ed << ")"
+        << ", because array size is " << size;
+    CopyOnWrite()                         //
+        ->MoveElementsLeft(st, ed, size)  //
+        ->ShrinkBy(ed - st);
+  }
+
+  /*!
+   * \brief Resize the array.
+   * \param n The new size.
+   */
+  void resize(int64_t n) {
+    ICHECK_GE(n, 0) << "ValueError: cannot resize an Array to negative size";
+    if (data_ == nullptr) {
+      SwitchContainer(n);
+      return;
+    }
+    int64_t size = GetArrayNode()->size_;
+    if (size < n) {
+      CopyOnWrite(n - size)->EnlargeBy(n - size);
+    } else if (size > n) {
+      CopyOnWrite()->ShrinkBy(size - n);
+    }
+  }
+
+  /*!
+   * \brief Make sure the list has the capacity of at least n
+   * \param n lower bound of the capacity
+   */
+  void reserve(int64_t n) {
+    if (data_ == nullptr || n > GetArrayNode()->capacity_) {
+      SwitchContainer(n);
+    }
+  }
+
+  /*! \brief Release reference to all the elements */
+  void clear() {
+    if (data_ != nullptr) {
+      ArrayNode* p = CopyOnWrite();
+      p->clear();
+    }
+  }
+
+ public:
+  // Array's own methods
+
+  /*!
+   * \brief set i-th element of the array.
+   * \param i The index
+   * \param value The value to be setted.
+   */
+  void Set(int64_t i, T value) {
+    ArrayNode* p = this->CopyOnWrite();
+    ICHECK(0 <= i && i < p->size_)
+        << "IndexError: indexing " << i << " on an array of size " << p->size_;
+    *(p->MutableBegin() + i) = std::move(value);
+  }
+
+  /*! \return The underlying ArrayNode */
+  ArrayNode* GetArrayNode() const { return static_cast<ArrayNode*>(data_.get()); }
+
+  /*!
+   * \brief Helper function to apply a map function onto the array.
+   *
+   * \param fmap The transformation function T -> U.
+   *
+   * \tparam F The type of the mutation function.
+   *
+   * \tparam U The type of the returned array, inferred from the
+   * return type of F.  If overridden by the user, must be something
+   * that is convertible from the return type of F.
+   *
+   * \note This function performs copy on write optimization.  If
+   * `fmap` returns an object of type `T`, and all elements of the
+   * array are mapped to themselves, then the returned array will be
+   * the same as the original, and reference counts of the elements in
+   * the array will not be incremented.
+   *
+   * \return The transformed array.
+   */
+  template <typename F, typename U = std::invoke_result_t<F, T>>
+  Array<U> Map(F fmap) const {
+    return Array<U>(MapHelper(data_, fmap));
+  }
+
+  /*!
+   * \brief Helper function to apply fmutate to mutate an array.
+   * \param fmutate The transformation function T -> T.
+   * \tparam F the type of the mutation function.
+   * \note This function performs copy on write optimization.
+   */
+  template <typename F, typename = std::enable_if_t<std::is_same_v<T, std::invoke_result_t<F, T>>>>
+  void MutateByApply(F fmutate) {
+    data_ = MapHelper(std::move(data_), fmutate);
+  }
+
+  /*!
+   * \brief reset the array to content from iterator.
+   * \param first begin of iterator
+   * \param last end of iterator
+   * \tparam IterType The type of iterator
+   */
+  template <typename IterType>
+  void Assign(IterType first, IterType last) {
+    int64_t cap = std::distance(first, last);
+    ICHECK_GE(cap, 0) << "ValueError: cannot construct an Array of negative size";
+    ArrayNode* p = GetArrayNode();
+    if (p != nullptr && data_.unique() && p->capacity_ >= cap) {
+      // do not have to make new space
+      p->clear();
+    } else {
+      // create new space
+      data_ = ArrayNode::Empty(cap);
+      p = GetArrayNode();
+    }
+    // To ensure exception safety, size is only incremented after the initialization succeeds
+    ObjectRef* itr = p->MutableBegin();
+    for (int64_t& i = p->size_ = 0; i < cap; ++i, ++first, ++itr) {
+      new (itr) ObjectRef(*first);
+    }
+  }
+
+  /*!
+   * \brief Copy on write semantics
+   *  Do nothing if current handle is the unique copy of the array.
+   *  Otherwise make a new copy of the array to ensure the current handle
+   *  hold a unique copy.
+   *
+   * \return Handle to the internal node container(which ganrantees to be unique)
+   */
+  ArrayNode* CopyOnWrite() {
+    if (data_ == nullptr) {
+      return SwitchContainer(ArrayNode::kInitSize);
+    }
+    if (!data_.unique()) {
+      return SwitchContainer(capacity());
+    }
+    return static_cast<ArrayNode*>(data_.get());
+  }
+
+  /*! \brief specify container node */
+  using ContainerType = ArrayNode;
+
+ private:
+  /*!
+   * \brief Implement copy-on-write semantics, and ensures capacity is enough for extra elements.
+   * \param reserve_extra Number of extra slots needed
+   * \return ArrayNode pointer to the unique copy
+   */
+  ArrayNode* CopyOnWrite(int64_t reserve_extra) {
+    ArrayNode* p = GetArrayNode();
+    if (p == nullptr) {
+      // necessary to get around the constexpr address issue before c++17
+      const int64_t kInitSize = ArrayNode::kInitSize;
+      return SwitchContainer(std::max(kInitSize, reserve_extra));
+    }
+    if (p->capacity_ >= p->size_ + reserve_extra) {
+      return CopyOnWrite();
+    }
+    int64_t cap = p->capacity_ * ArrayNode::kIncFactor;
+    cap = std::max(cap, p->size_ + reserve_extra);
+    return SwitchContainer(cap);
+  }
+
+  /*!
+   * \brief Move or copy the ArrayNode to new address with the given capacity
+   * \param capacity The capacity requirement of the new address
+   */
+  ArrayNode* SwitchContainer(int64_t capacity) {
+    if (data_ == nullptr) {
+      data_ = ArrayNode::Empty(capacity);
+    } else if (data_.unique()) {
+      data_ = ArrayNode::MoveFrom(capacity, GetArrayNode());
+    } else {
+      data_ = ArrayNode::CopyFrom(capacity, GetArrayNode());
+    }
+    return static_cast<ArrayNode*>(data_.get());
+  }
+
+  /*! \brief Helper method for mutate/map
+   *
+   * A helper function used internally by both `Array::Map` and
+   * `Array::MutateInPlace`.  Given an array of data, apply the
+   * mapping function to each element, returning the collected array.
+   * Applies both mutate-in-place and copy-on-write optimizations, if
+   * possible.
+   *
+   * \param data A pointer to the ArrayNode containing input data.
+   * Passed by value to allow for mutate-in-place optimizations.
+   *
+   * \param fmap The mapping function
+   *
+   * \tparam F The type of the mutation function.
+   *
+   * \tparam U The output type of the mutation function.  Inferred
+   * from the callable type given.  Must inherit from ObjectRef.
+   *
+   * \return The mapped array.  Depending on whether mutate-in-place
+   * or copy-on-write optimizations were applicable, may be the same
+   * underlying array as the `data` parameter.
+   */
+  template <typename F, typename U = std::invoke_result_t<F, T>>
+  static ObjectPtr<Object> MapHelper(ObjectPtr<Object> data, F fmap) {
+    if (data == nullptr) {
+      return nullptr;
+    }
+
+    ICHECK(data->IsInstance<ArrayNode>());
+
+    constexpr bool is_same_output_type = std::is_same_v<T, U>;
+
+    if constexpr (is_same_output_type) {
+      if (data.unique()) {
+        // Mutate-in-place path.  Only allowed if the output type U is
+        // the same as type T, we have a mutable this*, and there are
+        // no other shared copies of the array.
+        auto arr = static_cast<ArrayNode*>(data.get());
+        for (auto it = arr->MutableBegin(); it != arr->MutableEnd(); it++) {
+          T mapped = fmap(DowncastNoCheck<T>(std::move(*it)));
+          *it = std::move(mapped);
+        }
+        return data;
+      }
+    }
+
+    constexpr bool compatible_types = is_valid_iterator_v<T, U*> || is_valid_iterator_v<U, T*>;
+
+    ObjectPtr<ArrayNode> output = nullptr;
+    auto arr = static_cast<ArrayNode*>(data.get());
+
+    auto it = arr->begin();
+    if constexpr (compatible_types) {
+      // Copy-on-write path, if the output Array<U> might be
+      // represented by the same underlying array as the existing
+      // Array<T>.  Typically, this is for functions that map `T` to
+      // `T`, but can also apply to functions that map `T` to
+      // `Optional<T>`, or that map `T` to a subclass or superclass of
+      // `T`.
+      bool all_identical = true;
+      for (; it != arr->end(); it++) {
+        U mapped = fmap(DowncastNoCheck<T>(*it));
+        if (!mapped.same_as(*it)) {
+          // At least one mapped element is different than the
+          // original.  Therefore, prepare the output array,
+          // consisting of any previous elements that had mapped to
+          // themselves (if any), and the element that didn't map to
+          // itself.
+          all_identical = false;
+          output = ArrayNode::CreateRepeated(arr->size(), U());
+          output->InitRange(0, arr->begin(), it);
+          output->SetItem(it - arr->begin(), std::move(mapped));
+          it++;
+          break;
+        }
+      }
+      if (all_identical) {
+        return data;
+      }
+    } else {
+      // Path for incompatible types.  The constexpr check for
+      // compatible types isn't strictly necessary, as the first
+      // mapped.same_as(*it) would return false, but we might as well
+      // avoid it altogether.
+      output = ArrayNode::CreateRepeated(arr->size(), U());
+    }
+
+    // Normal path for incompatible types, or post-copy path for
+    // copy-on-write instances.
+    //
+    // If the types are incompatible, then at this point `output` is
+    // empty, and `it` points to the first element of the input.
+    //
+    // If the types were compatible, then at this point `output`
+    // contains zero or more elements that mapped to themselves
+    // followed by the first element that does not map to itself, and
+    // `it` points to the element just after the first element that
+    // does not map to itself.  Because at least one element has been
+    // changed, we no longer have the opportunity to avoid a copy, so
+    // we don't need to check the result.
+    //
+    // In both cases, `it` points to the next element to be processed,
+    // so we can either start or resume the iteration from that point,
+    // with no further checks on the result.
+    for (; it != arr->end(); it++) {
+      U mapped = fmap(DowncastNoCheck<T>(*it));
+      output->SetItem(it - arr->begin(), std::move(mapped));
+    }
+
+    return output;
+  }
+};
+
+/*!
+ * \brief Concat two Arrays.
+ * \param lhs first Array to be concatenated.
+ * \param rhs second Array to be concatenated.
+ * \return The concatenated Array. Original Arrays are kept unchanged.
+ */
+template <typename T,
+          typename = typename std::enable_if<std::is_base_of<ObjectRef, T>::value>::type>
+inline Array<T> Concat(Array<T> lhs, const Array<T>& rhs) {
+  for (const auto& x : rhs) {
+    lhs.push_back(x);
+  }
+  return std::move(lhs);
+}
+
+// Specialize make_object<ArrayNode> to make sure it is correct.
+template <>
+inline ObjectPtr<ArrayNode> make_object() {
+  return ArrayNode::Empty();
+}
+
+}  // namespace runtime
+
+// expose the functions to the root namespace.
+using runtime::Array;
+using runtime::ArrayNode;
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_CONTAINER_ARRAY_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/container/base.h b/darknet_drp_ros/include/tvm/runtime/container/base.h
new file mode 100644
index 0000000..262041e
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/container/base.h
@@ -0,0 +1,302 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/container/base.h
+ * \brief Base utilities for common POD(plain old data) container types.
+ */
+#ifndef TVM_RUNTIME_CONTAINER_BASE_H_
+#define TVM_RUNTIME_CONTAINER_BASE_H_
+
+#include <dmlc/logging.h>
+#include <tvm/runtime/logging.h>
+#include <tvm/runtime/memory.h>
+#include <tvm/runtime/object.h>
+
+#include <algorithm>
+#include <initializer_list>
+#include <utility>
+
+namespace tvm {
+namespace runtime {
+
+/*! \brief String-aware ObjectRef equal functor */
+struct ObjectHash {
+  /*!
+   * \brief Calculate the hash code of an ObjectRef
+   * \param a The given ObjectRef
+   * \return Hash code of a, string hash for strings and pointer address otherwise.
+   */
+  size_t operator()(const ObjectRef& a) const;
+};
+
+/*! \brief String-aware ObjectRef hash functor */
+struct ObjectEqual {
+  /*!
+   * \brief Check if the two ObjectRef are equal
+   * \param a One ObjectRef
+   * \param b The other ObjectRef
+   * \return String equality if both are strings, pointer address equality otherwise.
+   */
+  bool operator()(const ObjectRef& a, const ObjectRef& b) const;
+};
+
+/*!
+ * \brief Base template for classes with array like memory layout.
+ *
+ *        It provides general methods to access the memory. The memory
+ *        layout is ArrayType + [ElemType]. The alignment of ArrayType
+ *        and ElemType is handled by the memory allocator.
+ *
+ * \tparam ArrayType The array header type, contains object specific metadata.
+ * \tparam ElemType The type of objects stored in the array right after
+ * ArrayType.
+ *
+ * \code
+ * // Example usage of the template to define a simple array wrapper
+ * class ArrayObj : public InplaceArrayBase<ArrayObj, Elem> {
+ * public:
+ *  // Wrap EmplaceInit to initialize the elements
+ *  template <typename Iterator>
+ *  void Init(Iterator begin, Iterator end) {
+ *   size_t num_elems = std::distance(begin, end);
+ *   auto it = begin;
+ *   this->size = 0;
+ *   for (size_t i = 0; i < num_elems; ++i) {
+ *     InplaceArrayBase::EmplaceInit(i, *it++);
+ *     this->size++;
+ *   }
+ *  }
+ * }
+ *
+ * void test_function() {
+ *   vector<Elem> fields;
+ *   auto ptr = make_inplace_array_object<ArrayObj, Elem>(fields.size());
+ *   ptr->Init(fields.begin(), fields.end());
+ *
+ *   // Access the 0th element in the array.
+ *   assert(ptr->operator[](0) == fields[0]);
+ * }
+ *
+ * \endcode
+ */
+template <typename ArrayType, typename ElemType>
+class InplaceArrayBase {
+ public:
+  /*!
+   * \brief Access element at index
+   * \param idx The index of the element.
+   * \return Const reference to ElemType at the index.
+   */
+  const ElemType& operator[](size_t idx) const {
+    size_t size = Self()->GetSize();
+    ICHECK_LT(idx, size) << "Index " << idx << " out of bounds " << size << "\n";
+    return *(reinterpret_cast<ElemType*>(AddressOf(idx)));
+  }
+
+  /*!
+   * \brief Access element at index
+   * \param idx The index of the element.
+   * \return Reference to ElemType at the index.
+   */
+  ElemType& operator[](size_t idx) {
+    size_t size = Self()->GetSize();
+    ICHECK_LT(idx, size) << "Index " << idx << " out of bounds " << size << "\n";
+    return *(reinterpret_cast<ElemType*>(AddressOf(idx)));
+  }
+
+  /*!
+   * \brief Destroy the Inplace Array Base object
+   */
+  ~InplaceArrayBase() {
+    if (!(std::is_standard_layout<ElemType>::value && std::is_trivial<ElemType>::value)) {
+      size_t size = Self()->GetSize();
+      for (size_t i = 0; i < size; ++i) {
+        ElemType* fp = reinterpret_cast<ElemType*>(AddressOf(i));
+        fp->ElemType::~ElemType();
+      }
+    }
+  }
+
+ protected:
+  /*!
+   * \brief Construct a value in place with the arguments.
+   *
+   * \tparam Args Type parameters of the arguments.
+   * \param idx Index of the element.
+   * \param args Arguments to construct the new value.
+   *
+   * \note Please make sure ArrayType::GetSize returns 0 before first call of
+   * EmplaceInit, and increment GetSize by 1 each time EmplaceInit succeeds.
+   */
+  template <typename... Args>
+  void EmplaceInit(size_t idx, Args&&... args) {
+    void* field_ptr = AddressOf(idx);
+    new (field_ptr) ElemType(std::forward<Args>(args)...);
+  }
+
+  /*!
+   * \brief Return the self object for the array.
+   *
+   * \return Pointer to ArrayType.
+   */
+  inline ArrayType* Self() const {
+    return static_cast<ArrayType*>(const_cast<InplaceArrayBase*>(this));
+  }
+
+  /*!
+   * \brief Return the raw pointer to the element at idx.
+   *
+   * \param idx The index of the element.
+   * \return Raw pointer to the element.
+   */
+  void* AddressOf(size_t idx) const {
+    static_assert(
+        alignof(ArrayType) % alignof(ElemType) == 0 && sizeof(ArrayType) % alignof(ElemType) == 0,
+        "The size and alignment of ArrayType should respect "
+        "ElemType's alignment.");
+
+    size_t kDataStart = sizeof(ArrayType);
+    ArrayType* self = Self();
+    char* data_start = reinterpret_cast<char*>(self) + kDataStart;
+    return data_start + idx * sizeof(ElemType);
+  }
+};
+
+/*!
+ * \brief iterator adapter that adapts TIter to return another type.
+ * \tparam Converter a struct that contains converting function
+ * \tparam TIter the content iterator type.
+ */
+template <typename Converter, typename TIter>
+class IterAdapter {
+ public:
+  using difference_type = typename std::iterator_traits<TIter>::difference_type;
+  using value_type = typename Converter::ResultType;
+  using pointer = typename Converter::ResultType*;
+  using reference = typename Converter::ResultType&;
+  using iterator_category = typename std::iterator_traits<TIter>::iterator_category;
+
+  explicit IterAdapter(TIter iter) : iter_(iter) {}
+  IterAdapter& operator++() {
+    ++iter_;
+    return *this;
+  }
+  IterAdapter& operator--() {
+    --iter_;
+    return *this;
+  }
+  IterAdapter operator++(int) {
+    IterAdapter copy = *this;
+    ++iter_;
+    return copy;
+  }
+  IterAdapter operator--(int) {
+    IterAdapter copy = *this;
+    --iter_;
+    return copy;
+  }
+
+  IterAdapter operator+(difference_type offset) const { return IterAdapter(iter_ + offset); }
+
+  IterAdapter operator-(difference_type offset) const { return IterAdapter(iter_ - offset); }
+
+  template <typename T = IterAdapter>
+  typename std::enable_if<std::is_same<iterator_category, std::random_access_iterator_tag>::value,
+                          typename T::difference_type>::type inline
+  operator-(const IterAdapter& rhs) const {
+    return iter_ - rhs.iter_;
+  }
+
+  bool operator==(IterAdapter other) const { return iter_ == other.iter_; }
+  bool operator!=(IterAdapter other) const { return !(*this == other); }
+  const value_type operator*() const { return Converter::convert(*iter_); }
+
+ private:
+  TIter iter_;
+};
+
+/*!
+ * \brief iterator adapter that adapts TIter to return another type.
+ * \tparam Converter a struct that contains converting function
+ * \tparam TIter the content iterator type.
+ */
+template <typename Converter, typename TIter>
+class ReverseIterAdapter {
+ public:
+  using difference_type = typename std::iterator_traits<TIter>::difference_type;
+  using value_type = typename Converter::ResultType;
+  using pointer = typename Converter::ResultType*;
+  using reference = typename Converter::ResultType&;  // NOLINT(*)
+  using iterator_category = typename std::iterator_traits<TIter>::iterator_category;
+
+  explicit ReverseIterAdapter(TIter iter) : iter_(iter) {}
+  ReverseIterAdapter& operator++() {
+    --iter_;
+    return *this;
+  }
+  ReverseIterAdapter& operator--() {
+    ++iter_;
+    return *this;
+  }
+  ReverseIterAdapter operator++(int) {
+    ReverseIterAdapter copy = *this;
+    --iter_;
+    return copy;
+  }
+  ReverseIterAdapter operator--(int) {
+    ReverseIterAdapter copy = *this;
+    ++iter_;
+    return copy;
+  }
+  ReverseIterAdapter operator+(difference_type offset) const {
+    return ReverseIterAdapter(iter_ - offset);
+  }
+
+  template <typename T = ReverseIterAdapter>
+  typename std::enable_if<std::is_same<iterator_category, std::random_access_iterator_tag>::value,
+                          typename T::difference_type>::type inline
+  operator-(const ReverseIterAdapter& rhs) const {
+    return rhs.iter_ - iter_;
+  }
+
+  bool operator==(ReverseIterAdapter other) const { return iter_ == other.iter_; }
+  bool operator!=(ReverseIterAdapter other) const { return !(*this == other); }
+  const value_type operator*() const { return Converter::convert(*iter_); }
+
+ private:
+  TIter iter_;
+};
+
+}  // namespace runtime
+
+// expose the functions to the root namespace.
+using runtime::Downcast;
+using runtime::IterAdapter;
+using runtime::make_object;
+using runtime::Object;
+using runtime::ObjectEqual;
+using runtime::ObjectHash;
+using runtime::ObjectPtr;
+using runtime::ObjectPtrEqual;
+using runtime::ObjectPtrHash;
+using runtime::ObjectRef;
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_CONTAINER_BASE_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/container/closure.h b/darknet_drp_ros/include/tvm/runtime/container/closure.h
new file mode 100644
index 0000000..a280d1a
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/container/closure.h
@@ -0,0 +1,52 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/container/closure.h
+ * \brief Runtime Closure container types.
+ */
+#ifndef TVM_RUNTIME_CONTAINER_CLOSURE_H_
+#define TVM_RUNTIME_CONTAINER_CLOSURE_H_
+
+#include "./base.h"
+
+namespace tvm {
+namespace runtime {
+
+/*!
+ * \brief An object representing a closure. This object is used by both the
+ * Relay VM and interpreter.
+ */
+class ClosureObj : public Object {
+ public:
+  static constexpr const uint32_t _type_index = TypeIndex::kRuntimeClosure;
+  static constexpr const char* _type_key = "runtime.Closure";
+  TVM_DECLARE_BASE_OBJECT_INFO(ClosureObj, Object);
+};
+
+/*! \brief reference to closure. */
+class Closure : public ObjectRef {
+ public:
+  TVM_DEFINE_OBJECT_REF_METHODS(Closure, ObjectRef, ClosureObj);
+};
+
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_CONTAINER_CLOSURE_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/container/map.h b/darknet_drp_ros/include/tvm/runtime/container/map.h
new file mode 100644
index 0000000..53c37cc
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/container/map.h
@@ -0,0 +1,1485 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/container/map.h
+ * \brief Runtime Map container types.
+ */
+#ifndef TVM_RUNTIME_CONTAINER_MAP_H_
+#define TVM_RUNTIME_CONTAINER_MAP_H_
+
+#ifndef USE_FALLBACK_STL_MAP
+#define USE_FALLBACK_STL_MAP 0
+#endif
+
+#include <algorithm>
+#include <unordered_map>
+#include <utility>
+
+#include "./base.h"
+#include "./optional.h"
+
+namespace tvm {
+namespace runtime {
+
+#if TVM_LOG_DEBUG
+#define TVM_MAP_FAIL_IF_CHANGED() \
+  ICHECK(state_marker == self->state_marker) << "Concurrent modification of the Map";
+#else
+#define TVM_MAP_FAIL_IF_CHANGED()
+#endif  // TVM_LOG_DEBUG
+
+#if (USE_FALLBACK_STL_MAP != 0)
+
+/*! \brief Shared content of all specializations of hash map */
+class MapNode : public Object {
+ public:
+  /*! \brief Type of the keys in the hash map */
+  using key_type = ObjectRef;
+  /*! \brief Type of the values in the hash map */
+  using mapped_type = ObjectRef;
+  /*! \brief Type of the actual underlying container */
+  using ContainerType = std::unordered_map<ObjectRef, ObjectRef, ObjectHash, ObjectEqual>;
+  /*! \brief Iterator class */
+  using iterator = ContainerType::iterator;
+  /*! \brief Iterator class */
+  using const_iterator = ContainerType::const_iterator;
+  /*! \brief Type of value stored in the hash map */
+  using KVType = ContainerType::value_type;
+
+  static_assert(std::is_standard_layout<KVType>::value, "KVType is not standard layout");
+  static_assert(sizeof(KVType) == 16 || sizeof(KVType) == 8, "sizeof(KVType) incorrect");
+
+  static constexpr const uint32_t _type_index = runtime::TypeIndex::kRuntimeMap;
+  static constexpr const char* _type_key = "Map";
+  TVM_DECLARE_FINAL_OBJECT_INFO(MapNode, Object);
+
+  /*!
+   * \brief Number of elements in the SmallMapNode
+   * \return The result
+   */
+  size_t size() const { return data_.size(); }
+  /*!
+   * \brief Count the number of times a key exists in the hash map
+   * \param key The indexing key
+   * \return The result, 0 or 1
+   */
+  size_t count(const key_type& key) const { return data_.count(key); }
+  /*!
+   * \brief Index value associated with a key, throw exception if the key does not exist
+   * \param key The indexing key
+   * \return The const reference to the value
+   */
+  const mapped_type& at(const key_type& key) const { return data_.at(key); }
+  /*!
+   * \brief Index value associated with a key, throw exception if the key does not exist
+   * \param key The indexing key
+   * \return The mutable reference to the value
+   */
+  mapped_type& at(const key_type& key) { return data_.at(key); }
+  /*! \return begin iterator */
+  iterator begin() { return data_.begin(); }
+  /*! \return const begin iterator */
+  const_iterator begin() const { return data_.begin(); }
+  /*! \return end iterator */
+  iterator end() { return data_.end(); }
+  /*! \return end iterator */
+  const_iterator end() const { return data_.end(); }
+  /*!
+   * \brief Index value associated with a key
+   * \param key The indexing key
+   * \return The iterator of the entry associated with the key, end iterator if not exists
+   */
+  const_iterator find(const key_type& key) const { return data_.find(key); }
+  /*!
+   * \brief Index value associated with a key
+   * \param key The indexing key
+   * \return The iterator of the entry associated with the key, end iterator if not exists
+   */
+  iterator find(const key_type& key) { return data_.find(key); }
+  /*!
+   * \brief Erase the entry associated with the iterator
+   * \param position The iterator
+   */
+  void erase(const iterator& position) { data_.erase(position); }
+  /*!
+   * \brief Erase the entry associated with the key, do nothing if not exists
+   * \param key The indexing key
+   */
+  void erase(const key_type& key) { data_.erase(key); }
+  /*!
+   * \brief Create an empty container
+   * \return The object created
+   */
+  static ObjectPtr<MapNode> Empty() { return make_object<MapNode>(); }
+
+ protected:
+  /*!
+   * \brief Create the map using contents from the given iterators.
+   * \param first Begin of iterator
+   * \param last End of iterator
+   * \tparam IterType The type of iterator
+   * \return ObjectPtr to the map created
+   */
+  template <typename IterType>
+  static ObjectPtr<Object> CreateFromRange(IterType first, IterType last) {
+    ObjectPtr<MapNode> p = make_object<MapNode>();
+    p->data_ = ContainerType(first, last);
+    return p;
+  }
+  /*!
+   * \brief InsertMaybeReHash an entry into the given hash map
+   * \param kv The entry to be inserted
+   * \param map The pointer to the map, can be changed if re-hashing happens
+   */
+  static void InsertMaybeReHash(const KVType& kv, ObjectPtr<Object>* map) {
+    MapNode* map_node = static_cast<MapNode*>(map->get());
+    map_node->data_[kv.first] = kv.second;
+  }
+  /*!
+   * \brief Create an empty container with elements copying from another MapNode
+   * \param from The source container
+   * \return The object created
+   */
+  static ObjectPtr<MapNode> CopyFrom(MapNode* from) {
+    ObjectPtr<MapNode> p = make_object<MapNode>();
+    p->data_ = ContainerType(from->data_.begin(), from->data_.end());
+    return p;
+  }
+  /*! \brief The real container storing data */
+  ContainerType data_;
+  template <typename, typename, typename, typename>
+  friend class Map;
+};
+
+#else
+
+/*! \brief Shared content of all specializations of hash map */
+class MapNode : public Object {
+ public:
+  /*! \brief Type of the keys in the hash map */
+  using key_type = ObjectRef;
+  /*! \brief Type of the values in the hash map */
+  using mapped_type = ObjectRef;
+  /*! \brief Type of value stored in the hash map */
+  using KVType = std::pair<ObjectRef, ObjectRef>;
+  /*! \brief Iterator class */
+  class iterator;
+
+  static_assert(std::is_standard_layout<KVType>::value, "KVType is not standard layout");
+  static_assert(sizeof(KVType) == 16 || sizeof(KVType) == 8, "sizeof(KVType) incorrect");
+
+  static constexpr const uint32_t _type_index = runtime::TypeIndex::kRuntimeMap;
+  static constexpr const char* _type_key = "Map";
+  TVM_DECLARE_FINAL_OBJECT_INFO(MapNode, Object);
+
+  /*!
+   * \brief Number of elements in the SmallMapNode
+   * \return The result
+   */
+  size_t size() const { return size_; }
+  /*!
+   * \brief Count the number of times a key exists in the hash map
+   * \param key The indexing key
+   * \return The result, 0 or 1
+   */
+  size_t count(const key_type& key) const;
+  /*!
+   * \brief Index value associated with a key, throw exception if the key does not exist
+   * \param key The indexing key
+   * \return The const reference to the value
+   */
+  const mapped_type& at(const key_type& key) const;
+  /*!
+   * \brief Index value associated with a key, throw exception if the key does not exist
+   * \param key The indexing key
+   * \return The mutable reference to the value
+   */
+  mapped_type& at(const key_type& key);
+  /*! \return begin iterator */
+  iterator begin() const;
+  /*! \return end iterator */
+  iterator end() const;
+  /*!
+   * \brief Index value associated with a key
+   * \param key The indexing key
+   * \return The iterator of the entry associated with the key, end iterator if not exists
+   */
+  iterator find(const key_type& key) const;
+  /*!
+   * \brief Erase the entry associated with the iterator
+   * \param position The iterator
+   */
+  void erase(const iterator& position);
+  /*!
+   * \brief Erase the entry associated with the key, do nothing if not exists
+   * \param key The indexing key
+   */
+  void erase(const key_type& key) { erase(find(key)); }
+
+  class iterator {
+   public:
+    using iterator_category = std::forward_iterator_tag;
+    using difference_type = int64_t;
+    using value_type = KVType;
+    using pointer = KVType*;
+    using reference = KVType&;
+/*! \brief Default constructor */
+#if TVM_LOG_DEBUG
+    iterator() : state_marker(0), index(0), self(nullptr) {}
+#else
+    iterator() : index(0), self(nullptr) {}
+#endif  // TVM_LOG_DEBUG
+    /*! \brief Compare iterators */
+    bool operator==(const iterator& other) const {
+      TVM_MAP_FAIL_IF_CHANGED()
+      return index == other.index && self == other.self;
+    }
+    /*! \brief Compare iterators */
+    bool operator!=(const iterator& other) const { return !(*this == other); }
+    /*! \brief De-reference iterators */
+    pointer operator->() const;
+    /*! \brief De-reference iterators */
+    reference operator*() const {
+      TVM_MAP_FAIL_IF_CHANGED()
+      return *((*this).operator->());
+    }
+    /*! \brief Prefix self increment, e.g. ++iter */
+    iterator& operator++();
+    /*! \brief Prefix self decrement, e.g. --iter */
+    iterator& operator--();
+    /*! \brief Suffix self increment */
+    iterator operator++(int) {
+      TVM_MAP_FAIL_IF_CHANGED()
+      iterator copy = *this;
+      ++(*this);
+      return copy;
+    }
+    /*! \brief Suffix self decrement */
+    iterator operator--(int) {
+      TVM_MAP_FAIL_IF_CHANGED()
+      iterator copy = *this;
+      --(*this);
+      return copy;
+    }
+
+   protected:
+#if TVM_LOG_DEBUG
+    uint64_t state_marker;
+    /*! \brief Construct by value */
+    iterator(uint64_t index, const MapNode* self)
+        : state_marker(self->state_marker), index(index), self(self) {}
+
+#else
+    iterator(uint64_t index, const MapNode* self) : index(index), self(self) {}
+#endif  // TVM_LOG_DEBUG
+    /*! \brief The position on the array */
+    uint64_t index;
+    /*! \brief The container it points to */
+    const MapNode* self;
+
+    friend class DenseMapNode;
+    friend class SmallMapNode;
+  };
+  /*!
+   * \brief Create an empty container
+   * \return The object created
+   */
+  static inline ObjectPtr<MapNode> Empty();
+
+ protected:
+#if TVM_LOG_DEBUG
+  uint64_t state_marker;
+#endif  // TVM_LOG_DEBUG
+  /*!
+   * \brief Create the map using contents from the given iterators.
+   * \param first Begin of iterator
+   * \param last End of iterator
+   * \tparam IterType The type of iterator
+   * \return ObjectPtr to the map created
+   */
+  template <typename IterType>
+  static inline ObjectPtr<Object> CreateFromRange(IterType first, IterType last);
+  /*!
+   * \brief InsertMaybeReHash an entry into the given hash map
+   * \param kv The entry to be inserted
+   * \param map The pointer to the map, can be changed if re-hashing happens
+   */
+  static inline void InsertMaybeReHash(const KVType& kv, ObjectPtr<Object>* map);
+  /*!
+   * \brief Create an empty container with elements copying from another SmallMapNode
+   * \param from The source container
+   * \return The object created
+   */
+  static inline ObjectPtr<MapNode> CopyFrom(MapNode* from);
+  /*! \brief number of slots minus 1 */
+  uint64_t slots_;
+  /*! \brief number of entries in the container */
+  uint64_t size_;
+  // Reference class
+  template <typename, typename, typename, typename>
+  friend class Map;
+};
+
+/*! \brief A specialization of small-sized hash map */
+class SmallMapNode : public MapNode,
+                     public runtime::InplaceArrayBase<SmallMapNode, MapNode::KVType> {
+ private:
+  static constexpr uint64_t kInitSize = 2;
+  static constexpr uint64_t kMaxSize = 4;
+
+ public:
+  using MapNode::iterator;
+  using MapNode::KVType;
+
+  /*! \brief Defaults to the destructor of InplaceArrayBase */
+  ~SmallMapNode() = default;
+  /*!
+   * \brief Count the number of times a key exists in the SmallMapNode
+   * \param key The indexing key
+   * \return The result, 0 or 1
+   */
+  size_t count(const key_type& key) const { return find(key).index < size_; }
+  /*!
+   * \brief Index value associated with a key, throw exception if the key does not exist
+   * \param key The indexing key
+   * \return The const reference to the value
+   */
+  const mapped_type& at(const key_type& key) const {
+    iterator itr = find(key);
+    ICHECK(itr.index < size_) << "IndexError: key is not in Map";
+    return itr->second;
+  }
+  /*!
+   * \brief Index value associated with a key, throw exception if the key does not exist
+   * \param key The indexing key
+   * \return The mutable reference to the value
+   */
+  mapped_type& at(const key_type& key) {
+    iterator itr = find(key);
+    ICHECK(itr.index < size_) << "IndexError: key is not in Map";
+    return itr->second;
+  }
+  /*! \return begin iterator */
+  iterator begin() const { return iterator(0, this); }
+  /*! \return end iterator */
+  iterator end() const { return iterator(size_, this); }
+  /*!
+   * \brief Index value associated with a key
+   * \param key The indexing key
+   * \return The iterator of the entry associated with the key, end iterator if not exists
+   */
+  iterator find(const key_type& key) const {
+    KVType* ptr = static_cast<KVType*>(AddressOf(0));
+    for (uint64_t i = 0; i < size_; ++i, ++ptr) {
+      if (ObjectEqual()(ptr->first, key)) {
+        return iterator(i, this);
+      }
+    }
+    return iterator(size_, this);
+  }
+  /*!
+   * \brief Erase the entry associated with the iterator
+   * \param position The iterator
+   */
+  void erase(const iterator& position) { Erase(position.index); }
+
+ private:
+  /*!
+   * \brief Remove a position in SmallMapNode
+   * \param index The position to be removed
+   */
+  void Erase(const uint64_t index) {
+    if (index >= size_) {
+      return;
+    }
+    KVType* begin = static_cast<KVType*>(AddressOf(0));
+    KVType* last = begin + (size_ - 1);
+    if (index + 1 == size_) {
+      last->first.ObjectRef::~ObjectRef();
+      last->second.ObjectRef::~ObjectRef();
+    } else {
+      *(begin + index) = std::move(*last);
+    }
+    size_ -= 1;
+  }
+  /*!
+   * \brief Create an empty container
+   * \param n Number of empty slots
+   * \return The object created
+   */
+  static ObjectPtr<SmallMapNode> Empty(uint64_t n = kInitSize) {
+    using ::tvm::runtime::make_inplace_array_object;
+    ObjectPtr<SmallMapNode> p = make_inplace_array_object<SmallMapNode, KVType>(n);
+    p->size_ = 0;
+    p->slots_ = n;
+    return p;
+  }
+  /*!
+   * \brief Create an empty container initialized with a given range
+   * \param n Number of empty slots
+   * \param first begin of iterator
+   * \param last end of iterator
+   * \tparam IterType The type of iterator
+   * \return The object created
+   */
+  template <typename IterType>
+  static ObjectPtr<SmallMapNode> CreateFromRange(uint64_t n, IterType first, IterType last) {
+    ObjectPtr<SmallMapNode> p = Empty(n);
+    KVType* ptr = static_cast<KVType*>(p->AddressOf(0));
+    for (; first != last; ++first, ++p->size_) {
+      new (ptr++) KVType(*first);
+    }
+    return p;
+  }
+  /*!
+   * \brief Create an empty container with elements copying from another SmallMapNode
+   * \param from The source container
+   * \return The object created
+   */
+  static ObjectPtr<SmallMapNode> CopyFrom(SmallMapNode* from) {
+    KVType* first = static_cast<KVType*>(from->AddressOf(0));
+    KVType* last = first + from->size_;
+    return CreateFromRange(from->size_, first, last);
+  }
+  /*!
+   * \brief InsertMaybeReHash an entry into the given hash map
+   * \param kv The entry to be inserted
+   * \param map The pointer to the map, can be changed if re-hashing happens
+   */
+  static void InsertMaybeReHash(const KVType& kv, ObjectPtr<Object>* map) {
+    SmallMapNode* map_node = static_cast<SmallMapNode*>(map->get());
+    iterator itr = map_node->find(kv.first);
+    if (itr.index < map_node->size_) {
+      itr->second = kv.second;
+      return;
+    }
+    if (map_node->size_ < map_node->slots_) {
+      KVType* ptr = static_cast<KVType*>(map_node->AddressOf(map_node->size_));
+      new (ptr) KVType(kv);
+      ++map_node->size_;
+      return;
+    }
+    uint64_t next_size = std::max(map_node->slots_ * 2, uint64_t(kInitSize));
+    next_size = std::min(next_size, uint64_t(kMaxSize));
+    ICHECK_GT(next_size, map_node->slots_);
+    ObjectPtr<Object> new_map = CreateFromRange(next_size, map_node->begin(), map_node->end());
+    InsertMaybeReHash(kv, &new_map);
+    *map = std::move(new_map);
+  }
+  /*!
+   * \brief Increment the pointer
+   * \param index The pointer to be incremented
+   * \return The increased pointer
+   */
+  uint64_t IncItr(uint64_t index) const { return index + 1 < size_ ? index + 1 : size_; }
+  /*!
+   * \brief Decrement the pointer
+   * \param index The pointer to be decremented
+   * \return The decreased pointer
+   */
+  uint64_t DecItr(uint64_t index) const { return index > 0 ? index - 1 : size_; }
+  /*!
+   * \brief De-reference the pointer
+   * \param index The pointer to be dereferenced
+   * \return The result
+   */
+  KVType* DeRefItr(uint64_t index) const { return static_cast<KVType*>(AddressOf(index)); }
+  /*! \brief A size function used by InplaceArrayBase */
+  uint64_t GetSize() const { return size_; }
+
+ protected:
+  friend class MapNode;
+  friend class DenseMapNode;
+  friend class runtime::InplaceArrayBase<SmallMapNode, MapNode::KVType>;
+};
+
+/*! \brief A specialization of hash map that implements the idea of array-based hash map.
+ * Another reference implementation can be found [1].
+ *
+ * A. Overview
+ *
+ * DenseMapNode did several improvements over traditional separate chaining hash,
+ * in terms of cache locality, memory footprints and data organization.
+ *
+ * A1. Implicit linked list. For better cache locality, instead of using linked list
+ * explicitly for each bucket, we store list data into a single array that spans contiguously
+ * in memory, and then carefully design access patterns to make sure most of them fall into
+ * a single cache line.
+ *
+ * A2. 1-byte metadata. There is only 1 byte overhead for each slot in the array to indexing and
+ * traversal. This can be divided in 3 parts.
+ * 1) Reserved code: (0b11111111)_2 indicates a slot is empty; (0b11111110)_2 indicates protected,
+ * which means the slot is empty but not allowed to be written.
+ * 2) If not empty or protected, the highest bit is used to indicate whether data in the slot is
+ * head of a linked list.
+ * 3) The rest 7 bits are used as the "next pointer" (i.e. pointer to the next element). On 64-bit
+ * architecture, an ordinary pointer can take up to 8 bytes, which is not acceptable overhead when
+ * dealing with 16-byte ObjectRef pairs. Based on a commonly noticed fact that the lists are
+ * relatively short (length <= 3) in hash maps, we follow [1]'s idea that only allows the pointer to
+ * be one of the 126 possible values, i.e. if the next element of i-th slot is (i + x)-th element,
+ * then x must be one of the 126 pre-defined values.
+ *
+ * A3. Data blocking. We organize the array in the way that every 16 elements forms a data block.
+ * The 16-byte metadata of those 16 elements are stored together, followed by the real data, i.e.
+ * 16 key-value pairs.
+ *
+ * B. Implementation details
+ *
+ * B1. Power-of-2 table size and Fibonacci Hashing. We use power-of-two as table size to avoid
+ * modulo for more efficient arithmetics. To make the hash-to-slot mapping distribute more evenly,
+ * we use the Fibonacci Hashing [2] trick.
+ *
+ * B2. Traverse a linked list in the array.
+ * 1) List head. Assume Fibonacci Hashing maps a given key to slot i, if metadata at slot i
+ * indicates that it is list head, then we found the head; otherwise the list is empty. No probing
+ * is done in this procedure. 2) Next element. To find the next element of a non-empty slot i, we
+ * look at the last 7 bits of the metadata at slot i. If they are all zeros, then it is the end of
+ * list; otherwise, we know that the next element is (i + candidates[the-last-7-bits]).
+ *
+ * B3. InsertMaybeReHash an element. Following B2, we first traverse the linked list to see if this
+ * element is in the linked list, and if not, we put it at the end by probing the next empty
+ * position in one of the 126 candidate positions. If the linked list does not even exist, but the
+ * slot for list head has been occupied by another linked list, we should find this intruder another
+ * place.
+ *
+ * B4. Quadratic probing with triangle numbers. In open address hashing, it is provable that probing
+ * with triangle numbers can traverse power-of-2-sized table [3]. In our algorithm, we follow the
+ * suggestion in [1] that also use triangle numbers for "next pointer" as well as sparing for list
+ * head.
+ *
+ * [1] https://github.com/skarupke/flat_hash_map
+ * [2] https://programmingpraxis.com/2018/06/19/fibonacci-hash/
+ * [3] https://fgiesen.wordpress.com/2015/02/22/triangular-numbers-mod-2n/
+ */
+class DenseMapNode : public MapNode {
+ private:
+  /*! \brief The number of elements in a memory block */
+  static constexpr int kBlockCap = 16;
+  /*! \brief Maximum load factor of the hash map */
+  static constexpr double kMaxLoadFactor = 0.99;
+  /*! \brief Binary representation of the metadata of an empty slot */
+  static constexpr uint8_t kEmptySlot = uint8_t(0b11111111);
+  /*! \brief Binary representation of the metadata of a protected slot */
+  static constexpr uint8_t kProtectedSlot = uint8_t(0b11111110);
+  /*! \brief Number of probing choices available */
+  static constexpr int kNumJumpDists = 126;
+  /*! \brief Head of the implicit linked list */
+  struct ListNode;
+  /*! \brief POD type of a block of memory */
+  struct Block {
+    uint8_t bytes[kBlockCap + kBlockCap * sizeof(KVType)];
+  };
+  static_assert(sizeof(Block) == kBlockCap * (sizeof(KVType) + 1), "sizeof(Block) incorrect");
+  static_assert(std::is_standard_layout<Block>::value, "Block is not standard layout");
+
+ public:
+  using MapNode::iterator;
+
+  /*!
+   * \brief Destroy the DenseMapNode
+   */
+  ~DenseMapNode() { this->Reset(); }
+  /*! \return The number of elements of the key */
+  size_t count(const key_type& key) const { return !Search(key).IsNone(); }
+  /*!
+   * \brief Index value associated with a key, throw exception if the key does not exist
+   * \param key The indexing key
+   * \return The const reference to the value
+   */
+  const mapped_type& at(const key_type& key) const { return At(key); }
+  /*!
+   * \brief Index value associated with a key, throw exception if the key does not exist
+   * \param key The indexing key
+   * \return The mutable reference to the value
+   */
+  mapped_type& at(const key_type& key) { return At(key); }
+  /*!
+   * \brief Index value associated with a key
+   * \param key The indexing key
+   * \return The iterator of the entry associated with the key, end iterator if not exists
+   */
+  iterator find(const key_type& key) const {
+    ListNode node = Search(key);
+    return node.IsNone() ? end() : iterator(node.index, this);
+  }
+  /*!
+   * \brief Erase the entry associated with the iterator
+   * \param position The iterator
+   */
+  void erase(const iterator& position) {
+    uint64_t index = position.index;
+    if (position.self != nullptr && index <= this->slots_) {
+      Erase(ListNode(index, this));
+    }
+  }
+  /*! \return begin iterator */
+  iterator begin() const {
+    if (slots_ == 0) {
+      return iterator(0, this);
+    }
+    for (uint64_t index = 0; index <= slots_; ++index) {
+      if (!ListNode(index, this).IsEmpty()) {
+        return iterator(index, this);
+      }
+    }
+    return iterator(slots_ + 1, this);
+  }
+  /*! \return end iterator */
+  iterator end() const { return slots_ == 0 ? iterator(0, this) : iterator(slots_ + 1, this); }
+
+ private:
+  /*!
+   * \brief Search for the given key
+   * \param key The key
+   * \return ListNode that associated with the key
+   */
+  ListNode Search(const key_type& key) const {
+    if (this->size_ == 0) {
+      return ListNode();
+    }
+    for (ListNode iter = GetListHead(ObjectHash()(key)); !iter.IsNone(); iter.MoveToNext(this)) {
+      if (ObjectEqual()(key, iter.Key())) {
+        return iter;
+      }
+    }
+    return ListNode();
+  }
+  /*!
+   * \brief Search for the given key, throw exception if not exists
+   * \param key The key
+   * \return ListNode that associated with the key
+   */
+  mapped_type& At(const key_type& key) const {
+    ListNode iter = Search(key);
+    ICHECK(!iter.IsNone()) << "IndexError: key is not in Map";
+    return iter.Val();
+  }
+  /*!
+   * \brief Try to insert a key, or do nothing if already exists
+   * \param key The indexing key
+   * \param result The linked-list entry found or just constructed
+   * \return A boolean, indicating if actual insertion happens
+   */
+  bool TryInsert(const key_type& key, ListNode* result) {
+    if (slots_ == 0) {
+      return false;
+    }
+    // required that `iter` to be the head of a linked list through which we can iterator
+    ListNode iter = IndexFromHash(ObjectHash()(key));
+    // `iter` can be: 1) empty; 2) body of an irrelevant list; 3) head of the relevant list
+    // Case 1: empty
+    if (iter.IsEmpty()) {
+      iter.NewHead(KVType(key, ObjectRef(nullptr)));
+      this->size_ += 1;
+      *result = iter;
+      return true;
+    }
+    // Case 2: body of an irrelevant list
+    if (!iter.IsHead()) {
+      // we move the elements around and construct the single-element linked list
+      return IsFull() ? false : TrySpareListHead(iter, key, result);
+    }
+    // Case 3: head of the relevant list
+    // we iterate through the linked list until the end
+    // make sure `iter` is the previous element of `next`
+    ListNode next = iter;
+    do {
+      // find equal item, do not insert
+      if (ObjectEqual()(key, next.Key())) {
+        *result = next;
+        return true;
+      }
+      // make sure `iter` is the previous element of `next`
+      iter = next;
+    } while (next.MoveToNext(this));
+    // `iter` is the tail of the linked list
+    // always check capacity before insertion
+    if (IsFull()) {
+      return false;
+    }
+    // find the next empty slot
+    uint8_t jump;
+    if (!iter.GetNextEmpty(this, &jump, result)) {
+      return false;
+    }
+    result->NewTail(KVType(key, ObjectRef(nullptr)));
+    // link `iter` to `empty`, and move forward
+    iter.SetJump(jump);
+    this->size_ += 1;
+    return true;
+  }
+  /*!
+   * \brief Spare an entry to be the head of a linked list.
+   * As described in B3, during insertion, it is possible that the entire linked list does not
+   * exist, but the slot of its head has been occupied by other linked lists. In this case, we need
+   * to spare the slot by moving away the elements to another valid empty one to make insertion
+   * possible.
+   * \param target The given entry to be spared
+   * \param key The indexing key
+   * \param result The linked-list entry constructed as the head
+   * \return A boolean, if actual insertion happens
+   */
+  bool TrySpareListHead(ListNode target, const key_type& key, ListNode* result) {
+    // `target` is not the head of the linked list
+    // move the original item of `target` (if any)
+    // and construct new item on the position `target`
+    // To make `target` empty, we
+    // 1) find `w` the previous element of `target` in the linked list
+    // 2) copy the linked list starting from `r = target`
+    // 3) paste them after `w`
+    // read from the linked list after `r`
+    ListNode r = target;
+    // write to the tail of `w`
+    ListNode w = target.FindPrev(this);
+    // after `target` is moved, we disallow writing to the slot
+    bool is_first = true;
+    uint8_t r_meta, jump;
+    ListNode empty;
+    do {
+      // `jump` describes how `w` is jumped to `empty`
+      // rehash if there is no empty space after `w`
+      if (!w.GetNextEmpty(this, &jump, &empty)) {
+        return false;
+      }
+      // move `r` to `empty`
+      empty.NewTail(std::move(r.Data()));
+      // clear the metadata of `r`
+      r_meta = r.Meta();
+      if (is_first) {
+        is_first = false;
+        r.SetProtected();
+      } else {
+        r.SetEmpty();
+      }
+      // link `w` to `empty`, and move forward
+      w.SetJump(jump);
+      w = empty;
+      // move `r` forward as well
+    } while (r.MoveToNext(this, r_meta));
+    // finally we have done moving the linked list
+    // fill data_ into `target`
+    target.NewHead(KVType(key, ObjectRef(nullptr)));
+    this->size_ += 1;
+    *result = target;
+    return true;
+  }
+  /*!
+   * \brief Remove a ListNode
+   * \param iter The node to be removed
+   */
+  void Erase(const ListNode& iter) {
+    this->size_ -= 1;
+    if (!iter.HasNext()) {
+      // `iter` is the last
+      if (!iter.IsHead()) {
+        // cut the link if there is any
+        iter.FindPrev(this).SetJump(0);
+      }
+      iter.Data().KVType::~KVType();
+      iter.SetEmpty();
+    } else {
+      ListNode last = iter, prev = iter;
+      for (last.MoveToNext(this); last.HasNext(); prev = last, last.MoveToNext(this)) {
+      }
+      iter.Data() = std::move(last.Data());
+      last.SetEmpty();
+      prev.SetJump(0);
+    }
+  }
+  /*! \brief Clear the container to empty, release all entries and memory acquired */
+  void Reset() {
+    uint64_t n_blocks = CalcNumBlocks(this->slots_);
+    for (uint64_t bi = 0; bi < n_blocks; ++bi) {
+      uint8_t* meta_ptr = data_[bi].bytes;
+      KVType* data_ptr = reinterpret_cast<KVType*>(data_[bi].bytes + kBlockCap);
+      for (int j = 0; j < kBlockCap; ++j, ++meta_ptr, ++data_ptr) {
+        uint8_t& meta = *meta_ptr;
+        if (meta != uint8_t(kProtectedSlot) && meta != uint8_t(kEmptySlot)) {
+          meta = uint8_t(kEmptySlot);
+          data_ptr->KVType::~KVType();
+        }
+      }
+    }
+    ReleaseMemory();
+  }
+  /*! \brief Release the memory acquired by the container without deleting its entries stored inside
+   */
+  void ReleaseMemory() {
+    delete[] data_;
+    data_ = nullptr;
+    slots_ = 0;
+    size_ = 0;
+    fib_shift_ = 63;
+  }
+  /*!
+   * \brief Create an empty container
+   * \param fib_shift The fib shift provided
+   * \param n_slots Number of slots required, should be power-of-two
+   * \return The object created
+   */
+  static ObjectPtr<DenseMapNode> Empty(uint32_t fib_shift, uint64_t n_slots) {
+    ICHECK_GT(n_slots, uint64_t(SmallMapNode::kMaxSize));
+    ObjectPtr<DenseMapNode> p = make_object<DenseMapNode>();
+    uint64_t n_blocks = CalcNumBlocks(n_slots - 1);
+    Block* block = p->data_ = new Block[n_blocks];
+    p->slots_ = n_slots - 1;
+    p->size_ = 0;
+    p->fib_shift_ = fib_shift;
+    for (uint64_t i = 0; i < n_blocks; ++i, ++block) {
+      std::fill(block->bytes, block->bytes + kBlockCap, uint8_t(kEmptySlot));
+    }
+    return p;
+  }
+  /*!
+   * \brief Create an empty container with elements copying from another DenseMapNode
+   * \param from The source container
+   * \return The object created
+   */
+  static ObjectPtr<DenseMapNode> CopyFrom(DenseMapNode* from) {
+    ObjectPtr<DenseMapNode> p = make_object<DenseMapNode>();
+    uint64_t n_blocks = CalcNumBlocks(from->slots_);
+    p->data_ = new Block[n_blocks];
+    p->slots_ = from->slots_;
+    p->size_ = from->size_;
+    p->fib_shift_ = from->fib_shift_;
+    for (uint64_t bi = 0; bi < n_blocks; ++bi) {
+      uint8_t* meta_ptr_from = from->data_[bi].bytes;
+      KVType* data_ptr_from = reinterpret_cast<KVType*>(from->data_[bi].bytes + kBlockCap);
+      uint8_t* meta_ptr_to = p->data_[bi].bytes;
+      KVType* data_ptr_to = reinterpret_cast<KVType*>(p->data_[bi].bytes + kBlockCap);
+      for (int j = 0; j < kBlockCap;
+           ++j, ++meta_ptr_from, ++data_ptr_from, ++meta_ptr_to, ++data_ptr_to) {
+        uint8_t& meta = *meta_ptr_to = *meta_ptr_from;
+        ICHECK(meta != kProtectedSlot);
+        if (meta != uint8_t(kEmptySlot)) {
+          new (data_ptr_to) KVType(*data_ptr_from);
+        }
+      }
+    }
+    return p;
+  }
+  /*!
+   * \brief InsertMaybeReHash an entry into the given hash map
+   * \param kv The entry to be inserted
+   * \param map The pointer to the map, can be changed if re-hashing happens
+   */
+  static void InsertMaybeReHash(const KVType& kv, ObjectPtr<Object>* map) {
+    DenseMapNode* map_node = static_cast<DenseMapNode*>(map->get());
+    ListNode iter;
+    // Try to insert. If succeed, we simply return
+    if (map_node->TryInsert(kv.first, &iter)) {
+      iter.Val() = kv.second;
+      return;
+    }
+    ICHECK_GT(map_node->slots_, uint64_t(SmallMapNode::kMaxSize));
+    // Otherwise, start rehash
+    ObjectPtr<Object> p = Empty(map_node->fib_shift_ - 1, map_node->slots_ * 2 + 2);
+    // Insert the given `kv` into the new hash map
+    InsertMaybeReHash(kv, &p);
+    uint64_t n_blocks = CalcNumBlocks(map_node->slots_);
+    // Then Insert data from the original block.
+    for (uint64_t bi = 0; bi < n_blocks; ++bi) {
+      uint8_t* meta_ptr = map_node->data_[bi].bytes;
+      KVType* data_ptr = reinterpret_cast<KVType*>(map_node->data_[bi].bytes + kBlockCap);
+      for (int j = 0; j < kBlockCap; ++j, ++meta_ptr, ++data_ptr) {
+        uint8_t& meta = *meta_ptr;
+        if (meta != uint8_t(kProtectedSlot) && meta != uint8_t(kEmptySlot)) {
+          meta = uint8_t(kEmptySlot);
+          KVType kv = std::move(*data_ptr);
+          InsertMaybeReHash(kv, &p);
+        }
+      }
+    }
+    map_node->ReleaseMemory();
+    *map = p;
+  }
+  /*!
+   * \brief Check whether the hash table is full
+   * \return A boolean indicating whether hash table is full
+   */
+  bool IsFull() const { return size_ + 1 > (slots_ + 1) * kMaxLoadFactor; }
+  /*!
+   * \brief Increment the pointer
+   * \param index The pointer to be incremented
+   * \return The increased pointer
+   */
+  uint64_t IncItr(uint64_t index) const {
+    for (++index; index <= slots_; ++index) {
+      if (!ListNode(index, this).IsEmpty()) {
+        return index;
+      }
+    }
+    return slots_ + 1;
+  }
+  /*!
+   * \brief Decrement the pointer
+   * \param index The pointer to be decremented
+   * \return The decreased pointer
+   */
+  uint64_t DecItr(uint64_t index) const {
+    while (index != 0) {
+      index -= 1;
+      if (!ListNode(index, this).IsEmpty()) {
+        return index;
+      }
+    }
+    return slots_ + 1;
+  }
+  /*!
+   * \brief De-reference the pointer
+   * \param index The pointer to be dereferenced
+   * \return The result
+   */
+  KVType* DeRefItr(uint64_t index) const { return &ListNode(index, this).Data(); }
+  /*! \brief Construct from hash code */
+  ListNode IndexFromHash(uint64_t hash_value) const {
+    return ListNode(FibHash(hash_value, fib_shift_), this);
+  }
+  /*! \brief Construct from hash code if the position is head of list */
+  ListNode GetListHead(uint64_t hash_value) const {
+    ListNode node = IndexFromHash(hash_value);
+    return node.IsHead() ? node : ListNode();
+  }
+  /*! \brief Construct the number of blocks in the hash table */
+  static uint64_t CalcNumBlocks(uint64_t n_slots_m1) {
+    uint64_t n_slots = n_slots_m1 > 0 ? n_slots_m1 + 1 : 0;
+    return (n_slots + kBlockCap - 1) / kBlockCap;
+  }
+  /*!
+   * \brief Calculate the power-of-2 table size given the lower-bound of required capacity.
+   * \param cap The lower-bound of the required capacity
+   * \param fib_shift The result shift for Fibonacci Hashing
+   * \param n_slots The result number of slots
+   */
+  static void CalcTableSize(uint64_t cap, uint32_t* fib_shift, uint64_t* n_slots) {
+    uint32_t shift = 64;
+    uint64_t slots = 1;
+    for (uint64_t c = cap; c; c >>= 1) {
+      shift -= 1;
+      slots <<= 1;
+    }
+    ICHECK_GT(slots, cap);
+    if (slots < cap * 2) {
+      *fib_shift = shift - 1;
+      *n_slots = slots << 1;
+    } else {
+      *fib_shift = shift;
+      *n_slots = slots;
+    }
+  }
+  /*!
+   * \brief Fibonacci Hashing, maps a hash code to an index in a power-of-2-sized table.
+   * See also: https://programmingpraxis.com/2018/06/19/fibonacci-hash/.
+   * \param hash_value The raw hash value
+   * \param fib_shift The shift in Fibonacci Hashing
+   * \return An index calculated using Fibonacci Hashing
+   */
+  static uint64_t FibHash(uint64_t hash_value, uint32_t fib_shift) {
+    constexpr uint64_t coeff = 11400714819323198485ull;
+    return (coeff * hash_value) >> fib_shift;
+  }
+  /*! \brief The implicit in-place linked list used to index a chain */
+  struct ListNode {
+    /*! \brief Construct None */
+    ListNode() : index(0), block(nullptr) {}
+    /*! \brief Construct from position */
+    ListNode(uint64_t index, const DenseMapNode* self)
+        : index(index), block(self->data_ + (index / kBlockCap)) {}
+    /*! \brief Metadata on the entry */
+    uint8_t& Meta() const { return *(block->bytes + index % kBlockCap); }
+    /*! \brief Data on the entry */
+    KVType& Data() const {
+      return *(reinterpret_cast<KVType*>(block->bytes + kBlockCap +
+                                         (index % kBlockCap) * sizeof(KVType)));
+    }
+    /*! \brief Key on the entry */
+    key_type& Key() const { return Data().first; }
+    /*! \brief Value on the entry */
+    mapped_type& Val() const { return Data().second; }
+    /*! \brief If the entry is head of linked list */
+    bool IsHead() const { return (Meta() & 0b10000000) == 0b00000000; }
+    /*! \brief If the entry is none */
+    bool IsNone() const { return block == nullptr; }
+    /*! \brief If the entry is empty slot */
+    bool IsEmpty() const { return Meta() == uint8_t(kEmptySlot); }
+    /*! \brief If the entry is protected slot */
+    bool IsProtected() const { return Meta() == uint8_t(kProtectedSlot); }
+    /*! \brief Set the entry to be empty */
+    void SetEmpty() const { Meta() = uint8_t(kEmptySlot); }
+    /*! \brief Set the entry to be protected */
+    void SetProtected() const { Meta() = uint8_t(kProtectedSlot); }
+    /*! \brief Set the entry's jump to its next entry */
+    void SetJump(uint8_t jump) const { (Meta() &= 0b10000000) |= jump; }
+    /*! \brief Construct a head of linked list in-place */
+    void NewHead(KVType v) const {
+      Meta() = 0b00000000;
+      new (&Data()) KVType(std::move(v));
+    }
+    /*! \brief Construct a tail of linked list in-place */
+    void NewTail(KVType v) const {
+      Meta() = 0b10000000;
+      new (&Data()) KVType(std::move(v));
+    }
+    /*! \brief If the entry has next entry on the linked list */
+    bool HasNext() const { return NextProbeLocation(Meta() & 0b01111111) != 0; }
+    /*! \brief Move the entry to the next entry on the linked list */
+    bool MoveToNext(const DenseMapNode* self, uint8_t meta) {
+      uint64_t offset = NextProbeLocation(meta & 0b01111111);
+      if (offset == 0) {
+        index = 0;
+        block = nullptr;
+        return false;
+      }
+      index = (index + offset) & (self->slots_);
+      block = self->data_ + (index / kBlockCap);
+      return true;
+    }
+    /*! \brief Move the entry to the next entry on the linked list */
+    bool MoveToNext(const DenseMapNode* self) { return MoveToNext(self, Meta()); }
+    /*! \brief Get the previous entry on the linked list */
+    ListNode FindPrev(const DenseMapNode* self) const {
+      // start from the head of the linked list, which must exist
+      ListNode next = self->IndexFromHash(ObjectHash()(Key()));
+      // `prev` is always the previous item of `next`
+      ListNode prev = next;
+      for (next.MoveToNext(self); index != next.index; prev = next, next.MoveToNext(self)) {
+      }
+      return prev;
+    }
+    /*! \brief Get the next empty jump */
+    bool GetNextEmpty(const DenseMapNode* self, uint8_t* jump, ListNode* result) const {
+      for (uint8_t idx = 1; idx < kNumJumpDists; ++idx) {
+        ListNode candidate((index + NextProbeLocation(idx)) & (self->slots_), self);
+        if (candidate.IsEmpty()) {
+          *jump = idx;
+          *result = candidate;
+          return true;
+        }
+      }
+      return false;
+    }
+    /*! \brief Index on the real array */
+    uint64_t index;
+    /*! \brief Pointer to the actual block */
+    Block* block;
+  };
+
+ protected:
+  /*! \brief fib shift in Fibonacci Hashing */
+  uint32_t fib_shift_;
+  /*! \brief array of data blocks */
+  Block* data_;
+  static uint64_t NextProbeLocation(size_t index) {
+    /* clang-format off */
+    /*! \brief Candidates of probing distance */
+    static const uint64_t kNextProbeLocation[kNumJumpDists] {
+      0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,
+      // Quadratic probing with triangle numbers. See also:
+      // 1) https://en.wikipedia.org/wiki/Quadratic_probing
+      // 2) https://fgiesen.wordpress.com/2015/02/22/triangular-numbers-mod-2n/
+      // 3) https://github.com/skarupke/flat_hash_map
+      21, 28, 36, 45, 55, 66, 78, 91, 105, 120,
+      136, 153, 171, 190, 210, 231, 253, 276, 300, 325,
+      351, 378, 406, 435, 465, 496, 528, 561, 595, 630,
+      666, 703, 741, 780, 820, 861, 903, 946, 990, 1035,
+      1081, 1128, 1176, 1225, 1275, 1326, 1378, 1431, 1485, 1540,
+      1596, 1653, 1711, 1770, 1830, 1891, 1953, 2016, 2080, 2145,
+      2211, 2278, 2346, 2415, 2485, 2556, 2628,
+      // larger triangle numbers
+      8515, 19110, 42778, 96141, 216153,
+      486591, 1092981, 2458653, 5532801, 12442566,
+      27993903, 62983476, 141717030, 318844378, 717352503,
+      1614057336, 3631522476, 8170957530, 18384510628, 41364789378,
+      93070452520, 209408356380, 471168559170, 1060128894105, 2385289465695,
+      5366898840628, 12075518705635, 27169915244790, 61132312065111, 137547689707000,
+      309482283181501, 696335127828753, 1566753995631385, 3525196511162271, 7931691992677701,
+      17846306936293605, 40154190677507445, 90346928918121501, 203280589587557251,
+      457381325854679626, 1029107982097042876, 2315492959180353330, 5209859154120846435,
+    };
+    /* clang-format on */
+    return kNextProbeLocation[index];
+  }
+  friend class MapNode;
+};
+
+#define TVM_DISPATCH_MAP(base, var, body)     \
+  {                                           \
+    using TSmall = SmallMapNode*;             \
+    using TDense = DenseMapNode*;             \
+    uint64_t slots = base->slots_;            \
+    if (slots <= SmallMapNode::kMaxSize) {    \
+      TSmall var = static_cast<TSmall>(base); \
+      body;                                   \
+    } else {                                  \
+      TDense var = static_cast<TDense>(base); \
+      body;                                   \
+    }                                         \
+  }
+
+#define TVM_DISPATCH_MAP_CONST(base, var, body) \
+  {                                             \
+    using TSmall = const SmallMapNode*;         \
+    using TDense = const DenseMapNode*;         \
+    uint64_t slots = base->slots_;              \
+    if (slots <= SmallMapNode::kMaxSize) {      \
+      TSmall var = static_cast<TSmall>(base);   \
+      body;                                     \
+    } else {                                    \
+      TDense var = static_cast<TDense>(base);   \
+      body;                                     \
+    }                                           \
+  }
+
+inline MapNode::iterator::pointer MapNode::iterator::operator->() const {
+  TVM_MAP_FAIL_IF_CHANGED()
+  TVM_DISPATCH_MAP_CONST(self, p, { return p->DeRefItr(index); });
+}
+
+inline MapNode::iterator& MapNode::iterator::operator++() {
+  TVM_MAP_FAIL_IF_CHANGED()
+  TVM_DISPATCH_MAP_CONST(self, p, {
+    index = p->IncItr(index);
+    return *this;
+  });
+}
+
+inline MapNode::iterator& MapNode::iterator::operator--() {
+  TVM_MAP_FAIL_IF_CHANGED()
+  TVM_DISPATCH_MAP_CONST(self, p, {
+    index = p->DecItr(index);
+    return *this;
+  });
+}
+
+inline size_t MapNode::count(const key_type& key) const {
+  TVM_DISPATCH_MAP_CONST(this, p, { return p->count(key); });
+}
+
+inline const MapNode::mapped_type& MapNode::at(const MapNode::key_type& key) const {
+  TVM_DISPATCH_MAP_CONST(this, p, { return p->at(key); });
+}
+
+inline MapNode::mapped_type& MapNode::at(const MapNode::key_type& key) {
+  TVM_DISPATCH_MAP(this, p, { return p->at(key); });
+}
+
+inline MapNode::iterator MapNode::begin() const {
+  TVM_DISPATCH_MAP_CONST(this, p, { return p->begin(); });
+}
+
+inline MapNode::iterator MapNode::end() const {
+  TVM_DISPATCH_MAP_CONST(this, p, { return p->end(); });
+}
+
+inline MapNode::iterator MapNode::find(const MapNode::key_type& key) const {
+  TVM_DISPATCH_MAP_CONST(this, p, { return p->find(key); });
+}
+
+inline void MapNode::erase(const MapNode::iterator& position) {
+  TVM_DISPATCH_MAP(this, p, { return p->erase(position); });
+}
+
+#undef TVM_DISPATCH_MAP
+#undef TVM_DISPATCH_MAP_CONST
+
+inline ObjectPtr<MapNode> MapNode::Empty() { return SmallMapNode::Empty(); }
+
+inline ObjectPtr<MapNode> MapNode::CopyFrom(MapNode* from) {
+  if (from->slots_ <= SmallMapNode::kMaxSize) {
+    return SmallMapNode::CopyFrom(static_cast<SmallMapNode*>(from));
+  } else {
+    return DenseMapNode::CopyFrom(static_cast<DenseMapNode*>(from));
+  }
+}
+
+template <typename IterType>
+inline ObjectPtr<Object> MapNode::CreateFromRange(IterType first, IterType last) {
+  int64_t _cap = std::distance(first, last);
+  if (_cap < 0) {
+    return SmallMapNode::Empty();
+  }
+  uint64_t cap = static_cast<uint64_t>(_cap);
+  if (cap < SmallMapNode::kMaxSize) {
+    return SmallMapNode::CreateFromRange(cap, first, last);
+  }
+  uint32_t fib_shift;
+  uint64_t n_slots;
+  DenseMapNode::CalcTableSize(cap, &fib_shift, &n_slots);
+  ObjectPtr<Object> obj = DenseMapNode::Empty(fib_shift, n_slots);
+  for (; first != last; ++first) {
+    KVType kv(*first);
+    DenseMapNode::InsertMaybeReHash(kv, &obj);
+  }
+  return obj;
+}
+
+inline void MapNode::InsertMaybeReHash(const KVType& kv, ObjectPtr<Object>* map) {
+  constexpr uint64_t kSmallMapMaxSize = SmallMapNode::kMaxSize;
+  MapNode* base = static_cast<MapNode*>(map->get());
+#if TVM_LOG_DEBUG
+  base->state_marker++;
+#endif  // TVM_LOG_DEBUG
+  if (base->slots_ < kSmallMapMaxSize) {
+    SmallMapNode::InsertMaybeReHash(kv, map);
+  } else if (base->slots_ == kSmallMapMaxSize) {
+    if (base->size_ < base->slots_) {
+      SmallMapNode::InsertMaybeReHash(kv, map);
+    } else {
+      ObjectPtr<Object> new_map = MapNode::CreateFromRange(base->begin(), base->end());
+      DenseMapNode::InsertMaybeReHash(kv, &new_map);
+      *map = std::move(new_map);
+    }
+  } else {
+    DenseMapNode::InsertMaybeReHash(kv, map);
+  }
+}
+
+template <>
+inline ObjectPtr<MapNode> make_object<>() = delete;
+
+#endif
+
+/*!
+ * \brief Map container of NodeRef->NodeRef in DSL graph.
+ *  Map implements copy on write semantics, which means map is mutable
+ *  but copy will happen when array is referenced in more than two places.
+ *
+ * operator[] only provide const acces, use Set to mutate the content.
+ * \tparam K The key NodeRef type.
+ * \tparam V The value NodeRef type.
+ */
+template <typename K, typename V,
+          typename = typename std::enable_if<std::is_base_of<ObjectRef, K>::value>::type,
+          typename = typename std::enable_if<std::is_base_of<ObjectRef, V>::value>::type>
+class Map : public ObjectRef {
+ public:
+  using key_type = K;
+  using mapped_type = V;
+  class iterator;
+  /*!
+   * \brief default constructor
+   */
+  Map() { data_ = MapNode::Empty(); }
+  /*!
+   * \brief move constructor
+   * \param other source
+   */
+  Map(Map<K, V>&& other) { data_ = std::move(other.data_); }
+  /*!
+   * \brief copy constructor
+   * \param other source
+   */
+  Map(const Map<K, V>& other) : ObjectRef(other.data_) {}
+  /*!
+   * \brief copy assign operator
+   * \param other The source of assignment
+   * \return reference to self.
+   */
+  Map<K, V>& operator=(Map<K, V>&& other) {
+    data_ = std::move(other.data_);
+    return *this;
+  }
+  /*!
+   * \brief move assign operator
+   * \param other The source of assignment
+   * \return reference to self.
+   */
+  Map<K, V>& operator=(const Map<K, V>& other) {
+    data_ = other.data_;
+    return *this;
+  }
+  /*!
+   * \brief constructor from pointer
+   * \param n the container pointer
+   */
+  explicit Map(ObjectPtr<Object> n) : ObjectRef(n) {}
+  /*!
+   * \brief constructor from iterator
+   * \param begin begin of iterator
+   * \param end end of iterator
+   * \tparam IterType The type of iterator
+   */
+  template <typename IterType>
+  Map(IterType begin, IterType end) {
+    data_ = MapNode::CreateFromRange(begin, end);
+  }
+  /*!
+   * \brief constructor from initializer list
+   * \param init The initalizer list
+   */
+  Map(std::initializer_list<std::pair<K, V>> init) {
+    data_ = MapNode::CreateFromRange(init.begin(), init.end());
+  }
+  /*!
+   * \brief constructor from unordered_map
+   * \param init The unordered_map
+   */
+  template <typename Hash, typename Equal>
+  Map(const std::unordered_map<K, V, Hash, Equal>& init) {  // NOLINT(*)
+    data_ = MapNode::CreateFromRange(init.begin(), init.end());
+  }
+  /*!
+   * \brief Read element from map.
+   * \param key The key
+   * \return the corresonding element.
+   */
+  const V at(const K& key) const { return DowncastNoCheck<V>(GetMapNode()->at(key)); }
+  /*!
+   * \brief Read element from map.
+   * \param key The key
+   * \return the corresonding element.
+   */
+  const V operator[](const K& key) const { return this->at(key); }
+  /*! \return The size of the array */
+  size_t size() const {
+    MapNode* n = GetMapNode();
+    return n == nullptr ? 0 : n->size();
+  }
+  /*! \return The number of elements of the key */
+  size_t count(const K& key) const {
+    MapNode* n = GetMapNode();
+    return n == nullptr ? 0 : GetMapNode()->count(key);
+  }
+  /*! \return whether array is empty */
+  bool empty() const { return size() == 0; }
+  /*! \brief Release reference to all the elements */
+  void clear() {
+    MapNode* n = GetMapNode();
+    if (n != nullptr) {
+      data_ = MapNode::Empty();
+    }
+  }
+  /*!
+   * \brief set the Map.
+   * \param key The index key.
+   * \param value The value to be setted.
+   */
+  void Set(const K& key, const V& value) {
+    CopyOnWrite();
+    MapNode::InsertMaybeReHash(MapNode::KVType(key, value), &data_);
+  }
+  /*! \return begin iterator */
+  iterator begin() const { return iterator(GetMapNode()->begin()); }
+  /*! \return end iterator */
+  iterator end() const { return iterator(GetMapNode()->end()); }
+  /*! \return find the key and returns the associated iterator */
+  iterator find(const K& key) const { return iterator(GetMapNode()->find(key)); }
+  /*! \return The value associated with the key, NullOpt if not found */
+  Optional<V> Get(const K& key) const {
+    MapNode::iterator iter = GetMapNode()->find(key);
+    if (iter == GetMapNode()->end()) {
+      return NullOptType{};
+    }
+    return DowncastNoCheck<V>(iter->second);
+  }
+  void erase(const K& key) { CopyOnWrite()->erase(key); }
+
+  /*!
+   * \brief copy on write semantics
+   *  Do nothing if current handle is the unique copy of the array.
+   *  Otherwise make a new copy of the array to ensure the current handle
+   *  hold a unique copy.
+   *
+   * \return Handle to the internal node container(which guarantees to be unique)
+   */
+  MapNode* CopyOnWrite() {
+    if (data_.get() == nullptr) {
+      data_ = MapNode::Empty();
+    } else if (!data_.unique()) {
+      data_ = MapNode::CopyFrom(GetMapNode());
+    }
+    return GetMapNode();
+  }
+  /*! \brief specify container node */
+  using ContainerType = MapNode;
+
+  /*! \brief Iterator of the hash map */
+  class iterator {
+   public:
+    using iterator_category = std::bidirectional_iterator_tag;
+    using difference_type = int64_t;
+    using value_type = const std::pair<K, V>;
+    using pointer = value_type*;
+    using reference = value_type;
+
+    iterator() : itr() {}
+
+    /*! \brief Compare iterators */
+    bool operator==(const iterator& other) const { return itr == other.itr; }
+    /*! \brief Compare iterators */
+    bool operator!=(const iterator& other) const { return itr != other.itr; }
+    /*! \brief De-reference iterators is not allowed */
+    pointer operator->() const = delete;
+    /*! \brief De-reference iterators */
+    reference operator*() const {
+      auto& kv = *itr;
+      return std::make_pair(DowncastNoCheck<K>(kv.first), DowncastNoCheck<V>(kv.second));
+    }
+    /*! \brief Prefix self increment, e.g. ++iter */
+    iterator& operator++() {
+      ++itr;
+      return *this;
+    }
+    /*! \brief Suffix self increment */
+    iterator operator++(int) {
+      iterator copy = *this;
+      ++(*this);
+      return copy;
+    }
+
+   private:
+    iterator(const MapNode::iterator& itr)  // NOLINT(*)
+        : itr(itr) {}
+
+    template <typename, typename, typename, typename>
+    friend class Map;
+
+    MapNode::iterator itr;
+  };
+
+ private:
+  /*! \brief Return data_ as type of pointer of MapNode */
+  MapNode* GetMapNode() const { return static_cast<MapNode*>(data_.get()); }
+};
+
+/*!
+ * \brief Merge two Maps.
+ * \param lhs the first Map to merge.
+ * \param rhs the second Map to merge.
+ * @return The merged Array. Original Maps are kept unchanged.
+ */
+template <typename K, typename V,
+          typename = typename std::enable_if<std::is_base_of<ObjectRef, K>::value>::type,
+          typename = typename std::enable_if<std::is_base_of<ObjectRef, V>::value>::type>
+inline Map<K, V> Merge(Map<K, V> lhs, const Map<K, V>& rhs) {
+  for (const auto& p : rhs) {
+    lhs.Set(p.first, p.second);
+  }
+  return std::move(lhs);
+}
+
+}  // namespace runtime
+
+// expose the functions to the root namespace.
+using runtime::Map;
+using runtime::MapNode;
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_CONTAINER_MAP_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/container/optional.h b/darknet_drp_ros/include/tvm/runtime/container/optional.h
new file mode 100644
index 0000000..9961d5e
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/container/optional.h
@@ -0,0 +1,163 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/container/optional.h
+ * \brief Runtime Optional container types.
+ */
+#ifndef TVM_RUNTIME_CONTAINER_OPTIONAL_H_
+#define TVM_RUNTIME_CONTAINER_OPTIONAL_H_
+
+#include <utility>
+
+#include "./base.h"
+
+namespace tvm {
+namespace runtime {
+
+/*! \brief Helper to represent nullptr for optional. */
+struct NullOptType {};
+
+/*!
+ * \brief Optional container that to represent to a Nullable variant of T.
+ * \tparam T The original ObjectRef.
+ *
+ * \code
+ *
+ *  Optional<String> opt0 = nullptr;
+ *  Optional<String> opt1 = String("xyz");
+ *  ICHECK(opt0 == nullptr);
+ *  ICHECK(opt1 == "xyz");
+ *
+ * \endcode
+ */
+template <typename T>
+class Optional : public ObjectRef {
+ public:
+  using ContainerType = typename T::ContainerType;
+  static_assert(std::is_base_of<ObjectRef, T>::value, "Optional is only defined for ObjectRef.");
+  // default constructors.
+  Optional() = default;
+  Optional(const Optional<T>&) = default;
+  Optional(Optional<T>&&) = default;
+  Optional<T>& operator=(const Optional<T>&) = default;
+  Optional<T>& operator=(Optional<T>&&) = default;
+  /*!
+   * \brief Construct from an ObjectPtr
+   *        whose type already matches the ContainerType.
+   * \param ptr
+   */
+  explicit Optional(ObjectPtr<Object> ptr) : ObjectRef(ptr) {}
+  /*! \brief Nullopt handling */
+  Optional(NullOptType) {}  // NOLINT(*)
+  // nullptr handling.
+  // disallow implicit conversion as 0 can be implicitly converted to nullptr_t
+  explicit Optional(std::nullptr_t) {}
+  Optional<T>& operator=(std::nullptr_t) {
+    data_ = nullptr;
+    return *this;
+  }
+  // normal value handling.
+  Optional(T other)  // NOLINT(*)
+      : ObjectRef(std::move(other)) {}
+  Optional<T>& operator=(T other) {
+    ObjectRef::operator=(std::move(other));
+    return *this;
+  }
+  // delete the int constructor
+  // since Optional<Integer>(0) is ambiguious
+  // 0 can be implicitly casted to nullptr_t
+  explicit Optional(int val) = delete;
+  Optional<T>& operator=(int val) = delete;
+  /*!
+   * \return A not-null container value in the optional.
+   * \note This function performs not-null checking.
+   */
+  T value() const {
+    ICHECK(data_ != nullptr);
+    return T(data_);
+  }
+  /*!
+   * \return The internal object pointer with container type of T.
+   * \note This function do not perform not-null checking.
+   */
+  const ContainerType* get() const { return static_cast<ContainerType*>(data_.get()); }
+  /*!
+   * \return The contained value if the Optional is not null
+   *         otherwise return the default_value.
+   */
+  T value_or(T default_value) const { return data_ != nullptr ? T(data_) : default_value; }
+
+  /*! \return Whether the container is not nullptr.*/
+  explicit operator bool() const { return *this != nullptr; }
+  // operator overloadings
+  bool operator==(std::nullptr_t) const { return data_ == nullptr; }
+  bool operator!=(std::nullptr_t) const { return data_ != nullptr; }
+  auto operator==(const Optional<T>& other) const {
+    // support case where sub-class returns a symbolic ref type.
+    using RetType = decltype(value() == other.value());
+    if (same_as(other)) return RetType(true);
+    if (*this != nullptr && other != nullptr) {
+      return value() == other.value();
+    } else {
+      // one of them is nullptr.
+      return RetType(false);
+    }
+  }
+  auto operator!=(const Optional<T>& other) const {
+    // support case where sub-class returns a symbolic ref type.
+    using RetType = decltype(value() != other.value());
+    if (same_as(other)) return RetType(false);
+    if (*this != nullptr && other != nullptr) {
+      return value() != other.value();
+    } else {
+      // one of them is nullptr.
+      return RetType(true);
+    }
+  }
+  auto operator==(const T& other) const {
+    using RetType = decltype(value() == other);
+    if (same_as(other)) return RetType(true);
+    if (*this != nullptr) return value() == other;
+    return RetType(false);
+  }
+  auto operator!=(const T& other) const { return !(*this == other); }
+  template <typename U>
+  auto operator==(const U& other) const {
+    using RetType = decltype(value() == other);
+    if (*this == nullptr) return RetType(false);
+    return value() == other;
+  }
+  template <typename U>
+  auto operator!=(const U& other) const {
+    using RetType = decltype(value() != other);
+    if (*this == nullptr) return RetType(true);
+    return value() != other;
+  }
+  static constexpr bool _type_is_nullable = true;
+};
+
+}  // namespace runtime
+
+// expose the functions to the root namespace.
+using runtime::Optional;
+constexpr runtime::NullOptType NullOpt{};
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_CONTAINER_OPTIONAL_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/container/shape_tuple.h b/darknet_drp_ros/include/tvm/runtime/container/shape_tuple.h
new file mode 100644
index 0000000..3a6f184
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/container/shape_tuple.h
@@ -0,0 +1,180 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/container/shape_tuple.h
+ * \brief Runtime ShapeTuple container types.
+ */
+#ifndef TVM_RUNTIME_CONTAINER_SHAPE_TUPLE_H_
+#define TVM_RUNTIME_CONTAINER_SHAPE_TUPLE_H_
+
+#include <utility>
+#include <vector>
+
+#include "./base.h"
+
+namespace tvm {
+namespace runtime {
+
+/*! \brief An object representing a shape tuple. */
+class ShapeTupleObj : public Object {
+ public:
+  /*! \brief The type of shape index element. */
+  using index_type = int64_t;
+  /*! \brief The pointer to shape tuple data. */
+  index_type* data;
+  /*! \brief The size of the shape tuple object. */
+  uint64_t size;
+
+  static constexpr const uint32_t _type_index = runtime::TypeIndex::kRuntimeShapeTuple;
+  static constexpr const char* _type_key = "runtime.ShapeTuple";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ShapeTupleObj, Object);
+
+ private:
+  /*! \brief ShapeTuple object which is moved from std::vector container. */
+  class FromStd;
+
+  friend class ShapeTuple;
+};
+
+/*! \brief An object representing shape tuple moved from std::vector. */
+class ShapeTupleObj::FromStd : public ShapeTupleObj {
+ public:
+  /*! \brief The type of shape index element. */
+  using index_type = ShapeTupleObj::index_type;
+  /*!
+   * \brief Construct a new FromStd object
+   *
+   * \param other The moved/copied std::vector object
+   *
+   * \note If user passes const reference, it will trigger copy. If it's rvalue,
+   * it will be moved into other.
+   */
+  explicit FromStd(std::vector<index_type> other) : data_container{other} {}
+
+ private:
+  /*! \brief Container that holds the memory. */
+  std::vector<index_type> data_container;
+
+  friend class ShapeTuple;
+};
+
+/*!
+ * \brief Reference to shape tuple objects.
+ */
+class ShapeTuple : public ObjectRef {
+ public:
+  /*! \brief The type of shape index element. */
+  using index_type = ShapeTupleObj::index_type;
+
+  /*!
+   * \brief Construct an empty shape tuple.
+   */
+  ShapeTuple() : ShapeTuple(std::vector<index_type>()) {}
+
+  /*!
+   * \brief Constructor from iterator
+   * \param begin begin of iterator
+   * \param end end of iterator
+   * \tparam IterType The type of iterator
+   */
+  template <typename IterType>
+  ShapeTuple(IterType begin, IterType end) : ShapeTuple(std::vector<index_type>(begin, end)) {}
+
+  /*!
+   * \brief constructor from initializer list
+   * \param shape The initializer list
+   */
+  ShapeTuple(std::initializer_list<index_type> shape) : ShapeTuple(shape.begin(), shape.end()) {}
+
+  /*!
+   * \brief Construct a new ShapeTuple object
+   *
+   * \param shape The moved/copied std::vector object
+   *
+   * \note If user passes const reference, it will trigger copy. If it's rvalue,
+   * it will be moved into other.
+   */
+  ShapeTuple(std::vector<index_type> shape);  // NOLINT(*)
+
+  /*!
+   * \brief Return the data pointer
+   *
+   * \return const index_type* data pointer
+   */
+  const index_type* data() const { return get()->data; }
+
+  /*!
+   * \brief Return the size of the shape tuple
+   *
+   * \return size_t shape tuple size
+   */
+  size_t size() const { return get()->size; }
+
+  /*!
+   * \brief Immutably read i-th element from the shape tuple.
+   * \param idx The index
+   * \return the i-th element.
+   */
+  index_type operator[](size_t idx) const {
+    ICHECK(idx < this->size()) << "IndexError: indexing " << idx << " on an array of size "
+                               << this->size();
+    return this->data()[idx];
+  }
+
+  /*!
+   * \brief Immutably read i-th element from the shape tuple.
+   * \param idx The index
+   * \return the i-th element.
+   */
+  index_type at(size_t idx) const { return this->operator[](idx); }
+
+  /*! \return Whether shape tuple is empty */
+  bool empty() const { return size() == 0; }
+
+  /*! \return The first element of the shape tuple */
+  index_type front() const { return this->at(0); }
+
+  /*! \return The last element of the shape tuple */
+  index_type back() const { return this->at(this->size() - 1); }
+
+  /*! \return begin iterator */
+  const index_type* begin() const { return get()->data; }
+
+  /*! \return end iterator */
+  const index_type* end() const { return (get()->data + size()); }
+
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(ShapeTuple, ObjectRef, ShapeTupleObj);
+};
+
+inline ShapeTuple::ShapeTuple(std::vector<index_type> shape) {
+  auto ptr = make_object<ShapeTupleObj::FromStd>(std::move(shape));
+  ptr->size = ptr->data_container.size();
+  ptr->data = ptr->data_container.data();
+  data_ = std::move(ptr);
+}
+
+}  // namespace runtime
+
+// expose the functions to the root namespace.
+using runtime::ShapeTuple;
+using runtime::ShapeTupleObj;
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_CONTAINER_SHAPE_TUPLE_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/container/string.h b/darknet_drp_ros/include/tvm/runtime/container/string.h
new file mode 100644
index 0000000..5ecd89e
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/container/string.h
@@ -0,0 +1,484 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/container/string.h
+ * \brief Runtime String container types.
+ */
+#ifndef TVM_RUNTIME_CONTAINER_STRING_H_
+#define TVM_RUNTIME_CONTAINER_STRING_H_
+
+#include <dmlc/logging.h>
+#include <tvm/runtime/container/base.h>
+#include <tvm/runtime/logging.h>
+#include <tvm/runtime/memory.h>
+#include <tvm/runtime/object.h>
+
+#include <algorithm>
+#include <cstddef>
+#include <cstring>
+#include <initializer_list>
+#include <memory>
+#include <string>
+#include <string_view>
+#include <type_traits>
+#include <unordered_map>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+namespace runtime {
+
+// Forward declare TVMArgValue
+class TVMArgValue;
+
+/*! \brief An object representing string. It's POD type. */
+class StringObj : public Object {
+ public:
+  /*! \brief The pointer to string data. */
+  const char* data;
+
+  /*! \brief The length of the string object. */
+  uint64_t size;
+
+  static constexpr const uint32_t _type_index = TypeIndex::kRuntimeString;
+  static constexpr const char* _type_key = "runtime.String";
+  TVM_DECLARE_FINAL_OBJECT_INFO(StringObj, Object);
+
+ private:
+  /*! \brief String object which is moved from std::string container. */
+  class FromStd;
+
+  friend class String;
+};
+
+/*!
+ * \brief Reference to string objects.
+ *
+ * \code
+ *
+ * // Example to create runtime String reference object from std::string
+ * std::string s = "hello world";
+ *
+ * // You can create the reference from existing std::string
+ * String ref{std::move(s)};
+ *
+ * // You can rebind the reference to another string.
+ * ref = std::string{"hello world2"};
+ *
+ * // You can use the reference as hash map key
+ * std::unordered_map<String, int32_t> m;
+ * m[ref] = 1;
+ *
+ * // You can compare the reference object with other string objects
+ * assert(ref == "hello world", true);
+ *
+ * // You can convert the reference to std::string again
+ * string s2 = (string)ref;
+ *
+ * \endcode
+ */
+class String : public ObjectRef {
+ public:
+  /*!
+   * \brief Construct an empty string.
+   */
+  String() : String(std::string()) {}
+  /*!
+   * \brief Construct a new String object
+   *
+   * \param other The moved/copied std::string object
+   *
+   * \note If user passes const reference, it will trigger copy. If it's rvalue,
+   * it will be moved into other.
+   */
+  String(std::string other);  // NOLINT(*)
+
+  /*!
+   * \brief Construct a new String object
+   *
+   * \param other a char array.
+   */
+  String(const char* other)  // NOLINT(*)
+      : String(std::string(other)) {}
+
+  /*!
+   * \brief Construct a new null object
+   */
+  String(std::nullptr_t)  // NOLINT(*)
+      : ObjectRef(nullptr) {}
+
+  /*!
+   * \brief Change the value the reference object points to.
+   *
+   * \param other The value for the new String
+   *
+   */
+  inline String& operator=(std::string other);
+
+  /*!
+   * \brief Change the value the reference object points to.
+   *
+   * \param other The value for the new String
+   */
+  inline String& operator=(const char* other);
+
+  /*!
+   * \brief Compares this String object to other
+   *
+   * \param other The String to compare with.
+   *
+   * \return zero if both char sequences compare equal. negative if this appear
+   * before other, positive otherwise.
+   */
+  int compare(const String& other) const {
+    return memncmp(data(), other.data(), size(), other.size());
+  }
+
+  /*!
+   * \brief Compares this String object to other
+   *
+   * \param other The string to compare with.
+   *
+   * \return zero if both char sequences compare equal. negative if this appear
+   * before other, positive otherwise.
+   */
+  int compare(const std::string& other) const {
+    return memncmp(data(), other.data(), size(), other.size());
+  }
+
+  /*!
+   * \brief Compares this to other
+   *
+   * \param other The character array to compare with.
+   *
+   * \return zero if both char sequences compare equal. negative if this appear
+   * before other, positive otherwise.
+   */
+  int compare(const char* other) const {
+    return memncmp(data(), other, size(), std::strlen(other));
+  }
+
+  /*!
+   * \brief Returns a pointer to the char array in the string.
+   *
+   * \return const char*
+   */
+  const char* c_str() const { return get()->data; }
+
+  /*!
+   * \brief Return the length of the string
+   *
+   * \return size_t string length
+   */
+  size_t size() const {
+    const auto* ptr = get();
+    return ptr->size;
+  }
+
+  /*!
+   * \brief Return the length of the string
+   *
+   * \return size_t string length
+   */
+  size_t length() const { return size(); }
+
+  /*!
+   * \brief Retun if the string is empty
+   *
+   * \return true if empty, false otherwise.
+   */
+  bool empty() const { return size() == 0; }
+
+  /*!
+   * \brief Read an element.
+   * \param pos The position at which to read the character.
+   *
+   * \return The char at position
+   */
+  char at(size_t pos) const {
+    if (pos < size()) {
+      return data()[pos];
+    } else {
+      throw std::out_of_range("tvm::String index out of bounds");
+    }
+  }
+
+  /*!
+   * \brief Return the data pointer
+   *
+   * \return const char* data pointer
+   */
+  const char* data() const { return get()->data; }
+
+  /*!
+   * \brief Convert String to an std::string object
+   *
+   * \return std::string
+   */
+  operator std::string() const { return std::string{get()->data, size()}; }
+
+  /*!
+   * \brief Check if a TVMArgValue can be converted to String, i.e. it can be std::string or String
+   * \param val The value to be checked
+   * \return A boolean indicating if val can be converted to String
+   */
+  inline static bool CanConvertFrom(const TVMArgValue& val);
+
+  /*!
+   * \brief Hash the binary bytes
+   * \param data The data pointer
+   * \param size The size of the bytes.
+   * \return the hash value.
+   */
+  static size_t HashBytes(const char* data, size_t size) {
+    // This function falls back to string copy with c++11 compiler and is
+    // recommended to be compiled with c++14
+    return std::hash<std::string_view>()(std::string_view(data, size));
+  }
+
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(String, ObjectRef, StringObj);
+
+ private:
+  /*!
+   * \brief Compare two char sequence
+   *
+   * \param lhs Pointers to the char array to compare
+   * \param rhs Pointers to the char array to compare
+   * \param lhs_count Length of the char array to compare
+   * \param rhs_count Length of the char array to compare
+   * \return int zero if both char sequences compare equal. negative if this
+   * appear before other, positive otherwise.
+   */
+  static int memncmp(const char* lhs, const char* rhs, size_t lhs_count, size_t rhs_count);
+
+  /*!
+   * \brief Concatenate two char sequences
+   *
+   * \param lhs Pointers to the lhs char array
+   * \param lhs_size The size of the lhs char array
+   * \param rhs Pointers to the rhs char array
+   * \param rhs_size The size of the rhs char array
+   *
+   * \return The concatenated char sequence
+   */
+  static String Concat(const char* lhs, size_t lhs_size, const char* rhs, size_t rhs_size) {
+    std::string ret(lhs, lhs_size);
+    ret.append(rhs, rhs_size);
+    return String(ret);
+  }
+
+  // Overload + operator
+  friend String operator+(const String& lhs, const String& rhs);
+  friend String operator+(const String& lhs, const std::string& rhs);
+  friend String operator+(const std::string& lhs, const String& rhs);
+  friend String operator+(const String& lhs, const char* rhs);
+  friend String operator+(const char* lhs, const String& rhs);
+
+  friend struct tvm::runtime::ObjectEqual;
+};
+
+/*! \brief An object representing string moved from std::string. */
+class StringObj::FromStd : public StringObj {
+ public:
+  /*!
+   * \brief Construct a new FromStd object
+   *
+   * \param other The moved/copied std::string object
+   *
+   * \note If user passes const reference, it will trigger copy. If it's rvalue,
+   * it will be moved into other.
+   */
+  explicit FromStd(std::string other) : data_container{other} {}
+
+ private:
+  /*! \brief Container that holds the memory. */
+  std::string data_container;
+
+  friend class String;
+};
+
+inline String::String(std::string other) {
+  auto ptr = make_object<StringObj::FromStd>(std::move(other));
+  ptr->size = ptr->data_container.size();
+  ptr->data = ptr->data_container.data();
+  data_ = std::move(ptr);
+}
+
+inline String& String::operator=(std::string other) {
+  String replace{std::move(other)};
+  data_.swap(replace.data_);
+  return *this;
+}
+
+inline String& String::operator=(const char* other) { return operator=(std::string(other)); }
+
+inline String operator+(const String& lhs, const String& rhs) {
+  size_t lhs_size = lhs.size();
+  size_t rhs_size = rhs.size();
+  return String::Concat(lhs.data(), lhs_size, rhs.data(), rhs_size);
+}
+
+inline String operator+(const String& lhs, const std::string& rhs) {
+  size_t lhs_size = lhs.size();
+  size_t rhs_size = rhs.size();
+  return String::Concat(lhs.data(), lhs_size, rhs.data(), rhs_size);
+}
+
+inline String operator+(const std::string& lhs, const String& rhs) {
+  size_t lhs_size = lhs.size();
+  size_t rhs_size = rhs.size();
+  return String::Concat(lhs.data(), lhs_size, rhs.data(), rhs_size);
+}
+
+inline String operator+(const char* lhs, const String& rhs) {
+  size_t lhs_size = std::strlen(lhs);
+  size_t rhs_size = rhs.size();
+  return String::Concat(lhs, lhs_size, rhs.data(), rhs_size);
+}
+
+inline String operator+(const String& lhs, const char* rhs) {
+  size_t lhs_size = lhs.size();
+  size_t rhs_size = std::strlen(rhs);
+  return String::Concat(lhs.data(), lhs_size, rhs, rhs_size);
+}
+
+// Overload < operator
+inline bool operator<(const String& lhs, const std::string& rhs) { return lhs.compare(rhs) < 0; }
+
+inline bool operator<(const std::string& lhs, const String& rhs) { return rhs.compare(lhs) > 0; }
+
+inline bool operator<(const String& lhs, const String& rhs) { return lhs.compare(rhs) < 0; }
+
+inline bool operator<(const String& lhs, const char* rhs) { return lhs.compare(rhs) < 0; }
+
+inline bool operator<(const char* lhs, const String& rhs) { return rhs.compare(lhs) > 0; }
+
+// Overload > operator
+inline bool operator>(const String& lhs, const std::string& rhs) { return lhs.compare(rhs) > 0; }
+
+inline bool operator>(const std::string& lhs, const String& rhs) { return rhs.compare(lhs) < 0; }
+
+inline bool operator>(const String& lhs, const String& rhs) { return lhs.compare(rhs) > 0; }
+
+inline bool operator>(const String& lhs, const char* rhs) { return lhs.compare(rhs) > 0; }
+
+inline bool operator>(const char* lhs, const String& rhs) { return rhs.compare(lhs) < 0; }
+
+// Overload <= operator
+inline bool operator<=(const String& lhs, const std::string& rhs) { return lhs.compare(rhs) <= 0; }
+
+inline bool operator<=(const std::string& lhs, const String& rhs) { return rhs.compare(lhs) >= 0; }
+
+inline bool operator<=(const String& lhs, const String& rhs) { return lhs.compare(rhs) <= 0; }
+
+inline bool operator<=(const String& lhs, const char* rhs) { return lhs.compare(rhs) <= 0; }
+
+inline bool operator<=(const char* lhs, const String& rhs) { return rhs.compare(lhs) >= 0; }
+
+// Overload >= operator
+inline bool operator>=(const String& lhs, const std::string& rhs) { return lhs.compare(rhs) >= 0; }
+
+inline bool operator>=(const std::string& lhs, const String& rhs) { return rhs.compare(lhs) <= 0; }
+
+inline bool operator>=(const String& lhs, const String& rhs) { return lhs.compare(rhs) >= 0; }
+
+inline bool operator>=(const String& lhs, const char* rhs) { return lhs.compare(rhs) >= 0; }
+
+inline bool operator>=(const char* lhs, const String& rhs) { return rhs.compare(rhs) <= 0; }
+
+// Overload == operator
+inline bool operator==(const String& lhs, const std::string& rhs) { return lhs.compare(rhs) == 0; }
+
+inline bool operator==(const std::string& lhs, const String& rhs) { return rhs.compare(lhs) == 0; }
+
+inline bool operator==(const String& lhs, const String& rhs) { return lhs.compare(rhs) == 0; }
+
+inline bool operator==(const String& lhs, const char* rhs) { return lhs.compare(rhs) == 0; }
+
+inline bool operator==(const char* lhs, const String& rhs) { return rhs.compare(lhs) == 0; }
+
+// Overload != operator
+inline bool operator!=(const String& lhs, const std::string& rhs) { return lhs.compare(rhs) != 0; }
+
+inline bool operator!=(const std::string& lhs, const String& rhs) { return rhs.compare(lhs) != 0; }
+
+inline bool operator!=(const String& lhs, const String& rhs) { return lhs.compare(rhs) != 0; }
+
+inline bool operator!=(const String& lhs, const char* rhs) { return lhs.compare(rhs) != 0; }
+
+inline bool operator!=(const char* lhs, const String& rhs) { return rhs.compare(lhs) != 0; }
+
+inline std::ostream& operator<<(std::ostream& out, const String& input) {
+  out.write(input.data(), input.size());
+  return out;
+}
+
+inline int String::memncmp(const char* lhs, const char* rhs, size_t lhs_count, size_t rhs_count) {
+  if (lhs == rhs && lhs_count == rhs_count) return 0;
+
+  for (size_t i = 0; i < lhs_count && i < rhs_count; ++i) {
+    if (lhs[i] < rhs[i]) return -1;
+    if (lhs[i] > rhs[i]) return 1;
+  }
+  if (lhs_count < rhs_count) {
+    return -1;
+  } else if (lhs_count > rhs_count) {
+    return 1;
+  } else {
+    return 0;
+  }
+}
+
+inline size_t ObjectHash::operator()(const ObjectRef& a) const {
+  if (const auto* str = a.as<StringObj>()) {
+    return String::HashBytes(str->data, str->size);
+  }
+  return ObjectPtrHash()(a);
+}
+
+inline bool ObjectEqual::operator()(const ObjectRef& a, const ObjectRef& b) const {
+  if (a.same_as(b)) {
+    return true;
+  }
+  if (const auto* str_a = a.as<StringObj>()) {
+    if (const auto* str_b = b.as<StringObj>()) {
+      return String::memncmp(str_a->data, str_b->data, str_a->size, str_b->size) == 0;
+    }
+  }
+  return false;
+}
+}  // namespace runtime
+
+// expose the functions to the root namespace.
+using runtime::String;
+using runtime::StringObj;
+}  // namespace tvm
+
+namespace std {
+
+template <>
+struct hash<::tvm::runtime::String> {
+  std::size_t operator()(const ::tvm::runtime::String& str) const {
+    return ::tvm::runtime::String::HashBytes(str.data(), str.size());
+  }
+};
+}  // namespace std
+
+#endif  // TVM_RUNTIME_CONTAINER_STRING_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/contrib/libtorch_runtime.h b/darknet_drp_ros/include/tvm/runtime/contrib/libtorch_runtime.h
new file mode 100644
index 0000000..2645fb9
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/contrib/libtorch_runtime.h
@@ -0,0 +1,40 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \brief runtime implementation for LibTorch/TorchScript.
+ */
+#ifndef TVM_RUNTIME_CONTRIB_LIBTORCH_RUNTIME_H_
+#define TVM_RUNTIME_CONTRIB_LIBTORCH_RUNTIME_H_
+#include <tvm/runtime/module.h>
+
+#include <string>
+
+namespace tvm {
+namespace runtime {
+namespace contrib {
+
+runtime::Module TorchRuntimeCreate(const String& symbol_name,
+                                   const std::string& serialized_function);
+
+}  // namespace contrib
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_CONTRIB_LIBTORCH_RUNTIME_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/contrib/papi.h b/darknet_drp_ros/include/tvm/runtime/contrib/papi.h
new file mode 100644
index 0000000..ff2d75c
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/contrib/papi.h
@@ -0,0 +1,46 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+/*!
+ * \brief Performance counters for profiling via the PAPI library.
+ */
+#ifndef TVM_RUNTIME_CONTRIB_PAPI_H_
+#define TVM_RUNTIME_CONTRIB_PAPI_H_
+
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/map.h>
+#include <tvm/runtime/profiling.h>
+
+namespace tvm {
+namespace runtime {
+namespace profiling {
+
+/*! \brief Construct a metric collector that collects data from hardware
+ * performance counters using the Performance Application Programming Interface
+ * (PAPI).
+ *
+ * \param metrics A mapping from a device type to the metrics that should be
+ * collected on that device. You can find the names of available metrics by
+ * running `papi_native_avail`.
+ */
+TVM_DLL MetricCollector CreatePAPIMetricCollector(Map<DeviceWrapper, Array<String>> metrics);
+}  // namespace profiling
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_CONTRIB_PAPI_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/crt/aot_executor.h b/darknet_drp_ros/include/tvm/runtime/crt/aot_executor.h
new file mode 100644
index 0000000..c6a9f02
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/crt/aot_executor.h
@@ -0,0 +1,107 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file aot_executor.h
+ * \brief AoT Executor
+ */
+#ifndef TVM_RUNTIME_CRT_AOT_EXECUTOR_H_
+#define TVM_RUNTIME_CRT_AOT_EXECUTOR_H_
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include <dlpack/dlpack.h>
+#include <tvm/runtime/crt/internal/common/ndarray.h>
+#include <tvm/runtime/metadata_types.h>
+
+typedef struct TVMMetadata TVMMetadata;
+
+typedef struct TVMAotExecutor {
+  /*! \brief The top-level metadata structure supplied by the generated code */
+  const TVMMetadata* metadata;
+  /*! \brief The code module that contains the compiled model */
+  TVMModuleHandle module_handle;
+  /*! \brief The device type */
+  DLDevice device;
+  /*! \brief List of allocated arguments, input(s), output(s), and pool(s)*/
+  TVMNDArray* args;
+  int64_t num_args;
+} TVMAotExecutor;
+
+/*!
+ * \brief Allocate a new AotExecutor with TVMPlatformMemoryAllocate and initialize it.
+ *
+ * \param module_handle TVM Module that exposes the functions to call.
+ * \param device Runtime execution device, only supports device type kDLCPU, index 0.
+ * \param executor Pointer which receives a pointer to the newly-created instance.
+ * \param module_name TVM Module name prefix, typically "default".
+ * \return 0 if successful.
+ */
+int TVMAotExecutor_Create(TVMModuleHandle module_handle, const DLDevice device,
+                          TVMAotExecutor** executor, const char* module_name);
+
+/*!
+ * \brief Release the AoT executor created by TVMAotExecutor_Create().
+ *
+ * \param executor Pointer to executor instance, created by TVMAotExecutor_Create().
+ * \param device Runtime execution device, only supports device type kDLCPU, index 0.
+ * \return 0 if successful.
+ */
+int TVMAotExecutor_Release(TVMAotExecutor* executor, const DLDevice device);
+
+/*!
+ * \brief Return the number of inputs.
+ *
+ * \param executor Pointer to executor instance, created by TVMAotExecutor_Create().
+ * \return Number of inputs.
+ */
+int TVMAotExecutor_GetNumInputs(TVMAotExecutor* executor);
+
+/*!
+ * \brief Return the number of outputs.
+ *
+ * \param executor Pointer to executor instance, created by TVMAotExecutor_Create().
+ * \return Number of outputs.
+ */
+int TVMAotExecutor_GetNumOutputs(TVMAotExecutor* executor);
+
+/*!
+ * \brief Return the input index of the specified input name
+ *
+ * \param executor Pointer to executor instance, created by TVMAotExecutor_Create().
+ * \param name Input name for retrieving index.
+ * \return Input index.
+ */
+int TVMAotExecutor_GetInputIndex(TVMAotExecutor* executor, const char* name);
+
+/*!
+ * \brief Run the generated program.
+ *
+ * \param executor Pointer to executor instance, created by TVMAotExecutor_Create().
+ * \return 0 if successful.
+ */
+int TVMAotExecutor_Run(TVMAotExecutor* executor);
+
+#ifdef __cplusplus
+}  // extern "C"
+#endif
+
+#endif  // TVM_RUNTIME_CRT_AOT_EXECUTOR_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/crt/aot_executor_module.h b/darknet_drp_ros/include/tvm/runtime/crt/aot_executor_module.h
new file mode 100644
index 0000000..bd539c9
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/crt/aot_executor_module.h
@@ -0,0 +1,42 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file graph_executor.h
+ * \brief Tiny AoT executor
+ */
+#ifndef TVM_RUNTIME_CRT_AOT_EXECUTOR_MODULE_H_
+#define TVM_RUNTIME_CRT_AOT_EXECUTOR_MODULE_H_
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include <tvm/runtime/crt/error_codes.h>
+
+/*!
+ * \brief Register the "tvm.aot_executor.create" constructor PackedFunc.
+ */
+tvm_crt_error_t TVMAotExecutorModule_Register();
+
+#ifdef __cplusplus
+}  // extern "C"
+#endif
+
+#endif  // TVM_RUNTIME_CRT_AOT_EXECUTOR_MODULE_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/crt/crt.h b/darknet_drp_ros/include/tvm/runtime/crt/crt.h
new file mode 100644
index 0000000..8c9ef45
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/crt/crt.h
@@ -0,0 +1,48 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/crt/crt.h
+ * \brief Defines core life cycle functions used by CRT.
+ */
+
+#ifndef TVM_RUNTIME_CRT_CRT_H_
+#define TVM_RUNTIME_CRT_CRT_H_
+
+#include <inttypes.h>
+#include <tvm/runtime/crt/error_codes.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/*!
+ * \brief Initialize various data structures used by the runtime.
+ * Prior to calling this, any initialization needed to support TVMPlatformMemory* functions should
+ * be completed.
+ * \return An error code describing the outcome of initialization. Generally, initialization
+ *     is only expected to fail due to a misconfiguration.
+ */
+tvm_crt_error_t TVMInitializeRuntime();
+
+#ifdef __cplusplus
+}  // extern "C"
+#endif
+
+#endif  // TVM_RUNTIME_CRT_CRT_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/crt/error_codes.h b/darknet_drp_ros/include/tvm/runtime/crt/error_codes.h
new file mode 100644
index 0000000..2495cad
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/crt/error_codes.h
@@ -0,0 +1,110 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file include/tvm/runtime/crt/error_codes.h
+ * \brief Defines integral error codes returned by the CRT.
+ */
+#ifndef TVM_RUNTIME_CRT_ERROR_CODES_H_
+#define TVM_RUNTIME_CRT_ERROR_CODES_H_
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#define TVM_CRT_ERROR_CATEGORY_Pos 8
+#define TVM_CRT_ERROR_CATEGORY_Msk (0xff << TVM_CRT_ERROR_CATEGORY_Pos)
+#define TVM_CRT_ERROR_CODE_Pos 0
+#define TVM_CRT_ERROR_CODE_Msk (0xff << TVM_CRT_ERROR_CODE_Pos)
+
+#define DEFINE_TVM_CRT_ERROR(category, code) \
+  (((category) << TVM_CRT_ERROR_CATEGORY_Pos) | ((code) << TVM_CRT_ERROR_CODE_Pos))
+typedef enum {
+  kTvmErrorCategoryFunctionRegistry = 1,
+  kTvmErrorCategoryFraming = 2,
+  kTvmErrorCategoryWriteStream = 3,
+  kTvmErrorCategorySession = 4,
+  kTvmErrorCategoryPlatform = 5,
+  kTvmErrorCategoryGenerated = 6,
+  kTvmErrorCategoryExecutor = 7,
+  kTvmErrorCategoryFunctionCall = 8,
+  kTvmErrorCategoryTimeEvaluator = 9,
+} tvm_crt_error_category_t;
+
+typedef enum {
+  kTvmErrorNoError = 0,
+
+  // Function Registry
+  kTvmErrorFunctionNameNotFound = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryFunctionRegistry, 0),
+  kTvmErrorFunctionIndexInvalid = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryFunctionRegistry, 1),
+  kTvmErrorFunctionRegistryFull = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryFunctionRegistry, 2),
+  kTvmErrorFunctionAlreadyDefined = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryFunctionRegistry, 3),
+  kTvmErrorBufferTooSmall = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryFunctionRegistry, 4),
+
+  // Framing
+  kTvmErrorFramingInvalidState = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryFraming, 0),
+  kTvmErrorFramingShortPacket = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryFraming, 1),
+  kTvmErrorFramingInvalidEscape = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryFraming, 2),
+  kTvmErrorFramingPayloadOverflow = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryFraming, 3),
+  kTvmErrorFramingPayloadIncomplete = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryFraming, 4),
+
+  // Write stream
+  kTvmErrorWriteStreamShortWrite = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryWriteStream, 0),
+  kTvmErrorWriteStreamLongWrite = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryWriteStream, 1),
+
+  // Session
+  kTvmErrorSessionInvalidState = DEFINE_TVM_CRT_ERROR(kTvmErrorCategorySession, 0),
+  kTvmErrorSessionReceiveBufferBusy = DEFINE_TVM_CRT_ERROR(kTvmErrorCategorySession, 1),
+  kTvmErrorSessionReceiveBufferShortWrite = DEFINE_TVM_CRT_ERROR(kTvmErrorCategorySession, 2),
+
+  // Platform
+  kTvmErrorPlatformCheckFailure = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryPlatform, 0),
+  kTvmErrorPlatformMemoryManagerInitialized = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryPlatform, 1),
+  kTvmErrorPlatformShutdown = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryPlatform, 2),
+  kTvmErrorPlatformNoMemory = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryPlatform, 3),
+  kTvmErrorPlatformTimerBadState = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryPlatform, 4),
+  kTvmErrorPlatformStackAllocBadFree = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryPlatform, 5),
+
+  // Common error codes returned from generated functions.
+  kTvmErrorGeneratedInvalidStorageId = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryGenerated, 0),
+
+  // Graph or AoT executor
+  kTvmErrorExecutorModuleAlreadyCreated = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryExecutor, 0),
+  kTvmErrorExecutorModuleBadContext = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryExecutor, 1),
+  kTvmErrorExecutorModuleNoSuchInput = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryExecutor, 2),
+
+  // Function Calls - common problems encountered calling functions.
+  kTvmErrorFunctionCallNumArguments = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryFunctionCall, 0),
+  kTvmErrorFunctionCallWrongArgType = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryFunctionCall, 1),
+  kTvmErrorFunctionCallNotImplemented = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryFunctionCall, 2),
+  kTvmErrorFunctionCallInvalidArg = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryFunctionCall, 3),
+
+  // Time Evaluator - times functions for use with debug runtime.
+  kTvmErrorTimeEvaluatorBadHandle = DEFINE_TVM_CRT_ERROR(kTvmErrorCategoryTimeEvaluator, 0),
+
+  // System errors are always negative integers; this mask indicates presence of a system error.
+  // Cast tvm_crt_error_t to a signed integer to interpret the negative error code.
+  kTvmErrorSystemErrorMask = (1 << (sizeof(int) * 8 - 1)),
+} tvm_crt_error_t;
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif  // TVM_RUNTIME_CRT_ERROR_CODES_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/crt/func_registry.h b/darknet_drp_ros/include/tvm/runtime/crt/func_registry.h
new file mode 100644
index 0000000..50737f8
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/crt/func_registry.h
@@ -0,0 +1,162 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file include/tvm/runtime/crt/func_registry.h
+ * \brief Defines generic string-based function lookup structs
+ */
+#ifndef TVM_RUNTIME_CRT_FUNC_REGISTRY_H_
+#define TVM_RUNTIME_CRT_FUNC_REGISTRY_H_
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include <tvm/runtime/c_backend_api.h>
+#include <tvm/runtime/crt/error_codes.h>
+
+typedef uint16_t tvm_function_index_t;
+
+typedef uint16_t tvm_module_index_t;
+
+/*!
+ * \brief A data structure that facilitates function lookup by C-string name.
+ */
+typedef struct TVMFuncRegistry {
+  /*! \brief Names of registered functions, concatenated together and separated by \0.
+   * An additional \0 is present at the end of the concatenated blob to mark the end.
+   *
+   * Byte 0 and 1 are the number of functions in `funcs`.
+   */
+  const char* names;
+
+  /*! \brief Function pointers, in the same order as their names in `names`. */
+  const TVMBackendPackedCFunc* funcs;
+} TVMFuncRegistry;
+
+/*!
+ * \brief Get the of the number of functions from registry.
+ *
+ * \param reg TVMFunctionRegistry instance that contains the function.
+ * \return The number of functions from registry.
+ */
+uint16_t TVMFuncRegistry_GetNumFuncs(const TVMFuncRegistry* reg);
+
+/*!
+ * \brief Set the number of functions to registry.
+ *
+ * \param reg TVMFunctionRegistry instance that contains the function.
+ * \param num_funcs The number of functions
+ * \return 0 when successful.
+ */
+int TVMFuncRegistry_SetNumFuncs(const TVMFuncRegistry* reg, const uint16_t num_funcs);
+
+/*!
+ * \brief Get the address of 0th function from registry.
+ *
+ * \param reg TVMFunctionRegistry instance that contains the function.
+ * \return the address of 0th function from registry
+ */
+const char* TVMFuncRegistry_Get0thFunctionName(const TVMFuncRegistry* reg);
+
+/*!
+ * \brief Get packed function from registry by name.
+ *
+ * \param reg TVMFunctionRegistry instance that contains the function.
+, * \param name The function name
+ * \param function_index Pointer to receive the 0-based index of the function in the registry, if it
+ *     was found. Unmodified otherwise.
+ * \return kTvmErrorNoError when successful. kTvmErrorFunctionNameNotFound when no function matched
+`name`.
+ */
+tvm_crt_error_t TVMFuncRegistry_Lookup(const TVMFuncRegistry* reg, const char* name,
+                                       tvm_function_index_t* function_index);
+
+/*!
+ * \brief Fetch TVMBackendPackedCFunc given a function index
+ *
+ * \param reg TVMFunctionRegistry instance that contains the function.
+ * \param index Index of the function.
+ * \param out_func Pointer which receives the function pointer at `index`, if a valid
+ *      index was given. Unmodified otherwise.
+ * \return kTvmErrorNoError when successful. kTvmErrorFunctionIndexInvalid when index was out of
+ * range.
+ */
+tvm_crt_error_t TVMFuncRegistry_GetByIndex(const TVMFuncRegistry* reg, tvm_function_index_t index,
+                                           TVMBackendPackedCFunc* out_func);
+
+/*!
+ * \brief A TVMFuncRegistry that supports adding and changing the functions.
+ */
+typedef struct TVMMutableFuncRegistry {
+  TVMFuncRegistry registry;
+
+  /*! \brief maximum number of functions in this registry. */
+  size_t max_functions;
+} TVMMutableFuncRegistry;
+
+// Defined to work around compiler limitations.
+#define TVM_AVERAGE_FUNCTION_NAME_STRLEN_BYTES 10
+
+/*!
+ * \brief Size of an average function name in a TVMMutableFuncRegistry, in bytes.
+ *
+ * This is just an assumption made by the runtime for ease of use.
+ */
+static const size_t kTvmAverageFunctionNameStrlenBytes = TVM_AVERAGE_FUNCTION_NAME_STRLEN_BYTES;
+
+/*!
+ * \brief Size of an average entry in a TVMMutableFuncRegistry, in bytes.
+ *
+ * Assumes a constant average function name length.
+ */
+static const size_t kTvmAverageFuncEntrySizeBytes =
+    TVM_AVERAGE_FUNCTION_NAME_STRLEN_BYTES + 1 + sizeof(void*);
+
+/*!
+ * \brief Create a new mutable function registry from a block of memory.
+ *
+ * \param reg TVMMutableFuncRegistry to create.
+ * \param buffer Backing memory available for this function registry.
+ * \param buffer_size_bytes Number of bytes available in buffer.
+ * \return kTvmErrorNoError when successful. kTvmErrorBufferTooSmall when buffer_size_bytes is so
+ *      small that a single function cannot be registered.
+ */
+tvm_crt_error_t TVMMutableFuncRegistry_Create(TVMMutableFuncRegistry* reg, uint8_t* buffer,
+                                              size_t buffer_size_bytes);
+
+/*!
+ * \brief Add or set a function in the registry.
+ *
+ * \param reg The mutable function registry to affect.
+ * \param name Name of the function.
+ * \param func The function pointer.
+ * \param override non-zero if an existing entry should be overridden.
+ * \return kTvmErrorNoError when successful. kTvmErrorRegistryFull when `reg` already contains
+ *     `max_functions` entries. kTvmErrorFunctionAlreadyDefined when a function named `name` is
+ * already present in the registry, and `override` == 0.
+ */
+tvm_crt_error_t TVMMutableFuncRegistry_Set(TVMMutableFuncRegistry* reg, const char* name,
+                                           TVMBackendPackedCFunc func, int override);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif  // TVM_RUNTIME_CRT_FUNC_REGISTRY_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/crt/graph_executor.h b/darknet_drp_ros/include/tvm/runtime/crt/graph_executor.h
new file mode 100644
index 0000000..1353d8e
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/crt/graph_executor.h
@@ -0,0 +1,130 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file graph_executor.h
+ * \brief Tiny graph executor that can run graph containing only tvm PackedFunc.
+ */
+#ifndef TVM_RUNTIME_CRT_GRAPH_EXECUTOR_H_
+#define TVM_RUNTIME_CRT_GRAPH_EXECUTOR_H_
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include <dlpack/dlpack.h>
+#include <tvm/runtime/c_runtime_api.h>
+#include <tvm/runtime/crt/packed_func.h>
+
+struct TVMModule;
+
+/*! \brief operator attributes about tvm op */
+typedef struct TVMOpParam {
+  char func_name[TVM_CRT_MAX_STRLEN_FUNCTION_NAME];
+  uint32_t num_inputs;
+  uint32_t num_outputs;
+  uint32_t flatten_data;
+} TVMOpParam;
+
+// Graph attribute
+typedef struct TVMGraphExecutorGraphAttr {
+  uint32_t storage_num_not_alloctaed;
+  uint32_t* storage_id;
+  uint32_t* device_index;
+  char* dltype;  // "int8", "int16", "float32"
+  uint32_t dltype_count;
+  int64_t* shape;
+  uint32_t* ndim;
+  uint32_t shape_count;
+} TVMGraphExecutorGraphAttr;
+
+typedef struct TVMGraphExecutor TVMGraphExecutor;
+
+// public functions
+/*!
+ * \brief Allocate a new GraphExecutor with TVMPlatformMemoryAllocate and initialize it.
+ *
+ * \param sym_json JSON-encoded graph.
+ * \param module_handle TVM Module that exposes the functions to call.
+ * \param devices runtime execution device.
+ * \param executor Pointer which receives a pointer to the newly-created instance.
+ * \return 0 if successful.
+ */
+int TVMGraphExecutor_Create(const char* sym_json, TVMModuleHandle module_handle,
+                            const DLDevice* devices, TVMGraphExecutor** executor);
+
+int TVMGraphExecutor_GetInputIndex(TVMGraphExecutor* executor, const char* name);
+
+/*!
+ * \brief get number of input tensors allocated.
+ * \return integer number of tensors available to use.
+ */
+int TVMGraphExecutor_GetNumInputs();
+
+/*!
+ * \brief set input to the graph based on name.
+ * \param executor The graph executor.
+ * \param name The name of the input.
+ * \param data_in The input data.
+ */
+void TVMGraphExecutor_SetInput(TVMGraphExecutor* executor, const char* name, DLTensor* data_in);
+
+/*!
+ * \brief get number of output tensors allocated.
+ * \return integer number of output tensors allocated.
+ */
+int TVMGraphExecutor_GetNumOutputs();
+
+/*!
+ * \brief Return NDArray for given output index.
+ * \param executor The graph executor.
+ * \param index The output index.
+ * \param out The DLTensor corresponding to given output node index.
+ * \return The result of this function execution.
+ */
+int TVMGraphExecutor_GetOutput(TVMGraphExecutor* executor, const int32_t index, DLTensor* out);
+
+/*!
+ * \brief Load parameters from parameter blob.
+ * \param executor The graph executor.
+ * \param param_blob A binary blob of parameter.
+ * \param param_size The parameter size.
+ * \return The result of this function execution.
+ */
+int TVMGraphExecutor_LoadParams(TVMGraphExecutor* executor, const char* param_blob,
+                                const uint32_t param_size);
+
+/*!
+ * \brief Execute the graph.
+ * \param executor The graph executor.
+ */
+void TVMGraphExecutor_Run(TVMGraphExecutor* executor);
+
+/*!
+ * \brief Release memory associated with the graph executor.
+ * \param executor Pointer to graph executor.
+ * \return 0 if successful
+ */
+int TVMGraphExecutor_Release(TVMGraphExecutor** executor);
+
+#ifdef __cplusplus
+}  // extern "C"
+#endif
+
+#endif  // TVM_RUNTIME_CRT_GRAPH_EXECUTOR_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/crt/graph_executor_module.h b/darknet_drp_ros/include/tvm/runtime/crt/graph_executor_module.h
new file mode 100644
index 0000000..5eb3994
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/crt/graph_executor_module.h
@@ -0,0 +1,42 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file graph_executor_module.h
+ * \brief Tiny graph executor that can run graph containing only tvm PackedFunc.
+ */
+#ifndef TVM_RUNTIME_CRT_GRAPH_EXECUTOR_MODULE_H_
+#define TVM_RUNTIME_CRT_GRAPH_EXECUTOR_MODULE_H_
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include <tvm/runtime/crt/error_codes.h>
+
+/*!
+ * \brief Register the "tvm.graph_executor.create" constructor PackedFunc.
+ */
+tvm_crt_error_t TVMGraphExecutorModule_Register();
+
+#ifdef __cplusplus
+}  // extern "C"
+#endif
+
+#endif  // TVM_RUNTIME_CRT_GRAPH_EXECUTOR_MODULE_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/crt/logging.h b/darknet_drp_ros/include/tvm/runtime/crt/logging.h
new file mode 100644
index 0000000..6cedf1b
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/crt/logging.h
@@ -0,0 +1,105 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file runtime/crt/logging.h
+ * \brief A replacement of the dmlc logging system that avoids
+ *  the usage of GLOG and C++ headers
+ */
+
+#ifndef TVM_RUNTIME_CRT_LOGGING_H_
+#define TVM_RUNTIME_CRT_LOGGING_H_
+
+#include <tvm/runtime/crt/platform.h>
+
+#define TVM_CRT_LOG_LEVEL_DEBUG 3
+#define TVM_CRT_LOG_LEVEL_INFO 2
+#define TVM_CRT_LOG_LEVEL_WARN 1
+#define TVM_CRT_LOG_LEVEL_ERROR 0
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#if defined(_MSC_VER)
+void TVMLogf(const char* fmt, ...);
+#else
+void __attribute__((format(printf, 1, 2))) TVMLogf(const char* fmt, ...);
+#endif
+
+#define LOG(level, x, ...)          \
+  if (TVM_CRT_LOG_LEVEL >= level) { \
+    TVMLogf(x, ##__VA_ARGS__);      \
+  }
+
+#define LOG_ERROR(x, ...) LOG(TVM_CRT_LOG_LEVEL_ERROR, x, ##__VA_ARGS__)
+#define LOG_WARN(x, ...) LOG(TVM_CRT_LOG_LEVEL_WARN, x, ##__VA_ARGS__)
+#define LOG_INFO(x, ...) LOG(TVM_CRT_LOG_LEVEL_INFO, x, ##__VA_ARGS__)
+#define LOG_DEBUG(x, ...) LOG(TVM_CRT_LOG_LEVEL_DEBUG, x, ##__VA_ARGS__)
+
+#ifndef CHECK
+#define CHECK(x)                                                   \
+  do {                                                             \
+    if (!(x)) {                                                    \
+      LOG_ERROR(__FILE__ ":%d: Check failed: %s\n", __LINE__, #x); \
+      TVMPlatformAbort(kTvmErrorPlatformCheckFailure);             \
+    }                                                              \
+  } while (0)
+#endif
+
+#ifndef CHECK_BINARY_OP
+#define CHECK_BINARY_OP(op, x, y, fmt, ...)                                               \
+  do {                                                                                    \
+    if (!(x op y)) {                                                                      \
+      LOG_ERROR(__FILE__ ":%d: Check failed: %s %s %s: " fmt "\n", __LINE__, #x, #op, #y, \
+                ##__VA_ARGS__);                                                           \
+      TVMPlatformAbort(kTvmErrorPlatformCheckFailure);                                    \
+    }                                                                                     \
+  } while (0)
+#endif
+
+#ifndef CHECK_LT
+#define CHECK_LT(x, y, fmt, ...) CHECK_BINARY_OP(<, x, y, fmt, ##__VA_ARGS__)
+#endif
+
+#ifndef CHECK_GT
+#define CHECK_GT(x, y, fmt, ...) CHECK_BINARY_OP(>, x, y, fmt, ##__VA_ARGS__)
+#endif
+
+#ifndef CHECK_LE
+#define CHECK_LE(x, y, fmt, ...) CHECK_BINARY_OP(<=, x, y, fmt, ##__VA_ARGS__)
+#endif
+
+#ifndef CHECK_GE
+#define CHECK_GE(x, y, fmt, ...) CHECK_BINARY_OP(>=, x, y, fmt, ##__VA_ARGS__)
+#endif
+
+#ifndef CHECK_EQ
+#define CHECK_EQ(x, y, fmt, ...) CHECK_BINARY_OP(==, x, y, fmt, ##__VA_ARGS__)
+#endif
+
+#ifndef CHECK_NE
+#define CHECK_NE(x, y, fmt, ...) CHECK_BINARY_OP(!=, x, y, fmt, ##__VA_ARGS__)
+#endif
+
+#ifdef __cplusplus
+}  // extern "C"
+#endif
+
+#endif  // TVM_RUNTIME_CRT_LOGGING_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/crt/microtvm_rpc_server.h b/darknet_drp_ros/include/tvm/runtime/crt/microtvm_rpc_server.h
new file mode 100644
index 0000000..9a7ed54
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/crt/microtvm_rpc_server.h
@@ -0,0 +1,79 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file microtvm_rpc_server.h
+ * \brief MicroTVM RPC Server
+ */
+
+#ifndef TVM_RUNTIME_CRT_MICROTVM_RPC_SERVER_H_
+#define TVM_RUNTIME_CRT_MICROTVM_RPC_SERVER_H_
+
+#include <stdlib.h>
+#include <sys/types.h>
+#include <tvm/runtime/crt/error_codes.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/*! \brief TVM RPC channel write function.
+ *
+ * Tries to write `num_bytes` from `data` to the underlying channel.
+ * \param data Pointer to data to write.
+ * \param num_bytes Number of bytes avaiable in data.
+ * \return The number of bytes written.
+ */
+typedef ssize_t (*microtvm_rpc_channel_write_t)(void* context, const uint8_t* data,
+                                                size_t num_bytes);
+
+/*! \brief Opaque pointer type to TVM RPC Server. */
+typedef void* microtvm_rpc_server_t;
+
+/*! \brief Initialize the TVM RPC Server.
+ *
+ * Call this on device startup before calling anyother microtvm_rpc_server_ functions.
+ *
+ * \param write_func A callback function invoked by the TVM RPC Server to write data back to the
+ *                   host. Internally, the TVM RPC Server will block until all data in a reply
+ *                   packet has been written.
+ * \param write_func_ctx An opaque pointer passed to write_func when it is called.
+ * \return A pointer to the TVM RPC Server. The pointer is allocated in the same memory space as
+ *         the TVM workspace.
+ */
+microtvm_rpc_server_t MicroTVMRpcServerInit(microtvm_rpc_channel_write_t write_func,
+                                            void* write_func_ctx);
+
+/*! \brief Do any tasks suitable for the main thread, and maybe process new incoming data.
+ *
+ * \param server The TVM RPC Server pointer.
+ * \param new_data If not nullptr, a pointer to a buffer pointer, which should point at new input
+ *     data to process. On return, updated to point past data that has been consumed.
+ * \param new_data_size_bytes Points to the number of valid bytes in `new_data`. On return,
+ *     updated to the number of unprocessed bytes remaining in `new_data` (usually 0).
+ * \return An error code indicating the outcome of the server main loop iteration.
+ */
+tvm_crt_error_t MicroTVMRpcServerLoop(microtvm_rpc_server_t server, uint8_t** new_data,
+                                      size_t* new_data_size_bytes);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif  // TVM_RUNTIME_CRT_MICROTVM_RPC_SERVER_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/crt/module.h b/darknet_drp_ros/include/tvm/runtime/crt/module.h
new file mode 100644
index 0000000..2527667
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/crt/module.h
@@ -0,0 +1,56 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file include/tvm/runtime/crt/module.h
+ * \brief Runtime container of the functions
+ */
+#ifndef TVM_RUNTIME_CRT_MODULE_H_
+#define TVM_RUNTIME_CRT_MODULE_H_
+
+#include <tvm/runtime/c_backend_api.h>
+#include <tvm/runtime/crt/func_registry.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/*!
+ * \brief Module container of TVM.
+ */
+typedef struct TVMModule {
+  /*! \brief The function registry associated with this module. */
+  const TVMFuncRegistry* registry;
+} TVMModule;
+
+/*!
+ * \brief Create a new module handle from the given TVMModule instance.
+ * \param mod The module instance to register.
+ * \param out_handle Pointer to receive the newly-minted handle for this module.
+ * \return 0 on success, non-zero on error.
+ */
+int TVMModCreateFromCModule(const TVMModule* mod, TVMModuleHandle* out_handle);
+
+/*! \brief Entry point for the system lib module. */
+const TVMModule* TVMSystemLibEntryPoint(void);
+
+#ifdef __cplusplus
+}
+#endif
+#endif  // TVM_RUNTIME_CRT_MODULE_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/crt/packed_func.h b/darknet_drp_ros/include/tvm/runtime/crt/packed_func.h
new file mode 100644
index 0000000..83d961b
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/crt/packed_func.h
@@ -0,0 +1,78 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/crt/packed_func.h
+ * \brief Type-erased function used across TVM API.
+ */
+#ifndef TVM_RUNTIME_CRT_PACKED_FUNC_H_
+#define TVM_RUNTIME_CRT_PACKED_FUNC_H_
+
+#include <assert.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <tvm/runtime/c_runtime_api.h>
+#include <tvm/runtime/crt/module.h>
+#include <tvm/runtime/crt/platform.h>
+
+#include "crt_config.h"
+
+DLDataType String2DLDataType(const char* s);
+
+typedef struct TVMArgs {
+  TVMValue values[TVM_CRT_MAX_ARGS];
+  int tcodes[TVM_CRT_MAX_ARGS]; /* Data type should be identical to type_codes in TVMPackedCFunc */
+  uint32_t values_count;
+} TVMArgs;
+
+TVMArgs TVMArgs_Create(TVMValue* values, uint32_t* tcodes, uint32_t values_count);
+
+typedef struct TVMPackedFunc {
+  char name[200];
+  TVMFunctionHandle fexec;
+  TVMArgs args;
+  TVMArgs ret_value;
+  int (*Call)(struct TVMPackedFunc* pf);
+  void (*SetArgs)(struct TVMPackedFunc* pf, const struct TVMArgs* args);
+} TVMPackedFunc;
+
+int TVMPackedFunc_InitGlobalFunc(TVMPackedFunc* pf, const char* name, const TVMArgs* args);
+int TVMPackedFunc_InitModuleFunc(TVMPackedFunc* pf, TVMModuleHandle module, const char* name,
+                                 const TVMArgs* args);
+
+int TVMPackedFunc_Call(TVMPackedFunc* pf);
+
+void TVMPackedFunc_SetArgs(TVMPackedFunc* pf, const TVMArgs* args);
+
+inline TVMModuleHandle TVMArgs_AsModuleHandle(const TVMArgs* args, size_t index) {
+  if (index >= args->values_count) {
+    TVMPlatformAbort((tvm_crt_error_t)-1);
+  }
+
+  if (args->tcodes[index] != kTVMModuleHandle) {
+    TVMPlatformAbort((tvm_crt_error_t)-1);
+  }
+
+  return args->values[index].v_handle;
+}
+
+extern TVMPackedFunc* g_fexecs;
+extern uint32_t g_fexecs_count;
+
+#endif  // TVM_RUNTIME_CRT_PACKED_FUNC_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/crt/page_allocator.h b/darknet_drp_ros/include/tvm/runtime/crt/page_allocator.h
new file mode 100644
index 0000000..7a5de16
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/crt/page_allocator.h
@@ -0,0 +1,82 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/crt/page_allocator.h
+ * \brief An implementation of a dynamic memory allocator for microcontrollers.
+ */
+
+#ifndef TVM_RUNTIME_CRT_PAGE_ALLOCATOR_H_
+#define TVM_RUNTIME_CRT_PAGE_ALLOCATOR_H_
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include <stdlib.h>
+#include <tvm/runtime/c_runtime_api.h>
+#include <tvm/runtime/crt/error_codes.h>
+
+extern int vleak_size;
+
+typedef struct MemoryManagerInterface MemoryManagerInterface;
+
+struct MemoryManagerInterface {
+  /*!
+   * \brief Allocate a chunk of memory.
+   * \param interface Pointer to this structure.
+   * \param num_bytes Number of bytes requested.
+   * \param dev Execution device that will be used with the allocated memory. Must be {kDLCPU, 0}.
+   * \param out_ptr A pointer to which is written a pointer to the newly-allocated memory.
+   * \return kTvmErrorNoError if successful; a descriptive error code otherwise.
+   */
+  tvm_crt_error_t (*Allocate)(MemoryManagerInterface* interface, size_t num_bytes, DLDevice dev,
+                              void** out_ptr);
+
+  /*!
+   * \brief Free a chunk of previously-used memory.
+   *
+   * \param interface Pointer to this structure.
+   * \param ptr A pointer returned from TVMPlatformMemoryAllocate which should be free'd.
+   * \param dev Execution device passed to TVMPlatformMemoryAllocate. Fixed to {kDLCPU, 0}.
+   * \return kTvmErrorNoError if successful; a descriptive error code otherwise.
+   */
+  tvm_crt_error_t (*Free)(MemoryManagerInterface* interface, void* ptr, DLDevice dev);
+
+  /*! \brief Used in testing; the number of allocated objects. */
+  int vleak_size;
+};
+
+/*!
+ * Exposed for testing.
+ *
+ * \param manager Pointer, initialized with the new MemoryManager.
+ * \param memory_pool Pointer to the global memory pool used by the CRT.
+ * \param memory_pool_size_bytes Size of `memory_pool`, in bytes.
+ * \param page_size_bytes_log2 log2 of the page size, in bytes.
+ * \return kTvmErrorNoError on success.
+ */
+tvm_crt_error_t PageMemoryManagerCreate(MemoryManagerInterface** manager, uint8_t* memory_pool,
+                                        size_t memory_pool_size_bytes, size_t page_size_bytes_log2);
+
+#ifdef __cplusplus
+}  // extern "C"
+#endif
+
+#endif  // TVM_RUNTIME_CRT_PAGE_ALLOCATOR_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/crt/platform.h b/darknet_drp_ros/include/tvm/runtime/crt/platform.h
new file mode 100644
index 0000000..1bc610e
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/crt/platform.h
@@ -0,0 +1,146 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/crt/platform.h
+ * \brief The virtual memory manager for micro-controllers
+ */
+
+#ifndef TVM_RUNTIME_CRT_PLATFORM_H_
+#define TVM_RUNTIME_CRT_PLATFORM_H_
+
+#include <stdarg.h>
+#include <stddef.h>
+#include <tvm/runtime/c_runtime_api.h>
+#include <tvm/runtime/crt/error_codes.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/*! \brief Called when an internal error occurs and execution cannot continue.
+ *
+ * The platform should ideally restart or hang at this point.
+ *
+ * \param code An error code.
+ */
+#if defined(_MSC_VER)
+__declspec(noreturn) void TVMPlatformAbort(tvm_crt_error_t code);
+#else
+void __attribute__((noreturn)) TVMPlatformAbort(tvm_crt_error_t code);
+#endif
+
+/*! \brief Called by the microTVM RPC server to implement TVMLogf.
+ *
+ * Not required to be implemented when the RPC server is not linked into the binary. This
+ * function's signature matches that of vsnprintf, so trivial implementations can just call
+ * vsnprintf.
+ *
+ * \param out_buf A char buffer where the formatted string should be written.
+ * \param out_buf_size_bytes Number of bytes available for writing in out_buf.
+ * \param fmt The printf-style formatstring.
+ * \param args extra arguments to be formatted.
+ * \return number of bytes written.
+ */
+size_t TVMPlatformFormatMessage(char* out_buf, size_t out_buf_size_bytes, const char* fmt,
+                                va_list args);
+
+/*!
+ * \brief Allocate memory for use by TVM.
+ *
+ * When this function returns something other than kTvmErrorNoError, *out_ptr should not be modified
+ * and the caller is not obligated to call TVMPlatformMemoryFree in order to avoid a memory leak.
+ *
+ * \param num_bytes Number of bytes requested.
+ * \param dev Execution device that will be used with the allocated memory. Fixed to {kDLCPU, 0}.
+ * \param out_ptr A pointer to which is written a pointer to the newly-allocated memory.
+ * \return kTvmErrorNoError if successful; a descriptive error code otherwise.
+ */
+tvm_crt_error_t TVMPlatformMemoryAllocate(size_t num_bytes, DLDevice dev, void** out_ptr);
+
+/*!
+ * \brief Free memory used by TVM.
+ *
+ * \param ptr A pointer returned from TVMPlatformMemoryAllocate which should be free'd.
+ * \param dev Execution device passed to TVMPlatformMemoryAllocate. Fixed to {kDLCPU, 0}.
+ * \return kTvmErrorNoError if successful; a descriptive error code otherwise.
+ */
+tvm_crt_error_t TVMPlatformMemoryFree(void* ptr, DLDevice dev);
+
+/*! \brief Start a device timer.
+ *
+ * The device timer used must not be running.
+ *
+ * \return kTvmErrorNoError if successful; a descriptive error code otherwise.
+ */
+tvm_crt_error_t TVMPlatformTimerStart();
+
+/*! \brief Stop the running device timer and get the elapsed time (in microseconds).
+ *
+ * The device timer used must be running.
+ *
+ * \param elapsed_time_seconds Pointer to write elapsed time into.
+ *
+ * \return kTvmErrorNoError if successful; a descriptive error code otherwise.
+ */
+tvm_crt_error_t TVMPlatformTimerStop(double* elapsed_time_seconds);
+
+/*! \brief Platform-specific before measurement call.
+ *
+ * A function which is called before calling TVMFuncCall in the TimeEvaluator.
+ * Can be used, for example, to initialize reset global state which may affect the results of
+ * measurement.
+ *
+ * \return kTvmErrorNoError if successful; a descriptive error code otherwise.
+ */
+tvm_crt_error_t TVMPlatformBeforeMeasurement();
+
+/*! \brief Platform-specific after measurement call.
+ *
+ * A function which is called after calling TVMFuncCall in the TimeEvaluator.
+ * It is the counterpart of the TVMPlatformBeforeMeasurement function.
+ *
+ * \return kTvmErrorNoError if successful; a descriptive error code otherwise.
+ */
+tvm_crt_error_t TVMPlatformAfterMeasurement();
+
+/*! \brief Fill a buffer with random data.
+ *
+ * Cryptographically-secure random data is NOT required. This function is intended for use
+ * cases such as filling autotuning input tensors and choosing the nonce used for microTVM RPC.
+ *
+ * This function does not need to be implemented for inference tasks. It is used only by
+ * AutoTVM and the RPC server. When not implemented, an internal weak-linked stub is provided.
+ *
+ * Please take care that across successive resets, this function returns different sequences of
+ * values. If e.g. the random number generator is seeded with the same value, it may make it
+ * difficult for a host to detect device resets during autotuning or host-driven inference.
+ *
+ * \param buffer Pointer to the 0th byte to write with random data. `num_bytes` of random data
+ * should be written here.
+ * \param num_bytes Number of bytes to write.
+ * \return kTvmErrorNoError if successful; a descriptive error code otherwise.
+ */
+tvm_crt_error_t TVMPlatformGenerateRandom(uint8_t* buffer, size_t num_bytes);
+
+#ifdef __cplusplus
+}  // extern "C"
+#endif
+
+#endif  // TVM_RUNTIME_CRT_PLATFORM_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/crt/rpc_common/frame_buffer.h b/darknet_drp_ros/include/tvm/runtime/crt/rpc_common/frame_buffer.h
new file mode 100644
index 0000000..0d264e3
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/crt/rpc_common/frame_buffer.h
@@ -0,0 +1,72 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/crt/rpc_common/frame_buffer.h
+ * \brief Defines a buffer for use by the RPC framing layer.
+ */
+
+#ifndef TVM_RUNTIME_CRT_RPC_COMMON_FRAME_BUFFER_H_
+#define TVM_RUNTIME_CRT_RPC_COMMON_FRAME_BUFFER_H_
+
+#include <inttypes.h>
+#include <stdlib.h>
+
+namespace tvm {
+namespace runtime {
+namespace micro_rpc {
+
+class FrameBuffer {
+ public:
+  FrameBuffer(uint8_t* data, size_t data_size_bytes)
+      : data_{data}, capacity_{data_size_bytes}, num_valid_bytes_{0}, read_cursor_{0} {}
+
+  size_t Write(const uint8_t* data, size_t data_size_bytes);
+
+  size_t Read(uint8_t* data, size_t data_size_bytes);
+
+  size_t Peek(uint8_t* data, size_t data_size_bytes);
+
+  void Clear();
+
+  size_t ReadAvailable() const { return num_valid_bytes_ - read_cursor_; }
+
+  size_t Size() const { return num_valid_bytes_; }
+
+ private:
+  /*! \brief pointer to data buffer. */
+  uint8_t* data_;
+
+  /*! \brief The total number of bytes available in data_. Always a power of 2. */
+  size_t capacity_;
+
+  /*! \brief index into data_ of the next potentially-available byte in the buffer.
+   * The byte is available when tail_ != data_ + capacity_.
+   */
+  size_t num_valid_bytes_;
+
+  /*! \brief Read cursor position. */
+  size_t read_cursor_;
+};
+
+}  // namespace micro_rpc
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_CRT_RPC_COMMON_FRAME_BUFFER_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/crt/rpc_common/framing.h b/darknet_drp_ros/include/tvm/runtime/crt/rpc_common/framing.h
new file mode 100644
index 0000000..33f37a0
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/crt/rpc_common/framing.h
@@ -0,0 +1,270 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file framing.h
+ * \brief Framing for RPC.
+ */
+
+#ifndef TVM_RUNTIME_CRT_RPC_COMMON_FRAMING_H_
+#define TVM_RUNTIME_CRT_RPC_COMMON_FRAMING_H_
+
+#include <inttypes.h>
+#include <stddef.h>
+#include <tvm/runtime/crt/error_codes.h>
+#include <tvm/runtime/crt/rpc_common/write_stream.h>
+
+namespace tvm {
+namespace runtime {
+namespace micro_rpc {
+
+uint16_t crc16_compute(const uint8_t* data, size_t data_size_bytes, uint16_t* previous_crc);
+
+enum class Escape : uint8_t { kEscapeStart = 0xff, kEscapeNop = 0xfe, kPacketStart = 0xfd };
+
+class PacketFieldSizeBytes {
+ public:
+  static constexpr const size_t kPayloadLength = sizeof(uint32_t);
+  static constexpr const size_t kCrc = sizeof(uint16_t);
+};
+
+class Unframer {
+ public:
+  explicit Unframer(WriteStream* stream)
+      : stream_{stream},
+        state_{State::kFindPacketStart},
+        saw_escape_start_{false},
+        num_buffer_bytes_valid_{0} {}
+
+  /*!
+   * \brief Push data into unframer and try to decode one packet.
+   *
+   * This function will return when exactly one packet has been decoded. It may not consume all of
+   * `data` in this case, and valid bytes may remain at the end of data.
+   *
+   * \param data The new data to unframe and send downstream.
+   * \param data_size_bytes The number of valid bytes in data.
+   * \param bytes_consumed Pointer written with the number of bytes consumed from data.
+   * \return
+   *     - kTvmErrorNoError when successful -- continue writing data.
+   *     - kTvmErrorFramingInvalidState when the Unframer was in or enters an invalid state
+   *       (probably indicates memory corruption).
+   *     - kTvmErrorFramingShortPacket when a new packet started before the current one ended.
+   *     - kTvmErrorFramingInvalidEscape when an invalid escape sequence was seen
+   */
+  tvm_crt_error_t Write(const uint8_t* data, size_t data_size_bytes, size_t* bytes_consumed);
+
+  /*! \brief Reset unframer to initial state. */
+  void Reset();
+
+  /*! \brief Return an underestimate of the number of bytes needed from the wire. */
+  size_t BytesNeeded();
+
+ private:
+  tvm_crt_error_t FindPacketStart();
+  tvm_crt_error_t FindPacketLength();
+  tvm_crt_error_t FindPacketCrc();
+  tvm_crt_error_t FindCrcEnd();
+
+  bool IsBufferFull(size_t buffer_full_bytes) {
+    return num_buffer_bytes_valid_ >= buffer_full_bytes;
+  }
+
+  /*! \brief Consume input into buffer_ until buffer_ has buffer_full_bytes. */
+  tvm_crt_error_t AddToBuffer(size_t buffer_full_bytes, bool update_crc);
+
+  void ClearBuffer();
+
+  /*! \brief Unescape and consume input bytes, storing into buffer.
+   *
+   * \param buffer A buffer to fill with consumed, unescaped bytes.
+   * \param buffer_size_bytes Size of buffer, in bytes.
+   * \param bytes_filled A pointer to an accumulator to which is added the number of bytes written
+   *      to `buffer`.
+   * \param update_crc true when the CRC should be updated with the escaped bytes.
+   * \return
+   *     - kTvmErrorNoError if successful
+   *     - kTvmErrorFramingShortPacket if a start-of-packet escape code was encountered. If so,
+   *       *bytes_filled indicates the number of bytes before the Escape::kEscapeStart byte.
+   *     - kTvmErrorFramingInvalidEscape if an invalid escape sequence was seen.
+   *     - kTvmErrorWriteStreamShortWrite if the WriteStream passed to constructor's Write()
+   *       function returns 0.
+   *     - kTvmErrorWriteStreamShortWrite if the WriteStream passed to constructor's Write()
+   *       function returns an invalid positive number.
+   *     - Any negative value (i.e. with bits in kTvmErrorSystemErrorMask set) returned by the
+   *       WriteStream's Write() function.
+   */
+  tvm_crt_error_t ConsumeInput(uint8_t* buffer, size_t buffer_size_bytes, size_t* bytes_filled,
+                               bool update_crc);
+
+  WriteStream* stream_;
+
+  enum class State : uint8_t {
+    kFindPacketStart = 0,
+    kFindPacketLength = 1,
+    kFindPacketCrc = 2,
+    kFindCrcEnd = 3,
+  };
+  State state_;
+
+  const uint8_t* input_;
+  size_t input_size_bytes_;
+
+  bool saw_escape_start_;
+
+  /*! \brief unframe buffer, sized to the longest framing field. */
+  uint8_t buffer_[128];
+
+  /*! \brief number of bytes in buffer that are currently valid. */
+  size_t num_buffer_bytes_valid_;
+
+  /*! \brief number of payload bytes left to receive before the CRC begins. */
+  size_t num_payload_bytes_remaining_;
+
+  /*! \brief Running CRC value. */
+  uint16_t crc_;
+};
+
+class Framer {
+ public:
+  typedef ssize_t (*WriteFunc)(const uint8_t* data, size_t data_size_bytes);
+
+  explicit Framer(WriteStream* stream)
+      : stream_{stream}, state_{State::kReset}, num_payload_bytes_remaining_{0} {}
+
+  /*! \brief Frame and write a full packet.
+   * \param payload The entire packet payload.
+   * \param payload_size_bytes Number of bytes in the packet.
+   * \return
+   *     - kTvmErrorNoError when no error occurs
+   *     - kTvmErrorWriteStreamShortWrite if the WriteStream passed to constructor's Write()
+   *       function returns 0.
+   *     - kTvmErrorWriteStreamShortWrite if the WriteStream passed to constructor's Write()
+   *       function returns an invalid positive number.
+   *     - Any negative value (i.e. with bits in kTvmErrorSystemErrorMask set) returned by the
+   *       WriteStream's Write() function.
+   */
+  tvm_crt_error_t Write(const uint8_t* payload, size_t payload_size_bytes);
+
+  /*! \brief Start framing and writing a new packet to the wire.
+   *
+   * When transmitting payloads that are too large to be buffered, call this function first to send
+   * the packet header and length fields.
+   *
+   * \param payload_size_bytes Number of payload bytes included as part of this packet.
+   * \return
+   *     - kTvmErrorNoError when no error occurs
+   *     - kTvmErrorWriteStreamShortWrite if the WriteStream passed to constructor's Write()
+   *       function returns 0.
+   *     - kTvmErrorWriteStreamShortWrite if the WriteStream passed to constructor's Write()
+   *       function returns an invalid positive number.
+   *     - Any negative value (i.e. with bits in kTvmErrorSystemErrorMask set) returned by the
+   *       WriteStream's Write() function.
+   */
+  tvm_crt_error_t StartPacket(size_t payload_size_bytes);
+
+  /*! \brief Write payload data to the wire.
+   *
+   * When transmitting payloads that are too large to be buffered, call this function after calling
+   * StartPacket to escape and transmit framed payloads. This function can be called multiple times
+   * for a single packet.
+   *
+   * \param payload_chunk A piece of the packet payload.
+   * \param payload_chunk_size_bytes Number of valid bytes in payload_chunk.
+   * \return
+   *     - kTvmErrorNoError when no error occurs
+   *     - kTvmErrorFramingInvalidState when StartPacket() has not been called.
+   *     - kTvmErrorFramingPayloadOverflow when more bytes were requested to be written than were
+   *       declared in the payload_size_bytes parameter given to StartPacket().
+   *     - kTvmErrorWriteStreamShortWrite if the WriteStream passed to constructor's Write()
+   *       function returns 0.
+   *     - kTvmErrorWriteStreamShortWrite if the WriteStream passed to constructor's Write()
+   *       function returns an invalid positive number.
+   *     - Any negative value (i.e. with bits in kTvmErrorSystemErrorMask set) returned by the
+   *       WriteStream's Write() function.
+   */
+  tvm_crt_error_t WritePayloadChunk(const uint8_t* payload_chunk, size_t payload_chunk_size_bytes);
+
+  /* \brief Finish writing one packet by sending the CRC.
+   *
+   * When transmitting paylaods that are too large to be buffered, call this function after sending
+   * the entire payload using WritePayloadChunk.
+   *
+   * \return
+   *     - kTvmErrorNoError when no error occurs
+   *     - kTvmErrorFramingInvalidState when StartPacket() has not been called.
+   *     - kTvmErrorFramingPayloadIncomplete when less bytes were written using WritePayloadChunk()
+   *       than were declared in the payload_size_bytes parameter given to StartPacket().
+   *     - kTvmErrorWriteStreamShortWrite if the WriteStream passed to constructor's Write()
+   *       function returns 0.
+   *     - kTvmErrorWriteStreamShortWrite if the WriteStream passed to constructor's Write()
+   *       function returns an invalid positive number.
+   *     - Any negative value (i.e. with bits in kTvmErrorSystemErrorMask set) returned by the
+   *       WriteStream's Write() function.
+   */
+  tvm_crt_error_t FinishPacket();
+
+  /* \brief Reset state of the Framer. */
+  void Reset();
+
+ private:
+  /*! \brief Maximum size of stack-based buffer. */
+  static constexpr const size_t kMaxStackBufferSizeBytes = 128;
+
+  enum class State : uint8_t {
+    /*! \brief State entered at construction time or after write error, before first packet sent. */
+    kReset = 0,
+
+    /*! \brief State entered after a packet has successfully finished transmitting. */
+    kIdle = 1,
+
+    /*! \brief State entered when a packet payload or CRC needs to be transmitted. */
+    kTransmitPacketPayload = 2,
+  };
+
+  /*!
+   * \brief Escape data and write the result to wire, and update crc_.
+   *
+   * \param data Unescaped data to write.
+   * \param data_size_bytes Number of valid bytes in data.
+   * \param escape true if escaping should be applied.
+   * \param update_crc true if escaping should be applied.
+   * \return kTvmErrorNoError on success, negative value on error.
+   */
+  tvm_crt_error_t WriteAndCrc(const uint8_t* data, size_t data_size_bytes, bool escape,
+                              bool update_crc);
+
+  /*! \brief Called to write framed data to the transport. */
+  WriteStream* stream_;
+
+  /*! \brief State fo the Framer. */
+  State state_;
+
+  /*! \brief When state_ == kTransmitPacketPayload, number of payload bytes left to transmit. */
+  size_t num_payload_bytes_remaining_;
+
+  /*! \brief Running CRC value. */
+  uint16_t crc_;
+};
+
+}  // namespace micro_rpc
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_CRT_RPC_COMMON_FRAMING_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/crt/rpc_common/session.h b/darknet_drp_ros/include/tvm/runtime/crt/rpc_common/session.h
new file mode 100644
index 0000000..9bea4b0
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/crt/rpc_common/session.h
@@ -0,0 +1,256 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file session.h
+ * \brief RPC Session
+ */
+
+#ifndef TVM_RUNTIME_CRT_RPC_COMMON_SESSION_H_
+#define TVM_RUNTIME_CRT_RPC_COMMON_SESSION_H_
+
+#include <inttypes.h>
+#include <tvm/runtime/crt/error_codes.h>
+#include <tvm/runtime/crt/rpc_common/frame_buffer.h>
+#include <tvm/runtime/crt/rpc_common/framing.h>
+#include <tvm/runtime/crt/rpc_common/write_stream.h>
+
+namespace tvm {
+namespace runtime {
+namespace micro_rpc {
+
+enum class MessageType : uint8_t {
+  kStartSessionInit = 0x00,
+  kStartSessionReply = 0x01,
+  kTerminateSession = 0x02,
+  kLog = 0x03,
+  kNormal = 0x10,
+};
+
+#if defined(_MSC_VER)
+
+#pragma pack(push, 1)
+typedef struct SessionHeader {
+  uint16_t session_id;
+  MessageType message_type;
+} SessionHeader;
+#pragma pack(pop)
+
+#else
+
+typedef struct SessionHeader {
+  uint16_t session_id;
+  MessageType message_type;
+} __attribute__((packed)) SessionHeader;
+
+#endif
+
+/*!
+ * \brief CRT communication session management class.
+ * Assumes the following properties provided by the underlying transport:
+ *  - in-order delivery.
+ *  - reliable delivery.
+ *
+ * Specifically, designed for use with UARTs. Will probably work over semihosting, USB, and TCP;
+ * will probably not work reliably enough over UDP.
+ */
+class Session {
+ public:
+  /*! \brief Callback invoked when a full message is received.
+   *
+   * This function is called in the following situations:
+   *  - When a new session is established (this typically indicates the remote end reset).
+   *    In this case, buf is NULL.
+   *  - When a log message or normal traffic is received. In this case, buf points to a
+   *    valid buffer containing the message content.
+   *
+   * \param context The value of `message_received_func_context` passed to the constructor.
+   * \param message_type The type of session message received. Currently, this is always
+   *      either kNormal or kLog.
+   * \param buf When message_type is not kStartSessionMessage, a FrameBuffer whose read cursor is
+   *      at the first byte of the message payload. Otherwise, NULL.
+   */
+  typedef void (*MessageReceivedFunc)(void* context, MessageType message_type, FrameBuffer* buf);
+
+  /*! \brief An invalid nonce value that typically indicates an unknown nonce. */
+  static constexpr const uint8_t kInvalidNonce = 0;
+
+  Session(Framer* framer, FrameBuffer* receive_buffer, MessageReceivedFunc message_received_func,
+          void* message_received_func_context)
+      : local_nonce_{kInvalidNonce},
+        session_id_{0},
+        state_{State::kReset},
+        receiver_{this},
+        framer_{framer},
+        receive_buffer_{receive_buffer},
+        receive_buffer_has_complete_message_{false},
+        message_received_func_{message_received_func},
+        message_received_func_context_{message_received_func_context} {
+    // Session can be used for system startup logging, before the RPC server is instantiated. In
+    // this case, allow receive_buffer_ to be nullptr. The instantiator agrees not to use
+    // Receiver().
+    if (receive_buffer_ != nullptr) {
+      receive_buffer_->Clear();
+    }
+  }
+
+  /*!
+   * \brief Send a session terminate message, usually done at startup to interrupt a hanging remote.
+   * \param initial_session_nonce Initial nonce that should be used on the first session start
+   *      message. Callers should ensure this is different across device resets.
+   * \return kTvmErrorNoError on success, or an error code otherwise.
+   */
+  tvm_crt_error_t Initialize(uint8_t initial_session_nonce);
+
+  /*!
+   * \brief Terminate any previously-established session.
+   * \return kTvmErrorNoError on success, or an error code otherwise.
+   */
+  tvm_crt_error_t TerminateSession();
+
+  /*!
+   * \brief Start a new session regardless of state. Sends kStartSessionMessage.
+   *
+   * Generally speaking, this function should be called once per device reset by exactly one side
+   * in the system. No traffic can flow until this function is called.
+   *
+   * \return kTvmErrorNoError on success, or an error code otherwise.
+   */
+  tvm_crt_error_t StartSession();
+
+  /*!
+   * \brief Obtain a WriteStream implementation for use by the framing layer.
+   * \return A WriteStream to which received data should be written. Owned by this class.
+   */
+  WriteStream* Receiver() { return &receiver_; }
+
+  /*!
+   * \brief Send a full message including header, payload, and CRC footer.
+   * \param message_type One of MessageType; distinguishes the type of traffic at the session layer.
+   * \param message_data The data contained in the message.
+   * \param message_size_bytes The number of valid bytes in message_data.
+   * \return kTvmErrorNoError on success, or an error code otherwise.
+   */
+  tvm_crt_error_t SendMessage(MessageType message_type, const uint8_t* message_data,
+                              size_t message_size_bytes);
+
+  /*!
+   * \brief Send the framing and session layer headers.
+   *
+   * This function allows messages to be sent in pieces.
+   *
+   * \param message_type One of MessageType; distinguishes the type of traffic at the session layer.
+   * \param message_size_bytes The size of the message body, in bytes. Excludes the framing and
+   * session layer headers. \return 0 on success, negative error code on failure.
+   * \return kTvmErrorNoError on success, or an error code otherwise.
+   */
+  tvm_crt_error_t StartMessage(MessageType message_type, size_t message_size_bytes);
+
+  /*!
+   * \brief Send a part of the message body.
+   *
+   * This function allows messages to be sent in pieces.
+   *
+   * \param chunk_data The data contained in this message body chunk.
+   * \param chunk_size_bytes The number of valid bytes in chunk_data.
+   * \return kTvmErrorNoError on success, or an error code otherwise.
+   */
+  tvm_crt_error_t SendBodyChunk(const uint8_t* chunk_data, size_t chunk_size_bytes);
+
+  /*!
+   * \brief Finish sending the message by sending the framing layer footer.
+   * \return kTvmErrorNoError on success, or an error code otherwise.
+   */
+  tvm_crt_error_t FinishMessage();
+
+  /*! \brief Returns true if the session is in the established state. */
+  bool IsEstablished() const { return state_ == State::kSessionEstablished; }
+
+  /*!
+   * \brief Clear the receive buffer and prepare to receive next message.
+   *
+   * Call this function after MessageReceivedFunc is invoked. Any SessionReceiver::Write() calls
+   * made will return errors until this function is called to prevent them from corrupting the
+   * valid message in the receive buffer.
+   */
+  void ClearReceiveBuffer();
+
+  /*! \brief A version number used to check compatibility of the remote session implementation. */
+  static const constexpr uint8_t kVersion = 0x01;
+
+ private:
+  class SessionReceiver : public WriteStream {
+   public:
+    explicit SessionReceiver(Session* session) : session_{session} {}
+    virtual ~SessionReceiver() {}
+
+    ssize_t Write(const uint8_t* data, size_t data_size_bytes) override;
+    void PacketDone(bool is_valid) override;
+
+   private:
+    void operator delete(void*) noexcept {}  // NOLINT(readability/casting)
+    Session* session_;
+  };
+
+  enum class State : uint8_t {
+    kReset = 0,
+    kNoSessionEstablished = 1,
+    kStartSessionSent = 2,
+    kSessionEstablished = 3,
+  };
+
+  void RegenerateNonce();
+
+  tvm_crt_error_t SendInternal(MessageType message_type, const uint8_t* message_data,
+                               size_t message_size_bytes);
+
+  void SendSessionStartReply(const SessionHeader& header);
+
+  void ProcessStartSessionInit(const SessionHeader& header);
+
+  void ProcessStartSessionReply(const SessionHeader& header);
+
+  void OnSessionEstablishedMessage();
+
+  void OnSessionTerminatedMessage();
+
+  void SetSessionId(uint8_t initiator_nonce, uint8_t responder_nonce) {
+    session_id_ = initiator_nonce | (((uint16_t)responder_nonce) << 8);
+  }
+
+  uint8_t InitiatorNonce(uint16_t session_id) { return session_id & 0xff; }
+
+  uint8_t ResponderNonce(uint16_t session_id) { return (session_id >> 8) & 0xff; }
+
+  uint8_t local_nonce_;
+  uint16_t session_id_;
+  State state_;
+  SessionReceiver receiver_;
+  Framer* framer_;
+  FrameBuffer* receive_buffer_;
+  bool receive_buffer_has_complete_message_;
+  MessageReceivedFunc message_received_func_;
+  void* message_received_func_context_;
+};
+
+}  // namespace micro_rpc
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_CRT_RPC_COMMON_SESSION_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/crt/rpc_common/write_stream.h b/darknet_drp_ros/include/tvm/runtime/crt/rpc_common/write_stream.h
new file mode 100644
index 0000000..f72ba02
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/crt/rpc_common/write_stream.h
@@ -0,0 +1,52 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file framing.h
+ * \brief Framing for RPC.
+ */
+
+#ifndef TVM_RUNTIME_CRT_RPC_COMMON_WRITE_STREAM_H_
+#define TVM_RUNTIME_CRT_RPC_COMMON_WRITE_STREAM_H_
+
+#include <inttypes.h>
+#include <stddef.h>
+#include <sys/types.h>
+#include <tvm/runtime/crt/error_codes.h>
+
+#include "../../../../../src/support/ssize.h"
+
+namespace tvm {
+namespace runtime {
+namespace micro_rpc {
+
+class WriteStream {
+ public:
+  virtual ~WriteStream();
+  virtual ssize_t Write(const uint8_t* data, size_t data_size_bytes) = 0;
+  virtual void PacketDone(bool is_valid) = 0;
+
+  tvm_crt_error_t WriteAll(uint8_t* data, size_t data_size_bytes, size_t* bytes_consumed);
+};
+
+}  // namespace micro_rpc
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_CRT_RPC_COMMON_WRITE_STREAM_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/crt/stack_allocator.h b/darknet_drp_ros/include/tvm/runtime/crt/stack_allocator.h
new file mode 100644
index 0000000..4184dff
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/crt/stack_allocator.h
@@ -0,0 +1,107 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+// LINT_C_FILE
+#ifndef TVM_RUNTIME_CRT_STACK_ALLOCATOR_H_
+#define TVM_RUNTIME_CRT_STACK_ALLOCATOR_H_
+#include <stddef.h>
+#include <stdint.h>
+
+#include "crt_config.h"
+#include "error_codes.h"
+
+#define STACK_ALLOCATOR_TAG 0xabcd1234
+#define STACK_ALLOCATOR_TAG_SIZE_BYTES 4
+
+/*! Memory alignment for allocator */
+
+#ifndef TVM_RUNTIME_ALLOC_ALIGNMENT_BYTES
+#define TVM_RUNTIME_ALLOC_ALIGNMENT_BYTES 16
+#endif
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+typedef struct {
+  uint8_t* next_alloc;    // Pointer to the next block of TVM_RUNTIME_ALLOC_ALIGNMENT_BYTES
+  uint8_t* workspace;     // Pointer to start of the workspace
+  size_t workspace_size;  // Total number of bytes in the workspace
+} tvm_workspace_t;
+
+/*!
+ * \brief Initialize the stack-based memory manager
+ *
+ * \param tvm_runtime_workspace The tvm_workspace_t struct containing state
+ * \param g_aot_memory The memory buffer used to allocate within
+ * \param workspace_size The total size of the workspace buffer workspace
+ */
+tvm_crt_error_t StackMemoryManager_Init(tvm_workspace_t* tvm_runtime_workspace,
+                                        uint8_t* g_aot_memory, size_t workspace_size);
+
+/*!
+ * \brief The intended user-facing function to allocate within the buffer. It wraps
+ * StackMemoryManager_Allocate_Body enable and disable the LIFO check that is useful for debugging
+ * the AoT codegen.
+ *
+ * \param tvm_runtime_workspace The tvm_workspace_t struct containing state
+ * \param nbytes The number of bytes required for the allocation
+ * \param current_alloc The pointer-to-pointer to be populated with the allocated address
+ */
+tvm_crt_error_t StackMemoryManager_Allocate(tvm_workspace_t* tvm_runtime_workspace, int32_t nbytes,
+                                            void** current_alloc);
+
+/*!
+ * \brief The internal function that accepts allocate inputs and an extra byte to say to enable the
+ * LIFO check that is useful in debugging for debugging the AoT codegen.
+ *
+ * \param tvm_runtime_workspace The tvm_workspace_t struct containing state
+ * \param nbytes The number of bytes required for the allocation
+ * \param current_alloc The pointer-to-pointer to be populated with the allocated address
+ * \param do_lifo_check This being non-zero indicates to perform a check LIFO pattern Allocs/Frees
+ */
+tvm_crt_error_t StackMemoryManager_Allocate_Body(tvm_workspace_t* tvm_runtime_workspace,
+                                                 int32_t nbytes, void** current_alloc,
+                                                 uint8_t do_lifo_check);
+
+/*!
+ * \brief The intended user-facing function to free the tensor within the buffer. It wraps
+ * StackMemoryManager_Free_Body enable and disable the stack allocator
+ *
+ * \param tvm_runtime_workspace The tvm_workspace_t struct containing state
+ * \param ptr The base pointer of the tensor to be free'd
+ */
+tvm_crt_error_t StackMemoryManager_Free(tvm_workspace_t* tvm_runtime_workspace, void* ptr);
+
+/*!
+ * \brief The internal function that accepts free inputs and an extra byte to say to enable the LIFO
+ * check that is useful in debugging for debugging the AoT codegen.
+ *
+ * \param tvm_runtime_workspace The tvm_workspace_t struct containing state
+ * \param ptr The base pointer of tensor to be free'd within the workspace buffer
+ * \param do_lifo_check This being non-zero indicates to perform a check LIFO pattern Allocs/Frees
+ */
+tvm_crt_error_t StackMemoryManager_Free_Body(tvm_workspace_t* tvm_runtime_workspace, void* ptr,
+                                             uint8_t do_lifo_check);
+
+#ifdef __cplusplus
+}  // extern "C"
+#endif
+
+#endif  // TVM_RUNTIME_CRT_STACK_ALLOCATOR_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/data_type.h b/darknet_drp_ros/include/tvm/runtime/data_type.h
new file mode 100644
index 0000000..0891477
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/data_type.h
@@ -0,0 +1,416 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+/*
+ * \file tvm/runtime/data_type.h
+ * \brief Primitive runtime data type.
+ */
+// Acknowledgement: DataType structure design originates from Halide.
+#ifndef TVM_RUNTIME_DATA_TYPE_H_
+#define TVM_RUNTIME_DATA_TYPE_H_
+
+#include <tvm/runtime/c_runtime_api.h>
+#include <tvm/runtime/logging.h>
+
+#include <string>
+#include <type_traits>
+
+namespace tvm {
+namespace runtime {
+/*!
+ * \brief Runtime primitive data type.
+ *
+ *  This class is a thin wrapper of DLDataType.
+ *  We also make use of DataType in compiler to store quick hint
+ */
+class DataType {
+ public:
+  /*!
+   * \brief Type code for the DataType.
+   *
+   * DLPack consistency:
+   * 1) kInt is consistent with kDLInt
+   * 2) kUInt is consistent with kDLUInt
+   * 3) kFloat is consistent with kDLFloat
+   */
+  enum TypeCode {
+    kInt = kDLInt,
+    kUInt = kDLUInt,
+    kFloat = kDLFloat,
+    kHandle = TVMArgTypeCode::kTVMOpaqueHandle,
+    kBFloat = kDLBfloat,
+    kCustomBegin = 129
+  };
+  /*! \brief default constructor */
+  DataType() { data_ = DataType::Void(); }
+  /*!
+   * \brief Constructor
+   * \param dtype The DLDataType
+   */
+  explicit DataType(DLDataType dtype) : data_(dtype) {}
+  /*!
+   * \brief Constructor
+   * \param code The type code.
+   * \param bits The number of bits in the type.
+   * \param lanes The number of lanes.
+   */
+  DataType(int code, int bits, int lanes) {
+    data_.code = static_cast<uint8_t>(code);
+    data_.bits = static_cast<uint8_t>(bits);
+    data_.lanes = static_cast<uint16_t>(lanes);
+    if (code == kBFloat) {
+      ICHECK_EQ(bits, 16);
+    }
+  }
+  /*! \return The type code. */
+  int code() const { return static_cast<int>(data_.code); }
+  /*! \return number of bits in the data. */
+  int bits() const { return static_cast<int>(data_.bits); }
+  /*! \return number of bytes to store each scalar. */
+  int bytes() const { return (bits() + 7) / 8; }
+  /*! \return number of lanes in the data. */
+  int lanes() const { return static_cast<int>(data_.lanes); }
+  /*! \return whether type is a scalar type. */
+  bool is_scalar() const { return lanes() == 1; }
+  /*! \return whether type is a scalar type. */
+  bool is_bool() const { return code() == DataType::kUInt && bits() == 1; }
+  /*! \return whether type is a float type. */
+  bool is_float() const { return code() == DataType::kFloat; }
+  /*! \return whether type is a float16 type. */
+  bool is_float16() const { return is_float() && bits() == 16; }
+  /*! \return whether type is a bfloat16 type. */
+  bool is_bfloat16() const { return code() == DataType::kBFloat && bits() == 16; }
+  /*! \return whether type is an int type. */
+  bool is_int() const { return code() == DataType::kInt; }
+  /*! \return whether type is an uint type. */
+  bool is_uint() const { return code() == DataType::kUInt; }
+  /*! \return whether type is a handle type. */
+  bool is_handle() const { return code() == DataType::kHandle && !is_void(); }
+  /*! \return whether type is a vector type. */
+  bool is_vector() const { return lanes() > 1; }
+  /*! \return whether type is a bool vector type. */
+  bool is_vector_bool() const { return is_vector() && bits() == 1; }
+  /*! \return whether type is a Void type. */
+  bool is_void() const { return code() == DataType::kHandle && bits() == 0 && lanes() == 0; }
+  /*!
+   * \brief Create a new data type by change lanes to a specified value.
+   * \param lanes The target number of lanes.
+   * \return the result type.
+   */
+  DataType with_lanes(int lanes) const { return DataType(data_.code, data_.bits, lanes); }
+  /*!
+   * \brief Create a new data type by change bits to a specified value.
+   * \param bits The target number of bits.
+   * \return the result type.
+   */
+  DataType with_bits(int bits) const { return DataType(data_.code, bits, data_.lanes); }
+  /*!
+   * \brief Get the scalar version of the type.
+   * \return the result type.
+   */
+  DataType element_of() const { return with_lanes(1); }
+  /*!
+   * \brief Assignment operator.
+   */
+  DataType& operator=(const DataType& rhs) {
+    if (this == &rhs) {
+      return *this;
+    }
+    data_ = rhs.data_;
+    return *this;
+  }
+  /*!
+   * \brief Equal comparator.
+   * \param other The data type to compare against.
+   * \return The comparison result.
+   */
+  bool operator==(const DataType& other) const {
+    return data_.code == other.data_.code && data_.bits == other.data_.bits &&
+           data_.lanes == other.data_.lanes;
+  }
+  /*!
+   * \brief NotEqual comparator.
+   * \param other The data type to compare against.
+   * \return The comparison result.
+   */
+  bool operator!=(const DataType& other) const { return !operator==(other); }
+  /*!
+   * \brief Converter to DLDataType
+   * \return the result.
+   */
+  operator DLDataType() const { return data_; }
+
+  /*!
+   * \brief Construct an int type.
+   * \param bits The number of bits in the type.
+   * \param lanes The number of lanes.
+   * \return The constructed data type.
+   */
+  static DataType Int(int bits, int lanes = 1) { return DataType(kDLInt, bits, lanes); }
+  /*!
+   * \brief Construct an uint type.
+   * \param bits The number of bits in the type.
+   * \param lanes The number of lanes
+   * \return The constructed data type.
+   */
+  static DataType UInt(int bits, int lanes = 1) { return DataType(kDLUInt, bits, lanes); }
+  /*!
+   * \brief Construct an float type.
+   * \param bits The number of bits in the type.
+   * \param lanes The number of lanes
+   * \return The constructed data type.
+   */
+  static DataType Float(int bits, int lanes = 1) { return DataType(kDLFloat, bits, lanes); }
+  /*!
+   * \brief Construct an bfloat type.
+   * \param bits The number of bits in the type.
+   * \param lanes The number of lanes
+   * \return The constructed data type.
+   */
+  static DataType BFloat(int bits, int lanes = 1) { return DataType(kDLBfloat, bits, lanes); }
+  /*!
+   * \brief Construct a bool type.
+   * \param lanes The number of lanes
+   * \return The constructed data type.
+   */
+  static DataType Bool(int lanes = 1) { return DataType::UInt(1, lanes); }
+  /*!
+   * \brief Construct a handle type.
+   * \param bits The number of bits in the type.
+   * \param lanes The number of lanes
+   * \return The constructed data type.
+   */
+  static DataType Handle(int bits = 64, int lanes = 1) { return DataType(kHandle, bits, lanes); }
+  /*!
+   * \brief Construct a Void type.
+   * \return The constructed data type.
+   */
+  static DataType Void() { return DataType(kHandle, 0, 0); }
+  /*!
+   * \brief Get the corresponding type of TVMShapeIndex.
+   * \return The type of TVM shape index.
+   */
+  static DataType ShapeIndex() {
+    if (std::is_signed<tvm_index_t>::value) {
+      return DataType::Int(sizeof(tvm_index_t) * 8);
+    } else {
+      return DataType::UInt(sizeof(tvm_index_t) * 8);
+    }
+  }
+
+ private:
+  DLDataType data_;
+};
+
+/*!
+ * \brief Get the number of bytes needed in a vector.
+ * \param dtype The data type.
+ * \return Number of bytes needed.
+ */
+inline int GetVectorBytes(DataType dtype) {
+  int data_bits = dtype.bits() * dtype.lanes();
+  // allow bool to exist
+  if (dtype == DataType::Bool() || dtype == DataType::Int(4) || dtype == DataType::UInt(4) ||
+      dtype == DataType::Int(1)) {
+    return 1;
+  }
+  ICHECK_EQ(data_bits % 8, 0U) << "Need to load/store by multiple of bytes";
+  return data_bits / 8;
+}
+
+/*!
+ * \brief Check whether type matches the given spec.
+ * \param t The type
+ * \param code The type code.
+ * \param bits The number of bits to be matched.
+ * \param lanes The number of lanes in the type.
+ */
+inline bool TypeMatch(DLDataType t, int code, int bits, int lanes = 1) {
+  return t.code == code && t.bits == bits && t.lanes == lanes;
+}
+/*!
+ * \brief Check whether two types are equal .
+ * \param lhs The left operand.
+ * \param rhs The right operand.
+ */
+inline bool TypeEqual(DLDataType lhs, DLDataType rhs) {
+  return lhs.code == rhs.code && lhs.bits == rhs.bits && lhs.lanes == rhs.lanes;
+}
+
+/*!
+ * \brief Runtime utility for getting custom type name from code
+ * \param type_code Custom type code
+ * \return Custom type name
+ */
+TVM_DLL std::string GetCustomTypeName(uint8_t type_code);
+
+/*!
+ * \brief Runtime utility for checking whether custom type is registered
+ * \param type_code Custom type code
+ * \return Bool representing whether type is registered
+ */
+TVM_DLL bool GetCustomTypeRegistered(uint8_t type_code);
+
+/*!
+ * \brief Runtime utility for parsing string of the form "custom[<typename>]"
+ * \param s String to parse
+ * \param scan pointer to parsing pointer, which is scanning across s
+ * \return type code of custom type parsed
+ */
+TVM_DLL uint8_t ParseCustomDatatype(const std::string& s, const char** scan);
+
+/*!
+ * \brief Convert type code to its name
+ * \param type_code The type code .
+ * \return The name of type code.
+ */
+inline const char* DLDataTypeCode2Str(DLDataTypeCode type_code);
+
+/*!
+ * \brief convert a string to TVM type.
+ * \param s The string to be converted.
+ * \return The corresponding tvm type.
+ */
+inline DLDataType String2DLDataType(std::string s);
+
+/*!
+ * \brief convert a TVM type to string.
+ * \param t The type to be converted.
+ * \return The corresponding tvm type in string.
+ */
+inline std::string DLDataType2String(DLDataType t);
+
+// implementation details
+inline const char* DLDataTypeCode2Str(DLDataTypeCode type_code) {
+  switch (static_cast<int>(type_code)) {
+    case kDLInt:
+      return "int";
+    case kDLUInt:
+      return "uint";
+    case kDLFloat:
+      return "float";
+    case DataType::kHandle:
+      return "handle";
+    case kDLBfloat:
+      return "bfloat";
+    default:
+      LOG(FATAL) << "unknown type_code=" << static_cast<int>(type_code);
+  }
+}
+
+inline std::ostream& operator<<(std::ostream& os, DLDataType t) {  // NOLINT(*)
+  if (t.bits == 1 && t.lanes == 1 && t.code == kDLUInt) {
+    os << "bool";
+    return os;
+  }
+  if (DataType(t).is_void()) {
+    return os << "void";
+  }
+  if (t.code < DataType::kCustomBegin) {
+    os << DLDataTypeCode2Str(static_cast<DLDataTypeCode>(t.code));
+  } else {
+    os << "custom[" << GetCustomTypeName(t.code) << "]";
+  }
+  if (t.code == kTVMOpaqueHandle) return os;
+  os << static_cast<int>(t.bits);
+  if (t.lanes != 1) {
+    os << 'x' << static_cast<int>(t.lanes);
+  }
+  return os;
+}
+
+inline std::ostream& operator<<(std::ostream& os, const DataType& dtype) {  // NOLINT(*)
+  return os << dtype.operator DLDataType();
+}
+
+inline std::string DLDataType2String(DLDataType t) {
+  if (t.bits == 0) return "";
+  std::ostringstream os;
+  os << t;
+  return os.str();
+}
+
+inline DLDataType String2DLDataType(std::string s) {
+  DLDataType t;
+  // handle void type
+  if (s.length() == 0) {
+    t = DataType::Void();
+    return t;
+  }
+  t.bits = 32;
+  t.lanes = 1;
+  const char* scan;
+  if (s.substr(0, 3) == "int") {
+    t.code = kDLInt;
+    scan = s.c_str() + 3;
+  } else if (s.substr(0, 4) == "uint") {
+    t.code = kDLUInt;
+    scan = s.c_str() + 4;
+  } else if (s.substr(0, 5) == "float") {
+    t.code = kDLFloat;
+    scan = s.c_str() + 5;
+  } else if (s.substr(0, 6) == "handle") {
+    t.code = kTVMOpaqueHandle;
+    t.bits = 64;  // handle uses 64 bit by default.
+    scan = s.c_str() + 6;
+  } else if (s == "bool") {
+    t.code = kDLUInt;
+    t.bits = 1;
+    t.lanes = 1;
+    return t;
+  } else if (s.substr(0, 6) == "bfloat") {
+    t.code = DataType::kBFloat;
+    scan = s.c_str() + 6;
+  } else if (s.substr(0, 6) == "custom") {
+    t.code = ParseCustomDatatype(s, &scan);
+  } else {
+    scan = s.c_str();
+    LOG(FATAL) << "unknown type " << s;
+  }
+  char* xdelim;  // emulate sscanf("%ux%u", bits, lanes)
+  uint8_t bits = static_cast<uint8_t>(strtoul(scan, &xdelim, 10));
+  if (bits != 0) t.bits = bits;
+  char* endpt = xdelim;
+  if (*xdelim == 'x') {
+    t.lanes = static_cast<uint16_t>(strtoul(xdelim + 1, &endpt, 10));
+  }
+  ICHECK(endpt == s.c_str() + s.length()) << "unknown type " << s;
+  return t;
+}
+
+}  // namespace runtime
+
+using DataType = runtime::DataType;
+
+}  // namespace tvm
+
+namespace std {
+template <>
+struct hash<tvm::DataType> {
+  inline int cantor_pairing_function(int a, int b) const { return (a + b) * (a + b + 1) / 2 + b; }
+  std::size_t operator()(tvm::DataType const& dtype) const {
+    int a = dtype.code();
+    int b = dtype.bits();
+    int c = dtype.lanes();
+    int d = cantor_pairing_function(a, b);
+    return cantor_pairing_function(c, d);
+  }
+};
+}  // namespace std
+
+#endif  //  TVM_RUNTIME_DATA_TYPE_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/debug.h b/darknet_drp_ros/include/tvm/runtime/debug.h
new file mode 100644
index 0000000..29d812b
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/debug.h
@@ -0,0 +1,54 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/debug.h
+ * \brief Helpers for debugging at runtime.
+ */
+#ifndef TVM_RUNTIME_DEBUG_H_
+#define TVM_RUNTIME_DEBUG_H_
+
+#include <tvm/runtime/container/adt.h>
+#include <tvm/runtime/ndarray.h>
+
+#include <ostream>
+#include <string>
+
+namespace tvm {
+namespace runtime {
+
+/*!
+ * \brief Helpers to describe runtime objects in human-friendly form. For \p nd_arrays we show their
+ * shapes and dtypes, but also their contents if 'small' and on the \p host_device (mostly so that
+ * we can see dynamic shapes as they are computed). For \p adts we show the ADT fields. For
+ * \p objects we dispatch to one of the above as appropriate.
+ */
+void AppendNDArray(std::ostream& os, const NDArray& nd_array, const DLDevice& host_device,
+                   bool show_content = true);
+void AppendADT(std::ostream& os, const ADT& adt, const DLDevice& host_device,
+               bool show_content = true);
+void AppendRuntimeObject(std::ostream& os, const ObjectRef& object, const DLDevice& host_device,
+                         bool show_content = true);
+std::string RuntimeObject2String(const ObjectRef& object, const DLDevice& host_device,
+                                 bool show_content = true);
+
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_DEBUG_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/device_api.h b/darknet_drp_ros/include/tvm/runtime/device_api.h
new file mode 100644
index 0000000..faaebe0
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/device_api.h
@@ -0,0 +1,363 @@
+/*
+ * Extended by EdgeCortix, Inc.
+ */
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/device_api.h
+ * \brief Abstract device memory management API
+ */
+#ifndef TVM_RUNTIME_DEVICE_API_H_
+#define TVM_RUNTIME_DEVICE_API_H_
+
+#include <tvm/runtime/c_runtime_api.h>
+#include <tvm/runtime/ndarray.h>
+#include <tvm/runtime/packed_func.h>
+
+#include <string>
+
+namespace tvm {
+namespace runtime {
+/*!
+ * \brief the query type into GetAttr
+ */
+enum DeviceAttrKind : int {
+  kExist = 0,
+  kMaxThreadsPerBlock = 1,
+  kWarpSize = 2,
+  kMaxSharedMemoryPerBlock = 3,
+  kComputeVersion = 4,
+  kDeviceName = 5,
+  kMaxClockRate = 6,
+  kMultiProcessorCount = 7,
+  kMaxThreadDimensions = 8,
+  kMaxRegistersPerBlock = 9,
+  kGcnArch = 10,
+  kApiVersion = 11,
+  kDriverVersion = 12
+};
+
+#ifdef TVM_KALLOC_ALIGNMENT
+/*! \brief Number of bytes each allocation must align to */
+constexpr int kAllocAlignment = TVM_KALLOC_ALIGNMENT;
+
+/*! \brief Number of bytes each allocation must align to in temporary allocation */
+constexpr int kTempAllocaAlignment = TVM_KALLOC_ALIGNMENT;
+#else
+/*! \brief Number of bytes each allocation must align to */
+constexpr int kAllocAlignment = 64;
+
+/*! \brief Number of bytes each allocation must align to in temporary allocation */
+constexpr int kTempAllocaAlignment = 64;
+#endif  // TVM_KALLOC_ALIGNMENT
+
+/*! \brief Maximum size that can be allocated on stack */
+constexpr int kMaxStackAlloca = 1024;
+
+/*! \brief Number of bytes each allocation must align to by default in the workspace buffer to
+ * service intermediate tensors */
+constexpr int kDefaultWorkspaceAlignment = 1;
+
+/*!
+ *  \brief TVM Runtime Device API, abstracts the device
+ *  specific interface for memory management.
+ */
+class TVM_DLL DeviceAPI {
+ public:
+  /*! \brief virtual destructor */
+  virtual ~DeviceAPI() {}
+  /*!
+   * \brief Set the environment device id to device
+   * \param dev The device to be set.
+   */
+  virtual void SetDevice(Device dev) = 0;
+  /*!
+   * \brief Get attribute of specified device.
+   * \param dev The device device
+   * \param kind The result kind
+   * \param rv The return value.
+   * \sa DeviceAttrKind
+   */
+  virtual void GetAttr(Device dev, DeviceAttrKind kind, TVMRetValue* rv) = 0;
+
+  /*!
+   * \brief Query the device for specified properties.
+   *
+   * This is used to expand "-from_device=N" in the target string to
+   * all properties that can be determined from that device.
+   */
+  virtual void GetTargetProperty(Device dev, const std::string& property, TVMRetValue* rv) {}
+
+  /*!
+   * \brief Allocate a data space on device.
+   * \param dev The device device to perform operation.
+   * \param nbytes The number of bytes in memory.
+   * \param alignment The alignment of the memory.
+   * \param type_hint The type of elements. Only needed by certain backends such
+   * as OpenGL, as nbytes & alignment are sufficient for most backends.
+   * \return The allocated device pointer.
+   */
+  virtual void* AllocDataSpace(Device dev, size_t nbytes, size_t alignment,
+                               DLDataType type_hint) = 0;
+  /*!
+   * \brief Get base virtual address of in/out buffer
+   * \param dev The device device to perform operation.
+   * \return The base virtual address
+   */
+  virtual uint64_t GetBaseVirtualAddress() {
+     return 0;
+  };
+
+  /*!
+   * \brief Allocate a data space on device with memory scope support.
+   * \param dev The device device to perform operation.
+   * \param ndim The number of dimension of allocated tensor.
+   * \param shape The shape of allocated tensor.
+   * \param dtype The type of elements.
+   * \param mem_scope The memory scope of allocated tensor.
+   * \return The allocated device pointer.
+   */
+  virtual void* AllocDataSpace(Device dev, int ndim, const int64_t* shape, DLDataType dtype,
+                               Optional<String> mem_scope = NullOpt);
+  /*!
+   * \brief Free a data space on device.
+   * \param dev The device device to perform operation.
+   * \param ptr The data space.
+   */
+  virtual void FreeDataSpace(Device dev, void* ptr) = 0;
+  /*!
+   * \brief copy data from one place to another
+   * \note This API is designed to support special memory with shape dependent layout.
+   *       We pass in DLTensor* with shape information to support these cases.
+   * \param from The source array.
+   * \param to The target array.
+   * \param stream Optional stream object.
+   */
+  virtual void CopyDataFromTo(DLTensor* from, DLTensor* to, TVMStreamHandle stream);
+  /*!
+   * \brief Create a new stream of execution.
+   *
+   * \param dev The device of allocation.
+   */
+  virtual TVMStreamHandle CreateStream(Device dev);
+
+  /*!
+   * \brief Free a stream of execution
+   *
+   * \param dev The device of the stream
+   * \param stream The pointer to be freed.
+   */
+  virtual void FreeStream(Device dev, TVMStreamHandle stream);
+
+  /*!
+   * \brief Synchronize the stream
+   * \param dev The device to perform operation.
+   * \param stream The stream to be sync.
+   */
+  virtual void StreamSync(Device dev, TVMStreamHandle stream) = 0;
+  /*!
+   * \brief Set the stream
+   * \param dev The device to set stream.
+   * \param stream The stream to be set.
+   */
+  virtual void SetStream(Device dev, TVMStreamHandle stream) {}
+  /*!
+   * \brief Synchronize 2 streams of execution.
+   *
+   * An event is created in event_src stream that the second then
+   * stream waits on.  Neither event_src or event_dst need to be of
+   * the same device ID as the device, but they must be of the same
+   * device type.
+   *
+   * \param dev The device of the streams.
+   * \param event_src The source stream to synchronize.
+   * \param event_dst The destination stream to synchronize.
+   */
+  virtual void SyncStreamFromTo(Device dev, TVMStreamHandle event_src, TVMStreamHandle event_dst);
+  /*!
+   * \brief Allocate temporal workspace for backend execution.
+   *
+   *  \note We have the following assumption about backend temporal
+   *   workspace allocation, and backend will optimize for such assumption:
+   *
+   *  - Only a few allocation will happen, and space will be released after use.
+   *  - The release order is usually in reverse order of allocate (stack style).
+   *  - Repeative pattern of same allocations over different runs.
+   *  - Workspace should not overlap between different threads(i.e. be threadlocal)
+   *
+   * \param dev The device of allocation.
+   * \param nbytes The size to be allocated.
+   * \param type_hint The type of elements. Only needed by certain backends such
+   * as OpenGL, as nbytes is sufficient for most backends.
+   */
+  virtual void* AllocWorkspace(Device dev, size_t nbytes, DLDataType type_hint = {});
+  /*!
+   * \brief Free temporal workspace in backend execution.
+   *
+   * \param dev The device of allocation.
+   * \param ptr The pointer to be freed.
+   */
+  virtual void FreeWorkspace(Device dev, void* ptr);
+
+  /*!
+   * \brief Get device API based on device.
+   * \param dev The device
+   * \param allow_missing Whether allow missing
+   * \return The corresponding device API.
+   */
+  static DeviceAPI* Get(Device dev, bool allow_missing = false);
+
+  /*!
+   * \brief Whether a certian device type requires set device device
+   *        before launching the kernel function.
+   * \param device_type The device type.
+   */
+  static bool NeedSetDevice(int device_type) {
+    return device_type != kDLCPU && device_type != kDLMicroDev;
+  }
+
+ protected:
+  /*!
+   * \brief copy data from one place to another
+   * \param from The source array.
+   * \param from_offset The byte offeset in the from.
+   * \param to The target array.
+   * \param to_offset The byte offset in the to.
+   * \param num_bytes The size of the memory in bytes
+   * \param dev_from The source device
+   * \param dev_to The target device
+   * \param type_hint The type of elements, only neded by certain backends.
+   *                  can be useful for cross device endian converison.
+   * \param stream Optional stream object.
+   */
+  virtual void CopyDataFromTo(const void* from, size_t from_offset, void* to, size_t to_offset,
+                              size_t num_bytes, Device dev_from, Device dev_to,
+                              DLDataType type_hint, TVMStreamHandle stream);
+};
+
+/*! \brief The device type bigger than this is RPC device */
+constexpr int kRPCSessMask = 128;
+static_assert(kRPCSessMask >= TVMDeviceExtType_End);
+
+/*!
+ * \brief The name of Device API factory.
+ * \param type The device type.
+ * \return the device name.
+ */
+inline const char* DeviceName(int type) {
+  switch (type) {
+    case kDLCPU:
+      return "cpu";
+    case kDLCUDA:
+      return "cuda";
+    case kDLCUDAHost:
+      return "cuda_host";
+    case kDLCUDAManaged:
+      return "cuda_managed";
+    case kDLOpenCL:
+      return "opencl";
+    case kDLSDAccel:
+      return "sdaccel";
+    case kDLAOCL:
+      return "aocl";
+    case kDLVulkan:
+      return "vulkan";
+    case kDLMetal:
+      return "metal";
+    case kDLVPI:
+      return "vpi";
+    case kDLROCM:
+      return "rocm";
+    case kDLROCMHost:
+      return "rocm_host";
+    case kDLExtDev:
+      return "ext_dev";
+    case kDLOneAPI:
+      return "oneapi";
+    case kDLWebGPU:
+      return "webgpu";
+    case kDLHexagon:
+      return "hexagon";
+    case kOpenGL:
+      return "opengl";
+    case kDLMicroDev:
+      return "microdev";
+    case kDLDrpAi:
+      return "drpai";
+    default:
+      LOG(FATAL) << "unknown type =" << type;
+  }
+}
+
+/*!
+ * \brief Return true if a Device is owned by an RPC session.
+ */
+inline bool IsRPCSessionDevice(Device dev) { return (dev.device_type / kRPCSessMask) > 0; }
+
+/*!
+ * \brief Return the RPCSessTable index of the RPC Session that owns this device.
+ * \return the table index.
+ */
+inline int GetRPCSessionIndex(Device dev) {
+  ICHECK(IsRPCSessionDevice(dev)) << "GetRPCSessionIndex: dev has no RPC session";
+  return dev.device_type / kRPCSessMask - 1;
+}
+
+/*!
+ * \brief Remove the RPC session mask from a Device.
+ * RPC clients typically do this when encoding a Device for transmission to an RPC remote.
+ * On the wire, RPCdevice are expected to be valid on the server without interpretation.
+ * \param dev A Device with non-zero RPC Session mask, valid on the RPC client.
+ * \return A Device without any RPC Session mask, valid on the RPC server.
+ */
+inline Device RemoveRPCSessionMask(Device dev) {
+  dev.device_type = static_cast<DLDeviceType>(dev.device_type % kRPCSessMask);
+  return dev;
+}
+
+inline std::ostream& operator<<(std::ostream& os, DLDevice dev) {  // NOLINT(*)
+  if (tvm::runtime::IsRPCSessionDevice(dev)) {
+    os << "remote[" << tvm::runtime::GetRPCSessionIndex(dev) << "]-";
+    dev = tvm::runtime::RemoveRPCSessionMask(dev);
+  }
+  os << tvm::runtime::DeviceName(static_cast<int>(dev.device_type)) << "(" << dev.device_id << ")";
+  return os;
+}
+
+/*!
+ * \brief Add a RPC session mask to a Device.
+ * RPC clients typically do this when decoding a Device received from a RPC remote.
+ * \param dev A Device without any RPC Session mask, valid on the RPC server.
+ * \param session_table_index Numeric index of the RPC session in the session table.
+ * \return A Device with RPC session mask added, valid on the RPC client.
+ */
+inline Device AddRPCSessionMask(Device dev, int session_table_index) {
+  CHECK(!IsRPCSessionDevice(dev)) << "AddRPCSessionMask: dev already non-zero RPCSessionIndex: "
+                                  << dev;
+  dev.device_type =
+      static_cast<DLDeviceType>(dev.device_type | (kRPCSessMask * (session_table_index + 1)));
+  return dev;
+}
+
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_DEVICE_API_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/executor_info.h b/darknet_drp_ros/include/tvm/runtime/executor_info.h
new file mode 100644
index 0000000..5b35721
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/executor_info.h
@@ -0,0 +1,39 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file executor_info.h
+ * \brief Executor information
+ */
+#ifndef TVM_RUNTIME_EXECUTOR_INFO_H_
+#define TVM_RUNTIME_EXECUTOR_INFO_H_
+
+namespace tvm {
+namespace runtime {
+
+/*! \brief Value used to indicate the graph executor. */
+static constexpr const char* kTvmExecutorGraph = "graph";
+
+/*! \brief Value used to indicate the aot executor. */
+static constexpr const char* kTvmExecutorAot = "aot";
+
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_EXECUTOR_INFO_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/logging.h b/darknet_drp_ros/include/tvm/runtime/logging.h
new file mode 100644
index 0000000..f0c303f
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/logging.h
@@ -0,0 +1,720 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/logging.h
+ * \brief logging utilities
+ *
+ * We define our own CHECK and LOG macros to replace those from dmlc-core.
+ * These macros are then injected into dmlc-core via the
+ * DMLC_USE_LOGGING_LIBRARY define. dmlc-core will #include this file wherever
+ * it needs logging.
+ */
+#ifndef TVM_RUNTIME_LOGGING_H_
+#define TVM_RUNTIME_LOGGING_H_
+
+#include <dmlc/common.h>
+#include <dmlc/thread_local.h>
+#include <tvm/runtime/c_runtime_api.h>
+
+#include <ctime>
+#include <iomanip>
+#include <iostream>
+#include <memory>
+#include <sstream>
+#include <string>
+#include <unordered_map>
+#include <vector>
+
+/*!
+ * \brief Macro helper to force a function not to be inlined.
+ * It is only used in places that we know not inlining is good,
+ * e.g. some logging functions.
+ */
+#if defined(_MSC_VER)
+#define TVM_NO_INLINE __declspec(noinline)
+#else
+#define TVM_NO_INLINE __attribute__((noinline))
+#endif
+
+/*!
+ * \brief Macro helper to force a function to be inlined.
+ * It is only used in places that we know inline is important,
+ * e.g. some template expansion cases.
+ */
+#ifdef _MSC_VER
+#define TVM_ALWAYS_INLINE __forceinline
+#else
+#define TVM_ALWAYS_INLINE inline __attribute__((always_inline))
+#endif
+
+/*!
+ * \brief Macro helper for exception throwing.
+ */
+#define TVM_THROW_EXCEPTION noexcept(false)
+
+/*!
+ * \brief Whether or not enable backtrace logging during a
+ *        fatal error.
+ *
+ * \note TVM won't depend on LIBBACKTRACE or other exec_info
+ *       library when this option is disabled.
+ */
+#ifndef TVM_LOG_STACK_TRACE
+#define TVM_LOG_STACK_TRACE 1
+#endif
+
+/*!
+ * \brief Whether or not use libbacktrace library
+ *        for getting backtrace information
+ */
+#ifndef TVM_USE_LIBBACKTRACE
+#define TVM_USE_LIBBACKTRACE 0
+#endif
+
+/*!
+ * \brief Whether or not customize the logging output.
+ *  If log customize is enabled, the user must implement
+ *  tvm::runtime::detail::LogFatalImpl and tvm::runtime::detail::LogMessageImpl.
+ */
+#ifndef TVM_LOG_CUSTOMIZE
+#define TVM_LOG_CUSTOMIZE 0
+#endif
+
+// a technique that enables overriding macro names on the number of parameters. This is used
+// to define other macros below
+#define GET_MACRO(_1, _2, _3, _4, _5, NAME, ...) NAME
+
+/*!
+ * \brief COND_X calls COND_X_N where N is the number of parameters passed to COND_X
+ * X can be any of CHECK_GE, CHECK_EQ, CHECK, or LOG COND_X (but not COND_X_N)
+ * are supposed to be used outside this file.
+ * The first parameter of COND_X (and therefore, COND_X_N), which we call 'quit_on_assert',
+ * is a boolean. The rest of the parameters of COND_X is the same as the parameters of X.
+ * quit_on_assert determines the overall behavior of COND_X. If it's true COND_X
+ * quits the program on assertion failure. If it's false, then it moves on and somehow reports
+ * the assertion failure back to the macro caller in an appropriate manner (e.g, 'return false'
+ * in a function, or 'continue' or 'break' in a loop)
+ * The default behavior when quit_on_assertion is false, is to 'return false'. If this is not
+ * desirable, the macro caller can pass one more last parameter to COND_X to tell COND_X what
+ * to do when when quit_on_assertion is false and the assertion fails.
+ *
+ * Rationale: These macros were designed to implement functions that have two behaviors
+ * in a concise way. Those behaviors are quitting on assertion failures, or trying to
+ * move on from assertion failures. Note that these macros hide lots of control flow in them,
+ * and therefore, makes the logic of the whole code slightly harder to understand. However,
+ * in pieces of code that use these macros frequently, it will significantly shorten the
+ * amount of code needed to be read, and we won't need to clutter the main logic of the
+ * function by repetitive control flow structure. The first problem
+ * mentioned will be improved over time as the developer gets used to the macro.
+ *
+ * Here is an example of how to use it
+ * \code
+ * bool f(..., bool quit_on_assertion) {
+ *   int a = 0, b = 0;
+ *   ...
+ *   a = ...
+ *   b = ...
+ *   // if quit_on_assertion is true, if a==b, continue, otherwise quit.
+ *   // if quit_on_assertion is false, if a==b, continue, otherwise 'return false'
+ *   //   (default behaviour)
+ *   COND_CHECK_EQ(quit_on_assertion, a, b) << "some error message when  quiting"
+ *   ...
+ *   for (int i = 0; i < N; i++) {
+ *     a = ...
+ *     b = ...
+ *     // if quit_on_assertion is true, if a==b, continue, otherwise quit.
+ *     // if quit_on_assertion is false, if a==b, continue, otherwise 'break'
+ *     //   (non-default behaviour, therefore, has to be explicitly specified)
+ *     COND_CHECK_EQ(quit_on_assertion, a, b, break) << "some error message when  quiting"
+ *   }
+ * }
+ * \endcode
+ */
+#define COND_CHECK_GE(...) \
+  GET_MACRO(__VA_ARGS__, COND_CHECK_GE_5, COND_CHECK_GE_4, COND_CHECK_GE_3)(__VA_ARGS__)
+#define COND_CHECK_EQ(...) \
+  GET_MACRO(__VA_ARGS__, COND_CHECK_EQ_5, COND_CHECK_EQ_4, COND_CHECK_EQ_3)(__VA_ARGS__)
+#define COND_CHECK(...) \
+  GET_MACRO(__VA_ARGS__, COND_CHECK_5, COND_CHECK_4, COND_CHECK_3, COND_CHECK_2)(__VA_ARGS__)
+#define COND_LOG(...) \
+  GET_MACRO(__VA_ARGS__, COND_LOG_5, COND_LOG_4, COND_LOG_3, COND_LOG_2)(__VA_ARGS__)
+
+// Not supposed to be used by users directly.
+#define COND_CHECK_OP(quit_on_assert, x, y, what, op) \
+  if (!quit_on_assert) {                              \
+    if (!((x)op(y))) what;                            \
+  } else /* NOLINT(*) */                              \
+    CHECK_##op(x, y)
+
+#define COND_CHECK_EQ_4(quit_on_assert, x, y, what) COND_CHECK_OP(quit_on_assert, x, y, what, ==)
+#define COND_CHECK_GE_4(quit_on_assert, x, y, what) COND_CHECK_OP(quit_on_assert, x, y, what, >=)
+
+#define COND_CHECK_3(quit_on_assert, x, what) \
+  if (!quit_on_assert) {                      \
+    if (!(x)) what;                           \
+  } else /* NOLINT(*) */                      \
+    CHECK(x)
+
+#define COND_LOG_3(quit_on_assert, x, what) \
+  if (!quit_on_assert) {                    \
+    what;                                   \
+  } else /* NOLINT(*) */                    \
+    LOG(x)
+
+#define COND_CHECK_EQ_3(quit_on_assert, x, y) COND_CHECK_EQ_4(quit_on_assert, x, y, return false)
+#define COND_CHECK_GE_3(quit_on_assert, x, y) COND_CHECK_GE_4(quit_on_assert, x, y, return false)
+#define COND_CHECK_2(quit_on_assert, x) COND_CHECK_3(quit_on_assert, x, return false)
+#define COND_LOG_2(quit_on_assert, x) COND_LOG_3(quit_on_assert, x, return false)
+
+namespace tvm {
+namespace runtime {
+
+/*!
+ * \brief Generate a backtrace when called.
+ * \return A multiline string of the backtrace. There will be either one or two lines per frame.
+ */
+TVM_DLL std::string Backtrace();
+
+/*! \brief Base error type for TVM. Wraps a string message. */
+class Error : public ::dmlc::Error {  // for backwards compatibility
+ public:
+  /*!
+   * \brief Construct an error.
+   * \param s The message to be displayed with the error.
+   */
+  explicit Error(const std::string& s) : ::dmlc::Error(s) {}
+};
+
+/*!
+ * \brief Error message already set in frontend env.
+ *
+ *  This error can be thrown by EnvCheckSignals to indicate
+ *  that there is an error set in the frontend environment(e.g.
+ *  python interpreter). The TVM FFI should catch this error
+ *  and return a proper code tell the frontend caller about
+ *  this fact.
+ */
+class EnvErrorAlreadySet : public ::dmlc::Error {
+ public:
+  /*!
+   * \brief Construct an error.
+   * \param s The message to be displayed with the error.
+   */
+  explicit EnvErrorAlreadySet(const std::string& s) : ::dmlc::Error(s) {}
+};
+
+/*!
+ * \brief Error type for errors from CHECK, ICHECK, and LOG(FATAL). This error
+ * contains a backtrace of where it occurred.
+ */
+class InternalError : public Error {
+ public:
+  /*! \brief Construct an error. Not recommended to use directly. Instead use LOG(FATAL).
+   *
+   * \param file The file where the error occurred.
+   * \param lineno The line number where the error occurred.
+   * \param message The error message to display.
+   * \param time The time at which the error occurred. This should be in local time.
+   * \param backtrace Backtrace from when the error occurred.
+   */
+  InternalError(std::string file, int lineno, std::string message,
+                std::time_t time = std::time(nullptr), std::string backtrace = Backtrace())
+      : Error(""),
+        file_(file),
+        lineno_(lineno),
+        message_(message),
+        time_(time),
+        backtrace_(backtrace) {
+    std::ostringstream s;
+    // XXX: Do not change this format, otherwise all error handling in python will break (because it
+    // parses the message to reconstruct the error type).
+    // TODO(tkonolige): Convert errors to Objects, so we can avoid the mess of formatting/parsing
+    // error messages correctly.
+    s << "[" << std::put_time(std::localtime(&time), "%H:%M:%S") << "] " << file << ":" << lineno
+      << ": " << message << std::endl;
+    if (backtrace.size() > 0) {
+      s << backtrace << std::endl;
+    }
+    full_message_ = s.str();
+  }
+  /*! \return The file in which the error occurred. */
+  const std::string& file() const { return file_; }
+  /*! \return The message associated with this error. */
+  const std::string& message() const { return message_; }
+  /*! \return Formatted error message including file, linenumber, backtrace, and message. */
+  const std::string& full_message() const { return full_message_; }
+  /*! \return The backtrace from where this error occurred. */
+  const std::string& backtrace() const { return backtrace_; }
+  /*! \return The time at which this error occurred. */
+  const std::time_t& time() const { return time_; }
+  /*! \return The line number at which this error occurred. */
+  int lineno() const { return lineno_; }
+  virtual const char* what() const noexcept { return full_message_.c_str(); }
+
+ private:
+  std::string file_;
+  int lineno_;
+  std::string message_;
+  std::time_t time_;
+  std::string backtrace_;
+  std::string full_message_;  // holds the full error string
+};
+
+/*! \brief Internal implementation */
+namespace detail {
+// Provide support for customized logging.
+#if TVM_LOG_CUSTOMIZE
+/*!
+ * \brief Custom implementations of LogFatal.
+ *
+ * \sa TVM_LOG_CUSTOMIZE
+ */
+[[noreturn]] TVM_DLL void LogFatalImpl(const std::string& file, int lineno,
+                                       const std::string& message);
+
+/*!
+ * \brief Custom implementations of LogMessage.
+ *
+ * \sa TVM_LOG_CUSTOMIZE
+ */
+TVM_DLL void LogMessageImpl(const std::string& file, int lineno, int level,
+                            const std::string& message);
+
+/*!
+ * \brief Class to accumulate an error message and throw it. Do not use
+ * directly, instead use LOG(FATAL).
+ */
+class LogFatal {
+ public:
+  LogFatal(const std::string& file, int lineno) : file_(file), lineno_(lineno) {}
+#ifdef _MSC_VER
+#pragma disagnostic push
+#pragma warning(disable : 4722)
+#endif
+  [[noreturn]] ~LogFatal() TVM_THROW_EXCEPTION { LogFatalImpl(file_, lineno_, stream_.str()); }
+#ifdef _MSC_VER
+#pragma disagnostic pop
+#endif
+  std::ostringstream& stream() { return stream_; }
+
+ private:
+  std::ostringstream stream_;
+  std::string file_;
+  int lineno_;
+};
+
+/*!
+ * \brief Class to accumulate an log message. Do not use directly, instead use
+ * LOG(INFO), LOG(WARNING), LOG(ERROR).
+ */
+class LogMessage {
+ public:
+  LogMessage(const std::string& file, int lineno, int level)
+      : file_(file), lineno_(lineno), level_(level) {}
+  ~LogMessage() { LogMessageImpl(file_, lineno_, level_, stream_.str()); }
+  std::ostringstream& stream() { return stream_; }
+
+ private:
+  std::string file_;
+  int lineno_;
+  int level_;
+  std::ostringstream stream_;
+};
+
+#else
+
+/*!
+ * \brief Class to accumulate an error message and throw it. Do not use
+ * directly, instead use LOG(FATAL).
+ * \note The `LogFatal` class is designed to be an empty class to reduce stack size usage.
+ * To play this trick, we use the thread-local storage to store its internal data.
+ */
+class LogFatal {
+ public:
+  TVM_NO_INLINE LogFatal(const char* file, int lineno) { GetEntry().Init(file, lineno); }
+#ifdef _MSC_VER
+#pragma disagnostic push
+#pragma warning(disable : 4722)
+#endif
+  [[noreturn]] ~LogFatal() TVM_THROW_EXCEPTION { GetEntry().Finalize(); }
+#ifdef _MSC_VER
+#pragma disagnostic pop
+#endif
+  std::ostringstream& stream() { return GetEntry().stream_; }
+
+ private:
+  struct Entry {
+    void Init(const char* file, int lineno) {
+      this->stream_.str("");
+      this->file_ = file;
+      this->lineno_ = lineno;
+    }
+    [[noreturn]] TVM_NO_INLINE dmlc::Error Finalize() {
+      throw InternalError(file_, lineno_, stream_.str());
+    }
+    std::ostringstream stream_;
+    std::string file_;
+    int lineno_;
+  };
+
+  TVM_DLL TVM_NO_INLINE static Entry& GetEntry();
+};
+
+/*!
+ * \brief Class to accumulate an log message. Do not use directly, instead use
+ * LOG(INFO), LOG(WARNING), LOG(ERROR).
+ */
+class LogMessage {
+ public:
+  LogMessage(const std::string& file, int lineno, int level) {
+    std::time_t t = std::time(nullptr);
+    stream_ << "[" << std::put_time(std::localtime(&t), "%H:%M:%S") << "] " << file << ":" << lineno
+            << level_strings_[level];
+  }
+  TVM_NO_INLINE ~LogMessage() { std::cerr << stream_.str() << std::endl; }
+  std::ostringstream& stream() { return stream_; }
+
+ private:
+  std::ostringstream stream_;
+  TVM_DLL static const char* level_strings_[];
+};
+
+#endif
+
+// Below is from dmlc-core
+// This class is used to explicitly ignore values in the conditional
+// logging macros.  This avoids compiler warnings like "value computed
+// is not used" and "statement has no effect".
+class LogMessageVoidify {
+ public:
+  LogMessageVoidify() {}
+  // This has to be an operator with a precedence lower than << but
+  // higher than "?:". See its usage.
+  void operator&(std::ostream&) {}
+};
+
+/*! \brief Captures the state of the \p TVM_LOG_DEBUG environment flag. */
+class TvmLogDebugSettings {
+ public:
+  /*!
+   * \brief Parses the \p TVM_LOG_DEBUG environment flag as per the specification given by
+   * \p DebugLoggingEnabled and \p VerboseLoggingEnabled, and caches the result.
+   */
+  inline static const TvmLogDebugSettings& FromFlag() {
+    // Parse and cache the verbosity level map.
+    static const auto* settings =
+        new TvmLogDebugSettings(TvmLogDebugSettings::ParseSpec(std::getenv("TVM_LOG_DEBUG")));
+    return *settings;
+  }
+
+  /*!
+   * \brief Parses \p opt_spec as per specification for \p TVM_LOG_DEBUG given by
+   * \p DebugLoggingEnabled and \p VerboseLoggingEnabled. Throws if specification is ill-formed.
+   */
+  static TvmLogDebugSettings ParseSpec(const char* opt_spec);
+
+  /*!
+   * \brief Implements \p VerboseLoggingEnabled below w.r.t. the already parsed \p TVM_LOG_DEBUG
+   * environment variable.
+   */
+  inline bool VerboseEnabled(const char* opt_filename, int level) const {
+    if (opt_filename == nullptr || level < 0 || vlog_level_map_.empty()) {
+      return false;
+    }
+    return VerboseEnabledImpl(opt_filename, level);
+  }
+
+  /*! \brief Returns true if \p DLOG statements should be executed. */
+  bool dlog_enabled() const { return dlog_enabled_; }
+
+ private:
+  // Slow path for VerboseEnabled.
+  bool VerboseEnabledImpl(const std::string& filename, int level) const;
+
+  /*! \brief If true, DLOG statements are enabled. */
+  bool dlog_enabled_ = false;
+  /*!
+   * \brief A map from canonicalized filenames to the maximum VLOG verbosity level for that file.
+   * May also contain the 'wildcard' entry \p "DEFAULT" representing the level for all other files.
+   */
+  std::unordered_map<std::string, int> vlog_level_map_;
+};
+
+/*!
+ * \brief Returns true if a DLOG statement is enabled by the \p TVM_LOG_DEBUG environment
+ * variable. Requires:
+ * \code
+ *   TVM_LOG_DEBUG=1
+ * \endcode
+ * or a valid setting as described by \p VerboseLoggingEnabled below.
+ */
+// Also from dmlc-core
+inline bool DebugLoggingEnabled() {
+  static int state = 0;
+  if (state == 0) {
+    state = TvmLogDebugSettings::FromFlag().dlog_enabled() ? 1 : -1;
+  }
+  return state == 1;
+}
+
+/*!
+ * \brief Returns true if a VLOG statement in \p filename is enabled by the \p TVM_LOG_DEBUG
+ * environment variable for logging at verbosity \p level. Levels should be non-negative.
+ *
+ * Filenames are canonicalized to be w.r.t. the src/ dir of the TVM tree. (VLOG's should not
+ * appear under include/).
+ *
+ * To enable file \p relay/foo.cc up to level 2 and \p ir/bar.cc for level 0 only set:
+ * \code
+ * TVM_LOG_DEBUG="relay/foo.cc=2,ir/bar.cc=0"
+ * \endcode
+ *
+ * To enable all files up to level 3 but disable \p ir/bar.cc set:
+ * \code
+ * TVM_LOG_DEBUG="DEFAULT=2,ir/bar.cc=-1"
+ * \endcode
+ *
+ * Any of these settings will also enable DLOG statements.
+ */
+inline bool VerboseLoggingEnabled(const char* opt_filename, int level) {
+  return TvmLogDebugSettings::FromFlag().VerboseEnabled(opt_filename, level);
+}
+
+/*!
+ * \brief A stack of VLOG context messages.
+ *
+ * For use by \p VLOG_CONTEXT macro only.
+ */
+class VLogContext {
+ public:
+  void Push(std::stringstream* stream) { context_stack_.push_back(stream); }
+  void Pop() {
+    if (!context_stack_.empty()) {
+      context_stack_.pop_back();
+    }
+  }
+
+  std::string str() const;
+
+ private:
+  std::vector<std::stringstream*> context_stack_;
+};
+
+/*! \brief Thread local \p VLogContext for tracking a stack of VLOG context messages. */
+using ThreadLocalVLogContext = dmlc::ThreadLocalStore<VLogContext>;
+
+/*!
+ * \brief A RAII class to push/pos a VLOG context message onto the thread-local stack.
+ *
+ * For use by \p VLOG_CONTEXT macro only.
+ */
+class VLogContextEntry {
+ public:
+  VLogContextEntry() { ThreadLocalVLogContext::Get()->Push(&sstream_); }
+  ~VLogContextEntry() { ThreadLocalVLogContext::Get()->Pop(); }
+  std::ostream& stream() { return sstream_; }
+
+ private:
+  std::stringstream sstream_;
+};
+
+constexpr const char* kTVM_INTERNAL_ERROR_MESSAGE =
+    "\n"
+    "---------------------------------------------------------------\n"
+    "An error occurred during the execution of TVM.\n"
+    "For more information, please see: https://tvm.apache.org/docs/errors.html\n"
+    "---------------------------------------------------------------\n";
+
+template <typename X, typename Y>
+std::unique_ptr<std::string> LogCheckFormat(const X& x, const Y& y) {
+  std::ostringstream os;
+  os << " (" << x << " vs. " << y << ") ";  // CHECK_XX(x, y) requires x and y can be serialized to
+                                            // string. Use CHECK(x OP y) otherwise.
+  return std::make_unique<std::string>(os.str());
+}
+
+// Inline _Pragma in macros does not work reliably on old version of MSVC and
+// GCC. We wrap all comparisons in a function so that we can use #pragma to
+// silence bad comparison warnings.
+#define TVM_CHECK_FUNC(name, op)                                                          \
+  template <typename X, typename Y>                                                       \
+  TVM_ALWAYS_INLINE std::unique_ptr<std::string> LogCheck##name(const X& x, const Y& y) { \
+    if (x op y) return nullptr;                                                           \
+    return LogCheckFormat(x, y);                                                          \
+  }                                                                                       \
+  TVM_ALWAYS_INLINE std::unique_ptr<std::string> LogCheck##name(int x, int y) {           \
+    return LogCheck##name<int, int>(x, y);                                                \
+  }
+
+#pragma GCC diagnostic push
+#pragma GCC diagnostic ignored "-Wsign-compare"
+TVM_CHECK_FUNC(_LT, <)
+TVM_CHECK_FUNC(_GT, >)
+TVM_CHECK_FUNC(_LE, <=)
+TVM_CHECK_FUNC(_GE, >=)
+TVM_CHECK_FUNC(_EQ, ==)
+TVM_CHECK_FUNC(_NE, !=)
+#pragma GCC diagnostic pop
+
+}  // namespace detail
+
+#define TVM_LOG_LEVEL_DEBUG 0
+#define TVM_LOG_LEVEL_INFO 1
+#define TVM_LOG_LEVEL_WARNING 2
+#define TVM_LOG_LEVEL_ERROR 3
+#define TVM_LOG_LEVEL_FATAL 4
+#define LOG(level) LOG_##level
+#define LOG_DEBUG \
+  ::tvm::runtime::detail::LogMessage(__FILE__, __LINE__, TVM_LOG_LEVEL_DEBUG).stream()
+#define LOG_FATAL ::tvm::runtime::detail::LogFatal(__FILE__, __LINE__).stream()
+#define LOG_INFO ::tvm::runtime::detail::LogMessage(__FILE__, __LINE__, TVM_LOG_LEVEL_INFO).stream()
+#define LOG_ERROR \
+  ::tvm::runtime::detail::LogMessage(__FILE__, __LINE__, TVM_LOG_LEVEL_ERROR).stream()
+#define LOG_WARNING \
+  ::tvm::runtime::detail::LogMessage(__FILE__, __LINE__, TVM_LOG_LEVEL_WARNING).stream()
+
+#define TVM_CHECK_BINARY_OP(name, op, x, y)                                \
+  if (auto __tvm__log__err = ::tvm::runtime::detail::LogCheck##name(x, y)) \
+  ::tvm::runtime::detail::LogFatal(__FILE__, __LINE__).stream()            \
+      << "Check failed: " << #x " " #op " " #y << *__tvm__log__err << ": "
+
+#define CHECK(x)                                                \
+  if (!(x))                                                     \
+  ::tvm::runtime::detail::LogFatal(__FILE__, __LINE__).stream() \
+      << "Check failed: (" #x << ") is false: "
+
+#define CHECK_LT(x, y) TVM_CHECK_BINARY_OP(_LT, <, x, y)
+#define CHECK_GT(x, y) TVM_CHECK_BINARY_OP(_GT, >, x, y)
+#define CHECK_LE(x, y) TVM_CHECK_BINARY_OP(_LE, <=, x, y)
+#define CHECK_GE(x, y) TVM_CHECK_BINARY_OP(_GE, >=, x, y)
+#define CHECK_EQ(x, y) TVM_CHECK_BINARY_OP(_EQ, ==, x, y)
+#define CHECK_NE(x, y) TVM_CHECK_BINARY_OP(_NE, !=, x, y)
+#define CHECK_NOTNULL(x)                                                          \
+  ((x) == nullptr ? ::tvm::runtime::detail::LogFatal(__FILE__, __LINE__).stream() \
+                        << "Check not null: " #x << ' ',                          \
+   (x) : (x))  // NOLINT(*)
+
+#define LOG_IF(severity, condition) \
+  !(condition) ? (void)0 : ::tvm::runtime::detail::LogMessageVoidify() & LOG(severity)
+
+#if TVM_LOG_DEBUG
+
+#define LOG_DFATAL LOG_FATAL
+#define DFATAL FATAL
+#define DLOG(severity) LOG_IF(severity, ::tvm::runtime::detail::DebugLoggingEnabled())
+#define DLOG_IF(severity, condition) \
+  LOG_IF(severity, ::tvm::runtime::detail::DebugLoggingEnabled() && (condition))
+
+/*!
+ * \brief If the \p TVM_LOG_DEBUG build flag is enabled, push a context message onto an internal
+ * stack. All VLOG messages will include this stack in their prefix to help with debugging. E.g.:
+ * \code
+ *   VLOG_CONTEXT << "my context";
+ *   VLOG(1) << "my log message";
+ * \endcode
+ * Thread safe. No-op with no execution overhead if the \p TVM_LOG_DEBUG build flag is not enabled.
+ */
+#define VLOG_CONTEXT                                    \
+  ::tvm::runtime::detail::VLogContextEntry vlog_entry_; \
+  vlog_entry_.stream()
+
+#else
+
+#define LOG_DFATAL LOG_ERROR
+#define DFATAL ERROR
+#define DLOG(severity) true ? (void)0 : ::tvm::runtime::detail::LogMessageVoidify() & LOG(severity)
+#define DLOG_IF(severity, condition) \
+  (true || !(condition)) ? (void)0 : ::tvm::runtime::detail::LogMessageVoidify() & LOG(severity)
+#define VLOG_CONTEXT true ? (void)0 : ::tvm::runtime::detail::LogMessageVoidify() & LOG(INFO)
+
+#endif
+
+/*!
+ * \brief If the \p TVM_LOG_DEBUG build flag is enabled, and the containing file has been enabled
+ * at \p level or greater in the \p TVM_LOG_DEBUG environment variable, then log a message at
+ * \p INFO severity.
+ *
+ * See \p VerboseLoggingEnabled for the format of the \p TVM_LOG_DEBUG environment variable.
+ * Thread safe. No-op with no execution overhead if the \p TVM_LOG_DEBUG build flag is not enabled.
+ * No-op with some execution overhead if the \p TVM_LOG_DEBUG build flag is enabled but the
+ * containing file is not enabled.
+ */
+#define VLOG(level)                                                               \
+  DLOG_IF(INFO, ::tvm::runtime::detail::VerboseLoggingEnabled(__FILE__, (level))) \
+      << ::tvm::runtime::detail::ThreadLocalVLogContext::Get()->str()
+
+#if TVM_LOG_DEBUG
+#define DCHECK(x) CHECK(x)
+#define DCHECK_LT(x, y) CHECK((x) < (y))
+#define DCHECK_GT(x, y) CHECK((x) > (y))
+#define DCHECK_LE(x, y) CHECK((x) <= (y))
+#define DCHECK_GE(x, y) CHECK((x) >= (y))
+#define DCHECK_EQ(x, y) CHECK((x) == (y))
+#define DCHECK_NE(x, y) CHECK((x) != (y))
+#else
+#define DCHECK(x) \
+  while (false) CHECK(x)
+#define DCHECK_LT(x, y) \
+  while (false) CHECK((x) < (y))
+#define DCHECK_GT(x, y) \
+  while (false) CHECK((x) > (y))
+#define DCHECK_LE(x, y) \
+  while (false) CHECK((x) <= (y))
+#define DCHECK_GE(x, y) \
+  while (false) CHECK((x) >= (y))
+#define DCHECK_EQ(x, y) \
+  while (false) CHECK((x) == (y))
+#define DCHECK_NE(x, y) \
+  while (false) CHECK((x) != (y))
+#endif
+
+#define TVM_ICHECK_INDENT "  "
+
+#define ICHECK_BINARY_OP(name, op, x, y)                                   \
+  if (auto __tvm__log__err = ::tvm::runtime::detail::LogCheck##name(x, y)) \
+  ::tvm::runtime::detail::LogFatal(__FILE__, __LINE__).stream()            \
+      << ::tvm::runtime::detail::kTVM_INTERNAL_ERROR_MESSAGE << std::endl  \
+      << TVM_ICHECK_INDENT << "Check failed: " << #x " " #op " " #y << *__tvm__log__err << ": "
+
+#define ICHECK(x)                                                                 \
+  if (!(x))                                                                       \
+  ::tvm::runtime::detail::LogFatal(__FILE__, __LINE__).stream()                   \
+      << ::tvm::runtime::detail::kTVM_INTERNAL_ERROR_MESSAGE << TVM_ICHECK_INDENT \
+      << "Check failed: (" #x << ") is false: "
+
+#define ICHECK_LT(x, y) ICHECK_BINARY_OP(_LT, <, x, y)
+#define ICHECK_GT(x, y) ICHECK_BINARY_OP(_GT, >, x, y)
+#define ICHECK_LE(x, y) ICHECK_BINARY_OP(_LE, <=, x, y)
+#define ICHECK_GE(x, y) ICHECK_BINARY_OP(_GE, >=, x, y)
+#define ICHECK_EQ(x, y) ICHECK_BINARY_OP(_EQ, ==, x, y)
+#define ICHECK_NE(x, y) ICHECK_BINARY_OP(_NE, !=, x, y)
+#define ICHECK_NOTNULL(x)                                                         \
+  ((x) == nullptr ? ::tvm::runtime::detail::LogFatal(__FILE__, __LINE__).stream() \
+                        << ::tvm::runtime::detail::kTVM_INTERNAL_ERROR_MESSAGE    \
+                        << TVM_ICHECK_INDENT << "Check not null: " #x << ' ',     \
+   (x) : (x))  // NOLINT(*)
+
+}  // namespace runtime
+// Re-export error types
+using runtime::Error;
+using runtime::InternalError;
+
+}  // namespace tvm
+#endif  // TVM_RUNTIME_LOGGING_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/memory.h b/darknet_drp_ros/include/tvm/runtime/memory.h
new file mode 100644
index 0000000..1199c42
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/memory.h
@@ -0,0 +1,207 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+/*!
+ * \file tvm/runtime/memory.h
+ * \brief Runtime memory management.
+ */
+#ifndef TVM_RUNTIME_MEMORY_H_
+#define TVM_RUNTIME_MEMORY_H_
+
+#include <tvm/runtime/object.h>
+
+#include <cstdlib>
+#include <type_traits>
+#include <utility>
+
+namespace tvm {
+namespace runtime {
+/*!
+ * \brief Allocate an object using default allocator.
+ * \param args arguments to the constructor.
+ * \tparam T the node type.
+ * \return The ObjectPtr to the allocated object.
+ */
+template <typename T, typename... Args>
+inline ObjectPtr<T> make_object(Args&&... args);
+
+// Detail implementations after this
+//
+// The current design allows swapping the
+// allocator pattern when necessary.
+//
+// Possible future allocator optimizations:
+// - Arena allocator that gives ownership of memory to arena (deleter_= nullptr)
+// - Thread-local object pools: one pool per size and alignment requirement.
+// - Can specialize by type of object to give the specific allocator to each object.
+
+/*!
+ * \brief Base class of object allocators that implements make.
+ *  Use curiously recurring template pattern.
+ *
+ * \tparam Derived The derived class.
+ */
+template <typename Derived>
+class ObjAllocatorBase {
+ public:
+  /*!
+   * \brief Make a new object using the allocator.
+   * \tparam T The type to be allocated.
+   * \tparam Args The constructor signature.
+   * \param args The arguments.
+   */
+  template <typename T, typename... Args>
+  inline ObjectPtr<T> make_object(Args&&... args) {
+    using Handler = typename Derived::template Handler<T>;
+    static_assert(std::is_base_of<Object, T>::value, "make can only be used to create Object");
+    T* ptr = Handler::New(static_cast<Derived*>(this), std::forward<Args>(args)...);
+    ptr->type_index_ = T::RuntimeTypeIndex();
+    ptr->deleter_ = Handler::Deleter();
+    return ObjectPtr<T>(ptr);
+  }
+
+  /*!
+   * \tparam ArrayType The type to be allocated.
+   * \tparam ElemType The type of array element.
+   * \tparam Args The constructor signature.
+   * \param num_elems The number of array elements.
+   * \param args The arguments.
+   */
+  template <typename ArrayType, typename ElemType, typename... Args>
+  inline ObjectPtr<ArrayType> make_inplace_array(size_t num_elems, Args&&... args) {
+    using Handler = typename Derived::template ArrayHandler<ArrayType, ElemType>;
+    static_assert(std::is_base_of<Object, ArrayType>::value,
+                  "make_inplace_array can only be used to create Object");
+    ArrayType* ptr =
+        Handler::New(static_cast<Derived*>(this), num_elems, std::forward<Args>(args)...);
+    ptr->type_index_ = ArrayType::RuntimeTypeIndex();
+    ptr->deleter_ = Handler::Deleter();
+    return ObjectPtr<ArrayType>(ptr);
+  }
+};
+
+// Simple allocator that uses new/delete.
+class SimpleObjAllocator : public ObjAllocatorBase<SimpleObjAllocator> {
+ public:
+  template <typename T>
+  class Handler {
+   public:
+    using StorageType = typename std::aligned_storage<sizeof(T), alignof(T)>::type;
+
+    template <typename... Args>
+    static T* New(SimpleObjAllocator*, Args&&... args) {
+      // NOTE: the first argument is not needed for SimpleObjAllocator
+      // It is reserved for special allocators that needs to recycle
+      // the object to itself (e.g. in the case of object pool).
+      //
+      // In the case of an object pool, an allocator needs to create
+      // a special chunk memory that hides reference to the allocator
+      // and call allocator's release function in the deleter.
+
+      // NOTE2: Use inplace new to allocate
+      // This is used to get rid of warning when deleting a virtual
+      // class with non-virtual destructor.
+      // We are fine here as we captured the right deleter during construction.
+      // This is also the right way to get storage type for an object pool.
+      StorageType* data = new StorageType();
+      new (data) T(std::forward<Args>(args)...);
+      return reinterpret_cast<T*>(data);
+    }
+
+    static Object::FDeleter Deleter() { return Deleter_; }
+
+   private:
+    static void Deleter_(Object* objptr) {
+      // NOTE: this is important to cast back to T*
+      // because objptr and tptr may not be the same
+      // depending on how sub-class allocates the space.
+      T* tptr = static_cast<T*>(objptr);
+      // It is important to do tptr->T::~T(),
+      // so that we explicitly call the specific destructor
+      // instead of tptr->~T(), which could mean the intention
+      // call a virtual destructor(which may not be available and is not required).
+      tptr->T::~T();
+      delete reinterpret_cast<StorageType*>(tptr);
+    }
+  };
+
+  // Array handler that uses new/delete.
+  template <typename ArrayType, typename ElemType>
+  class ArrayHandler {
+   public:
+    using StorageType = typename std::aligned_storage<sizeof(ArrayType), alignof(ArrayType)>::type;
+    // for now only support elements that aligns with array header.
+    static_assert(alignof(ArrayType) % alignof(ElemType) == 0 &&
+                      sizeof(ArrayType) % alignof(ElemType) == 0,
+                  "element alignment constraint");
+
+    template <typename... Args>
+    static ArrayType* New(SimpleObjAllocator*, size_t num_elems, Args&&... args) {
+      // NOTE: the first argument is not needed for ArrayObjAllocator
+      // It is reserved for special allocators that needs to recycle
+      // the object to itself (e.g. in the case of object pool).
+      //
+      // In the case of an object pool, an allocator needs to create
+      // a special chunk memory that hides reference to the allocator
+      // and call allocator's release function in the deleter.
+      // NOTE2: Use inplace new to allocate
+      // This is used to get rid of warning when deleting a virtual
+      // class with non-virtual destructor.
+      // We are fine here as we captured the right deleter during construction.
+      // This is also the right way to get storage type for an object pool.
+      size_t unit = sizeof(StorageType);
+      size_t requested_size = num_elems * sizeof(ElemType) + sizeof(ArrayType);
+      size_t num_storage_slots = (requested_size + unit - 1) / unit;
+      StorageType* data = new StorageType[num_storage_slots];
+      new (data) ArrayType(std::forward<Args>(args)...);
+      return reinterpret_cast<ArrayType*>(data);
+    }
+
+    static Object::FDeleter Deleter() { return Deleter_; }
+
+   private:
+    static void Deleter_(Object* objptr) {
+      // NOTE: this is important to cast back to ArrayType*
+      // because objptr and tptr may not be the same
+      // depending on how sub-class allocates the space.
+      ArrayType* tptr = static_cast<ArrayType*>(objptr);
+      // It is important to do tptr->ArrayType::~ArrayType(),
+      // so that we explicitly call the specific destructor
+      // instead of tptr->~ArrayType(), which could mean the intention
+      // call a virtual destructor(which may not be available and is not required).
+      tptr->ArrayType::~ArrayType();
+      StorageType* p = reinterpret_cast<StorageType*>(tptr);
+      delete[] p;
+    }
+  };
+};
+
+template <typename T, typename... Args>
+inline ObjectPtr<T> make_object(Args&&... args) {
+  return SimpleObjAllocator().make_object<T>(std::forward<Args>(args)...);
+}
+
+template <typename ArrayType, typename ElemType, typename... Args>
+inline ObjectPtr<ArrayType> make_inplace_array_object(size_t num_elems, Args&&... args) {
+  return SimpleObjAllocator().make_inplace_array<ArrayType, ElemType>(num_elems,
+                                                                      std::forward<Args>(args)...);
+}
+
+}  // namespace runtime
+}  // namespace tvm
+#endif  // TVM_RUNTIME_MEMORY_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/metadata.h b/darknet_drp_ros/include/tvm/runtime/metadata.h
new file mode 100644
index 0000000..f921f3e
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/metadata.h
@@ -0,0 +1,142 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/metadata.h
+ * \brief Defines types which can be used in Metadata.
+ */
+#ifndef TVM_RUNTIME_METADATA_H_
+#define TVM_RUNTIME_METADATA_H_
+
+#include <dmlc/memory_io.h>
+#include <tvm/runtime/c_runtime_api.h>
+#include <tvm/runtime/metadata_base.h>
+#include <tvm/runtime/metadata_types.h>
+#include <tvm/runtime/object.h>
+#include <tvm/support/span.h>
+
+#include <memory>
+#include <string>
+#include <vector>
+
+// Version number recorded in emitted artifacts for runtime checking.
+#define TVM_METADATA_VERSION 1
+
+namespace tvm {
+namespace runtime {
+namespace metadata {
+/*!
+ * \brief Version of metadata emitted and understood by this compiler/runtime.
+ * Should be populated into the `version` field of all TVMMetadata.
+ */
+static const constexpr int64_t kMetadataVersion = TVM_METADATA_VERSION;
+
+class Metadata;
+class TensorInfo;
+class ConstantInfoMetadata;
+
+class MetadataNode : public MetadataBaseNode {
+ public:
+  explicit MetadataNode(const struct ::TVMMetadata* data) : data_{data} {}
+  static constexpr const char* _type_key = "metadata.MetadataNode";
+  const char* get_c_struct_name() const override;
+  inline int64_t version() const { return int64_t(data_->version); }
+  inline int64_t num_inputs() const { return data_->num_inputs; }
+  ArrayAccessor<struct TVMTensorInfo, TensorInfo> inputs();
+  inline int64_t num_outputs() const { return data_->num_outputs; }
+  ArrayAccessor<struct TVMTensorInfo, TensorInfo> outputs();
+  inline int64_t num_workspace_pools() const { return data_->num_workspace_pools; }
+  ArrayAccessor<struct TVMTensorInfo, TensorInfo> workspace_pools();
+  inline ::tvm::runtime::String mod_name() const { return ::tvm::runtime::String(data_->mod_name); }
+  const struct ::TVMMetadata* data() const { return data_; }
+  ArrayAccessor<struct TVMConstantInfo, ConstantInfoMetadata> constant_pools();
+  inline int64_t num_constant_pools() const { return data_->num_constant_pools; }
+  TVM_DECLARE_FINAL_OBJECT_INFO(MetadataNode, MetadataBaseNode);
+
+ private:
+  const struct ::TVMMetadata* data_;
+};
+
+class Metadata : public MetadataBase {
+ public:
+  explicit Metadata(const struct ::TVMMetadata* data);
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(Metadata, MetadataBase, MetadataNode);
+};
+
+class TensorInfoNode : public MetadataBaseNode {
+ public:
+  explicit TensorInfoNode(const struct ::TVMTensorInfo* data) : data_{data} {}
+  static constexpr const char* _type_key = "metadata.TensorInfoNode";
+  const char* get_c_struct_name() const override;
+  inline ::tvm::runtime::String name() const { return ::tvm::runtime::String(data_->name); }
+  inline int64_t num_shape() const { return data_->num_shape; }
+  inline ::tvm::support::Span<const int64_t, int64_t> shape() const {
+    return ::tvm::support::Span<const int64_t, int64_t>(data_->shape,
+                                                        data_->shape + data_->num_shape);
+  }
+  inline ::tvm::runtime::DataType dtype() const { return ::tvm::runtime::DataType(data_->dtype); }
+  const struct ::TVMTensorInfo* data() const { return data_; }
+  TVM_DECLARE_FINAL_OBJECT_INFO(TensorInfoNode, MetadataBaseNode);
+
+ private:
+  const struct ::TVMTensorInfo* data_;
+};
+
+class TensorInfo : public MetadataBase {
+ public:
+  explicit TensorInfo(const struct ::TVMTensorInfo* data);
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(TensorInfo, MetadataBase, TensorInfoNode);
+};
+
+class ConstantInfoMetadataNode : public MetadataBaseNode {
+ public:
+  explicit ConstantInfoMetadataNode(const struct ::TVMConstantInfo* data) : data_{data} {}
+  // This name should match TVMConstantInfo after processing
+  static constexpr const char* _type_key = "metadata.ConstantInfoNode";
+  const char* get_c_struct_name() const override;
+  inline ::tvm::runtime::String name_hint() const {
+    return ::tvm::runtime::String(data_->name_hint);
+  }
+  inline size_t byte_offset() const { return data_->byte_offset; }
+  inline ::tvm::runtime::NDArray data() const {
+    ::tvm::runtime::NDArray ndarray;
+    if (data_->data_len) {
+      dmlc::MemoryFixedSizeStream bytes(const_cast<void*>(data_->data_bytes), data_->data_len);
+      ndarray.Load(&bytes);
+    }
+    return ndarray;
+  }
+  TVM_DECLARE_FINAL_OBJECT_INFO(ConstantInfoMetadataNode, MetadataBaseNode);
+
+ protected:
+  const struct ::TVMConstantInfo* data_;
+};
+
+class ConstantInfoMetadata : public MetadataBase {
+ public:
+  explicit ConstantInfoMetadata(const struct ::TVMConstantInfo* data);
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(ConstantInfoMetadata, MetadataBase,
+                                        ConstantInfoMetadataNode);
+};
+
+}  // namespace metadata
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_METADATA_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/metadata_base.h b/darknet_drp_ros/include/tvm/runtime/metadata_base.h
new file mode 100644
index 0000000..698f56d
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/metadata_base.h
@@ -0,0 +1,217 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/metadata_base.h
+ * \brief Defines types which can be used in Metadata.
+ */
+#ifndef TVM_RUNTIME_METADATA_BASE_H_
+#define TVM_RUNTIME_METADATA_BASE_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/runtime/object.h>
+
+#include <memory>
+#include <string>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+namespace runtime {
+namespace metadata {
+
+/*!
+ * \brief Common base class for all Metadata.
+ *
+ * This class is used in the visitor classes as a internal check to ensure that verify that all
+ * parts of the Metadata struct used in codegen are Metadata objects.
+ */
+class MetadataBaseNode : public ::tvm::runtime::Object {
+ public:
+  virtual const char* get_c_struct_name() const = 0;
+
+  static constexpr const char* _type_key = "metadata.MetadataBaseNode";
+  TVM_DECLARE_BASE_OBJECT_INFO(MetadataBaseNode, ::tvm::runtime::Object);
+};
+
+/*! \brief Reference class for the common MetadataBaseNode class. */
+class MetadataBase : public ::tvm::runtime::ObjectRef {
+ public:
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(MetadataBase, ::tvm::runtime::ObjectRef, MetadataBaseNode);
+};
+
+template <typename C, class Ref>
+class ArrayAccessor;
+
+/*! \brief An iterator implementation that lazily instantiates the C++ wrapping Metadata class. */
+template <typename C, class Ref>
+class ArrayIterator {
+ public:
+  ArrayIterator(size_t index, const ArrayAccessor<C, Ref>* parent)
+      : index_{index}, parent_{parent} {}
+
+  inline Ref operator*() { return (*parent_)[index_]; }
+
+  inline ArrayIterator<C, Ref>& operator++() {
+    if (index_ < parent_->size()) {
+      index_++;
+    }
+
+    return *this;
+  }
+
+  inline bool operator==(const ArrayIterator<C, Ref>& other) const {
+    return parent_ == other.parent_ && index_ == other.index_;
+  }
+
+  inline bool operator!=(const ArrayIterator<C, Ref>& other) const { return !operator==(other); }
+
+ private:
+  size_t index_;
+  const ArrayAccessor<C, Ref>* parent_;
+};
+
+/*! \brief A span-like class which permits access to Array fields with complex elements.
+ * These array fields should be accessed from C++ using the Metadata wrapper classes. This class
+ * lazily instantiates those wrappers as they are accessed.
+ */
+template <typename C, class Ref>
+class ArrayAccessor {
+ public:
+  using value_type = Ref;
+  using iterator = ArrayIterator<C, Ref>;
+  using const_iterator = iterator;
+
+  template <typename T = typename std::enable_if<std::is_base_of<ObjectRef, Ref>::value>::type>
+  ArrayAccessor(const C* data, size_t num_data) : data_{data}, num_data_{num_data} {}
+
+  inline size_t size() const { return num_data_; }
+
+  inline Ref operator[](size_t index) const {
+    if (index >= num_data_) {
+      throw std::runtime_error("Index out of range");
+    }
+
+    return Ref(&data_[index]);
+  }
+
+  inline ArrayIterator<C, Ref> begin() const { return ArrayIterator<C, Ref>{0, this}; }
+
+  inline ArrayIterator<C, Ref> end() const { return ArrayIterator<C, Ref>{num_data_, this}; }
+
+ private:
+  const C* data_;
+  size_t num_data_;
+};
+
+/*! \brief A specialization of ArrayAccessor for String.
+ * This class is needed because the String constructor signature is different from the typical
+ * Metadata subclass.
+ */
+template <>
+class ArrayAccessor<const char*, ::tvm::runtime::String> {
+ public:
+  using value_type = ::tvm::runtime::String;
+  using iterator = ArrayIterator<const char*, ::tvm::runtime::String>;
+  using const_iterator = iterator;
+
+  ArrayAccessor(const char** data, size_t num_data) : data_{data}, num_data_{num_data} {}
+
+  inline size_t size() const { return num_data_; }
+
+  inline ::tvm::runtime::String operator[](size_t index) const {
+    if (index >= num_data_) {
+      throw std::runtime_error("Index out of range");
+    }
+    return ::tvm::runtime::String(data_[index]);
+  }
+
+  inline ArrayIterator<const char*, ::tvm::runtime::String> begin() const {
+    return ArrayIterator<const char*, ::tvm::runtime::String>{0, this};
+  }
+
+  inline ArrayIterator<const char*, ::tvm::runtime::String> end() const {
+    return ArrayIterator<const char*, ::tvm::runtime::String>{num_data_, this};
+  }
+
+ private:
+  const char** data_;
+  size_t num_data_;
+};
+
+/*! \brief Enumerates the primitive types which can be part of a Metadata instance.
+ *
+ * These are separate from TIR DataType because TIR does not model structs.
+ */
+enum MetadataKind : uint8_t {
+  kUint64 = 0,
+  kInt64 = 1,
+  kBool = 2,
+  kString = 3,
+  kHandle = 4,
+  kMetadata = 5,
+};
+
+/*! \brief Container for arrays in the metadata.
+ *
+ * Type information is needed when emitting arrays. This container augments the data field with
+ * the necessary typing information.
+ */
+class MetadataArrayNode : public MetadataBaseNode {
+ public:
+  MetadataArrayNode(Array<ObjectRef> array, MetadataKind kind, const char* type_key)
+      : array(::std::move(array)), kind{kind}, type_key{type_key} {}
+
+  const char* get_c_struct_name() const final;
+
+  std::string get_element_c_struct_name() const {
+    CHECK(kind == MetadataKind::kMetadata)
+        << "cannot get struct name for MetadataArray with kind=" << kind;
+    constexpr int prefix_size = sizeof("metadata.") - 1;
+    constexpr int suffix_size = sizeof("Node") - 1;
+    std::string type_key_str(type_key);
+    return std::string("TVM") +
+           type_key_str.substr(prefix_size, type_key_str.size() - prefix_size - suffix_size);
+  }
+
+  Array<ObjectRef> array;
+
+  /*! \brief Describes the storage class of the emitted struct member. */
+  MetadataKind kind;
+
+  /*! \brief When `kind` is Metadata, type_key of the MetadataBaseNode used with this array. */
+  const char* type_key;
+
+  static constexpr const char* _type_key = "metadata.MetadataArrayNode";
+  TVM_DECLARE_BASE_OBJECT_INFO(MetadataArrayNode, MetadataBaseNode);
+};
+
+/*! \brief Reference class for MetadataArray. */
+class MetadataArray : public MetadataBase {
+ public:
+  MetadataArray(Array<ObjectRef> array, MetadataKind kind, const char* struct_name);
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(MetadataArray, MetadataBase, MetadataArrayNode);
+};
+
+}  // namespace metadata
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_METADATA_BASE_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/metadata_types.h b/darknet_drp_ros/include/tvm/runtime/metadata_types.h
new file mode 100644
index 0000000..5d82884
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/metadata_types.h
@@ -0,0 +1,109 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+// LINT_C_FILE
+
+/*!
+ * \file tvm/runtime/metadata_types.h
+ * \brief Defines types which can be used in metadata here which
+ * are also shared between C and C++ code bases.
+ */
+#ifndef TVM_RUNTIME_METADATA_TYPES_H_
+#define TVM_RUNTIME_METADATA_TYPES_H_
+
+#include <inttypes.h>
+#include <tvm/runtime/c_runtime_api.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/*!
+ * \brief Top-level metadata structure. Holds all other metadata types.
+ */
+struct TVMMetadata {
+  /*! \brief Version identifier for this metadata. */
+  int64_t version;
+  /*! \brief Inputs to the AOT run_model function.
+   * The order of the elements is the same as in the arguments to run_model. That is to say,
+   * this array specifies the first `num_inputs` arguments to run_model.
+   */
+  const struct TVMTensorInfo* inputs;
+  /*! \brief Number of elements in `inputs` array. */
+  int64_t num_inputs;
+  /*! \brief Outputs of the AOT run_model function.
+   * The order of the elements is the same as in the arguments to run_model. That is to say,
+   * this array specifies the last `num_outputs` arguments to run_model.
+   */
+  const struct TVMTensorInfo* outputs;
+  /*! \brief Number of elements in `outputs` array. */
+  int64_t num_outputs;
+  /*! \brief Workspace Memory Pools needed by the AOT main function.
+   * The order of the elements is the same as in the arguments to run_model. That is to say,
+   * this array specifies the last `num_workspace_pools` arguments to run_model.
+   */
+  const struct TVMTensorInfo* workspace_pools;
+  /*! \brief Number of elements in `workspace_pools` array. */
+  int64_t num_workspace_pools;
+  /*! \brief Constant pools needed by the AOT main function.
+   */
+  const struct TVMConstantInfo* constant_pools;
+  /*! \brief Number of elements in `constant_pools` array. */
+  int64_t num_constant_pools;
+  /*! \brief Name of the model, as passed to tvm.relay.build. */
+  const char* mod_name;
+};
+
+/*!
+ * \brief Describes one tensor argument to `run_model`.
+ * NOTE: while TIR allows for other types of arguments, such as scalars, the AOT run_model
+ * function does not currently accept these. Therefore it's not possible to express those
+ * in this metadata. A future patch may modify this.
+ */
+struct TVMTensorInfo {
+  /*! \brief Name of the tensor, as specified in the Relay program. */
+  const char* name;
+  /*! \brief Shape of the tensor. */
+  const int64_t* shape;
+  /*! \brief Rank of this tensor. */
+  int64_t num_shape;
+  /*! \brief Data type of one element of this tensor. */
+  DLDataType dtype;
+};
+
+/*!
+ * \brief Describes one constant argument to `run_model`.
+ *
+ */
+struct TVMConstantInfo {
+  /*! \brief Name of the constant */
+  const char* name_hint;
+  /*! \brief Offset in bytes of the constant */
+  int64_t byte_offset;
+  /*! \brief length of the data_bytes field */
+  int64_t data_len;
+  /*! \brief data bytes of serialized NDArray */
+  const void* data_bytes;
+};
+
+#ifdef __cplusplus
+}  // extern "C"
+#endif
+
+#endif  // TVM_RUNTIME_METADATA_TYPES_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/micro/standalone/microtvm_runtime.h b/darknet_drp_ros/include/tvm/runtime/micro/standalone/microtvm_runtime.h
new file mode 100644
index 0000000..827d91f
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/micro/standalone/microtvm_runtime.h
@@ -0,0 +1,45 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+#ifndef TVM_RUNTIME_MICRO_STANDALONE_MICROTVM_RUNTIME_H_
+#define TVM_RUNTIME_MICRO_STANDALONE_MICROTVM_RUNTIME_H_
+
+#include <stddef.h>
+#include <stdint.h>
+
+#define TVM_MICRO_RUNTIME_API_API extern "C" __attribute__((visibility("default")))
+
+TVM_MICRO_RUNTIME_API_API void* MicroTVMRuntimeCreate(const char* json, size_t json_len,
+                                                      void* module);
+
+TVM_MICRO_RUNTIME_API_API void MicroTVMRuntimeDestroy(void* handle);
+
+TVM_MICRO_RUNTIME_API_API void MicroTVMRuntimeSetInput(void* handle, int index, void* tensor);
+
+TVM_MICRO_RUNTIME_API_API void MicroTVMRuntimeRun(void* handle);
+
+TVM_MICRO_RUNTIME_API_API void MicroTVMRuntimeGetOutput(void* handle, int index, void* tensor);
+
+TVM_MICRO_RUNTIME_API_API void* MicroTVMRuntimeDSOModuleCreate(const char* so, size_t so_len);
+
+TVM_MICRO_RUNTIME_API_API void MicroTVMRuntimeDSOModuleDestroy(void* module);
+
+#undef TVM_MICRO_RUNTIME_API_API
+
+#endif  // TVM_RUNTIME_MICRO_STANDALONE_MICROTVM_RUNTIME_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/module.h b/darknet_drp_ros/include/tvm/runtime/module.h
new file mode 100644
index 0000000..a54f98a
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/module.h
@@ -0,0 +1,296 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/module.h
+ * \brief Runtime container of the functions generated by TVM,
+ *  This is used to support dynamically link, load and save
+ *  functions from different convention under unified API.
+ */
+#ifndef TVM_RUNTIME_MODULE_H_
+#define TVM_RUNTIME_MODULE_H_
+
+#include <dmlc/io.h>
+#include <tvm/runtime/c_runtime_api.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/runtime/memory.h>
+#include <tvm/runtime/object.h>
+
+#include <memory>
+#include <mutex>
+#include <string>
+#include <unordered_map>
+#include <vector>
+
+namespace tvm {
+namespace runtime {
+
+class ModuleNode;
+class PackedFunc;
+
+/*!
+ * \brief Module container of TVM.
+ */
+class Module : public ObjectRef {
+ public:
+  Module() {}
+  // constructor from container.
+  explicit Module(ObjectPtr<Object> n) : ObjectRef(n) {}
+  /*!
+   * \brief Get packed function from current module by name.
+   *
+   * \param name The name of the function.
+   * \param query_imports Whether also query dependency modules.
+   * \return The result function.
+   *  This function will return PackedFunc(nullptr) if function do not exist.
+   * \note Implemented in packed_func.cc
+   */
+  inline PackedFunc GetFunction(const std::string& name, bool query_imports = false);
+  // The following functions requires link with runtime.
+  /*!
+   * \brief Import another module into this module.
+   * \param other The module to be imported.
+   *
+   * \note Cyclic dependency is not allowed among modules,
+   *  An error will be thrown when cyclic dependency is detected.
+   */
+  inline void Import(Module other);
+  /*! \return internal container */
+  inline ModuleNode* operator->();
+  /*! \return internal container */
+  inline const ModuleNode* operator->() const;
+  /*!
+   * \brief Load a module from file.
+   * \param file_name The name of the host function module.
+   * \param format The format of the file.
+   * \note This function won't load the import relationship.
+   *  Re-create import relationship by calling Import.
+   */
+  TVM_DLL static Module LoadFromFile(const std::string& file_name, const std::string& format = "");
+  // refer to the corresponding container.
+  using ContainerType = ModuleNode;
+  friend class ModuleNode;
+};
+
+/*!
+ * \brief Base container of module.
+ *
+ * Please subclass ModuleNode to create a specific runtime module.
+ *
+ * \code
+ *
+ *  class MyModuleNode : public ModuleNode {
+ *   public:
+ *    // implement the interface
+ *  };
+ *
+ *  // use make_object to create a specific
+ *  // instace of MyModuleNode.
+ *  Module CreateMyModule() {
+ *    ObjectPtr<MyModuleNode> n =
+ *      tvm::runtime::make_object<MyModuleNode>();
+ *    return Module(n);
+ *  }
+ *
+ * \endcode
+ */
+class TVM_DLL ModuleNode : public Object {
+ public:
+  /*! \brief virtual destructor */
+  virtual ~ModuleNode() = default;
+  /*!
+   * \return The per module type key.
+   * \note This key is used to for serializing custom modules.
+   */
+  virtual const char* type_key() const = 0;
+  /*!
+   * \brief Get a PackedFunc from module.
+   *
+   *  The PackedFunc may not be fully initialized,
+   *  there might still be first time running overhead when
+   *  executing the function on certain devices.
+   *  For benchmarking, use prepare to eliminate
+   *
+   * \param name the name of the function.
+   * \param sptr_to_self The ObjectPtr that points to this module node.
+   *
+   * \return PackedFunc(nullptr) when it is not available.
+   *
+   * \note The function will always remain valid.
+   *   If the function need resource from the module(e.g. late linking),
+   *   it should capture sptr_to_self.
+   */
+  virtual PackedFunc GetFunction(const std::string& name,
+                                 const ObjectPtr<Object>& sptr_to_self) = 0;
+  /*!
+   * \brief Save the module to file.
+   * \param file_name The file to be saved to.
+   * \param format The format of the file.
+   */
+  virtual void SaveToFile(const std::string& file_name, const std::string& format);
+  /*!
+   * \brief Save the module to binary stream.
+   * \param stream The binary stream to save to.
+   * \note It is recommended to implement this for device modules,
+   *   but not necessarily host modules.
+   *   We can use this to do AOT loading of bundled device functions.
+   */
+  virtual void SaveToBinary(dmlc::Stream* stream);
+  /*!
+   * \brief Get the source code of module, when available.
+   * \param format Format of the source code, can be empty by default.
+   * \return Possible source code when available.
+   */
+  virtual std::string GetSource(const std::string& format = "");
+  /*!
+   * \brief Get the format of the module, when available.
+   * \return Possible format when available.
+   */
+  virtual std::string GetFormat();
+  /*!
+   * \brief Get packed function from current module by name.
+   *
+   * \param name The name of the function.
+   * \param query_imports Whether also query dependency modules.
+   * \return The result function.
+   *  This function will return PackedFunc(nullptr) if function do not exist.
+   * \note Implemented in packed_func.cc
+   */
+  PackedFunc GetFunction(const std::string& name, bool query_imports = false);
+  /*!
+   * \brief Import another module into this module.
+   * \param other The module to be imported.
+   *
+   * \note Cyclic dependency is not allowed among modules,
+   *  An error will be thrown when cyclic dependency is detected.
+   */
+  void Import(Module other);
+  /*!
+   * \brief Get a function from current environment
+   *  The environment includes all the imports as well as Global functions.
+   *
+   * \param name name of the function.
+   * \return The corresponding function.
+   */
+  const PackedFunc* GetFuncFromEnv(const std::string& name);
+  /*! \return The module it imports from */
+  const std::vector<Module>& imports() const { return imports_; }
+
+  /*!
+   * \brief Returns true if this module is 'DSO exportable'.
+   *
+   * A DSO exportable module (eg a CSourceModuleNode of type_key 'c') can be incorporated into the
+   * final runtime artifact (ie shared library) by compilation and/or linking using the external
+   * compiler (llvm, nvcc, etc). DSO exportable modules must implement SaveToFile.
+   *
+   * By contrast, non-DSO exportable modules (eg CUDAModuleNode of type_key 'cuda') typically must
+   * be incorporated into the final runtime artifact by being serialized as data into the
+   * artifact, then deserialized at runtime. Non-DSO exportable modules must implement SaveToBinary,
+   * and have a matching deserializer registered as 'runtime.module.loadbinary_<type_key>'.
+   *
+   * The default implementation returns false.
+   */
+  virtual bool IsDSOExportable() const;
+
+  /*!
+   * \brief Returns true if this module has a definition for a function of \p name. If
+   * \p query_imports is true, also search in any imported modules.
+   *
+   * Note that even if this function returns true the corresponding \p GetFunction result may be
+   * nullptr if the function is not yet callable without further compilation.
+   *
+   * The default implementation just checkis if \p GetFunction is non-null.
+   */
+  virtual bool ImplementsFunction(const String& name, bool query_imports = false);
+
+  // integration with the existing components.
+  static constexpr const uint32_t _type_index = TypeIndex::kRuntimeModule;
+  static constexpr const char* _type_key = "runtime.Module";
+  // NOTE: ModuleNode can still be sub-classed
+  //
+  TVM_DECLARE_FINAL_OBJECT_INFO(ModuleNode, Object);
+
+ protected:
+  friend class Module;
+  friend class ModuleInternal;
+  /*! \brief The modules this module depend on */
+  std::vector<Module> imports_;
+
+ private:
+  /*! \brief Cache used by GetImport */
+  std::unordered_map<std::string, std::shared_ptr<PackedFunc>> import_cache_;
+  std::mutex mutex_;
+};
+
+/*!
+ * \brief Check if runtime module is enabled for target.
+ * \param target The target module name.
+ * \return Whether runtime is enabled.
+ */
+TVM_DLL bool RuntimeEnabled(const std::string& target);
+
+/*! \brief namespace for constant symbols */
+namespace symbol {
+/*! \brief A PackedFunc that retrieves exported metadata. */
+constexpr const char* tvm_get_c_metadata = "get_c_metadata";
+/*! \brief Global variable to store module context. */
+constexpr const char* tvm_module_ctx = "__tvm_module_ctx";
+/*! \brief Global variable to store device module blob */
+constexpr const char* tvm_dev_mblob = "__tvm_dev_mblob";
+/*! \brief Number of bytes of device module blob. */
+constexpr const char* tvm_dev_mblob_nbytes = "__tvm_dev_mblob_nbytes";
+/*! \brief global function to set device */
+constexpr const char* tvm_set_device = "__tvm_set_device";
+/*! \brief Auxiliary counter to global barrier. */
+constexpr const char* tvm_global_barrier_state = "__tvm_global_barrier_state";
+/*! \brief Prepare the global barrier before kernels that uses global barrier. */
+constexpr const char* tvm_prepare_global_barrier = "__tvm_prepare_global_barrier";
+/*! \brief Placeholder for the module's entry function. */
+constexpr const char* tvm_module_main = "__tvm_main__";
+/*! \brief Prefix for parameter symbols emitted into the main program. */
+constexpr const char* tvm_param_prefix = "__tvm_param__";
+/*! \brief A PackedFunc that looks up linked parameters by storage_id. */
+constexpr const char* tvm_lookup_linked_param = "_lookup_linked_param";
+/*! \brief Model entrypoint generated as an interface to the AOT function outside of TIR */
+constexpr const char* tvm_entrypoint_suffix = "run";
+}  // namespace symbol
+
+// implementations of inline functions.
+
+inline void Module::Import(Module other) { return (*this)->Import(other); }
+
+inline ModuleNode* Module::operator->() { return static_cast<ModuleNode*>(get_mutable()); }
+
+inline const ModuleNode* Module::operator->() const {
+  return static_cast<const ModuleNode*>(get());
+}
+
+inline std::ostream& operator<<(std::ostream& out, const Module& module) {
+  out << "Module(type_key= ";
+  out << module->type_key();
+  out << ")";
+
+  return out;
+}
+
+}  // namespace runtime
+}  // namespace tvm
+
+#include <tvm/runtime/packed_func.h>  // NOLINT(*)
+#endif                                // TVM_RUNTIME_MODULE_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/name_transforms.h b/darknet_drp_ros/include/tvm/runtime/name_transforms.h
new file mode 100644
index 0000000..267dda4
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/name_transforms.h
@@ -0,0 +1,43 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/name_transforms.h
+ * \brief Transformations which are applied on names to generate appropriately named.
+ *  These functions are used in both Runtime and Backend.
+ */
+#ifndef TVM_RUNTIME_NAME_TRANSFORMS_H_
+#define TVM_RUNTIME_NAME_TRANSFORMS_H_
+
+#include <string>
+
+namespace tvm {
+namespace runtime {
+
+/*!
+ * \brief Sanitize name for output into compiler artifacts
+ * \param name Original name
+ * \return Sanitized name
+ */
+std::string SanitizeName(const std::string& name);
+
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_NAME_TRANSFORMS_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/ndarray.h b/darknet_drp_ros/include/tvm/runtime/ndarray.h
new file mode 100644
index 0000000..23fba36
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/ndarray.h
@@ -0,0 +1,564 @@
+/*
+ * Extended by EdgeCortix, Inc.
+ */
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/ndarray.h
+ * \brief A device-independent managed NDArray abstraction.
+ */
+#ifndef TVM_RUNTIME_NDARRAY_H_
+#define TVM_RUNTIME_NDARRAY_H_
+
+#include <tvm/runtime/c_runtime_api.h>
+#include <tvm/runtime/container/optional.h>
+#include <tvm/runtime/container/shape_tuple.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/runtime/data_type.h>
+#include <tvm/runtime/object.h>
+#include <tvm/runtime/serializer.h>
+
+#include <atomic>
+#include <functional>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+
+// alias DLDevice
+using Device = DLDevice;
+
+// A 'null' device type, does not correspond to any DLDeviceType enum.
+// TODO(mbs): This is to help us as we transition away from representing the 'homogenous' case
+// as a singleton target map indexed by the invalid DLDeviceType '0'.
+constexpr DLDeviceType kNullDeviceType = static_cast<DLDeviceType>(0);
+
+// An 'invalid' device type, does not correspond to any DLDeviceType enum.
+constexpr DLDeviceType kInvalidDeviceType = static_cast<DLDeviceType>(-1);
+
+namespace runtime {
+
+/*!
+ * \brief Managed NDArray.
+ *  The array is backed by reference counted blocks.
+ */
+class NDArray : public ObjectRef {
+ public:
+  /*! \brief ContainerBase used to back the TVMArrayHandle */
+  class ContainerBase;
+  /*! \brief NDArray internal container type */
+  class Container;
+  /*! \brief Container type for Object system. */
+  using ContainerType = Container;
+  /*! \brief default constructor */
+  NDArray() {}
+  /*!
+   * \brief constructor.
+   * \param data ObjectPtr to the data container.
+   */
+  explicit NDArray(ObjectPtr<Object> data) : ObjectRef(data) {}
+
+  /*! \brief reset the content of NDArray to be nullptr */
+  inline void reset();
+  /*!
+   * \return the reference counter
+   * \note this number is approximate in multi-threaded setting.
+   */
+  inline int use_count() const;
+  /*! \return Pointer to content of DLTensor */
+  inline const DLTensor* operator->() const;
+  /*! \return Whether the tensor is contiguous */
+  inline bool IsContiguous() const;
+  /*!
+   * \brief Copy data content from another array.
+   * \param other The source array to be copied from.
+   * \note The copy may happen asynchronously if it involves a GPU context.
+   *       TVMSynchronize is necessary.
+   */
+  inline void CopyFrom(const DLTensor* other);
+  inline void CopyFrom(const NDArray& other);
+  /*!
+   * \brief Copy data content from a byte buffer.
+   * \param data The source bytes to be copied from.
+   * \param nbytes The size of the buffer in bytes
+   *        Must be equal to the size of the NDArray.
+   * \note The copy always triggers a TVMSynchronize.
+   */
+  TVM_DLL void CopyFromBytes(const void* data, size_t nbytes);
+  /*!
+   * \brief Copy data content into another array.
+   * \param other The source array to be copied from.
+   * \note The copy may happen asynchronously if it involves a GPU context.
+   *       TVMSynchronize is necessary.
+   */
+  inline void CopyTo(DLTensor* other) const;
+  inline void CopyTo(const NDArray& other) const;
+  /*!
+   * \brief Copy data content into another array.
+   * \param data The source bytes to be copied from.
+   * \param nbytes The size of the data buffer.
+   *        Must be equal to the size of the NDArray.
+   * \note The copy always triggers a TVMSynchronize.
+   */
+  TVM_DLL void CopyToBytes(void* data, size_t nbytes) const;
+  /*!
+   * \brief Copy the data to another device.
+   * \param dev The target device.
+   * \return The array under another device.
+   */
+  inline NDArray CopyTo(const Device& dev) const;
+  /*!
+   * \brief Load NDArray from stream
+   * \param stream The input data stream
+   * \return Whether load is successful
+   */
+  inline bool Load(dmlc::Stream* stream);
+  /*!
+   * \brief Save NDArray to stream
+   * \param stream The output data stream
+   */
+  inline void Save(dmlc::Stream* stream) const;
+  /*!
+   * \brief Create a NDArray that shares the data memory with the current one.
+   * \param shape The shape of the new array.
+   * \param dtype The data type of the new array.
+   * \note The memory size of new array must be smaller than the current one.
+   */
+  TVM_DLL NDArray CreateView(ShapeTuple shape, DLDataType dtype);
+  /*!
+   * \brief Create a reference view of NDArray that
+   *  represents as DLManagedTensor.
+   * \return A DLManagedTensor
+   */
+  TVM_DLL DLManagedTensor* ToDLPack() const;
+  /*!
+   * \brief Create an empty NDArray.
+   * \param shape The shape of the new array.
+   * \param dtype The data type of the new array.
+   * \param dev The device of the array.
+   * \param mem_scope The memory scope of the array.
+   * \return The created Array
+   */
+  TVM_DLL static NDArray Empty(ShapeTuple shape, DLDataType dtype, Device dev,
+                               Optional<String> mem_scope = NullOpt);
+  /*!
+   * \brief Get virtual address base of Input/Output buffer.
+   * \param dev The device of the array.
+   * \return The base virtual address
+   */
+  TVM_DLL static uint64_t GetBaseVirtualAddress(Device dev);
+  /*!
+   * \brief Create a NDArray backed by an external DLTensor without memory copying.
+   *
+   * If DLTensor is not contiguous or has bad aligned data, It fails.
+   * This allows us to create a NDArray using the memory
+   * allocated by an external source. Responsibility for memory
+   * retaining lies with the external source.
+   * \param dl_tensor The DLTensor for NDArray base.
+   * \return The created NDArray view.
+   */
+  TVM_DLL static NDArray FromExternalDLTensor(const DLTensor& dl_tensor);
+  /*!
+   * \brief Create new NDArray, data is copied from DLTensor.
+   *
+   * \param dl_tensor The DLTensor to copy from.
+   * \param dev device location of the created NDArray.
+   * \return The created NDArray view.
+   */
+  TVM_DLL static NDArray NewFromDLTensor(DLTensor* dl_tensor, const Device& dev);
+  /*!
+   * \brief Create a NDArray backed by a dlpack tensor.
+   *
+   * This allows us to create a NDArray using the memory
+   * allocated by an external deep learning framework
+   * that is DLPack compatible.
+   *
+   * The memory is retained until the NDArray went out of scope.
+   * \param tensor The DLPack tensor to copy from.
+   * \return The created NDArray view.
+   */
+  TVM_DLL static NDArray FromDLPack(DLManagedTensor* tensor);
+  /*!
+   * \brief Function to copy data from one array to another.
+   * \param from The source array.
+   * \param to The target array.
+   * \param stream The stream used in copy.
+   */
+  TVM_DLL static void CopyFromTo(const DLTensor* from, DLTensor* to,
+                                 TVMStreamHandle stream = nullptr);
+
+  TVM_DLL ShapeTuple Shape() const;
+  TVM_DLL runtime::DataType DataType() const;
+  /*!
+   * \brief Check conditions for construction NDArray over DLTensor without copying.
+   * There are three conditions to check:
+   * 1. Destination device is the same as DLTensor device
+   * 2. Destination device id is the same as DLTensor device id
+   * 3. Memory in DLTensor is aligned as expected for NDArray
+   * \param tensor the DLTensor.
+   * \param dev destination device.
+   * \return true if all conditions are satisfied.
+   */
+  TVM_DLL static bool AbilityOfZeroCopyForDLTensor(DLTensor* tensor, const Device& dev);
+  // internal namespace
+  struct Internal;
+
+ private:
+  TVM_DLL static bool IsAligned(const DLTensor& tensor);
+
+ protected:
+  friend class TVMPODValue_;
+  friend class TVMRetValue;
+  friend class TVMArgsSetter;
+  /*!
+   * \brief Get mutable internal container pointer.
+   * \return a mutable container pointer.
+   */
+  inline Container* get_mutable() const;
+  // Helper functions for FFI handling.
+  /*!
+   * \brief Construct NDArray's Data field from array handle in FFI.
+   * \param handle The array handle.
+   * \return The corresponding ObjectPtr to the constructed container object.
+   *
+   * \note We keep a special calling convention for NDArray by passing
+   *       ContainerBase pointer in FFI.
+   *       As a result, the argument is compatible to DLTensor*.
+   */
+  inline static ObjectPtr<Object> FFIDataFromHandle(TVMArrayHandle handle);
+  /*!
+   * \brief DecRef resource managed by an FFI array handle.
+   * \param handle The array handle.
+   */
+  inline static void FFIDecRef(TVMArrayHandle handle);
+  /*!
+   * \brief Get FFI Array handle from ndarray.
+   * \param nd The object with ndarray type.
+   * \return The result array handle.
+   */
+  inline static TVMArrayHandle FFIGetHandle(const ObjectRef& nd);
+};
+
+/*!
+ * \brief Save a DLTensor to stream
+ * \param strm The output stream
+ * \param tensor The tensor to be saved.
+ */
+inline bool SaveDLTensor(dmlc::Stream* strm, const DLTensor* tensor);
+
+/*!
+ * \brief The container base structure
+ *        contains all the fields except for the Object header.
+ *
+ * \note We explicitly declare this structure in order to pass
+ *       PackedFunc argument using ContainerBase*.
+ */
+class NDArray::ContainerBase {
+ public:
+  /*!
+   * \brief The corresponding dl_tensor field.
+   * \note it is important that the first field is DLTensor
+   *  So that this data structure is DLTensor compatible.
+   *  The head ptr of this struct can be viewed as DLTensor*.
+   */
+  DLTensor dl_tensor;
+
+  /*!
+   * \brief additional context, reserved for recycling
+   * \note We can attach additional content here
+   *  which the current container depend on
+   *  (e.g. reference to original memory when creating views).
+   */
+  void* manager_ctx{nullptr};
+
+ protected:
+  /*!
+   * \brief The shape container,
+   *  can be used used for shape data.
+   */
+  ShapeTuple shape_;
+};
+
+/*!
+ * \brief Object container class that backs NDArray.
+ * \note do not use this function directly, use NDArray.
+ */
+class NDArray::Container : public Object, public NDArray::ContainerBase {
+ public:
+  /*! \brief default constructor */
+  Container() {
+    // Initialize the type index.
+    type_index_ = Container::RuntimeTypeIndex();
+    dl_tensor.data = nullptr;
+    dl_tensor.ndim = 0;
+    dl_tensor.shape = nullptr;
+    dl_tensor.strides = nullptr;
+    dl_tensor.byte_offset = 0;
+  }
+
+  Container(void* data, ShapeTuple shape, DLDataType dtype, Device dev) {
+    // Initialize the type index.
+    type_index_ = Container::RuntimeTypeIndex();
+    dl_tensor.data = data;
+    shape_ = std::move(shape);
+    dl_tensor.ndim = static_cast<int>(shape_.size());
+    dl_tensor.shape = const_cast<ShapeTuple::index_type*>(shape_.data());
+    dl_tensor.dtype = dtype;
+    dl_tensor.strides = nullptr;
+    dl_tensor.byte_offset = 0;
+    dl_tensor.device = dev;
+  }
+  /*!
+   * \brief Set the deleter field.
+   * \param deleter The deleter.
+   */
+  void SetDeleter(FDeleter deleter) { deleter_ = deleter; }
+
+  // Expose DecRef and IncRef as public function
+  // NOTE: they are only for developer purposes only.
+  using Object::DecRef;
+  using Object::IncRef;
+
+  // Information for object protocol.
+  static constexpr const uint32_t _type_index = TypeIndex::kRuntimeNDArray;
+  static constexpr const uint32_t _type_child_slots = 0;
+  static constexpr const uint32_t _type_child_slots_can_overflow = true;
+  static constexpr const char* _type_key = "runtime.NDArray";
+  TVM_DECLARE_BASE_OBJECT_INFO(NDArray::Container, Object);
+
+ protected:
+  friend class RPCWrappedFunc;
+  friend class NDArray;
+};
+
+// implementations of inline functions
+/*!
+ * \brief return the size of data the DLTensor hold, in term of number of bytes
+ *
+ *  \param arr the input DLTensor
+ *  \return number of  bytes of data in the DLTensor.
+ */
+inline size_t GetDataSize(const DLTensor& arr) {
+  size_t size = 1;
+  for (tvm_index_t i = 0; i < arr.ndim; ++i) {
+    size *= static_cast<size_t>(arr.shape[i]);
+  }
+  size *= (arr.dtype.bits * arr.dtype.lanes + 7) / 8;
+  return size;
+}
+
+/*!
+ * \brief check if a DLTensor is contiguous.
+ * \param arr The input DLTensor.
+ * \return The check result.
+ */
+static inline bool IsContiguous(const DLTensor& arr) {
+  if (arr.strides == nullptr) return true;
+  int64_t expected_stride = 1;
+  for (int32_t i = arr.ndim; i != 0; --i) {
+    int32_t k = i - 1;
+    if (arr.shape[k] == 1) {
+      // Skip stride check if shape[k] is 1, where the dimension is contiguous
+      // regardless of the value of stride.
+      //
+      // For example, PyTorch will normalize stride to 1 if shape is 1 when exporting
+      // to DLPack.
+      // More context: https://github.com/pytorch/pytorch/pull/83158
+      continue;
+    }
+    if (arr.strides[k] != expected_stride) return false;
+    expected_stride *= arr.shape[k];
+  }
+  return true;
+}
+
+inline bool NDArray::IsContiguous() const {
+  return ::tvm::runtime::IsContiguous(get_mutable()->dl_tensor);
+}
+
+inline void NDArray::CopyFrom(const DLTensor* other) {
+  ICHECK(data_ != nullptr);
+  CopyFromTo(other, &(get_mutable()->dl_tensor));
+}
+
+inline void NDArray::CopyFrom(const NDArray& other) {
+  ICHECK(data_ != nullptr);
+  ICHECK(other.data_ != nullptr);
+  CopyFromTo(&(other.get_mutable()->dl_tensor), &(get_mutable()->dl_tensor));
+}
+
+inline void NDArray::CopyTo(DLTensor* other) const {
+  ICHECK(data_ != nullptr);
+  CopyFromTo(&(get_mutable()->dl_tensor), other);
+}
+
+inline void NDArray::CopyTo(const NDArray& other) const {
+  ICHECK(data_ != nullptr);
+  ICHECK(other.data_ != nullptr);
+  CopyFromTo(&(get_mutable()->dl_tensor), &(other.get_mutable()->dl_tensor));
+}
+
+inline NDArray NDArray::CopyTo(const Device& dev) const {
+  ICHECK(data_ != nullptr);
+  const DLTensor* dptr = operator->();
+  NDArray ret = Empty(ShapeTuple(dptr->shape, dptr->shape + dptr->ndim), dptr->dtype, dev);
+  this->CopyTo(ret);
+  return ret;
+}
+
+inline int NDArray::use_count() const { return data_.use_count(); }
+
+inline const DLTensor* NDArray::operator->() const { return &(get_mutable()->dl_tensor); }
+
+inline NDArray::Container* NDArray::get_mutable() const {
+  return static_cast<NDArray::Container*>(data_.get());
+}
+
+inline ObjectPtr<Object> NDArray::FFIDataFromHandle(TVMArrayHandle handle) {
+  return GetObjectPtr<Object>(
+      static_cast<NDArray::Container*>(reinterpret_cast<NDArray::ContainerBase*>(handle)));
+}
+
+inline TVMArrayHandle NDArray::FFIGetHandle(const ObjectRef& nd) {
+  // NOTE: it is necessary to cast to container then to base
+  //       so that the FFI handle uses the ContainerBase address.
+  auto ptr = reinterpret_cast<TVMArrayHandle>(static_cast<NDArray::ContainerBase*>(
+      static_cast<NDArray::Container*>(const_cast<Object*>(nd.get()))));
+  return ptr;
+}
+
+inline void NDArray::FFIDecRef(TVMArrayHandle handle) {
+  static_cast<NDArray::Container*>(reinterpret_cast<NDArray::ContainerBase*>(handle))->DecRef();
+}
+
+inline Object* TVMArrayHandleToObjectHandle(TVMArrayHandle handle) {
+  return static_cast<NDArray::Container*>(reinterpret_cast<NDArray::ContainerBase*>(handle));
+}
+
+/*! \brief Magic number for NDArray file */
+constexpr uint64_t kTVMNDArrayMagic = 0xDD5E40F096B4A13F;
+
+inline bool SaveDLTensor(dmlc::Stream* strm, const DLTensor* tensor) {
+  uint64_t header = kTVMNDArrayMagic, reserved = 0;
+  strm->Write(header);
+  strm->Write(reserved);
+  // Always save data as CPU context
+  //
+  // Parameters that get serialized should be in CPU by default.
+  // So even the array's context is GPU, it will be stored as CPU array.
+  // This is used to prevent case when another user loads the parameters
+  // back on machine that do not have GPU or related context.
+  //
+  // We can always do array.CopyTo(target_dev) to get a corresponding
+  // array in the target context.
+  Device cpu_dev;
+  cpu_dev.device_type = kDLCPU;
+  cpu_dev.device_id = 0;
+  strm->Write(cpu_dev);
+  strm->Write(tensor->ndim);
+  strm->Write(tensor->dtype);
+  int ndim = tensor->ndim;
+  strm->WriteArray(tensor->shape, ndim);
+  int type_bytes = (tensor->dtype.bits + 7) / 8;
+  int64_t num_elems = 1;
+  for (int i = 0; i < ndim; ++i) {
+    num_elems *= tensor->shape[i];
+  }
+  int64_t data_byte_size = type_bytes * num_elems;
+  strm->Write(data_byte_size);
+
+  if (DMLC_IO_NO_ENDIAN_SWAP && tensor->device.device_type == kDLCPU &&
+      tensor->strides == nullptr && tensor->byte_offset == 0) {
+    // quick path
+    strm->Write(tensor->data, data_byte_size);
+  } else {
+    std::vector<uint8_t> bytes(data_byte_size);
+    ICHECK_EQ(
+        TVMArrayCopyToBytes(const_cast<DLTensor*>(tensor), dmlc::BeginPtr(bytes), data_byte_size),
+        0)
+        << TVMGetLastError();
+    if (!DMLC_IO_NO_ENDIAN_SWAP) {
+      dmlc::ByteSwap(dmlc::BeginPtr(bytes), type_bytes, num_elems);
+    }
+    strm->Write(dmlc::BeginPtr(bytes), data_byte_size);
+  }
+  return true;
+}
+
+inline void NDArray::Save(dmlc::Stream* strm) const { SaveDLTensor(strm, operator->()); }
+
+inline bool NDArray::Load(dmlc::Stream* strm) {
+  uint64_t header, reserved;
+  ICHECK(strm->Read(&header)) << "Invalid DLTensor file format";
+  ICHECK(strm->Read(&reserved)) << "Invalid DLTensor file format";
+  ICHECK(header == kTVMNDArrayMagic) << "Invalid DLTensor file format";
+  Device dev;
+  int ndim;
+  DLDataType dtype;
+  ICHECK(strm->Read(&dev)) << "Invalid DLTensor file format";
+  ICHECK(strm->Read(&ndim)) << "Invalid DLTensor file format";
+  ICHECK(strm->Read(&dtype)) << "Invalid DLTensor file format";
+  ICHECK_EQ(dev.device_type, kDLCPU) << "Invalid DLTensor device: can only save as CPU tensor";
+  std::vector<int64_t> shape(ndim);
+  if (ndim != 0) {
+    ICHECK(strm->ReadArray(&shape[0], ndim)) << "Invalid DLTensor file format";
+  }
+  NDArray ret = NDArray::Empty(ShapeTuple(shape), dtype, dev);
+  int64_t num_elems = 1;
+  int elem_bytes = (ret->dtype.bits + 7) / 8;
+  for (int i = 0; i < ret->ndim; ++i) {
+    num_elems *= ret->shape[i];
+  }
+  int64_t data_byte_size;
+  ICHECK(strm->Read(&data_byte_size)) << "Invalid DLTensor file format";
+  ICHECK(data_byte_size == num_elems * elem_bytes) << "Invalid DLTensor file format";
+  auto read_ret = strm->Read(ret->data, data_byte_size);
+  // Only check non-empty data
+  if (ndim > 0 && shape[0] != 0) {
+    ICHECK(read_ret) << "Invalid DLTensor file format";
+  }
+  if (!DMLC_IO_NO_ENDIAN_SWAP) {
+    dmlc::ByteSwap(ret->data, elem_bytes, num_elems);
+  }
+  *this = ret;
+  return true;
+}
+
+}  // namespace runtime
+}  // namespace tvm
+
+namespace std {
+template <>
+struct hash<tvm::Device> {
+  std::size_t operator()(const tvm::Device& dev) const {
+    return ((dev.device_id << 8) | dev.device_type);
+  }
+};
+
+template <>
+struct equal_to<tvm::Device> {
+  bool operator()(const tvm::Device& lhs, const tvm::Device& rhs) const {
+    return (lhs.device_type == rhs.device_type && lhs.device_id == rhs.device_id);
+  }
+};
+}  // namespace std
+
+#endif  // TVM_RUNTIME_NDARRAY_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/object.h b/darknet_drp_ros/include/tvm/runtime/object.h
new file mode 100644
index 0000000..e571679
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/object.h
@@ -0,0 +1,906 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+/*!
+ * \file tvm/runtime/object.h
+ * \brief A managed object in the TVM runtime.
+ */
+#ifndef TVM_RUNTIME_OBJECT_H_
+#define TVM_RUNTIME_OBJECT_H_
+
+#include <tvm/runtime/c_runtime_api.h>
+#include <tvm/runtime/logging.h>
+
+#include <string>
+#include <type_traits>
+#include <utility>
+
+/*!
+ * \brief Whether or not use atomic reference counter.
+ *  If the reference counter is not atomic,
+ *  an object cannot be owned by multiple threads.
+ *  We can, however, move an object across threads
+ */
+#ifndef TVM_OBJECT_ATOMIC_REF_COUNTER
+#define TVM_OBJECT_ATOMIC_REF_COUNTER 1
+#endif
+
+#if TVM_OBJECT_ATOMIC_REF_COUNTER
+#include <atomic>
+#endif  // TVM_OBJECT_ATOMIC_REF_COUNTER
+
+namespace tvm {
+namespace runtime {
+
+/*!
+ * \brief Namespace for the list of type index.
+ * \note Use struct so that we have to use TypeIndex::ENumName to refer to
+ *       the constant, but still able to use enum.
+ */
+struct TypeIndex {
+  enum {
+    /*! \brief Root object type. */
+    kRoot = 0,
+    // Standard static index assignments,
+    // Frontends can take benefit of these constants.
+    /*! \brief runtime::Module. */
+    kRuntimeModule = 1,
+    /*! \brief runtime::NDArray. */
+    kRuntimeNDArray = 2,
+    /*! \brief runtime::String. */
+    kRuntimeString = 3,
+    /*! \brief runtime::Array. */
+    kRuntimeArray = 4,
+    /*! \brief runtime::Map. */
+    kRuntimeMap = 5,
+    /*! \brief runtime::ShapeTuple. */
+    kRuntimeShapeTuple = 6,
+    /*! \brief runtime::PackedFunc. */
+    kRuntimePackedFunc = 7,
+    // static assignments that may subject to change.
+    kRuntimeClosure,
+    kRuntimeADT,
+    kStaticIndexEnd,
+    /*! \brief Type index is allocated during runtime. */
+    kDynamic = kStaticIndexEnd
+  };
+};  // namespace TypeIndex
+
+/*!
+ * \brief base class of all object containers.
+ *
+ * Sub-class of objects should declare the following static constexpr fields:
+ *
+ * - _type_index:
+ *      Static type index of the object, if assigned to TypeIndex::kDynamic
+ *      the type index will be assigned during runtime.
+ *      Runtime type index can be accessed by ObjectType::TypeIndex();
+ * - _type_key:
+ *       The unique string identifier of the type.
+ * - _type_final:
+ *       Whether the type is terminal type(there is no subclass of the type in the object system).
+ *       This field is automatically set by macro TVM_DECLARE_FINAL_OBJECT_INFO
+ *       It is still OK to sub-class a terminal object type T and construct it using make_object.
+ *       But IsInstance check will only show that the object type is T(instead of the sub-class).
+ *
+ * The following two fields are necessary for base classes that can be sub-classed.
+ *
+ * - _type_child_slots:
+ *       Number of reserved type index slots for child classes.
+ *       Used for runtime optimization for type checking in IsInstance.
+ *       If an object's type_index is within range of [type_index, type_index + _type_child_slots]
+ *       Then the object can be quickly decided as sub-class of the current object class.
+ *       If not, a fallback mechanism is used to check the global type table.
+ *       Recommendation: set to estimate number of children needed.
+ * - _type_child_slots_can_overflow:
+ *       Whether we can add additional child classes even if the number of child classes
+ *       exceeds the _type_child_slots. A fallback mechanism to check global type table will be
+ * used. Recommendation: set to false for optimal runtime speed if we know exact number of children.
+ *
+ * Two macros are used to declare helper functions in the object:
+ * - Use TVM_DECLARE_BASE_OBJECT_INFO for object classes that can be sub-classed.
+ * - Use TVM_DECLARE_FINAL_OBJECT_INFO for object classes that cannot be sub-classed.
+ *
+ * New objects can be created using make_object function.
+ * Which will automatically populate the type_index and deleter of the object.
+ *
+ * \sa make_object
+ * \sa ObjectPtr
+ * \sa ObjectRef
+ *
+ * \code
+ *
+ *  // Create a base object
+ *  class BaseObj : public Object {
+ *   public:
+ *    // object fields
+ *    int field0;
+ *
+ *    // object properties
+ *    static constexpr const uint32_t _type_index = TypeIndex::kDynamic;
+ *    static constexpr const char* _type_key = "test.BaseObj";
+ *    TVM_DECLARE_BASE_OBJECT_INFO(BaseObj, Object);
+ *  };
+ *
+ *  class LeafObj : public BaseObj {
+ *   public:
+ *    // fields
+ *    int child_field0;
+ *    // object properties
+ *    static constexpr const uint32_t _type_index = TypeIndex::kDynamic;
+ *    static constexpr const char* _type_key = "test.LeafObj";
+ *    TVM_DECLARE_BASE_OBJECT_INFO(LeafObj, Object);
+ *  };
+ *
+ *  // The following code should be put into a cc file.
+ *  TVM_REGISTER_OBJECT_TYPE(BaseObj);
+ *  TVM_REGISTER_OBJECT_TYPE(LeafObj);
+ *
+ *  // Usage example.
+ *  void TestObjects() {
+ *    // create an object
+ *    ObjectRef leaf_ref(make_object<LeafObj>());
+ *    // cast to a specific instance
+ *    const LeafObj* leaf_ptr = leaf_ref.as<LeafObj>();
+ *    ICHECK(leaf_ptr != nullptr);
+ *    // can also cast to the base class.
+ *    ICHECK(leaf_ref.as<BaseObj>() != nullptr);
+ *  }
+ *
+ * \endcode
+ */
+class TVM_DLL Object {
+ public:
+  /*!
+   * \brief Object deleter
+   * \param self pointer to the Object.
+   */
+  typedef void (*FDeleter)(Object* self);
+  /*! \return The internal runtime type index of the object. */
+  uint32_t type_index() const { return type_index_; }
+  /*!
+   * \return the type key of the object.
+   * \note this operation is expensive, can be used for error reporting.
+   */
+  std::string GetTypeKey() const { return TypeIndex2Key(type_index_); }
+  /*!
+   * \return A hash value of the return of GetTypeKey.
+   */
+  size_t GetTypeKeyHash() const { return TypeIndex2KeyHash(type_index_); }
+  /*!
+   * Check if the object is an instance of TargetType.
+   * \tparam TargetType The target type to be checked.
+   * \return Whether the target type is true.
+   */
+  template <typename TargetType>
+  inline bool IsInstance() const;
+  /*!
+   * \return Whether the cell has only one reference
+   * \note We use stl style naming to be consistent with known API in shared_ptr.
+   */
+  inline bool unique() const;
+  /*!
+   * \brief Get the type key of the corresponding index from runtime.
+   * \param tindex The type index.
+   * \return the result.
+   */
+  static std::string TypeIndex2Key(uint32_t tindex);
+  /*!
+   * \brief Get the type key hash of the corresponding index from runtime.
+   * \param tindex The type index.
+   * \return the related key-hash.
+   */
+  static size_t TypeIndex2KeyHash(uint32_t tindex);
+  /*!
+   * \brief Get the type index of the corresponding key from runtime.
+   * \param key The type key.
+   * \return the result.
+   */
+  static uint32_t TypeKey2Index(const std::string& key);
+
+#if TVM_OBJECT_ATOMIC_REF_COUNTER
+  using RefCounterType = std::atomic<int32_t>;
+#else
+  using RefCounterType = int32_t;
+#endif
+
+  static constexpr const char* _type_key = "runtime.Object";
+
+  static uint32_t _GetOrAllocRuntimeTypeIndex() { return TypeIndex::kRoot; }
+  static uint32_t RuntimeTypeIndex() { return TypeIndex::kRoot; }
+
+  // Default object type properties for sub-classes
+  static constexpr bool _type_final = false;
+  static constexpr uint32_t _type_child_slots = 0;
+  static constexpr bool _type_child_slots_can_overflow = true;
+  // member information
+  static constexpr bool _type_has_method_visit_attrs = true;
+  static constexpr bool _type_has_method_sequal_reduce = false;
+  static constexpr bool _type_has_method_shash_reduce = false;
+  // NOTE: the following field is not type index of Object
+  // but was intended to be used by sub-classes as default value.
+  // The type index of Object is TypeIndex::kRoot
+  static constexpr uint32_t _type_index = TypeIndex::kDynamic;
+
+  // Default constructor and copy constructor
+  Object() {}
+  // Override the copy and assign constructors to do nothing.
+  // This is to make sure only contents, but not deleter and ref_counter
+  // are copied when a child class copies itself.
+  // This will enable us to use make_object<ObjectClass>(*obj_ptr)
+  // to copy an existing object.
+  Object(const Object& other) {  // NOLINT(*)
+  }
+  Object(Object&& other) {  // NOLINT(*)
+  }
+  Object& operator=(const Object& other) {  // NOLINT(*)
+    return *this;
+  }
+  Object& operator=(Object&& other) {  // NOLINT(*)
+    return *this;
+  }
+
+ protected:
+  // The fields of the base object cell.
+  /*! \brief Type index(tag) that indicates the type of the object. */
+  uint32_t type_index_{0};
+  /*! \brief The internal reference counter */
+  RefCounterType ref_counter_{0};
+  /*!
+   * \brief deleter of this object to enable customized allocation.
+   * If the deleter is nullptr, no deletion will be performed.
+   * The creator of the object must always set the deleter field properly.
+   */
+  FDeleter deleter_ = nullptr;
+  // Invariant checks.
+  static_assert(sizeof(int32_t) == sizeof(RefCounterType) &&
+                    alignof(int32_t) == sizeof(RefCounterType),
+                "RefCounter ABI check.");
+
+  /*!
+   * \brief Get the type index using type key.
+   *
+   *  When the function is first time called for a type,
+   *  it will register the type to the type table in the runtime.
+   *  If the static_tindex is TypeIndex::kDynamic, the function will
+   *  allocate a runtime type index.
+   *  Otherwise, we will populate the type table and return the static index.
+   *
+   * \param key the type key.
+   * \param static_tindex The current _type_index field.
+   *                      can be TypeIndex::kDynamic.
+   * \param parent_tindex The index of the parent.
+   * \param type_child_slots Number of slots reserved for its children.
+   * \param type_child_slots_can_overflow Whether to allow child to overflow the slots.
+   * \return The allocated type index.
+   */
+  static uint32_t GetOrAllocRuntimeTypeIndex(const std::string& key, uint32_t static_tindex,
+                                             uint32_t parent_tindex, uint32_t type_child_slots,
+                                             bool type_child_slots_can_overflow);
+
+  // reference counter related operations
+  /*! \brief developer function, increases reference counter. */
+  inline void IncRef();
+  /*!
+   * \brief developer function, decrease reference counter.
+   * \note The deleter will be called when ref_counter_ becomes zero.
+   */
+  inline void DecRef();
+
+ private:
+  /*!
+   * \return The usage count of the cell.
+   * \note We use stl style naming to be consistent with known API in shared_ptr.
+   */
+  inline int use_count() const;
+  /*!
+   * \brief Check of this object is derived from the parent.
+   * \param parent_tindex The parent type index.
+   * \return The derivation results.
+   */
+  bool DerivedFrom(uint32_t parent_tindex) const;
+  // friend classes
+  template <typename>
+  friend class ObjAllocatorBase;
+  template <typename>
+  friend class ObjectPtr;
+  friend class TVMRetValue;
+  friend class ObjectInternal;
+};
+
+/*!
+ * \brief Get a reference type from a raw object ptr type
+ *
+ *  It is always important to get a reference type
+ *  if we want to return a value as reference or keep
+ *  the object alive beyond the scope of the function.
+ *
+ * \param ptr The object pointer
+ * \tparam RefType The reference type
+ * \tparam ObjectType The object type
+ * \return The corresponding RefType
+ */
+template <typename RelayRefType, typename ObjectType>
+inline RelayRefType GetRef(const ObjectType* ptr);
+
+/*!
+ * \brief Downcast a base reference type to a more specific type.
+ *
+ * \param ref The input reference
+ * \return The corresponding SubRef.
+ * \tparam SubRef The target specific reference type.
+ * \tparam BaseRef the current reference type.
+ */
+template <typename SubRef, typename BaseRef>
+inline SubRef Downcast(BaseRef ref);
+
+/*!
+ * \brief A custom smart pointer for Object.
+ * \tparam T the content data type.
+ * \sa make_object
+ */
+template <typename T>
+class ObjectPtr {
+ public:
+  /*! \brief default constructor */
+  ObjectPtr() {}
+  /*! \brief default constructor */
+  ObjectPtr(std::nullptr_t) {}  // NOLINT(*)
+  /*!
+   * \brief copy constructor
+   * \param other The value to be moved
+   */
+  ObjectPtr(const ObjectPtr<T>& other)  // NOLINT(*)
+      : ObjectPtr(other.data_) {}
+  /*!
+   * \brief copy constructor
+   * \param other The value to be moved
+   */
+  template <typename U>
+  ObjectPtr(const ObjectPtr<U>& other)  // NOLINT(*)
+      : ObjectPtr(other.data_) {
+    static_assert(std::is_base_of<T, U>::value,
+                  "can only assign of child class ObjectPtr to parent");
+  }
+  /*!
+   * \brief move constructor
+   * \param other The value to be moved
+   */
+  ObjectPtr(ObjectPtr<T>&& other)  // NOLINT(*)
+      : data_(other.data_) {
+    other.data_ = nullptr;
+  }
+  /*!
+   * \brief move constructor
+   * \param other The value to be moved
+   */
+  template <typename Y>
+  ObjectPtr(ObjectPtr<Y>&& other)  // NOLINT(*)
+      : data_(other.data_) {
+    static_assert(std::is_base_of<T, Y>::value,
+                  "can only assign of child class ObjectPtr to parent");
+    other.data_ = nullptr;
+  }
+  /*! \brief destructor */
+  ~ObjectPtr() { this->reset(); }
+  /*!
+   * \brief Swap this array with another Object
+   * \param other The other Object
+   */
+  void swap(ObjectPtr<T>& other) {  // NOLINT(*)
+    std::swap(data_, other.data_);
+  }
+  /*!
+   * \return Get the content of the pointer
+   */
+  T* get() const { return static_cast<T*>(data_); }
+  /*!
+   * \return The pointer
+   */
+  T* operator->() const { return get(); }
+  /*!
+   * \return The reference
+   */
+  T& operator*() const {  // NOLINT(*)
+    return *get();
+  }
+  /*!
+   * \brief copy assignment
+   * \param other The value to be assigned.
+   * \return reference to self.
+   */
+  ObjectPtr<T>& operator=(const ObjectPtr<T>& other) {  // NOLINT(*)
+    // takes in plane operator to enable copy elison.
+    // copy-and-swap idiom
+    ObjectPtr(other).swap(*this);  // NOLINT(*)
+    return *this;
+  }
+  /*!
+   * \brief move assignment
+   * \param other The value to be assigned.
+   * \return reference to self.
+   */
+  ObjectPtr<T>& operator=(ObjectPtr<T>&& other) {  // NOLINT(*)
+    // copy-and-swap idiom
+    ObjectPtr(std::move(other)).swap(*this);  // NOLINT(*)
+    return *this;
+  }
+  /*!
+   * \brief nullptr check
+   * \return result of comparison of internal pointer with nullptr.
+   */
+  explicit operator bool() const { return get() != nullptr; }
+  /*! \brief reset the content of ptr to be nullptr */
+  void reset() {
+    if (data_ != nullptr) {
+      data_->DecRef();
+      data_ = nullptr;
+    }
+  }
+  /*! \return The use count of the ptr, for debug purposes */
+  int use_count() const { return data_ != nullptr ? data_->use_count() : 0; }
+  /*! \return whether the reference is unique */
+  bool unique() const { return data_ != nullptr && data_->use_count() == 1; }
+  /*! \return Whether two ObjectPtr do not equal each other */
+  bool operator==(const ObjectPtr<T>& other) const { return data_ == other.data_; }
+  /*! \return Whether two ObjectPtr equals each other */
+  bool operator!=(const ObjectPtr<T>& other) const { return data_ != other.data_; }
+  /*! \return Whether the pointer is nullptr */
+  bool operator==(std::nullptr_t null) const { return data_ == nullptr; }
+  /*! \return Whether the pointer is not nullptr */
+  bool operator!=(std::nullptr_t null) const { return data_ != nullptr; }
+
+ private:
+  /*! \brief internal pointer field */
+  Object* data_{nullptr};
+  /*!
+   * \brief constructor from Object
+   * \param data The data pointer
+   */
+  explicit ObjectPtr(Object* data) : data_(data) {
+    if (data != nullptr) {
+      data_->IncRef();
+    }
+  }
+  /*!
+   * \brief Move an ObjectPtr from an RValueRef argument.
+   * \param ref The rvalue reference.
+   * \return the moved result.
+   */
+  static ObjectPtr<T> MoveFromRValueRefArg(Object** ref) {
+    ObjectPtr<T> ptr;
+    ptr.data_ = *ref;
+    *ref = nullptr;
+    return ptr;
+  }
+  // friend classes
+  friend class Object;
+  friend class ObjectRef;
+  friend struct ObjectPtrHash;
+  template <typename>
+  friend class ObjectPtr;
+  template <typename>
+  friend class ObjAllocatorBase;
+  friend class TVMPODValue_;
+  friend class TVMArgsSetter;
+  friend class TVMRetValue;
+  friend class TVMArgValue;
+  friend class TVMMovableArgValue_;
+  template <typename RelayRefType, typename ObjType>
+  friend RelayRefType GetRef(const ObjType* ptr);
+  template <typename BaseType, typename ObjType>
+  friend ObjectPtr<BaseType> GetObjectPtr(ObjType* ptr);
+};
+
+/*! \brief Base class of all object reference */
+class ObjectRef {
+ public:
+  /*! \brief default constructor */
+  ObjectRef() = default;
+  /*! \brief Constructor from existing object ptr */
+  explicit ObjectRef(ObjectPtr<Object> data) : data_(data) {}
+  /*!
+   * \brief Comparator
+   * \param other Another object ref.
+   * \return the compare result.
+   */
+  bool same_as(const ObjectRef& other) const { return data_ == other.data_; }
+  /*!
+   * \brief Comparator
+   * \param other Another object ref.
+   * \return the compare result.
+   */
+  bool operator==(const ObjectRef& other) const { return data_ == other.data_; }
+  /*!
+   * \brief Comparator
+   * \param other Another object ref.
+   * \return the compare result.
+   */
+  bool operator!=(const ObjectRef& other) const { return data_ != other.data_; }
+  /*!
+   * \brief Comparator
+   * \param other Another object ref by address.
+   * \return the compare result.
+   */
+  bool operator<(const ObjectRef& other) const { return data_.get() < other.data_.get(); }
+  /*!
+   * \return whether the object is defined(not null).
+   */
+  bool defined() const { return data_ != nullptr; }
+  /*! \return the internal object pointer */
+  const Object* get() const { return data_.get(); }
+  /*! \return the internal object pointer */
+  const Object* operator->() const { return get(); }
+  /*! \return whether the reference is unique */
+  bool unique() const { return data_.unique(); }
+  /*! \return The use count of the ptr, for debug purposes */
+  int use_count() const { return data_.use_count(); }
+  /*!
+   * \brief Try to downcast the internal Object to a
+   *  raw pointer of a corresponding type.
+   *
+   *  The function will return a nullptr if the cast failed.
+   *
+   * if (const Add *add = node_ref.As<Add>()) {
+   *   // This is an add node
+   * }
+   * \tparam ObjectType the target type, must be a subtype of Object/
+   */
+  template <typename ObjectType>
+  inline const ObjectType* as() const;
+
+  /*! \brief type indicate the container type. */
+  using ContainerType = Object;
+  // Default type properties for the reference class.
+  static constexpr bool _type_is_nullable = true;
+
+ protected:
+  /*! \brief Internal pointer that backs the reference. */
+  ObjectPtr<Object> data_;
+  /*! \return return a mutable internal ptr, can be used by sub-classes. */
+  Object* get_mutable() const { return data_.get(); }
+  /*!
+   * \brief Internal helper function downcast a ref without check.
+   * \note Only used for internal dev purposes.
+   * \tparam T The target reference type.
+   * \return The casted result.
+   */
+  template <typename T>
+  static T DowncastNoCheck(ObjectRef ref) {
+    return T(std::move(ref.data_));
+  }
+  /*!
+   * \brief Clear the object ref data field without DecRef
+   *        after we successfully moved the field.
+   * \param ref The reference data.
+   */
+  static void FFIClearAfterMove(ObjectRef* ref) { ref->data_.data_ = nullptr; }
+  /*!
+   * \brief Internal helper function get data_ as ObjectPtr of ObjectType.
+   * \note only used for internal dev purpose.
+   * \tparam ObjectType The corresponding object type.
+   * \return the corresponding type.
+   */
+  template <typename ObjectType>
+  static ObjectPtr<ObjectType> GetDataPtr(const ObjectRef& ref) {
+    return ObjectPtr<ObjectType>(ref.data_.data_);
+  }
+  // friend classes.
+  friend struct ObjectPtrHash;
+  friend class TVMRetValue;
+  friend class TVMArgsSetter;
+  friend class ObjectInternal;
+  template <typename SubRef, typename BaseRef>
+  friend SubRef Downcast(BaseRef ref);
+};
+
+/*!
+ * \brief Get an object ptr type from a raw object ptr.
+ *
+ * \param ptr The object pointer
+ * \tparam BaseType The reference type
+ * \tparam ObjectType The object type
+ * \return The corresponding RefType
+ */
+template <typename BaseType, typename ObjectType>
+inline ObjectPtr<BaseType> GetObjectPtr(ObjectType* ptr);
+
+/*! \brief ObjectRef hash functor */
+struct ObjectPtrHash {
+  size_t operator()(const ObjectRef& a) const { return operator()(a.data_); }
+
+  template <typename T>
+  size_t operator()(const ObjectPtr<T>& a) const {
+    return std::hash<Object*>()(a.get());
+  }
+};
+
+/*! \brief ObjectRef equal functor */
+struct ObjectPtrEqual {
+  bool operator()(const ObjectRef& a, const ObjectRef& b) const { return a.same_as(b); }
+
+  template <typename T>
+  size_t operator()(const ObjectPtr<T>& a, const ObjectPtr<T>& b) const {
+    return a == b;
+  }
+};
+
+/*!
+ * \brief helper macro to declare a base object type that can be inherited.
+ * \param TypeName The name of the current type.
+ * \param ParentType The name of the ParentType
+ */
+#define TVM_DECLARE_BASE_OBJECT_INFO(TypeName, ParentType)                                     \
+  static_assert(!ParentType::_type_final, "ParentObj marked as final");                        \
+  static uint32_t RuntimeTypeIndex() {                                                         \
+    static_assert(TypeName::_type_child_slots == 0 || ParentType::_type_child_slots == 0 ||    \
+                      TypeName::_type_child_slots < ParentType::_type_child_slots,             \
+                  "Need to set _type_child_slots when parent specifies it.");                  \
+    if (TypeName::_type_index != ::tvm::runtime::TypeIndex::kDynamic) {                        \
+      return TypeName::_type_index;                                                            \
+    }                                                                                          \
+    return _GetOrAllocRuntimeTypeIndex();                                                      \
+  }                                                                                            \
+  static uint32_t _GetOrAllocRuntimeTypeIndex() {                                              \
+    static uint32_t tindex = Object::GetOrAllocRuntimeTypeIndex(                               \
+        TypeName::_type_key, TypeName::_type_index, ParentType::_GetOrAllocRuntimeTypeIndex(), \
+        TypeName::_type_child_slots, TypeName::_type_child_slots_can_overflow);                \
+    return tindex;                                                                             \
+  }
+
+/*!
+ * \brief helper macro to declare type information in a final class.
+ * \param TypeName The name of the current type.
+ * \param ParentType The name of the ParentType
+ */
+#define TVM_DECLARE_FINAL_OBJECT_INFO(TypeName, ParentType) \
+  static const constexpr bool _type_final = true;           \
+  static const constexpr int _type_child_slots = 0;         \
+  TVM_DECLARE_BASE_OBJECT_INFO(TypeName, ParentType)
+
+/*! \brief helper macro to suppress unused warning */
+#if defined(__GNUC__)
+#define TVM_ATTRIBUTE_UNUSED __attribute__((unused))
+#else
+#define TVM_ATTRIBUTE_UNUSED
+#endif
+
+#define TVM_STR_CONCAT_(__x, __y) __x##__y
+#define TVM_STR_CONCAT(__x, __y) TVM_STR_CONCAT_(__x, __y)
+
+#define TVM_OBJECT_REG_VAR_DEF static TVM_ATTRIBUTE_UNUSED uint32_t __make_Object_tid
+
+/*!
+ * \brief Helper macro to register the object type to runtime.
+ *  Makes sure that the runtime type table is correctly populated.
+ *
+ *  Use this macro in the cc file for each terminal class.
+ */
+#define TVM_REGISTER_OBJECT_TYPE(TypeName) \
+  TVM_STR_CONCAT(TVM_OBJECT_REG_VAR_DEF, __COUNTER__) = TypeName::_GetOrAllocRuntimeTypeIndex()
+
+/*
+ * \brief Define the default copy/move constructor and assign operator
+ * \param TypeName The class typename.
+ */
+#define TVM_DEFINE_DEFAULT_COPY_MOVE_AND_ASSIGN(TypeName) \
+  TypeName(const TypeName& other) = default;              \
+  TypeName(TypeName&& other) = default;                   \
+  TypeName& operator=(const TypeName& other) = default;   \
+  TypeName& operator=(TypeName&& other) = default;
+
+/*
+ * \brief Define object reference methods.
+ * \param TypeName The object type name
+ * \param ParentType The parent type of the objectref
+ * \param ObjectName The type name of the object.
+ */
+#define TVM_DEFINE_OBJECT_REF_METHODS(TypeName, ParentType, ObjectName)                        \
+  TypeName() = default;                                                                        \
+  explicit TypeName(::tvm::runtime::ObjectPtr<::tvm::runtime::Object> n) : ParentType(n) {}    \
+  TVM_DEFINE_DEFAULT_COPY_MOVE_AND_ASSIGN(TypeName);                                           \
+  const ObjectName* operator->() const { return static_cast<const ObjectName*>(data_.get()); } \
+  const ObjectName* get() const { return operator->(); }                                       \
+  using ContainerType = ObjectName;
+
+/*
+ * \brief Define object reference methods that is not nullable.
+ *
+ * \param TypeName The object type name
+ * \param ParentType The parent type of the objectref
+ * \param ObjectName The type name of the object.
+ */
+#define TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(TypeName, ParentType, ObjectName)            \
+  explicit TypeName(::tvm::runtime::ObjectPtr<::tvm::runtime::Object> n) : ParentType(n) {}    \
+  TVM_DEFINE_DEFAULT_COPY_MOVE_AND_ASSIGN(TypeName);                                           \
+  const ObjectName* operator->() const { return static_cast<const ObjectName*>(data_.get()); } \
+  const ObjectName* get() const { return operator->(); }                                       \
+  static constexpr bool _type_is_nullable = false;                                             \
+  using ContainerType = ObjectName;
+
+/*
+ * \brief Define object reference methods of whose content is mutable.
+ * \param TypeName The object type name
+ * \param ParentType The parent type of the objectref
+ * \param ObjectName The type name of the object.
+ * \note We recommend making objects immutable when possible.
+ *       This macro is only reserved for objects that stores runtime states.
+ */
+#define TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(TypeName, ParentType, ObjectName)             \
+  TypeName() = default;                                                                     \
+  TVM_DEFINE_DEFAULT_COPY_MOVE_AND_ASSIGN(TypeName);                                        \
+  explicit TypeName(::tvm::runtime::ObjectPtr<::tvm::runtime::Object> n) : ParentType(n) {} \
+  ObjectName* operator->() const { return static_cast<ObjectName*>(data_.get()); }          \
+  using ContainerType = ObjectName;
+
+/*
+ * \brief Define object reference methods that is both not nullable and mutable.
+ *
+ * \param TypeName The object type name
+ * \param ParentType The parent type of the objectref
+ * \param ObjectName The type name of the object.
+ */
+#define TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(TypeName, ParentType, ObjectName) \
+  explicit TypeName(::tvm::runtime::ObjectPtr<::tvm::runtime::Object> n) : ParentType(n) {} \
+  TVM_DEFINE_DEFAULT_COPY_MOVE_AND_ASSIGN(TypeName);                                        \
+  ObjectName* operator->() const { return static_cast<ObjectName*>(data_.get()); }          \
+  ObjectName* get() const { return operator->(); }                                          \
+  static constexpr bool _type_is_nullable = false;                                          \
+  using ContainerType = ObjectName;
+
+/*!
+ * \brief Define CopyOnWrite function in an ObjectRef.
+ * \param ObjectName The Type of the Node.
+ *
+ *  CopyOnWrite will generate a unique copy of the internal node.
+ *  The node will be copied if it is referenced by multiple places.
+ *  The function returns the raw pointer to the node to allow modification
+ *  of the content.
+ *
+ * \code
+ *
+ *  MyCOWObjectRef ref, ref2;
+ *  ref2 = ref;
+ *  ref.CopyOnWrite()->value = new_value;
+ *  assert(ref2->value == old_value);
+ *  assert(ref->value == new_value);
+ *
+ * \endcode
+ */
+#define TVM_DEFINE_OBJECT_REF_COW_METHOD(ObjectName)     \
+  ObjectName* CopyOnWrite() {                            \
+    ICHECK(data_ != nullptr);                            \
+    if (!data_.unique()) {                               \
+      auto n = make_object<ObjectName>(*(operator->())); \
+      ObjectPtr<Object>(std::move(n)).swap(data_);       \
+    }                                                    \
+    return static_cast<ObjectName*>(data_.get());        \
+  }
+
+// Implementations details below
+// Object reference counting.
+#if TVM_OBJECT_ATOMIC_REF_COUNTER
+
+inline void Object::IncRef() { ref_counter_.fetch_add(1, std::memory_order_relaxed); }
+
+inline void Object::DecRef() {
+  if (ref_counter_.fetch_sub(1, std::memory_order_release) == 1) {
+    std::atomic_thread_fence(std::memory_order_acquire);
+    if (this->deleter_ != nullptr) {
+      (*this->deleter_)(this);
+    }
+  }
+}
+
+inline int Object::use_count() const { return ref_counter_.load(std::memory_order_relaxed); }
+
+#else
+
+inline void Object::IncRef() { ++ref_counter_; }
+
+inline void Object::DecRef() {
+  if (--ref_counter_ == 0) {
+    if (this->deleter_ != nullptr) {
+      (*this->deleter_)(this);
+    }
+  }
+}
+
+inline int Object::use_count() const { return ref_counter_; }
+
+#endif  // TVM_OBJECT_ATOMIC_REF_COUNTER
+
+template <typename TargetType>
+inline bool Object::IsInstance() const {
+  const Object* self = this;
+  // NOTE: the following code can be optimized by
+  // compiler dead-code elimination for already known constants.
+  if (self != nullptr) {
+    // Everything is a subclass of object.
+    if (std::is_same<TargetType, Object>::value) return true;
+    if (TargetType::_type_final) {
+      // if the target type is a final type
+      // then we only need to check the equivalence.
+      return self->type_index_ == TargetType::RuntimeTypeIndex();
+    } else {
+      // if target type is a non-leaf type
+      // Check if type index falls into the range of reserved slots.
+      uint32_t begin = TargetType::RuntimeTypeIndex();
+      // The condition will be optimized by constant-folding.
+      if (TargetType::_type_child_slots != 0) {
+        uint32_t end = begin + TargetType::_type_child_slots;
+        if (self->type_index_ >= begin && self->type_index_ < end) return true;
+      } else {
+        if (self->type_index_ == begin) return true;
+      }
+      if (!TargetType::_type_child_slots_can_overflow) return false;
+      // Invariance: parent index is always smaller than the child.
+      if (self->type_index_ < TargetType::RuntimeTypeIndex()) return false;
+      // The rare slower-path, check type hierarchy.
+      return self->DerivedFrom(TargetType::RuntimeTypeIndex());
+    }
+  } else {
+    return false;
+  }
+}
+
+inline bool Object::unique() const { return use_count() == 1; }
+
+template <typename ObjectType>
+inline const ObjectType* ObjectRef::as() const {
+  if (data_ != nullptr && data_->IsInstance<ObjectType>()) {
+    return static_cast<ObjectType*>(data_.get());
+  } else {
+    return nullptr;
+  }
+}
+
+template <typename RefType, typename ObjType>
+inline RefType GetRef(const ObjType* ptr) {
+  static_assert(std::is_base_of<typename RefType::ContainerType, ObjType>::value,
+                "Can only cast to the ref of same container type");
+  if (!RefType::_type_is_nullable) {
+    ICHECK(ptr != nullptr);
+  }
+  return RefType(ObjectPtr<Object>(const_cast<Object*>(static_cast<const Object*>(ptr))));
+}
+
+template <typename BaseType, typename ObjType>
+inline ObjectPtr<BaseType> GetObjectPtr(ObjType* ptr) {
+  static_assert(std::is_base_of<BaseType, ObjType>::value,
+                "Can only cast to the ref of same container type");
+  return ObjectPtr<BaseType>(static_cast<Object*>(ptr));
+}
+
+template <typename SubRef, typename BaseRef>
+inline SubRef Downcast(BaseRef ref) {
+  if (ref.defined()) {
+    ICHECK(ref->template IsInstance<typename SubRef::ContainerType>())
+        << "Downcast from " << ref->GetTypeKey() << " to " << SubRef::ContainerType::_type_key
+        << " failed.";
+  } else {
+    ICHECK(SubRef::_type_is_nullable) << "Downcast from nullptr to not nullable reference of "
+                                      << SubRef::ContainerType::_type_key;
+  }
+  return SubRef(std::move(ref.data_));
+}
+
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_OBJECT_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/packed_func.h b/darknet_drp_ros/include/tvm/runtime/packed_func.h
new file mode 100644
index 0000000..9b92f64
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/packed_func.h
@@ -0,0 +1,2010 @@
+/*
+ * Extended by EdgeCortix, Inc.
+ */
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/packed_func.h
+ * \brief Type-erased function used across TVM API.
+ */
+#ifndef TVM_RUNTIME_PACKED_FUNC_H_
+#define TVM_RUNTIME_PACKED_FUNC_H_
+
+#include <tvm/runtime/c_runtime_api.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/map.h>
+#include <tvm/runtime/data_type.h>
+#include <tvm/runtime/logging.h>
+#include <tvm/runtime/module.h>
+#include <tvm/runtime/ndarray.h>
+#include <tvm/runtime/object.h>
+
+#include <functional>
+#include <limits>
+#include <memory>
+#include <string>
+#include <tuple>
+#include <type_traits>
+#include <utility>
+#include <vector>
+
+// Whether use TVM runtime in header only mode.
+#ifndef TVM_RUNTIME_HEADER_ONLY
+#define TVM_RUNTIME_HEADER_ONLY 0
+#endif
+
+namespace tvm {
+namespace runtime {
+
+// forward declarations
+class TVMArgs;
+class TVMArgValue;
+class TVMMovableArgValueWithContext_;
+class TVMRetValue;
+class TVMArgsSetter;
+template <typename FType>
+class TypedPackedFunc;
+template <typename TSignature>
+struct SignaturePrinter;
+
+/*!
+ * \brief Object container class that backs PackedFunc.
+ * \note Do not use this function directly, use PackedFunc.
+ */
+class PackedFuncObj : public Object {
+ public:
+  /*!
+   * \brief Call the function in packed format.
+   * \param args The arguments
+   * \param rv The return value.
+   */
+  TVM_ALWAYS_INLINE void CallPacked(TVMArgs args, TVMRetValue* rv) const;
+
+  static constexpr const uint32_t _type_index = TypeIndex::kRuntimePackedFunc;
+  static constexpr const char* _type_key = "runtime.PackedFunc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PackedFuncObj, Object);
+
+ protected:
+  /*!
+   * \brief Internal struct for extracting the callable method from callable type.
+   */
+  template <class TPackedFuncSubObj>
+  struct Extractor {
+    /*!
+     * \brief Extracting the callable method from callable type.
+     * \param obj The base packed function object class.
+     * \param args The arguments
+     * \param rv The return value.
+     */
+    static void Call(const PackedFuncObj* obj, TVMArgs args, TVMRetValue* rv);
+  };
+
+  /*! \brief The internal callable function type. */
+  using FCallPacked = void(const PackedFuncObj*, TVMArgs, TVMRetValue*);
+
+  /*!
+   * \brief Constructing a packed function object from a function pointer.
+   * \param f_call_pack The function pointer used to call the packed function.
+   */
+  explicit PackedFuncObj(FCallPacked* f_call_pack) : f_call_packed_(f_call_pack) {}
+
+  /*! \brief Delete the default constructor explicitly. */
+  PackedFuncObj() = delete;
+
+  /*! \brief Internal callable function pointer used to call the packed function. */
+  FCallPacked* f_call_packed_;
+};
+
+/*! \brief Derived object class for constructing PackedFuncObj. */
+template <class TCallable>
+class PackedFuncSubObj : public PackedFuncObj {
+  using TStorage = typename std::remove_cv<typename std::remove_reference<TCallable>::type>::type;
+
+ public:
+  /*! \brief The type of derived object class */
+  using TSelf = PackedFuncSubObj<TCallable>;
+  /*!
+   * \brief Derived object class for constructing PackedFuncObj.
+   * \param callable The type-erased callable object.
+   */
+  explicit PackedFuncSubObj(TCallable callable)
+      : PackedFuncObj(Extractor<TSelf>::Call), callable_(callable) {}
+  /*! \brief Type-erased filed for storing callable object*/
+  mutable TStorage callable_;
+};
+
+/*!
+ * \brief Packed function is a type-erased function.
+ *  The arguments are passed by packed format.
+ *
+ *  This is an useful unified interface to call generated functions,
+ *  It is the unified function function type of TVM.
+ *  It corresponds to TVMFunctionHandle in C runtime API.
+ */
+class PackedFunc : public ObjectRef {
+ public:
+  /*! \brief Constructor from null */
+  PackedFunc(std::nullptr_t null) : ObjectRef(nullptr) {}  // NOLINT(*)
+  /*!
+   * \brief Constructing a packed function from a callable type
+   *        whose signature is consistent with `PackedFunc`
+   * \param data the internal container of packed function.
+   */
+  template <typename TCallable,
+            typename = std::enable_if_t<
+                std::is_convertible<TCallable, std::function<void(TVMArgs, TVMRetValue*)>>::value &&
+                !std::is_base_of<TCallable, PackedFunc>::value>>
+  explicit PackedFunc(TCallable data) {
+    using ObjType = PackedFuncSubObj<TCallable>;
+    data_ = make_object<ObjType>(std::forward<TCallable>(data));
+  }
+  /*!
+   * \brief Call packed function by directly passing in unpacked format.
+   * \param args Arguments to be passed.
+   * \tparam Args arguments to be passed.
+   *
+   * \code
+   *   // Example code on how to call packed function
+   *   void CallPacked(PackedFunc f) {
+   *     // call like normal functions by pass in arguments
+   *     // return value is automatically converted back
+   *     int rvalue = f(1, 2.0);
+   *   }
+   * \endcode
+   */
+  template <typename... Args>
+  inline TVMRetValue operator()(Args&&... args) const;
+  /*!
+   * \brief Call the function in packed format.
+   * \param args The arguments
+   * \param rv The return value.
+   */
+  TVM_ALWAYS_INLINE void CallPacked(TVMArgs args, TVMRetValue* rv) const;
+  /*! \return Whether the packed function is nullptr */
+  bool operator==(std::nullptr_t null) const { return data_ == nullptr; }
+  /*! \return Whether the packed function is not nullptr */
+  bool operator!=(std::nullptr_t null) const { return data_ != nullptr; }
+
+  TVM_DEFINE_OBJECT_REF_METHODS(PackedFunc, ObjectRef, PackedFuncObj);
+};
+
+/*! \brief Using static function to output TypedPackedFunc signature */
+using FSig = std::string();
+
+/*!
+ * \brief Please refer to \ref TypedPackedFuncAnchor "TypedPackedFunc<R(Args..)>"
+ */
+template <typename FType>
+class TypedPackedFunc;
+
+/*!
+ * \anchor TypedPackedFuncAnchor
+ * \brief A PackedFunc wrapper to provide typed function signature.
+ * It is backed by a PackedFunc internally.
+ *
+ * TypedPackedFunc enables compile time type checking.
+ * TypedPackedFunc works with the runtime system:
+ * - It can be passed as an argument of PackedFunc.
+ * - It can be assigned to TVMRetValue.
+ * - It can be directly converted to a type-erased PackedFunc.
+ *
+ * Developers should prefer TypedPackedFunc over PackedFunc in C++ code
+ * as it enables compile time checking.
+ * We can construct a TypedPackedFunc from a lambda function
+ * with the same signature.
+ *
+ * \code
+ *  // user defined lambda function.
+ *  auto addone = [](int x)->int {
+ *    return x + 1;
+ *  };
+ *  // We can directly convert
+ *  // lambda function to TypedPackedFunc
+ *  TypedPackedFunc<int(int)> ftyped(addone);
+ *  // invoke the function.
+ *  int y = ftyped(1);
+ *  // Can be directly converted to PackedFunc
+ *  PackedFunc packed = ftype;
+ * \endcode
+ * \tparam R The return value of the function.
+ * \tparam Args The argument signature of the function.
+ */
+template <typename R, typename... Args>
+class TypedPackedFunc<R(Args...)> {
+ public:
+  /*! \brief short hand for this function type */
+  using TSelf = TypedPackedFunc<R(Args...)>;
+  /*! \brief default constructor */
+  TypedPackedFunc() {}
+  /*! \brief constructor from null */
+  TypedPackedFunc(std::nullptr_t null) {}  // NOLINT(*)
+  /*!
+   * \brief construct by wrap a PackedFunc
+   *
+   * Example usage:
+   * \code
+   * PackedFunc packed([](TVMArgs args, TVMRetValue *rv) {
+   *   int x = args[0];
+   *   *rv = x + 1;
+   *  });
+   * // construct from packed function
+   * TypedPackedFunc<int(int)> ftyped(packed);
+   * // call the typed version.
+   * ICHECK_EQ(ftyped(1), 2);
+   * \endcode
+   *
+   * \param packed The packed function
+   */
+  inline TypedPackedFunc(PackedFunc packed);  // NOLINT(*)
+  /*!
+   * \brief constructor from TVMRetValue
+   * \param value The TVMRetValue
+   */
+  inline TypedPackedFunc(const TVMRetValue& value);  // NOLINT(*)
+  /*!
+   * \brief constructor from TVMArgValue
+   * \param value The TVMArgValue
+   */
+  inline TypedPackedFunc(const TVMArgValue& value);  // NOLINT(*)
+  /*!
+   * \brief constructor from TVMMovableArgValue_
+   * \param value The TVMMovableArgValue_
+   */
+  inline TypedPackedFunc(TVMMovableArgValueWithContext_&& value);  // NOLINT(*)
+  /*!
+   * \brief construct from a lambda function with the same signature.
+   *
+   * Example usage:
+   * \code
+   * auto typed_lambda = [](int x)->int { return x + 1; }
+   * // construct from packed function
+   * TypedPackedFunc<int(int)> ftyped(typed_lambda, "add_one");
+   * // call the typed version.
+   * ICHECK_EQ(ftyped(1), 2);
+   * \endcode
+   *
+   * \param typed_lambda typed lambda function.
+   * \param name the name of the lambda function.
+   * \tparam FLambda the type of the lambda function.
+   */
+  template <typename FLambda, typename = typename std::enable_if<std::is_convertible<
+                                  FLambda, std::function<R(Args...)>>::value>::type>
+  TypedPackedFunc(const FLambda& typed_lambda, std::string name) {  // NOLINT(*)
+    this->AssignTypedLambda(typed_lambda, name);
+  }
+  /*!
+   * \brief construct from a lambda function with the same signature.
+   *
+   * This version does not take a name. It is highly recommend you use the
+   * version that takes a name for the lambda.
+   *
+   * Example usage:
+   * \code
+   * auto typed_lambda = [](int x)->int { return x + 1; }
+   * // construct from packed function
+   * TypedPackedFunc<int(int)> ftyped(typed_lambda);
+   * // call the typed version.
+   * ICHECK_EQ(ftyped(1), 2);
+   * \endcode
+   *
+   * \param typed_lambda typed lambda function.
+   * \tparam FLambda the type of the lambda function.
+   */
+  template <typename FLambda, typename = typename std::enable_if<std::is_convertible<
+                                  FLambda, std::function<R(Args...)>>::value>::type>
+  TypedPackedFunc(const FLambda& typed_lambda) {  // NOLINT(*)
+    this->AssignTypedLambda(typed_lambda);
+  }
+  /*!
+   * \brief copy assignment operator from typed lambda
+   *
+   * Example usage:
+   * \code
+   * // construct from packed function
+   * TypedPackedFunc<int(int)> ftyped;
+   * ftyped = [](int x) { return x + 1; }
+   * // call the typed version.
+   * ICHECK_EQ(ftyped(1), 2);
+   * \endcode
+   *
+   * \param typed_lambda typed lambda function.
+   * \tparam FLambda the type of the lambda function.
+   * \returns reference to self.
+   */
+  template <typename FLambda, typename = typename std::enable_if<
+                                  std::is_convertible<FLambda,
+                                                      std::function<R(Args...)>>::value>::type>
+  TSelf& operator=(FLambda typed_lambda) {  // NOLINT(*)
+    this->AssignTypedLambda(typed_lambda);
+    return *this;
+  }
+  /*!
+   * \brief copy assignment operator from PackedFunc.
+   * \param packed The packed function.
+   * \returns reference to self.
+   */
+  TSelf& operator=(PackedFunc packed) {
+    packed_ = packed;
+    return *this;
+  }
+  /*!
+   * \brief Invoke the operator.
+   * \param args The arguments
+   * \returns The return value.
+   */
+  TVM_ALWAYS_INLINE R operator()(Args... args) const;
+  /*!
+   * \brief convert to PackedFunc
+   * \return the internal PackedFunc
+   */
+  operator PackedFunc() const { return packed(); }
+  /*!
+   * \return reference the internal PackedFunc
+   */
+  const PackedFunc& packed() const { return packed_; }
+  /*! \return Whether the packed function is nullptr */
+  bool operator==(std::nullptr_t null) const { return packed_ == nullptr; }
+  /*! \return Whether the packed function is not nullptr */
+  bool operator!=(std::nullptr_t null) const { return packed_ != nullptr; }
+
+ private:
+  friend class TVMRetValue;
+  /*! \brief The internal packed function */
+  PackedFunc packed_;
+  /*!
+   * \brief Assign the packed field using a typed lambda function.
+   *
+   * \param flambda The lambda function.
+   * \param name The name associated with this lambda.
+   * \tparam FLambda The lambda function type.
+   * \note We capture the lambda when possible for maximum efficiency.
+   */
+  template <typename FLambda>
+  inline void AssignTypedLambda(FLambda flambda, std::string name);
+  /*!
+   * \brief Assign the packed field using a typed lambda function. This variant is for functions
+   * without names.
+   *
+   * \param flambda The lambda function.
+   * \tparam FLambda The lambda function type.
+   * \note We capture the lambda when possible for maximum efficiency.
+   */
+  template <typename FLambda>
+  inline void AssignTypedLambda(FLambda flambda);
+};
+
+/*! \brief Arguments into TVM functions. */
+class TVMArgs {
+ public:
+  const TVMValue* values;
+  const int* type_codes;
+  int num_args;
+  uint64_t base_virtual_address;
+  /*!
+   * \brief constructor
+   * \param values The argument values
+   * \param type_codes The argument type codes
+   * \param num_args number of arguments.
+   */
+  TVMArgs(const TVMValue* values, const int* type_codes, int num_args)
+      : values(values), type_codes(type_codes), num_args(num_args), base_virtual_address{0} {}
+  /*!
+   * \brief constructor
+   * \param values The argument values
+   * \param type_codes The argument type codes
+   * \param num_args number of arguments.
+   * \param base_virtual_address virtual base address of in/out buffer
+   */
+  TVMArgs(const TVMValue* values, const int* type_codes, int num_args, uint64_t base_virtual_address)
+      : values(values), type_codes(type_codes), num_args(num_args), base_virtual_address{base_virtual_address} {}
+  /*! \return size of the arguments */
+  inline int size() const;
+  /*!
+   * \brief Get i-th argument
+   * \param i the index.
+   * \return the ith argument.
+   */
+  inline TVMArgValue operator[](int i) const;
+};
+
+/*!
+ * \brief Convert argument type code to string.
+ * \param type_code The input type code.
+ * \return The corresponding string repr.
+ */
+inline const char* ArgTypeCode2Str(int type_code);
+
+// macro to check type code.
+#define TVM_CHECK_TYPE_CODE(CODE, T) \
+  ICHECK_EQ(CODE, T) << "expected " << ArgTypeCode2Str(T) << " but got " << ArgTypeCode2Str(CODE)
+
+/*!
+ * \brief Type traits for runtime type check during FFI conversion.
+ * \tparam T the type to be checked.
+ */
+template <typename T>
+struct ObjectTypeChecker {
+  /*!
+   * \brief Check if an object matches the template type and return the
+   *        mismatched type if it exists.
+   * \param ptr The object to check the type of.
+   * \return An Optional containing the actual type of the pointer if it does not match the
+   *         template type. If the Optional does not contain a value, then the types match.
+   */
+  static Optional<String> CheckAndGetMismatch(const Object* ptr) {
+    using ContainerType = typename T::ContainerType;
+    if (ptr == nullptr) {
+      if (T::_type_is_nullable) {
+        return NullOpt;
+      } else {
+        return String("nullptr");
+      }
+    }
+    if (ptr->IsInstance<ContainerType>()) {
+      return NullOpt;
+    } else {
+      return String(ptr->GetTypeKey());
+    }
+  }
+  /*!
+   * \brief Check if an object matches the template type.
+   * \param ptr The object to check the type of.
+   * \return Whether or not the template type matches the objects type.
+   */
+  static bool Check(const Object* ptr) {
+    using ContainerType = typename T::ContainerType;
+    if (ptr == nullptr) return T::_type_is_nullable;
+    return ptr->IsInstance<ContainerType>();
+  }
+  static std::string TypeName() {
+    using ContainerType = typename T::ContainerType;
+    return ContainerType::_type_key;
+  }
+};
+
+// Additional overloads for PackedFunc checking.
+template <typename T>
+struct ObjectTypeChecker<Array<T>> {
+  static Optional<String> CheckAndGetMismatch(const Object* ptr) {
+    if (ptr == nullptr) {
+      return NullOpt;
+    }
+    if (!ptr->IsInstance<ArrayNode>()) {
+      return String(ptr->GetTypeKey());
+    }
+    const ArrayNode* n = static_cast<const ArrayNode*>(ptr);
+    for (size_t i = 0; i < n->size(); i++) {
+      const ObjectRef& p = (*n)[i];
+      Optional<String> check_subtype = ObjectTypeChecker<T>::CheckAndGetMismatch(p.get());
+      if (check_subtype.defined()) {
+        return String("Array[index " + std::to_string(i) + ": " + check_subtype.value() + "]");
+      }
+    }
+    return NullOpt;
+  }
+  static bool Check(const Object* ptr) {
+    if (ptr == nullptr) return true;
+    if (!ptr->IsInstance<ArrayNode>()) return false;
+    const ArrayNode* n = static_cast<const ArrayNode*>(ptr);
+    for (const ObjectRef& p : *n) {
+      if (!ObjectTypeChecker<T>::Check(p.get())) {
+        return false;
+      }
+    }
+    return true;
+  }
+  static std::string TypeName() { return "Array[" + ObjectTypeChecker<T>::TypeName() + "]"; }
+};
+template <typename K, typename V>
+struct ObjectTypeChecker<Map<K, V>> {
+  static Optional<String> CheckAndGetMismatch(const Object* ptr) {
+    if (ptr == nullptr) return NullOpt;
+    if (!ptr->IsInstance<MapNode>()) return String(ptr->GetTypeKey());
+    const MapNode* n = static_cast<const MapNode*>(ptr);
+    for (const auto& kv : *n) {
+      Optional<String> key_type = ObjectTypeChecker<K>::CheckAndGetMismatch(kv.first.get());
+      Optional<String> value_type = ObjectTypeChecker<K>::CheckAndGetMismatch(kv.first.get());
+      if (key_type.defined() || value_type.defined()) {
+        std::string key_name =
+            key_type.defined() ? std::string(key_type.value()) : ObjectTypeChecker<K>::TypeName();
+        std::string value_name = value_type.defined() ? std::string(value_type.value())
+                                                      : ObjectTypeChecker<V>::TypeName();
+        return String("Map[" + key_name + ", " + value_name + "]");
+      }
+    }
+    return NullOpt;
+  }
+  static bool Check(const Object* ptr) {
+    if (ptr == nullptr) return true;
+    if (!ptr->IsInstance<MapNode>()) return false;
+    const MapNode* n = static_cast<const MapNode*>(ptr);
+    for (const auto& kv : *n) {
+      if (!ObjectTypeChecker<K>::Check(kv.first.get())) return false;
+      if (!ObjectTypeChecker<V>::Check(kv.second.get())) return false;
+    }
+    return true;
+  }
+  static std::string TypeName() {
+    return "Map[" + ObjectTypeChecker<K>::TypeName() + ", " + ObjectTypeChecker<V>::TypeName() +
+           ']';
+  }
+};
+
+/*!
+ * \brief Internal base class to
+ *  handle conversion to POD values.
+ */
+class TVMPODValue_ {
+ public:
+  operator double() const {
+    // Allow automatic conversion from int to float
+    // This avoids errors when user pass in int from
+    // the frontend while the API expects a float.
+    if (type_code_ == kDLInt) {
+      return static_cast<double>(value_.v_int64);
+    }
+    TVM_CHECK_TYPE_CODE(type_code_, kDLFloat);
+    return value_.v_float64;
+  }
+  operator int64_t() const {
+    TVM_CHECK_TYPE_CODE(type_code_, kDLInt);
+    return value_.v_int64;
+  }
+  operator uint64_t() const {
+    TVM_CHECK_TYPE_CODE(type_code_, kDLInt);
+    return value_.v_int64;
+  }
+  operator int() const {
+    TVM_CHECK_TYPE_CODE(type_code_, kDLInt);
+    ICHECK_LE(value_.v_int64, std::numeric_limits<int>::max());
+    ICHECK_GE(value_.v_int64, std::numeric_limits<int>::min());
+    return static_cast<int>(value_.v_int64);
+  }
+  operator bool() const {
+    TVM_CHECK_TYPE_CODE(type_code_, kDLInt);
+    return value_.v_int64 != 0;
+  }
+  operator void*() const {
+    if (type_code_ == kTVMNullptr) return nullptr;
+    if (type_code_ == kTVMDLTensorHandle) return value_.v_handle;
+    TVM_CHECK_TYPE_CODE(type_code_, kTVMOpaqueHandle);
+    return value_.v_handle;
+  }
+  operator DLTensor*() const {
+    if (type_code_ == kTVMDLTensorHandle || type_code_ == kTVMNDArrayHandle) {
+      return static_cast<DLTensor*>(value_.v_handle);
+    } else {
+      if (type_code_ == kTVMNullptr) return nullptr;
+      LOG(FATAL) << "Expected "
+                 << "DLTensor* or NDArray but got " << ArgTypeCode2Str(type_code_);
+      return nullptr;
+    }
+  }
+  operator NDArray() const {
+    if (type_code_ == kTVMNullptr) return NDArray(ObjectPtr<Object>(nullptr));
+    TVM_CHECK_TYPE_CODE(type_code_, kTVMNDArrayHandle);
+    return NDArray(NDArray::FFIDataFromHandle(static_cast<TVMArrayHandle>(value_.v_handle)));
+  }
+  operator Module() const {
+    if (type_code_ == kTVMNullptr) {
+      return Module(ObjectPtr<Object>(nullptr));
+    }
+    TVM_CHECK_TYPE_CODE(type_code_, kTVMModuleHandle);
+    return Module(ObjectPtr<Object>(static_cast<Object*>(value_.v_handle)));
+  }
+  operator PackedFunc() const {
+    if (type_code_ == kTVMNullptr) {
+      return PackedFunc(ObjectPtr<Object>(nullptr));
+    }
+    TVM_CHECK_TYPE_CODE(type_code_, kTVMPackedFuncHandle);
+    return PackedFunc(ObjectPtr<Object>(static_cast<Object*>(value_.v_handle)));
+  }
+  operator Device() const {
+    TVM_CHECK_TYPE_CODE(type_code_, kDLDevice);
+    return value_.v_device;
+  }
+  int type_code() const { return type_code_; }
+  /*!
+   * \brief return handle as specific pointer type.
+   * \tparam T the data type.
+   * \return The pointer type.
+   */
+  template <typename T>
+  T* ptr() const {
+    return static_cast<T*>(value_.v_handle);
+  }
+  // ObjectRef handling
+  template <typename TObjectRef,
+            typename = typename std::enable_if<std::is_base_of<ObjectRef, TObjectRef>::value>::type>
+  inline bool IsObjectRef() const;
+  template <typename TObjectRef>
+  inline TObjectRef AsObjectRef() const;
+
+ protected:
+  friend class TVMArgsSetter;
+  friend class TVMRetValue;
+  friend class TVMMovableArgValue_;
+  TVMPODValue_() : type_code_(kTVMNullptr) {}
+  TVMPODValue_(TVMValue value, int type_code) : value_(value), type_code_(type_code) {}
+
+  /*! \brief The value */
+  TVMValue value_;
+  /*! \brief the type code */
+  int type_code_;
+};
+
+/*!
+ * \brief A single argument value to PackedFunc.
+ *  Containing both type_code and TVMValue
+ *
+ *  Provides utilities to do type cast into other types.
+ */
+class TVMArgValue : public TVMPODValue_ {
+ public:
+  /*! \brief default constructor */
+  TVMArgValue() {}
+  /*!
+   * \brief constructor
+   * \param value of the function
+   * \param type_code The type code.
+   */
+  TVMArgValue(TVMValue value, int type_code) : TVMPODValue_(value, type_code) {}
+  // reuse converter from parent
+  using TVMPODValue_::operator double;
+  using TVMPODValue_::operator int64_t;
+  using TVMPODValue_::operator uint64_t;
+  using TVMPODValue_::operator int;
+  using TVMPODValue_::operator bool;
+  using TVMPODValue_::operator void*;
+  using TVMPODValue_::operator DLTensor*;
+  using TVMPODValue_::operator NDArray;
+  using TVMPODValue_::operator Device;
+  using TVMPODValue_::operator Module;
+  using TVMPODValue_::operator PackedFunc;
+  using TVMPODValue_::AsObjectRef;
+  using TVMPODValue_::IsObjectRef;
+
+  // conversion operator.
+  operator std::string() const {
+    if (type_code_ == kTVMDataType) {
+      return DLDataType2String(operator DLDataType());
+    } else if (type_code_ == kTVMBytes) {
+      TVMByteArray* arr = static_cast<TVMByteArray*>(value_.v_handle);
+      return std::string(arr->data, arr->size);
+    } else if (type_code_ == kTVMStr) {
+      return std::string(value_.v_str);
+    } else {
+      ICHECK(IsObjectRef<tvm::runtime::String>())
+          << "Could not convert TVM object of type " << runtime::Object::TypeIndex2Key(type_code_)
+          << " to a string.";
+      return AsObjectRef<tvm::runtime::String>().operator std::string();
+    }
+  }
+  template <typename FType>
+  operator TypedPackedFunc<FType>() const {
+    return TypedPackedFunc<FType>(operator PackedFunc());
+  }
+  const TVMValue& value() const { return value_; }
+
+  template <typename T, typename = typename std::enable_if<std::is_class<T>::value>::type>
+  inline operator T() const;
+  inline operator DLDataType() const;
+  inline operator DataType() const;
+};
+
+/*!
+ * \brief Internal auxiliary struct for TypedPackedFunc to indicate a movable argument.
+ *
+ *  We can only construct a movable argument once from a single argument position.
+ *  If the argument is passed as RValue reference, the result will be moved.
+ *  We should only construct a MovableArg from an argument once,
+ *  as the result will can moved.
+ *
+ * \note For internal development purpose only.
+ */
+class TVMMovableArgValue_ : public TVMPODValue_ {
+ public:
+  TVMMovableArgValue_(TVMValue value, int type_code) : TVMPODValue_(value, type_code) {}
+  // reuse converter from parent
+  using TVMPODValue_::operator double;
+  using TVMPODValue_::operator int64_t;
+  using TVMPODValue_::operator uint64_t;
+  using TVMPODValue_::operator int;
+  using TVMPODValue_::operator bool;
+  using TVMPODValue_::operator void*;
+  using TVMPODValue_::operator DLTensor*;
+  using TVMPODValue_::operator NDArray;
+  using TVMPODValue_::operator Device;
+  using TVMPODValue_::operator Module;
+  using TVMPODValue_::operator PackedFunc;
+  // reuse conversion rule from ArgValue.
+  operator std::string() const { return AsArgValue().operator std::string(); }
+  template <typename FType>
+  operator TypedPackedFunc<FType>() const {
+    return TypedPackedFunc<FType>(operator PackedFunc());
+  }
+  operator DLDataType() const { return AsArgValue().operator DLDataType(); }
+  operator DataType() const { return AsArgValue().operator DataType(); }
+  operator TVMArgValue() const { return AsArgValue(); }
+  /*!
+   * \brief Helper converter function.
+   *  Try to move out an argument if possible,
+   *  fall back to normal argument conversion rule otherwise.
+   */
+  template <typename T,
+            typename = typename std::enable_if<std::is_base_of<ObjectRef, T>::value>::type>
+  inline operator T() const;
+
+ private:
+  /*! \return The arg value repr of the value. */
+  TVMArgValue AsArgValue() const { return TVMArgValue(value_, type_code_); }
+};
+
+/*!
+ * \brief Internal auxiliary struct for TypedPackedFunc to indicate a movable argument with
+ * additional context information (function name and argument index) for better error reporting.
+ *
+ * \sa MovableArgValue_
+ * \note For internal development purpose only.
+ */
+class TVMMovableArgValueWithContext_ {
+ public:
+  /*!
+   * \brief move constructor from another return value.
+   * \param value The other return value.
+   * \param type_code The code associated with the type of the value.
+   * \param arg_index In a function call, this argument is at index arg_index (0-indexed).
+   * \param optional_name Name of the function being called. Can be nullptr if the function is not.
+   * \param f_sig Pointer to static function outputting signature of the function being called.
+   * named.
+   */
+  TVMMovableArgValueWithContext_(TVMValue value, int type_code, int arg_index,
+                                 const std::string* optional_name, FSig* f_sig)
+      : value_(value, type_code),
+        arg_index_(arg_index),
+        optional_name_(optional_name),
+        f_sig_(f_sig) {}
+
+  template <typename T>
+  operator T() const {
+    try {
+      return value_;  // implicit conversion happens here
+    } catch (dmlc::Error& e) {
+      LOG(FATAL) << "In function " << (optional_name_ == nullptr ? "<anonymous>" : *optional_name_)
+                 << (f_sig_ == nullptr ? "" : (*f_sig_)()) << ": error while converting argument "
+                 << arg_index_ << ": " << e.what();
+      throw;  // never reached, LOG(FATAL) throws, but this silences a warning.
+    }
+  }
+
+ private:
+  TVMMovableArgValue_ value_;
+  int arg_index_;
+  const std::string* optional_name_;
+  FSig* f_sig_;
+};
+
+/*!
+ * \brief Return Value container,
+ *  Unlike TVMArgValue, which only holds reference and do not delete
+ *  the underlying container during destruction.
+ *
+ *  TVMRetValue holds value and will manage the underlying containers
+ *  when it stores a complicated data type.
+ */
+class TVMRetValue : public TVMPODValue_ {
+ public:
+  /*! \brief default constructor */
+  TVMRetValue() {}
+  /*!
+   * \brief move constructor from another return value.
+   * \param other The other return value.
+   */
+  TVMRetValue(TVMRetValue&& other) : TVMPODValue_(other.value_, other.type_code_) {
+    other.value_.v_handle = nullptr;
+    other.type_code_ = kTVMNullptr;
+  }
+  /*! \brief destructor */
+  ~TVMRetValue() { this->Clear(); }
+  // reuse converter from parent
+  using TVMPODValue_::operator double;
+  using TVMPODValue_::operator int64_t;
+  using TVMPODValue_::operator uint64_t;
+  using TVMPODValue_::operator int;
+  using TVMPODValue_::operator bool;
+  using TVMPODValue_::operator void*;
+  using TVMPODValue_::operator DLTensor*;
+  using TVMPODValue_::operator Device;
+  using TVMPODValue_::operator NDArray;
+  using TVMPODValue_::operator Module;
+  using TVMPODValue_::operator PackedFunc;
+  using TVMPODValue_::AsObjectRef;
+  using TVMPODValue_::IsObjectRef;
+
+  TVMRetValue(const TVMRetValue& other) : TVMPODValue_() { this->Assign(other); }
+  // conversion operators
+  operator std::string() const {
+    if (type_code_ == kTVMDataType) {
+      return DLDataType2String(operator DLDataType());
+    } else if (type_code_ == kTVMBytes) {
+      return *ptr<std::string>();
+    }
+    TVM_CHECK_TYPE_CODE(type_code_, kTVMStr);
+    return *ptr<std::string>();
+  }
+  operator DLDataType() const {
+    if (type_code_ == kTVMStr) {
+      return String2DLDataType(operator std::string());
+    }
+    TVM_CHECK_TYPE_CODE(type_code_, kTVMDataType);
+    return value_.v_type;
+  }
+  operator DataType() const { return DataType(operator DLDataType()); }
+  template <typename FType>
+  operator TypedPackedFunc<FType>() const {
+    return TypedPackedFunc<FType>(operator PackedFunc());
+  }
+  // Assign operators
+  TVMRetValue& operator=(TVMRetValue&& other) {
+    this->Clear();
+    value_ = other.value_;
+    type_code_ = other.type_code_;
+    other.type_code_ = kTVMNullptr;
+    return *this;
+  }
+  TVMRetValue& operator=(double value) {
+    this->SwitchToPOD(kDLFloat);
+    value_.v_float64 = value;
+    return *this;
+  }
+  TVMRetValue& operator=(std::nullptr_t value) {
+    this->SwitchToPOD(kTVMNullptr);
+    value_.v_handle = value;
+    return *this;
+  }
+  TVMRetValue& operator=(void* value) {
+    this->SwitchToPOD(kTVMOpaqueHandle);
+    value_.v_handle = value;
+    return *this;
+  }
+  TVMRetValue& operator=(int64_t value) {
+    this->SwitchToPOD(kDLInt);
+    value_.v_int64 = value;
+    return *this;
+  }
+  TVMRetValue& operator=(int value) {
+    this->SwitchToPOD(kDLInt);
+    value_.v_int64 = value;
+    return *this;
+  }
+  TVMRetValue& operator=(DLDevice value) {
+    this->SwitchToPOD(kDLDevice);
+    value_.v_device = value;
+    return *this;
+  }
+  TVMRetValue& operator=(DLDataType t) {
+    this->SwitchToPOD(kTVMDataType);
+    value_.v_type = t;
+    return *this;
+  }
+  TVMRetValue& operator=(const DataType& other) { return operator=(other.operator DLDataType()); }
+  TVMRetValue& operator=(bool value) {
+    this->SwitchToPOD(kDLInt);
+    value_.v_int64 = value;
+    return *this;
+  }
+  TVMRetValue& operator=(std::string value) {
+    this->SwitchToClass(kTVMStr, value);
+    return *this;
+  }
+  TVMRetValue& operator=(TVMByteArray value) {
+    this->SwitchToClass(kTVMBytes, std::string(value.data, value.size));
+    return *this;
+  }
+  TVMRetValue& operator=(NDArray other) {
+    if (other.data_ != nullptr) {
+      this->Clear();
+      type_code_ = kTVMNDArrayHandle;
+      value_.v_handle = NDArray::FFIGetHandle(other);
+      ObjectRef::FFIClearAfterMove(&other);
+    } else {
+      SwitchToPOD(kTVMNullptr);
+      value_.v_handle = nullptr;
+    }
+    return *this;
+  }
+  TVMRetValue& operator=(Module m) {
+    SwitchToObject(kTVMModuleHandle, std::move(m.data_));
+    return *this;
+  }
+  TVMRetValue& operator=(PackedFunc f) {
+    this->SwitchToObject(kTVMPackedFuncHandle, std::move(f.data_));
+    return *this;
+  }
+  template <typename FType>
+  TVMRetValue& operator=(const TypedPackedFunc<FType>& f) {
+    return operator=(f.packed());
+  }
+  TVMRetValue& operator=(const TVMRetValue& other) {  // NOLINT(*0
+    this->Assign(other);
+    return *this;
+  }
+  TVMRetValue& operator=(const TVMArgValue& other) {
+    this->Assign(other);
+    return *this;
+  }
+  TVMRetValue& operator=(TVMMovableArgValue_&& other) {
+    this->Assign(other);
+    return *this;
+  }
+  /*!
+   * \brief Move the value back to front-end via C API.
+   *  This marks the current container as null.
+   *  The managed resources are moved to the front-end.
+   *  The front end should take charge in managing them.
+   *
+   * \param ret_value The return value.
+   * \param ret_type_code The return type code.
+   */
+  void MoveToCHost(TVMValue* ret_value, int* ret_type_code) {
+    // cannot move str; need specially handle.
+    ICHECK(type_code_ != kTVMStr && type_code_ != kTVMBytes);
+    *ret_value = value_;
+    *ret_type_code = type_code_;
+    type_code_ = kTVMNullptr;
+  }
+  /*!
+   * \brief Construct a new TVMRetValue by
+   *        moving from return value stored via C API.
+   * \param value the value.
+   * \param type_code The type code.
+   * \return The created TVMRetValue.
+   */
+  static TVMRetValue MoveFromCHost(TVMValue value, int type_code) {
+    // Can move POD and everything under the object system.
+    ICHECK(type_code <= kTVMPackedFuncHandle || type_code == kTVMNDArrayHandle);
+    TVMRetValue ret;
+    ret.value_ = value;
+    ret.type_code_ = type_code;
+    return ret;
+  }
+  /*! \return The value field, if the data is POD */
+  const TVMValue& value() const {
+    ICHECK(type_code_ != kTVMObjectHandle && type_code_ != kTVMPackedFuncHandle &&
+           type_code_ != kTVMModuleHandle && type_code_ != kTVMStr)
+        << "TVMRetValue.value can only be used for POD data";
+    return value_;
+  }
+  // ObjectRef handling
+  template <typename TObjectRef,
+            typename = typename std::enable_if<std::is_base_of<ObjectRef, TObjectRef>::value>::type>
+  inline TVMRetValue& operator=(TObjectRef other);
+  template <typename T, typename = typename std::enable_if<std::is_class<T>::value>::type>
+  inline operator T() const;
+
+ private:
+  template <typename T>
+  void Assign(const T& other) {
+    switch (other.type_code()) {
+      case kTVMStr: {
+        SwitchToClass<std::string>(kTVMStr, other);
+        break;
+      }
+      case kTVMBytes: {
+        SwitchToClass<std::string>(kTVMBytes, other);
+        break;
+      }
+      case kTVMPackedFuncHandle: {
+        *this = other.operator PackedFunc();
+        break;
+      }
+      case kTVMModuleHandle: {
+        *this = other.operator Module();
+        break;
+      }
+      case kTVMNDArrayHandle: {
+        *this = other.operator NDArray();
+        break;
+      }
+      case kTVMObjectHandle: {
+        // Avoid operator ObjectRef as we already know it is not NDArray/Module
+        SwitchToObject(kTVMObjectHandle,
+                       GetObjectPtr<Object>(static_cast<Object*>(other.value_.v_handle)));
+        break;
+      }
+      case kTVMObjectRValueRefArg: {
+        operator=(other.operator ObjectRef());
+        break;
+      }
+      default: {
+        SwitchToPOD(other.type_code());
+        value_ = other.value_;
+        break;
+      }
+    }
+  }
+  // get the internal container.
+  void SwitchToPOD(int type_code) {
+    if (type_code_ != type_code) {
+      this->Clear();
+      type_code_ = type_code;
+    }
+  }
+  template <typename T>
+  void SwitchToClass(int type_code, T v) {
+    if (type_code_ != type_code) {
+      this->Clear();
+      type_code_ = type_code;
+      value_.v_handle = new T(v);
+    } else {
+      *static_cast<T*>(value_.v_handle) = v;
+    }
+  }
+  void SwitchToObject(int type_code, ObjectPtr<Object> other) {
+    if (other.data_ != nullptr) {
+      this->Clear();
+      type_code_ = type_code;
+      // move the handle out
+      value_.v_handle = other.data_;
+      other.data_ = nullptr;
+    } else {
+      SwitchToPOD(kTVMNullptr);
+      value_.v_handle = nullptr;
+    }
+  }
+  void Clear() {
+    if (type_code_ == kTVMNullptr) return;
+    switch (type_code_) {
+      case kTVMStr:
+      case kTVMBytes:
+        delete ptr<std::string>();
+        break;
+      case kTVMPackedFuncHandle:
+        static_cast<Object*>(value_.v_handle)->DecRef();
+        break;
+      case kTVMNDArrayHandle: {
+        NDArray::FFIDecRef(static_cast<TVMArrayHandle>(value_.v_handle));
+        break;
+      }
+      case kTVMModuleHandle: {
+        static_cast<Object*>(value_.v_handle)->DecRef();
+        break;
+      }
+      case kTVMObjectHandle: {
+        static_cast<Object*>(value_.v_handle)->DecRef();
+        break;
+      }
+    }
+    type_code_ = kTVMNullptr;
+  }
+};
+
+/*!
+ * \brief Type trait to specify special value conversion rules from
+ *        TVMArgValue and TVMRetValue.
+ *
+ *  The trait can be specialized to add type specific conversion logic
+ *  from the TVMArgvalue and TVMRetValue.
+ *
+ * \tparam TObjectRef the specific ObjectRefType.
+ */
+template <typename TObjectRef>
+struct PackedFuncValueConverter {
+  /*!
+   * \brief Convert a TObjectRef from an argument value.
+   * \param val The argument value.
+   * \return the converted result.
+   */
+  static TObjectRef From(const TVMArgValue& val) { return val.AsObjectRef<TObjectRef>(); }
+  /*!
+   * \brief Convert a TObjectRef from a return value.
+   * \param val The argument value.
+   * \return the converted result.
+   */
+  static TObjectRef From(const TVMRetValue& val) { return val.AsObjectRef<TObjectRef>(); }
+};
+
+/*!
+ * \brief Export a function with the PackedFunc signature
+ *        as a PackedFunc that can be loaded by LibraryModule.
+ *
+ * \param ExportName The symbol name to be exported.
+ * \param Function The function with PackedFunc signature.
+ * \sa PackedFunc
+ *
+ * \code
+ *
+ * void AddOne_(TVMArgs args, TVMRetValue* rv) {
+ *   int value = args[0];
+ *   *rv = value + 1;
+ * }
+ * // Expose the function as "AddOne"
+ * TVM_DLL_EXPORT_PACKED_FUNC(AddOne, AddOne_);
+ *
+ * \endcode
+ */
+#define TVM_DLL_EXPORT_PACKED_FUNC(ExportName, Function)                                    \
+  extern "C" {                                                                              \
+  TVM_DLL int ExportName(TVMValue* args, int* type_code, int num_args, TVMValue* out_value, \
+                         int* out_type_code, void* resource_handle);                        \
+  int ExportName(TVMValue* args, int* type_code, int num_args, TVMValue* out_value,         \
+                 int* out_type_code, void* resource_handle) {                               \
+    try {                                                                                   \
+      ::tvm::runtime::TVMRetValue rv;                                                       \
+      Function(::tvm::runtime::TVMArgs(args, type_code, num_args), &rv);                    \
+      rv.MoveToCHost(out_value, out_type_code);                                             \
+      return 0;                                                                             \
+    } catch (const ::std::exception& _except_) {                                            \
+      TVMAPISetLastError(_except_.what());                                                  \
+      return -1;                                                                            \
+    }                                                                                       \
+  }                                                                                         \
+  }
+
+/*!
+ * \brief Export typed function as a PackedFunc
+ *        that can be loaded by LibraryModule.
+ *
+ * \param ExportName The symbol name to be exported.
+ * \param Function The typed function.
+ * \note ExportName and Function must be different,
+ *       see code examples below.
+ *
+ * \sa TypedPackedFunc
+ *
+ * \code
+ *
+ * int AddOne_(int x) {
+ *   return x + 1;
+ * }
+ *
+ * // Expose the function as "AddOne"
+ * TVM_DLL_EXPORT_TYPED_FUNC(AddOne, AddOne_);
+ *
+ * // Expose the function as "SubOne"
+ * TVM_DLL_EXPORT_TYPED_FUNC(SubOne, [](int x) {
+ *   return x - 1;
+ * });
+ *
+ * // The following code will cause compilation error.
+ * // Because the same Function and ExportName
+ * // TVM_DLL_EXPORT_TYPED_FUNC(AddOne_, AddOne_);
+ *
+ * // The following code is OK, assuming the macro
+ * // is in a different namespace from xyz
+ * // TVM_DLL_EXPORT_TYPED_FUNC(AddOne_, xyz::AddOne_);
+ *
+ * \endcode
+ */
+#define TVM_DLL_EXPORT_TYPED_FUNC(ExportName, Function)                                     \
+  extern "C" {                                                                              \
+  TVM_DLL int ExportName(TVMValue* args, int* type_code, int num_args, TVMValue* out_value, \
+                         int* out_type_code, void* resource_handle) {                       \
+    try {                                                                                   \
+      auto f = Function;                                                                    \
+      using FType = ::tvm::runtime::detail::function_signature<decltype(f)>::FType;         \
+      ::tvm::runtime::TVMRetValue rv;                                                       \
+      ::tvm::runtime::detail::unpack_call_by_signature<FType>::run(                         \
+          f, ::tvm::runtime::TVMArgs(args, type_code, num_args), &rv);                      \
+      rv.MoveToCHost(out_value, out_type_code);                                             \
+      return 0;                                                                             \
+    } catch (const ::std::exception& _except_) {                                            \
+      TVMAPISetLastError(_except_.what());                                                  \
+      return -1;                                                                            \
+    }                                                                                       \
+  }                                                                                         \
+  }
+
+inline TVMArgValue TVMArgs::operator[](int i) const {
+  ICHECK_LT(i, num_args) << "not enough argument passed, " << num_args << " passed"
+                         << " but request arg[" << i << "].";
+  return TVMArgValue(values[i], type_codes[i]);
+}
+
+inline int TVMArgs::size() const { return num_args; }
+
+template <class TPackedFuncSubObj>
+void PackedFuncObj::Extractor<TPackedFuncSubObj>::Call(const PackedFuncObj* obj, TVMArgs args,
+                                                       TVMRetValue* rv) {
+  (static_cast<const TPackedFuncSubObj*>(obj))->callable_(args, rv);
+}
+
+TVM_ALWAYS_INLINE void PackedFuncObj::CallPacked(TVMArgs args, TVMRetValue* rv) const {
+  (*f_call_packed_)(this, args, rv);
+}
+
+TVM_ALWAYS_INLINE void PackedFunc::CallPacked(TVMArgs args, TVMRetValue* rv) const {
+  (static_cast<PackedFuncObj*>(data_.get()))->CallPacked(args, rv);
+}
+
+// internal namespace
+inline const char* ArgTypeCode2Str(int type_code) {
+  switch (type_code) {
+    case kDLInt:
+      return "int";
+    case kDLUInt:
+      return "uint";
+    case kDLFloat:
+      return "float";
+    case kTVMStr:
+      return "str";
+    case kTVMBytes:
+      return "bytes";
+    case kTVMOpaqueHandle:
+      return "handle";
+    case kTVMNullptr:
+      return "NULL";
+    case kTVMDLTensorHandle:
+      return "ArrayHandle";
+    case kTVMDataType:
+      return "DLDataType";
+    case kDLDevice:
+      return "DLDevice";
+    case kTVMPackedFuncHandle:
+      return "FunctionHandle";
+    case kTVMModuleHandle:
+      return "ModuleHandle";
+    case kTVMNDArrayHandle:
+      return "NDArrayContainer";
+    case kTVMObjectHandle:
+      return "Object";
+    case kTVMObjectRValueRefArg:
+      return "ObjectRValueRefArg";
+    default:
+      LOG(FATAL) << "unknown type_code=" << static_cast<int>(type_code);
+  }
+}
+
+namespace detail {
+
+template <bool stop, std::size_t I, typename F>
+struct for_each_dispatcher {
+  template <typename T, typename... Args>
+  static void run(const F& f, T&& value, Args&&... args) {  // NOLINT(*)
+    f(I, std::forward<T>(value));
+    for_each_dispatcher<sizeof...(Args) == 0, (I + 1), F>::run(f, std::forward<Args>(args)...);
+  }
+};
+
+template <std::size_t I, typename F>
+struct for_each_dispatcher<true, I, F> {
+  static void run(const F& f) {}  // NOLINT(*)
+};
+
+template <typename F, typename... Args>
+inline void for_each(const F& f, Args&&... args) {  // NOLINT(*)
+  for_each_dispatcher<sizeof...(Args) == 0, 0, F>::run(f, std::forward<Args>(args)...);
+}
+
+namespace parameter_pack {
+
+template <typename... EnumArgs>
+struct EnumeratedParamPack {
+  struct Invoke {
+    template <template <size_t i, typename TArgument> class Functor, typename... ExtraParams>
+    static void F(ExtraParams&&... extra_params) {
+      using TExpander = int[];
+      (void)TExpander{
+          0,
+          (Functor<EnumArgs::i, typename EnumArgs::T>::F(extra_params...), 0)...,
+      };
+    }
+  };
+};
+
+template <typename... Args>
+struct EnumerateImpl {
+ private:
+  template <size_t _i, typename _T>
+  struct Item {
+    static const constexpr size_t i = _i;
+    using T = _T;
+  };
+
+  template <typename...>
+  struct Zipper;
+
+  template <std::size_t... id>
+  struct Zipper<std::integer_sequence<std::size_t, id...>> {
+    using T = EnumeratedParamPack<Item<id, Args>...>;
+  };
+
+ public:
+  using T = typename Zipper<std::index_sequence_for<Args...>>::T;
+};
+
+template <typename... Args>
+using Enumerate = typename EnumerateImpl<Args...>::T;
+
+template <typename... Args>
+struct ParamPack {
+  template <template <size_t i, typename TArgument> class Functor, typename... ExtraParams>
+  static void InvokeWithoutArg(ExtraParams&&... extra_params) {
+    Enumerate<Args...>::Invoke::template F<Functor, ExtraParams...>(
+        std::forward<ExtraParams>(extra_params)...);
+  }
+};
+
+}  // namespace parameter_pack
+
+/*!
+ * \brief Template class to get function signature of a function or functor.
+ * \tparam T The function/functor type.
+ */
+template <typename T>
+struct func_signature_helper {
+  using FType = void;
+};
+
+template <typename T, typename R, typename... Args>
+struct func_signature_helper<R (T::*)(Args...)> {
+  using FType = R(Args...);
+  using ParamType = parameter_pack::ParamPack<Args...>;
+  using RetType = R;
+  static_assert(!std::is_reference<R>::value, "TypedPackedFunc return reference");
+};
+
+template <typename T, typename R, typename... Args>
+struct func_signature_helper<R (T::*)(Args...) const> {
+  using FType = R(Args...);
+  using ParamType = parameter_pack::ParamPack<Args...>;
+  using RetType = R;
+  static_assert(!std::is_reference<R>::value, "TypedPackedFunc return reference");
+};
+
+/*!
+ * \brief Template class to get function signature of a function or functor.
+ * \tparam T The function/functor type.
+ */
+template <typename T>
+struct function_signature {
+  using FType = typename func_signature_helper<decltype(&T::operator())>::FType;
+  using ParamType = typename func_signature_helper<decltype(&T::operator())>::ParamType;
+  using RetType = typename func_signature_helper<decltype(&T::operator())>::RetType;
+};
+
+// handle case of function.
+template <typename R, typename... Args>
+struct function_signature<R(Args...)> {
+  using FType = R(Args...);
+  using ParamType = parameter_pack::ParamPack<Args...>;
+  using RetType = R;
+  static_assert(!std::is_reference<R>::value, "TypedPackedFunc return reference");
+};
+
+// handle case of function ptr.
+template <typename R, typename... Args>
+struct function_signature<R (*)(Args...)> {
+  using FType = R(Args...);
+  using ParamType = detail::parameter_pack::ParamPack<Args...>;
+  using RetType = R;
+  static_assert(!std::is_reference<R>::value, "TypedPackedFunc return reference");
+};
+
+template <typename TSignature>
+struct SignaturePrinter;
+
+namespace type2str {
+
+template <typename T>
+struct TypeSimplifier;
+
+template <typename T>
+struct Type2Str {
+  template <typename = std::enable_if_t<std::is_base_of<ObjectRef, T>::value>>
+  static std::string v() {
+    return T::ContainerType::_type_key;
+  }
+};
+template <>
+struct Type2Str<int> {
+  static std::string v() { return "int"; }
+};
+template <>
+struct Type2Str<double> {
+  static std::string v() { return "double"; }
+};
+template <>
+struct Type2Str<int64_t> {
+  static std::string v() { return "int64_t"; }
+};
+template <>
+struct Type2Str<uint64_t> {
+  static std::string v() { return "uint64_t"; }
+};
+template <>
+struct Type2Str<bool> {
+  static std::string v() { return "bool"; }
+};
+template <>
+struct Type2Str<void> {
+  static std::string v() { return "void"; }
+};
+template <>
+struct Type2Str<std::basic_string<char>> {
+  static std::string v() { return "basic_string<char>"; }
+};
+template <typename K, typename V>
+struct Type2Str<Map<K, V>> {
+  static std::string v() {
+    return "Map<" + TypeSimplifier<K>::v() + ", " + TypeSimplifier<V>::v() + ">";
+  }
+};
+template <>
+struct Type2Str<DLDevice> {
+  static std::string v() { return "DLDevice"; }
+};
+template <>
+struct Type2Str<DLTensor> {
+  static std::string v() { return "DLTensor"; }
+};
+template <>
+struct Type2Str<DataType> {
+  static std::string v() { return "DataType"; }
+};
+template <>
+struct Type2Str<DLDataType> {
+  static std::string v() { return "DLDataType"; }
+};
+template <>
+struct Type2Str<TVMRetValue> {
+  static std::string v() { return "TVMRetValue"; }
+};
+template <>
+struct Type2Str<TVMArgValue> {
+  static std::string v() { return "TVMArgValue"; }
+};
+template <typename FType>
+struct Type2Str<TypedPackedFunc<FType>> {
+  static std::string v() { return SignaturePrinter<function_signature<FType>>::F(); }
+};
+template <typename T>
+struct Type2Str<Array<T>> {
+  static std::string v() { return "Array<" + TypeSimplifier<T>::v() + ">"; }
+};
+
+/*!
+ * \brief Template class to remove const, pointer and reference of original type.
+ * \tparam T The original type.
+ */
+template <typename T>
+struct TypeSimplifier {
+  static std::string v() {
+    using U = typename std::remove_cv<
+        typename std::remove_reference<typename std::remove_pointer<T>::type>::type>::type;
+    return (std::is_const<T>::value ? "const " : "") + Type2Str<U>::v() +
+           (std::is_pointer<T>::value ? "*" : "") + (std::is_reference<T>::value ? "&" : "");
+  }
+};
+
+}  // namespace type2str
+
+/*!
+ * \brief Template class to generate static function outputting signature of a function or functor.
+ * \tparam TSignature The function/functor signature type generated by `function_signature`.
+ */
+template <typename TSignature>
+struct SignaturePrinter {
+  using ParamType = typename TSignature::ParamType;
+  using RetType = typename TSignature::RetType;
+
+  template <size_t i, typename TArgument>
+  struct PrintParamType {
+    static void F(std::ostream& os) {
+      os << (i == 0 ? "" : ", ") << i << ": " << type2str::TypeSimplifier<TArgument>::v();
+    }
+  };
+
+  static std::string F() {
+    std::ostringstream oss;
+    oss << "(";
+    ParamType::template InvokeWithoutArg<PrintParamType>(oss);
+    oss << ") -> " << type2str::TypeSimplifier<RetType>::v();
+    return oss.str();
+  }
+};
+}  // namespace detail
+
+/* \brief argument settter to PackedFunc */
+class TVMArgsSetter {
+ public:
+  TVMArgsSetter(TVMValue* values, int* type_codes) : values_(values), type_codes_(type_codes) {}
+  // setters for POD types
+  template <typename T, typename = typename std::enable_if<std::is_integral<T>::value>::type>
+  TVM_ALWAYS_INLINE void operator()(size_t i, T value) const {
+    values_[i].v_int64 = static_cast<int64_t>(value);
+    type_codes_[i] = kDLInt;
+  }
+  TVM_ALWAYS_INLINE void operator()(size_t i, uint64_t value) const {
+    values_[i].v_int64 = static_cast<int64_t>(value);
+    ICHECK_LE(value, static_cast<uint64_t>(std::numeric_limits<int64_t>::max()));
+    type_codes_[i] = kDLInt;
+  }
+  TVM_ALWAYS_INLINE void operator()(size_t i, double value) const {
+    values_[i].v_float64 = value;
+    type_codes_[i] = kDLFloat;
+  }
+  TVM_ALWAYS_INLINE void operator()(size_t i, std::nullptr_t value) const {
+    values_[i].v_handle = value;
+    type_codes_[i] = kTVMNullptr;
+  }
+  TVM_ALWAYS_INLINE void operator()(size_t i, const TVMArgValue& value) const {
+    values_[i] = value.value_;
+    type_codes_[i] = value.type_code_;
+  }
+  TVM_ALWAYS_INLINE void operator()(size_t i, void* value) const {
+    values_[i].v_handle = value;
+    type_codes_[i] = kTVMOpaqueHandle;
+  }
+  TVM_ALWAYS_INLINE void operator()(size_t i, DLTensor* value) const {
+    values_[i].v_handle = value;
+    type_codes_[i] = kTVMDLTensorHandle;
+  }
+  TVM_ALWAYS_INLINE void operator()(size_t i, Device value) const {
+    values_[i].v_device = value;
+    type_codes_[i] = kDLDevice;
+  }
+  TVM_ALWAYS_INLINE void operator()(size_t i, DLDataType value) const {
+    values_[i].v_type = value;
+    type_codes_[i] = kTVMDataType;
+  }
+  TVM_ALWAYS_INLINE void operator()(size_t i, DataType dtype) const {
+    operator()(i, dtype.operator DLDataType());
+  }
+  TVM_ALWAYS_INLINE void operator()(size_t i, const char* value) const {
+    values_[i].v_str = value;
+    type_codes_[i] = kTVMStr;
+  }
+  // setters for container types
+  TVM_ALWAYS_INLINE void operator()(size_t i, const std::string& value) const {
+    values_[i].v_str = value.c_str();
+    type_codes_[i] = kTVMStr;
+  }
+  TVM_ALWAYS_INLINE void operator()(size_t i, const TVMByteArray& value) const {
+    values_[i].v_handle = const_cast<TVMByteArray*>(&value);
+    type_codes_[i] = kTVMBytes;
+  }
+  template <typename FType>
+  TVM_ALWAYS_INLINE void operator()(size_t i, const TypedPackedFunc<FType>& value) const {
+    operator()(i, value.packed());
+  }
+  void operator()(size_t i, const TVMRetValue& value) const {
+    if (value.type_code() == kTVMStr) {
+      values_[i].v_str = value.ptr<std::string>()->c_str();
+      type_codes_[i] = kTVMStr;
+    } else {
+      ICHECK_NE(value.type_code(), kTVMBytes) << "not handled.";
+      values_[i] = value.value_;
+      type_codes_[i] = value.type_code();
+    }
+  }
+  // ObjectRef handling
+  template <typename TObjectRef,
+            typename = typename std::enable_if<std::is_base_of<ObjectRef, TObjectRef>::value>::type>
+  TVM_ALWAYS_INLINE void operator()(size_t i, const TObjectRef& value) const {
+    this->SetObject(i, value);
+  }
+
+  template <typename TObjectRef,
+            typename = typename std::enable_if<std::is_base_of<
+                ObjectRef, typename std::remove_reference<TObjectRef>::type>::value>::type>
+  TVM_ALWAYS_INLINE void operator()(size_t i, TObjectRef&& value) const {
+    this->SetObject(i, std::forward<TObjectRef>(value));
+  }
+
+ private:
+  template <typename TObjectRef>
+  inline void SetObject(size_t i, TObjectRef&& value) const;
+  /*! \brief The values fields */
+  TVMValue* values_;
+  /*! \brief The type code fields */
+  int* type_codes_;
+};
+
+template <typename... Args>
+inline TVMRetValue PackedFunc::operator()(Args&&... args) const {
+  const int kNumArgs = sizeof...(Args);
+  const int kArraySize = kNumArgs > 0 ? kNumArgs : 1;
+  TVMValue values[kArraySize];
+  int type_codes[kArraySize];
+  detail::for_each(TVMArgsSetter(values, type_codes), std::forward<Args>(args)...);
+  TVMRetValue rv;
+  (static_cast<PackedFuncObj*>(data_.get()))
+      ->CallPacked(TVMArgs(values, type_codes, kNumArgs), &rv);
+  return rv;
+}
+
+namespace detail {
+template <typename R, int nleft, int index, typename F>
+struct unpack_call_dispatcher {
+  template <typename... Args>
+  TVM_ALWAYS_INLINE static void run(const std::string* optional_name, FSig* f_sig, const F& f,
+                                    const TVMArgs& args_pack, TVMRetValue* rv,
+                                    Args&&... unpacked_args) {
+    // construct a movable argument value
+    // which allows potential move of argument to the input of F.
+    unpack_call_dispatcher<R, nleft - 1, index + 1, F>::run(
+        optional_name, f_sig, f, args_pack, rv, std::forward<Args>(unpacked_args)...,
+        TVMMovableArgValueWithContext_(args_pack.values[index], args_pack.type_codes[index], index,
+                                       optional_name, f_sig));
+  }
+};
+
+template <typename R, int index, typename F>
+struct unpack_call_dispatcher<R, 0, index, F> {
+  template <typename... Args>
+  TVM_ALWAYS_INLINE static void run(const std::string* optional_name, FSig* f_sig, const F& f,
+                                    const TVMArgs& args_pack, TVMRetValue* rv,
+                                    Args&&... unpacked_args) {
+    using RetType = decltype(f(std::forward<Args>(unpacked_args)...));
+    if (std::is_same<RetType, R>::value) {
+      *rv = f(std::forward<Args>(unpacked_args)...);
+    } else {
+      *rv = R(f(std::forward<Args>(unpacked_args)...));
+    }
+  }
+};
+
+template <int index, typename F>
+struct unpack_call_dispatcher<void, 0, index, F> {
+  template <typename... Args>
+  TVM_ALWAYS_INLINE static void run(const std::string* optional_name, FSig* f_sig, const F& f,
+                                    const TVMArgs& args_pack, TVMRetValue* rv,
+                                    Args&&... unpacked_args) {
+    f(std::forward<Args>(unpacked_args)...);
+  }
+};
+
+template <typename R, int nargs, typename F>
+TVM_ALWAYS_INLINE void unpack_call(const std::string* optional_name, const F& f,
+                                   const TVMArgs& args, TVMRetValue* rv) {
+  FSig* f_sig = detail::SignaturePrinter<detail::function_signature<F>>::F;
+  CHECK_EQ(nargs, args.size()) << "Function "
+                               << (optional_name == nullptr ? "<anonymous>" : *optional_name)
+                               << (f_sig == nullptr ? "" : (*f_sig)()) << " expects " << nargs
+                               << " arguments but " << args.size() << " were provided";
+  unpack_call_dispatcher<R, nargs, 0, F>::run(optional_name, f_sig, f, args, rv);
+}
+
+template <typename FType>
+struct unpack_call_by_signature {};
+
+template <typename R, typename... Args>
+struct unpack_call_by_signature<R(Args...)> {
+  template <typename F>
+  TVM_ALWAYS_INLINE static void run(const F& f, const TVMArgs& args, TVMRetValue* rv) {
+    unpack_call<R, sizeof...(Args)>(nullptr, f, args, rv);
+  }
+};
+
+template <typename R, typename... Args>
+TVM_ALWAYS_INLINE R call_packed(const PackedFunc& pf, Args&&... args) {
+  return R(pf(std::forward<Args>(args)...));
+}
+
+template <typename R>
+struct typed_packed_call_dispatcher {
+  template <typename... Args>
+  TVM_ALWAYS_INLINE static R run(const PackedFunc& pf, Args&&... args) {
+    return pf(std::forward<Args>(args)...);
+  }
+};
+
+template <>
+struct typed_packed_call_dispatcher<void> {
+  template <typename... Args>
+  TVM_ALWAYS_INLINE static void run(const PackedFunc& pf, Args&&... args) {
+    pf(std::forward<Args>(args)...);
+  }
+};
+}  // namespace detail
+
+template <typename R, typename... Args>
+TypedPackedFunc<R(Args...)>::TypedPackedFunc(PackedFunc packed) : packed_(packed) {}
+
+template <typename R, typename... Args>
+TypedPackedFunc<R(Args...)>::TypedPackedFunc(const TVMRetValue& value)
+    : packed_(value.operator PackedFunc()) {}
+
+template <typename R, typename... Args>
+TypedPackedFunc<R(Args...)>::TypedPackedFunc(const TVMArgValue& value)
+    : packed_(value.operator PackedFunc()) {}
+
+template <typename R, typename... Args>
+TypedPackedFunc<R(Args...)>::TypedPackedFunc(TVMMovableArgValueWithContext_&& value)
+    : packed_(value.operator PackedFunc()) {}
+
+template <typename R, typename... Args>
+template <typename FType>
+inline void TypedPackedFunc<R(Args...)>::AssignTypedLambda(FType flambda, std::string name) {
+  FSig* f_sig = detail::SignaturePrinter<detail::function_signature<FType>>::F;
+  packed_ = PackedFunc([flambda, name, f_sig](const TVMArgs& args, TVMRetValue* rv) {
+    if (args.size() != sizeof...(Args)) {
+      LOG(FATAL) << "Function " << name << (f_sig == nullptr ? "" : (*f_sig)()) << " expects "
+                 << sizeof...(Args) << " arguments, but " << args.size() << " were provided.";
+    }
+    detail::unpack_call<R, sizeof...(Args)>(&name, flambda, args, rv);
+  });
+}
+
+template <typename R, typename... Args>
+template <typename FType>
+inline void TypedPackedFunc<R(Args...)>::AssignTypedLambda(FType flambda) {
+  FSig* f_sig = detail::SignaturePrinter<detail::function_signature<FType>>::F;
+  packed_ = PackedFunc([flambda, f_sig](const TVMArgs& args, TVMRetValue* rv) {
+    if (args.size() != sizeof...(Args)) {
+      LOG(FATAL) << "Function <anonymous> " << (*f_sig)() << " expects " << sizeof...(Args)
+                 << " arguments, but " << args.size() << " were provided.";
+    }
+    detail::unpack_call<R, sizeof...(Args)>(nullptr, flambda, args, rv);
+  });
+}
+
+template <typename R, typename... Args>
+TVM_ALWAYS_INLINE R TypedPackedFunc<R(Args...)>::operator()(Args... args) const {
+  return detail::typed_packed_call_dispatcher<R>::run(packed_, std::forward<Args>(args)...);
+}
+
+// ObjectRef related conversion handling
+// Object can have three possible type codes:
+//      kTVMNDArrayHandle, kTVMModuleHandle, kTVMObjectHandle
+//
+// We use type traits to eliminate un-necessary checks.
+template <typename T>
+inline void TVMArgsSetter::SetObject(size_t i, T&& value) const {
+  using ContainerType = typename std::remove_reference<T>::type::ContainerType;
+  if (value.defined()) {
+    Object* ptr = value.data_.data_;
+    if (std::is_base_of<NDArray::ContainerType, ContainerType>::value ||
+        (std::is_base_of<ContainerType, NDArray::ContainerType>::value &&
+         ptr->IsInstance<NDArray::ContainerType>())) {
+      values_[i].v_handle = NDArray::FFIGetHandle(value);
+      type_codes_[i] = kTVMNDArrayHandle;
+    } else if (std::is_base_of<Module::ContainerType, ContainerType>::value ||
+               (std::is_base_of<ContainerType, Module::ContainerType>::value &&
+                ptr->IsInstance<Module::ContainerType>())) {
+      values_[i].v_handle = ptr;
+      type_codes_[i] = kTVMModuleHandle;
+    } else if (std::is_base_of<PackedFunc::ContainerType, ContainerType>::value ||
+               (std::is_base_of<ContainerType, PackedFunc::ContainerType>::value &&
+                ptr->IsInstance<PackedFunc::ContainerType>())) {
+      values_[i].v_handle = ptr;
+      type_codes_[i] = kTVMPackedFuncHandle;
+    } else if (std::is_rvalue_reference<decltype(value)>::value) {
+      values_[i].v_handle = const_cast<Object**>(&(value.data_.data_));
+      type_codes_[i] = kTVMObjectRValueRefArg;
+    } else {
+      values_[i].v_handle = value.data_.data_;
+      type_codes_[i] = kTVMObjectHandle;
+    }
+  } else {
+    type_codes_[i] = kTVMNullptr;
+    values_[i].v_handle = nullptr;
+  }
+}
+
+template <typename TObjectRef, typename>
+inline bool TVMPODValue_::IsObjectRef() const {
+  using ContainerType = typename TObjectRef::ContainerType;
+  // NOTE: the following code can be optimized by constant folding.
+  if (std::is_base_of<NDArray::ContainerType, ContainerType>::value) {
+    return type_code_ == kTVMNDArrayHandle &&
+           TVMArrayHandleToObjectHandle(static_cast<TVMArrayHandle>(value_.v_handle))
+               ->IsInstance<ContainerType>();
+  }
+  if (std::is_base_of<Module::ContainerType, ContainerType>::value) {
+    return type_code_ == kTVMModuleHandle &&
+           static_cast<Object*>(value_.v_handle)->IsInstance<ContainerType>();
+  }
+  if (std::is_base_of<PackedFunc::ContainerType, ContainerType>::value) {
+    return type_code_ == kTVMPackedFuncHandle &&
+           static_cast<Object*>(value_.v_handle)->IsInstance<ContainerType>();
+  }
+  // NOTE: we don't pass NDArray and runtime::Module as RValue ref.
+  if (type_code_ == kTVMObjectRValueRefArg) {
+    return ObjectTypeChecker<TObjectRef>::Check(*static_cast<Object**>(value_.v_handle));
+  }
+  return (std::is_base_of<ContainerType, NDArray::ContainerType>::value &&
+          type_code_ == kTVMNDArrayHandle) ||
+         (std::is_base_of<ContainerType, Module::ContainerType>::value &&
+          type_code_ == kTVMModuleHandle) ||
+         (std::is_base_of<ContainerType, PackedFunc::ContainerType>::value &&
+          type_code_ == kTVMPackedFuncHandle) ||
+         (type_code_ == kTVMObjectHandle &&
+          ObjectTypeChecker<TObjectRef>::Check(static_cast<Object*>(value_.v_handle)));
+}
+
+template <typename TObjectRef>
+inline TObjectRef TVMPODValue_::AsObjectRef() const {
+  static_assert(std::is_base_of<ObjectRef, TObjectRef>::value,
+                "Conversion only works for ObjectRef");
+  using ContainerType = typename TObjectRef::ContainerType;
+
+  if (type_code_ == kTVMNullptr) {
+    CHECK(TObjectRef::_type_is_nullable)
+        << "Expect a not null value of " << ContainerType::_type_key;
+    return TObjectRef(ObjectPtr<Object>(nullptr));
+  }
+  // NOTE: the following code can be optimized by constant folding.
+  if (std::is_base_of<NDArray::ContainerType, ContainerType>::value) {
+    // Casting to a sub-class of NDArray
+    TVM_CHECK_TYPE_CODE(type_code_, kTVMNDArrayHandle);
+    ObjectPtr<Object> data =
+        NDArray::FFIDataFromHandle(static_cast<TVMArrayHandle>(value_.v_handle));
+    CHECK(data->IsInstance<ContainerType>())
+        << "Expected " << ContainerType::_type_key << " but got " << data->GetTypeKey();
+    return TObjectRef(data);
+  }
+  if (std::is_base_of<Module::ContainerType, ContainerType>::value) {
+    // Casting to a sub-class of Module
+    TVM_CHECK_TYPE_CODE(type_code_, kTVMModuleHandle);
+    ObjectPtr<Object> data = GetObjectPtr<Object>(static_cast<Object*>(value_.v_handle));
+    CHECK(data->IsInstance<ContainerType>())
+        << "Expected " << ContainerType::_type_key << " but got " << data->GetTypeKey();
+    return TObjectRef(data);
+  }
+  if (std::is_base_of<PackedFunc::ContainerType, ContainerType>::value) {
+    // Casting to a sub-class of PackedFunc
+    TVM_CHECK_TYPE_CODE(type_code_, kTVMPackedFuncHandle);
+    ObjectPtr<Object> data = GetObjectPtr<Object>(static_cast<Object*>(value_.v_handle));
+    CHECK(data->IsInstance<ContainerType>())
+        << "Expected " << ContainerType::_type_key << " but got " << data->GetTypeKey();
+    return TObjectRef(data);
+  }
+  if (type_code_ == kTVMObjectHandle) {
+    // normal object type check.
+    Object* ptr = static_cast<Object*>(value_.v_handle);
+    Optional<String> checked_type = ObjectTypeChecker<TObjectRef>::CheckAndGetMismatch(ptr);
+    ICHECK(!checked_type.defined()) << "Expected " << ObjectTypeChecker<TObjectRef>::TypeName()
+                                    << ", but got " << checked_type.value();
+    return TObjectRef(GetObjectPtr<Object>(ptr));
+  } else if (type_code_ == kTVMObjectRValueRefArg) {
+    Object* ptr = *static_cast<Object**>(value_.v_handle);
+    Optional<String> checked_type = ObjectTypeChecker<TObjectRef>::CheckAndGetMismatch(ptr);
+    ICHECK(!checked_type.defined()) << "Expected " << ObjectTypeChecker<TObjectRef>::TypeName()
+                                    << ", but got " << checked_type.value();
+    return TObjectRef(GetObjectPtr<Object>(ptr));
+  } else if (std::is_base_of<ContainerType, NDArray::ContainerType>::value &&
+             type_code_ == kTVMNDArrayHandle) {
+    // Casting to a base class that NDArray can sub-class
+    ObjectPtr<Object> data =
+        NDArray::FFIDataFromHandle(static_cast<TVMArrayHandle>(value_.v_handle));
+    return TObjectRef(data);
+  } else if (std::is_base_of<ContainerType, Module::ContainerType>::value &&
+             type_code_ == kTVMModuleHandle) {
+    // Casting to a base class that Module can sub-class
+    return TObjectRef(GetObjectPtr<Object>(static_cast<Object*>(value_.v_handle)));
+  } else if (std::is_base_of<ContainerType, PackedFunc::ContainerType>::value &&
+             type_code_ == kTVMPackedFuncHandle) {
+    // Casting to a base class that PackedFunc can sub-class
+    return TObjectRef(GetObjectPtr<Object>(static_cast<Object*>(value_.v_handle)));
+  } else {
+    TVM_CHECK_TYPE_CODE(type_code_, kTVMObjectHandle);
+    return TObjectRef(ObjectPtr<Object>(nullptr));
+  }
+}
+
+template <typename TObjectRef, typename>
+inline TVMRetValue& TVMRetValue::operator=(TObjectRef other) {
+  using ContainerType = typename TObjectRef::ContainerType;
+  const Object* ptr = other.get();
+  if (ptr != nullptr) {
+    if (std::is_base_of<NDArray::ContainerType, ContainerType>::value ||
+        (std::is_base_of<ContainerType, NDArray::ContainerType>::value &&
+         ptr->IsInstance<NDArray::ContainerType>())) {
+      return operator=(NDArray(std::move(other.data_)));
+    }
+    if (std::is_base_of<Module::ContainerType, ContainerType>::value ||
+        (std::is_base_of<ContainerType, Module::ContainerType>::value &&
+         ptr->IsInstance<Module::ContainerType>())) {
+      return operator=(Module(std::move(other.data_)));
+    }
+    SwitchToObject(kTVMObjectHandle, std::move(other.data_));
+  } else {
+    SwitchToPOD(kTVMNullptr);
+    value_.v_handle = nullptr;
+  }
+  return *this;
+}
+
+template <typename T, typename>
+inline TVMArgValue::operator T() const {
+  return PackedFuncValueConverter<T>::From(*this);
+}
+
+template <typename T, typename>
+inline TVMMovableArgValue_::operator T() const {
+  if (type_code_ == kTVMObjectRValueRefArg) {
+    auto** ref = static_cast<Object**>(value_.v_handle);
+    if (ObjectTypeChecker<T>::Check(*ref)) {
+      return T(ObjectPtr<Object>::MoveFromRValueRefArg(ref));
+    }
+  }
+  // fallback
+  return PackedFuncValueConverter<T>::From(AsArgValue());
+}
+
+template <typename T, typename>
+inline TVMRetValue::operator T() const {
+  return PackedFuncValueConverter<T>::From(*this);
+}
+
+inline PackedFunc Module::GetFunction(const std::string& name, bool query_imports) {
+  return (*this)->GetFunction(name, query_imports);
+}
+
+// specializations of PackedFuncValueConverter
+template <>
+struct PackedFuncValueConverter<::tvm::runtime::String> {
+  static String From(const TVMArgValue& val) {
+    if (val.IsObjectRef<tvm::runtime::String>()) {
+      return val.AsObjectRef<tvm::runtime::String>();
+    } else {
+      return tvm::runtime::String(val.operator std::string());
+    }
+  }
+
+  static String From(const TVMRetValue& val) {
+    if (val.IsObjectRef<tvm::runtime::String>()) {
+      return val.AsObjectRef<tvm::runtime::String>();
+    } else {
+      return tvm::runtime::String(val.operator std::string());
+    }
+  }
+};
+
+template <typename T>
+struct PackedFuncValueConverter<Optional<T>> {
+  static Optional<T> From(const TVMArgValue& val) {
+    if (val.type_code() == kTVMNullptr) return Optional<T>(nullptr);
+    return PackedFuncValueConverter<T>::From(val);
+  }
+  static Optional<T> From(const TVMRetValue& val) {
+    if (val.type_code() == kTVMNullptr) return Optional<T>(nullptr);
+    return PackedFuncValueConverter<T>::From(val);
+  }
+};
+
+inline bool String::CanConvertFrom(const TVMArgValue& val) {
+  return val.type_code() == kTVMStr || val.IsObjectRef<tvm::runtime::String>();
+}
+
+inline TVMArgValue::operator DLDataType() const {
+  if (String::CanConvertFrom(*this)) {
+    return String2DLDataType(PackedFuncValueConverter<String>::From(*this).operator std::string());
+  }
+  // None type
+  if (type_code_ == kTVMNullptr) {
+    DLDataType t;
+    t.code = kTVMOpaqueHandle;
+    t.bits = 0;
+    t.lanes = 0;
+    return t;
+  }
+  TVM_CHECK_TYPE_CODE(type_code_, kTVMDataType);
+  return value_.v_type;
+}
+
+inline TVMArgValue::operator DataType() const { return DataType(operator DLDataType()); }
+
+}  // namespace runtime
+}  // namespace tvm
+#endif  // TVM_RUNTIME_PACKED_FUNC_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/profiling.h b/darknet_drp_ros/include/tvm/runtime/profiling.h
new file mode 100644
index 0000000..3922ef7
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/profiling.h
@@ -0,0 +1,594 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file include/tvm/runtime/profiling.h
+ * \brief Runtime profiling including timers.
+ */
+#ifndef TVM_RUNTIME_PROFILING_H_
+#define TVM_RUNTIME_PROFILING_H_
+
+#include <tvm/runtime/c_runtime_api.h>
+#include <tvm/runtime/container/map.h>
+#include <tvm/runtime/device_api.h>
+#include <tvm/runtime/object.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/runtime/registry.h>
+
+#include <stack>
+#include <string>
+#include <unordered_map>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+
+namespace runtime {
+
+/*! \brief Base class for all implementations.
+ *
+ * New implementations of this interface should make sure that `Start` and `Stop`
+ * are as lightweight as possible. Expensive state synchronization should be
+ * done in `SyncAndGetElapsedNanos`.
+ */
+class TimerNode : public Object {
+ public:
+  /*! \brief Start the timer.
+   *
+   * Note: this function should only be called once per object.
+   */
+  virtual void Start() = 0;
+  /*! \brief Stop the timer.
+   *
+   * Note: this function should only be called once per object.
+   */
+  virtual void Stop() = 0;
+  /*! \brief Synchronize timer state and return elapsed time between `Start` and `Stop`.
+   * \return The time in nanoseconds between `Start` and `Stop`.
+   *
+   * This function is necessary because we want to avoid timing the overhead of
+   * doing timing. When using multiple timers, it is recommended to stop all of
+   * them before calling `SyncAndGetElapsedNanos` on any of them.
+   *
+   * Note: this function should be only called once per object. It may incur
+   * a large synchronization overhead (for example, with GPUs).
+   */
+  virtual int64_t SyncAndGetElapsedNanos() = 0;
+
+  virtual ~TimerNode() {}
+
+  static constexpr const char* _type_key = "TimerNode";
+  TVM_DECLARE_BASE_OBJECT_INFO(TimerNode, Object);
+};
+
+/*! \brief Timer for a specific device.
+ *
+ * This is a managed reference to a TimerNode.
+ *
+ * \sa TimerNode
+ */
+class Timer : public ObjectRef {
+ public:
+  /*!
+   * \brief Get a device specific timer.
+   * \param dev The device to time.
+   * \return A `Timer` that has already been started.
+   *
+   * Use this function to time runtime of arbitrary regions of code on a specific
+   * device. The code that you want to time should be running on the device
+   * otherwise the timer will not return correct results. This is a lower level
+   * interface than TimeEvaluator and only runs the timed code once
+   * (TimeEvaluator runs the code multiple times).
+   *
+   * A default timer is used if a device specific one does not exist. This
+   * timer performs synchronization between the device and CPU, which can lead
+   * to overhead in the reported results.
+   *
+   * Example usage:
+   * \code{.cpp}
+   * Timer t = Timer::Start(Device::cpu());
+   * my_long_running_function();
+   * t->Stop();
+   * ... // some more computation
+   * int64_t nanosecs = t->SyncAndGetElapsedNanos() // elapsed time in nanoseconds
+   * \endcode
+   *
+   * To add a new device-specific timer, register a new function
+   * "profiler.timer.my_device" (where `my_device` is the `DeviceName` of your
+   * device). This function should accept a `Device` and return a new `Timer`
+   * that has already been started.
+   *
+   * For example, this is how the CPU timer is implemented:
+   * \code{.cpp}
+   *  class CPUTimerNode : public TimerNode {
+   *   public:
+   *    virtual void Start() { start_ = std::chrono::high_resolution_clock::now(); }
+   *    virtual void Stop() { duration_ = std::chrono::high_resolution_clock::now() - start_; }
+   *    virtual int64_t SyncAndGetElapsedNanos() { return duration_.count(); }
+   *    virtual ~CPUTimerNode() {}
+   *
+   *    static constexpr const char* _type_key = "CPUTimerNode";
+   *    TVM_DECLARE_FINAL_OBJECT_INFO(CPUTimerNode, TimerNode);
+   *
+   *   private:
+   *    std::chrono::high_resolution_clock::time_point start_;
+   *    std::chrono::duration<int64_t, std::nano> duration_;
+   *  };
+   *  TVM_REGISTER_OBJECT_TYPE(CPUTimerNode);
+   *
+   *  TVM_REGISTER_GLOBAL("profiling.timer.cpu").set_body_typed([](Device dev) {
+   *    return Timer(make_object<CPUTimerNode>());
+   *  });
+   * \endcode
+   */
+  static TVM_DLL Timer Start(Device dev);
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(Timer, ObjectRef, TimerNode);
+};
+
+/*!
+ * \brief Default timer if one does not exist for the device.
+ * \param dev The device to time on.
+ *
+ * Note that this timer performs synchronization between the device and CPU,
+ * which can lead to overhead in the reported results.
+ */
+Timer DefaultTimer(Device dev);
+
+namespace profiling {
+/*! \brief Wrapper for `Device` because `Device` is not passable across the
+ * PackedFunc interface.
+ */
+struct DeviceWrapperNode : public Object {
+  /*! The device */
+  Device device;
+
+  /*! Constructor */
+  explicit DeviceWrapperNode(Device device) : device(device) {}
+
+  static constexpr const char* _type_key = "runtime.profiling.DeviceWrapper";
+  TVM_DECLARE_BASE_OBJECT_INFO(DeviceWrapperNode, Object);
+};
+
+/*! \brief Wrapper for `Device`. */
+class DeviceWrapper : public ObjectRef {
+ public:
+  explicit DeviceWrapper(Device dev) { data_ = make_object<DeviceWrapperNode>(dev); }
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(DeviceWrapper, ObjectRef, DeviceWrapperNode);
+};
+
+/*! \brief Data collected from a profiling run. Includes per-call metrics and per-device metrics.
+ */
+class ReportNode : public Object {
+ public:
+  /*! \brief A list of function calls and the metrics recorded for that call.
+   *
+   * Each element is a mapping from metric name to value. Some metrics that
+   * appear in every call are "Name" (the function name), "Argument Shapes",
+   * and "Duration (us)". Values are one of `String`, `PercentNode`,
+   * `DurationNode`, or `CountNode`.
+   */
+  Array<Map<String, ObjectRef>> calls;
+  /*! \brief Metrics collected for the entire run of the model on a per-device basis.
+   *
+   * `device_metrics` is indexed by device name then metric.
+   *
+   * These metrics may be larger than the sum of the same metric in `calls`
+   * because these metrics include the overhead of the executor.
+   */
+  Map<String, Map<String, ObjectRef>> device_metrics;
+  /*! Configuration used for this profiling run. Includes number of threads, executor.
+   *
+   * Values must be an object type that can be used with device_metrics.
+   */
+  Map<String, ObjectRef> configuration;
+  /*! \brief Output `calls` in CSV format.
+   *
+   * Note that this does not include `device_metrics`, it only includes per-call metrics.
+   */
+  String AsCSV() const;
+  /*! \brief Create a human readable table of profiling metrics.
+   *
+   *  \param aggregate Whether or not to join multiple calls to the
+   *      same op into a single line.
+   *
+   *  \param sort Whether or not to sort call frames by descending
+   *      duration. If false and if `aggregate` is false, frames will
+   *      be sorted by order of appearance in the program. Order is
+   *      undefined if `sort` is false and `aggregate` is true.
+   *
+   *  \param compute_col_sums Whether or not to include sum totals for
+   *      the Count, Duation, and Percent columns.
+   *
+   */
+  String AsTable(bool sort = true, bool aggregate = true, bool compute_col_sums = true) const;
+  /*! \brief Convert this report to JSON.
+   *
+   * Output JSON will be of this format:
+   * \code
+   *  {
+   *    "calls": [
+   *      {
+   *        "Duration (us)": {
+   *          "microseconds": 12.3
+   *        },
+   *        "Name": "fused_dense",
+   *        "Count": {
+   *          "count": 1
+   *        },
+   *        "Percent": {
+   *          "percent": 10.3
+   *        }
+   *      }
+   *    ],
+   *    "device_metrics": {
+   *      "cpu": {
+   *        "Duration (us)": {
+   *          "microseconds": 334.2
+   *        },
+   *        "Percent": {
+   *          "percent": 100
+   *        }
+   *      }
+   *    }
+   *  }
+   * \endcode
+   */
+  String AsJSON() const;
+
+  static constexpr const char* _type_key = "runtime.profiling.Report";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ReportNode, Object);
+};
+
+class Report : public ObjectRef {
+ public:
+  /*! Construct a Report from a set of calls (with associated metrics) and per-device metrics.
+   * \param calls Function calls and associated metrics.
+   * \param device_metrics Per-device metrics for overall execution.
+   * \param configuration Configuration data specific to this profiling run.
+   */
+  explicit Report(Array<Map<String, ObjectRef>> calls,
+                  Map<String, Map<String, ObjectRef>> device_metrics,
+                  Map<String, ObjectRef> configuration);
+
+  /*! Deserialize a Report from a JSON object. Needed for sending the report over RPC.
+   * \param json Serialized json report from `ReportNode::AsJSON`.
+   * \returns A Report.
+   */
+  static Report FromJSON(String json);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(Report, ObjectRef, ReportNode);
+};
+
+/*! \brief Interface for user defined profiling metric collection.
+ *
+ * Users can register their own collector by registering a packed function with
+ * the name "runtime.profiling.metrics.my_collector_name" where
+ * "my_collector_name" is the name of their collector. This function should
+ * take an Array of Device as input which contains the devices the collector
+ * will be run on.
+ *
+ * `MetricCollectorNode`s will be called in the following fashion.
+ * \code
+ * MetricCollector mc;
+ * for (auto op : model) {
+ *   auto o = mc.Start();
+ *   op();
+ *   auto metrics = mc.Stop(o); // metrics are added the profiling report
+ * }
+ * \endcode
+ */
+class MetricCollectorNode : public Object {
+ public:
+  /*! \brief Initialization call. Called before profiling has started. Any
+   * expensive precomputation should happen here.
+   * \param devs The list of devices this collector will be run on.
+   */
+  virtual void Init(Array<DeviceWrapper> devs) = 0;
+  /*! \brief Start colling metrics for a function call.
+   * \param dev The device the call will be run on.
+   * \returns An object used to maintain state of the metric collection. This
+   * object will be passed to the corresponding `Stop` call. If the device is
+   * not supported, this function will return a nullptr ObjectRef.
+   */
+  virtual ObjectRef Start(Device dev) = 0;
+  /*! \brief Stop collecting metrics.
+   * \param obj The object created by the corresponding `Start` call.
+   * \returns A set of metric names and the associated values. Values must be
+   * one of DurationNode, PercentNode, CountNode, or StringObj.
+   */
+  virtual Map<String, ObjectRef> Stop(ObjectRef obj) = 0;
+
+  virtual ~MetricCollectorNode() {}
+
+  static constexpr const char* _type_key = "runtime.profiling.MetricCollector";
+  TVM_DECLARE_BASE_OBJECT_INFO(MetricCollectorNode, Object);
+};
+
+/*! \brief Wrapper for `MetricCollectorNode`. */
+class MetricCollector : public ObjectRef {
+ public:
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(MetricCollector, ObjectRef, MetricCollectorNode);
+};
+
+/*! Information about a single function or operator call. */
+struct CallFrame {
+  /*! Device on which the call was made */
+  Device dev;
+  /*! Name of the function or op */
+  String name;
+  /*! Runtime of the function or op */
+  Timer timer;
+  /*! Extra performance metrics */
+  std::unordered_map<std::string, ObjectRef> extra_metrics;
+  /*! User defined metric collectors. Each pair is the MetricCollector and its
+   * associated data (returned from MetricCollector.Start).
+   */
+  std::vector<std::pair<MetricCollector, ObjectRef>> extra_collectors;
+};
+
+/*! Runtime profiler for function and/or operator calls. Used in the graph
+ * runtime and VM to provide profiling information for all operators.
+ *
+ * Example usage:
+ * \code{.cpp}
+ * Device cpu, gpu;
+ * Profiler prof({cpu, gpu});
+ * my_gpu_kernel(); // do a warmup iteration
+ * prof.Start();
+ * prof.StartCall("my_gpu_kernel", gpu);
+ * my_gpu_kernel();
+ * prof.StopCall();
+ * prof.StartCall("my_cpu_function", cpu);
+ * my_cpu_function();
+ * prof.StopCall();
+ * prof.Stop();
+ * std::cout << prof.Report << std::endl; // print profiling report
+ * \endcode
+ */
+class Profiler {
+ public:
+  /*! Constructor.
+   *
+   * The profiler should be constructed before you do any warmup iterations.
+   *
+   * \note
+   * Calling this constructor will reset the TVM threadpool. It is necessary in
+   * order to install thread handlers required by certain collectors.
+   *
+   * \param devs The list of devices the profiler will be running on. Should
+   *             include all devices used by profiled operators.
+   * \param metric_collectors Additional `MetricCollector`s to use with this profiler.
+   * \param configuration Additional configuration data to add to the outputted profiling report.
+   */
+  explicit Profiler(std::vector<Device> devs, std::vector<MetricCollector> metric_collectors,
+                    std::unordered_map<String, ObjectRef> configuration = {});
+  /*! \brief Start the profiler.
+   *
+   * This function should only be called once per object.
+   */
+  void Start();
+  /*! \brief Stop the profiler.
+   *
+   * This function should only be called once per object after start has been called.
+   */
+  void Stop();
+  /*! \brief Start a function call.
+   * \param name The name of the function being called.
+   * \param dev The device on which the function is running.
+   * \param extra_metrics Optional additional profiling information to add to
+   * the frame (input sizes, allocations).
+   *
+   * `StartCall` may be nested, but each `StartCall` needs a matching
+   * `StopCall`. Function calls are stopped in LIFO order, so calls to
+   * `StartCall` and `StopCall` must be nested properly.
+   */
+  void StartCall(String name, Device dev,
+                 std::unordered_map<std::string, ObjectRef> extra_metrics = {});
+  /*! \brief Stop the last `StartCall`.
+   * \param extra_metrics Optional additional profiling information to add to
+   * the frame (input sizes, allocations).
+   */
+  void StopCall(std::unordered_map<std::string, ObjectRef> extra_metrics = {});
+  /*! \brief A report of total runtime between `Start` and `Stop` as
+   *        well as individual statistics for each `StartCall`-`StopCall` pair.
+   *  \returns A `Report` that can either be formatted as CSV (with `.AsCSV`)
+   *  or as a human readable table (with `.AsTable`).
+   */
+  profiling::Report Report();
+  /*! \brief Check if the profiler is currently running.
+   * \returns Whether or not the profiler is running.
+   */
+  bool IsRunning() const { return is_running_; }
+
+ private:
+  std::vector<Device> devs_;
+  bool is_running_{false};
+  std::vector<CallFrame> calls_;
+  std::stack<CallFrame> in_flight_;
+  std::vector<MetricCollector> collectors_;
+  std::unordered_map<String, ObjectRef> configuration_;
+};
+
+/* \brief A duration in time. */
+class DurationNode : public Object {
+ public:
+  /* The duration as a floating point number of microseconds. */
+  double microseconds;
+
+  /* \brief Construct a new duration.
+   * \param a The duration in microseconds.
+   */
+  explicit DurationNode(double a) : microseconds(a) {}
+
+  static constexpr const char* _type_key = "runtime.profiling.Duration";
+  TVM_DECLARE_FINAL_OBJECT_INFO(DurationNode, Object);
+};
+
+/* A percentage of something */
+class PercentNode : public Object {
+ public:
+  /* The percent as a floating point value out of 100%. i.e. if `percent` is 10 then we have 10%. */
+  double percent;
+
+  /* \brief Construct a new percentage.
+   * \param a The percentage out of 100.
+   */
+  explicit PercentNode(double a) : percent(a) {}
+
+  static constexpr const char* _type_key = "runtime.profiling.Percent";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PercentNode, Object);
+};
+
+/* A count of something */
+class CountNode : public Object {
+ public:
+  /* The actual count */
+  int64_t value;
+
+  /* \brief Construct a new count.
+   * \param a The count.
+   */
+  explicit CountNode(int64_t a) : value(a) {}
+
+  static constexpr const char* _type_key = "runtime.profiling.Count";
+  TVM_DECLARE_FINAL_OBJECT_INFO(CountNode, Object);
+};
+
+/* \brief A ratio of two things. */
+class RatioNode : public Object {
+ public:
+  /* The ratio as a double precision floating point number. */
+  double ratio;
+
+  /* \brief Construct a new ratio.
+   * \param a The ratio.
+   */
+  explicit RatioNode(double a) : ratio(a) {}
+
+  static constexpr const char* _type_key = "runtime.profiling.Ratio";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RatioNode, Object);
+};
+
+/*! \brief String representation of an array of NDArray shapes
+ *  \param shapes Array of NDArrays to get the shapes of.
+ *  \return A textual representation of the shapes. For example: `float32[2], int64[1, 2]`.
+ */
+String ShapeString(const std::vector<NDArray>& shapes);
+/*! \brief String representation of shape encoded as an NDArray
+ *  \param shape NDArray containing the shape.
+ *  \param dtype The dtype of the shape.
+ *  \return A textual representation of the shape. For example: `float32[2]`.
+ */
+String ShapeString(NDArray shape, DLDataType dtype);
+/*! \brief String representation of a shape encoded as a vector
+ *  \param shape Shape as a vector of integers.
+ *  \param dtype The dtype of the shape.
+ *  \return A textual representation of the shape. For example: `float32[2]`.
+ */
+String ShapeString(const std::vector<int64_t>& shape, DLDataType dtype);
+
+/*! \brief Collect performance information of a function execution. Usually
+ * used with a compiled PrimFunc (via tvm.build).
+ *
+ * This information can include performance counters like cache hits and FLOPs
+ * that are useful in debugging performance issues of individual PrimFuncs.
+ * Different metrics can be collected depending on which MetricCollector is
+ * used.
+ *
+ * Example usage:
+ * \code{.cpp}
+ * // Use PAPI to measure the number of floating point operations.
+ * PackedFunc profiler = ProfileModule(
+ *     mod, "main", kDLCPU, 0, {CreatePAPIMetricCollector({{kDLCPU, 0}, {"PAPI_FP_OPS"}})});
+ * Report r = profiler(arg1, arg2, arg);
+ * std::cout << r << std::endl;
+ * \endcode
+ *
+ * \param mod Module to profile. Usually a PrimFunc that has been compiled to machine code.
+ * \param func_name Name of function to run in the module.
+ * \param device_type Device type to run on. Profiling will include performance
+ *                    metrics specific to this device type.
+ * \param device_id Id of device to run on.
+ * \param warmup_iters Number of iterations of the function to run before collecting
+ *                     performance information. Recommend to set this larger
+ *                     than 0 so that cache effects are consistent.
+ * \param collectors List of different
+ *                   ways to collect metrics. See MetricCollector.
+ * \returns A PackedFunc which takes the same arguments as the `mod[func_name]`
+ *          and returns performance metrics as a `Map<String, ObjectRef>` where
+ *          values can be `CountNode`, `DurationNode`, `PercentNode`.
+ */
+PackedFunc ProfileFunction(Module mod, std::string func_name, int device_type, int device_id,
+                           int warmup_iters, Array<MetricCollector> collectors);
+
+/*!
+ * \brief Wrap a timer function to measure the time cost of a given packed function.
+ *
+ * Approximate implementation:
+ * \code{.py}
+ * f() // warmup
+ * for i in range(repeat)
+ *   f_preproc()
+ *   while True:
+ *     start = time()
+ *     for j in range(number):
+ *       f()
+ *     duration_ms = time() - start
+ *     if duration_ms >= min_repeat_ms:
+ *       break
+ *     else:
+ *        number = (min_repeat_ms / (duration_ms / number) + 1
+ *   if cooldown_interval_ms and i % repeats_to_cooldown == 0:
+ *     sleep(cooldown_interval_ms)
+ * \endcode
+ *
+ * \param f The function argument.
+ * \param dev The device.
+ * \param number The number of times to run this function for taking average.
+ *        We call these runs as one `repeat` of measurement.
+ * \param repeat The number of times to repeat the measurement.
+ *        In total, the function will be invoked (1 + number x repeat) times,
+ *        where the first one is warm up and will be discarded.
+ *        The returned result contains `repeat` costs,
+ *        each of which is an average of `number` costs.
+ * \param min_repeat_ms The minimum duration of one `repeat` in milliseconds.
+ *        By default, one `repeat` contains `number` runs. If this parameter is set,
+ *        the parameters `number` will be dynamically adjusted to meet the
+ *        minimum duration requirement of one `repeat`.
+ *        i.e., When the run time of one `repeat` falls below this time,
+ *        the `number` parameter will be automatically increased.
+ * \param limit_zero_time_iterations The maximum number of repeats when
+ *        measured time is equal to 0.  It helps to avoid hanging during measurements.
+ * \param cooldown_interval_ms The cooldown interval in milliseconds between the number of repeats
+ *        defined by `repeats_to_cooldown`.
+ * \param repeats_to_cooldown The number of repeats before the
+ *        cooldown is activated.
+ * \param f_preproc The function to be executed before we execute time
+ *        evaluator.
+ * \return f_timer A timer function.
+ */
+PackedFunc WrapTimeEvaluator(PackedFunc f, Device dev, int number, int repeat, int min_repeat_ms,
+                             int limit_zero_time_iterations, int cooldown_interval_ms,
+                             int repeats_to_cooldown, PackedFunc f_preproc = nullptr);
+
+}  // namespace profiling
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_PROFILING_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/registry.h b/darknet_drp_ros/include/tvm/runtime/registry.h
new file mode 100644
index 0000000..5a467c8
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/registry.h
@@ -0,0 +1,352 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/registry.h
+ * \brief This file defines the TVM global function registry.
+ *
+ *  The registered functions will be made available to front-end
+ *  as well as backend users.
+ *
+ *  The registry stores type-erased functions.
+ *  Each registered function is automatically exposed
+ *  to front-end language(e.g. python).
+ *
+ *  Front-end can also pass callbacks as PackedFunc, or register
+ *  then into the same global registry in C++.
+ *  The goal is to mix the front-end language and the TVM back-end.
+ *
+ * \code
+ *   // register the function as MyAPIFuncName
+ *   TVM_REGISTER_GLOBAL(MyAPIFuncName)
+ *   .set_body([](TVMArgs args, TVMRetValue* rv) {
+ *     // my code.
+ *   });
+ * \endcode
+ */
+#ifndef TVM_RUNTIME_REGISTRY_H_
+#define TVM_RUNTIME_REGISTRY_H_
+
+#include <tvm/runtime/packed_func.h>
+
+#include <string>
+#include <type_traits>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+namespace runtime {
+
+/*!
+ * \brief Check if signals have been sent to the process and if so
+ *  invoke the registered signal handler in the frontend environment.
+ *
+ *  When running TVM in another language (Python), the signal handler
+ *  may not be immediately executed, but instead the signal is marked
+ *  in the interpreter state (to ensure non-blocking of the signal handler).
+ *
+ *  This function can be explicitly invoked to check the cached signal
+ *  and run the related processing if a signal is marked.
+ *
+ *  On Linux, when siginterrupt() is set, invoke this function whenever a syscall returns EINTR.
+ *  When it is not set, invoke it between long-running syscalls when you will not immediately
+ *  return to the frontend. On Windows, the same rules apply, but due to differences in signal
+ *  processing, these are likely to only make a difference when used with Ctrl+C and socket calls.
+ *
+ *  Not inserting this function will not cause any correctness
+ *  issue, but will delay invoking the Python-side signal handler until the function returns to
+ *  the Python side. This means that the effect of e.g. pressing Ctrl+C or sending signals the
+ *  process will be delayed until function return. When a C function is blocked on a syscall
+ *  such as accept(), it needs to be called when EINTR is received.
+ *  So this function is not needed in most API functions, which can finish quickly in a
+ *  reasonable, deterministic amount of time.
+ *
+ * \code
+ *
+ * int check_signal_every_k_iter = 10;
+ *
+ * for (int iter = 0; iter < very_large_number; ++iter) {
+ *   if (iter % check_signal_every_k_iter == 0) {
+ *     tvm::runtime::EnvCheckSignals();
+ *   }
+ *   // do work here
+ * }
+ *
+ * \endcode
+ *
+ * \note This function is a nop when no PyErr_CheckSignals is registered.
+ *
+ * \throws This function throws an exception when the frontend signal handler
+ *         indicate an error happens, otherwise it returns normally.
+ */
+TVM_DLL void EnvCheckSignals();
+
+/*! \brief Registry for global function */
+class Registry {
+ public:
+  /*!
+   * \brief set the body of the function to be f
+   * \param f The body of the function.
+   */
+  TVM_DLL Registry& set_body(PackedFunc f);  // NOLINT(*)
+  /*!
+   * \brief set the body of the function to be f
+   * \param f The body of the function.
+   */
+  template <typename TCallable,
+            typename = typename std::enable_if_t<
+                std::is_convertible<TCallable, std::function<void(TVMArgs, TVMRetValue*)>>::value &&
+                !std::is_base_of<PackedFunc, TCallable>::value>>
+  Registry& set_body(TCallable f) {  // NOLINT(*)
+    return set_body(PackedFunc(f));
+  }
+  /*!
+   * \brief set the body of the function to the given function.
+   *        Note that this will ignore default arg values and always require all arguments to be
+   * provided.
+   *
+   * \code
+   *
+   * int multiply(int x, int y) {
+   *   return x * y;
+   * }
+   *
+   * TVM_REGISTER_GLOBAL("multiply")
+   * .set_body_typed(multiply); // will have type int(int, int)
+   *
+   * // will have type int(int, int)
+   * TVM_REGISTER_GLOBAL("sub")
+   * .set_body_typed([](int a, int b) -> int { return a - b; });
+   *
+   * \endcode
+   *
+   * \param f The function to forward to.
+   * \tparam FLambda The signature of the function.
+   */
+  template <typename FLambda>
+  Registry& set_body_typed(FLambda f) {
+    using FType = typename detail::function_signature<FLambda>::FType;
+    return set_body(TypedPackedFunc<FType>(std::move(f), name_).packed());
+  }
+  /*!
+   * \brief set the body of the function to be the passed method pointer.
+   *        Note that this will ignore default arg values and always require all arguments to be
+   * provided.
+   *
+   * \code
+   *
+   * // node subclass:
+   * struct Example {
+   *    int doThing(int x);
+   * }
+   * TVM_REGISTER_GLOBAL("Example_doThing")
+   * .set_body_method(&Example::doThing); // will have type int(Example, int)
+   *
+   * \endcode
+   *
+   * \param f the method pointer to forward to.
+   * \tparam T the type containing the method (inferred).
+   * \tparam R the return type of the function (inferred).
+   * \tparam Args the argument types of the function (inferred).
+   */
+  template <typename T, typename R, typename... Args>
+  Registry& set_body_method(R (T::*f)(Args...)) {
+    using R_ = typename std::remove_reference<R>::type;
+    auto fwrap = [f](T target, Args... params) -> R_ {
+      // call method pointer
+      return (target.*f)(params...);
+    };
+    return set_body(TypedPackedFunc<R_(T, Args...)>(fwrap, name_));
+  }
+
+  /*!
+   * \brief set the body of the function to be the passed method pointer.
+   *        Note that this will ignore default arg values and always require all arguments to be
+   * provided.
+   *
+   * \code
+   *
+   * // node subclass:
+   * struct Example {
+   *    int doThing(int x);
+   * }
+   * TVM_REGISTER_GLOBAL("Example_doThing")
+   * .set_body_method(&Example::doThing); // will have type int(Example, int)
+   *
+   * \endcode
+   *
+   * \param f the method pointer to forward to.
+   * \tparam T the type containing the method (inferred).
+   * \tparam R the return type of the function (inferred).
+   * \tparam Args the argument types of the function (inferred).
+   */
+  template <typename T, typename R, typename... Args>
+  Registry& set_body_method(R (T::*f)(Args...) const) {
+    auto fwrap = [f](const T target, Args... params) -> R {
+      // call method pointer
+      return (target.*f)(params...);
+    };
+    return set_body(TypedPackedFunc<R(const T, Args...)>(fwrap, name_));
+  }
+
+  /*!
+   * \brief set the body of the function to be the passed method pointer.
+   *        Used when calling a method on a Node subclass through a ObjectRef subclass.
+   *        Note that this will ignore default arg values and always require all arguments to be
+   * provided.
+   *
+   * \code
+   *
+   * // node subclass:
+   * struct ExampleNode: BaseNode {
+   *    int doThing(int x);
+   * }
+   *
+   * // noderef subclass
+   * struct Example;
+   *
+   * TVM_REGISTER_GLOBAL("Example_doThing")
+   * .set_body_method<Example>(&ExampleNode::doThing); // will have type int(Example, int)
+   *
+   * // note that just doing:
+   * // .set_body_method(&ExampleNode::doThing);
+   * // wouldn't work, because ExampleNode can't be taken from a TVMArgValue.
+   *
+   * \endcode
+   *
+   * \param f the method pointer to forward to.
+   * \tparam TObjectRef the node reference type to call the method on
+   * \tparam TNode the node type containing the method (inferred).
+   * \tparam R the return type of the function (inferred).
+   * \tparam Args the argument types of the function (inferred).
+   */
+  template <typename TObjectRef, typename TNode, typename R, typename... Args,
+            typename = typename std::enable_if<std::is_base_of<ObjectRef, TObjectRef>::value>::type>
+  Registry& set_body_method(R (TNode::*f)(Args...)) {
+    auto fwrap = [f](TObjectRef ref, Args... params) {
+      TNode* target = ref.operator->();
+      // call method pointer
+      return (target->*f)(params...);
+    };
+    return set_body(TypedPackedFunc<R(TObjectRef, Args...)>(fwrap, name_));
+  }
+
+  /*!
+   * \brief set the body of the function to be the passed method pointer.
+   *        Used when calling a method on a Node subclass through a ObjectRef subclass.
+   *        Note that this will ignore default arg values and always require all arguments to be
+   * provided.
+   *
+   * \code
+   *
+   * // node subclass:
+   * struct ExampleNode: BaseNode {
+   *    int doThing(int x);
+   * }
+   *
+   * // noderef subclass
+   * struct Example;
+   *
+   * TVM_REGISTER_GLOBAL("Example_doThing")
+   * .set_body_method<Example>(&ExampleNode::doThing); // will have type int(Example, int)
+   *
+   * // note that just doing:
+   * // .set_body_method(&ExampleNode::doThing);
+   * // wouldn't work, because ExampleNode can't be taken from a TVMArgValue.
+   *
+   * \endcode
+   *
+   * \param f the method pointer to forward to.
+   * \tparam TObjectRef the node reference type to call the method on
+   * \tparam TNode the node type containing the method (inferred).
+   * \tparam R the return type of the function (inferred).
+   * \tparam Args the argument types of the function (inferred).
+   */
+  template <typename TObjectRef, typename TNode, typename R, typename... Args,
+            typename = typename std::enable_if<std::is_base_of<ObjectRef, TObjectRef>::value>::type>
+  Registry& set_body_method(R (TNode::*f)(Args...) const) {
+    auto fwrap = [f](TObjectRef ref, Args... params) {
+      const TNode* target = ref.operator->();
+      // call method pointer
+      return (target->*f)(params...);
+    };
+    return set_body(TypedPackedFunc<R(TObjectRef, Args...)>(fwrap, name_));
+  }
+
+  /*!
+   * \brief Register a function with given name
+   * \param name The name of the function.
+   * \param override Whether allow override existing function.
+   * \return Reference to the registry.
+   */
+  TVM_DLL static Registry& Register(const std::string& name, bool override = false);  // NOLINT(*)
+  /*!
+   * \brief Erase global function from registry, if exist.
+   * \param name The name of the function.
+   * \return Whether function exist.
+   */
+  TVM_DLL static bool Remove(const std::string& name);
+  /*!
+   * \brief Get the global function by name.
+   * \param name The name of the function.
+   * \return pointer to the registered function,
+   *   nullptr if it does not exist.
+   */
+  TVM_DLL static const PackedFunc* Get(const std::string& name);  // NOLINT(*)
+  /*!
+   * \brief Get the names of currently registered global function.
+   * \return The names
+   */
+  TVM_DLL static std::vector<std::string> ListNames();
+
+  // Internal class.
+  struct Manager;
+
+ protected:
+  /*! \brief name of the function */
+  std::string name_;
+  /*! \brief internal packed function */
+  PackedFunc func_;
+  friend struct Manager;
+};
+
+#define TVM_FUNC_REG_VAR_DEF static TVM_ATTRIBUTE_UNUSED ::tvm::runtime::Registry& __mk_##TVM
+
+/*!
+ * \brief Register a function globally.
+ * \code
+ *   TVM_REGISTER_GLOBAL("MyPrint")
+ *   .set_body([](TVMArgs args, TVMRetValue* rv) {
+ *   });
+ * \endcode
+ */
+#define TVM_REGISTER_GLOBAL(OpName) \
+  TVM_STR_CONCAT(TVM_FUNC_REG_VAR_DEF, __COUNTER__) = ::tvm::runtime::Registry::Register(OpName)
+
+#define TVM_STRINGIZE_DETAIL(x) #x
+#define TVM_STRINGIZE(x) TVM_STRINGIZE_DETAIL(x)
+#define TVM_DESCRIBE(...) describe(__VA_ARGS__ "\n\nFrom:" __FILE__ ":" TVM_STRINGIZE(__LINE__))
+/*!
+ * \brief Macro to include current line as string
+ */
+#define TVM_ADD_FILELINE "\n\nDefined in " __FILE__ ":L" TVM_STRINGIZE(__LINE__)
+
+}  // namespace runtime
+}  // namespace tvm
+#endif  // TVM_RUNTIME_REGISTRY_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/serializer.h b/darknet_drp_ros/include/tvm/runtime/serializer.h
new file mode 100644
index 0000000..b35cad3
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/serializer.h
@@ -0,0 +1,69 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/serializer.h
+ * \brief Serializer extension to support TVM data types
+ *  Include this file to enable serialization of DLDataType, DLDevice
+ */
+#ifndef TVM_RUNTIME_SERIALIZER_H_
+#define TVM_RUNTIME_SERIALIZER_H_
+
+#include <dmlc/io.h>
+#include <dmlc/serializer.h>
+#include <tvm/runtime/c_runtime_api.h>
+#include <tvm/runtime/ndarray.h>
+
+namespace dmlc {
+namespace serializer {
+
+template <>
+struct Handler<DLDataType> {
+  inline static void Write(Stream* strm, const DLDataType& dtype) {
+    Handler<uint8_t>::Write(strm, dtype.code);
+    Handler<uint8_t>::Write(strm, dtype.bits);
+    Handler<uint16_t>::Write(strm, dtype.lanes);
+  }
+  inline static bool Read(Stream* strm, DLDataType* dtype) {
+    if (!Handler<uint8_t>::Read(strm, &(dtype->code))) return false;
+    if (!Handler<uint8_t>::Read(strm, &(dtype->bits))) return false;
+    if (!Handler<uint16_t>::Read(strm, &(dtype->lanes))) return false;
+    return true;
+  }
+};
+
+template <>
+struct Handler<DLDevice> {
+  inline static void Write(Stream* strm, const DLDevice& dev) {
+    int32_t device_type = static_cast<int32_t>(dev.device_type);
+    Handler<int32_t>::Write(strm, device_type);
+    Handler<int32_t>::Write(strm, dev.device_id);
+  }
+  inline static bool Read(Stream* strm, DLDevice* dev) {
+    int32_t device_type = 0;
+    if (!Handler<int32_t>::Read(strm, &(device_type))) return false;
+    dev->device_type = static_cast<DLDeviceType>(device_type);
+    if (!Handler<int32_t>::Read(strm, &(dev->device_id))) return false;
+    return true;
+  }
+};
+
+}  // namespace serializer
+}  // namespace dmlc
+#endif  // TVM_RUNTIME_SERIALIZER_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/threading_backend.h b/darknet_drp_ros/include/tvm/runtime/threading_backend.h
new file mode 100644
index 0000000..77d6730
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/threading_backend.h
@@ -0,0 +1,153 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/threading_backend.h
+ * \brief Utilities for manipulating thread pool threads.
+ */
+#ifndef TVM_RUNTIME_THREADING_BACKEND_H_
+#define TVM_RUNTIME_THREADING_BACKEND_H_
+
+#include <functional>
+#include <memory>
+#include <vector>
+
+#if defined(__linux__) || defined(__ANDROID__)
+#if defined(__ANDROID__)
+#ifndef CPU_SET
+#define CPU_SETSIZE 1024
+#define __NCPUBITS (8 * sizeof(uint64_t))
+typedef struct {
+  uint64_t __bits[CPU_SETSIZE / __NCPUBITS];
+} cpu_set_t;
+
+#define CPU_SET(cpu, cpusetp) \
+  ((cpusetp)->__bits[(cpu) / __NCPUBITS] |= (1UL << ((cpu) % __NCPUBITS)))
+#define CPU_ZERO(cpusetp) memset((cpusetp), 0, sizeof(cpu_set_t))
+#define CPU_ISSET(cpu, cpusetp)    \
+  (1UL << ((cpu) % __NCPUBITS)) == \
+      ((cpusetp)->__bits[(cpu) / __NCPUBITS] & (1UL << ((cpu) % __NCPUBITS)))
+#define CPU_EQUAL(left, right) (memcmp(&left, &right, sizeof(cpu_set_t)) == 0)
+
+#endif
+#endif
+#endif
+
+namespace tvm {
+namespace runtime {
+namespace threading {
+
+/*!
+ * \brief A platform-agnostic abstraction for managing a collection of
+ *        thread pool threads.
+ */
+class ThreadGroup {
+ public:
+  class Impl;
+
+  /*!
+   * \brief Creates a collection of threads which run a provided function.
+   *
+   * \param num_workers The total number of worker threads in this group.
+            Includes main thread if `exclude_worker0 = true`
+   * \param worker_callback A callback which is run in its own thread.
+            Receives the worker_id as an argument.
+   * \param exclude_worker0 Whether to use the main thread as a worker.
+   *        If  `true`, worker0 will not be launched in a new thread and
+   *        `worker_callback` will only be called for values >= 1. This
+   *        allows use of the main thread as a worker.
+   */
+  ThreadGroup(int num_workers, std::function<void(int)> worker_callback,
+              bool exclude_worker0 = false);
+  ~ThreadGroup();
+
+  /*!
+   * \brief Blocks until all non-main threads in the pool finish.
+   */
+  void Join();
+
+  enum AffinityMode : int {
+    kBig = 1,
+    kLittle = -1,
+    /*Different threads will get different affinities.*/
+    kSpecifyOneCorePerThread = -2,
+    /*All threads will get the same core group affinity.*/
+    kSpecifyThreadShareAllCore = -3,
+  };
+  /*!
+   * \brief configure the CPU id affinity
+   *
+   * \param mode The preferred CPU type (1 = big, -1 = little ...).
+   * \param nthreads The number of threads to use (0 = use all).
+   * \param exclude_worker0 Whether to use the main thread as a worker.
+   *        If  `true`, worker0 will not be launched in a new thread and
+   *        `worker_callback` will only be called for values >= 1. This
+   *        allows use of the main thread as a worker.
+   * \param cpus A list of CPU used to set 'cpu affinity'.
+   *
+   * \return The number of workers to use.
+   */
+  int Configure(AffinityMode mode, int nthreads, bool exclude_worker0,
+                std::vector<unsigned int> cpus = {});
+
+ private:
+  Impl* impl_;
+};
+
+/*!
+ * \brief Platform-agnostic no-op.
+ */
+void Yield();
+/*!
+ * \return the maximum number of effective workers for this system.
+ */
+int MaxConcurrency();
+/*!
+ * \brief Setting the maximum number of available cores.
+ */
+void SetMaxConcurrency(int value);
+/*!
+ * \brief Reset the threads in the pool. All current threads are destroyed and
+ * new ones are created.
+ *
+ * Note that this does nothing when openmp is used.
+ */
+void ResetThreadPool();
+
+/*!
+ * \brief Configuring the CPU affinity mode for the working threads.
+ * \param mode The preferred CPU type (1 = big, -1 = little, -2 = kSpecifyOneCorePerThread,
+ *  -3 = kSpecifyThreadShareAllCore).
+ * \param nthreads The number of threads to use (0 = use all).
+ * \param cpus A list of CPUs is used to set the 'cpu affinity' for the worker threads.
+ */
+TVM_DLL void Configure(tvm::runtime::threading::ThreadGroup::AffinityMode mode, int nthreads,
+                       std::vector<unsigned int> cpus);
+
+/*!
+ * \brief Get the number of threads being used by the TVM runtime
+ * \returns The number of threads used.
+ */
+int32_t NumThreads();
+
+}  // namespace threading
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_THREADING_BACKEND_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/vm/bytecode.h b/darknet_drp_ros/include/tvm/runtime/vm/bytecode.h
new file mode 100644
index 0000000..2fe855f
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/vm/bytecode.h
@@ -0,0 +1,404 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/vm/bytecode.h
+ * \brief The bytecode for Relay virtual machine.
+ */
+#ifndef TVM_RUNTIME_VM_BYTECODE_H_
+#define TVM_RUNTIME_VM_BYTECODE_H_
+
+#include <tvm/runtime/data_type.h>
+#include <tvm/runtime/logging.h>
+
+#include <iostream>
+#include <vector>
+
+namespace tvm {
+namespace runtime {
+namespace vm {
+
+/*! \brief A register name. */
+using RegName = int64_t;
+
+/*! \brief An alias for the integer type used ubiquitously
+ * in the VM.
+ */
+using Index = int64_t;
+
+/*! \brief An enumeration of Relay's opcodes.
+ *
+ * The opcode is used to implement instruction
+ * as a tagged union.
+ */
+enum class Opcode {
+  Move = 0U,
+  Ret = 1U,
+  Invoke = 2U,
+  InvokeClosure = 3U,
+  InvokePacked = 4U,
+  AllocTensor = 5U,
+  AllocTensorReg = 6U,
+  AllocADT = 7U,
+  AllocClosure = 8U,
+  GetField = 9U,
+  If = 10U,
+  LoadConst = 11U,
+  Goto = 12U,
+  GetTag = 13U,
+  LoadConsti = 14U,
+  Fatal = 15U,
+  AllocStorage = 16U,
+  ShapeOf = 17U,
+  ReshapeTensor = 18U,
+  DeviceCopy = 19U,
+  KillRegister = 20U,
+};
+
+/*! \brief A single virtual machine instruction.
+ *
+ * The representation of the instruction is as
+ * a tagged union.
+ *
+ * The first field represents which instruction,
+ * and by extension which field of the union
+ * is active.
+ */
+struct Instruction {
+  /*! \brief The instruction opcode. */
+  Opcode op;
+
+  /*! \brief The destination register. */
+  RegName dst;
+
+  union {
+    struct /* AllocTensor Operands */ {
+      /*! \brief The storage to allocate from. */
+      RegName storage;
+      /*! \brief The offset into the storage to allocate from. */
+      Index offset;
+      /*! \brief The number of dimensions. */
+      uint32_t ndim;
+      /*! \brief The shape of tensor. */
+      int64_t* shape;
+      /*! \brief The datatype of tensor to be allocated. */
+      DLDataType dtype;
+    } alloc_tensor;
+    struct /* AllocTensorReg Operands */ {
+      /*! \brief The storage to allocate from. */
+      RegName storage;
+      /*! \brief The offset into the storage to allocate from. */
+      Index offset;
+      /*! \brief The register to read the shape out of. */
+      RegName shape_register;
+      /*! \brief The datatype of tensor to be allocated. */
+      DLDataType dtype;
+    } alloc_tensor_reg;
+    struct /* InvokeClosure Operands */ {
+      /*! \brief The register containing the closure. */
+      RegName closure;
+      /*! \brief The number of arguments to the closure. */
+      Index num_closure_args;
+      /*! \brief The closure arguments as an array. */
+      RegName* closure_args;
+    };
+    struct /* Return Operands */ {
+      /*! \brief The register to return. */
+      RegName result;
+    };
+    struct /* Move Operands */ {
+      /*! \brief The source register for a move operation. */
+      RegName from;
+    };
+    struct /* InvokePacked Operands */ {
+      /*! \brief The index into the packed function table. */
+      Index packed_index;
+      /*! \brief The arity of the packed function. */
+      Index arity;
+      /*! \brief The number of outputs produced by the packed function. */
+      Index output_size;
+      /*! \brief The arguments to pass to the packed function. */
+      RegName* packed_args;
+    };
+    struct /* If Operands */ {
+      /*! \brief The register containing the test value. */
+      RegName test;
+      /*! \brief The register containing the target value. */
+      RegName target;
+      /*! \brief The program counter offset for the true branch. */
+      Index true_offset;
+      /*! \brief The program counter offset for the false branch. */
+      Index false_offset;
+    } if_op;
+    struct /* Invoke Operands */ {
+      /*! \brief The function to call. */
+      Index func_index;
+      /*! \brief The number of arguments to the function. */
+      Index num_args;
+      /*! \brief The registers containing the arguments. */
+      RegName* invoke_args_registers;
+    };
+    struct /* LoadConst Operands */ {
+      /* \brief The index into the constant pool. */
+      Index const_index;
+    };
+    struct /* LoadConsti Operands */ {
+      /* \brief The index into the constant pool. */
+      Index val;
+    } load_consti;
+    struct /* Jump Operands */ {
+      /*! \brief The jump offset. */
+      Index pc_offset;
+    };
+    struct /* Proj Operands */ {
+      /*! \brief The register to project from. */
+      RegName object;
+      /*! \brief The field to read out. */
+      Index field_index;
+    };
+    struct /* GetTag Operands */ {
+      /*! \brief The register to project from. */
+      RegName object;
+    } get_tag;
+    struct /* AllocADT Operands */ {
+      // TODO(mbs): Needs a DeviceAndScope.
+      /*! \brief The datatype's constructor tag. */
+      Index constructor_tag;
+      /*! \brief The number of fields to store in the datatype. */
+      Index num_fields;
+      /*! \brief The fields as an array. */
+      RegName* datatype_fields;
+    };
+    struct /* AllocClosure Operands */ {
+      // TODO(mbs): Needs a DeviceAndScope.
+      /*! \brief The index into the function table. */
+      Index clo_index;
+      /*! \brief The number of free variables to capture. */
+      Index num_freevar;
+      /*! \brief The free variables as an array. */
+      RegName* free_vars;
+    };
+    struct /* AllocStorage Operands */ {
+      /*! \brief The size of the allocation. */
+      RegName allocation_size;
+      /*! \brief The alignment of the allocation. */
+      Index alignment;
+      /*! \brief The hint of the dtype. */
+      DLDataType dtype_hint;
+      /*! \brief The index of the device on which the allocation will be made. */
+      Index device_index;
+    } alloc_storage;
+    struct /* ShapeOf Operands */ {
+      RegName tensor;
+    } shape_of;
+    struct /* ReshapeTensor Operands */ {
+      RegName tensor;
+      RegName newshape;
+    } reshape_tensor;
+    struct /* DeviceCopy Operands */ {
+      RegName src;
+      /*! \brief The index of the source device to copy from. */
+      Index src_device_index;
+      /*! \brief The index of the destination deviceto copy to. */
+      Index dst_device_index;
+    } device_copy;
+  };
+
+  /*!
+   * \brief Construct a return instruction.
+   * \param return_reg The register containing the return value.
+   * \return The return instruction.
+   */
+  static Instruction Ret(RegName return_reg);
+  /*!
+   * \brief Construct a fatal instruction.
+   * \return The fatal instruction.
+   */
+  static Instruction Fatal();
+  /*!
+   * \brief Construct a invoke packed instruction.
+   * \param packed_index The index of the packed function.
+   * \param arity The arity of the function.
+   * \param output_size The number of outputs of the packed function.
+   * \param args The argument registers.
+   * \return The invoke packed instruction.
+   */
+  static Instruction InvokePacked(Index packed_index, Index arity, Index output_size,
+                                  const std::vector<RegName>& args);
+  /*!
+   * \brief Construct an allocate tensor instruction with constant shape.
+   * \param storage The storage to allocate out of.
+   * \param offset The offset to allocate at.
+   * \param shape The shape of the tensor.
+   * \param dtype The dtype of the tensor.
+   * \param dst The destination register.
+   * \return The allocate tensor instruction.
+   */
+  static Instruction AllocTensor(RegName storage, Index offset, const std::vector<int64_t>& shape,
+                                 DLDataType dtype, RegName dst);
+  /*!
+   * \brief Construct an allocate tensor instruction with register.
+   * \param storage The storage to allocate out of.
+   * \param offset The offset into the storage to allocate from.
+   * \param shape_register The register containing the shape.
+   * \param dtype The dtype of the tensor.
+   * \param dst The destination register.
+   * \return The allocate tensor instruction.
+   */
+  static Instruction AllocTensorReg(RegName storage, Index offset, RegName shape_register,
+                                    DLDataType dtype, RegName dst);
+  /*!
+   * \brief Construct an allocate datatype instruction.
+   * \param tag The datatype tag.
+   * \param num_fields The number of fields for the datatype.
+   * \param fields The registers containing the fields.
+   * \param dst The register name of the destination.
+   * \return The allocate instruction tensor.
+   */
+  static Instruction AllocADT(Index tag, Index num_fields, const std::vector<RegName>& fields,
+                              RegName dst);
+  /*!
+   * \brief Construct an allocate closure instruction.
+   * \param func_index The index of the function table.
+   * \param num_freevar The number of free variables.
+   * \param free_vars The registers of the free variables.
+   * \param dst The destination register.
+   * \return The allocate closure instruction.
+   */
+  static Instruction AllocClosure(Index func_index, Index num_freevar,
+                                  const std::vector<RegName>& free_vars, RegName dst);
+  /*!
+   * \brief Construct a get field instruction.
+   * \param object_reg The register containing the object to project from.
+   * \param field_index The field to read out of the object.
+   * \param dst The destination register.
+   * \return The get field instruction.
+   */
+  static Instruction GetField(RegName object_reg, Index field_index, RegName dst);
+  /*!
+   * \brief Construct a get_tag instruction.
+   * \param object_reg The register containing the object to project from.
+   * \param dst The destination register.
+   * \return The get_tag instruction.
+   */
+  static Instruction GetTag(RegName object_reg, RegName dst);
+  /*!
+   * \brief Construct an if instruction.
+   * \param test The register containing the test value.
+   * \param target The register containing the target value.
+   * \param true_branch The offset to the true branch.
+   * \param false_branch The offset to the false branch.
+   * \return The if instruction.
+   */
+  static Instruction If(RegName test, RegName target, Index true_branch, Index false_branch);
+  /*!
+   * \brief Construct a goto instruction.
+   * \param pc_offset The offset from the current pc.
+   * \return The goto instruction.
+   */
+  static Instruction Goto(Index pc_offset);
+  /*!
+   * \brief Construct an invoke instruction.
+   * \param func_index The index of the function to invoke.
+   * \param args The registers containing the arguments.
+   * \param dst The destination register.
+   * \return The invoke instruction.
+   */
+  static Instruction Invoke(Index func_index, const std::vector<RegName>& args, RegName dst);
+  /*!
+   * \brief Construct an invoke closure instruction.
+   * \param closure The register of the closure to invoke.
+   * \param args The registers containing the arguments.
+   * \param dst The destination register.
+   * \return The invoke closure instruction.
+   */
+  static Instruction InvokeClosure(RegName closure, const std::vector<RegName>& args, RegName dst);
+  /*!
+   * \brief Construct a load constant instruction.
+   * \param const_index The index of the constant.
+   * \param dst The destination register.
+   * \return The load constant instruction.
+   */
+  static Instruction LoadConst(Index const_index, RegName dst);
+  /*!
+   * \brief Construct a load_constanti instruction.
+   * \param val The interger constant value.
+   * \param dst The destination register.
+   * \return The load_constanti instruction.
+   */
+  static Instruction LoadConsti(Index val, RegName dst);
+  /*!
+   * \brief Construct a move instruction.
+   * \param src The source register.
+   * \param dst The destination register.
+   * \return The move instruction.
+   */
+  static Instruction Move(RegName src, RegName dst);
+  /*!
+   * \brief Allocate a storage block.
+   * \param size The size of the allocation.
+   * \param alignment The allocation's alignment.
+   * \param dtype_hint The data type hint for the allocator.
+   * \param device_index The index of the device to allocate on.
+   * \param dst The destination to place the storage.
+   * \return The alloc storage instruction.
+   */
+  static Instruction AllocStorage(RegName size, Index alignment, DLDataType dtype_hint,
+                                  Index device_index, RegName dst);
+  /*!
+   * \brief Get the shape of an input tensor.
+   * \param tensor The input tensor.
+   * \param dst The destination to store the shape of the given tensor.
+   * \return The shape of instruction.
+   */
+  static Instruction ShapeOf(RegName tensor, RegName dst);
+  /*!
+   * \brief Reshape the tensor given the new shape.
+   * \param tensor The input tensor.
+   * \param newshape The shape tensor.
+   * \param dst The destination to store the output tensor with new shape.
+   * \return The reshape tensor instruction.
+   */
+  static Instruction ReshapeTensor(RegName tensor, RegName newshape, RegName dst);
+  /*!
+   * \brief Copy tensor cross different devices.
+   * \param src The source register.
+   * \param src_device_index The index of the device holding the tensor in the source register.
+   * \param dst_device_index The index of the device to hold the tensor in the destination register.
+   * \param dst The destination register to store the copied tensor.
+   * \return The device copy instruction.
+   */
+  static Instruction DeviceCopy(RegName src, Index src_device_index, Index dst_device_index,
+                                RegName dst);
+
+  static Instruction KillRegister(RegName dst);
+
+  Instruction();
+  Instruction(const Instruction& instr);
+  Instruction& operator=(const Instruction& instr);
+  ~Instruction();
+
+  friend std::ostream& operator<<(std::ostream& os, const Instruction&);
+};
+
+}  // namespace vm
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_VM_BYTECODE_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/vm/executable.h b/darknet_drp_ros/include/tvm/runtime/vm/executable.h
new file mode 100644
index 0000000..fdbc176
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/vm/executable.h
@@ -0,0 +1,375 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/vm/executable.h
+ * \brief The Relay virtual machine executable.
+ */
+#ifndef TVM_RUNTIME_VM_EXECUTABLE_H_
+#define TVM_RUNTIME_VM_EXECUTABLE_H_
+
+#include <tvm/runtime/container/map.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/runtime/module.h>
+#include <tvm/runtime/object.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/runtime/vm/bytecode.h>
+
+#include <map>
+#include <string>
+#include <unordered_map>
+#include <vector>
+
+namespace tvm {
+namespace runtime {
+namespace vm {
+
+struct VMFunction;
+
+/*!
+ * \brief The executable emitted by the VM compiler.
+ *
+ * The executable contains information (e.g. data in different memory regions)
+ * to run in a virtual machine.
+ *
+ *  - Global section, containing all globals.
+ *  - Constant section, storing the constant pool.
+ *  - Primitive name section, containing the function name of the primitive ops
+ *  used by the virtual machine.
+ *  - Code section, handling the VM functions and bytecode.
+ */
+class TVM_DLL Executable : public ModuleNode {
+ public:
+  /*!
+   * \brief Get a PackedFunc from an executable module.
+   *
+   * \param name the name of the function.
+   * \param sptr_to_self The shared_ptr that points to this module node.
+   *
+   * \return PackedFunc or nullptr when it is not available.
+   */
+  PackedFunc GetFunction(const std::string& name, const ObjectPtr<Object>& sptr_to_self) final;
+
+  /*!
+   * \brief Write the Executable to the binary stream in serialized form.
+   *
+   * Late-bound constants (if any) must have already been saved by \p
+   * MoveLateBoundConstantsToBinary.
+   *
+   * \param stream The binary stream to save the executable to.
+   */
+  void SaveToBinary(dmlc::Stream* stream) final;
+
+  /*!
+   * \brief Write the Executable to the provided path as a file containing its serialized content.
+   *
+   * Late-bound constants (if any) must have already been saved by \p
+   * MoveLateBoundConstantsToBinary.
+   *
+   * \param path The path to write the serialized data to.
+   * \param format The format of the serialized blob.
+   */
+  void SaveToFile(const std::string& path, const std::string& format) final;
+
+  /*!
+   * \brief Serialize the executable into global section, constant section, and
+   * code section. This object must outlive the returned byte array.
+   *
+   * Late-bound constants (if any) must have already been saved by \p
+   * MoveLateBoundConstantsToBinary.
+   *
+   * \return The binary representation of the VM.
+   */
+  TVMByteArray Save();
+
+  /*!
+   * \brief Load the saved VM executable.
+   *
+   * Late-bound constants (if any) must then be loaded by \p LoadLateBoundConstantsFromBinary.
+   *
+   * \param code The bytecode in string.
+   * \param lib The compiled runtime library.
+   *
+   * \return exe The constructed executable.
+   */
+  static runtime::Module Load(const std::string& code, const runtime::Module lib);
+
+  /*!
+   * \brief Returns the late-bound constants for the executable (if any) as a byte-stream.
+   * Leaves the executable's late-bound constants map empty. Only constants who's byte
+   * tensor size is greater than or equal to \p byte_limit are marked as late-bound. \p byte_limit
+   * may be zero.
+   *
+   * Must be called before \p SaveToBinary and friends if late-bound constants are
+   * desired. Otherwise can be ignore.
+   */
+  void MoveLateBoundConstantsToStream(dmlc::Stream* stream, size_t byte_limit);
+
+  /*!
+   * \brief As for \p MoveLateBoundConstantsToStream, but save to file at \p path.
+   */
+  void MoveLateBoundConstantsToFile(const std::string& path, size_t byte_limit);
+
+  /*!
+   * \brief Get a map of all constants with larger that byte_limit in size.
+   */
+  Map<String, NDArray> GetLateBoundConstants(size_t byte_limit);
+
+  /*!
+   * \brief Restores the late-bound constants for the executable (if any) from given byte-stream.
+   *
+   * Must be called after \p Load but before any other methods if \p MoveLateBoundConstantsToBinary
+   * was used when saving. Otherwise can be ignored.
+   */
+  void LoadLateBoundConstantsFromStream(dmlc::Stream* stream);
+
+  /*!
+   * \brief Restores the late-bound constants for the executable (if any) from given map.
+   *
+   * Must be called after \p Load but before any other methods if \p MoveLateBoundConstantsToBinary
+   * was used when saving. Otherwise can be ignored.
+   */
+  void LoadLateBoundConstantsFromMap(Map<String, NDArray> map);
+
+  /*!
+   * \brief As for \p LoadLateBoundConstantsFromStream, but load from file at \p path.
+   */
+  void LoadLateBoundConstantsFromFile(const std::string& path);
+
+  /*!
+   * \brief Get the serialized form of the `functions`. This is
+   * essentially bytecode serialization.
+   *
+   * \return The serialized vm bytecode.
+   *
+   * \note The bytecode is in the following format:
+   *   func_name reg_file_size num_instructions
+   *   param1 param2 ... paramM
+   *   instruction1
+   *   instruction2
+   *   ...
+   *   instructionN
+   *
+   * Each instruction is printed in the following format:
+   *   opcode num_fields field1 ... fieldX # The text format.
+   *
+   * Serializing an `Instruction` requires us to deal with the bytecode. Each line
+   * of the instructions could be serialized as the following format:
+   *   hash, opcode, f1, f2, ..., fX, field with variable length
+   *   1. hash: the hash of the instruction. This number will be used to help us
+   * validate if an instruction is well-formed during deserialization.
+   *   2. opcode: the opcode code of the instruction.
+   *   3. f1, f2, ..., fX. These fields together represent the fixed fields in
+   * an instruction, e.g., `from` and `dst` fields of a `Move` instruction. For
+   * example, `DLDataType` will be unpacked into three fields (code, bits, lanes).
+   *   4. The rest of the line indicates the field with variable length, e.g.,
+   * the shape of a tensor, the args used by an `InvokPacked` instruction, etc.
+   *
+   * The field starting from # is only used for debugging. The serialized code
+   * doesn't contain it, therefore the deserializer doens't need to handle it.
+   */
+  std::string GetBytecode() const;
+
+  /*!
+   * \brief Returns a description of all the constants in the executable in human-readable
+   * format. Intended for debugging and diff-testing.
+   */
+  std::string GetConstants() const;
+
+  /*!
+   * \brief Returns a description of all the (virtual) devices in the executable in human-readable
+   * format. Intended for debugging and diff-testing.
+   */
+  std::string GetVirtualDevices() const;
+
+  /*!
+   * \brief Returns a description of all the 'primitive' (ie PackedFuncs) in the executable in
+   * human-readable format. These correspond either to PrimFuncs we've compiled locally, or
+   * functions compiled by a BYOC external codegen. Intended for debugging and diff-testing.
+   */
+  std::string GetPrimitives() const;
+
+  /*!
+   * \brief Print the detailed statistics of the given code, i.e. number of
+   * globls and constants, etc.
+   */
+  std::string Stats() const;
+
+  /*!
+   * \brief Get the `lib` module in an executable. Users have the flexibility to call
+   * `export_library` from the frontend to save the library to disk.
+   *
+   * \return The runtime module that contains the hardware dependent code.
+   */
+  runtime::Module GetLib() const;
+
+  /*!
+   * \brief Set the `lib` module in an executable.
+   *
+   * This allows us to do partial initialization in the case of (de|ser)ialization cases.
+   * This method also ensures correct initialization of library ensuring we only Import a
+   * single library.
+   *
+   * NB: This also provides some abstraction over how libraries are stored as there are plans
+   * to iterate on the way runtime::Module works in the backend of the compiler.
+   */
+  void SetLib(const runtime::Module& lib);
+
+  /*!
+   * \brief Get VMFunction.
+   * \param func_name The function's name.
+   * \return VMFunction.
+   */
+  const VMFunction& GetVMFunctionWithName(const std::string& func_name) const;
+
+  /*!
+   * \brief Get the arity of the VMFunction.
+   * \param func Function name.
+   * \return The number of parameters.
+   */
+  int GetFunctionArity(std::string func) const;
+
+  /*!
+   * \brief Get the parameter name given the function name and parameter index.
+   * \param func Function name.
+   * \param index Parameter index.
+   * \return The parameter name.
+   */
+  std::string GetFunctionParameterName(std::string func, uint32_t index) const;
+
+  virtual ~Executable() {}
+
+  const char* type_key() const final { return "VMExecutable"; }
+
+  /*!
+   * \brief The (compile-time, virtual) devices corresponding to each device index.
+   * Currently we only support at most one device per device type.
+   */
+  std::vector<Device> virtual_devices;
+  /*!
+   * \brief The device index corresponding to the 'host' device. That will hold and evaluate
+   * shape-related data and code.
+   */
+  int host_device_index = -1;
+  /*!
+   * \brief The global constant array.
+   *
+   * LoadConst instructions indexes are w.r.t. this vector. Late-bound constants are removed
+   * from this table after saving late-bound constants.
+   */
+  std::vector<ObjectRef> constants;
+  /*!
+   * \brief For each constant index the name of the late-bound constant, or null if constant is
+   * immediate. Only populated after loading executable but before loading late-bound constants.
+   */
+  std::vector<String> late_bound_constant_names;
+
+  /*! \brief A map from globals (as strings) to their index in the Relay function map. */
+  std::unordered_map<std::string, Index> global_map;
+  /*! \brief A mapping from the packed function's global name (as string) to the index that
+   * corresponds to the position of the `packed_funcs` list in a `VirtualMachine` object.
+   */
+  std::unordered_map<std::string, Index> primitive_map;
+  /*! \brief The structural hashes of the operators in this function. */
+  std::map<Index, Map<String, ObjectRef>> op_attrs;
+  /*! \brief The virtual machine's function table. */
+  std::vector<VMFunction> functions;
+  /*! \brief The index of the device holding each constant. */
+  std::vector<Index> const_device_indexes;
+
+ private:
+  /*!
+   * \brief Save the virtual devices
+   *
+   * /param strm The output stream.
+   */
+  void SaveVirtualDevicesSection(dmlc::Stream* strm);
+
+  /*!
+   * \brief Save the globals.
+   *
+   * \param strm The output stream.
+   */
+  void SaveGlobalSection(dmlc::Stream* strm);
+
+  /*!
+   * \brief Save the constant pool.
+   *
+   * \param stream The output stream.
+   */
+  void SaveConstantSection(dmlc::Stream* stream);
+
+  /*!
+   * \brief Load the constant pool.
+   *
+   * \param stream The input stream.
+   */
+  void LoadConstantSection(dmlc::Stream* stream);
+
+  /*!
+   * \brief Save primitive op names.
+   *
+   *  \param strm The output stream.
+   */
+  void SavePrimitiveOpNames(dmlc::Stream* strm);
+
+  /*!
+   * \brief Save the vm functions.
+   *
+   * \param strm The output stream.
+   */
+  void SaveCodeSection(dmlc::Stream* strm);
+
+  /*!
+   * \brief Load the virtual devices
+   *
+   * /param strm The input stream.
+   */
+  void LoadVirtualDevicesSection(dmlc::Stream* strm);
+
+  /*!
+   * \brief Load the globals.
+   *
+   * \param strm The input stream.
+   */
+  void LoadGlobalSection(dmlc::Stream* strm);
+
+  /*!
+   * \brief Load primitive op names.
+   *
+   * \param strm The input stream.
+   */
+  void LoadPrimitiveOpNames(dmlc::Stream* strm);
+
+  /*!
+   * \brief Load the vm functions.
+   *
+   * \param strm The input stream.
+   */
+  void LoadCodeSection(dmlc::Stream* strm);
+
+  /*! \brief The serialized bytecode. */
+  std::string code_;
+};
+
+}  // namespace vm
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_VM_EXECUTABLE_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/vm/memory_manager.h b/darknet_drp_ros/include/tvm/runtime/vm/memory_manager.h
new file mode 100644
index 0000000..fb2354b
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/vm/memory_manager.h
@@ -0,0 +1,147 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/vm/memory_manager.h
+ * \brief Abstract device memory management API
+ */
+#ifndef TVM_RUNTIME_VM_MEMORY_MANAGER_H_
+#define TVM_RUNTIME_VM_MEMORY_MANAGER_H_
+
+#include <tvm/runtime/c_runtime_api.h>
+#include <tvm/runtime/ndarray.h>
+#include <tvm/runtime/object.h>
+
+#include <functional>
+#include <memory>
+#include <mutex>
+#include <unordered_map>
+#include <vector>
+
+namespace tvm {
+namespace runtime {
+namespace vm {
+
+struct Buffer {
+  /*! \brief The pointer to the allocated block of memory. */
+  void* data{nullptr};
+  /*! \brief The size of the block. */
+  size_t size{0};
+  /*! \brief The context of the allocated buffers. */
+  Device device;
+};
+
+enum AllocatorType {
+  kNaive = 1,
+  kPooled,
+};
+
+class Allocator {
+ public:
+  explicit Allocator(AllocatorType type) : type_(type) {}
+  virtual ~Allocator() = default;
+  /*! \brief Allocate an empty NDArray using from the allocator.
+   *  \param shape The shape of the NDArray.
+   *  \param dtype The datatype of the NDArray.
+   *  \param dev The device where the array is allocated.
+   *  \return The empty NDArray.
+   */
+  NDArray Empty(std::vector<int64_t> shape, DLDataType dtype, Device dev);
+  /*! \brief Return the allocator type. */
+  inline AllocatorType type() const { return type_; }
+  /*! \brief Allocate a buffer given a size, alignment and type.
+   *  \param nbytes The size of the buffer.
+   *  \param alignment The alignment of the buffer.
+   *  \param type_hint A type hint to the allocator.
+   *  \return A sized allocation in the form of a buffer.
+   */
+  virtual Buffer Alloc(size_t nbytes, size_t alignment, DLDataType type_hint) = 0;
+  /*! \brief Free a buffer allocated by the allocator.
+   *  \param buffer The buffer to free.
+   */
+  virtual void Free(const Buffer& buffer) = 0;
+  /*! \brief The amount of memory currently allocated.
+   *  \return The amount of memory currently allocated.
+   */
+  virtual size_t UsedMemory() const = 0;
+
+ private:
+  AllocatorType type_;
+};
+
+class MemoryManager {
+ public:
+  static MemoryManager* Global();
+  /*!
+   * \brief Get or create an allocator given the context and allocator type.
+   * \param dev The TVM device
+   * \param type The allocator type
+   * \return The memory allocator.
+   */
+  static Allocator* GetOrCreateAllocator(Device dev, AllocatorType type);
+  /*!
+   * \brief Get an allocator given the context.
+   * \param dev The TVM device
+   * \return The memory allocator.
+   */
+  static Allocator* GetAllocator(Device dev);
+
+ private:
+  MemoryManager() {}
+
+ private:
+  std::mutex mu_;
+  std::unordered_map<Device, std::unique_ptr<Allocator>> allocators_;
+};
+
+/*! \brief An object representing a storage allocation. */
+class StorageObj : public Object {
+ public:
+  /*! \brief The index into the VM function table. */
+  Buffer buffer;
+
+  /*! \brief Allocate an NDArray from a given piece of storage. */
+  NDArray AllocNDArray(size_t offset, std::vector<int64_t> shape, DLDataType dtype);
+
+  /*! \brief The deleter for an NDArray when allocated from underlying storage. */
+  static void Deleter(Object* ptr);
+
+  ~StorageObj() {
+    auto alloc = MemoryManager::Global()->GetAllocator(buffer.device);
+    alloc->Free(buffer);
+  }
+
+  static constexpr const uint32_t _type_index = TypeIndex::kDynamic;
+  static constexpr const char* _type_key = "vm.Storage";
+  TVM_DECLARE_FINAL_OBJECT_INFO(StorageObj, Object);
+};
+
+/*! \brief reference to storage. */
+class Storage : public ObjectRef {
+ public:
+  explicit Storage(Buffer buffer);
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(Storage, ObjectRef, StorageObj);
+};
+
+}  // namespace vm
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_VM_MEMORY_MANAGER_H_
diff --git a/darknet_drp_ros/include/tvm/runtime/vm/vm.h b/darknet_drp_ros/include/tvm/runtime/vm/vm.h
new file mode 100644
index 0000000..6fa9183
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/runtime/vm/vm.h
@@ -0,0 +1,467 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/runtime/vm/vm.h
+ * \brief The Relay virtual machine runtime.
+ */
+#ifndef TVM_RUNTIME_VM_VM_H_
+#define TVM_RUNTIME_VM_VM_H_
+
+#include <tvm/runtime/container/closure.h>
+#include <tvm/runtime/module.h>
+#include <tvm/runtime/object.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/runtime/registry.h>
+#include <tvm/runtime/vm/bytecode.h>
+#include <tvm/runtime/vm/executable.h>
+#include <tvm/runtime/vm/memory_manager.h>
+
+#include <memory>
+#include <string>
+#include <unordered_map>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+namespace runtime {
+namespace vm {
+
+/*!
+ * \brief An object representing a vm closure.
+ */
+class VMClosureObj : public ClosureObj {
+ public:
+  /*!
+   * \brief The index into the function list. The function could be any
+   * function object that is compatible to the VM runtime.
+   */
+  size_t func_index;
+  /*! \brief The free variables of the closure. */
+  std::vector<ObjectRef> free_vars;
+
+  static constexpr const uint32_t _type_index = TypeIndex::kDynamic;
+  static constexpr const char* _type_key = "vm.Closure";
+  TVM_DECLARE_FINAL_OBJECT_INFO(VMClosureObj, ClosureObj);
+};
+
+/*! \brief reference to closure. */
+class VMClosure : public Closure {
+ public:
+  VMClosure(size_t func_index, std::vector<ObjectRef> free_vars);
+  TVM_DEFINE_OBJECT_REF_METHODS(VMClosure, Closure, VMClosureObj);
+};
+
+/*!
+ * \brief A representation of a Relay function in the VM.
+ *
+ * Contains metadata about the compiled function, as
+ * well as the compiled VM instructions.
+ */
+struct VMFunction {
+  /*! \brief The function's name. */
+  std::string name;
+  /*! \brief The function parameter names. */
+  std::vector<std::string> params;
+  /*! \brief The instructions representing the function. */
+  std::vector<Instruction> instructions;
+  /*! \brief The size of the frame for this function */
+  Index register_file_size = 0;
+  /*! \brief The indexes for the device holding each function parameter. */
+  std::vector<Index> param_device_indexes;
+
+  VMFunction(std::string name, std::vector<std::string> params,
+             std::vector<Instruction> instructions, Index register_file_size,
+             std::vector<Index> param_device_indexes)
+      : name(std::move(name)),
+        params(std::move(params)),
+        instructions(std::move(instructions)),
+        register_file_size(register_file_size),
+        param_device_indexes(std::move(param_device_indexes)) {
+    ICHECK_EQ(this->params.size(), this->param_device_indexes.size());
+  }
+
+  VMFunction() = default;
+
+  friend std::ostream& operator<<(std::ostream& os, const VMFunction&);
+};
+
+/*!
+ * \brief A representation of a stack frame.
+ *
+ * A stack frame is a record containing the information needed
+ * to restore the caller's virtual machine state after returning
+ * from a function call.
+ */
+struct VMFrame {
+  /*! \brief The return program counter. */
+  Index pc;
+  /*! \brief The index into the function table, points to the caller. */
+  Index func_index;
+  /*! \brief The number of arguments. */
+  Index args;
+  /*! \brief A pointer into the caller function's instructions. */
+  const Instruction* code;
+
+  /*! \brief Statically allocated space for objects */
+  std::vector<ObjectRef> register_file;
+
+  /*! \brief Register in caller's frame to put return value */
+  RegName caller_return_register;
+
+  VMFrame(Index pc, Index func_index, Index args, const Instruction* code, Index register_file_size)
+      : pc(pc),
+        func_index(func_index),
+        args(args),
+        code(code),
+        register_file(register_file_size),
+        caller_return_register(0) {}
+};
+
+/*!
+ * \brief The virtual machine.
+ *
+ * The virtual machine contains all the current execution state,
+ * as well as the executable.
+ *
+ * The goal is to have a single self-contained object,
+ * enabling one to easily pass around VMs, execute them on
+ * multiple threads, or serialize them to disk or over the
+ * wire.
+ */
+class TVM_DLL VirtualMachine : public runtime::ModuleNode {
+ public:
+  /*!
+   * \brief Get a PackedFunc from module.
+   *
+   *  The PackedFunc may not be fully initialized,
+   *  there might still be first time running overhead when
+   *  executing the function on certain devices.
+   *  For benchmarking, use prepare to eliminate
+   *
+   * \param name the name of the function.
+   * \param sptr_to_self The shared_ptr that points to this module node.
+   *
+   * \return PackedFunc(nullptr) when it is not available.
+   *
+   * \note The function will always remain valid.
+   *   If the function needs resource from the module(e.g. late linking),
+   *   it should capture sptr_to_self.
+   */
+  virtual PackedFunc GetFunction(const std::string& name, const ObjectPtr<Object>& sptr_to_self);
+
+  virtual ~VirtualMachine() {}
+
+  const char* type_key() const final { return "VirtualMachine"; }
+
+  VirtualMachine() : frames_(), func_index_(0), code_(nullptr), pc_(0), exec_(nullptr) {}
+
+  /*!
+   * \brief load the executable for the virtual machine.
+   * \param exec The executable.
+   */
+  virtual void LoadExecutable(const ObjectPtr<Executable>& exec);
+
+ protected:
+  /*! \brief Push a call frame on to the call stack. */
+  void PushFrame(Index arg_count, Index ret_pc, const VMFunction& vm_func);
+
+  /*!
+   * \brief Pop a frame off the call stack.
+   * \return The number of frames left.
+   */
+  Index PopFrame();
+
+  /*!
+   * \brief Write to a VM register.
+   * \param reg The register to write to.
+   * \param obj The object to write to.
+   */
+  inline void WriteRegister(RegName reg, const ObjectRef& obj);
+
+  /*!
+   * \brief Read a VM register.
+   * \param reg The register to read from.
+   * \return The read object.
+   */
+  ObjectRef ReadRegister(RegName reg) const;
+
+  /*!
+   * \brief Read a VM register and cast it to int32_t
+   * \param reg The register to read from.
+   * \return The read scalar.
+   */
+  int64_t LoadScalarInt(RegName reg) const;
+
+  /*!
+   * \brief Invoke a VM function.
+   * \param func The function.
+   * \param args The arguments to the function.
+   * \return The object representing the result.
+   */
+  ObjectRef Invoke(const VMFunction& func, const std::vector<ObjectRef>& args);
+
+  // TODO(@jroesch): I really would like this to be a global variable.
+  /*!
+   * \brief Invoke a VM function by name.
+   * \param name The function's name.
+   * \param args The arguments to the function.
+   * \return The object representing the result.
+   */
+  ObjectRef Invoke(const std::string& name, const std::vector<ObjectRef>& args);
+
+  /*!
+   * \brief Invoke a VM function.
+   * \param func The function.
+   * \param input_args The input arguments to the function.
+   * \param output_args The pre-allocated output arguments of the function.
+   * \return The object(s) representing the result.
+   */
+  ObjectRef Invoke(const VMFunction& func, const std::vector<ObjectRef>& input_args,
+                   const std::vector<ObjectRef>& output_args);
+
+  /*!
+   * \brief Invoke a PackedFunction
+   *
+   * \param packed_index The offset of the PackedFunction in all functions.
+   * \param func The PackedFunction to be invoked.
+   * \param arg_count The number of arguments to the PackedFunction.
+   * \param output_size The number of outputs of the PackedFunction.
+   * \param args Arguments to the PackedFunction.
+   *
+   * \note The return value will be stored in the last output_size slots of args.
+   */
+  virtual void InvokePacked(Index packed_index, const PackedFunc& func, Index arg_count,
+                            Index output_size, const std::vector<ObjectRef>& args);
+
+  /*!
+   * \brief Initialize the virtual machine for a set of (physical) devices.
+   * \param physical_devices The set of TVM devices.
+   * \param alloc_types The allocator types for each device.
+   */
+  void Init(const std::vector<Device>& physical_devices,
+            const std::vector<AllocatorType>& alloc_types);
+
+  /*! \brief Run VM dispatch loop. */
+  void RunLoop(const std::vector<Index>& output_tensor_reg_indices = {});
+
+  /*! \brief Get device from the device list based on a given device index. */
+  Device GetDevice(Index device_index) const;
+  Allocator* GetAllocator(Index device_index) const;
+
+  /*!
+   * \brief Invoke a global setting up the VM state to execute.
+   *
+   * This does not begin execution of the VM.
+   */
+  void InvokeGlobal(const VMFunction& func, const std::vector<ObjectRef>& args);
+
+  /*!
+   * \brief Set inputs to a function.
+   * \param name The function name
+   * \param args args[offset:] are arguments to the
+   * function. If the arguments are not of the correct device for the function,
+   * they will be copied to the device.
+   * \param offset Starting offset of the arguments in `args`.
+   */
+  void SetInput(std::string name, TVMArgs args, int offset);
+
+  /*!
+   * \brief Set one input tensor with index or name to a function.
+   * \param name The function name.
+   * \param tag index or name of the input tensor .
+   * \param tensor the input tensor. If the tensor is not of the correct device for the function,
+   * they will be copied to the device.
+   */
+  void SetOneInput(std::string name, const TVMArgValue& tag, const TVMArgValue& tensor);
+
+  /*!
+   * \brief Set pre-allocated output tensors to a function.
+   * It is native implementation of 'set_outputs' python method.
+   * It is used in scenario when output tensors are allocated outside each invocation.
+   * Note: it sets set_outputs_enabled_[name] true and fill outputs_[name]
+   * but after invocation the first is switched off and the second is cleared
+   * \param name The function name
+   * \param args outputs to the function.
+   */
+  void SetOutputs(std::string name, TVMArgs args);
+
+  /*!
+   * \brief Preparation part of Invoke method before RunLoop.
+   * \param func the function.
+   * \param args input args
+   */
+  void PrintInfoAndSetInputArgs(const VMFunction& func, const std::vector<ObjectRef>& args);
+
+  /*!
+   * \brief Set pre-allocated outputs to register for specified function.
+   * \param func_name The function's name.
+   * \param outputs set of output tensors.
+   */
+  void SetOutputTensorsToRegister(const std::string& func_name,
+                                  const std::vector<ObjectRef>& outputs);
+
+  /*!
+   * \brief Internal hook for profiling the start of an op.
+   *
+   * This hook is only called on certain ops that are likely to take a
+   * significant amount of runtime (normally because they alloc or transfer to
+   * device).
+   *
+   * \param instr Instruction that will be executed after this hook fires
+   */
+  virtual void OpStartHook(Instruction instr);
+
+  /*!
+   * \brief Internal hook for profiling the end of an op.
+   */
+  virtual void OpStopHook();
+
+ private:
+  /*!
+   * \brief Get index of input tensor from its name.
+   * \param func_name The function's name.
+   * \param input_name The input tensor name.
+   * \return The input tensor index.
+   */
+  int64_t GetInputIndexFromVMFunction(const std::string& func_name,
+                                      const std::string& input_name) const;
+
+  /*!
+   * \brief Get index of input tensor from its name.
+   * \param params parameter names.
+   * \param input_name The input tensor name.
+   * \return The input tensor index.
+   */
+  int64_t GetInputIndexFromName(const std::vector<std::string>& params,
+                                const std::string& input_name) const;
+
+  /*!
+   * \brief Check executable exists and get VM function from it.
+   * \param func_name The function's name.
+   * \return VM function.
+   */
+  const VMFunction& CheckAndGetVMFunction(const std::string& func_name) const;
+
+  /*!
+   * \brief Creats inputs_ field, if it exists check its size.
+   * \param func_name The function's name.
+   * \param size inputs_ field size.
+   * \return VM function.
+   */
+  void CreateInputsOrCheckSize(const std::string& func_name, size_t size);
+
+  /*!
+   * \brief Set one input tensor with given index to set of input tensors if need copy to given
+   * device. \param tensors the input tensors set (destination) \param tensor some tensor (not
+   * necessary DLTensor). \param index The input tensor index. \param dev device to copy if need.
+   */
+  void SetInputTensorWithIndex(std::vector<ObjectRef>& tensors,  // NOLINT(*)
+                               const TVMArgValue& tensor, int index, Device dev);
+
+  /*!
+   * \brief Convert tensor from TVMArgValue to ObjectRef.
+   * DLTensor and NDArray types are supported.
+   * \param tensor given arg value containing tensor.
+   * \return tensor in ObjectRef format
+   */
+  ObjectRef TensorFromTVMArgValueToObjectRef(const TVMArgValue& tensor) const;
+
+  /*!
+   * \brief Get index of outputs in register_file from func code
+   * \return result register index
+   */
+  Index GetResultRegisterIndex() const;
+
+  /*!
+   * \brief Calculate the index of operation which destination is result
+   * \param res_index is the index of op returning result
+   */
+  void CalculatePreResultOpIndex(Index res_index);
+
+  /*!
+   * \brief Get indices from register_file for output tensors.
+   * It helps to replace output tensors allocated in RunLoop by
+   * tensors pre-allocated outside. Scenario is when `set_output` is used
+   * \return indices from register_file for output tensors.
+   */
+  std::vector<Index> GetOutputTensorRegIndices();
+
+  /*!
+   * \brief Write new allocated tensor to register_file of frame.
+   * \param instr current instruction containing shape and storage info.
+   */
+  void WriteAllocatedTensor(const Instruction& instr);
+
+  /*!
+   * \brief 'set_outputs_enabled' is assumed true for using this method.
+   * It is expected that result register has already contained tensor from outside,
+   * new memory is not allocated and write, but expected shape and data type are checked.
+   * For other register WriteAllocatedTensor method is used.
+   * \param instr current instruction containing shape and storage info.
+   */
+  void WriteAllocatedTensorFromOutside(const Instruction& instr);
+
+  bool FindIndex(const std::vector<Index>& indices, Index val) const;
+
+ protected:
+  /*! \brief The virtual machine's packed function table. */
+  std::vector<PackedFunc> packed_funcs_;
+  /*! \brief The current stack of call frames. */
+  std::vector<VMFrame> frames_;
+  /*! \brief The fuction table index of the current function. */
+  Index func_index_;
+  /*! \brief The current pointer to the code section. */
+  const Instruction* code_;
+  /*! \brief The virtual machine PC. */
+  Index pc_;
+  /*! \brief The special return register. */
+  ObjectRef return_register_;
+  /*! \brief The executable the VM will operate on. */
+  ObjectPtr<Executable> exec_;
+  /*! \brief The function name to inputs mapping. */
+  std::unordered_map<std::string, std::vector<ObjectRef>> inputs_;
+  /*! \brief The function name to flag enabling scenario with set outputs. */
+  std::unordered_map<std::string, bool> set_outputs_enabled_;
+  /*! \brief The index of operation which destination is result. */
+  Index preresult_op_index_ = -1;
+  /*! \brief The function name to indices of output tensors in register file. */
+  std::unordered_map<std::string, std::vector<Index>> output_tensor_reg_indices_;
+  /*! \brief The function name to pre-allocated outputs mapping. */
+  std::unordered_map<std::string, std::vector<ObjectRef>> outputs_;
+  /*!
+   * \brief The "physical" devices the VM can execute primitives on. All "device indexes"
+   * are w.r.t. this vector. Each entry in this vector must match the corresponding entry
+   * in the executable's "virtual" devices vector.
+   */
+  std::vector<Device> devices_;
+  /*! \brief The cached memory allocators, one per device. */
+  std::vector<Allocator*> allocators_;
+  /*!
+   * \brief The constant pool for runtime. It caches the device dependent
+   * object to avoid rellocation of constants during inference.
+   */
+  std::vector<ObjectRef> const_pool_;
+};
+
+}  // namespace vm
+}  // namespace runtime
+}  // namespace tvm
+
+#endif  // TVM_RUNTIME_VM_VM_H_
diff --git a/darknet_drp_ros/include/tvm/script/ir_builder/base.h b/darknet_drp_ros/include/tvm/script/ir_builder/base.h
new file mode 100644
index 0000000..61ca3eb
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/script/ir_builder/base.h
@@ -0,0 +1,302 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_SCRIPT_IR_BUILDER_BASE_H_
+#define TVM_SCRIPT_IR_BUILDER_BASE_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/ir/function.h>
+#include <tvm/node/node.h>
+
+#include <vector>
+
+namespace tvm {
+namespace script {
+namespace ir_builder {
+
+////////////////////////////// IRBuilderFrame //////////////////////////////
+
+/*!
+ * \brief A stack frame of the IRBuilder used to keep track of the current scope.
+ * Furthermore, the information stored in each stack frame can be useful for context-dependent
+ * IR construction.
+ *
+ * \example
+ *
+ * The `T::MatchBuffer` below adds an element in `PrimFuncNode::buffer_map`:
+ *
+ * \code {.cpp}
+ *
+ * using T = tvm::script::ir_builder::tir;
+ * With <PrimFuncFrame> _(...);
+ * Buffer buffer = T::MatchBuffer(...);
+ *
+ * \endcode
+ *
+ * The `T::MatchBuffer` below instead generates `MatchBufferRegion` in a TIR block:
+ *
+ * \code {.cpp}
+ *
+ * using T = tvm::script::ir_builder::tir;
+ * With <PrimFuncFrame> _(...);
+ * {
+ *   With<BlockFrame> _2(...);
+ *   Buffer buffer = T::MatchBuffer(...);
+ * }
+ *
+ * \endcode
+ */
+class IRBuilderFrameNode : public runtime::Object {
+ public:
+  /*! \brief A list of callbacks used when exiting the frame. */
+  std::vector<runtime::TypedPackedFunc<void()>> callbacks;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    // `callbacks` is not visited.
+  }
+
+  static constexpr const char* _type_key = "script.ir_builder.IRBuilderFrame";
+  TVM_DECLARE_BASE_OBJECT_INFO(IRBuilderFrameNode, runtime::Object);
+
+ public:
+  /*! \brief Default destructor. */
+  virtual ~IRBuilderFrameNode() = default;
+  /*!
+   * \brief The method called when entering RAII scope.
+   * \sa tvm::support::With
+   */
+  virtual void EnterWithScope();
+  /*!
+   * \brief The method called when exiting RAII scope.
+   * \sa tvm::support::With
+   */
+  virtual void ExitWithScope();
+  /*!
+   * \brief Add a callback method invoked when exiting the RAII scope.
+   * \param callback The callback to be added.
+   */
+  void AddCallback(runtime::TypedPackedFunc<void()> callback);
+};
+
+/*!
+ * \brief Managed reference to an IRBuilderFrameNode.
+ * \sa IRBuilderFrameNode
+ */
+class IRBuilderFrame : public runtime::ObjectRef {
+ public:
+  /*! \brief Default destructor. */
+  virtual ~IRBuilderFrame() = default;
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(IRBuilderFrame, ObjectRef, IRBuilderFrameNode);
+
+ protected:
+  /*! \brief Disallow direct construction of this object. */
+  IRBuilderFrame() = default;
+
+ public:
+  /*!
+   * \brief Redirected to `IRBuilderFrameNode::EnterWithScope`.
+   * \sa IRBuilderFrameNode::EnterWithScope
+   */
+  inline void EnterWithScope() {
+    ICHECK(data_ != nullptr);
+    static_cast<IRBuilderFrameNode*>(data_.get())->EnterWithScope();
+  }
+  /*!
+   * \brief Redirected to `IRBuilderFrameNode::ExitWithScope`.
+   * \sa IRBuilderFrameNode::ExitWithScope
+   */
+  inline void ExitWithScope() {
+    ICHECK(data_ != nullptr);
+    static_cast<IRBuilderFrameNode*>(data_.get())->ExitWithScope();
+    data_.reset();
+  }
+};
+
+////////////////////////////// IRBuilder //////////////////////////////
+
+/*!
+ * \brief A dialect-agnostic IRBuilder that constructs any IR of TVM.
+ * An idiomatic use of this class is to put this inside the RAII with-scope,
+ * call dialect-specific methods accordingly. Upon exiting the scope.
+ *
+ * \code
+ *
+ * PrimFunc ConstructPrimFunc() {
+ *   using tvm::script::ir_builder::IRBuilder;
+ *   using T = tvm::script::ir_builder::tir;
+ *   IRBuilder builder;
+ *   // Step 1. Place IRBuilder inside the with-scope.
+ *   {
+ *     With<IRBuilder> _(builder);
+ *     // Step 2. Call dialect-specific methods.
+ *     With<T::PrimFuncFrame> _2(...);
+ *     T::MatchBuffer(...);
+ *   }
+ *   // Step 3. Return the constructed PrimFunc.
+ *   return builder->Get<PrimFunc>();
+ * }
+ *
+ * \endcode
+ */
+class IRBuilderNode : public runtime::Object {
+ public:
+  /*! \brief A stack of context frames in the IRBuilder */
+  runtime::Array<IRBuilderFrame> frames;
+  /*! \brief The outcome of IR construction */
+  Optional<ObjectRef> result;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("frames", &frames);
+    v->Visit("result", &result);
+  }
+
+  static constexpr const char* _type_key = "script.ir_builder.IRBuilder";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IRBuilderNode, runtime::Object);
+
+ public:
+  /*!
+   * \brief Find a frame of the given type in the stack `this->frames` from top to bottom.
+   * \tparam T The type of the frame to find.
+   * \return The frame if found, otherwise NullOpt.
+   */
+  template <typename TFrame>
+  inline Optional<TFrame> FindFrame() const;
+  /*!
+   * \brief Get the frame on top of the stack `this->frames` if its type is `TFrame`.
+   * \tparam TFrame The assumed type of the last frame on stack.
+   * \return The frame if the stack is non-empty and the top of the stack is of type `TFrame`.
+   * Otherwise NullOpt.
+   */
+  template <typename TFrame>
+  inline Optional<TFrame> GetLastFrame() const;
+  /*!
+   * \brief Get the IR being constructed.
+   * \tparam TObjectRef The type of the IR being constructed.
+   * \return The resulting IR. Throw an exception if the IR is not constructed yet.
+   */
+  template <typename TObjectRef>
+  inline TObjectRef Get() const;
+};
+
+/*!
+ * \brief Managed reference to an IRBuilderNode.
+ * \sa IRBuilderNode
+ */
+class IRBuilder : public runtime::ObjectRef {
+ public:
+  /*! \brief Creates an IRBuilder. */
+  IRBuilder();
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(IRBuilder, ObjectRef, IRBuilderNode);
+
+ public:
+  /*!
+   * \brief Puts the current IRBuilder into a thread-local scope, which can be retrieved using
+   * `IRBuilder::Current()`.
+   *
+   * \code {.cpp}
+   * IRBuilder builder;
+   * {
+   *   With<IRBuilder> _(builder);
+   *   // IRBuilder::Current() == builder
+   * }
+   * // IRBuilder::Current() == nullptr
+   * \endcode
+   *
+   * \sa IRBuilder::Current
+   * \sa IRBuilder::ExitWithScope
+   * \sa tvm::support::With
+   */
+  void EnterWithScope();
+  /*!
+   * \brief Exit the RAII scope.
+   * \sa IRBuilder::EnterWithScope
+   * \sa IRBuilder::Current
+   * \sa tvm::support::With
+   */
+  void ExitWithScope();
+  /*!
+   * \brief Get the current IRBuilder in the current thread-local scope.
+   * \return The current IRBuilder.
+   * \sa IRBuilder::EnterWithScope
+   * \sa IRBuilder::ExitWithScope
+   * \sa tvm::support::With
+   */
+  static IRBuilder Current();
+  /*!
+   * \brief Give a string name to the `obj`
+   * \tparam TObjectRef The type of the object to name.
+   * \param name The name to give to the object.
+   * \param obj The object to name.
+   */
+  template <class TObjectRef>
+  inline static TObjectRef Name(String name, TObjectRef obj);
+};
+
+////////////////////////////// Details //////////////////////////////
+
+namespace details {
+
+class Namer {
+ public:
+  using FType = NodeFunctor<void(const ObjectRef&, String)>;
+  static FType& vtable();
+  static void Name(ObjectRef node, String name);
+};
+
+}  // namespace details
+
+template <class TObjectRef>
+inline TObjectRef IRBuilder::Name(String name, TObjectRef obj) {
+  details::Namer::Name(obj, name);
+  return Downcast<TObjectRef>(obj);
+}
+
+template <typename TFrame>
+inline Optional<TFrame> IRBuilderNode::FindFrame() const {
+  using TFrameNode = typename TFrame::ContainerType;
+  for (auto it = frames.rbegin(); it != frames.rend(); ++it) {
+    if (const TFrameNode* p = (*it).template as<TFrameNode>()) {
+      return GetRef<TFrame>(p);
+    }
+  }
+  return NullOpt;
+}
+
+template <typename TFrame>
+inline Optional<TFrame> IRBuilderNode::GetLastFrame() const {
+  using TFrameNode = typename TFrame::ContainerType;
+  if (!frames.empty() && frames.back()->IsInstance<TFrameNode>()) {
+    return Downcast<TFrame>(frames.back());
+  }
+  return NullOpt;
+}
+
+template <typename TObjectRef>
+inline TObjectRef IRBuilderNode::Get() const {
+  using TObject = typename TObjectRef::ContainerType;
+  CHECK(result.defined()) << "IndexError: No result exists in IRBuilder yet";
+  const auto* n = result.as<TObject>();
+  CHECK(n != nullptr) << "TypeError: IRBuilder result is not of type: " << TObject::_type_key;
+  return GetRef<TObjectRef>(n);
+}
+
+}  // namespace ir_builder
+}  // namespace script
+}  // namespace tvm
+
+#endif  // TVM_SCRIPT_IR_BUILDER_BASE_H_
diff --git a/darknet_drp_ros/include/tvm/script/ir_builder/ir/frame.h b/darknet_drp_ros/include/tvm/script/ir_builder/ir/frame.h
new file mode 100644
index 0000000..887981c
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/script/ir_builder/ir/frame.h
@@ -0,0 +1,73 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_SCRIPT_IR_BUILDER_IR_FRAME_H_
+#define TVM_SCRIPT_IR_BUILDER_IR_FRAME_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/ir/function.h>
+#include <tvm/node/node.h>
+#include <tvm/script/ir_builder/base.h>
+
+#include <vector>
+
+namespace tvm {
+namespace script {
+namespace ir_builder {
+namespace ir {
+
+/*!
+ * \brief A frame that represents the IRModule frame with functions and global variables.
+ *
+ * \sa IRModuleFrame
+ */
+class IRModuleFrameNode : public IRBuilderFrameNode {
+ public:
+  Array<GlobalVar> global_vars;
+  Array<BaseFunc> functions;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    IRBuilderFrameNode::VisitAttrs(v);
+    v->Visit("global_vars", &global_vars);
+    v->Visit("functions", &functions);
+  }
+
+  static constexpr const char* _type_key = "script.ir_builder.IRModuleFrame";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IRModuleFrameNode, IRBuilderFrameNode);
+
+ public:
+  void ExitWithScope() final;
+};
+
+/*!
+ * \brief Managed reference to IRModuleFrameNode.
+ *
+ * \sa IRModuleFrameNode
+ */
+class IRModuleFrame : public IRBuilderFrame {
+ public:
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(IRModuleFrame, IRBuilderFrame,
+                                                    IRModuleFrameNode);
+};
+
+}  // namespace ir
+}  // namespace ir_builder
+}  // namespace script
+}  // namespace tvm
+
+#endif  // TVM_SCRIPT_IR_BUILDER_IR_FRAME_H_
diff --git a/darknet_drp_ros/include/tvm/script/ir_builder/ir/ir.h b/darknet_drp_ros/include/tvm/script/ir_builder/ir/ir.h
new file mode 100644
index 0000000..f0e7cc6
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/script/ir_builder/ir/ir.h
@@ -0,0 +1,45 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_SCRIPT_IR_BUILDER_IR_IR_H_
+#define TVM_SCRIPT_IR_BUILDER_IR_IR_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/ir/function.h>
+#include <tvm/node/node.h>
+#include <tvm/script/ir_builder/ir/frame.h>
+
+#include <vector>
+
+namespace tvm {
+namespace script {
+namespace ir_builder {
+namespace ir {
+
+/*!
+ * \brief The IRModule declaration statement.
+ * \return The IRModuleFrame.
+ */
+TVM_DLL IRModuleFrame IRModule();
+
+}  // namespace ir
+}  // namespace ir_builder
+}  // namespace script
+}  // namespace tvm
+
+#endif  // TVM_SCRIPT_IR_BUILDER_IR_IR_H_
diff --git a/darknet_drp_ros/include/tvm/script/ir_builder/tir/frame.h b/darknet_drp_ros/include/tvm/script/ir_builder/tir/frame.h
new file mode 100644
index 0000000..ee80322
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/script/ir_builder/tir/frame.h
@@ -0,0 +1,751 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_SCRIPT_IR_BUILDER_TIR_FRAME_H_
+#define TVM_SCRIPT_IR_BUILDER_TIR_FRAME_H_
+
+#include <tvm/script/ir_builder/base.h>
+#include <tvm/script/ir_builder/ir/frame.h>
+#include <tvm/tir/stmt.h>
+
+namespace tvm {
+namespace script {
+namespace ir_builder {
+namespace tir {
+
+/*!
+ * \brief A base frame that represents the TIR fame with body of statements.
+ *
+ * \sa TIRFrame
+ */
+class TIRFrameNode : public IRBuilderFrameNode {
+ public:
+  /*! \brief The Stmt within in this frame. */
+  Array<tvm::tir::Stmt> stmts;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    IRBuilderFrameNode::VisitAttrs(v);
+    v->Visit("stmts", &stmts);
+  }
+
+  static constexpr const char* _type_key = "script.ir_builder.tir.TIRFrame";
+  TVM_DECLARE_BASE_OBJECT_INFO(TIRFrameNode, IRBuilderFrameNode);
+};
+
+/*!
+ * \brief Managed reference to TIRFrameNode.
+ *
+ * \sa TIRFrameNode
+ */
+class TIRFrame : public IRBuilderFrame {
+ public:
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(TIRFrame, IRBuilderFrame, TIRFrameNode);
+
+ protected:
+  TIRFrame() = default;
+};
+
+/*!
+ * \brief A frame that represents the PrimFunc containing TIR statements.
+ *
+ * \sa PrimFuncFrame
+ */
+class PrimFuncFrameNode : public TIRFrameNode {
+ public:
+  /*! \brief The name of the block. */
+  Optional<String> name;
+  /*! \brief Function parameters. */
+  Array<tvm::tir::Var> args;
+  /*! \brief The return type of the function. */
+  Optional<Type> ret_type;
+  /*! \brief Maps some parameters to specific Buffer data structures. */
+  Map<tvm::tir::Var, tvm::tir::Buffer> buffer_map;
+  /*! \brief Additional attributes storing the meta-data */
+  Optional<Map<String, ObjectRef>> attrs;
+  /*! \brief The variable map bound to thread env. */
+  Map<tvm::tir::Var, tvm::tir::IterVar> env_threads;
+  /*! \brief The buffer allocated in root block. */
+  Array<tvm::tir::Buffer> root_alloc_buffers;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    TIRFrameNode::VisitAttrs(v);
+    v->Visit("name", &name);
+    v->Visit("args", &args);
+    v->Visit("ret_type", &ret_type);
+    v->Visit("buffer_map", &buffer_map);
+    v->Visit("attrs", &attrs);
+    v->Visit("env_threads", &env_threads);
+    v->Visit("root_alloc_buffers", &root_alloc_buffers);
+  }
+
+  static constexpr const char* _type_key = "script.ir_builder.tir.PrimFuncFrame";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PrimFuncFrameNode, TIRFrameNode);
+
+ public:
+  /*!
+   * \brief The method called when exiting RAII scope.
+   * \sa tvm::support::With
+   */
+  void ExitWithScope() final;
+};
+
+/*!
+ * \brief Managed reference to PrimFuncFrameNode.
+ *
+ * \sa PrimFuncFrameNode
+ */
+class PrimFuncFrame : public TIRFrame {
+ public:
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(PrimFuncFrame, TIRFrame, PrimFuncFrameNode);
+};
+
+/*!
+ * \brief A frame that represents the block.
+ *
+ * \sa BlockFrame
+ */
+class BlockFrameNode : public TIRFrameNode {
+ public:
+  /*! \brief The name of the block. */
+  String name;
+  /*! \brief The variables of the block. */
+  Array<tvm::tir::IterVar> iter_vars;
+  /*! \brief The read buffer regions of the block. */
+  Optional<Array<tvm::tir::BufferRegion>> reads;
+  /*! \brief The write buffer regions of the block. */
+  Optional<Array<tvm::tir::BufferRegion>> writes;
+  /*! \brief The init statement of the bolck. */
+  Optional<tvm::tir::Stmt> init;
+  /*! \brief The buffer allocated in the block. */
+  Array<tvm::tir::Buffer> alloc_buffers;
+  /*! \brief The match buffer regions. */
+  Array<tvm::tir::MatchBufferRegion> match_buffers;
+  /*! \brief The annotation of the block. */
+  Optional<Map<String, ObjectRef>> annotations;
+  /*! \brief The corresponding values of the iter vars. */
+  Array<PrimExpr> iter_values;
+  /*!
+   * \brief The predicate of the block realization, the block will only be executed when the
+   * predicate is true.
+   */
+  Optional<PrimExpr> predicate;
+  /*! \brief The flag whether to construct BlockRealize or Block. */
+  bool no_realize;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    TIRFrameNode::VisitAttrs(v);
+    v->Visit("name", &name);
+    v->Visit("iter_vars", &iter_vars);
+    v->Visit("reads", &reads);
+    v->Visit("writes", &writes);
+    v->Visit("init", &init);
+    v->Visit("alloc_buffers", &alloc_buffers);
+    v->Visit("match_buffers", &match_buffers);
+    v->Visit("annotations", &annotations);
+    v->Visit("iter_values", &iter_values);
+    v->Visit("predicate", &predicate);
+    v->Visit("no_realize", &no_realize);
+  }
+
+  static constexpr const char* _type_key = "script.ir_builder.tir.BlockFrame";
+  TVM_DECLARE_FINAL_OBJECT_INFO(BlockFrameNode, TIRFrameNode);
+
+ public:
+  /*!
+   * \brief The method called when exiting RAII scope.
+   * \sa tvm::support::With
+   */
+  void ExitWithScope() final;
+};
+
+/*!
+ * \brief Managed reference to BlockFrameNode.
+ *
+ * \sa BlockFrameNode
+ */
+
+class BlockFrame : public TIRFrame {
+ public:
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(BlockFrame, TIRFrame, BlockFrameNode);
+};
+
+/*!
+ * \brief A frame that represents the block initialization statment.
+ *
+ * \sa BlockInitFrame
+ */
+class BlockInitFrameNode : public TIRFrameNode {
+ public:
+  void VisitAttrs(tvm::AttrVisitor* v) { TIRFrameNode::VisitAttrs(v); }
+
+  static constexpr const char* _type_key = "script.ir_builder.tir.BlockInitFrame";
+  TVM_DECLARE_FINAL_OBJECT_INFO(BlockInitFrameNode, TIRFrameNode);
+
+ public:
+  /*!
+   * \brief The method called when entering RAII scope.
+   * \sa tvm::support::With
+   */
+  void EnterWithScope() final;
+  /*!
+   * \brief The method called when exiting RAII scope.
+   * \sa tvm::support::With
+   */
+  void ExitWithScope() final;
+};
+
+/*!
+ * \brief Managed reference to BlockInitFrameNode.
+ *
+ * \sa BlockInitFrameNode
+ */
+class BlockInitFrame : public TIRFrame {
+ public:
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(BlockInitFrame, TIRFrame, BlockInitFrameNode);
+};
+
+/*!
+ * \brief A frame that represents the for loop.
+ *
+ * \sa ForFrame
+ */
+class ForFrameNode : public TIRFrameNode {
+ public:
+  /*!
+   * \brief Functions that generate loop nests.
+   * \param loop_vars The loop variables, from outer to inner
+   * \param loop_extents The loop extents that correspond to loop variables
+   * \param loop_body The loop body
+   * \return A stmt, the loop nest
+   */
+  using FMakeForLoop = runtime::TypedPackedFunc<tvm::tir::Stmt(
+      Array<tvm::tir::Var> loop_vars, Array<Range> loop_extents, tvm::tir::Stmt loop_body)>;
+  /*! \brief The loop variable. */
+  Array<tvm::tir::Var> vars;
+  /*! \brief The domains of iteration. */
+  Array<Range> doms;
+  /*! \brief The for loop generating function. */
+  FMakeForLoop f_make_for_loop;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    TIRFrameNode::VisitAttrs(v);
+    v->Visit("vars", &vars);
+    v->Visit("doms", &doms);
+    // `f_make_for_loop` is not visited.
+  }
+
+  static constexpr const char* _type_key = "script.ir_builder.tir.ForFrame";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ForFrameNode, TIRFrameNode);
+
+ public:
+  /*!
+   * \brief The method called when exiting RAII scope.
+   * \sa tvm::support::With
+   */
+  void ExitWithScope() final;
+};
+
+/*!
+ * \brief Managed reference to ForFrameNode.
+ *
+ * \sa ForFrameNode
+ */
+class ForFrame : public TIRFrame {
+ public:
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(ForFrame, TIRFrame, ForFrameNode);
+};
+
+/*!
+ * \brief A frame that represents the assert statement. Proceeds if the condition is true,
+ * otherwise aborts with the message.
+ *
+ * \sa AssertFrame
+ */
+class AssertFrameNode : public TIRFrameNode {
+ public:
+  /*! \brief The PrimExpr to test. */
+  PrimExpr condition;
+  /*! \brief The output error message when the assertion failed. */
+  PrimExpr message;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    TIRFrameNode::VisitAttrs(v);
+    v->Visit("condition", &condition);
+    v->Visit("message", &message);
+  }
+
+  static constexpr const char* _type_key = "script.ir_builder.tir.AssertFrame";
+  TVM_DECLARE_FINAL_OBJECT_INFO(AssertFrameNode, TIRFrameNode);
+
+ public:
+  /*!
+   * \brief The method called when exiting RAII scope.
+   * \sa tvm::support::With
+   */
+  void ExitWithScope() final;
+};
+
+/*!
+ * \brief Managed reference to AssertFrameNode.
+ *
+ * \sa AssertFrameNode
+ */
+class AssertFrame : public TIRFrame {
+ public:
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(AssertFrame, TIRFrame, AssertFrameNode);
+};
+
+/*!
+ * \brief A frame represents the let binding expression, which binds a var.
+ *
+ * \sa LetFrameNode
+ */
+class LetFrameNode : public TIRFrameNode {
+ public:
+  /*! \brief The variable we bind to */
+  tvm::tir::Var var;
+  /*! \brief The value we bind var to */
+  PrimExpr value;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    TIRFrameNode::VisitAttrs(v);
+    v->Visit("var", &var);
+    v->Visit("value", &value);
+  }
+
+  static constexpr const char* _type_key = "script.ir_builder.tir.LetFrame";
+  TVM_DECLARE_FINAL_OBJECT_INFO(LetFrameNode, TIRFrameNode);
+
+ public:
+  /*!
+   * \brief The method called when exiting RAII scope.
+   * \sa tvm::support::With
+   */
+  void ExitWithScope() final;
+};
+
+/*!
+ * \brief Managed reference to LetFrameNode.
+ *
+ * \sa LetFrameNode
+ */
+class LetFrame : public TIRFrame {
+ public:
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(LetFrame, TIRFrame, LetFrameNode);
+};
+
+/*!
+ * \brief The LaunchThreadFrameNode.
+ * \note It is used only inside a PrimFunc.
+ */
+class LaunchThreadFrameNode : public TIRFrameNode {
+ public:
+  /*! \brief The extent of environment thread. */
+  PrimExpr extent;
+  /*! \brief The attribute key, could be either virtual_thread or thread_extent. */
+  String attr_key;
+  /*! \brief The iteration variable. */
+  tvm::tir::IterVar iter_var;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    TIRFrameNode::VisitAttrs(v);
+    v->Visit("extent", &extent);
+    v->Visit("attr_key", &attr_key);
+    v->Visit("iter_var", &iter_var);
+  }
+
+  static constexpr const char* _type_key = "script.ir_builder.tir.LaunchThreadFrame";
+  TVM_DECLARE_FINAL_OBJECT_INFO(LaunchThreadFrameNode, TIRFrameNode);
+
+ public:
+  /*!
+   * \brief The method called when exiting RAII scope.
+   * \sa tvm::support::With
+   */
+  void ExitWithScope() final;
+};
+
+/*!
+ * \brief Managed reference to LaunchThreadFrameNode.
+ *
+ * \sa LaunchThreadFrameNode
+ */
+class LaunchThreadFrame : public TIRFrame {
+ public:
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(LaunchThreadFrame, TIRFrame,
+                                                    LaunchThreadFrameNode);
+};
+
+/*!
+ * \brief A frame that represents realization.
+ *
+ * \sa RealizeFrame
+ */
+class RealizeFrameNode : public TIRFrameNode {
+ public:
+  /*! \brief The region of buffer access. */
+  tvm::tir::BufferRegion buffer_slice;
+  /*! \brief The storage scope associated with this realization. */
+  String storage_scope;
+  /*! \brief The condition expression. */
+  PrimExpr condition;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    TIRFrameNode::VisitAttrs(v);
+    v->Visit("buffer_slice", &buffer_slice);
+    v->Visit("storage_scope", &storage_scope);
+    v->Visit("condition", &condition);
+  }
+
+  static constexpr const char* _type_key = "script.ir_builder.tir.RealizeFrame";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RealizeFrameNode, TIRFrameNode);
+
+ public:
+  /*!
+   * \brief The method called when exiting RAII scope.
+   * \sa tvm::support::With
+   */
+  void ExitWithScope() final;
+};
+
+/*!
+ * \brief Managed reference to RealizeFrameNode.
+ *
+ * \sa RealizeFrameNode
+ */
+class RealizeFrame : public TIRFrame {
+ public:
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(RealizeFrame, TIRFrame, RealizeFrameNode);
+};
+
+/*!
+ * \brief A frame represents the allocate.
+ *
+ * \sa AllocateFrame
+ */
+class AllocateFrameNode : public TIRFrameNode {
+ public:
+  /*! \brief The extents of the allocate. */
+  Array<PrimExpr> extents;
+  /*! \brief The data type of the buffer. */
+  DataType dtype;
+  /*! \brief The storage scope. */
+  String storage_scope;
+  /*! \brief The condition. */
+  PrimExpr condition;
+  /*! \brief Additional annotation hints. */
+  Map<String, ObjectRef> annotations;
+  /*! \brief The buffer var. */
+  tvm::tir::Var buffer_var;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    TIRFrameNode::VisitAttrs(v);
+    v->Visit("extents", &extents);
+    v->Visit("dtype", &dtype);
+    v->Visit("storage_scope", &storage_scope);
+    v->Visit("condition", &condition);
+    v->Visit("annotations", &annotations);
+    v->Visit("buffer_var", &buffer_var);
+  }
+
+  static constexpr const char* _type_key = "script.ir_builder.tir.AllocateFrame";
+  TVM_DECLARE_FINAL_OBJECT_INFO(AllocateFrameNode, TIRFrameNode);
+
+ public:
+  /*!
+   * \brief The method called when exiting RAII scope.
+   * \sa tvm::support::With
+   */
+  void ExitWithScope() final;
+};
+
+/*!
+ * \brief Managed reference to AllocateFrameNode.
+ *
+ * \sa AllocateFrameNode
+ */
+class AllocateFrame : public TIRFrame {
+ public:
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(AllocateFrame, TIRFrame, AllocateFrameNode);
+};
+
+/*!
+ * \brief A frame represents the allocate constant.
+ *
+ * \sa AllocateConstFrame
+ */
+class AllocateConstFrameNode : public TIRFrameNode {
+ public:
+  /*! \brief The data type of the buffer. */
+  DataType dtype;
+  /*! \brief The extents of the allocate. */
+  Array<PrimExpr> extents;
+  /*! \brief The data associated with the constant. */
+  tvm::runtime::NDArray data;
+  /*! \brief The buffer var */
+  tvm::tir::Var buffer_var;
+  /*! \brief Additional annotations about the allocation. */
+  Map<String, ObjectRef> annotations;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    TIRFrameNode::VisitAttrs(v);
+    v->Visit("dtype", &dtype);
+    v->Visit("extents", &extents);
+    v->Visit("data", &data);
+    v->Visit("buffer_var", &buffer_var);
+    v->Visit("annotations", &annotations);
+  }
+
+  static constexpr const char* _type_key = "script.ir_builder.tir.AllocateConstFrame";
+  TVM_DECLARE_FINAL_OBJECT_INFO(AllocateConstFrameNode, TIRFrameNode);
+
+ public:
+  /*!
+   * \brief The method called when exiting RAII scope.
+   * \sa tvm::support::With
+   */
+  void ExitWithScope() final;
+};
+
+/*!
+ * \brief Managed reference to AllocateConstFrameNode.
+ *
+ * \sa AllocateConstFrameNode
+ */
+class AllocateConstFrame : public TIRFrame {
+ public:
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(AllocateConstFrame, TIRFrame,
+                                                    AllocateConstFrameNode);
+};
+/*!
+ * \brief A frame that represents attribute node.
+ *
+ * \sa AttrFrame
+ */
+class AttrFrameNode : public TIRFrameNode {
+ public:
+  /*! \brief The node to annotate the attribute. */
+  ObjectRef node;
+  /*! \brief Attribute type key. */
+  String attr_key;
+  /*! \brief The value of the attribute. */
+  PrimExpr value;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    TIRFrameNode::VisitAttrs(v);
+    v->Visit("node", &node);
+    v->Visit("attr_key", &attr_key);
+    v->Visit("value", &value);
+  }
+
+  static constexpr const char* _type_key = "script.ir_builder.tir.AttrFrame";
+  TVM_DECLARE_FINAL_OBJECT_INFO(AttrFrameNode, TIRFrameNode);
+
+ public:
+  /*!
+   * \brief The method called when exiting RAII scope.
+   * \sa tvm::support::With
+   */
+  void ExitWithScope() final;
+};
+
+/*!
+ * \brief Managed reference to AttrFrameNode.
+ *
+ * \sa AttrFrameNode
+ */
+class AttrFrame : public TIRFrame {
+ public:
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(AttrFrame, TIRFrame, AttrFrameNode);
+};
+
+/*!
+ * \brief A frame that represents while loop.
+ *
+ * \sa WhileFrame
+ */
+class WhileFrameNode : public TIRFrameNode {
+ public:
+  /*! \brief The termination condition of while. */
+  PrimExpr condition;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    TIRFrameNode::VisitAttrs(v);
+    v->Visit("condition", &condition);
+  }
+
+  static constexpr const char* _type_key = "script.ir_builder.tir.WhileFrame";
+  TVM_DECLARE_FINAL_OBJECT_INFO(WhileFrameNode, TIRFrameNode);
+
+ public:
+  /*!
+   * \brief The method called when exiting RAII scope.
+   * \sa tvm::support::With
+   */
+  void ExitWithScope() final;
+};
+
+/*!
+ * \brief Managed reference to WhileFrameNode.
+ *
+ * \sa WhileFrameNode
+ */
+class WhileFrame : public TIRFrame {
+ public:
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(WhileFrame, TIRFrame, WhileFrameNode);
+};
+
+/*!
+ * \brief A frame that represents if statement.
+ *
+ * \sa IfFrame
+ */
+class IfFrameNode : public TIRFrameNode {
+ public:
+  /*! \brief The condition of the if statement. */
+  PrimExpr condition;
+  /*! \brief The statements in the true branch. */
+  Optional<Array<tvm::tir::Stmt>> then_stmts;
+  /*! \brief The stetements in the false branch. */
+  Optional<Array<tvm::tir::Stmt>> else_stmts;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    TIRFrameNode::VisitAttrs(v);
+    v->Visit("condition", &condition);
+    v->Visit("then_stmts", &then_stmts);
+    v->Visit("else_stmts", &else_stmts);
+  }
+
+  static constexpr const char* _type_key = "script.ir_builder.tir.IfFrame";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IfFrameNode, TIRFrameNode);
+
+ public:
+  /*!
+   * \brief The method called when exiting RAII scope.
+   * \sa tvm::support::With
+   */
+  void ExitWithScope() final;
+};
+
+/*!
+ * \brief Managed reference to IfFrameNode.
+ *
+ * \sa IfFrameNode
+ */
+class IfFrame : public TIRFrame {
+ public:
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(IfFrame, TIRFrame, IfFrameNode);
+};
+
+/*!
+ * \brief A frame that represents then.
+ *
+ * \sa ThenFrame
+ */
+class ThenFrameNode : public TIRFrameNode {
+ public:
+  static constexpr const char* _type_key = "script.ir_builder.tir.ThenFrame";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ThenFrameNode, TIRFrameNode);
+
+ public:
+  /*!
+   * \brief The method called when entering RAII scope.
+   * \sa tvm::support::With
+   */
+  void EnterWithScope() final;
+  /*!
+   * \brief The method called when exiting RAII scope.
+   * \sa tvm::support::With
+   */
+  void ExitWithScope() final;
+};
+
+/*!
+ * \brief Managed reference to ThenFrameNode.
+ *
+ * \sa ThenFrameNode
+ */
+class ThenFrame : public TIRFrame {
+ public:
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(ThenFrame, TIRFrame, ThenFrameNode);
+};
+
+/*!
+ * \brief A frame that represents else.
+ *
+ * \sa ElseFrame
+ */
+class ElseFrameNode : public TIRFrameNode {
+ public:
+  static constexpr const char* _type_key = "script.ir_builder.tir.ElseFrame";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ElseFrameNode, TIRFrameNode);
+
+ public:
+  /*!
+   * \brief The method called when entering RAII scope.
+   * \sa tvm::support::With
+   */
+  void EnterWithScope() final;
+  /*!
+   * \brief The method called when exiting RAII scope.
+   * \sa tvm::support::With
+   */
+  void ExitWithScope() final;
+};
+
+/*!
+ * \brief Managed reference to ElseFrameNode.
+ *
+ * \sa ElseFrameNode
+ */
+class ElseFrame : public TIRFrame {
+ public:
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(ElseFrame, TIRFrame, ElseFrameNode);
+};
+
+class DeclBufferFrameNode : public TIRFrameNode {
+ public:
+  /*! \brief The declared buffer. */
+  tvm::tir::Buffer buffer;
+  /*! \brief The buffer allocated or not. */
+  bool allocated;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    TIRFrameNode::VisitAttrs(v);
+    v->Visit("buffer", &buffer);
+    v->Visit("allocated", &allocated);
+  }
+
+  static constexpr const char* _type_key = "script.ir_builder.tir.DeclBufferFrame";
+  TVM_DECLARE_FINAL_OBJECT_INFO(DeclBufferFrameNode, TIRFrameNode);
+
+ public:
+  void ExitWithScope() final;
+};
+
+class DeclBufferFrame : public TIRFrame {
+ public:
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(DeclBufferFrame, TIRFrame, DeclBufferFrameNode);
+};
+
+}  // namespace tir
+}  // namespace ir_builder
+}  // namespace script
+}  // namespace tvm
+
+#endif  // TVM_SCRIPT_IR_BUILDER_TIR_FRAME_H_
diff --git a/darknet_drp_ros/include/tvm/script/ir_builder/tir/ir.h b/darknet_drp_ros/include/tvm/script/ir_builder/tir/ir.h
new file mode 100644
index 0000000..5cba879
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/script/ir_builder/tir/ir.h
@@ -0,0 +1,468 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_SCRIPT_IR_BUILDER_TIR_IR_H_
+#define TVM_SCRIPT_IR_BUILDER_TIR_IR_H_
+
+#include <tvm/script/ir_builder/base.h>
+#include <tvm/script/ir_builder/tir/frame.h>
+#include <tvm/tir/op.h>
+
+namespace tvm {
+namespace script {
+namespace ir_builder {
+namespace tir {
+
+using tvm::runtime::NDArray;
+using tvm::tir::Buffer;
+using tvm::tir::Var;
+
+/*!
+ * \brief The buffer declaration function.
+ * \param shape The type of the buffer prior to flattening.
+ * \param dtype The data type in the content of the buffer.
+ * \param buffer_name The name of the buffer.
+ * \param data The pointer to the head of the data.
+ * \param strides The strides of each dimension.
+ * \param elem_offset The offset in terms of number of dtype elements (including lanes).
+ * \param storage_scope The optional storage scope of buffer data pointer.
+ * \param align The alignment requirement of data pointer in bytes.
+ * \param offset_factor The factor of elem_offset field.
+ * \param buffer_type The buffer type.
+ * \param axis_separators The separators between input axes when generating flattened output axes.
+ * \return The declared buffer.
+ */
+Buffer BufferDecl(Array<PrimExpr> shape, DataType dtype, String buffer_name, Optional<Var> data,
+                  Optional<Array<PrimExpr>> strides, Optional<PrimExpr> elem_offset,
+                  String storage_scope, int align, int offset_factor, String buffer_type,
+                  Optional<Array<IntImm>> axis_separators);
+
+/*!
+ * \brief The primitive function statement.
+ * \return The PrimFuncFrame.
+ */
+PrimFuncFrame PrimFunc();
+
+/*!
+ * \brief The PrimFunc variable arguments adding function.
+ * \param name The name of the variable.
+ * \param var The variable argument.
+ * \return The variable.
+ */
+Var Arg(String name, Var var);
+
+/*!
+ * \brief The PrimFunc buffer arguments adding function.
+ * \param name The name of the buffer.
+ * \param buffer The buffer argument.
+ * \return The buffer.
+ */
+Buffer Arg(String name, Buffer buffer);
+
+/*!
+ * \brief The PrimFunc naming statement.
+ * \param name The name of the PrimFunc.
+ */
+void FuncName(String name);
+
+/*!
+ * \brief The PrimFunc annotation statement.
+ * \param attrs The annotations of the PrimFunc.
+ */
+void FuncAttrs(Map<String, ObjectRef> attrs);
+
+/*!
+ * \brief The PrimFunc return type statement.
+ * \param ret_type The return type of the PrimFunc.
+ * \return The return type.
+ */
+Type FuncRet(Type ret_type);
+
+/*!
+ * \brief The buffer match statement.
+ * \param param The parameter of the PrimFunc to match.
+ * \param shape The type of the buffer prior to flattening.
+ * \param dtype The data type in the content of the buffer.
+ * \param data The pointer to the head of the data.
+ * \param strides The strides of each dimension.
+ * \param elem_offset The offset in terms of number of dtype elements (including lanes).
+ * \param storage_scope The optional storage scope of buffer data pointer.
+ * \param align The alignment requirement of data pointer in bytes.
+ * \param offset_factor The factor of elem_offset field.
+ * \param buffer_type The buffer type.
+ * \param axis_separators The separators between input axes when generating flattened output axes.
+ * \return The matched buffer.
+ */
+Buffer MatchBuffer(ObjectRef param, Array<PrimExpr> shape, DataType dtype = DataType::Float(32),
+                   Optional<Var> data = NullOpt, Array<PrimExpr> strides = {},
+                   PrimExpr elem_offset = PrimExpr(), String storage_scope = "global",
+                   int align = -1, int offset_factor = 0, String buffer_type = "default",
+                   Array<IntImm> axis_separators = {});
+
+/*!
+ * \brief The block declaration statement.
+ * \param name The name of the block.
+ * \param no_realize The flag whether to construct BlockRealize or Block.
+ * \return The BlockFrame.
+ */
+BlockFrame Block(String name, bool no_realize = false);
+
+/*!
+ * \brief The block initialization statement.
+ * \return The BlockInitFrame.
+ */
+BlockInitFrame Init();
+
+/*!
+ * \brief The block predicate statement.
+ * \param predicate The predicate condition.
+ */
+void Where(PrimExpr predicate);
+
+/*!
+ * \brief The block buffer region reading statement.
+ * \param buffer_slices The array of buffer regions to read.
+ */
+void Reads(Array<ObjectRef> buffer_slices);
+
+/*!
+ * \brief The block buffer region writing statement.
+ * \param buffer_slices The array of buffer regions to write.
+ */
+void Writes(Array<ObjectRef> buffer_slices);
+
+/*!
+ * \brief The block annotation statement.
+ * \param attrs The annotation of the block.
+ */
+void BlockAttrs(Map<String, ObjectRef> attrs);
+
+/*!
+ * \brief The buffer allocation function.
+ * \param shape The type of the buffer prior to flattening.
+ * \param dtype The data type in the content of the buffer.
+ * \param data The pointer to the head of the data.
+ * \param strides The strides of each dimension.
+ * \param elem_offset The offset in terms of number of dtype elements (including lanes).
+ * \param storage_scope The optional storage scope of buffer data pointer.
+ * \param align The alignment requirement of data pointer in bytes.
+ * \param offset_factor The factor of elem_offset field.
+ * \param buffer_type The buffer type.
+ * \param axis_separators The separators between input axes when generating flattened output axes.
+ * \return The allocated buffer.
+ */
+Buffer AllocBuffer(Array<PrimExpr> shape, DataType dtype = DataType::Float(32),
+                   Optional<Var> data = NullOpt, Array<PrimExpr> strides = {},
+                   PrimExpr elem_offset = PrimExpr(), String storage_scope = "", int align = -1,
+                   int offset_factor = 0, String buffer_type = "default",
+                   Array<IntImm> axis_separators = {});
+namespace axis {
+
+/*!
+ * \brief The spatial block axis defining function.
+ * \param dom The domain of the iteration variable.
+ * \param binding The binding value of the iteration variable.
+ * \param dtype The data type of the iteration variable.
+ * \return The iteration variable.
+ */
+Var Spatial(Range dom, PrimExpr binding, DataType dtype = DataType::Int(32));
+
+/*!
+ * \brief The reduced block axis defining function.
+ * \param dom The domain of the iteration variable.
+ * \param binding The binding value of the iteration variable.
+ * \param dtype The data type of the iteration variable.
+ * \return The iteration variable.
+ */
+Var Reduce(Range dom, PrimExpr binding, DataType dtype = DataType::Int(32));
+
+/*!
+ * \brief The scanning block axis defining function.
+ * \param dom The domain of the iteration variable.
+ * \param binding The binding value of the iteration variable.
+ * \param dtype The data type of the iteration variable.
+ * \return The iteration variable.
+ */
+Var Scan(Range dom, PrimExpr binding, DataType dtype = DataType::Int(32));
+
+/*!
+ * \brief The opaque block axis defining function.
+ * \param dom The domain of the iteration variable.
+ * \param binding The binding value of the iteration variable.
+ * \param dtype The data type of the iteration variable.
+ * \return The iteration variable.
+ */
+Var Opaque(Range dom, PrimExpr binding, DataType dtype = DataType::Int(32));
+
+/*!
+ * \brief The block axis remapping function.
+ * \param kinds The types of the iteration variables.
+ * \param bindings The binding values of the iteration variables.
+ * \param dtype The data types of the iteration variables.
+ * \return The iteration variables.
+ */
+Array<Var> Remap(String kinds, Array<PrimExpr> bindings, DataType dtype = DataType::Int(32));
+
+}  // namespace axis
+
+/*!
+ * \brief The serial For statement.
+ * \param start The minimum value of iteration.
+ * \param stop The maximum value of iteration.
+ * \param annotations The optional annotations of the For statement.
+ * \return The ForFrame.
+ */
+ForFrame Serial(PrimExpr start, PrimExpr stop,
+                Optional<Map<String, ObjectRef>> annotations = NullOpt);
+/*!
+ * \brief The parallel For statement.
+ * \param start The minimum value of iteration.
+ * \param stop The maximum value of iteration.
+ * \param annotations The optional annotations of the For statement.
+ * \return The ForFrame.
+ */
+ForFrame Parallel(PrimExpr start, PrimExpr stop,
+                  Optional<Map<String, ObjectRef>> annotations = NullOpt);
+/*!
+ * \brief The vectorized For statement.
+ * \param start The minimum value of iteration.
+ * \param stop The maximum value of iteration.
+ * \param annotations The optional annotations of the For statement.
+ * \return The ForFrame.
+ */
+ForFrame Vectorized(PrimExpr start, PrimExpr stop,
+                    Optional<Map<String, ObjectRef>> annotations = NullOpt);
+/*!
+ * \brief The unrolled For statement.
+ * \param start The minimum value of iteration.
+ * \param stop The maximum value of iteration.
+ * \param annotations The optional annotations of the For statement.
+ * \return The ForFrame.
+ */
+ForFrame Unroll(PrimExpr start, PrimExpr stop,
+                Optional<Map<String, ObjectRef>> annotations = NullOpt);
+/*!
+ * \brief The thread-binding For statement.
+ * \param start The minimum value of iteration.
+ * \param stop The maximum value of iteration.
+ * \param thread The thread for loop variable to bind.
+ * \param annotations The optional annotations of the For statement.
+ * \return The ForFrame.
+ */
+ForFrame ThreadBinding(PrimExpr start, PrimExpr stop, String thread,
+                       Optional<Map<String, ObjectRef>> annotations = NullOpt);
+/*!
+ * \brief The grid For statement.
+ * \param extents The extents of the iteration.
+ * \return The ForFrame.
+ */
+ForFrame Grid(Array<PrimExpr> extents);
+
+/*!
+ * \brief The assertion statement.
+ * \param condition The assertion condition.
+ * \param message The error message when the assertion fails.
+ * \return The AssertFrame.
+ */
+AssertFrame Assert(PrimExpr condition, String message);
+
+/*!
+ * \brief The let binding.
+ * \param var The variable to bind.
+ * \param value The value to be bound.
+ * \return The created LetFrame.
+ */
+LetFrame Let(Var var, PrimExpr value);
+
+/*!
+ * \brief The realization.
+ * \param buffer_slice The region of buffer access.
+ * \param storage_scope The storage scope associated with this realization.
+ * \param condition The condition expression.
+ * \return The result RealizeFrame.
+ */
+RealizeFrame Realize(tvm::tir::BufferRegion buffer_slice, String storage_scope, PrimExpr condition);
+
+/*!
+ * \brief The allocate node.
+ * \param extents The extents of the allocate.
+ * \param dtype The data type of the buffer.
+ * \param storage_scope The storage scope.
+ * \param condition The condition.
+ * \param annotations Additional annotation hints.
+ * \return The created AllocateFrame.
+ */
+AllocateFrame Allocate(Array<PrimExpr> extents, DataType dtype, String storage_scope = "",
+                       Optional<PrimExpr> condition = NullOpt,
+                       Optional<Map<String, ObjectRef>> annotations = NullOpt);
+
+/*!
+ * \brief The allocate constant node.
+ * \param data The data associated with the constant.
+ * \param dtype The data type of the buffer.
+ * \param extents The extents of the allocate.
+ * \param annotations Additional annotation hints.
+ * \return The created AllocateConstFrame.
+ */
+AllocateConstFrame AllocateConst(NDArray data, DataType dtype, Array<PrimExpr> extents,
+                                 Optional<Map<String, ObjectRef>> annotations = NullOpt);
+
+/*!
+ * \brief Create an attribute.
+ * \param node The node to annotate the attribute.
+ * \param attr_key Attribute type key.
+ * \param value The value of the attribute.
+ * \return The result AttrFrame.
+ */
+AttrFrame Attr(ObjectRef node, String attr_key, PrimExpr value);
+
+/*!
+ * \brief Create a while loop.
+ * \param condition The termination condition of the loop.
+ * \return The result WhileFrame.
+ */
+WhileFrame While(PrimExpr condition);
+
+/*!
+ * \brief Create an if statement.
+ * \param condition The condition of if statement.
+ * \return The result IfFrame.
+ */
+IfFrame If(PrimExpr condition);
+
+/*!
+ * \brief Create a then.
+ * \return The result ThenFrame.
+ */
+ThenFrame Then();
+
+/*!
+ * \brief Create an else.
+ * \return The result ElseFrame.
+ */
+ElseFrame Else();
+
+/*!
+ * \brief The buffer declaration frame.
+ * \param shape The type of the buffer prior to flattening.
+ * \param dtype The data type in the content of the buffer.
+ * \param buffer_name The name of the buffer.
+ * \param data The pointer to the head of the data.
+ * \param strides The strides of each dimension.
+ * \param elem_offset The offset in terms of number of dtype elements (including lanes).
+ * \param storage_scope The optional storage scope of buffer data pointer.
+ * \param align The alignment requirement of data pointer in bytes.
+ * \param offset_factor The factor of elem_offset field.
+ * \param buffer_type The buffer type.
+ * \param axis_separators The separators between input axes when generating flattened output axes.
+ * \return The declared buffer.
+ */
+DeclBufferFrame DeclBuffer(Array<PrimExpr> shape, DataType dtype, String buffer_name,
+                           Optional<Var> data, Optional<Array<PrimExpr>> strides,
+                           Optional<PrimExpr> elem_offset, String storage_scope, int align,
+                           int offset_factor, String buffer_type,
+                           Optional<Array<IntImm>> axis_separators);
+
+/*!
+ * \brief Launch a thread.
+ * \param var The iteration variable.
+ * \param extent The extent of environment thread.
+ * \return The result LaunchThreadFrame.
+ */
+LaunchThreadFrame LaunchThread(Var var, PrimExpr extent);
+
+/*!
+ * \brief Bind a var to thread env.
+ * \param thread_tag The thread type tag.
+ * \return The result variable which gets bound to the thread env.
+ */
+Var EnvThread(String thread_tag);
+
+/*!
+ * \brief Store data in a buffer.
+ * \param buffer The buffer.
+ * \param value The value to be stored.
+ * \param indices The indices location to be stored.
+ */
+void BufferStore(Buffer buffer, PrimExpr value, Array<PrimExpr> indices);
+
+/*!
+ * \brief The prefetch hint for a buffer
+ * \param buffer The buffer to be prefetched.
+ * \param bounds The bounds to be prefetched.
+ */
+void Prefetch(Buffer buffer, Array<Range> bounds);
+
+/*!
+ * \brief Evaluate the input expression.
+ * \param value The input expression to evaluate.
+ */
+void Evaluate(PrimExpr value);
+
+/*!
+ * \brief The pointer declaration function.
+ * \param dtype The data type of the pointer.
+ * \param storage_scope The storage scope of the pointer.
+ * \return The pointer.
+ */
+PrimExpr Ptr(runtime::DataType dtype, String storage_scope = "global");
+
+#define TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST(FuncName, DType)                             \
+  inline PrimExpr FuncName(Optional<PrimExpr> expr = NullOpt) {                        \
+    DataType dtype = DType;                                                            \
+    return expr.defined() ? tvm::cast(dtype, expr.value()) : tvm::tir::Var("", dtype); \
+  }
+
+#define TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST_SIZES(DType, FDType) \
+  TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST(DType##8, FDType(8));      \
+  TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST(DType##16, FDType(16));    \
+  TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST(DType##32, FDType(32));    \
+  TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST(DType##64, FDType(64));
+
+TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST_SIZES(Float, DataType::Float);
+TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST_SIZES(UInt, DataType::UInt);
+TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST_SIZES(Int, DataType::Int);
+
+#define TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST_LANES(FuncName, FDType, Size) \
+  TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST(FuncName##x4, FDType(Size, 4));     \
+  TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST(FuncName##x8, FDType(Size, 8));     \
+  TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST(FuncName##x16, FDType(Size, 16));   \
+  TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST(FuncName##x32, FDType(Size, 32));   \
+  TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST(FuncName##x64, FDType(Size, 64));
+
+#define TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST_SIZES_LANES(DType, FDType) \
+  TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST_LANES(DType##8, FDType, 8);      \
+  TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST_LANES(DType##16, FDType, 16);    \
+  TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST_LANES(DType##32, FDType, 32);    \
+  TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST_LANES(DType##64, FDType, 64);
+
+TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST_SIZES_LANES(Float, DataType::Float);
+TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST_SIZES_LANES(UInt, DataType::UInt);
+TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST_SIZES_LANES(Int, DataType::Int);
+TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST(Boolean, DataType::Bool());
+TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST(Handle, DataType::Handle());
+TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST(Void, DataType::Void());
+
+#undef TVM_TIR_IR_BUILDER_DEF_DTYPE_CAST
+
+}  // namespace tir
+}  // namespace ir_builder
+}  // namespace script
+}  // namespace tvm
+
+#endif  // TVM_SCRIPT_IR_BUILDER_TIR_IR_H_
diff --git a/darknet_drp_ros/include/tvm/script/printer.h b/darknet_drp_ros/include/tvm/script/printer.h
new file mode 100644
index 0000000..b0fc541
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/script/printer.h
@@ -0,0 +1,56 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_SCRIPT_PRINTER_H_
+#define TVM_SCRIPT_PRINTER_H_
+
+#include <tvm/node/node.h>
+#include <tvm/node/object_path.h>
+
+namespace tvm {
+namespace script {
+namespace printer {
+
+/*!
+ * \brief Print IR graph as TVMScript code
+ *
+ * \param root_node The root node to print.
+ * \param ir_name The dispatch token of the target IR, e.g., "tir", "relax".
+ * \param ir_prefix The symbol name for TVMScript IR namespaces. For example, {"tir": "T"}.
+ * \param indent_spaces Number of spaces used for indentation
+ * \param print_line_numbers Whether to print line numbers
+ * \param num_context_lines Number of context lines to print around the underlined text
+ * \param path_to_underline Object path to be underlined
+ *
+ * \return the TVMScript code as string.
+ */
+String Script(                                        //
+    const ObjectRef& root_node,                       //
+    String ir_name,                                   //
+    Map<String, String> ir_prefix,                    //
+    int indent_spaces = 4,                            //
+    bool print_line_numbers = false,                  //
+    int num_context_lines = -1,                       //
+    Optional<ObjectPath> path_to_underline = NullOpt  //
+);
+
+}  // namespace printer
+}  // namespace script
+}  // namespace tvm
+
+#endif  // TVM_SCRIPT_PRINTER_H_
diff --git a/darknet_drp_ros/include/tvm/script/printer/doc.h b/darknet_drp_ros/include/tvm/script/printer/doc.h
new file mode 100644
index 0000000..1ee7fd6
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/script/printer/doc.h
@@ -0,0 +1,1235 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_SCRIPT_PRINTER_DOC_H_
+#define TVM_SCRIPT_PRINTER_DOC_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/node/node.h>
+#include <tvm/runtime/data_type.h>
+#include <tvm/script/printer/traced_object.h>
+
+namespace tvm {
+namespace script {
+namespace printer {
+
+/*!
+ * \brief The base class of all Doc.
+ *
+ * Doc is an intermediate representation between IR from TVM
+ * and the TVMScript code.
+ * During printing, IR graph is first translated into Doc tree,
+ * then the Doc tree is translated to the target language in
+ * text format.
+ *
+ * \sa Doc
+ */
+class DocNode : public Object {
+ public:
+  /*!
+   * \brief The list of object paths of the source IR node.
+   *
+   * This is used to trace back to the IR node position where
+   * this Doc is generated, in order to position the diagnostic
+   * message.
+   */
+  mutable Array<ObjectPath> source_paths;
+
+  void VisitAttrs(AttrVisitor* v) { v->Visit("source_paths", &source_paths); }
+
+  static constexpr const char* _type_key = "script.printer.Doc";
+  TVM_DECLARE_BASE_OBJECT_INFO(DocNode, Object);
+
+ public:
+  virtual ~DocNode() = default;
+};
+
+/*!
+ * \brief Reference type of DocNode.
+ *
+ * \sa DocNode
+ */
+class Doc : public ObjectRef {
+ protected:
+  Doc() = default;
+
+ public:
+  virtual ~Doc() = default;
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(Doc, ObjectRef, DocNode);
+};
+
+class ExprDoc;
+
+/*!
+ * \brief The base class of expression doc.
+ *
+ * \sa ExprDoc
+ */
+class ExprDocNode : public DocNode {
+ public:
+  /*!
+   * \brief Create a doc representing attribute access on the current ExprDoc
+   * \param attr The attribute to access.
+   */
+  ExprDoc Attr(String attr) const;
+
+  /*!
+   * \brief Create a doc representing attribute access on the current ExprDoc
+   * \param attr The attribute to access.
+   *
+   * The ObjectPath of attr will be pushed to the source_path of the returned
+   * doc.
+   */
+  ExprDoc Attr(TracedObject<String> attr) const;
+
+  /*!
+   * \brief Create a doc representing index access on the current ExprDoc
+   * \param indices The indices to access.
+   */
+  ExprDoc operator[](Array<Doc> indices) const;
+
+  /*!
+   * \brief Create a doc representing calling the current ExprDoc
+   * \param args The positional arguments of the function call.
+   */
+  ExprDoc Call(Array<ExprDoc, void> args) const;
+
+  /*!
+   * \brief Create a doc representing attribute access on the current ExprDoc
+   * \param args The positional arguments of the function call.
+   * \param kwargs_keys Keys of keywords arguments of the function call.
+   * \param kwargs_values Values of keywords arguments of the function call.
+   */
+  ExprDoc Call(Array<ExprDoc, void> args,  //
+               Array<String> kwargs_keys,  //
+               Array<ExprDoc, void> kwargs_values) const;
+
+  void VisitAttrs(AttrVisitor* v) { DocNode::VisitAttrs(v); }
+
+  static constexpr const char* _type_key = "script.printer.ExprDoc";
+  TVM_DECLARE_BASE_OBJECT_INFO(ExprDocNode, DocNode);
+};
+
+/*!
+ * \brief Reference type of ExprDocNode.
+ *
+ * \sa ExprDocNode
+ */
+class ExprDoc : public Doc {
+ protected:
+  ExprDoc() = default;
+
+ public:
+  /*!
+   * \brief Create a doc representing index access on the current ExprDoc
+   * \param indices The indices to access.
+   */
+  ExprDoc operator[](Array<Doc> indices) const;
+
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(ExprDoc, Doc, ExprDocNode);
+};
+
+/*!
+ * \brief The base class of statement doc.
+ *
+ * \sa StmtDoc
+ */
+class StmtDocNode : public DocNode {
+ public:
+  /*!
+   * \brief The comment of this doc.
+   *
+   * The actual position of the comment depends on the type of Doc
+   * and also the DocPrinter implementation. It could be on the same
+   * line as the statement, or the line above, or inside the statement
+   * if it spans over multiple lines.
+   * */
+  mutable Optional<String> comment{NullOpt};
+
+  void VisitAttrs(AttrVisitor* v) {
+    DocNode::VisitAttrs(v);
+    v->Visit("comment", &comment);
+  }
+
+  static constexpr const char* _type_key = "script.printer.StmtDoc";
+  TVM_DECLARE_BASE_OBJECT_INFO(StmtDocNode, DocNode);
+};
+
+/*!
+ * \brief Reference type of StmtDocNode.
+ *
+ * \sa StmtDocNode
+ */
+class StmtDoc : public Doc {
+ protected:
+  StmtDoc() = default;
+
+ public:
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(StmtDoc, Doc, StmtDocNode);
+};
+
+/*!
+ * \brief The container doc that holds a list of StmtDoc.
+ * \note `StmtBlockDoc` is never used in the IR, but a temporary container that allows holding a
+ * list of StmtDoc.
+ * \sa StmtBlockDoc
+ */
+class StmtBlockDocNode : public DocNode {
+ public:
+  /*! \brief The list of statements. */
+  Array<StmtDoc> stmts;
+
+  void VisitAttrs(AttrVisitor* v) {
+    DocNode::VisitAttrs(v);
+    v->Visit("stmts", &stmts);
+  }
+
+  static constexpr const char* _type_key = "script.printer.StmtBlockDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(StmtBlockDocNode, DocNode);
+};
+
+/*!
+ * \brief Reference type of StmtBlockDocNode.
+ * \sa StmtBlockDocNode
+ */
+class StmtBlockDoc : public Doc {
+ public:
+  /*!
+   * \brief Constructor of StmtBlockDoc.
+   * \param stmts The list of statements.
+   */
+  explicit StmtBlockDoc(Array<StmtDoc> stmts);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(StmtBlockDoc, Doc, StmtBlockDocNode);
+};
+
+/*!
+ * \brief Doc that represents literal value.
+ *
+ * \sa LiteralDoc
+ */
+class LiteralDocNode : public ExprDocNode {
+ public:
+  /*!
+   * \brief the internal representation of the literal value.
+   *
+   * Possible actual types:
+   * - IntImm (integer or boolean)
+   * - FloatImm
+   * - String
+   * - null
+   */
+  ObjectRef value;
+
+  void VisitAttrs(AttrVisitor* v) {
+    ExprDocNode::VisitAttrs(v);
+    v->Visit("value", &value);
+  }
+
+  static constexpr const char* _type_key = "script.printer.LiteralDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(LiteralDocNode, ExprDocNode);
+};
+
+/*!
+ * \brief Reference type of LiteralDocNode.
+ *
+ * \sa LiteralDocNode
+ */
+class LiteralDoc : public ExprDoc {
+ protected:
+  explicit LiteralDoc(ObjectRef value);
+  LiteralDoc(ObjectRef value, ObjectPath object_path);
+
+ public:
+  /*!
+   * \brief Create a LiteralDoc to represent None/null/empty value.
+   */
+  static LiteralDoc None() { return LiteralDoc(ObjectRef(nullptr)); }
+
+  /*!
+   * \brief Create a LiteralDoc to represent None/null/empty value.
+   * \param object_path The source path of the returned Doc.
+   */
+  static LiteralDoc None(ObjectPath object_path) {
+    return LiteralDoc(ObjectRef(nullptr), object_path);
+  }
+
+  /*!
+   * \brief Create a LiteralDoc to represent integer.
+   * \param v The integer value.
+   */
+  static LiteralDoc Int(int v) { return LiteralDoc(IntImm(DataType::Int(64), v)); }
+
+  /*!
+   * \brief Create a LiteralDoc to represent integer.
+   * \param v The integer value.
+   *
+   * The ObjectPath of v will be pushed to the source_path of the returned doc.
+   */
+  static LiteralDoc Int(const TracedObject<IntImm>& v) { return LiteralDoc(v.Get(), v.GetPath()); }
+
+  /*!
+   * \brief Create a LiteralDoc to represent integer.
+   * \param v The integer value.
+   *
+   * The ObjectPath of v will be pushed to the source_path of the returned doc.
+   */
+  static LiteralDoc Int(const TracedBasicValue<int>& v) {
+    return LiteralDoc(IntImm(DataType::Int(64), v.Get()), v.GetPath());
+  }
+  /*!
+   * \brief Create a LiteralDoc to represent boolean.
+   * \param v The boolean value.
+   */
+  static LiteralDoc Boolean(bool v) { return LiteralDoc(IntImm(DataType::Bool(), v)); }
+
+  /*!
+   * \brief Create a LiteralDoc to represent boolean.
+   * \param v The boolean value.
+   *
+   * The ObjectPath of v will be pushed to the source_path of the returned doc.
+   */
+  static LiteralDoc Boolean(const TracedBasicValue<bool>& v) {
+    return LiteralDoc(IntImm(DataType::Bool(), v.Get()), v.GetPath());
+  }
+
+  /*!
+   * \brief Create a LiteralDoc to represent float.
+   * \param v The float value.
+   */
+  static LiteralDoc Float(double v) { return LiteralDoc(FloatImm(DataType::Float(64), v)); }
+
+  /*!
+   * \brief Create a LiteralDoc to represent float.
+   * \param v The float value.
+   *
+   * The ObjectPath of v will be pushed to the source_path of the returned doc.
+   */
+  static LiteralDoc Float(const TracedObject<FloatImm>& v) {
+    return LiteralDoc(v.Get(), v.GetPath());
+  }
+
+  /*!
+   * \brief Create a LiteralDoc to represent string.
+   * \param v The string value.
+   */
+  static LiteralDoc Str(const String& v) { return LiteralDoc(v); }
+
+  /*!
+   * \brief Create a LiteralDoc to represent string.
+   * \param v The string value.
+   *
+   * The ObjectPath of v will be pushed to the source_path of the returned doc.
+   */
+  static LiteralDoc Str(const TracedObject<String>& v) { return LiteralDoc(v.Get(), v.GetPath()); }
+
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(LiteralDoc, ExprDoc, LiteralDocNode);
+};
+
+/*!
+ * \brief Doc that represents identifier.
+ *
+ * \sa IdDoc
+ */
+class IdDocNode : public ExprDocNode {
+ public:
+  /*! \brief The name of the identifier */
+  String name;
+
+  void VisitAttrs(AttrVisitor* v) {
+    ExprDocNode::VisitAttrs(v);
+    v->Visit("name", &name);
+  }
+
+  static constexpr const char* _type_key = "script.printer.IdDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IdDocNode, ExprDocNode);
+};
+
+/*!
+ * \brief Reference type of IdDocNode.
+ *
+ * \sa IdDocNode
+ */
+class IdDoc : public ExprDoc {
+ public:
+  /*!
+   * \brief Constructor of IdDoc.
+   * \param name The name of identifier.
+   */
+  explicit IdDoc(String name);
+  explicit IdDoc(std::nullptr_t) : ExprDoc(nullptr) {}
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(IdDoc, ExprDoc, IdDocNode);
+};
+
+/*!
+ * \brief Doc that represents attribute access on another expression.
+ *
+ * \sa AttrAccessDoc
+ */
+class AttrAccessDocNode : public ExprDocNode {
+ public:
+  /*! \brief The target expression to be accessed */
+  ExprDoc value{nullptr};
+  /*! \brief The attribute to be accessed */
+  String name;
+
+  void VisitAttrs(AttrVisitor* v) {
+    ExprDocNode::VisitAttrs(v);
+    v->Visit("value", &value);
+    v->Visit("name", &name);
+  }
+
+  static constexpr const char* _type_key = "script.printer.AttrAccessDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(AttrAccessDocNode, ExprDocNode);
+};
+
+/*!
+ * \brief Reference type of AttrAccessDocNode.
+ *
+ * \sa AttrAccessDocNode
+ */
+class AttrAccessDoc : public ExprDoc {
+ public:
+  /*!
+   * \brief Constructor of AttrAccessDoc
+   * \param value The target expression of attribute access.
+   * \param name The name of attribute to access.
+   */
+  explicit AttrAccessDoc(ExprDoc value, String name);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(AttrAccessDoc, ExprDoc, AttrAccessDocNode);
+};
+
+/*!
+ * \brief Doc that represents index access on another expression.
+ *
+ * \sa IndexDoc
+ */
+class IndexDocNode : public ExprDocNode {
+ public:
+  /*! \brief The container value to be accessed */
+  ExprDoc value{nullptr};
+  /*!
+   * \brief The indices to access
+   *
+   * Possible actual types:
+   * - ExprDoc (single point access like a[1, 2])
+   * - SliceDoc (slice access like a[1:5, 2])
+   */
+  Array<Doc> indices;  // Each element is union of: Slice / ExprDoc
+
+  void VisitAttrs(AttrVisitor* v) {
+    ExprDocNode::VisitAttrs(v);
+    v->Visit("value", &value);
+    v->Visit("indices", &indices);
+  }
+
+  static constexpr const char* _type_key = "script.printer.IndexDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IndexDocNode, ExprDocNode);
+};
+
+/*!
+ * \brief Reference type of IndexDocNode.
+ *
+ * \sa IndexDocNode
+ */
+class IndexDoc : public ExprDoc {
+ public:
+  /*!
+   * \brief Constructor of IndexDoc
+   * \param value The target expression of index access.
+   * \param indices The indices to access.
+   */
+  explicit IndexDoc(ExprDoc value, Array<Doc> indices);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(IndexDoc, ExprDoc, IndexDocNode);
+};
+
+/*!
+ * \brief Doc that represents function call.
+ *
+ * \sa CallDoc
+ */
+class CallDocNode : public ExprDocNode {
+ public:
+  /*! \brief The callee of this function call */
+  ExprDoc callee{nullptr};
+  /*! \brief The positional arguments */
+  Array<ExprDoc> args;
+  /*! \brief The keys of keyword arguments */
+  Array<String> kwargs_keys;
+  /*!
+   * \brief The values of keyword arguments.
+   *
+   * The i-th element is the value of the i-th key in `kwargs_keys`.
+   * It must have the same length as `kwargs_keys`.
+   */
+  Array<ExprDoc> kwargs_values;
+
+  void VisitAttrs(AttrVisitor* v) {
+    ExprDocNode::VisitAttrs(v);
+    v->Visit("callee", &callee);
+    v->Visit("args", &args);
+    v->Visit("kwargs_keys", &kwargs_keys);
+    v->Visit("kwargs_values", &kwargs_values);
+  }
+
+  static constexpr const char* _type_key = "script.printer.CallDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(CallDocNode, ExprDocNode);
+};
+
+/*!
+ * \brief Reference type of CallDocNode.
+ *
+ * \sa CallDocNode
+ */
+class CallDoc : public ExprDoc {
+ public:
+  /*!
+   * \brief Constructor of CallDoc
+   * \param callee The callee of this function call.
+   * \param args The positional arguments.
+   * \param kwargs_keys Keys of keyword arguments.
+   * \param kwargs_values Values of keyword arguments, must have the same length as `kwargs_keys.
+   */
+  CallDoc(ExprDoc callee, Array<ExprDoc> args, Array<String> kwargs_keys,
+          Array<ExprDoc> kwargs_values);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(CallDoc, ExprDoc, CallDocNode);
+};
+
+/*!
+ * \brief Doc that represents operation.
+ *
+ * It can be unary, binary and other special operators (for example,
+ * the if-then-else expression).
+ *
+ * \sa OperationDoc
+ */
+class OperationDocNode : public ExprDocNode {
+ public:
+  enum class Kind : int32_t {
+    // Unary operators
+    kUnaryStart = 0,
+    kUSub = 1,    // -x
+    kInvert = 2,  // ~x
+    kNot = 3,     // not x
+    kUnaryEnd = 4,
+
+    // Binary operators
+    kBinaryStart = 5,
+    kAdd = 6,        // +
+    kSub = 7,        // -
+    kMult = 8,       // *
+    kDiv = 9,        // /
+    kFloorDiv = 10,  // // in Python
+    kMod = 11,       // % in Python
+    kPow = 12,       // ** in Python
+    kLShift = 13,    // <<
+    kRShift = 14,    // >>
+    kBitAnd = 15,    // &
+    kBitOr = 16,     // |
+    kBitXor = 17,    // ^
+    kLt = 18,        // <
+    kLtE = 19,       // <=
+    kEq = 20,        // ==
+    kNotEq = 21,     // !=
+    kGt = 22,        // >
+    kGtE = 23,       // >=
+    kAnd = 24,       // and
+    kOr = 25,        // or
+    kBinaryEnd = 26,
+
+    // Special
+    kSpecialStart = 27,
+    kIfThenElse = 28,  // <operands[1]> if <operands[0]> else <operands[2]>
+    kSpecialEnd = 29
+  };
+
+  /*! \brief The kind of operation (operator) */
+  Kind kind;
+  /*! \brief Operands of this expression */
+  Array<ExprDoc> operands;
+
+  void VisitAttrs(AttrVisitor* v) {
+    ExprDocNode::VisitAttrs(v);
+    v->Visit("kind", &kind);
+    v->Visit("operands", &operands);
+  }
+
+  static constexpr const char* _type_key = "script.printer.OperationDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(OperationDocNode, ExprDocNode);
+};
+
+/*!
+ * \brief Reference type of OperationDocNode.
+ *
+ * \sa OperationDocNode
+ */
+class OperationDoc : public ExprDoc {
+ public:
+  /*!
+   * \brief Constructor of OperationDoc
+   * \param kind The kind of operation.
+   * \param operands Operands of this expression.
+   */
+  explicit OperationDoc(OperationDocNode::Kind kind, Array<ExprDoc> operands);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(OperationDoc, ExprDoc, OperationDocNode);
+};
+
+/*!
+ * \brief Doc that represents anonymous function.
+ *
+ * LambdaDoc can only have positional arguments without type annotation,
+ * and a single expression as body.
+ *
+ * \sa LambdaDoc
+ */
+class LambdaDocNode : public ExprDocNode {
+ public:
+  /*! \brief The arguments of this anonymous function */
+  Array<IdDoc> args;
+  /*! \brief The body of this anonymous function */
+  ExprDoc body{nullptr};
+
+  void VisitAttrs(AttrVisitor* v) {
+    ExprDocNode::VisitAttrs(v);
+    v->Visit("args", &args);
+    v->Visit("body", &body);
+  }
+
+  static constexpr const char* _type_key = "script.printer.LambdaDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(LambdaDocNode, ExprDocNode);
+};
+
+/*!
+ * \brief Reference type of LambdaDocNode.
+ *
+ * \sa LambdaDocNode
+ */
+class LambdaDoc : public ExprDoc {
+ public:
+  /*!
+   * \brief Constructor of LambdaDoc
+   * \param args Arguments of this function.
+   * \param body Body expression of this function.
+   */
+  explicit LambdaDoc(Array<IdDoc> args, ExprDoc body);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(LambdaDoc, ExprDoc, LambdaDocNode);
+};
+
+/*!
+ * \brief Doc that represents tuple literal.
+ *
+ * \sa TupleDoc
+ */
+class TupleDocNode : public ExprDocNode {
+ public:
+  /*! \brief Elements of tuple */
+  Array<ExprDoc> elements;
+
+  void VisitAttrs(AttrVisitor* v) {
+    ExprDocNode::VisitAttrs(v);
+    v->Visit("elements", &elements);
+  }
+
+  static constexpr const char* _type_key = "script.printer.TupleDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TupleDocNode, ExprDocNode);
+};
+
+/*!
+ * \brief Reference type of TupleDocNode.
+ *
+ * \sa TupleDocNode
+ */
+class TupleDoc : public ExprDoc {
+ public:
+  /*!
+   * \brief Create an empty TupleDoc
+   */
+  TupleDoc() : TupleDoc(runtime::make_object<TupleDocNode>()) {}
+  /*!
+   * \brief Constructor of TupleDoc
+   * \param elements Elements of tuple.
+   */
+  explicit TupleDoc(Array<ExprDoc> elements);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(TupleDoc, ExprDoc, TupleDocNode);
+};
+
+/*!
+ * \brief Doc that represents list literal.
+ *
+ * \sa AttrAccessDoc
+ */
+class ListDocNode : public ExprDocNode {
+ public:
+  /*! \brief Elements of list */
+  Array<ExprDoc> elements;
+
+  void VisitAttrs(AttrVisitor* v) {
+    ExprDocNode::VisitAttrs(v);
+    v->Visit("elements", &elements);
+  }
+
+  static constexpr const char* _type_key = "script.printer.ListDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ListDocNode, ExprDocNode);
+};
+
+/*!
+ * \brief Reference type of ListDocNode.
+ *
+ * \sa ListDocNode
+ */
+class ListDoc : public ExprDoc {
+ public:
+  /*!
+   * \brief Create an empty ListDoc
+   */
+  ListDoc() : ListDoc(runtime::make_object<ListDocNode>()) {}
+  /*!
+   * \brief Constructor of ListDoc
+   * \param elements Elements of list.
+   */
+  explicit ListDoc(Array<ExprDoc> elements);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(ListDoc, ExprDoc, ListDocNode);
+};
+
+/*!
+ * \brief Doc that represents dictionary literal.
+ *
+ * \sa AttrAccessDoc
+ */
+class DictDocNode : public ExprDocNode {
+ public:
+  /*! \brief keys of dictionary */
+  Array<ExprDoc> keys;
+  /*!
+   * \brief Values of dictionary
+   *
+   * The i-th element is the value of the i-th element of `keys`.
+   * It must have the same length as `keys`.
+   */
+  Array<ExprDoc> values;
+
+  void VisitAttrs(AttrVisitor* v) {
+    ExprDocNode::VisitAttrs(v);
+    v->Visit("keys", &keys);
+    v->Visit("values", &values);
+  }
+
+  static constexpr const char* _type_key = "script.printer.DictDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(DictDocNode, ExprDocNode);
+};
+
+/*!
+ * \brief Reference type of DictDocNode.
+ *
+ * \sa DictDocNode
+ */
+class DictDoc : public ExprDoc {
+ public:
+  /*!
+   * \brief Create an empty dictionary
+   */
+  DictDoc() : DictDoc(runtime::make_object<DictDocNode>()) {}
+  /*!
+   * \brief Constructor of DictDoc
+   * \param keys Keys of dictionary.
+   * \param values Values of dictionary, must have same length as `keys`.
+   */
+  explicit DictDoc(Array<ExprDoc> keys, Array<ExprDoc> values);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(DictDoc, ExprDoc, DictDocNode);
+};
+
+/*!
+ * \brief Doc that represents slice in Index expression.
+ *
+ * This doc can only appear in IndexDoc::indices.
+ *
+ * \sa AttrAccessDoc
+ */
+class SliceDocNode : public DocNode {
+ public:
+  /*! \brief The start of slice */
+  Optional<ExprDoc> start;
+  /*! \brief The exclusive end of slice */
+  Optional<ExprDoc> stop;
+  /*! \brief The step of slice */
+  Optional<ExprDoc> step;
+
+  void VisitAttrs(AttrVisitor* v) {
+    DocNode::VisitAttrs(v);
+    v->Visit("start", &start);
+    v->Visit("stop", &stop);
+    v->Visit("step", &step);
+  }
+
+  static constexpr const char* _type_key = "script.printer.SliceDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(SliceDocNode, DocNode);
+};
+
+/*!
+ * \brief Reference type of SliceDocNode.
+ *
+ * \sa SliceDocNode
+ */
+class SliceDoc : public Doc {
+ public:
+  /*!
+   * \brief Constructor of SliceDoc
+   * \param start The start of slice.
+   * \param stop The exclusive end of slice.
+   * \param step The step of slice.
+   */
+  explicit SliceDoc(Optional<ExprDoc> start, Optional<ExprDoc> stop, Optional<ExprDoc> step);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(SliceDoc, Doc, SliceDocNode);
+};
+
+/*!
+ * \brief Doc that represents assign statement.
+ *
+ * \sa AssignDoc
+ */
+class AssignDocNode : public StmtDocNode {
+ public:
+  /*! \brief The left hand side of the assignment */
+  ExprDoc lhs{nullptr};
+  /*!
+   * \brief The right hand side of the assignment.
+   *
+   * If null, this doc represents declaration, e.g. `A: T.Buffer[(1,2)]`
+   * */
+  Optional<ExprDoc> rhs;
+  /*! \brief The type annotation of this assignment. */
+  Optional<ExprDoc> annotation;
+
+  void VisitAttrs(AttrVisitor* v) {
+    StmtDocNode::VisitAttrs(v);
+    v->Visit("lhs", &lhs);
+    v->Visit("rhs", &rhs);
+    v->Visit("annotation", &annotation);
+  }
+
+  static constexpr const char* _type_key = "script.printer.AssignDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(AssignDocNode, StmtDocNode);
+};
+
+/*!
+ * \brief Reference type of AssignDocNode.
+ *
+ * \sa AssignDoc
+ */
+class AssignDoc : public StmtDoc {
+ public:
+  /*!
+   * \brief Constructor of AssignDoc.
+   * \param lhs The left hand side of the assignment.
+   * \param rhs The right hand side of the assignment.
+   * \param annotation The type annotation of this assignment.
+   */
+  explicit AssignDoc(ExprDoc lhs, Optional<ExprDoc> rhs, Optional<ExprDoc> annotation);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(AssignDoc, StmtDoc, AssignDocNode);
+};
+
+/*!
+ * \brief Doc that represent if-then-else statement.
+ *
+ * \sa IfDoc
+ */
+class IfDocNode : public StmtDocNode {
+ public:
+  /*! \brief The predicate of the if-then-else statement. */
+  ExprDoc predicate{nullptr};
+  /*! \brief The then branch of the if-then-else statement. */
+  Array<StmtDoc> then_branch;
+  /*! \brief The else branch of the if-then-else statement. */
+  Array<StmtDoc> else_branch;
+
+  void VisitAttrs(AttrVisitor* v) {
+    StmtDocNode::VisitAttrs(v);
+    v->Visit("predicate", &predicate);
+    v->Visit("then_branch", &then_branch);
+    v->Visit("else_branch", &else_branch);
+  }
+
+  static constexpr const char* _type_key = "script.printer.IfDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IfDocNode, StmtDocNode);
+};
+
+/*!
+ * \brief Reference type of IfDocNode.
+ *
+ * \sa IfDocNode
+ */
+class IfDoc : public StmtDoc {
+ public:
+  /*!
+   * \brief Constructor of IfDoc.
+   * \param predicate The predicate of the if-then-else statement.
+   * \param then_branch The then branch of the if-then-else statement.
+   * \param else_branch The else branch of the if-then-else statement.
+   */
+  explicit IfDoc(ExprDoc predicate, Array<StmtDoc> then_branch, Array<StmtDoc> else_branch);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(IfDoc, StmtDoc, IfDocNode);
+};
+
+/*!
+ * \brief Doc that represents while statement.
+ *
+ * \sa WhileDoc
+ */
+class WhileDocNode : public StmtDocNode {
+ public:
+  /*! \brief The predicate of the while statement. */
+  ExprDoc predicate{nullptr};
+  /*! \brief The body of the while statement. */
+  Array<StmtDoc> body;
+
+  void VisitAttrs(AttrVisitor* v) {
+    StmtDocNode::VisitAttrs(v);
+    v->Visit("predicate", &predicate);
+    v->Visit("body", &body);
+  }
+
+  static constexpr const char* _type_key = "script.printer.WhileDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(WhileDocNode, StmtDocNode);
+};
+
+/*!
+ * \brief Reference type of WhileDocNode.
+ *
+ * \sa WhileDocNode
+ */
+class WhileDoc : public StmtDoc {
+ public:
+  /*!
+   * \brief Constructor of WhileDoc.
+   * \param predicate The predicate of the while statement.
+   * \param body The body of the while statement.
+   */
+  explicit WhileDoc(ExprDoc predicate, Array<StmtDoc> body);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(WhileDoc, StmtDoc, WhileDocNode);
+};
+
+/*!
+ * \brief Doc that represents for statement.
+ *
+ * Example:
+ * for 'lhs' in 'rhs':
+ *   'body...'
+ *
+ * \sa ForDoc
+ */
+class ForDocNode : public StmtDocNode {
+ public:
+  /*! \brief The left hand side of the assignment of iterating variable. */
+  ExprDoc lhs{nullptr};
+  /*! \brief The right hand side of the assignment of iterating variable. */
+  ExprDoc rhs{nullptr};
+  /*! \brief The body of the for statement. */
+  Array<StmtDoc> body;
+
+  void VisitAttrs(AttrVisitor* v) {
+    StmtDocNode::VisitAttrs(v);
+    v->Visit("lhs", &lhs);
+    v->Visit("rhs", &rhs);
+    v->Visit("body", &body);
+  }
+
+  static constexpr const char* _type_key = "script.printer.ForDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ForDocNode, StmtDocNode);
+};
+
+/*!
+ * \brief Reference type of ForDocNode.
+ *
+ * \sa ForDocNode
+ */
+class ForDoc : public StmtDoc {
+ public:
+  /*!
+   * \brief Constructor of ForDoc.
+   * \param lhs The left hand side of the assignment of iterating variable.
+   * \param rhs The right hand side of the assignment of iterating variable.
+   * \param body The body of the for statement.
+   */
+  explicit ForDoc(ExprDoc lhs, ExprDoc rhs, Array<StmtDoc> body);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(ForDoc, StmtDoc, ForDocNode);
+};
+
+/*!
+ * \brief Doc that represents special scopes.
+ *
+ * Specifically, this means the with statement in Python:
+ *
+ * with 'rhs' as 'lhs':
+ *   'body...'
+ *
+ * \sa ScopeDoc
+ */
+class ScopeDocNode : public StmtDocNode {
+ public:
+  /*! \brief The name of the scoped variable. */
+  Optional<ExprDoc> lhs{NullOpt};
+  /*! \brief The value of the scoped variable. */
+  ExprDoc rhs{nullptr};
+  /*! \brief The body of the scope doc. */
+  Array<StmtDoc> body;
+
+  void VisitAttrs(AttrVisitor* v) {
+    StmtDocNode::VisitAttrs(v);
+    v->Visit("lhs", &lhs);
+    v->Visit("rhs", &rhs);
+    v->Visit("body", &body);
+  }
+
+  static constexpr const char* _type_key = "script.printer.ScopeDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ScopeDocNode, StmtDocNode);
+};
+
+/*!
+ * \brief Reference type of ScopeDocNode.
+ *
+ * \sa ScopeDocNode
+ */
+class ScopeDoc : public StmtDoc {
+ public:
+  /*!
+   * \brief Constructor of ScopeDoc.
+   * \param lhs The name of the scoped variable.
+   * \param rhs The value of the scoped variable.
+   * \param body The body of the scope doc.
+   */
+  explicit ScopeDoc(Optional<ExprDoc> lhs, ExprDoc rhs, Array<StmtDoc> body);
+
+  /*!
+   * \brief Constructor of ScopeDoc.
+   * \param rhs The value of the scoped variable.
+   * \param body The body of the scope doc.
+   */
+  explicit ScopeDoc(ExprDoc rhs, Array<StmtDoc> body);
+
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(ScopeDoc, StmtDoc, ScopeDocNode);
+};
+
+/*!
+ * \brief Doc that represents an expression as statement.
+ *
+ * \sa ExprStmtDoc
+ */
+class ExprStmtDocNode : public StmtDocNode {
+ public:
+  /*! \brief The expression represented by this doc. */
+  ExprDoc expr{nullptr};
+
+  void VisitAttrs(AttrVisitor* v) {
+    StmtDocNode::VisitAttrs(v);
+    v->Visit("expr", &expr);
+  }
+
+  static constexpr const char* _type_key = "script.printer.ExprStmtDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ExprStmtDocNode, StmtDocNode);
+};
+
+/*!
+ * \brief Reference type of ExprStmtDocNode.
+ *
+ * \sa ExprStmtDocNode
+ */
+class ExprStmtDoc : public StmtDoc {
+ public:
+  /*!
+   * \brief Constructor of ExprStmtDoc.
+   * \param expr The expression represented by this doc.
+   */
+  explicit ExprStmtDoc(ExprDoc expr);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(ExprStmtDoc, StmtDoc, ExprStmtDocNode);
+};
+
+/*!
+ * \brief Doc that represents assert statement.
+ *
+ * \sa AssertDoc
+ */
+class AssertDocNode : public StmtDocNode {
+ public:
+  /*! \brief The expression to test. */
+  ExprDoc test{nullptr};
+  /*! \brief The optional error message when assertion failed. */
+  Optional<ExprDoc> msg{NullOpt};
+
+  void VisitAttrs(AttrVisitor* v) {
+    StmtDocNode::VisitAttrs(v);
+    v->Visit("test", &test);
+    v->Visit("msg", &msg);
+  }
+
+  static constexpr const char* _type_key = "script.printer.AssertDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(AssertDocNode, StmtDocNode);
+};
+
+/*!
+ * \brief Reference type of AssertDocNode.
+ *
+ * \sa AssertDocNode
+ */
+class AssertDoc : public StmtDoc {
+ public:
+  /*!
+   * \brief Constructor of AssertDoc.
+   * \param test The expression to test.
+   * \param msg The optional error message when assertion failed.
+   */
+  explicit AssertDoc(ExprDoc test, Optional<ExprDoc> msg = NullOpt);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(AssertDoc, StmtDoc, AssertDocNode);
+};
+
+/*!
+ * \brief Doc that represents return statement.
+ *
+ * \sa ReturnDoc
+ */
+class ReturnDocNode : public StmtDocNode {
+ public:
+  /*! \brief The value to return. */
+  ExprDoc value{nullptr};
+
+  void VisitAttrs(AttrVisitor* v) {
+    StmtDocNode::VisitAttrs(v);
+    v->Visit("value", &value);
+  }
+
+  static constexpr const char* _type_key = "script.printer.ReturnDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ReturnDocNode, StmtDocNode);
+};
+
+/*!
+ * \brief Reference type of ReturnDocNode.
+ *
+ * \sa ReturnDocNode
+ */
+class ReturnDoc : public StmtDoc {
+ public:
+  /*!
+   * \brief Constructor of ReturnDoc.
+   * \param value The value to return.
+   */
+  explicit ReturnDoc(ExprDoc value);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(ReturnDoc, StmtDoc, ReturnDocNode);
+};
+
+/*!
+ * \brief Doc that represents function definition.
+ *
+ * \sa FunctionDoc
+ */
+class FunctionDocNode : public StmtDocNode {
+ public:
+  /*! \brief The name of function. */
+  IdDoc name{nullptr};
+  /*!
+   * \brief The arguments of function.
+   *
+   * The `lhs` means argument name,
+   * `annotation` means argument type,
+   * and `rhs` means default value.
+   */
+  Array<AssignDoc> args;
+  /*! \brief Decorators of function. */
+  Array<ExprDoc> decorators;
+  /*! \brief The return type of function. */
+  Optional<ExprDoc> return_type{NullOpt};
+  /*! \brief The body of function. */
+  Array<StmtDoc> body;
+
+  void VisitAttrs(AttrVisitor* v) {
+    StmtDocNode::VisitAttrs(v);
+    v->Visit("name", &name);
+    v->Visit("args", &args);
+    v->Visit("decorators", &decorators);
+    v->Visit("return_type", &return_type);
+    v->Visit("body", &body);
+  }
+
+  static constexpr const char* _type_key = "script.printer.FunctionDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(FunctionDocNode, StmtDocNode);
+};
+
+/*!
+ * \brief Reference type of FunctionDocNode.
+ *
+ * \sa FunctionDocNode
+ */
+class FunctionDoc : public StmtDoc {
+ public:
+  /*!
+   * \brief Constructor of FunctionDoc.
+   * \param name The name of function..
+   * \param args The arguments of function.
+   * \param decorators The decorator of function.
+   * \param return_type The return type of function.
+   * \param body The body of function.
+   */
+  explicit FunctionDoc(IdDoc name, Array<AssignDoc> args, Array<ExprDoc> decorators,
+                       Optional<ExprDoc> return_type, Array<StmtDoc> body);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(FunctionDoc, StmtDoc, FunctionDocNode);
+};
+
+/*!
+ * \brief Doc that represents class definition.
+ *
+ * \sa ClassDoc
+ */
+class ClassDocNode : public StmtDocNode {
+ public:
+  /*! \brief The name of class. */
+  IdDoc name{nullptr};
+  /*! \brief Decorators of class. */
+  Array<ExprDoc> decorators;
+  /*! \brief The body of class. */
+  Array<StmtDoc> body;
+
+  void VisitAttrs(AttrVisitor* v) {
+    StmtDocNode::VisitAttrs(v);
+    v->Visit("name", &name);
+    v->Visit("decorators", &decorators);
+    v->Visit("body", &body);
+  }
+
+  static constexpr const char* _type_key = "script.printer.ClassDoc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ClassDocNode, StmtDocNode);
+};
+
+/*!
+ * \brief Reference type of ClassDocNode.
+ *
+ * \sa ClassDocNode
+ */
+class ClassDoc : public StmtDoc {
+ public:
+  /*!
+   * \brief Constructor of ClassDoc.
+   * \param name The name of class.
+   * \param decorators The decorator of class.
+   * \param body The body of class.
+   */
+  explicit ClassDoc(IdDoc name, Array<ExprDoc> decorators, Array<StmtDoc> body);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(ClassDoc, StmtDoc, ClassDocNode);
+};
+
+}  // namespace printer
+}  // namespace script
+}  // namespace tvm
+
+#endif  // TVM_SCRIPT_PRINTER_DOC_H_
diff --git a/darknet_drp_ros/include/tvm/script/printer/doc_printer.h b/darknet_drp_ros/include/tvm/script/printer/doc_printer.h
new file mode 100644
index 0000000..04a67a9
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/script/printer/doc_printer.h
@@ -0,0 +1,48 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_SCRIPT_PRINTER_DOC_PRINTER_H_
+#define TVM_SCRIPT_PRINTER_DOC_PRINTER_H_
+
+#include <tvm/script/printer/doc.h>
+
+namespace tvm {
+namespace script {
+namespace printer {
+
+/*!
+ * \brief Convert Doc into Python script.
+ *
+ * This function unpacks the DocPrinterOptions into function arguments
+ * to be FFI friendly.
+ *
+ * \param doc Doc to be converted
+ * \param indent_spaces Number of spaces used for indentation
+ * \param print_line_numbers Whether to print line numbers
+ * \param num_context_lines Number of context lines to print around the underlined text
+ * \param path_to_underline Object path to be underlined
+ */
+String DocToPythonScript(Doc doc, int indent_spaces = 4, bool print_line_numbers = false,
+                         int num_context_lines = -1,
+                         Optional<ObjectPath> path_to_underline = NullOpt);
+
+}  // namespace printer
+}  // namespace script
+}  // namespace tvm
+
+#endif  // TVM_SCRIPT_PRINTER_DOC_PRINTER_H_
diff --git a/darknet_drp_ros/include/tvm/script/printer/frame.h b/darknet_drp_ros/include/tvm/script/printer/frame.h
new file mode 100644
index 0000000..407ad16
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/script/printer/frame.h
@@ -0,0 +1,140 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_SCRIPT_PRINTER_FRAME_H_
+#define TVM_SCRIPT_PRINTER_FRAME_H_
+
+#include <tvm/node/node.h>
+#include <tvm/script/printer/doc.h>
+
+#include <utility>
+#include <vector>
+
+namespace tvm {
+namespace script {
+namespace printer {
+
+/*!
+ * Frame is the core data structure for semantic information
+ * when printing IR graph into TVMScript code.
+ */
+class FrameNode : public Object {
+ public:
+  void VisitAttrs(tvm::AttrVisitor* v) {}
+
+  virtual ~FrameNode() = default;
+
+  /*!
+   * \brief Add a callback function to be called when this frame exits.
+   * \param cb The callback function. It should have signature void().
+   */
+  template <typename TCallback>
+  void AddExitCallback(TCallback&& cb) {
+    callbacks_.emplace_back(std::forward<TCallback>(cb));
+  }
+
+  /*!
+   * \brief Method that's called when Frame enters the scope.
+   */
+  virtual void EnterWithScope() {}
+
+  /*!
+   * \brief Method that's called when Frame exits the scope.
+   */
+  virtual void ExitWithScope() {
+    for (const std::function<void()>& callback : callbacks_) {
+      callback();
+    }
+    callbacks_.clear();
+  }
+
+  static constexpr const char* _type_key = "script.printer.Frame";
+  TVM_DECLARE_BASE_OBJECT_INFO(FrameNode, Object);
+
+ private:
+  std::vector<std::function<void()>> callbacks_;
+};
+
+/*!
+ * \brief Reference type of FrameNode
+ */
+class Frame : public ObjectRef {
+ protected:
+  Frame() = default;
+
+ public:
+  virtual ~Frame() = default;
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(Frame, ObjectRef, FrameNode);
+};
+
+/*!
+ * \brief MetadataFrame contains information like contant parameter array.
+ */
+class MetadataFrameNode : public FrameNode {
+ public:
+  Array<ObjectRef> metadata;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    FrameNode::VisitAttrs(v);
+    v->Visit("metadata", &metadata);
+  }
+
+  static constexpr const char* _type_key = "script.printer.MetadataFrame";
+  TVM_DECLARE_FINAL_OBJECT_INFO(MetadataFrameNode, FrameNode);
+};
+
+/*!
+ * \brief Reference type of MetadataFrameNode
+ */
+class MetadataFrame : public Frame {
+ public:
+  MetadataFrame();
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(MetadataFrame, Frame, MetadataFrameNode);
+};
+
+/*!
+ * \brief VarDefFrame contains information about the free variables that needs to be defined
+ * at the beginning of the printed snippet.
+ */
+class VarDefFrameNode : public FrameNode {
+ public:
+  Array<StmtDoc> stmts;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    FrameNode::VisitAttrs(v);
+    v->Visit("stmts", &stmts);
+  }
+
+  static constexpr const char* _type_key = "script.printer.VarDefFrame";
+  TVM_DECLARE_FINAL_OBJECT_INFO(VarDefFrameNode, FrameNode);
+};
+
+/*!
+ * \brief Reference type of VarDefFrameNode
+ */
+class VarDefFrame : public Frame {
+ public:
+  VarDefFrame();
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(VarDefFrame, Frame, VarDefFrameNode);
+};
+
+}  // namespace printer
+}  // namespace script
+}  // namespace tvm
+
+#endif  // TVM_SCRIPT_PRINTER_FRAME_H_
diff --git a/darknet_drp_ros/include/tvm/script/printer/ir_docsifier.h b/darknet_drp_ros/include/tvm/script/printer/ir_docsifier.h
new file mode 100644
index 0000000..8945bd6
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/script/printer/ir_docsifier.h
@@ -0,0 +1,230 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_SCRIPT_PRINTER_IR_DOCSIFIER_H_
+#define TVM_SCRIPT_PRINTER_IR_DOCSIFIER_H_
+
+#include <tvm/node/node.h>
+#include <tvm/runtime/logging.h>
+#include <tvm/script/printer/doc.h>
+#include <tvm/script/printer/frame.h>
+#include <tvm/script/printer/traced_object.h>
+#include <tvm/script/printer/traced_object_functor.h>
+#include <tvm/script/printer/var_table.h>
+#include <tvm/support/with.h>
+
+namespace tvm {
+namespace script {
+namespace printer {
+
+using WithCtx = With<ContextManager>;
+
+/*!
+ * \brief IRDocsifier is the top-level interface in the IR->Doc process.
+ *
+ * It provides methods to convert IR node object to Doc, operate on Frame
+ * objects and change dispatch tokens.
+ *
+ * Example usage:
+ * \code
+ * TVM_STATIC_IR_FUNCTOR(IRDocsifier, vtable)
+ *    .set_dispatch([](TracedObject<tir::Var> obj, IRDocsifier p) { return IdDoc("x"); });
+ *
+ * TracedObject<tir::Var> var = ...;
+ * IRDocsifier p;
+ * p->AsDoc(var); // returns an IdDoc("x")
+ * \endcode
+ *
+ */
+class IRDocsifierNode : public Object {
+ public:
+  /*!
+   * \brief The var table to use during the printing process.
+   * \sa VarTableNode
+   */
+  VarTable vars;
+  /*!
+   * \brief The stack of frames.
+   * \sa FrameNode
+   */
+  Array<Frame> frames;
+  /*!
+   * \brief The stack of dispatch tokens.
+   *
+   * The dispatch token on the top decides which dispatch function to use
+   * when converting IR node object to Doc.
+   */
+  Array<String> dispatch_tokens;
+  /*!
+   * \brief This map connects IR dipatch token to the name of identifier.
+   */
+  Map<String, String> ir_prefix;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("vars", &vars);
+    v->Visit("frames", &frames);
+    v->Visit("dispatch_tokens", &dispatch_tokens);
+    v->Visit("ir_prefix", &ir_prefix);
+  }
+
+  static constexpr const char* _type_key = "script.printer.IRDocsifier";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IRDocsifierNode, Object);
+
+ public:
+  /*!
+   * \brief Transform the input object into TDoc.
+   * \param obj The object to be transformed.
+   *
+   * \return The Doc object.
+   */
+  template <class TDoc>
+  TDoc AsDoc(const TracedObject<ObjectRef>& obj) const {
+    auto result = Downcast<TDoc>(AsDocImpl(obj));
+    result->source_paths.push_back(obj.GetPath());
+    return result;
+  }
+
+  /*!
+   * \brief Helper method to transform object into ExprDoc.
+   * \param obj The object to be transformed.
+   *
+   * \return The ExprDoc object.
+   */
+  ExprDoc AsExprDoc(const TracedObject<ObjectRef>& obj) { return AsDoc<ExprDoc>(obj); }
+
+  /*!
+   * \brief Push a new dispatch token into the stack
+   * \details The top dispatch token decides which dispatch table to use
+   *          when printing Object. This method returns a RAII guard which
+   *          pops the token when going out of the scope.
+   *
+   * \param token The dispatch token to push.
+   *
+   * \return A RAII guard to pop dispatch token when going out of scope.
+   */
+  WithCtx WithDispatchToken(const String& token) {
+    this->dispatch_tokens.push_back(token);
+    return WithCtx(nullptr, [this]() { this->dispatch_tokens.pop_back(); });
+  }
+
+  /*!
+   * \brief Push a new frame the stack
+   * \details Frame contains the contextual information that's needed during printing,
+   *          for example, variables in the scope. This method returns a RAII guard which
+   *          pops the frame and call the cleanup method of frame when going out of the scope.
+   *
+   * \param frame The frame to push.
+   *
+   * \return A RAII guard to pop frame and call the exit method of frame
+   *          when going out of scope
+   */
+  WithCtx WithFrame(const Frame& frame) {
+    frame->EnterWithScope();
+    this->frames.push_back(frame);
+    return WithCtx(nullptr, [this, pushed_frame = frame]() {
+      Frame last_frame = this->frames.back();
+      ICHECK_EQ(last_frame, pushed_frame);
+      this->frames.pop_back();
+      last_frame->ExitWithScope();
+    });
+  }
+
+  /*!
+   * \brief Get the top frame with type FrameType
+   * \tparam FrameType The type of frame to get.
+   */
+  template <typename FrameType>
+  Optional<FrameType> GetFrame() const {
+    for (auto it = frames.rbegin(); it != frames.rend(); ++it) {
+      if (const auto* f = (*it).as<typename FrameType::ContainerType>()) {
+        return GetRef<FrameType>(f);
+      }
+    }
+    return NullOpt;
+  }
+
+ private:
+  Doc AsDocImpl(const TracedObject<ObjectRef>& obj) const;
+};
+
+/*!
+ * \brief Reference type of IRDocsifierNode.
+ */
+class IRDocsifier : public ObjectRef {
+ public:
+  /*!
+   * \brief Create a IRDocsifier.
+   * \param ir_prefix The ir_prefix to use for this IRDocsifier.
+   */
+  explicit IRDocsifier(Map<String, String> ir_prefix);
+
+  using FType = TracedObjectFunctor<printer::Doc, IRDocsifier>;
+  /*!
+   * \brief The registration table for IRDocsifier.
+   */
+  TVM_DLL static FType& vtable();
+
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(IRDocsifier, ObjectRef, IRDocsifierNode);
+};
+
+/*!
+ * \brief A wrapper object to provide injection point for printer of each IR.
+ *
+ * For any IR node to be transformed by IRDocsifier, it will be wrapped by RootNodeContainer
+ * and be dispatched to the corresponding function first. This provides an injection point for
+ * each IR's printer implemention to add specialized logic, for example, pushing a special
+ * Frame to the IRDocsifier before doing any IR->Doc transformation.
+ *
+ * \code
+ * TVM_STATIC_IR_FUNCTOR(IRDocsifier, vtable)
+ *     .set_dispatch("relax", [](TracedObject<RootNodeContainer> obj, IRDocsifier p) {
+ *       const ObjectRef& root_node = obj.Get()->root_node;
+ *       // For example, relax printer can create a Frame specialized to Relax here
+ *       RelaxGeneralFrame frame;
+ *       auto ctx = p->WithFrame(frame);
+ *       // More specialized logic for your IR.
+ *       return p->AsDoc<Doc>(MakeTraced(root_node));
+ *     });
+ * \endcode
+ */
+class RootNodeContainerNode : public Object {
+ public:
+  /*! \brief The root node to print. */
+  ObjectRef root_node;
+
+  void VisitAttrs(tvm::AttrVisitor* v) { v->Visit("root_node", &root_node); }
+
+  static constexpr const char* _type_key = "script.printer.RootNodeContainer";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RootNodeContainerNode, Object);
+};
+
+class RootNodeContainer : public ObjectRef {
+ public:
+  /*!
+   * \brief Constructor of RootNodeContainer.
+   * \param root_node The root node to print.
+   * */
+  explicit RootNodeContainer(ObjectRef root_node);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(RootNodeContainer, ObjectRef, RootNodeContainerNode);
+};
+
+}  // namespace printer
+}  // namespace script
+}  // namespace tvm
+
+#endif  // TVM_SCRIPT_PRINTER_IR_DOCSIFIER_H_
diff --git a/darknet_drp_ros/include/tvm/script/printer/traced_object.h b/darknet_drp_ros/include/tvm/script/printer/traced_object.h
new file mode 100644
index 0000000..cb63c31
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/script/printer/traced_object.h
@@ -0,0 +1,484 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/script/printer/traced_object.h
+ * Wrappers around TVM objects that also store an ObjectPath from some "root" object
+ * to the wrapper object.
+ */
+
+#ifndef TVM_SCRIPT_PRINTER_TRACED_OBJECT_H_
+#define TVM_SCRIPT_PRINTER_TRACED_OBJECT_H_
+
+#include <tvm/node/object_path.h>
+#include <tvm/node/reflection.h>
+#include <tvm/runtime/object.h>
+
+#include <string>
+#include <utility>
+
+namespace tvm {
+
+template <typename RefT>
+class TracedObject;
+template <typename K, typename V>
+class TracedMap;
+template <typename T>
+class TracedArray;
+template <typename T>
+class TracedOptional;
+template <typename T>
+class TracedBasicValue;
+
+namespace detail {
+
+template <typename T, bool IsObject = std::is_base_of<ObjectRef, T>::value>
+struct TracedObjectWrapperSelector;
+
+template <typename T>
+struct TracedObjectWrapperSelector<T, false> {
+  using Type = TracedBasicValue<T>;
+};
+
+template <typename T>
+struct TracedObjectWrapperSelector<T, true> {
+  using Type = TracedObject<T>;
+};
+
+template <typename K, typename V>
+struct TracedObjectWrapperSelector<Map<K, V>, true> {
+  using Type = TracedMap<K, V>;
+};
+
+template <typename T>
+struct TracedObjectWrapperSelector<Array<T>, true> {
+  using Type = TracedArray<T>;
+};
+
+template <typename T>
+struct TracedObjectWrapperSelector<Optional<T>, true> {
+  using Type = TracedOptional<T>;
+};
+
+}  // namespace detail
+
+/*!
+ * \brief Traced wrapper for regular (non-container) TVM objects.
+ */
+template <typename RefT>
+class TracedObject {
+  using ObjectType = typename RefT::ContainerType;
+
+ public:
+  using ObjectRefType = RefT;
+
+  // Don't use this direcly. For convenience, call MakeTraced() instead.
+  explicit TracedObject(const RefT& object_ref, ObjectPath path)
+      : ref_(object_ref), path_(std::move(path)) {}
+
+  // Implicit conversion from a derived reference class
+  template <typename DerivedRef>
+  TracedObject(const TracedObject<DerivedRef>& derived)
+      : ref_(derived.Get()), path_(derived.GetPath()) {}
+
+  /*!
+   * \brief Get a traced wrapper for an attribute of the wrapped object.
+   */
+  template <typename T, typename BaseType>
+  typename detail::TracedObjectWrapperSelector<T>::Type GetAttr(T BaseType::*member_ptr) const {
+    using WrapperType = typename detail::TracedObjectWrapperSelector<T>::Type;
+    const ObjectType* node = static_cast<const ObjectType*>(ref_.get());
+    const T& attr = node->*member_ptr;
+    Optional<String> attr_key = ICHECK_NOTNULL(GetAttrKeyByAddress(node, &attr));
+    return WrapperType(attr, path_->Attr(attr_key));
+  }
+
+  /*!
+   * \brief Access the wrapped object.
+   */
+  const RefT& Get() const { return ref_; }
+
+  /*!
+   * \brief Check if the reference to the wrapped object can be converted to `RefU`.
+   */
+  template <typename RefU>
+  bool IsInstance() const {
+    return ref_->template IsInstance<typename RefU::ContainerType>();
+  }
+
+  /*!
+   * \brief Same as Get().defined().
+   */
+  bool defined() const { return ref_.defined(); }
+
+  /*!
+   * \brief Convert the wrapped reference type to a subtype.
+   *
+   * Throws an exception if IsInstance<RefU>() is false.
+   */
+  template <typename RefU>
+  TracedObject<RefU> Downcast() const {
+    return TracedObject<RefU>(tvm::runtime::Downcast<RefU>(ref_), path_);
+  }
+
+  /*!
+   * \brief Convert the wrapped reference type to a subtype.
+   *
+   * Returns an empty optional if IsInstance<RefU>() is false.
+   */
+  template <typename RefU>
+  TracedOptional<RefU> TryDowncast() const {
+    if (ref_->template IsInstance<typename RefU::ContainerType>()) {
+      return Downcast<RefU>();
+    } else {
+      return TracedOptional<RefU>(NullOpt, path_);
+    }
+  }
+
+  /*!
+   * \brief Get the path of the wrapped object.
+   */
+  const ObjectPath& GetPath() const { return path_; }
+
+ private:
+  RefT ref_;
+  ObjectPath path_;
+};
+
+/*!
+ * \brief Iterator class for TracedMap<K, V>
+ */
+template <typename K, typename V>
+class TracedMapIterator {
+ public:
+  using WrappedV = typename detail::TracedObjectWrapperSelector<V>::Type;
+  using MapIter = typename Map<K, V>::iterator;
+
+  using iterator_category = std::bidirectional_iterator_tag;
+  using difference_type = ptrdiff_t;
+  using value_type = const std::pair<K, WrappedV>;
+  using pointer = value_type*;
+  using reference = value_type;
+
+  explicit TracedMapIterator(MapIter iter, ObjectPath map_path)
+      : iter_(iter), map_path_(std::move(map_path)) {}
+
+  bool operator==(const TracedMapIterator& other) const { return iter_ == other.iter_; }
+
+  bool operator!=(const TracedMapIterator& other) const { return iter_ != other.iter_; }
+
+  pointer operator->() const = delete;
+
+  reference operator*() const {
+    auto kv = *iter_;
+    return std::make_pair(kv.first, WrappedV(kv.second, map_path_->MapValue(kv.first)));
+  }
+
+  TracedMapIterator& operator++() {
+    ++iter_;
+    return *this;
+  }
+
+  TracedMapIterator operator++(int) {
+    TracedMapIterator copy = *this;
+    ++(*this);
+    return copy;
+  }
+
+ private:
+  MapIter iter_;
+  ObjectPath map_path_;
+};
+
+/*!
+ * \brief Traced wrapper for Map objects.
+ */
+template <typename K, typename V>
+class TracedMap {
+ public:
+  using WrappedV = typename detail::TracedObjectWrapperSelector<V>::Type;
+
+  using iterator = TracedMapIterator<K, V>;
+
+  // Don't use this direcly. For convenience, call MakeTraced() instead.
+  explicit TracedMap(Map<K, V> map, ObjectPath path)
+      : map_(std::move(map)), path_(std::move(path)) {}
+
+  /*!
+   * \brief Get a value by its key, wrapped in a traced wrapper.
+   */
+  WrappedV at(const K& key) const {
+    auto it = map_.find(key);
+    ICHECK(it != map_.end()) << "No such key in Map";
+    auto kv = *it;
+    return WrappedV(kv.second, path_->MapValue(kv.first));
+  }
+
+  /*!
+   * \brief Access the wrapped map object.
+   */
+  const Map<K, V>& Get() const { return map_; }
+
+  /*!
+   * \brief Get the path of the wrapped object.
+   */
+  const ObjectPath& GetPath() const { return path_; }
+
+  /*!
+   * \brief Get an iterator to the first item of the map.
+   */
+  iterator begin() const { return iterator(map_.begin(), path_); }
+
+  /*!
+   * \brief Get an iterator to the end of the map.
+   */
+  iterator end() const { return iterator(map_.end(), path_); }
+
+  /*!
+   * \brief Returns true iff the wrapped map is empty.
+   */
+  bool empty() const { return map_.empty(); }
+
+ private:
+  Map<K, V> map_;
+  ObjectPath path_;
+};
+
+/*!
+ * \brief Iterator class for TracedArray<T>
+ */
+template <typename T>
+class TracedArrayIterator {
+ public:
+  using WrappedT = typename detail::TracedObjectWrapperSelector<T>::Type;
+
+  using difference_type = ptrdiff_t;
+  using value_type = WrappedT;
+  using pointer = WrappedT*;
+  using reference = WrappedT&;
+  using iterator_category = std::random_access_iterator_tag;
+
+  explicit TracedArrayIterator(Array<T> array, size_t index, ObjectPath array_path)
+      : array_(array), index_(index), array_path_(array_path) {}
+
+  TracedArrayIterator& operator++() {
+    ++index_;
+    return *this;
+  }
+  TracedArrayIterator& operator--() {
+    --index_;
+    return *this;
+  }
+  TracedArrayIterator operator++(int) {
+    TracedArrayIterator copy = *this;
+    ++index_;
+    return copy;
+  }
+  TracedArrayIterator operator--(int) {
+    TracedArrayIterator copy = *this;
+    --index_;
+    return copy;
+  }
+
+  TracedArrayIterator operator+(difference_type offset) const {
+    return TracedArrayIterator(array_, index_ + offset, array_path_);
+  }
+
+  TracedArrayIterator operator-(difference_type offset) const {
+    return TracedArrayIterator(array_, index_ - offset, array_path_);
+  }
+
+  difference_type operator-(const TracedArrayIterator& rhs) const { return index_ - rhs.index_; }
+
+  bool operator==(TracedArrayIterator other) const {
+    return array_.get() == other.array_.get() && index_ == other.index_;
+  }
+  bool operator!=(TracedArrayIterator other) const { return !(*this == other); }
+  value_type operator*() const { return WrappedT(array_[index_], array_path_->ArrayIndex(index_)); }
+
+ private:
+  Array<T> array_;
+  size_t index_;
+  ObjectPath array_path_;
+};
+
+/*!
+ * \brief Traced wrapper for Array objects.
+ */
+template <typename T>
+class TracedArray {
+ public:
+  using WrappedT = typename detail::TracedObjectWrapperSelector<T>::Type;
+
+  using iterator = TracedArrayIterator<T>;
+
+  // Don't use this direcly. For convenience, call MakeTraced() instead.
+  explicit TracedArray(Array<T> array, ObjectPath path)
+      : array_(std::move(array)), path_(std::move(path)) {}
+
+  /*!
+   * \brief Access the wrapped array object.
+   */
+  const Array<T>& Get() const { return array_; }
+
+  /*!
+   * \brief Get the path of the wrapped array object.
+   */
+  const ObjectPath& GetPath() const { return path_; }
+
+  /*!
+   * \brief Get an element by index, wrapped in a traced wrapper.
+   */
+  WrappedT operator[](size_t index) const {
+    return WrappedT(array_[index], path_->ArrayIndex(index));
+  }
+
+  /*!
+   * \brief Get an iterator to the first array element.
+   *
+   * The iterator's dereference operator will automatically wrap each element in a traced wrapper.
+   */
+  iterator begin() const { return iterator(array_, 0, path_); }
+
+  /*!
+   * \brief Get an iterator to the end of the array.
+   *
+   * The iterator's dereference operator will automatically wrap each element in a traced wrapper.
+   */
+  iterator end() const { return iterator(array_, array_.size(), path_); }
+
+  /*!
+   * \brief Returns true iff the wrapped array is empty.
+   */
+  bool empty() const { return array_.empty(); }
+
+  /*!
+   * \brief Get the size of the wrapped array.
+   */
+  size_t size() const { return array_.size(); }
+
+ private:
+  Array<T> array_;
+  ObjectPath path_;
+};
+
+/*!
+ * \brief Traced wrapper for Optional objects.
+ */
+template <typename T>
+class TracedOptional {
+ public:
+  using WrappedT = typename detail::TracedObjectWrapperSelector<T>::Type;
+
+  /*!
+   * \brief Implicit conversion from the corresponding non-optional traced wrapper.
+   */
+  TracedOptional(const WrappedT& value)  // NOLINT(runtime/explicit)
+      : optional_(value.Get().defined() ? value.Get() : Optional<T>(NullOpt)),
+        path_(value.GetPath()) {}
+
+  // Don't use this direcly. For convenience, call MakeTraced() instead.
+  explicit TracedOptional(Optional<T> optional, ObjectPath path)
+      : optional_(std::move(optional)), path_(std::move(path)) {}
+
+  /*!
+   * \brief Access the wrapped optional object.
+   */
+  const Optional<T>& Get() const { return optional_; }
+
+  /*!
+   * \brief Get the path of the wrapped optional object.
+   */
+  const ObjectPath& GetPath() const { return path_; }
+
+  /*!
+   * \brief Returns true iff the object is present.
+   */
+  bool defined() const { return optional_.defined(); }
+
+  /*!
+   * \brief Returns a non-optional traced wrapper, throws if defined() is false.
+   */
+  WrappedT value() const { return WrappedT(optional_.value(), path_); }
+
+  /*!
+   * \brief Same as defined().
+   */
+  explicit operator bool() const { return optional_.defined(); }
+
+ private:
+  Optional<T> optional_;
+  ObjectPath path_;
+};
+
+/*!
+ * \brief Traced wrapper for basic values (i.e. non-TVM objects)
+ */
+template <typename T>
+class TracedBasicValue {
+ public:
+  explicit TracedBasicValue(const T& value, ObjectPath path)
+      : value_(value), path_(std::move(path)) {}
+
+  /*!
+   * \brief Access the wrapped value.
+   */
+  const T& Get() const { return value_; }
+
+  /*!
+   * \brief Get the path of the wrapped value.
+   */
+  const ObjectPath& GetPath() const { return path_; }
+
+  /*!
+   * \brief Transform the wrapped value without changing its path.
+   */
+  template <typename F>
+  typename detail::TracedObjectWrapperSelector<typename std::invoke_result<F, const T&>::type>::Type
+  ApplyFunc(F&& f) const {
+    return MakeTraced(f(value_), path_);
+  }
+
+ private:
+  T value_;
+  ObjectPath path_;
+};
+
+/*!
+ * \brief Wrap the given root object in an appropriate traced wrapper class.
+ */
+template <typename RefT>
+typename detail::TracedObjectWrapperSelector<RefT>::Type MakeTraced(const RefT& object) {
+  using WrappedT = typename detail::TracedObjectWrapperSelector<RefT>::Type;
+  return WrappedT(object, ObjectPath::Root());
+}
+
+/*!
+ * \brief Wrap the given object with the given path in an appropriate traced wrapper class.
+ */
+template <typename RefT>
+typename detail::TracedObjectWrapperSelector<RefT>::Type MakeTraced(const RefT& object,
+                                                                    ObjectPath path) {
+  using WrappedT = typename detail::TracedObjectWrapperSelector<RefT>::Type;
+  return WrappedT(object, std::move(path));
+}
+
+}  // namespace tvm
+
+#endif  // TVM_SCRIPT_PRINTER_TRACED_OBJECT_H_
diff --git a/darknet_drp_ros/include/tvm/script/printer/traced_object_functor.h b/darknet_drp_ros/include/tvm/script/printer/traced_object_functor.h
new file mode 100644
index 0000000..8f72d13
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/script/printer/traced_object_functor.h
@@ -0,0 +1,175 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_SCRIPT_PRINTER_TRACED_OBJECT_FUNCTOR_H_
+#define TVM_SCRIPT_PRINTER_TRACED_OBJECT_FUNCTOR_H_
+
+#include <tvm/node/node.h>
+#include <tvm/runtime/logging.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/script/printer/traced_object.h>
+
+#include <string>
+#include <type_traits>
+#include <unordered_map>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+namespace script {
+namespace printer {
+
+/*
+ * This type alias and the following free functions are created to reduce the binary bloat
+ * from template and also hide implementation details from this header
+ */
+using DispatchTable = std::unordered_map<std::string, std::vector<runtime::PackedFunc>>;
+
+/*!
+ * \brief Get function from dispatch table.
+ * \param dispatch_table The dispatch table.
+ * \param token The dispatch token.
+ * \param type_index The type index of the Object type to be dispatched.
+ *
+ * \return The dispatch function.
+ */
+const runtime::PackedFunc& GetDispatchFunction(const DispatchTable& dispatch_table,
+                                               const String& token, uint32_t type_index);
+
+/*!
+ * \brief Set function in dispatch table.
+ * \param dispatch_table The dispatch table.
+ * \param token The dispatch token.
+ * \param type_index The type index of the Object type to be dispatched.
+ * \param f The dispatch function.
+ */
+void SetDispatchFunction(DispatchTable* dispatch_table, const String& token, uint32_t type_index,
+                         runtime::PackedFunc f);
+
+/*!
+ * \brief Remove function from dispatch table.
+ * \param dispatch_table The dispatch table.
+ * \param token The dispatch token.
+ * \param type_index The TVM object type index for the dispatch function to be removed.
+ */
+void RemoveDispatchFunction(DispatchTable* dispatch_table, const String& token,
+                            uint32_t type_index);
+
+constexpr const char* kDefaultDispatchToken = "";
+
+/*!
+ * \brief Dynamic dispatch functor based on TracedObject.
+ *
+ * This functor dispatches based on the type of object ref inside the input TracedObject,
+ * and the input dispatch token.
+ */
+template <typename R, typename... Args>
+class TracedObjectFunctor {
+ private:
+  using TSelf = TracedObjectFunctor<R, Args...>;
+
+  template <class TObjectRef, class TCallable>
+  using IsDispatchFunction =
+      typename std::is_convertible<TCallable, std::function<R(TracedObject<TObjectRef>, Args...)>>;
+
+ public:
+  /*!
+   * \brief Call the dispatch function.
+   * \param token The dispatch token.
+   * \param traced_object The traced object.
+   * \param args Other args.
+   *
+   * \return The return value of the dispatch function
+   *
+   * If the TObjectRef isn't registered with the token, it will try to find
+   * dispatch function for TObjectRef with kDefaultDispatchToken.
+   */
+  template <class TObjectRef>
+  R operator()(const String& token, TracedObject<TObjectRef> traced_object, Args... args) const {
+    const runtime::PackedFunc& dispatch_function =
+        GetDispatchFunction(dispatch_table_, token, traced_object.Get()->type_index());
+    return dispatch_function(traced_object.Get(), traced_object.GetPath(), args...);
+  }
+
+  /*!
+   * \brief Set the dispatch function
+   * \param token The dispatch token.
+   * \param type_index The TVM object type index for this dispatch function.
+   * \param f The dispatch function.
+   *
+   * This takes a type-erased packed function as input. It should be used
+   * through FFI boundary, for example, registering dispatch function from Python.
+   */
+  TSelf& set_dispatch(String token, uint32_t type_index, runtime::PackedFunc f) {
+    SetDispatchFunction(&dispatch_table_, token, type_index, std::move(f));
+    return *this;
+  }
+
+  /*!
+   * \brief Set the dispatch function
+   * \param token The dispatch token.
+   * \param f The dispatch function.
+   *
+   * The diaptch function should have signature `R(TracedObject<TObjectRef>, Args...)`.
+   */
+  template <typename TObjectRef, typename TCallable,
+            typename = std::enable_if_t<IsDispatchFunction<TObjectRef, TCallable>::value>>
+  TSelf& set_dispatch(String token, TCallable f) {
+    return set_dispatch(
+        token,                                          //
+        TObjectRef::ContainerType::RuntimeTypeIndex(),  //
+        runtime::TypedPackedFunc<R(TObjectRef, ObjectPath, Args...)>(
+            [f = std::move(f)](TObjectRef object, ObjectPath path, Args... args) -> R {
+              return f(MakeTraced(object, path), args...);
+            }));
+  }
+  /*!
+   * \brief Set the default dispatch function
+   * \param f The dispatch function.
+   *
+   * Default dispatch function will be used if there is no function registered
+   * with the requested dispatch token.
+   *
+   * Default dispatch function has an empty string as dispatch token.
+   */
+  template <typename TObjectRef, typename TCallable,
+            typename = std::enable_if_t<IsDispatchFunction<TObjectRef, TCallable>::value>>
+  TSelf& set_dispatch(TCallable&& f) {
+    return set_dispatch<TObjectRef>(kDefaultDispatchToken, std::forward<TCallable>(f));
+  }
+
+  /*!
+   * \brief Remove dispatch function
+   * \param token The dispatch token.
+   * \param type_index The TVM object type index for the dispatch function to be removed.
+   *
+   * This is useful when dispatch function comes from other language's runtime, and
+   * those function should be removed before that language runtime shuts down.
+   */
+  void remove_dispatch(String token, uint32_t type_index) {
+    RemoveDispatchFunction(&dispatch_table_, token, type_index);
+  }
+
+ private:
+  DispatchTable dispatch_table_;
+};
+
+}  // namespace printer
+}  // namespace script
+}  // namespace tvm
+#endif  // TVM_SCRIPT_PRINTER_TRACED_OBJECT_FUNCTOR_H_
diff --git a/darknet_drp_ros/include/tvm/script/printer/var_table.h b/darknet_drp_ros/include/tvm/script/printer/var_table.h
new file mode 100644
index 0000000..2cd9335
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/script/printer/var_table.h
@@ -0,0 +1,155 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_SCRIPT_PRINTER_VAR_TABLE_H_
+#define TVM_SCRIPT_PRINTER_VAR_TABLE_H_
+
+#include <tvm/node/node.h>
+#include <tvm/node/object_path.h>
+#include <tvm/script/printer/doc.h>
+#include <tvm/script/printer/frame.h>
+#include <tvm/script/printer/traced_object.h>
+
+#include <unordered_map>
+#include <unordered_set>
+
+namespace tvm {
+namespace script {
+namespace printer {
+
+/*!
+ * \brief Variable Table manages mapping from variable object to ExprDoc during
+ * the process of printing TVMScript.
+ *
+ * The value type of this map is ExprDoc rather than IdDoc or String. It's
+ * because variables can be implicitly defined. For example in TIR buffer (tir::Buffer),
+ * `buf->data` is a variable, while its representation in TVMScript should be an
+ * expression `x.data`, where `x` is the variable for the buffer itself.
+ */
+class VarTableNode : public Object {
+ public:
+  void VisitAttrs(AttrVisitor*) {}
+
+  /*!
+   * \brief Define variable by name.
+   * \param obj The variable object.
+   * \param name_hint The hint for variable name.
+   * \param object_path The object_path for the returned ExprDoc.
+   * \param frame The frame that this variable is defined in.
+   *
+   * \return The id doc for this variable.
+   *
+   * This function will rename the variable to avoid name conflict with other variables
+   * in the table.
+   */
+  IdDoc Define(const ObjectRef& obj, const String& name_hint, const ObjectPath& object_path,
+               const Frame& frame);
+
+  /*!
+   * \brief Define variable by name.
+   * \param obj The variable object.
+   * \param name_hint The hint for variable name.
+   * \param frame The frame that this variable is defined in.
+   *
+   * \return The id doc for this variable.
+   *
+   * This is a shortcut version of `Define` which accepts a traced string.
+   */
+  IdDoc Define(const ObjectRef& obj, const TracedObject<String>& name_hint, const Frame& frame) {
+    return Define(obj, name_hint.Get(), name_hint.GetPath(), frame);
+  }
+
+  using DocFactory = std::function<ExprDoc()>;
+
+  /*!
+   * \brief Define variable by doc factory.
+   * \param obj The variable object.
+   * \param doc_factory The function to return an ExprDoc object for this variable.
+   * \param frame The frame that this variable is defined in.
+   *
+   * This function is a special form of `Define`. Variable is mapped to ExprDoc rather
+   * than IdDoc. It's useful when a variable is implicitly defined without a name, like
+   * the buf->data in TIR, which should be mapped to `AttrDoc(IdDoc("<buffer_name>"), "data")`.
+   *
+   * This function takes a DocFactory instead of Doc. It's because GetVarDoc needs to
+   * return a new Doc object every time it's called, as the returned doc will have
+   * different `soruce_path`. Currently there isn't a good way to deep copy a TVMObject
+   * so VarTable needs to call a factory function to get a freshly-constructed Doc object
+   * every time GetVarDoc is called.
+   */
+  void DefineByDoc(const ObjectRef& obj, DocFactory doc_factory, const Frame& frame);
+
+  /*!
+   * \brief Get the doc for variable.
+   * \param obj The variable object.
+   * \param object_path The object path for the variable.
+   *
+   * \return The doc for variable, if it exists in the table. Otherwise it returns NullOpt.
+   */
+  Optional<ExprDoc> GetVarDoc(const ObjectRef& obj, const ObjectPath& object_path) const;
+
+  /*!
+   * \brief Get the doc for variable.
+   * \param obj The traced variable object.
+   *
+   * \return The doc for variable, if it exists in the table. Otherwise it returns NullOpt.
+   */
+  template <typename TObjectRef>
+  Optional<ExprDoc> GetVarDoc(const TracedObject<TObjectRef> obj) const {
+    return GetVarDoc(obj.Get(), obj.GetPath());
+  }
+
+  /*!
+   * \brief Check if a variable exists in the table.
+   * \param obj The variable object.
+   *
+   * \return a boolean for whether variable exists.
+   */
+  bool IsVarDefined(const ObjectRef& obj) const;
+
+  static constexpr const char* _type_key = "script.printer.VarTable";
+  TVM_DECLARE_FINAL_OBJECT_INFO(VarTableNode, Object);
+
+ private:
+  void RemoveVar(const ObjectRef& obj);
+
+  struct VariableInfo {
+    DocFactory doc_factory;
+    Optional<String> name;
+  };
+  std::unordered_map<ObjectRef, VariableInfo, ObjectPtrHash, ObjectPtrEqual> obj2info;
+  std::unordered_set<String> defined_names;
+};
+
+/*!
+ * \brief Reference type of VarTableNode.
+ */
+class VarTable : public ObjectRef {
+ public:
+  /*!
+   * \brief Create an empty VarTable.
+   */
+  VarTable();
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(VarTable, ObjectRef, VarTableNode);
+};
+
+}  // namespace printer
+}  // namespace script
+}  // namespace tvm
+
+#endif  // TVM_SCRIPT_PRINTER_VAR_TABLE_H_
diff --git a/darknet_drp_ros/include/tvm/support/parallel_for.h b/darknet_drp_ros/include/tvm/support/parallel_for.h
new file mode 100644
index 0000000..8bd2e6b
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/support/parallel_for.h
@@ -0,0 +1,93 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file parallel_for.h
+ * \brief An implementation to run loop in parallel.
+ */
+#ifndef TVM_SUPPORT_PARALLEL_FOR_H_
+#define TVM_SUPPORT_PARALLEL_FOR_H_
+
+#include <tvm/runtime/c_runtime_api.h>
+
+#include <functional>
+#include <vector>
+
+namespace tvm {
+namespace support {
+
+using PartitionerFuncType = std::function<std::vector<std::vector<int>>(int, int, int, int)>;
+
+/*!
+ * \brief A partitioner to split the task to each thread in Round-robin manner.
+ * \param begin The start index of this parallel loop(inclusive).
+ * \param end The end index of this parallel loop(exclusive).
+ * \param step The traversal step to the index.
+ * \param num_threads The number of threads(the number of tasks to be partitioned to).
+ * \return A list with `num_threads` elements, and each is a list of integers indicating the loop
+ * indexes for the corresponding thread to process.
+ */
+TVM_DLL std::vector<std::vector<int>> rr_partitioner(int begin, int end, int step, int num_threads);
+
+/*!
+ * \brief A runtime api provided to run the task function in parallel.
+ * e.g. A for loop:
+ *   for (int i = 0; i < 10; i++) {
+ *     a[i] = i;
+ *   }
+ * should work the same as:
+ *   parallel_for(0, 10, [&a](int index) {
+ *     a[i] = i;
+ *   });
+ * \param begin The start index of this parallel loop(inclusive).
+ * \param end The end index of this parallel loop(exclusive).
+ * \param f The task function to be executed. Assert to take an int index as input with no output.
+ * \param step The traversal step to the index.
+ * \param partitioner A partition function to split tasks to different threads. Use Round-robin
+ * partitioner by default.
+ * \note 1. Currently do not support nested parallel_for; 2. The order of execution in each thread
+ * is not guaranteed, the for loop task should be thread independent and thread safe.
+ */
+TVM_DLL void parallel_for(int begin, int end, const std::function<void(int)>& f, int step = 1,
+                          const PartitionerFuncType partitioner = rr_partitioner);
+
+/*!
+ * \brief An API to launch fix amount of threads to run the specific functor in parallel.
+ * Different from `parallel_for`, the partition is determined dynamically on the fly,
+ * i.e. any time when a thread is idle, it fetches the next task to run.
+ * The behavior is similar to dynamic scheduling in OpenMP:
+ *
+ *   \#pragma omp parallel for schedule(dynamic) num_threads(num_threads)
+ *   for (int i = 0; i < 10; i++) {
+ *     a[i] = i;
+ *   }
+ *
+ * \param begin The start index of this parallel loop (inclusive).
+ * \param end The end index of this parallel loop (exclusive).
+ * \param num_threads The number of threads to be used.
+ * \param f The task function to be executed. Takes the thread index and the task index as
+ * input with no output.
+ * \note `step` support is left for future work.
+ */
+TVM_DLL void parallel_for_dynamic(int begin, int end, int num_threads,
+                                  const std::function<void(int thread_id, int task_id)>& f);
+}  // namespace support
+}  // namespace tvm
+
+#endif  // TVM_SUPPORT_PARALLEL_FOR_H_
diff --git a/darknet_drp_ros/include/tvm/support/random_engine.h b/darknet_drp_ros/include/tvm/support/random_engine.h
new file mode 100644
index 0000000..109a98b
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/support/random_engine.h
@@ -0,0 +1,136 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+/*!
+ * \file random_engine.h
+ * \brief Random number generator. It provides a generic interface consistent with
+ * `std::uniform_random_bit_generator`
+ */
+#ifndef TVM_SUPPORT_RANDOM_ENGINE_H_
+#define TVM_SUPPORT_RANDOM_ENGINE_H_
+#include <tvm/runtime/logging.h>
+
+#include <cstdint>
+#include <random>
+
+namespace tvm {
+namespace support {
+
+/*!
+ * \brief This linear congruential engine is a drop-in replacement for std::minstd_rand. It strictly
+ *  corresponds to std::minstd_rand and is designed to be platform-independent.
+ * \note Our linear congruential engine is a complete implementation of
+ *  std::uniform_random_bit_generator so it can be used as generator for any STL random number
+ *  distribution. However, parts of std::linear_congruential_engine's member functions are not
+ *  included for simplification. For full member functions of std::minstd_rand, please check out the
+ *  following link: https://en.cppreference.com/w/cpp/numeric/random/linear_congruential_engine
+ */
+
+class LinearCongruentialEngine {
+ public:
+  using TRandState = int64_t;
+  /*! \brief The result type. */
+  using result_type = uint64_t;
+  /*! \brief The multiplier */
+  static constexpr TRandState multiplier = 48271;
+  /*! \brief The increment */
+  static constexpr TRandState increment = 0;
+  /*! \brief The modulus */
+  static constexpr TRandState modulus = 2147483647;
+  /*! \brief The minimum possible value of random state here. */
+  static constexpr result_type min() { return 0; }
+  /*! \brief The maximum possible value of random state here. */
+  static constexpr result_type max() { return modulus - 1; }
+
+  /*!
+   * \brief Get a device random state
+   * \return The random state
+   */
+  static TRandState DeviceRandom() { return (std::random_device()()) % modulus; }
+
+  /*!
+   * \brief Operator to move the random state to the next and return the new random state. According
+   *  to definition of linear congruential engine, the new random state value is computed as
+   *  new_random_state = (current_random_state * multiplier + increment) % modulus.
+   * \return The next current random state value in the type of result_type.
+   * \note In order for better efficiency, the implementation here has a few assumptions:
+   *  1. The multiplication and addition won't overflow.
+   *  2. The given random state pointer `rand_state_ptr` is not nullptr.
+   *  3. The given random state `*(rand_state_ptr)` is in the range of [0, modulus - 1].
+   */
+  result_type operator()() {
+    (*rand_state_ptr_) = ((*rand_state_ptr_) * multiplier + increment) % modulus;
+    return *rand_state_ptr_;
+  }
+  /*!
+   * \brief Normalize the random seed to the range of [1, modulus - 1].
+   * \param rand_state The random seed.
+   * \return The normalized random seed.
+   */
+  static TRandState NormalizeSeed(TRandState rand_state) {
+    if (rand_state == -1) {
+      rand_state = DeviceRandom();
+    } else {
+      rand_state %= modulus;
+    }
+    if (rand_state == 0) {
+      rand_state = 1;
+    }
+    if (rand_state < 0) {
+      LOG(FATAL) << "ValueError: Random seed must be non-negative";
+    }
+    return rand_state;
+  }
+  /*!
+   * \brief Change the start random state of RNG with the seed of a new random state value.
+   * \param rand_state The random state given in result_type.
+   */
+  void Seed(TRandState rand_state) {
+    ICHECK(rand_state_ptr_ != nullptr);
+    *rand_state_ptr_ = NormalizeSeed(rand_state);
+  }
+
+  /*!
+   * \brief Fork a new seed for another RNG from current random state.
+   * \return The forked seed.
+   */
+  TRandState ForkSeed() {
+    // In order for reproducibility, we compute the new seed using RNG's random state and a
+    // different set of parameters. Note that both 32767 and 1999999973 are prime numbers.
+    return ((*this)() * 32767) % 1999999973;
+  }
+
+  /*!
+   * \brief Construct a random number generator with a random state pointer.
+   * \param rand_state_ptr The random state pointer given in result_type*.
+   * \note The random state is not checked for whether it's nullptr and whether it's in the range of
+   *  [0, modulus-1]. We assume the given random state is valid or the Seed function would be
+   *  called right after the constructor before any usage.
+   */
+  explicit LinearCongruentialEngine(TRandState* rand_state_ptr) {
+    rand_state_ptr_ = rand_state_ptr;
+  }
+
+ private:
+  TRandState* rand_state_ptr_;
+};
+
+}  // namespace support
+}  // namespace tvm
+
+#endif  // TVM_SUPPORT_RANDOM_ENGINE_H_
diff --git a/darknet_drp_ros/include/tvm/support/span.h b/darknet_drp_ros/include/tvm/support/span.h
new file mode 100644
index 0000000..768252f
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/support/span.h
@@ -0,0 +1,109 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ *
+ * \file tvm/support/span.h
+ * \brief Reimplementation of part of C++-20 style span.
+ */
+#ifndef TVM_SUPPORT_SPAN_H_
+#define TVM_SUPPORT_SPAN_H_
+
+#include <cstddef>
+#include <iterator>
+#include <type_traits>
+#include <vector>
+
+namespace tvm {
+namespace support {
+
+/*!
+ * \brief A partial implementation of the C++20 std::span.
+ *
+ * At the time of writing, TVM must compile against C++17.
+ */
+template <class T, class W>
+class Span {
+ public:
+  using value_type = W;
+  using const_W = typename std::add_const<W>::type;
+
+  template <class W1>
+  class iterator_base {
+   public:
+    using iterator_category = std::input_iterator_tag;
+    using value_type = W;
+    using difference_type = std::ptrdiff_t;
+    using pointer = const W*;
+    using reference = const W&;
+
+    inline iterator_base(T* ptr, T* end) : ptr_{ptr}, end_{end} { CHECK_GE(end, ptr); }
+
+    inline W1 operator*() { return W1(*ptr_); }
+
+    inline iterator_base<W1>& operator++() {
+      if (ptr_ != end_) ptr_++;
+      return *this;
+    }
+
+    inline bool operator==(iterator_base<W1> other) {
+      return ptr_ == other.ptr_ && end_ == other.end_;
+    }
+
+    inline bool operator!=(iterator_base<W1> other) { return !(*this == other); }
+
+    template <class X = W1, typename = std::enable_if_t<!std::is_const<X>::value>>
+    inline operator iterator_base<const_W>() const {
+      return iterator_base<const_W>(ptr_, end_);
+    }
+
+   private:
+    T* ptr_;
+    T* end_;
+  };
+
+  using iterator = iterator_base<W>;
+  using const_iterator = iterator_base<const_W>;
+
+  inline Span(T* begin, int num_elements) : begin_{begin}, end_{begin + num_elements} {}
+  inline Span(T* begin, T* end) : begin_{begin}, end_{end} {}
+
+  inline iterator begin() const { return iterator(begin_, end_); }
+
+  inline iterator end() const { return iterator(end_, end_); }
+
+  size_t size() const { return end_ - begin_; }
+
+  inline W operator[](int i) {
+    T* to_return = begin_ + i;
+    ICHECK_LT(to_return, end_) << "Span access out of bounds: " << i;
+    return W(*to_return);
+  }
+
+  inline operator std::vector<W>() { return std::vector<W>(begin(), end()); }
+
+ protected:
+  T* begin_;
+  T* end_;
+};
+
+}  // namespace support
+}  // namespace tvm
+
+#endif  // TVM_SUPPORT_SPAN_H_
diff --git a/darknet_drp_ros/include/tvm/support/with.h b/darknet_drp_ros/include/tvm/support/with.h
new file mode 100644
index 0000000..5959aff
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/support/with.h
@@ -0,0 +1,125 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/support/with.h
+ * \brief RAII wrapper function to enter and exit a context object
+ *        similar to python's with syntax.
+ */
+#ifndef TVM_SUPPORT_WITH_H_
+#define TVM_SUPPORT_WITH_H_
+
+#include <dmlc/common.h>
+
+#include <functional>
+#include <utility>
+
+namespace tvm {
+
+/*!
+ * \brief RAII wrapper function to enter and exit a context object
+ *        similar to python's with syntax.
+ *
+ * \code
+ * // context class
+ * class MyContext {
+ *  private:
+ *    friend class With<MyContext>;
+      MyContext(arguments);
+ *    void EnterWithScope();
+ *    void ExitWithScope();
+ * };
+ *
+ * {
+ *   With<MyContext> scope(arguments);
+ *   // effect take place.
+ * }
+ * \endcode
+ *
+ * \tparam ContextType Type of the context object.
+ */
+template <typename ContextType>
+class With {
+ public:
+  /*!
+   * \brief constructor.
+   *  Enter the scope of the context.
+   */
+  template <typename... Args>
+  explicit With(Args&&... args) : ctx_(std::forward<Args>(args)...) {
+    ctx_.EnterWithScope();
+  }
+  /*! \brief destructor, leaves the scope of the context. */
+  ~With() DMLC_THROW_EXCEPTION { ctx_.ExitWithScope(); }
+
+  // Disable copy and move construction.  `With` is intended only for
+  // use in nested contexts that are exited in the reverse order of
+  // entry.  Allowing context to be copied or moved would break this
+  // expectation.
+  With(const With& other) = delete;
+  With& operator=(const With& other) = delete;
+  With(With&& other) = delete;
+  With& operator=(With&& other) = delete;
+
+  ContextType* get() { return &ctx_; }
+  const ContextType* get() const { return &ctx_; }
+
+  ContextType* operator->() { return get(); }
+  const ContextType* operator->() const { return get(); }
+  ContextType& operator*() { return *get(); }
+  const ContextType* operator*() const { return *get(); }
+
+  ContextType operator()() { return ctx_; }
+
+ private:
+  /*! \brief internal context type. */
+  ContextType ctx_;
+};
+
+/*!
+ * \brief A context type that delegates EnterWithScope and ExitWithScope
+ *        to user-provided functions.
+ */
+class ContextManager {
+ public:
+  /*!
+   * \brief Constructor of ContextManager.
+   * \param f_enter The function to call when entering scope. If it's nullptr, do nothing when
+   *                entering.
+   * \param f_exit The function to call when exiting scope. If it's nullptr, do nothing
+   *               when exiting.
+   */
+  template <class FEnter, class FExit>
+  explicit ContextManager(FEnter f_enter, FExit f_exit) : f_enter_(f_enter), f_exit_(f_exit) {}
+
+ private:
+  void EnterWithScope() {
+    if (f_enter_) f_enter_();
+  }
+  void ExitWithScope() {
+    if (f_exit_) f_exit_();
+  }
+  std::function<void()> f_enter_;
+  std::function<void()> f_exit_;
+  template <typename>
+  friend class With;
+};
+
+}  // namespace tvm
+#endif  // TVM_SUPPORT_WITH_H_
diff --git a/darknet_drp_ros/include/tvm/target/codegen.h b/darknet_drp_ros/include/tvm/target/codegen.h
new file mode 100644
index 0000000..b2cab0e
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/target/codegen.h
@@ -0,0 +1,77 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/target/codegen.h
+ * \brief Translates IRModule to runtime::Module.
+ */
+#ifndef TVM_TARGET_CODEGEN_H_
+#define TVM_TARGET_CODEGEN_H_
+
+#include <tvm/ir/module.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/target/target.h>
+#include <tvm/tir/expr.h>
+
+#include <string>
+
+namespace tvm {
+/*! \brief namespace for target translation and codegen. */
+namespace codegen {
+// use packed function from runtime.
+using runtime::PackedFunc;
+using runtime::TVMArgs;
+using runtime::TVMRetValue;
+
+/*!
+ * \brief Build a module from array of lowered function.
+ * \param mod The Module to be built
+ * \param target The target to be built.
+ * \return The result runtime::Module.
+ */
+runtime::Module Build(IRModule mod, Target target);
+
+/*!
+ * \brief Pack imported device library to a C file.
+ *  Compile the C file and link with the host library
+ *  will allow the DSO loader to automatically discover and import
+ *  the dependency from the shared library.
+ *
+ * \param m The host module with the imports.
+ * \param system_lib Whether expose as system library.
+ * \return cstr The C string representation of the file.
+ */
+std::string PackImportsToC(const runtime::Module& m, bool system_lib);
+
+/*!
+ * \brief Pack imported device library to a LLVM module.
+ *  Compile the LLVM module and link with the host library
+ *  will allow the DSO loader to automatically discover and import
+ *  the dependency from the shared library.
+ *
+ * \param m The host module with the imports.
+ * \param system_lib Whether expose as system library.
+ * \param target_triple LLVM target triple
+ * \return runtime::Module The generated LLVM module.
+ */
+runtime::Module PackImportsToLLVM(const runtime::Module& m, bool system_lib,
+                                  const std::string& target_triple);
+}  // namespace codegen
+}  // namespace tvm
+#endif  // TVM_TARGET_CODEGEN_H_
diff --git a/darknet_drp_ros/include/tvm/target/compilation_config.h b/darknet_drp_ros/include/tvm/target/compilation_config.h
new file mode 100644
index 0000000..eab34de
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/target/compilation_config.h
@@ -0,0 +1,205 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/target/compilation_config.h
+ * \brief A helper class to collect all the targets in canonical form necessary for compilation.
+ */
+
+#ifndef TVM_TARGET_COMPILATION_CONFIG_H_
+#define TVM_TARGET_COMPILATION_CONFIG_H_
+
+#include <tvm/target/virtual_device.h>
+
+#include <string>
+
+namespace tvm {
+
+/*!
+ * \brief Gathers the \p Targets and distinguished \p VirtualDevices in canonical form needed to
+ * compile a Relay module for execution over possibly heterogeneous devices. Centralizes the
+ * validation and canonicalization logic needed to transition from targets supplied by the Python
+ * APIs to a single internal representation. Also holds a cache of canonical \p VirtualDevices
+ * so that structural equal virtual devices have pointer equal canonical virtual devices.
+ *
+ * The construction of \p CompilationConfig is idempotent, in that given the same \p PassContext
+ * \p ctx and an arbitrary \p Array<Target> \p raw_targets:
+ *
+ * \code
+ *   CompilationConfig(ctxt, raw_targets)
+ *      is structurally equal to
+ *   CompilationConfig(ctxt, CompilationConfig(ctxt, raw_targets)->primitive_targets)
+ * \endcode
+ *
+ * TODO(mbs): This is subject to change as we rework compilation options in general. This class
+ * is probably better called a 'CompositeTarget', and may be better made a sub-class of Target or
+ * some other common-target-root class.
+ */
+class CompilationConfigNode : public Object {
+ public:
+  /*!
+   * \brief The host target. Used for 'scalar' data and code (such as shapes and shape
+   * functions) and residual Relay expressions and data (such as conditionals and ADTs).
+   * Each \p primitive_target below will have this exact target object as its 'host'.
+   *
+   * Note that it is possible for a \p Target used for primitive operations to be structurally
+   * equal to the host \p Target (up to the \p host field.) However the \p Target objects will
+   * be distinct, and can be used as keys within a \p Map without collision.
+   */
+  Target host_target;
+
+  /*!
+   * \brief Vector of all available \p Targets for partitioning or compiling primitive tensor
+   * operators (kernels). May contain a \p Target for the same device type as for the
+   * \p host_target, however the \p host_target should be used for all host computations and data.
+   * Each \p Target will have \p host_target as its 'host'.
+   *
+   * Primitive targets must be unique by their kind name. In this way the
+   * \p FindPrimitiveTargetForKind method will find the unique target for the given kind name.
+   * This method is used when transitioning from an external codegen "Compiler" attribute value
+   * to the external codegen target representing that compiler.
+   *
+   * It is possible to have multiple primitive targets for the same device type. However given
+   * primitive targets left and right where:
+   *  - left appears before right in the array
+   *  - left->GetTargetDeviceType() == right->GetTargetDeviceType()
+   * then:
+   *  - right.IsExternalCodegenFor(left) must be true
+   * In this way the \p FindPrimitiveTargetForDeviceOrFail method will find the 'most general'
+   * target for the requested device type. This method is used when transitioning from a device
+   * constraint to the target needed to compile for that device.
+   *
+   * In the homogeneous case primitive_targets will have just one entry, which will be pointer equal
+   * to optional_homogeneous_target.
+   *
+   * In the homogenous case where the 'host' is the same device as used for compiling kernels it
+   * is *not* the case that optional_homogenous_target == host_target. This is because all
+   * primitive always have their host field set to the host_target. Ie, it is valid to have:
+   * \code
+   *   host_target=Target("llvm")
+   *   optional_homogenous_target=Target("llvm", host=host_target)
+   * \endcode
+   */
+  Array<Target> primitive_targets;
+
+  /*!
+   * \brief \p VirtualDevice for primitive operators which are not otherwise constrained to a
+   * particular device. Used by the PlanDevices pass to determine a virtual device for every
+   * sub-expression.
+   */
+  VirtualDevice default_primitive_virtual_device = VirtualDevice::FullyUnconstrained();
+
+  /*! \brief VirtualDevice for the host. */
+  VirtualDevice host_virtual_device = VirtualDevice::FullyUnconstrained();
+
+  /*!
+   * \brief If defined then compile and/or run in 'homogenous execution mode'. In this mode all
+   * primitives are compiled for this target only.
+   *
+   * This is to support legacy passes which have not been adapted to heterogeneous execution and
+   * rely on an implicit global \p Target to be in scope.
+   *
+   * TODO(mbs): Remove once all passes are 'heterogeneous aware'.
+   */
+  Target optional_homogeneous_target;
+
+  void VisitAttrs(AttrVisitor* v);
+
+  /*!
+   * \brief Returns the unique \p Target to use for \p device_type. Fail if no such target exists.
+   *
+   * This will be the first primitive target with matching device type.
+   */
+  Target FindPrimitiveTargetForDeviceOrFail(DLDeviceType device_type) const;
+
+  /*!
+   * \brief Returns the unique \p Target to use for \p kind_name. Returns null if none such.
+   */
+  Optional<Target> FindPrimitiveTargetForKind(const std::string& kind_name) const;
+
+  /*!
+   * \brief Returns a \p Target structurally equal to \p target, however prefer a structually equal
+   * known host or primitive target if the configuration has one.
+   */
+  Target CanonicalTarget(const Target& target) const;
+
+  /*!
+   * \brief Returns a \p VirtualDevice which is structurally equal to \p virtual_device on all its
+   * constrained fields, however:
+   * - If \p virtual_device has a device type but not a target, fill in a target using
+   *   \p FindPrimitiveTargetOrFail. This is the one place we allow targets to be defaulted
+   *   from device types alone.
+   * - If \p virtual_device has a target, also canonicalize it using \p CanonicalTarget.
+   * The returned object will be unique for the adjusted virtual device w.r.t. all other
+   * \p VirtualDevices returned by this method.
+   *
+   * We call the result the 'canonical' \p VirtualDevice. Two canonical \p VirtualDevices are
+   * structurally equal if and only if they are pointer equal. In this way we can build maps
+   * from virtual devices using just pointer equality.
+   */
+  VirtualDevice CanonicalVirtualDevice(const VirtualDevice& virtual_device) const;
+
+  static constexpr const char* _type_key = "CompilationConfig";
+  TVM_DECLARE_FINAL_OBJECT_INFO(CompilationConfigNode, Object)
+
+ private:
+  /*!
+   * \brief Sets the primitive targets, the host target, the default primitive virtual device, and
+   * the host virtual device given:
+   *  - the vector of 'raw' targets (in any order) supplied by one of the TVM entry points.
+   *  - any "relay.fallback_device_type" attribute on \p pass_ctx.
+   *  - whether the LLVM backend is available.
+   * Will look for a suitable host target in the given primitive targets, but if none found may
+   * reuse a raw target or create a default CPU target.
+   */
+  void Init(const transform::PassContext& pass_ctx, const Array<Target>& raw_targets);
+
+  /*!
+   * \brief Returns a freshly constructed CPU \p Target.
+   */
+  static Target MakeDefaultCPUTarget();
+
+  /*!
+   * \brief A cache of constructed virtual devices.
+   */
+  mutable VirtualDeviceCache virtual_device_cache_;
+
+  friend class CompilationConfig;
+};
+
+/*!
+ * \brief Managed reference class to \p CompilationConfig
+ *
+ * \sa CompilationConfig
+ */
+class CompilationConfig : public ObjectRef {
+ public:
+  /*!
+   * \brief Constructs the compilation config given the settings in \p pass_ctx and supplied
+   * \p raw_targets. See \p CompilationConfigNode::Init for details.
+   */
+  TVM_DLL CompilationConfig(const transform::PassContext& pass_ctx,
+                            const Array<Target>& raw_targets);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(CompilationConfig, ObjectRef, CompilationConfigNode);
+};
+
+}  // namespace tvm
+
+#endif  // TVM_TARGET_COMPILATION_CONFIG_H_
diff --git a/darknet_drp_ros/include/tvm/target/generic_func.h b/darknet_drp_ros/include/tvm/target/generic_func.h
new file mode 100644
index 0000000..bd49861
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/target/generic_func.h
@@ -0,0 +1,171 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/target/generic_func.h
+ * \brief Generic function that can be specialzied on a per target basis.
+ */
+#ifndef TVM_TARGET_GENERIC_FUNC_H_
+#define TVM_TARGET_GENERIC_FUNC_H_
+
+#include <tvm/runtime/packed_func.h>
+#include <tvm/support/with.h>
+#include <tvm/target/target.h>
+
+#include <string>
+#include <unordered_map>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+
+class GenericFuncNode;
+
+/*!
+ * \brief Generic function that can be specialized on a per-target basis.
+ */
+class GenericFunc : public ObjectRef {
+ public:
+  GenericFunc() {}
+  explicit GenericFunc(ObjectPtr<Object> n) : ObjectRef(n) {}
+
+  /*!
+   * \brief Set the default function implementaiton.
+   * \param value The default function
+   * \param allow_override If true, this call may override a previously registered function. If
+   * false, an error will be logged if the call would override a previously registered function.
+   * \return reference to self.
+   */
+  TVM_DLL GenericFunc& set_default(const runtime::PackedFunc value, bool allow_override = false);
+  /*!
+   * \brief Register a specialized function
+   * \param tags The tags for this specialization
+   * \param value The specialized function
+   * \param allow_override If true, this call may override previously registered tags. If false,
+   * an error will be logged if the call would override previously registered tags.
+   * \return reference to self.
+   */
+  TVM_DLL GenericFunc& register_func(const std::vector<std::string>& tags,
+                                     const runtime::PackedFunc value, bool allow_override = false);
+  /*!
+   * \brief Call generic function by directly passing in unpacked format.
+   * \param args Arguments to be passed.
+   * \tparam Args arguments to be passed.
+   *
+   * \code
+   *   // Example code on how to call generic function
+   *   void CallGeneric(GenericFunc f) {
+   *     // call like normal functions by pass in arguments
+   *     // return value is automatically converted back
+   *     int rvalue = f(1, 2.0);
+   *   }
+   * \endcode
+   */
+  template <typename... Args>
+  inline runtime::TVMRetValue operator()(Args&&... args) const;
+  /*!
+   * \brief Invoke the relevant function for the current target context, set by set_target_context.
+   * Arguments are passed in packed format.
+   * \param args The arguments to pass to the function.
+   * \param ret The return value
+   */
+  TVM_DLL void CallPacked(runtime::TVMArgs args, runtime::TVMRetValue* ret) const;
+  /*!
+   * \brief Get the packed function specified for the current target context.
+   */
+  TVM_DLL PackedFunc GetPacked() const;
+  /*!
+   * \brief Find or register the GenericFunc instance corresponding to the give name
+   * \param name The name of the registered GenericFunc
+   * \return The GenericFunc instance
+   */
+  TVM_DLL static GenericFunc Get(const std::string& name);
+
+  /*!
+   * \brief Add a GenericFunc instance to the registry
+   * \param func The GenericFunc instance
+   * \param name The name of the registered GenericFunc
+   */
+  TVM_DLL static void RegisterGenericFunc(GenericFunc func, const std::string& name);
+
+  /*!
+   * \brief access the internal node container
+   * \return the pointer to the internal node container
+   */
+  inline GenericFuncNode* operator->();
+
+  // declare container type
+  using ContainerType = GenericFuncNode;
+
+  // Internal class.
+  struct Manager;
+
+ private:
+  friend struct Manager;
+};
+
+template <typename... Args>
+inline runtime::TVMRetValue GenericFunc::operator()(Args&&... args) const {
+  const int kNumArgs = sizeof...(Args);
+  const int kArraySize = kNumArgs > 0 ? kNumArgs : 1;
+  TVMValue values[kArraySize];
+  int type_codes[kArraySize];
+  runtime::detail::for_each(runtime::TVMArgsSetter(values, type_codes),
+                            std::forward<Args>(args)...);
+  runtime::TVMRetValue rv;
+  CallPacked(runtime::TVMArgs(values, type_codes, kNumArgs), &rv);
+  return rv;
+}
+
+/*!
+ * \brief Represents a generic function that can be specialized on a per-target basis.
+ */
+class GenericFuncNode : public Object {
+ public:
+  /*! \brief name of the function */
+  std::string name_;
+  /* \brief the generic builder */
+  runtime::PackedFunc generic_func_;
+  /* \brief map from keys to registered functions */
+  std::unordered_map<std::string, runtime::PackedFunc> dispatch_dict_;
+
+  void VisitAttrs(AttrVisitor* v) {}
+
+  static constexpr const char* _type_key = "GenericFunc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(GenericFuncNode, Object);
+};
+
+inline GenericFuncNode* GenericFunc::operator->() {
+  return static_cast<GenericFuncNode*>(get_mutable());
+}
+
+#define TVM_GENERIC_FUNC_REG_VAR_DEF static TVM_ATTRIBUTE_UNUSED ::tvm::GenericFunc& __mk_##TVM
+
+/*!
+ * \def TVM_REGISTER_GENERIC_FUNC
+ * \brief Register a new generic function, or set a device-specific variant
+ * of the corresponding function.
+ *
+ * \param name The name of the function
+ */
+#define TVM_REGISTER_GENERIC_FUNC(name) \
+  TVM_STR_CONCAT(TVM_GENERIC_FUNC_REG_VAR_DEF, __COUNTER__) = ::tvm::GenericFunc::Get(#name)
+
+}  // namespace tvm
+#endif  // TVM_TARGET_GENERIC_FUNC_H_
diff --git a/darknet_drp_ros/include/tvm/target/tag.h b/darknet_drp_ros/include/tvm/target/tag.h
new file mode 100644
index 0000000..7add206
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/target/tag.h
@@ -0,0 +1,155 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/target/tag.h
+ * \brief Target tag registry
+ */
+#ifndef TVM_TARGET_TAG_H_
+#define TVM_TARGET_TAG_H_
+
+#include <tvm/node/attr_registry_map.h>
+#include <tvm/node/node.h>
+#include <tvm/target/target.h>
+
+#include <utility>
+
+namespace tvm {
+
+/*! \brief A target tag */
+class TargetTagNode : public Object {
+ public:
+  /*! \brief Name of the target */
+  String name;
+  /*! \brief Config map to generate the target */
+  Map<String, ObjectRef> config;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("name", &name);
+    v->Visit("config", &config);
+  }
+
+  static constexpr const char* _type_key = "TargetTag";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TargetTagNode, Object);
+
+ private:
+  /*! \brief Return the index stored in attr registry */
+  uint32_t AttrRegistryIndex() const { return index_; }
+  /*! \brief Return the name stored in attr registry */
+  String AttrRegistryName() const { return name; }
+  /*! \brief Index used for internal lookup of attribute registry */
+  uint32_t index_;
+
+  template <typename, typename>
+  friend class AttrRegistry;
+  template <typename>
+  friend class AttrRegistryMapContainerMap;
+  friend class TargetTagRegEntry;
+};
+
+/*!
+ * \brief Managed reference class to TargetTagNode
+ * \sa TargetTagNode
+ */
+class TargetTag : public ObjectRef {
+ public:
+  /*!
+   * \brief Retrieve the Target given it the name of target tag
+   * \param target_tag_name Name of the target tag
+   * \return The Target requested
+   */
+  TVM_DLL static Optional<Target> Get(const String& target_tag_name);
+  /*!
+   * \brief List all names of the existing target tags
+   * \return A dictionary that maps tag name to the concrete target it corresponds to
+   */
+  TVM_DLL static Map<String, Target> ListTags();
+  /*!
+   * \brief Add a tag into the registry
+   * \param name Name of the tag
+   * \param config The target config corresponding to the tag
+   * \param override Allow overriding existing tags
+   * \return Target created with the tag
+   */
+  TVM_DLL static Target AddTag(String name, Map<String, ObjectRef> config, bool override);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(TargetTag, ObjectRef, TargetTagNode);
+
+ private:
+  /*! \brief Mutable access to the container class  */
+  TargetTagNode* operator->() { return static_cast<TargetTagNode*>(data_.get()); }
+  friend class TargetTagRegEntry;
+};
+
+class TargetTagRegEntry {
+ public:
+  /*!
+   * \brief Set the config dict corresponding to the target tag
+   * \param config The config dict for target creation
+   */
+  inline TargetTagRegEntry& set_config(Map<String, ObjectRef> config);
+  /*! \brief Set name of the TargetTag to be the same as registry if it is empty */
+  inline TargetTagRegEntry& set_name();
+  /*!
+   * \brief Register or get a new entry.
+   * \param target_tag_name The name of the TargetTag.
+   * \return the corresponding entry.
+   */
+  TVM_DLL static TargetTagRegEntry& RegisterOrGet(const String& target_tag_name);
+
+ private:
+  TargetTag tag_;
+  String name;
+
+  /*! \brief private constructor */
+  explicit TargetTagRegEntry(uint32_t reg_index) : tag_(make_object<TargetTagNode>()) {
+    tag_->index_ = reg_index;
+  }
+  template <typename, typename>
+  friend class AttrRegistry;
+  friend class TargetTag;
+};
+
+inline TargetTagRegEntry& TargetTagRegEntry::set_config(Map<String, ObjectRef> config) {
+  tag_->config = std::move(config);
+  return *this;
+}
+
+inline TargetTagRegEntry& TargetTagRegEntry::set_name() {
+  if (tag_->name.empty()) {
+    tag_->name = name;
+  }
+  return *this;
+}
+
+#define TVM_TARGET_TAG_REGISTER_VAR_DEF \
+  static DMLC_ATTRIBUTE_UNUSED ::tvm::TargetTagRegEntry& __make_##TargetTag
+
+/*!
+ * \def TVM_REGISTER_TARGET_TAG
+ * \brief Register a new target tag, or set attribute of the corresponding target tag.
+ * \param TargetTagName The name of target tag
+ */
+#define TVM_REGISTER_TARGET_TAG(TargetTagName)                   \
+  TVM_STR_CONCAT(TVM_TARGET_TAG_REGISTER_VAR_DEF, __COUNTER__) = \
+      ::tvm::TargetTagRegEntry::RegisterOrGet(TargetTagName).set_name()
+
+}  // namespace tvm
+
+#endif  // TVM_TARGET_TAG_H_
diff --git a/darknet_drp_ros/include/tvm/target/target.h b/darknet_drp_ros/include/tvm/target/target.h
new file mode 100644
index 0000000..df69516
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/target/target.h
@@ -0,0 +1,285 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/target/target.h
+ * \brief Compilation target object.
+ */
+#ifndef TVM_TARGET_TARGET_H_
+#define TVM_TARGET_TARGET_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/ir/module.h>
+#include <tvm/node/node.h>
+#include <tvm/support/with.h>
+#include <tvm/target/target_kind.h>
+
+#include <string>
+#include <unordered_set>
+#include <vector>
+
+namespace tvm {
+
+class TargetInternal;
+class Target;
+
+/*!
+ * \brief Compilation target.
+ * \sa Target
+ */
+class TargetNode : public Object {
+ public:
+  /*! \brief The kind of the target device */
+  TargetKind kind;
+  /*! \brief Target host information, must be Target type */
+  Optional<ObjectRef> host;
+  /*! \brief Tag of the target, can be empty */
+  String tag;
+  /*! \brief Keys for this target */
+  Array<String> keys;
+  /*! \brief Collection of attributes */
+  Map<String, ObjectRef> attrs;
+  /*! \brief Target features */
+  Map<String, ObjectRef> features;
+
+  /*!
+   * \brief The raw string representation of the target
+   * \return the full device string to pass to codegen::Build
+   * \note It will be deprecated after the Target RFC is fully landed.
+   */
+  TVM_DLL const std::string& str() const;
+  /*! \return Export target to JSON-like configuration */
+  TVM_DLL Map<String, ObjectRef> Export() const;
+  /*! \return The Optional<Target> typed target host of the TargetNode */
+  TVM_DLL Optional<Target> GetHost() const;
+  /*! \return The device type for this target */
+  TVM_DLL int GetTargetDeviceType() const;
+
+  /*!
+   * \brief Returns a human readable representation of \p Target which includes all fields,
+   * especially the host. Useful for diagnostic messages and debugging.
+   *
+   * TODO(mbs): The ReprPrinter version should perhaps switch to this form, however currently
+   * code depends on str() and << being the same.
+   */
+  String ToDebugString() const;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("kind", &kind);
+    v->Visit("tag", &tag);
+    v->Visit("keys", &keys);
+    v->Visit("attrs", &attrs);
+    v->Visit("features", &features);
+    v->Visit("host", &host);
+  }
+
+  /*!
+   * \brief Get an entry from attrs of the target
+   * \tparam TObjectRef Type of the attribute
+   * \param attr_key The name of the attribute key
+   * \param default_value The value returned if the key is not present
+   * \return An optional, NullOpt if not found, otherwise the value found
+   */
+  template <typename TObjectRef>
+  Optional<TObjectRef> GetAttr(
+      const std::string& attr_key,
+      Optional<TObjectRef> default_value = Optional<TObjectRef>(nullptr)) const {
+    static_assert(std::is_base_of<ObjectRef, TObjectRef>::value,
+                  "Can only call GetAttr with ObjectRef types.");
+    auto it = attrs.find(attr_key);
+    if (it != attrs.end()) {
+      return Downcast<Optional<TObjectRef>>((*it).second);
+    } else {
+      return default_value;
+    }
+  }
+  /*!
+   * \brief Get an entry from attrs of the target
+   * \tparam TObjectRef Type of the attribute
+   * \param attr_key The name of the attribute key
+   * \param default_value The value returned if the key is not present
+   * \return An optional, NullOpt if not found, otherwise the value found
+   */
+  template <typename TObjectRef>
+  Optional<TObjectRef> GetAttr(const std::string& attr_key, TObjectRef default_value) const {
+    return GetAttr<TObjectRef>(attr_key, Optional<TObjectRef>(default_value));
+  }
+
+  /*!
+   * \brief Get a Target feature
+   *
+   * \param feature_key The feature key.
+   * \param default_value The default value if the key does not exist, defaults to nullptr.
+   *
+   * \return The result
+   *
+   * \tparam TOBjectRef the expected object type.
+   * \throw Error if the key exists but the value does not match TObjectRef
+   *
+   * \code
+   *
+   *  void GetTargetFeature(const Target& target) {
+   *    Bool has_feature = target->GetFeature<Bool>("has_feature", false).value();
+   *  }
+   *
+   * \endcode
+   */
+  template <typename TObjectRef>
+  Optional<TObjectRef> GetFeature(
+      const std::string& feature_key,
+      Optional<TObjectRef> default_value = Optional<TObjectRef>(nullptr)) const {
+    Optional<TObjectRef> feature = Downcast<Optional<TObjectRef>>(features.Get(feature_key));
+    if (!feature) {
+      return default_value;
+    }
+    return feature;
+  }
+  // variant that uses TObjectRef to enable implicit conversion to default value.
+  template <typename TObjectRef>
+  Optional<TObjectRef> GetFeature(const std::string& attr_key, TObjectRef default_value) const {
+    return GetFeature<TObjectRef>(attr_key, Optional<TObjectRef>(default_value));
+  }
+
+  /*! \brief Get the keys for this target as a vector of string */
+  TVM_DLL std::vector<std::string> GetKeys() const;
+  /*! \brief Get the keys for this target as an unordered_set of string */
+  TVM_DLL std::unordered_set<std::string> GetLibs() const;
+
+  bool SEqualReduce(const TargetNode* other, SEqualReducer equal) const;
+  void SHashReduce(SHashReducer hash_reduce) const;
+
+  static constexpr const char* _type_key = "Target";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_FINAL_OBJECT_INFO(TargetNode, Object);
+
+ private:
+  /*! \brief Internal string repr. */
+  mutable std::string str_repr_;
+
+  friend class TargetInternal;
+};
+
+/*!
+ * \brief Managed reference class to TargetNode.
+ * \sa TargetNode
+ */
+class Target : public ObjectRef {
+ public:
+  /*! \brief Construct a null Target */
+  TVM_DLL explicit Target(std::nullptr_t) { data_ = nullptr; }
+  /*!
+   * \brief Construct a Target given a string
+   * \param tag_or_config_or_target_str the string to parse for target
+   */
+  TVM_DLL explicit Target(const String& tag_or_config_or_target_str);
+  /*!
+   * \brief Construct a Target using a JSON-like configuration
+   * \param config The JSON-like configuration for target
+   */
+  TVM_DLL explicit Target(const Map<String, ObjectRef>& config);
+  /*!
+   * \brief Get the current target context from thread local storage.
+   * \param allow_not_defined If the context stack is empty and this is set to true, an
+   *   undefined Target will be returned. Otherwise, an empty context stack will cause a
+   *   runtime error.
+   * \return The target that is the current context. The target may not be defined if
+   * allow_not_defined is true.
+   */
+  TVM_DLL static tvm::Target Current(bool allow_not_defined = true);
+  /*!
+   * \brief Construct a Target given target and host
+   * \param target The Target typed object with host field undefined for target
+   * \param host The Target typed object for target host
+   * \return The Target with given target and host context information
+   */
+  TVM_DLL explicit Target(Target target, Target host);
+  TVM_DEFINE_OBJECT_REF_METHODS(Target, ObjectRef, TargetNode);
+  /*!
+   * \brief Create a new Target object with given target (w.o host) and target host.
+   * \param target The current Target typed object target, with or without host field.
+   * \param host The given Target typed object target host
+   * \return The new Target object with the given target and host field of given host.
+   */
+  static Target WithHost(const Target& target, const Target& host);
+
+  /*!
+   * \brief Returns true if \p this target represents an external codegen. If so,
+   * \p this->kind->name can be used as the "Compiler" attribute on partitioned functions,
+   * and can be used to retrieve a partitioning pattern table using
+   * \p get_pattern_table.
+   */
+  bool IsExternalCodegen() const;
+
+  /*!
+   * \brief Returns true if \p this target represents an external codegen which is compatible
+   * with \p that target. In particular:
+   *  - \p this has a true ::tvm::attr::kIsExternalCodegen attribute
+   *  - \p that does not have a true ::tvm::attr::kIsExternalCodegen attribute
+   *  - \p this and \p that have the same GetTargetDeviceType()
+   *
+   * After partitioning, the external codegen compilation path may use \p that to guide it's
+   * compilation to a \p runtime::Module. Given \p this, an appropriate \p that can be
+   * found using \p CompilationConfig::FindPrimitiveTargetOrFail(this->GetTargetDeviceType()).
+   *
+   * The \p CollagePartition pass uses this method to guide it's search over candidate partitions
+   * using external codegen.
+   */
+  bool IsExternalCodegenFor(const Target& that) const;
+
+ private:
+  Target(TargetKind kind, Optional<ObjectRef> host, String tag, Array<String> keys,
+         Map<String, ObjectRef> attrs);
+
+  // enable with syntax.
+  friend class TargetInternal;
+  friend class With<Target>;
+  /*!
+   * \brief Push a new target context onto the thread local stack.
+   *  The Target on top of the stack is used to determine which
+   *  specialization to use when invoking a GenericFunc.
+   */
+  TVM_DLL void EnterWithScope();
+  /*!
+   * \brief Pop a target off the thread local context stack,
+   *  restoring the previous target as the current context.
+   */
+  TVM_DLL void ExitWithScope();
+};
+
+/*!
+ * \brief Check and update host field of the given legacy target and target host pair.
+ *  Note that this function is for legacy target api compatibility issue only, not
+ *  recommended for other use.
+ * \param target The pointer to a Target typed object with host field to be updated
+ * \param host The pointer to a Target typed object for target host to be updated
+ */
+void CheckAndUpdateHostConsistency(Target* target, Target* host);
+
+/*!
+ * \brief Check and update host field of the given legacy heterogeneous targets and
+ *  target host.Note that this function is for legacy target api compatibility issue only,
+ *  not recommended for other use.
+ * \param ir_modules The pointer to a Map objects with keys being Target objects
+ * \param host The Target typed object for target host to be updated
+ */
+void CheckAndUpdateHostConsistency(Map<Target, IRModule>* ir_modules, Target* host);
+
+}  // namespace tvm
+#endif  // TVM_TARGET_TARGET_H_
diff --git a/darknet_drp_ros/include/tvm/target/target_info.h b/darknet_drp_ros/include/tvm/target/target_info.h
new file mode 100644
index 0000000..946161f
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/target/target_info.h
@@ -0,0 +1,76 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/target/target_info.h
+ * \brief Various information about target.
+ */
+#ifndef TVM_TARGET_TARGET_INFO_H_
+#define TVM_TARGET_TARGET_INFO_H_
+
+#include <tvm/ir/expr.h>
+
+#include <string>
+
+namespace tvm {
+
+/*!
+ * \brief Memory information of special memory region.
+ *  Use MemoryInfo as its container type
+ */
+class MemoryInfoNode : public Object {
+ public:
+  /*! \brief The addressable unit */
+  int64_t unit_bits;
+  /*! \brief Maximum number of bits supported in the memory */
+  int64_t max_num_bits;
+  /*! \brief maximum number of bits to be used in simd op */
+  int64_t max_simd_bits;
+  /*!
+   * \brief head address of the buffer, if visible to CPU
+   *  This address can be None.
+   */
+  PrimExpr head_address;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("unit_bits", &unit_bits);
+    v->Visit("max_num_bits", &max_num_bits);
+    v->Visit("max_simd_bits", &max_simd_bits);
+    v->Visit("head_address", &head_address);
+  }
+
+  static constexpr const char* _type_key = "MemoryInfo";
+  TVM_DECLARE_FINAL_OBJECT_INFO(MemoryInfoNode, Object);
+};
+
+/*! \brief Defines memory info */
+class MemoryInfo : public ObjectRef {
+ public:
+  TVM_DEFINE_OBJECT_REF_METHODS(MemoryInfo, ObjectRef, MemoryInfoNode);
+};
+
+/*!
+ * \brief get memory info given scope
+ * \param scope The scope name.
+ * \return info The memory info.
+ */
+TVM_DLL MemoryInfo GetMemoryInfo(const std::string& scope);
+
+}  // namespace tvm
+#endif  // TVM_TARGET_TARGET_INFO_H_
diff --git a/darknet_drp_ros/include/tvm/target/target_kind.h b/darknet_drp_ros/include/tvm/target/target_kind.h
new file mode 100644
index 0000000..19bcce3
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/target/target_kind.h
@@ -0,0 +1,478 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/target/target_kind.h
+ * \brief Target kind registry
+ */
+#ifndef TVM_TARGET_TARGET_KIND_H_
+#define TVM_TARGET_TARGET_KIND_H_
+
+#include <tvm/ir/transform.h>
+#include <tvm/node/attr_registry_map.h>
+#include <tvm/node/node.h>
+
+#include <memory>
+#include <unordered_map>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+
+class Target;
+
+/*!
+ * \brief Map containing parsed features of a specific Target
+ */
+using TargetFeatures = Map<String, ObjectRef>;
+
+/*!
+ * \brief TargetParser to apply on instantiation of a given TargetKind
+ *
+ * \param target_json Target in JSON format to be transformed during parsing.
+ *
+ * \return The transformed Target JSON object.
+ */
+using TargetJSON = Map<String, ObjectRef>;
+using FTVMTargetParser = TypedPackedFunc<TargetJSON(TargetJSON)>;
+
+/*!
+ * \brief RelayToTIR tvm::transform::Pass specific to a TargetKind
+ *
+ * Called before the default lowering passes.
+ *
+ * \param mod The module that an optimization pass runs on.
+ * \param pass_ctx The pass context that can provide information for the optimization.
+ *
+ * \return The transformed module.
+ */
+using FTVMRelayToTIR = transform::Pass;
+
+/*!
+ * \brief TIRToRuntime conversion specific to a TargetKind
+ *
+ * This function is responsible for scanning an IRModule for appropriate Target-specific functions
+ and generating a Runtime module representing the compiled output
+ *
+ * \param ir_module Unified IRModule
+ * \param target Target to filter on or retrieve arguments from
+ * \return Runtime Module containing compiled functions
+ */
+using FTVMTIRToRuntime = runtime::TypedPackedFunc<runtime::Module(IRModule, Target)>;
+
+namespace detail {
+template <typename, typename, typename>
+struct ValueTypeInfoMaker;
+}
+
+class TargetInternal;
+
+template <typename>
+class TargetKindAttrMap;
+
+/*! \brief Target kind, specifies the kind of the target */
+class TargetKindNode : public Object {
+ public:
+  /*! \brief Name of the target kind */
+  String name;
+  /*! \brief Device type of target kind */
+  int default_device_type;
+  /*! \brief Default keys of the target */
+  Array<String> default_keys;
+  /*! \brief Function used to preprocess on target creation */
+  PackedFunc preprocessor;
+  /*! \brief Function used to parse a JSON target during creation */
+  FTVMTargetParser target_parser;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("name", &name);
+    v->Visit("default_device_type", &default_device_type);
+    v->Visit("default_keys", &default_keys);
+  }
+
+  static constexpr const char* _type_key = "TargetKind";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TargetKindNode, Object);
+
+ private:
+  /*! \brief Return the index stored in attr registry */
+  uint32_t AttrRegistryIndex() const { return index_; }
+  /*! \brief Return the name stored in attr registry */
+  String AttrRegistryName() const { return name; }
+  /*! \brief Stores the required type_key and type_index of a specific attr of a target */
+  struct ValueTypeInfo {
+    String type_key;
+    uint32_t type_index;
+    std::unique_ptr<ValueTypeInfo> key;
+    std::unique_ptr<ValueTypeInfo> val;
+  };
+  /*! \brief A hash table that stores the type information of each attr of the target key */
+  std::unordered_map<String, ValueTypeInfo> key2vtype_;
+  /*! \brief A hash table that stores the default value of each attr of the target key */
+  std::unordered_map<String, ObjectRef> key2default_;
+  /*! \brief Index used for internal lookup of attribute registry */
+  uint32_t index_;
+
+  template <typename, typename, typename>
+  friend struct detail::ValueTypeInfoMaker;
+  template <typename, typename>
+  friend class AttrRegistry;
+  template <typename>
+  friend class AttrRegistryMapContainerMap;
+  friend class TargetKindRegEntry;
+  friend class TargetInternal;
+};
+
+/*!
+ * \brief Managed reference class to TargetKindNode
+ * \sa TargetKindNode
+ */
+class TargetKind : public ObjectRef {
+ public:
+  TargetKind() = default;
+  /*! \brief Get the attribute map given the attribute name */
+  template <typename ValueType>
+  static inline TargetKindAttrMap<ValueType> GetAttrMap(const String& attr_name);
+  /*!
+   * \brief Retrieve the TargetKind given its name
+   * \param target_kind_name Name of the target kind
+   * \return The TargetKind requested
+   */
+  TVM_DLL static Optional<TargetKind> Get(const String& target_kind_name);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(TargetKind, ObjectRef, TargetKindNode);
+
+ private:
+  /*! \brief Mutable access to the container class  */
+  TargetKindNode* operator->() { return static_cast<TargetKindNode*>(data_.get()); }
+  TVM_DLL static const AttrRegistryMapContainerMap<TargetKind>& GetAttrMapContainer(
+      const String& attr_name);
+  friend class TargetKindRegEntry;
+  friend class TargetInternal;
+};
+
+/*!
+ * \brief Map<TargetKind, ValueType> used to store meta-information about TargetKind
+ * \tparam ValueType The type of the value stored in map
+ */
+template <typename ValueType>
+class TargetKindAttrMap : public AttrRegistryMap<TargetKind, ValueType> {
+ public:
+  using TParent = AttrRegistryMap<TargetKind, ValueType>;
+  using TParent::count;
+  using TParent::get;
+  using TParent::operator[];
+  explicit TargetKindAttrMap(const AttrRegistryMapContainerMap<TargetKind>& map) : TParent(map) {}
+};
+
+/*! \brief Value used with --runtime in target specs to indicate the C++ runtime. */
+static constexpr const char* kTvmRuntimeCpp = "c++";
+
+/*! \brief Value used with --runtime in target specs to indicate the C runtime. */
+static constexpr const char* kTvmRuntimeCrt = "c";
+
+/*!
+ * \brief Helper structure to register TargetKind
+ * \sa TVM_REGISTER_TARGET_KIND
+ */
+class TargetKindRegEntry {
+ public:
+  /*!
+   * \brief Register additional attributes to target_kind.
+   * \param attr_name The name of the attribute.
+   * \param value The value to be set.
+   * \param plevel The priority level of this attribute,
+   *  an higher priority level attribute
+   *  will replace lower priority level attribute.
+   *  Must be bigger than 0.
+   *
+   *  Cannot set with same plevel twice in the code.
+   *
+   * \tparam ValueType The type of the value to be set.
+   */
+  template <typename ValueType>
+  inline TargetKindRegEntry& set_attr(const String& attr_name, const ValueType& value,
+                                      int plevel = 10);
+  /*!
+   * \brief Set DLPack's device_type the target
+   * \param device_type Device type
+   */
+  inline TargetKindRegEntry& set_default_device_type(int device_type);
+  /*!
+   * \brief Set DLPack's device_type the target
+   * \param keys The default keys
+   */
+  inline TargetKindRegEntry& set_default_keys(std::vector<String> keys);
+  /*!
+   * \brief Set the pre-processing function applied upon target creation
+   * \tparam FLambda Type of the function
+   * \param f The pre-processing function
+   */
+  template <typename FLambda>
+  inline TargetKindRegEntry& set_attrs_preprocessor(FLambda f);
+  /*!
+   * \brief Set the parsing function applied upon target creation
+   * \param parser The Target parsing function
+   */
+  inline TargetKindRegEntry& set_target_parser(FTVMTargetParser parser);
+  /*!
+   * \brief Register a valid configuration option and its ValueType for validation
+   * \param key The configuration key
+   * \tparam ValueType The value type to be registered
+   */
+  template <typename ValueType>
+  inline TargetKindRegEntry& add_attr_option(const String& key);
+  /*!
+   * \brief Register a valid configuration option and its ValueType for validation
+   * \param key The configuration key
+   * \param default_value The default value of the key
+   * \tparam ValueType The value type to be registered
+   */
+  template <typename ValueType>
+  inline TargetKindRegEntry& add_attr_option(const String& key, ObjectRef default_value);
+  /*! \brief Set name of the TargetKind to be the same as registry if it is empty */
+  inline TargetKindRegEntry& set_name();
+  /*!
+   * \brief List all the entry names in the registry.
+   * \return The entry names.
+   */
+  TVM_DLL static Array<String> ListTargetKinds();
+  /*!
+   * \brief Get all supported option names and types for a given Target kind.
+   * \return Map of option name to type
+   */
+  TVM_DLL static Map<String, String> ListTargetKindOptions(const TargetKind& kind);
+
+  /*!
+   * \brief Register or get a new entry.
+   * \param target_kind_name The name of the TargetKind.
+   * \return the corresponding entry.
+   */
+  TVM_DLL static TargetKindRegEntry& RegisterOrGet(const String& target_kind_name);
+
+ private:
+  TargetKind kind_;
+  String name;
+
+  /*! \brief private constructor */
+  explicit TargetKindRegEntry(uint32_t reg_index) : kind_(make_object<TargetKindNode>()) {
+    kind_->index_ = reg_index;
+  }
+  /*!
+   * \brief update the attribute TargetKindAttrMap
+   * \param key The name of the attribute
+   * \param value The value to be set
+   * \param plevel The priority level
+   */
+  TVM_DLL void UpdateAttr(const String& key, TVMRetValue value, int plevel);
+  template <typename, typename>
+  friend class AttrRegistry;
+  friend class TargetKind;
+};
+
+namespace detail {
+template <typename Type, template <typename...> class Container>
+struct is_specialized : std::false_type {
+  using type = std::false_type;
+};
+
+template <template <typename...> class Container, typename... Args>
+struct is_specialized<Container<Args...>, Container> : std::true_type {
+  using type = std::true_type;
+};
+
+template <typename ValueType, typename IsArray = typename is_specialized<ValueType, Array>::type,
+          typename IsMap = typename is_specialized<ValueType, Map>::type>
+struct ValueTypeInfoMaker {};
+
+template <typename ValueType>
+struct ValueTypeInfoMaker<ValueType, std::false_type, std::false_type> {
+  using ValueTypeInfo = TargetKindNode::ValueTypeInfo;
+
+  ValueTypeInfo operator()() const {
+    uint32_t tindex = ValueType::ContainerType::_GetOrAllocRuntimeTypeIndex();
+    ValueTypeInfo info;
+    info.type_index = tindex;
+    info.type_key = runtime::Object::TypeIndex2Key(tindex);
+    info.key = nullptr;
+    info.val = nullptr;
+    return info;
+  }
+};
+
+template <typename ValueType>
+struct ValueTypeInfoMaker<ValueType, std::true_type, std::false_type> {
+  using ValueTypeInfo = TargetKindNode::ValueTypeInfo;
+
+  ValueTypeInfo operator()() const {
+    using key_type = ValueTypeInfoMaker<typename ValueType::value_type>;
+    uint32_t tindex = ValueType::ContainerType::_GetOrAllocRuntimeTypeIndex();
+    ValueTypeInfo info;
+    info.type_index = tindex;
+    info.type_key = runtime::Object::TypeIndex2Key(tindex);
+    info.key = std::make_unique<ValueTypeInfo>(key_type()());
+    info.val = nullptr;
+    return info;
+  }
+};
+
+template <typename ValueType>
+struct ValueTypeInfoMaker<ValueType, std::false_type, std::true_type> {
+  using ValueTypeInfo = TargetKindNode::ValueTypeInfo;
+  ValueTypeInfo operator()() const {
+    using key_type = ValueTypeInfoMaker<typename ValueType::key_type>;
+    using val_type = ValueTypeInfoMaker<typename ValueType::mapped_type>;
+    uint32_t tindex = ValueType::ContainerType::_GetOrAllocRuntimeTypeIndex();
+    ValueTypeInfo info;
+    info.type_index = tindex;
+    info.type_key = runtime::Object::TypeIndex2Key(tindex);
+    info.key = std::make_unique<ValueTypeInfo>(key_type()());
+    info.val = std::make_unique<ValueTypeInfo>(val_type()());
+    return info;
+  }
+};
+
+}  // namespace detail
+
+template <typename ValueType>
+inline TargetKindAttrMap<ValueType> TargetKind::GetAttrMap(const String& attr_name) {
+  return TargetKindAttrMap<ValueType>(GetAttrMapContainer(attr_name));
+}
+
+template <typename ValueType>
+inline TargetKindRegEntry& TargetKindRegEntry::set_attr(const String& attr_name,
+                                                        const ValueType& value, int plevel) {
+  ICHECK_GT(plevel, 0) << "plevel in set_attr must be greater than 0";
+  runtime::TVMRetValue rv;
+  rv = value;
+  UpdateAttr(attr_name, rv, plevel);
+  return *this;
+}
+
+inline TargetKindRegEntry& TargetKindRegEntry::set_default_device_type(int device_type) {
+  kind_->default_device_type = device_type;
+  return *this;
+}
+
+inline TargetKindRegEntry& TargetKindRegEntry::set_default_keys(std::vector<String> keys) {
+  kind_->default_keys = keys;
+  return *this;
+}
+
+template <typename FLambda>
+inline TargetKindRegEntry& TargetKindRegEntry::set_attrs_preprocessor(FLambda f) {
+  LOG(WARNING) << "set_attrs_preprocessor is deprecated please use set_target_parser instead";
+  using FType = typename tvm::runtime::detail::function_signature<FLambda>::FType;
+  kind_->preprocessor = tvm::runtime::TypedPackedFunc<FType>(std::move(f)).packed();
+  return *this;
+}
+
+inline TargetKindRegEntry& TargetKindRegEntry::set_target_parser(FTVMTargetParser parser) {
+  kind_->target_parser = parser;
+  return *this;
+}
+
+template <typename ValueType>
+inline TargetKindRegEntry& TargetKindRegEntry::add_attr_option(const String& key) {
+  ICHECK(!kind_->key2vtype_.count(key))
+      << "AttributeError: add_attr_option failed because '" << key << "' has been set once";
+  kind_->key2vtype_[key] = detail::ValueTypeInfoMaker<ValueType>()();
+  return *this;
+}
+
+template <typename ValueType>
+inline TargetKindRegEntry& TargetKindRegEntry::add_attr_option(const String& key,
+                                                               ObjectRef default_value) {
+  add_attr_option<ValueType>(key);
+  kind_->key2default_[key] = default_value;
+  return *this;
+}
+
+inline TargetKindRegEntry& TargetKindRegEntry::set_name() {
+  if (kind_->name.empty()) {
+    kind_->name = name;
+  }
+  return *this;
+}
+
+#define TVM_TARGET_KIND_REGISTER_VAR_DEF \
+  static DMLC_ATTRIBUTE_UNUSED ::tvm::TargetKindRegEntry& __make_##TargetKind
+
+namespace attr {
+//
+// Distinguished TargetKind attribute names.
+//
+
+/*!
+ * \brief A \p TargetKind attribute of type \p Bool. If true, then the target kind name also
+ * corresponds to an external codegen 'compiler' name. That name may be used:
+ *  - To retrieve partitioning rules using \p get_partition_table.
+ *  - To attach to Relay Functions under the \p attr::kCompiler attribute to indicate
+ *    the function is to be compiled by the external codegen path.
+ *
+ * The \p CollagePartition pass uses this attribute to guide it's search over candidate partitions
+ * using external codegen.
+ *
+ * See also \p Target::IsExternalCodegenFor
+ */
+constexpr const char* kIsExternalCodegen = "is_external_codegen";
+
+/*!
+ * \brief A \p TargetKind attribute of type \p FTVMRelayToTIR. If set, then the target kind name
+ * also corresponds to an external codegen 'compiler' name, and the bound value is a \p Pass
+ * to apply before the TVM lowering.
+ *
+ * See also \p Target::IsExternalCodegenFor
+ */
+constexpr const char* kRelayToTIR = "RelayToTIR";
+
+}  // namespace attr
+
+/*!
+ * \def TVM_REGISTER_TARGET_KIND
+ * \brief Register a new target kind, or set attribute of the corresponding target kind.
+ *
+ * \param TargetKindName The name of target kind
+ * \param DeviceType The DLDeviceType of the target kind
+ *
+ * \code
+ *
+ *  TVM_REGISTER_TARGET_KIND("llvm")
+ *  .set_attr<TPreCodegenPass>("TPreCodegenPass", a-pre-codegen-pass)
+ *  .add_attr_option<Bool>("system_lib")
+ *  .add_attr_option<String>("mtriple")
+ *  .add_attr_option<String>("mattr");
+ *
+ * \endcode
+ */
+#define TVM_REGISTER_TARGET_KIND(TargetKindName, DeviceType)      \
+  TVM_STR_CONCAT(TVM_TARGET_KIND_REGISTER_VAR_DEF, __COUNTER__) = \
+      ::tvm::TargetKindRegEntry::RegisterOrGet(TargetKindName)    \
+          .set_name()                                             \
+          .set_default_device_type(DeviceType)                    \
+          .add_attr_option<Array<String>>("keys")                 \
+          .add_attr_option<String>("tag")                         \
+          .add_attr_option<String>("device")                      \
+          .add_attr_option<String>("model")                       \
+          .add_attr_option<Array<String>>("libs")                 \
+          .add_attr_option<Target>("host")                        \
+          .add_attr_option<Integer>("from_device")                \
+          .add_attr_option<Integer>("target_device_type")
+
+}  // namespace tvm
+
+#endif  // TVM_TARGET_TARGET_KIND_H_
diff --git a/darknet_drp_ros/include/tvm/target/virtual_device.h b/darknet_drp_ros/include/tvm/target/virtual_device.h
new file mode 100644
index 0000000..c26ae5b
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/target/virtual_device.h
@@ -0,0 +1,374 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/target/virtual_device.h
+ * \brief A compile time representation for where data is to be stored at runtime, and how to
+ * compile code to compute it.
+ */
+
+#ifndef TVM_TARGET_VIRTUAL_DEVICE_H_
+#define TVM_TARGET_VIRTUAL_DEVICE_H_
+
+#include <tvm/ir/transform.h>
+#include <tvm/target/target.h>
+
+#include <string>
+#include <unordered_set>
+#include <utility>
+
+namespace tvm {
+
+/*!
+ * Abstract label for an area of memory.
+ *
+ * Currently uninterpreted and arbitrary. Likely to be replaced by a structured representation
+ * of a memory pool in the future. Please try to use this alias instead of String to aid future
+ * code migration.
+ */
+using MemoryScope = String;
+
+/*!
+ * \brief Describes at compile time the constraints on where data is to be stored at runtime
+ * down to the (virtual) device and memory scope level, and how to compile code to compute that
+ * data. Used by the \p PlanDevices pass to collect and solve (virtual) device constraints for
+ * the whole Relay program.
+ *
+ * Is a quadruple of:
+ * - A \p device_type (\p DLDeviceType). May be \p kInvalidDeviceType if unconstrained.
+ * - A \p virtual_device_id (\p int). This allows us to distinguish distinct devices
+ *   with the same \p Target, for example in a multi-GPU system. May be -1 if unconstrained.
+ *   See "Virtual Devices" below.
+ * - A \p target (\p Target) describing how to compile code for the intended device. May be null
+ *   if unconstrained.
+ * - A \p memory_scope (\p MemoryScope, which is currently just \p String) describing which memory
+ *   area is to be used to hold data. May be "" if unconstrained. See "Memory Scopes and Devices"
+ *   below.
+ *
+ * Some or all of these fields may be unconstrained, signaling that device planning is free to
+ * choose a value consistent with the whole program. However if a \p target is given then the \p
+ * device_type must equal \p target->GetTargetDeviceType().
+ *
+ * Note that currently we assume if a function returns its result on a particular (virtual) device
+ * then the function body is also executed on that device. See the overview comment in
+ * src/relay/transforms/device_planner.cc for more details.
+ *
+ * By 'data' we include both tensors and additional supporting datastructures such as shapes,
+ * Relay ADT items (including tuples), Relay references, and Relay closures. Typically non-tensor
+ * data must reside on a 'CPU'-like host device with good support for scalars.
+ *
+ * By 'execution' we include both (fused) primitive operators, and all the Relay expressions
+ * surrounding them which coordinates data and control flow. Again, typically non-primitive
+ * operators must be executed on a 'CPU'-like device with good support for control flow.
+ *
+ * Since TVM targets such a wide range of systems it is not possible for \p VirtualDevice to impose
+ * much semantics on these fields, particularly for \p virtual_device_id and \p memory_scope.
+ * Instead we assume downstream passes and codegen will interpret an validate these fields
+ * appropriately.
+ *
+ * Targets vs Devices
+ * ------------------
+ * Generally \p Targets (a compile-time only datastructue) describe compiler options for a specific
+ * microarchitecture and toolchain, while \p Devices (a runtime datastructure also available at
+ * compile time) describe a physical device on the target system. Obviously the target must agree
+ * with the device's microarchitecture, but we otherwise don't impose any constraints between them:
+ *  - It's ok to use different \p Targets for the same \p Device, eg to squeeze some extra perf
+ *    out of a particular primitive using particular compiler flags.
+ *  - It's ok to use the same \p Target for multiple \p Devices, eg if we have multiple CPUs.
+ *
+ * Traditionally TVM assumes at most one \p Target per \p DLDeviceType. We are moving away from that
+ * assumption.
+ *
+ * Virtual vs Physical Devices
+ * ---------------------------
+ * The \p virtual_device_id may be used by downstream passes or the runtime to help decide which
+ * \p device_id to use for a particular physical runtime \p Device. For example:
+ *  - Some runtimes may support passing in an array of actual `device` specifications, and the
+ *    \p virtual_device_id can be used at runtime as an index into that array.
+ *  - Some runtimes may support dynamically allocating computations to physical devices. On these
+ *    systems a large space of \p virtual_device_ids could be used at compile time, even though
+ *    at runtime only a few physical devices will be present.
+ *
+ * The \p virtual_device_id may also be left unconstrained if not needed.
+ *
+ * Memory Scopes and Devices
+ * -------------------------
+ * Multi-device systems can have complex memory hierarchies. For example
+ * \code
+ * (kDLCPU, 0, "llvm", "global")
+ * \endcode
+ * and
+ * \code
+ * (kDLCPU, 1, "llvm", "global")
+ * \endcode
+ * could denote:
+ * - The same memory area accessible from two separate CPUs without any CPU affinity;
+ * - Distinct memory areas in a NUMA architecture for which cross-device access is handled
+ *   by the memory system;
+ * - Outright distinct memory areas, where one device cannot directly address the memory of
+ *   another.
+ *
+ * Similarly:
+ * \code
+ * (kDLCPU, 0, "llvm", "global")
+ * \endcode
+ * and
+ * \code
+ * (kDLCUDA, 0, "cuda", "host")
+ * \endcode
+ * could denote the same memory area, but with very different access costs.
+ *
+ * Furthermore, not all memory scopes are accessible to all devices, and it is possible for
+ * a memory scope to only be accessible to a device when code is compiled with particular
+ * \p Target options.
+ *
+ * \p VirtualDevices themselves have no system-level understanding. Currently the \p PlanDevices
+ * pass will simply insert "device_copy" operators wherever \p VirtualDevices are not exactly
+ * pointwise equal. We may revisit this in the future as the work on memory pools matures.
+ *
+ * Joining and Defaulting
+ * ----------------------
+ * It is possible to 'join' two \p VirtualDevices to yield the most constrained \p VirtualDevice
+ * which agrees with both join arguments. Eg:
+ * \code
+ * Join((kDLCPU, -1, "llvm", ""), (kInvalidDeviceType, 3, null, "global))
+ *   => (kDLCPU, 3, "llvm", "global")
+ * Join((kDLCPU, -1, "llvm", ""), (kInvalidDeviceType, 3, null, "local))
+ *   => null (no join possible)
+ * \endcode
+ *
+ * Related to 'join' is 'default', which only takes constrained fields from the rhs when the
+ * lhs is unconstrained:
+ * \code
+ * Default(kDLCPU, -1, "llvm", "local"), (kDLCPU, 3, null, "global"))
+ *   => (kDLCPU, 3, "llvm", "local")
+ * \endcode
+ *
+ * These operations are needed during device planning.
+ */
+
+class VirtualDeviceNode : public AttrsNode<VirtualDeviceNode> {
+ private:
+  /*!
+   * \brief The \p DLDeviceType (represented as an int) of the virtual device. If \p target is
+   * known then this will be equal to \p target->GetTargetDeviceType(). If \p target is null then
+   * the target is to be determined later.
+   *
+   * This is needed to support the legacy "on_device" and "device_copy" calls which only allow
+   * a \p DLDeviceTypes (as an integer) to be given.
+   *
+   * kInvalidDeviceType denotes unconstrained. An int since the DLDeviceType enum representation
+   * is not fixed. Private to discourage further int vs DLDeviceType confusion.
+   */
+  int /* actually DLDeviceType */ device_type_int;
+
+ public:
+  DLDeviceType device_type() const { return static_cast<DLDeviceType>(device_type_int); }
+
+  /*!
+   * \brief The device identifier for the virtual device. This must be resolved to a physical
+   * device identifier either during compilation or at runtime.
+   *
+   * -1 denotes unconstrained.
+   */
+  int virtual_device_id;
+
+  /*!
+   * \brief The \p Target describing how to compile for the virtual device.
+   *
+   * Null denotes unconstrained. Note that if a target later becomes known for this \p VirtualDevice
+   * then it must be consistent with the \p device_type if already known. This is enforced by the
+   * Join and Default methods.
+   */
+  Target target;
+
+  /*!
+   * \brief The scope of memory w.r.t. the virtual device which holds data.
+   *
+   * Empty denotes unconstrained.
+   */
+  MemoryScope memory_scope;
+
+  /*!
+   * \brief Returns true if virtual device is 'fully unconstrained', ie no target/device type,
+   * device id or memory scope is specified.
+   */
+  bool IsFullyUnconstrained() const {
+    return !target.defined() && device_type() == kInvalidDeviceType && virtual_device_id == -1 &&
+           memory_scope.empty();
+  }
+
+  /*!
+   * \brief Returns true if virtual device is 'fully constrained', ie target, device id and memory
+   * scope are all specified.
+   */
+  bool IsFullyConstrained() const {
+    return target.defined() && virtual_device_id != -1 && !memory_scope.empty();
+  }
+
+  /*!
+   * \brief Returns the (virtual) \p Device implied by this \p VirtualDevice. Both the \p
+   * device_type and \p virtual_device_must be constrained. The returned \p Device may not
+   * correspond to any physical device available at compile time or even runtime: see "Virtual vs
+   * Physical Devices" above.
+   */
+  Device ToDevice() const {
+    ICHECK(device_type() != kInvalidDeviceType);
+    ICHECK(virtual_device_id != -1);
+    Device device;
+    device.device_type = device_type();
+    device.device_id = virtual_device_id;
+    return device;
+  }
+
+  TVM_DECLARE_ATTRS(VirtualDeviceNode, "VirtualDevice") {
+    TVM_ATTR_FIELD(device_type_int)
+        .describe("The type of the virtual device.")
+        .set_default(kInvalidDeviceType);
+    TVM_ATTR_FIELD(virtual_device_id)
+        .describe("The device id of the virtual device.")
+        .set_default(-1);
+    TVM_ATTR_FIELD(target)
+        .describe("The target describing how to compile for the virtual device.")
+        .set_default(Target());
+    TVM_ATTR_FIELD(memory_scope)
+        .describe("The area of memory w.r.t. the virtual device where data is stored.")
+        .set_default("");
+  }
+
+  friend class VirtualDevice;
+};
+
+/*!
+ * \brief Managed reference class to \p VirtualDeviceNode.
+ */
+class VirtualDevice : public ObjectRef {
+ public:
+  /*!
+   * \brief Construct a virtual device.
+   * \param device_type The device type for the virtual device, or \p kInvalidDeviceType if
+   * unconstrained.  If \p target is defined then must match its \p target->GetTargetDeviceType().
+   * \param virtual_device_id The device id for the virtual device, or -1 if unconstrained.
+   * \param target The target describing how to compile for the virtual device, or null if
+   * unconstrained.
+   * \param memory_scope The memory scope w.r.t. the virtual device which holds data, or "" if
+   * unconstrained.
+   * \return The virtual device.
+   */
+  explicit VirtualDevice(DLDeviceType device_type = kInvalidDeviceType, int virtual_device_id = -1,
+                         Target target = {}, MemoryScope memory_scope = {});
+
+  /*! \brief Returns the unique fully unconstrained \p VirtualDevice. */
+  static VirtualDevice FullyUnconstrained();
+
+  /*!
+   * \brief Returns the \p VirtualDevice for \p device_type and (if not -1) \p virtual_device_id.
+   * The target and memory scope will be unconstrained.
+   */
+  static VirtualDevice ForDeviceType(DLDeviceType device_type, int virtual_device_id = -1) {
+    ICHECK_GT(device_type, 0);
+    return VirtualDevice(device_type, virtual_device_id);
+  }
+  static VirtualDevice ForDeviceType(int device_type, int virtual_device_id = -1) {
+    return ForDeviceType(static_cast<DLDeviceType>(device_type), virtual_device_id);
+  }
+  static VirtualDevice ForDeviceType(const Integer& device_type, int virtual_device_id = -1) {
+    return ForDeviceType(static_cast<int>(device_type->value), virtual_device_id);
+  }
+
+  /*! \brief Returns the \p VirtualDevice for \p device. */
+  static VirtualDevice ForDevice(const Device& device) {
+    return ForDeviceType(device.device_type, device.device_id);
+  }
+
+  /*! \brief Returns the \p VirtualDevice for \p device and \p target. */
+  static VirtualDevice ForDeviceAndTarget(const Device& device, Target target) {
+    return VirtualDevice(device.device_type, device.device_id, std::move(target));
+  }
+
+  /*! \brief Returns the \p VirtualDevice for \p target. */
+  static VirtualDevice ForTarget(Target target) {
+    DLDeviceType device_type = static_cast<DLDeviceType>(target->GetTargetDeviceType());
+    return VirtualDevice(device_type, /*virtual_device_id=*/0, std::move(target));
+  }
+
+  /*! \brief Returns the \p VirtualDevice for \p memory_scope alone. */
+  static VirtualDevice ForMemoryScope(MemoryScope memory_scope) {
+    return VirtualDevice(kInvalidDeviceType, -1, {}, std::move(memory_scope));
+  }
+
+  /*! \brief Returns the \p VirtualDevice for \p device, \p target and \p memory_scope. */
+  TVM_DLL static VirtualDevice ForDeviceTargetAndMemoryScope(const Device& device, Target target,
+                                                             MemoryScope memory_scope) {
+    return VirtualDevice(device.device_type, device.device_id, std::move(target),
+                         std::move(memory_scope));
+  }
+
+  /*!
+   * \brief Returns the 'join' of \p lhs and \p rhs. The result will agree pointwise with
+   * \p lhs and \p rhs on all their constrained fields. Returns the null optional if no such
+   * join exists, ie there's disagreement on at least one constrained field.
+   */
+  static Optional<VirtualDevice> Join(const VirtualDevice& lhs, const VirtualDevice& rhs);
+
+  /*!
+   * \brief Returns the 'default' of \p lhs and \p rhs. The result will be \p lhs, except any
+   * unconstrained fields in \p lhs will take their value from \p rhs. Always well-defined.
+   */
+  static VirtualDevice Default(const VirtualDevice& lhs, const VirtualDevice& rhs);
+
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(VirtualDevice, ObjectRef, VirtualDeviceNode);
+
+  friend class VirtualDeviceCache;  // Private implementation helper.
+};
+
+/*!
+ * \brief A cache of \p VirtualDevices. This can be used:
+ *  - To avoid ending up with lots of identical instances, since the space of VirtualDevices for any
+ *    one compilation is very small but the number of points they need to be constructed can
+ *    be very large (eg during device planning).
+ *  - So we can assume \p VirtualDevices are pointer equal if and only if they are structurally
+ * equal. This simplifies the unification of 'device domains' which are built on \p VirtualDevices.
+ */
+class VirtualDeviceCache {
+ public:
+  /*! \brief Returns the unique \p VirtualDevice representing given fields. */
+  VirtualDevice Make(DLDeviceType device_type = kInvalidDeviceType, int virtual_device_id = -1,
+                     Target target = {}, MemoryScope memory_scope = {});
+
+  /*!
+   * \brief Returns the unique \p VirtualDevice structurally equal to the given \p virtual_device.
+   */
+  VirtualDevice Unique(const VirtualDevice& virtual_device);
+
+ private:
+  /*! \brief Already constructed VirtualDevices. */
+  std::unordered_set<VirtualDevice, StructuralHash, StructuralEqual> cache_;
+};
+
+/*! brief The attribute key for the virtual device. This key will be promoted to first class on
+ * functions. For use in the parser and printer only.
+ *
+ * Type: VirtualDevice
+ */
+constexpr const char* kVirtualDevice = "virtual_device";
+
+}  // namespace tvm
+
+#endif  //  TVM_TARGET_VIRTUAL_DEVICE_H_
diff --git a/darknet_drp_ros/include/tvm/te/autodiff.h b/darknet_drp_ros/include/tvm/te/autodiff.h
new file mode 100644
index 0000000..e2d3799
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/te/autodiff.h
@@ -0,0 +1,96 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/te/autodiff.h
+ * \brief Automatic differentiation of tensor expressions.
+ */
+
+#ifndef TVM_TE_AUTODIFF_H_
+#define TVM_TE_AUTODIFF_H_
+
+#include <tvm/runtime/object.h>
+#include <tvm/tir/expr.h>
+
+#include "tensor.h"
+
+namespace tvm {
+/*! \brief Tensor expression language DSL. */
+namespace te {
+
+/*!
+ * \brief Take the derivative of the expression with respect to the given variable.
+ * \param expr The expression to differentiate.
+ * \param var The variable to differentiate with respect to.
+ * \return The expression for the derivative.
+ */
+PrimExpr Derivative(const PrimExpr& expr, const Var& var);
+
+/*!
+ * \brief Get the tensor representing the Jacobian of the output with respect to the input.
+ *
+ *  Note that if \p output depends on \p input indirectly (by using some other tensor
+ *  depending on \p input), this dependency won't contribute to the resulting Jacobian.
+ *  For such cases use the function ::Gradient.
+ *
+ * \param output The tensor to differentiate.
+ * \param input The input tensor, which \p output should directly use.
+ * \return The tensor representing the Jacobian of shape `output.shape + input.shape`.
+ */
+Tensor Jacobian(const Tensor& output, const Tensor& input);
+
+/*!
+ * \brief The building block for reverse-mode AD.
+ *
+ *  Differentiate \p output wrt \p input and multiply the result by \p head on the left using tensor
+ *  dot product. \p input must be an immediate dependency of \p output (must be called from within
+ *  the body of \p output). That is, the function will compute one summand of the adjoint for \p
+ * input given the adjoint for \p output (which is called \p head here).
+ *
+ * \param output The tensor to differentiate.
+ * \param input The input tensor, which \p output should directly use.
+ * \param head The adjoint of \p output. Must be of shape `prefix + output.shape`
+ * \return The tensor of shape `prefix + input.shape`
+ *         representing the partial adjoint of \p input wrt one of its consumers (output)
+ */
+Tensor VectorJacobianProduct(const Tensor& output, const Tensor& input, const Tensor& head);
+
+/*!
+ * \brief Perform reverse mode automatic differentiation.
+ *
+ *  Each item of the `result` field of the result is an adjoint for the corresponding item of
+ *  \p inputs, i.e. \p head multiplied by the Jacobian of \p output with respect to the
+ *  corresponding item of \p inputs.
+ *
+ * \param output The tensor to differentiate.
+ * \param inputs The array of input tensors. When the array is empty, will perform differentiation
+ *               wrt all tensors the output depends on.
+ * \param head The adjoint of the output, in other words, some tensor, by which the Jacobians
+ *             will be multiplied (using tensordot axes=`output.shape`).
+ *             Its shape must be of the form `prefix + output.shape`. If the null pointer is
+ * provided, the identity tensor of shape `output.shape + output.shape` will be used. \return An
+ * array of adjoints corresponding to \p inputs.
+ */
+TVM_DLL Array<Tensor> Gradient(const Tensor& output, const Array<Tensor>& inputs,
+                               const Tensor& head = Tensor());
+
+}  // namespace te
+}  // namespace tvm
+
+#endif  // TVM_TE_AUTODIFF_H_
diff --git a/darknet_drp_ros/include/tvm/te/operation.h b/darknet_drp_ros/include/tvm/te/operation.h
new file mode 100644
index 0000000..2c50f3c
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/te/operation.h
@@ -0,0 +1,645 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/te/operation.h
+ * \brief Operation node can generate one or multiple Tensors
+ */
+#ifndef TVM_TE_OPERATION_H_
+#define TVM_TE_OPERATION_H_
+
+#include <tvm/arith/analyzer.h>
+#include <tvm/te/schedule.h>
+#include <tvm/te/tensor.h>
+#include <tvm/tir/buffer.h>
+#include <tvm/tir/expr.h>
+#include <tvm/tir/op.h>
+
+#include <string>
+#include <unordered_map>
+#include <vector>
+
+namespace tvm {
+/*! \brief Tensor expression language DSL. */
+namespace te {
+
+/*!
+ * \brief Temporary data structure to store union
+ *  of bounds of each axis of Tensor.
+ */
+struct TensorDom {
+  // constructor
+  explicit TensorDom(int ndim) : data(ndim) {}
+  /*! \brief The domain data */
+  std::vector<std::vector<IntSet>> data;
+};
+
+/*!
+ * \brief Base class of all operation nodes
+ */
+class TVM_DLL OperationNode : public Object {
+ public:
+  /*! \brief optional name of the operation */
+  std::string name;
+  /*! \brief optional tag of the operation */
+  std::string tag;
+  /*! \brief additional attributes of the operation*/
+  Map<String, ObjectRef> attrs;
+  // virtual destructor.
+  virtual ~OperationNode() {}
+  /*! \return number of outputs */
+  virtual int num_outputs() const = 0;
+  /*!
+   * \return The list of iteration variable at root
+   * \note root_iter_vars decides the shape of the outputs.
+   */
+  virtual Array<IterVar> root_iter_vars() const = 0;
+  /*!
+   * \brief Get data type. i-th output tensor.
+   * \param i The output index.
+   * \return type of i-th output.
+   */
+  virtual DataType output_dtype(size_t i) const = 0;
+  /*!
+   * \brief Get shape of i-th output tensor.
+   * \param i The output index.
+   * \return shape of i-th output.
+   */
+  virtual Array<PrimExpr> output_shape(size_t i) const = 0;
+  /*!
+   * \brief List all the input Tensors.
+   * \return List of input tensors.
+   */
+  virtual Array<Tensor> InputTensors() const = 0;
+  /*!
+   * \brief Replace the input of the operation by pattern specified by rmap.
+   *
+   * \param self The reference to self.
+   * \param rmap The replacement map.
+   * \return self if nothing is replaced, otherwise return replaced op.
+   */
+  virtual Operation ReplaceInputs(const Operation& self,
+                                  const std::unordered_map<Tensor, Tensor>& rmap) const = 0;
+  /*!
+   * \brief Propagate the bounds to inputs
+   * \param self The reference to self.
+   * \param analyzer The analyzer to be used in the function.
+   * \param dom_map the domain map of Variables(corresponds to root_iter_vars)
+   * \param out_dom_map The output domain.
+   *  The function is only asked to fill the bounds for Tensors that
+   *  is already in the out_dom_map
+   */
+  virtual void PropBoundToInputs(const Operation& self, arith::Analyzer* analyzer,
+                                 const std::unordered_map<const VarNode*, IntSet>& dom_map,
+                                 std::unordered_map<Tensor, TensorDom>* out_dom_map) const = 0;
+  /*!
+   * \brief Gather the bound from output tensor.
+   *  Set the range of each root_iter_vars in the op to out_dom_map
+   *
+   * \param self The reference to self.
+   * \param tensor_dom Domain map of Tensor->access set of each dimension.
+   * \param out_dom_map The output domain map of each IterVar to be setted.
+   */
+  virtual void GatherBound(const Operation& self,
+                           const std::unordered_map<Tensor, TensorDom>& tensor_dom,
+                           std::unordered_map<IterVar, Range>* out_dom_map) const = 0;
+  /*!
+   * \brief Build the Realize statement that realizes
+   *   the op's output tensors.
+   * \param stage the op's stage.
+   * \param realize_map The realization domain map of the operators.
+   * \param body The body that is going to get
+   * \param storage_scope The storage scope associated with this realization
+   * \return A realization statement that wraps body.
+   */
+  virtual Stmt BuildRealize(const Stage& stage,
+                            const std::unordered_map<IterVar, Range>& realize_map, const Stmt& body,
+                            String storage_scope = "") const = 0;
+  /*!
+   * \brief Build the statement that provide the output tensors.
+   * \param stage The schedule stage of the op.
+   * \param dom_map The domain map of all iteration domains.
+   * \param debug_keep_trivial_loop Whether keep trivial loops with extent of 1
+   * \return A statement that add production and wraps consumer.
+   */
+  virtual Stmt BuildProvide(const Stage& stage, const std::unordered_map<IterVar, Range>& dom_map,
+                            bool debug_keep_trivial_loop) const = 0;
+
+  static constexpr const char* _type_key = "Operation";
+
+  TVM_DECLARE_BASE_OBJECT_INFO(OperationNode, Object);
+};
+
+/*!
+ * \brief A placeholder op represents an input placeholder.
+ */
+class PlaceholderOpNode : public OperationNode {
+ public:
+  /*! \brief The shape of the input */
+  Array<PrimExpr> shape;
+  /*! \brief The data type of the input. */
+  DataType dtype;
+  // override behavior.
+  int num_outputs() const final;
+  Array<IterVar> root_iter_vars() const final;
+  DataType output_dtype(size_t i) const final;
+  Array<PrimExpr> output_shape(size_t i) const final;
+  Array<Tensor> InputTensors() const final;
+  Operation ReplaceInputs(const Operation& self,
+                          const std::unordered_map<Tensor, Tensor>& rmap) const final;
+  void PropBoundToInputs(const Operation& self, arith::Analyzer* analyzer,
+                         const std::unordered_map<const VarNode*, IntSet>& dom_map,
+                         std::unordered_map<Tensor, TensorDom>* out_dom_map) const final;
+  void GatherBound(const Operation& self, const std::unordered_map<Tensor, TensorDom>& tensor_dom,
+                   std::unordered_map<IterVar, Range>* out_dom_map) const final;
+  Stmt BuildRealize(const Stage& stage, const std::unordered_map<IterVar, Range>& realize_map,
+                    const Stmt& body, String storage_scope = "") const final;
+  Stmt BuildProvide(const Stage& stage, const std::unordered_map<IterVar, Range>& dom_map,
+                    bool debug_keep_trivial_loop) const final;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("name", &name);
+    v->Visit("tag", &tag);
+    v->Visit("attrs", &attrs);
+    v->Visit("shape", &shape);
+    v->Visit("dtype", &dtype);
+  }
+
+  static constexpr const char* _type_key = "PlaceholderOp";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PlaceholderOpNode, OperationNode);
+};
+
+/*!
+ * \brief Managed reference to PlaceholderOpNode
+ * \sa PlaceholderOpNode
+ */
+class PlaceholderOp : public Operation {
+ public:
+  TVM_DLL PlaceholderOp(std::string name, Array<PrimExpr> shape, DataType dtype);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(PlaceholderOp, Operation, PlaceholderOpNode);
+};
+
+/*!
+ * \brief A Compute op that compute a tensor on certain domain.
+ * This is the base class for ComputeOp (operating on a scalar at a time) and
+ * TensorComputeOp (operating on a TensorSlice at a time)
+ */
+class TVM_DLL BaseComputeOpNode : public OperationNode {
+ public:
+  /*! \brief IterVar on each axis */
+  Array<IterVar> axis;
+  /*! \brief IterVar on each reduction axis, if the body is a Reduce */
+  Array<IterVar> reduce_axis;
+  // override functions
+  Array<IterVar> root_iter_vars() const final;
+  Array<PrimExpr> output_shape(size_t idx) const final;
+  void GatherBound(const Operation& self, const std::unordered_map<Tensor, TensorDom>& tensor_dom,
+                   std::unordered_map<IterVar, Range>* out_dom_map) const final;
+  Stmt BuildRealize(const Stage& stage, const std::unordered_map<IterVar, Range>& realize_map,
+                    const Stmt& body, String storage_scope = "") const final;
+  virtual size_t num_schedulable_dims() const = 0;
+
+  static constexpr const char* _type_key = "BaseComputeOp";
+  TVM_DECLARE_BASE_OBJECT_INFO(BaseComputeOpNode, OperationNode);
+};
+
+/*!
+ * \brief A Compute op that compute a tensor on certain domain.
+ */
+class TVM_DLL ComputeOpNode : public BaseComputeOpNode {
+ public:
+  /*! \brief the compute expression */
+  Array<PrimExpr> body;
+  /*! \brief constructor */
+  ComputeOpNode() {}
+  // override functions
+  int num_outputs() const final;
+  DataType output_dtype(size_t i) const final;
+  Array<Tensor> InputTensors() const final;
+  Operation ReplaceInputs(const Operation& self,
+                          const std::unordered_map<Tensor, Tensor>& rmap) const final;
+  void PropBoundToInputs(const Operation& self, arith::Analyzer* analyzer,
+                         const std::unordered_map<const VarNode*, IntSet>& dom_map,
+                         std::unordered_map<Tensor, TensorDom>* out_dom_map) const final;
+  Stmt BuildProvide(const Stage& stage, const std::unordered_map<IterVar, Range>& dom_map,
+                    bool debug_keep_trivial_loop) const final;
+  size_t num_schedulable_dims() const final;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("name", &name);
+    v->Visit("tag", &tag);
+    v->Visit("attrs", &attrs);
+    v->Visit("axis", &axis);
+    v->Visit("reduce_axis", &reduce_axis);
+    v->Visit("body", &body);
+  }
+
+  static constexpr const char* _type_key = "ComputeOp";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ComputeOpNode, BaseComputeOpNode);
+};
+
+/*!
+ * \brief Managed reference to ComputeOpNode
+ * \sa ComputeOpNode
+ */
+class ComputeOp : public Operation {
+ public:
+  TVM_DLL ComputeOp(std::string name, std::string tag, Map<String, ObjectRef> attrs,
+                    Array<IterVar> axis, Array<PrimExpr> body);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(ComputeOp, Operation, ComputeOpNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(ComputeOpNode);
+};
+
+/*!
+ * \brief A TenorCompute op that compute a tensor with an tensor intrinsic.
+ */
+class TensorComputeOpNode : public BaseComputeOpNode {
+ public:
+  /*! \brief number of axes that can be scheduled */
+  int schedulable_ndim;
+  /*! \brief TensorIntrin used to compute */
+  TensorIntrin intrin;
+  /*! \brief input tensors of intrin */
+  Array<Tensor> inputs;
+  /*! \brief region of input tensors */
+  Array<Region> input_regions;
+  /*! \brief scalar expression inputs */
+  Array<PrimExpr> scalar_inputs;
+  /*! \brief constructor */
+  TensorComputeOpNode() {}
+  // override functions
+  int num_outputs() const final;
+  DataType output_dtype(size_t i) const final;
+  Array<Tensor> InputTensors() const final;
+  Operation ReplaceInputs(const Operation& self,
+                          const std::unordered_map<Tensor, Tensor>& rmap) const final;
+  void PropBoundToInputs(const Operation& self, arith::Analyzer* analyzer,
+                         const std::unordered_map<const VarNode*, IntSet>& dom_map,
+                         std::unordered_map<Tensor, TensorDom>* out_dom_map) const final;
+  Stmt BuildProvide(const Stage& stage, const std::unordered_map<IterVar, Range>& dom_map,
+                    bool debug_keep_trivial_loop) const final;
+  size_t num_schedulable_dims() const final;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("name", &name);
+    v->Visit("tag", &tag);
+    v->Visit("axis", &axis);
+    v->Visit("reduce_axis", &reduce_axis);
+    v->Visit("schedulable_ndim", &schedulable_ndim);
+    v->Visit("intrin", &intrin);
+    v->Visit("inputs", &inputs);
+    v->Visit("input_regions", &input_regions);
+    v->Visit("scalar_inputs", &scalar_inputs);
+  }
+
+  static constexpr const char* _type_key = "TensorComputeOp";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TensorComputeOpNode, BaseComputeOpNode);
+};
+
+/*!
+ * \brief Managed reference to TensorComputeOpNode
+ * \sa TensorComputeOpNode
+ */
+class TensorComputeOp : public Operation {
+ public:
+  TVM_DLL TensorComputeOp(std::string name, std::string tag, Array<IterVar> axis,
+                          Array<IterVar> reduce_axis, int schedulable_ndim, TensorIntrin intrin,
+                          Array<Tensor> tensors, Array<Region> regions,
+                          Array<PrimExpr> scalar_inputs);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(TensorComputeOp, Operation, TensorComputeOpNode);
+};
+
+/*!
+ * \brief Symbolic scan.
+ */
+class ScanOpNode : public OperationNode {
+ public:
+  /*! \brief IterVar to scan over */
+  IterVar scan_axis;
+  /*! \brief the initialization tensors */
+  Array<Tensor> init;
+  /*! \brief the update function represented by tensor */
+  Array<Tensor> update;
+  /*! \brief The placeholder to refer as states in update. */
+  Array<Tensor> state_placeholder;
+  /*!
+   * \brief the inputs to the scan, these are optionally provided
+   *  But they can be helpful to provide hints to speedup get of scan body.
+   */
+  Array<Tensor> inputs;
+  /*!
+   * \brief Spatial axis to indicate spatial dimension of each output.
+   *  They corresponds to flattened spatial axis of the outputs.
+   *
+   *  [output[0].axis[1], output[0].axis[2]... output[k].axis[j]...]
+   *  These are auxiliary data structure for storing result of bound inference.
+   *  They do not corresponds to splittable iterations, thus the name comes
+   *  with underscore.
+   */
+  Array<IterVar> spatial_axis_;
+  /*! \brief constructor */
+  ScanOpNode() {}
+  // override behavior.
+  int num_outputs() const final;
+  Array<IterVar> root_iter_vars() const final;
+  DataType output_dtype(size_t i) const final;
+  Array<PrimExpr> output_shape(size_t i) const final;
+  Array<Tensor> InputTensors() const final;
+  Operation ReplaceInputs(const Operation& self,
+                          const std::unordered_map<Tensor, Tensor>& rmap) const final;
+  void PropBoundToInputs(const Operation& self, arith::Analyzer* analyzer,
+                         const std::unordered_map<const VarNode*, IntSet>& dom_map,
+                         std::unordered_map<Tensor, TensorDom>* out_dom_map) const final;
+  void GatherBound(const Operation& self, const std::unordered_map<Tensor, TensorDom>& tensor_dom,
+                   std::unordered_map<IterVar, Range>* out_dom_map) const final;
+  Stmt BuildRealize(const Stage& stage, const std::unordered_map<IterVar, Range>& realize_map,
+                    const Stmt& body, String storage_scope = "") const final;
+  Stmt BuildProvide(const Stage& stage, const std::unordered_map<IterVar, Range>& dom_map,
+                    bool debug_keep_trivial_loop) const final;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("name", &name);
+    v->Visit("tag", &tag);
+    v->Visit("attrs", &attrs);
+    v->Visit("scan_axis", &scan_axis);
+    v->Visit("init", &init);
+    v->Visit("update", &update);
+    v->Visit("state_placeholder", &state_placeholder);
+    v->Visit("inputs", &inputs);
+    v->Visit("spatial_axis_", &spatial_axis_);
+  }
+
+  static constexpr const char* _type_key = "ScanOp";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ScanOpNode, OperationNode);
+};
+
+/*!
+ * \brief Managed reference to ScanOpNode
+ * \sa ScanOpNode
+ */
+class ScanOp : public Operation {
+ public:
+  TVM_DLL ScanOp(std::string name, std::string tag, Map<String, ObjectRef> attrs, IterVar axis,
+                 Array<Tensor> init, Array<Tensor> update, Array<Tensor> state_placeholder,
+                 Array<Tensor> input);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(ScanOp, Operation, ScanOpNode);
+};
+
+/*!
+ * \brief External computation that cannot be splitted.
+ */
+class ExternOpNode : public OperationNode {
+ public:
+  /*! \brief The input tensors */
+  Array<Tensor> inputs;
+  /*! \brief Symbolic placeholder representation of inputs */
+  Array<Buffer> input_placeholders;
+  /*! \brief Symbolic placeholder representation of outputs */
+  Array<Buffer> output_placeholders;
+  /*! \brief the statement that generates the computation. */
+  Stmt body;
+
+  /*! \brief constructor */
+  ExternOpNode() {}
+  // override functions
+  int num_outputs() const final;
+  Array<IterVar> root_iter_vars() const final;
+  DataType output_dtype(size_t i) const final;
+  Array<PrimExpr> output_shape(size_t i) const final;
+  Array<Tensor> InputTensors() const final;
+  Operation ReplaceInputs(const Operation& self,
+                          const std::unordered_map<Tensor, Tensor>& rmap) const final;
+  void PropBoundToInputs(const Operation& self, arith::Analyzer* analyzer,
+                         const std::unordered_map<const VarNode*, IntSet>& dom_map,
+                         std::unordered_map<Tensor, TensorDom>* out_dom_map) const final;
+  void GatherBound(const Operation& self, const std::unordered_map<Tensor, TensorDom>& tensor_dom,
+                   std::unordered_map<IterVar, Range>* out_dom_map) const final;
+  Stmt BuildRealize(const Stage& stage, const std::unordered_map<IterVar, Range>& realize_map,
+                    const Stmt& body, String storage_scope = "") const final;
+  Stmt BuildProvide(const Stage& stage, const std::unordered_map<IterVar, Range>& dom_map,
+                    bool debug_keep_trivial_loop) const final;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("name", &name);
+    v->Visit("tag", &tag);
+    v->Visit("attrs", &attrs);
+    v->Visit("inputs", &inputs);
+    v->Visit("input_placeholders", &input_placeholders);
+    v->Visit("output_placeholders", &output_placeholders);
+    v->Visit("body", &body);
+  }
+
+  static constexpr const char* _type_key = "ExternOp";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ExternOpNode, OperationNode);
+};
+
+/*!
+ * \brief Managed reference to ExternOpNode
+ * \sa ExternOpNode
+ */
+class ExternOp : public Operation {
+ public:
+  TVM_DLL ExternOp(std::string name, std::string tag, Map<String, ObjectRef> attrs,
+                   Array<Tensor> inputs, Array<Buffer> input_placeholders,
+                   Array<Buffer> output_placeholders, Stmt body);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(ExternOp, Operation, ExternOpNode);
+};
+
+/*!
+ * \brief A computation operator that generated by hybrid script.
+ */
+class HybridOpNode : public OperationNode {
+ public:
+  /*! \brief The input tensors */
+  Array<Tensor> inputs;
+  /*! \brief Symbolic placeholder representation of outputs */
+  Array<Tensor> outputs;
+  /*! \brief The axis of iterations */
+  Array<IterVar> axis;
+  /*! \brief the statement that generates the computation. This is
+   * slightly different from the body in ExternOpNode. All the output
+   * tensors keep its own name specified by users in the script.
+   * However, when compilation, these tensors will be placed by those
+   * actual output tensors. */
+  Stmt body;
+
+  /*! \brief constructor */
+  HybridOpNode() {}
+  // override functions
+  int num_outputs() const final;
+  Array<IterVar> root_iter_vars() const final;
+  DataType output_dtype(size_t i) const final;
+  Array<PrimExpr> output_shape(size_t i) const final;
+  Array<Tensor> InputTensors() const final;
+  Operation ReplaceInputs(const Operation& self,
+                          const std::unordered_map<Tensor, Tensor>& rmap) const final;
+  void PropBoundToInputs(const Operation& self, arith::Analyzer* analyzer,
+                         const std::unordered_map<const VarNode*, IntSet>& dom_map,
+                         std::unordered_map<Tensor, TensorDom>* out_dom_map) const final;
+  void GatherBound(const Operation& self, const std::unordered_map<Tensor, TensorDom>& tensor_dom,
+                   std::unordered_map<IterVar, Range>* out_dom_map) const final;
+  Stmt BuildRealize(const Stage& stage, const std::unordered_map<IterVar, Range>& realize_map,
+                    const Stmt& body, String storage_scope = "") const final;
+  Stmt BuildProvide(const Stage& stage, const std::unordered_map<IterVar, Range>& dom_map,
+                    bool debug_keep_trivial_loop) const final;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("name", &name);
+    v->Visit("tag", &tag);
+    v->Visit("attrs", &attrs);
+    v->Visit("inputs", &inputs);
+    v->Visit("outputs", &outputs);
+    v->Visit("axis", &axis);
+    v->Visit("body", &body);
+  }
+
+  static constexpr const char* _type_key = "HybridOp";
+  TVM_DECLARE_FINAL_OBJECT_INFO(HybridOpNode, OperationNode);
+};
+
+/*!
+ * \brief Managed reference to HybridOpNode
+ * \sa HybridOpNode
+ */
+class HybridOp : public Operation {
+ public:
+  TVM_DLL HybridOp(std::string name, std::string tag, Map<String, ObjectRef> attrs,
+                   Array<Tensor> inputs, Array<Tensor> outputs, Stmt body);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(HybridOp, Operation, HybridOpNode);
+};
+
+/*!
+ * \brief Construct a new Var expression
+ * \param name_hint The name hint for the expression
+ * \param t The type of the expression
+ */
+TVM_DLL Var var(std::string name_hint, DataType t = DataType::Int(32));
+
+/*!
+ * \brief Create a new IterVar that represents an axis in thread.
+ *
+ * \param dom Optional, domain of the thread axis.
+ * \param tag The thread tag of the axis.
+ */
+TVM_DLL IterVar thread_axis(Range dom, std::string tag);
+
+/*!
+ * \brief Create a new IterVar for reduction operations.
+ *
+ * \param dom The domain of the reduction axis.
+ * \param name The name of the reduction axis.
+ */
+TVM_DLL IterVar reduce_axis(Range dom, std::string name = "rv");
+
+/*! \brief The compute function to specify the input source of a Tensor */
+using FCompute = std::function<PrimExpr(const Array<Var>& i)>;
+
+/*! \brief The compute function to specify the inputs source of Tensors */
+using FBatchCompute = std::function<Array<PrimExpr>(const Array<Var>& i)>;
+
+/*!
+ * \brief create a place holder tensor.
+ * \param shape The shape of the tensor.
+ * \param dtype the data type of the tensor.
+ * \param name The name of the Tensor.
+ */
+TVM_DLL Tensor placeholder(Array<PrimExpr> shape, DataType dtype = DataType::Float(32),
+                           std::string name = "placeholder");
+
+/*!
+ * \brief Construct a new tensor by computing over shape,
+ *  using the computation rule: result_tensor[axis] = fcompute(axis)
+ * \param shape Shape of the tensor.
+ * \param fcompute The compute function to create the tensor.
+ * \param name The optional name of the tensor.
+ * \param tag The optional tag of the tensor.
+ * \param attrs Optional additional attributes of the compute.
+ */
+TVM_DLL Tensor compute(Array<PrimExpr> shape, FCompute fcompute, std::string name = "tensor",
+                       std::string tag = "", Map<String, ObjectRef> attrs = {});
+
+/*!
+ * \brief Construct a new tensor by computing over shape,
+ *  using the computation rule: result_tensor[axis] = fcompute(axis)
+ * \param shape Shape of the tensor.
+ * \param fcompute The compute function to create the tensors.
+ * \param name The optional name of the tensor.
+ * \param tag The optional tag of the tensor.
+ * \param attrs Optional additional attributes of the compute.
+ */
+TVM_DLL Array<Tensor> compute(Array<PrimExpr> shape, FBatchCompute fcompute,
+                              std::string name = "tensor", std::string tag = "",
+                              Map<String, ObjectRef> attrs = {});
+
+/*!
+ * \brief Construct new tensors by scan.
+ *
+ * \param init The intialize tensor of first K steps.
+ * \param update The update tensor indicated the updated result after each timestamp.
+ * \param state_placeholder The placeholder for the states.
+ * \param inputs The inputs to the scan body, this is optional,
+ *    but recommended to provide concrete information about scan body.
+ * \param name The optional name of the tensor.
+ * \param tag The optional tag of the tensor.
+ * \param attrs Optional additional attributes of the compute.
+ */
+TVM_DLL Array<Tensor> scan(Array<Tensor> init, Array<Tensor> update,
+                           Array<Tensor> state_placeholder, Array<Tensor> inputs = Array<Tensor>(),
+                           std::string name = "scan", std::string tag = "",
+                           Map<String, ObjectRef> attrs = {});
+
+// same as compute, specialized for different fcompute function
+inline Tensor compute(Array<PrimExpr> shape, std::function<PrimExpr(Var)> f,
+                      std::string name = "tensor", std::string tag = "",
+                      Map<String, ObjectRef> attrs = {}) {
+  FCompute fc = [f](const Array<Var>& i) { return f(i[0]); };
+  return compute(shape, fc, name, tag, attrs);
+}
+inline Tensor compute(Array<PrimExpr> shape, std::function<PrimExpr(Var, Var)> f,
+                      std::string name = "tensor", std::string tag = "",
+                      Map<String, ObjectRef> attrs = {}) {
+  FCompute fc = [f](const Array<Var>& i) { return f(i[0], i[1]); };
+  return compute(shape, fc, name, tag, attrs);
+}
+inline Tensor compute(Array<PrimExpr> shape, std::function<PrimExpr(Var, Var, Var)> f,
+                      std::string name = "tensor", std::string tag = "",
+                      Map<String, ObjectRef> attrs = {}) {
+  FCompute fc = [f](const Array<Var>& i) { return f(i[0], i[1], i[2]); };
+  return compute(shape, fc, name, tag, attrs);
+}
+inline Tensor compute(Array<PrimExpr> shape, std::function<PrimExpr(Var, Var, Var, Var)> f,
+                      std::string name = "tensor", std::string tag = "",
+                      Map<String, ObjectRef> attrs = {}) {
+  FCompute fc = [f](const Array<Var>& i) { return f(i[0], i[1], i[2], i[3]); };
+  return compute(shape, fc, name, tag, attrs);
+}
+
+// inline function.
+inline const OperationNode* Operation::operator->() const {
+  return static_cast<const OperationNode*>(get());
+}
+}  // namespace te
+}  // namespace tvm
+#endif  // TVM_TE_OPERATION_H_
diff --git a/darknet_drp_ros/include/tvm/te/schedule.h b/darknet_drp_ros/include/tvm/te/schedule.h
new file mode 100644
index 0000000..5d88793
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/te/schedule.h
@@ -0,0 +1,958 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/te/schedule.h
+ * \brief Define a schedule.
+ */
+// Acknowledgement: Many schedule primitives originate from Halide and Loopy.
+#ifndef TVM_TE_SCHEDULE_H_
+#define TVM_TE_SCHEDULE_H_
+
+#include <tvm/support/with.h>
+#include <tvm/te/tensor.h>
+#include <tvm/te/tensor_intrin.h>
+#include <tvm/tir/expr.h>
+#include <tvm/tir/index_map.h>
+
+#include <string>
+#include <unordered_map>
+
+namespace tvm {
+namespace te {
+// Node container for Stage
+class StageNode;
+// Node container for Schedule
+class ScheduleNode;
+// Node container for IterVarRelation
+class IterVarRelationNode;
+// Attribute of itervar.
+class IterVarAttrNode;
+
+/*! \brief the attachment type */
+enum AttachType : int {
+  kGroupRoot = 1,
+  kInline = 2,
+  kInlinedAlready = 3,
+  kScope = 4,
+  kScanUpdate = 5
+};
+
+/*! \brief Stage, contains scheduling for a stage of computation. */
+class Stage : public ObjectRef {
+ public:
+  Stage() {}
+  explicit Stage(ObjectPtr<Object> n) : ObjectRef(n) {}
+  /*!
+   * \brief create a new schedule for op.
+   * \param op The operator in the schedule
+   */
+  explicit Stage(Operation op);
+  /*!
+   * \brief access the internal node container
+   * \return the pointer to the internal node container
+   */
+  inline const StageNode* operator->() const;
+  /*!
+   * \brief access the internal node container
+   * \return the pointer to the internal node container
+   */
+  inline StageNode* operator->();
+  /*!
+   * \brief set the memory scope of the stage
+   * \param scope The memory scope.
+   */
+  TVM_DLL Stage& set_scope(std::string scope);  // NOLINT(*)
+  /*!
+   * \brief specify the schedule to be computed at the parent schedule's scope.
+   * \param parent The parent schedule.
+   * \param scope The iteration point to carry the schedule.
+   * \return reference to self.
+   */
+  TVM_DLL Stage& compute_at(Stage parent, IterVar scope);  // NOLINT(*)
+  /*!
+   * \brief Compute the function inline.
+   * \return reference to self.
+   */
+  TVM_DLL Stage& compute_inline();  // NOLINT(*)
+  /*!
+   * \brief Compute the function at group root.
+   * \return reference to self.
+   */
+  TVM_DLL Stage& compute_root();  // NOLINT(*)
+  /*!
+   * \brief Bind the IterVar to thread index.
+   *
+   * \param ivar The IterVar to be bound.
+   * \param thread_ivar The thread axis to be bound.
+   * \return reference to self.
+   */
+  TVM_DLL Stage& bind(IterVar ivar, IterVar thread_ivar);
+  /*!
+   * \brief Set the predicate to determine whether a store to the array should be performed.
+   *  Use this when there are multiple threads performing the same store and we only
+   *  need one of them to do the store.
+   *
+   * \note This is a dangerous scheduling primitive that can change behavior of program.
+   *    Only do when we are certain that thare are duplicated stores.
+   * \param predicate The condition to be checked.
+   * \return reference to self.
+   */
+  TVM_DLL Stage& set_store_predicate(PrimExpr predicate);
+  /*!
+   * \brief Specify environment threads that launched around the group's scope.
+   *  This can only be used in group stage.
+   * \param threads The threads to be launched around the scope.
+   * \note Each thread can only appear in one env_threads.
+   *    This is a beta feature.
+   * \return reference to self.
+   */
+  TVM_DLL Stage& env_threads(Array<IterVar> threads);
+  /*!
+   * \brief Split the parent by factor, generate
+   * \param parent The parent iteration domain.
+   * \param factor The split factor of the loop.
+   * \param p_outer The result outer domain
+   * \param p_inner The result inner domain.
+   * \return reference to self.
+   */
+  TVM_DLL Stage& split(IterVar parent, PrimExpr factor, IterVar* p_outer,
+                       IterVar* p_inner);  // NOLINT(*)
+  /*!
+   * \brief Split the iteration with given number of parts.
+   *
+   * \param parent The parent domain.
+   * \param nparts The number of parts in the outer domain.
+   * \param p_outer The result outer domain.
+   * \param p_inner The result inner domain.
+   * \return reference to self.
+   */
+  TVM_DLL Stage& split_by_nparts(IterVar parent, PrimExpr nparts, IterVar* p_outer,
+                                 IterVar* p_inner);  // NOLINT(*)
+  /*!
+   * \brief Fuse the inner outer domain to the target
+   * \param outer The outer domain to be fused.
+   * \param inner The inner domain to be fused
+   * \param p_target The result target domain.
+   * \return reference to self.
+   */
+  TVM_DLL Stage& fuse(IterVar outer, IterVar inner, IterVar* p_target);  // NOLINT(*)
+  /*!
+   * \brief Fuse all the axes together into a single axis.
+   *
+   * \param axes All the axes to be fused.
+   * \param p_target The result target domain.
+   *
+   * \note axes can be an empty array,
+   *       in that case, a singleton IterVar is created and
+   *       inserted to the outermost loop.
+   *       The fuse of empty array is used to support zero-dimension tensors.
+   *
+   * \return reference to self.
+   */
+  TVM_DLL Stage& fuse(const Array<IterVar>& axes, IterVar* p_target);  // NOLINT(*)
+  /*!
+   * \brief Reorder the iteration
+   * \param order The order of iteration variable.
+   * \return reference to self.
+   */
+  TVM_DLL Stage& reorder(const Array<IterVar>& order);  // NOLINT(*)
+  /*!
+   * \brief Perform tiling on two dimensions
+   *  The final loop order from outmost to inner most are
+   *  [x_outer, y_outer, x_inner, y_inner]
+   *
+   * \param x_parent The original x dimension
+   * \param y_parent The original y dimension
+   * \param x_factor The stride factor on x axis
+   * \param y_factor The stride factor on y axis
+   * \param p_x_outer Outer axis of x dimension
+   * \param p_y_outer Outer axis of y dimension
+   * \param p_x_inner Inner axis of x dimension
+   * \param p_y_inner Inner axis of y dimension
+   * \return reference to self.
+   */
+  TVM_DLL Stage& tile(IterVar x_parent, IterVar y_parent,  // NOLINT(*)
+                      PrimExpr x_factor, PrimExpr y_factor, IterVar* p_x_outer, IterVar* p_y_outer,
+                      IterVar* p_x_inner, IterVar* p_y_inner);
+  /*!
+   * \brief Vectorize iteration.
+   * \param var The axis to be vectorized.
+   * \return reference to self.
+   */
+  TVM_DLL Stage& vectorize(IterVar var);  // NOLINT(*)
+  /*!
+   * \brief Replace computation of the current stage by tensor intrinsic f.
+   * \param var The axis marks beginning of tensorization.
+   *  Every operations inside the axis(include axis itself is tensorized).
+   * \param f The Tensor compute intrinsics.
+   * \return reference to self.
+   */
+  TVM_DLL Stage& tensorize(IterVar var, TensorIntrin f);  // NOLINT(*)
+  /*!
+   * \brief Unroll iteration.
+   * \param var The axis to be unrolled.
+   * \return reference to self.
+   */
+  TVM_DLL Stage& unroll(IterVar var);  // NOLINT(*)
+  /*!
+   * \brief Parallelize iteration.
+   * \param var The axis to be parallelized.
+   * \return reference to self.
+   */
+  TVM_DLL Stage& parallel(IterVar var);  // NOLINT(*)
+  /*!
+   * \brief Annotate the iteration with pragma
+   *
+   * \param var The axis to be parallelized.
+   * \param pragma_type The pragma type.
+   * \param pragma_value The pragma value
+   *
+   * \return reference to self.
+   */
+  TVM_DLL Stage& pragma(IterVar var, const std::string& pragma_type,
+                        const PrimExpr& pragma_value = PrimExpr());  // NOLINT(*)
+  /*!
+   * \brief Fetch data in advance.
+   * \param domain the tensor to be prefetched
+   * \param var the iteration point at which to apply prefetching
+   * \param offset the number of iterations be to fetched in advance
+   * \return reference to self
+   */
+  TVM_DLL Stage& prefetch(const Tensor& domain, IterVar var, PrimExpr offset);  // NOLINT(*)
+  /*!
+   * \brief Set alignment requirement for specific dimension.
+   *
+   *  Such that stride[axis] == k * factor + offset for some k.
+   *
+   * \param axis The dimension to be specified for alignment.
+   * \param factor The factor multiple of alignment
+   * \param offset The required offset factor.
+   * \return reference to self
+   */
+  TVM_DLL Stage& storage_align(IterVar axis, int factor, int offset);  // NOLINT(*)
+  /*!
+   * \brief Compute current stage with double buffering.
+   * \return reference to self.
+   */
+  TVM_DLL Stage& double_buffer();  // NOLINT(*)
+  /*!
+   * \brief Compute current stage with rolling buffering.
+   * \return reference to self.
+   */
+  TVM_DLL Stage& rolling_buffer();  // NOLINT(*)
+  /*!
+   * \brief Defines a layout transformation to be applied to the buffer.
+   *
+   * The map from initial_index to final_index must be an
+   * invertible affine transformation.
+   *
+   * \param initial_indices An array of variables to represent a
+   * value's location in the tensor, using the pre-transformation
+   * layout.  These variables are used as binding occurrences to
+   * represent the initial indices when applying the initial->final
+   * mapping, and should not occur elsewhere in the
+   * Schedule. (i.e. Pass in newly constructed variables, not the
+   * initial IterVar::var)
+   *
+   * \param final_indices An array of expressions, giving the
+   * value's location in the tensor, using the post-transformation layout.
+   * Expressions should be in terms of the variables given in
+   * initial_indices.
+   *
+   * \param out_iter_vars An optional output location for the updated
+   * loop iteration variables.
+   *
+   * \return reference to self
+   */
+  TVM_DLL Stage& transform_layout(const Array<Var>& initial_indices,
+                                  const Array<PrimExpr>& final_indices,
+                                  Array<IterVar>* out_iter_vars = nullptr);
+  /*! \brief Defines separators between groups of axes.
+   *
+   * Used to define `BufferNode::axis_separators`, which has
+   * additional details.
+   *
+   * \param axis_separators A list of axis separators.
+   */
+  TVM_DLL Stage& set_axis_separators(const Array<IntImm>& axis_separators);
+  /*!
+   * \brief whether the stage has been scheduled.
+   * \return whether the stage has been scheduled.
+   */
+  bool is_scheduled() const;
+  /*!
+   * \brief Get attachment spec of current stage.
+   *  If the stage compute at Group root, this function
+   *  will traverse the group function to get the
+   *  final spec from the group.
+   * \return A stage representing the attach spec of the group.
+   */
+  Stage GetAttachSpec() const;
+  // declare container type
+  using ContainerType = StageNode;
+};
+
+/*!
+ * \brief Global schedule container
+ *  For operations and all the operations they depend on.
+ *  The schedule per Operation is named as stage.
+ */
+class Schedule : public ObjectRef {
+ public:
+  Schedule() {}
+  explicit Schedule(ObjectPtr<Object> n) : ObjectRef(n) {}
+  /*!
+   * \brief Create a schedule for array of ops(and their dependencies).
+   * \param ops The ops to be scheduled.
+   * \return sch The created Schedule.
+   */
+  TVM_DLL explicit Schedule(Array<Operation> ops);
+  /*!
+   * \brief Get a copy of current schedule.
+   * \return The copied schedule.
+   */
+  Schedule copy() const;
+  /*!
+   * \brief Get the stage corresponds to the op
+   * \param op The operation.
+   */
+  TVM_DLL Stage operator[](const Operation& op);
+  /*!
+   * \brief Short hand for getting the stage of tensor's operation.
+   * \param tensor The tensor
+   * \return The stage corresponding to the tensor's op
+   */
+  TVM_DLL Stage operator[](const Tensor& tensor) { return this->operator[](tensor->op); }
+  /*!
+   * \brief Create a new stage group for all intermediate
+   *  operations between inputs and outputs.
+   *
+   * \param outputs The output boundary of the group.
+   * \param inputs The input boundary of the group.
+   * \param include_inputs Whether include inputs if they are reachable from outputs.
+   * \return The new grouped stage.
+   */
+  TVM_DLL Stage create_group(const Array<Tensor>& outputs, const Array<Tensor>& inputs,
+                             bool include_inputs = false);
+  /*!
+   * \brief create a cache read of original tensor for readers.
+   *  This will mutate the body of the readers.
+   *  A new stage will be created for the tensor.
+   * \param tensor The tensor cached.
+   * \param scope The scope of the cache.
+   * \param readers The readers to redirect to the tensor.
+   * \return The created tensor.
+   */
+  TVM_DLL Tensor cache_read(const Tensor& tensor, const std::string& scope,
+                            const Array<Operation>& readers);
+  /*!
+   * \brief Create a cache write tensor for producing tensor.
+   *  The tensor will take over body of original tensor op.
+   *
+   *  This function can be used to do data layout transformation.
+   *  If there is a split/fuse/reorder on the data parallel axis of tensor
+   *  before cache_write is called. The intermediate cache stores
+   *  the data in the layout as the iteration order of leave axis.
+   *  The data will be transformed back to the original layout in the original tensor.
+   *  User can further call compute_inline to inline the original layout and keep
+   *  the data stored in the transformed layout.
+   *
+   * \param tensor The tensors to be produced.
+   * \param scope The scope of the storage.
+   * \return The created tensor.
+   */
+  TVM_DLL Array<Tensor> cache_write(const Array<Tensor>& tensor, const std::string& scope);
+  /*!
+   * \brief Create a cache write tensor for producing tensor.
+   *  The tensor will take over body of original tensor op.
+   *
+   *  This function can be used to do data layout transformation.
+   *  If there is a split/fuse/reorder on the data parallel axis of tensor
+   *  before cache_write is called. The intermediate cache stores
+   *  the data in the layout as the iteration order of leave axis.
+   *  The data will be transformed back to the original layout in the original tensor.
+   *  User can further call compute_inline to inline the original layout and keep
+   *  the data stored in the transformed layout.
+   *
+   * \param tensor The tensor to be produced.
+   * \param scope The scope of the storage.
+   * \return The created tensor.
+   */
+  TVM_DLL Tensor cache_write(const Tensor& tensor, const std::string& scope);
+  /*!
+   * \brief Factor a reduction axis in tensor's schedule to be an explicit axis.
+   * This will create a new stage that generated the new tensor with axis
+   * as the first dimension. The tensor's body will be rewritten as a reduction
+   * over the factored tensor.
+   *
+   *  P. Suriana, A. Adams and S. Kamil. Parallel associative reductions in halide. CGO'17
+   *
+   * \param tensor The tensor to be factored.
+   * \param axis The reduction axis in tensor's schedule to be factored.
+   * \param factor_axis The position where the new axis is placed.
+   * \return The created factored tensors.
+   */
+  TVM_DLL Array<Tensor> rfactor(const Tensor& tensor, const IterVar& axis, int factor_axis = 0);
+  /*!
+   * \brief Normalize the schedule.
+   *  This is needed before bound inference.
+   *  Insert necessary RebaseNode to make sure all leaf_iter_vars
+   *  are in form [0, extent)
+   *
+   * \return A normalized schedule, can be same as current one.
+   */
+  Schedule normalize();
+
+  /*!
+   * \brief Normalize the schedule for feature extraction in auto-scheduler.
+   * This is similar to `Schedule::normalize`, but we do aggressive simplification
+   * to the TE compute with const_matrix=True for faster compilation and feature extraction.
+   * The resulted schedule may be wrong, but it is good enough for feature extraction
+   * purposes.
+   *
+   * \return A normalized schedule, can be same as current one.
+   */
+  Schedule normalize_for_feature_extraction();
+
+  /*!
+   * \brief access the internal node container
+   * \return the pointer to the internal node container
+   */
+  inline const ScheduleNode* operator->() const;
+  /*!
+   * \brief access the internal node container
+   * \return the pointer to the internal node container
+   */
+  inline ScheduleNode* operator->();
+  // declare container type
+  using ContainerType = ScheduleNode;
+};
+
+/*!
+ * \brief The schedule relation between IterVars
+ *  can be Split, Fuse.
+ */
+class IterVarRelation : public ObjectRef {
+ public:
+  IterVarRelation() {}
+  explicit IterVarRelation(ObjectPtr<Object> n) : ObjectRef(n) {}
+  /*!
+   * \brief access the internal node container
+   * \return the pointer to the internal node container
+   */
+  inline const IterVarRelationNode* operator->() const;
+};
+
+/*!
+ * \brief Additional scheduable attributes about IterVar.
+ */
+class IterVarAttr : public ObjectRef {
+ public:
+  IterVarAttr() {}
+  explicit IterVarAttr(ObjectPtr<Object> n) : ObjectRef(n) {}
+  /*!
+   * \brief access the internal node container
+   * \return the pointer to the internal node container
+   */
+  inline const IterVarAttrNode* operator->() const;
+};
+
+/*!
+ * \brief represents a stage.
+ *
+ *  relations form a Directed acylic hypergraph in bipartite manner.
+ *  With each node is represented by a IterVar,
+ *  and each hyper-edge is represented by a IterVarRelation.
+ *  The relations connects the IterVars in the graph.
+ *
+ *  Besides typical stage that corresponds to operations.
+ *  There is also group stage, which groups stages together.
+ *  Each stage's group(given by group) represent an constraint,
+ *  the stage can only be attached to stages within the group.
+ *
+ *  The group stage node can be attached to IterVars as in normal stage.
+ */
+class StageNode : public Object {
+ public:
+  /*!
+   * \brief The operation of stage, can be different from original op.
+   *  If it is null, then this stage is a group stage.
+   */
+  Operation op;
+  /*!
+   * \brief The original operator.
+   *  The op field can change during schedule to alternate the dataflow,
+   *  while origin_op remains fixed.
+   */
+  Operation origin_op;
+  /*! \brief All the nodes in the iter var
+   *
+   * Each element of all_iter_vars represents an iteration variable
+   * that may appear within this stage's computation.  Any element
+   * of `all_iter_vars` that is in `leaf_iter_vars` represents a
+   * variable that is directly defined and usable within the stage's
+   * computation.  All other elements of `all_iter_vars` represent
+   * variables whose value must be computed from the variables in
+   * `leaf_iter_vars`.  (e.g. Support index k has been split by
+   * ``ko, ki = s.split(k, factor=4)``.  ko and ki will appear in
+   * `leaf_iter_vars`, while k will not, and must be computed as
+   * `4*ko + ki`.
+   */
+  Array<IterVar> all_iter_vars;
+  /*! \brief The current active leaf iter vars in the stage.
+   *
+   * Each element of leaf_iter_vars will either be replaced with the
+   * bound index (e.g. threadIdx.x), or will be expanded into a loop
+   * over the variable's extent.  `leaf_iter_vars` is a subset of
+   * `all_iter_vars`.
+   */
+  Array<IterVar> leaf_iter_vars;
+  /*!
+   * \brief Specify threads to be launched at the stage.
+   *  This is only valid for composite ops such as Scan.
+   * \note Experimental primitive: used for thread persistence.
+   */
+  Array<IterVar> env_threads;
+  /*!
+   * \brief The predicate under which store can happen
+   *  Use this when there can be duplicated threads doing the same store.
+   * \note Experimental primitive: used by cross thread-reduction.
+   */
+  PrimExpr store_predicate;
+  /*! \brief The relation bwteen of IterVars */
+  Array<IterVarRelation> relations;
+  /*! \brief additional attributes about iter var. */
+  Map<IterVar, IterVarAttr> iter_var_attrs;
+  /*! \brief The attachment type of the schedule */
+  AttachType attach_type{kGroupRoot};
+  /*! \brief The attach point of this schedule. */
+  IterVar attach_ivar;
+  /*! \brief The stage this node attaches to */
+  Stage attach_stage;
+  /*! \brief The thread storage scope level of the stage */
+  std::string scope;
+  /*! \brief Whether this is an output stage */
+  bool is_output{false};
+  /*! \brief Whether apply double buffer optimization to this stage */
+  bool double_buffer{false};
+  /*! \brief Whether apply rolling buffer optimization to this stage */
+  bool rolling_buffer{false};
+  /*! \brief Layout transformations to be applied onto the stage's tensors. */
+  Array<IndexMap> layout_transforms;
+  /*! \brief List of axes after which to divide physical axes.
+   *
+   * Used to populate `BufferNode::axis_separators`, which has
+   * additional details.
+   */
+  Array<IntImm> axis_separators;
+  /*!
+   * \brief The parent group of the current stage.
+   *  The stage cannot be assigned to stages outside the group.
+   */
+  Stage group;
+  /*! \brief Number of direct child stages, only used for group stage.*/
+  int num_child_stages{0};
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("op", &op);
+    v->Visit("origin_op", &origin_op);
+    v->Visit("all_iter_vars", &all_iter_vars);
+    v->Visit("leaf_iter_vars", &leaf_iter_vars);
+    v->Visit("env_threads", &env_threads);
+    v->Visit("relations", &relations);
+    v->Visit("iter_var_attrs", &iter_var_attrs);
+    v->Visit("attach_type", &attach_type);
+    v->Visit("attach_ivar", &attach_ivar);
+    v->Visit("attach_stage", &attach_stage);
+    v->Visit("scope", &scope);
+    v->Visit("is_output", &is_output);
+    v->Visit("double_buffer", &double_buffer);
+    v->Visit("layout_transforms", &layout_transforms);
+    v->Visit("axis_separators", &axis_separators);
+    v->Visit("group", &group);
+    v->Visit("num_child_stages", &num_child_stages);
+  }
+
+  static constexpr const char* _type_key = "Stage";
+  TVM_DECLARE_FINAL_OBJECT_INFO(StageNode, Object);
+};
+
+/*! \brief node container for schedule */
+class ScheduleNode : public Object {
+ public:
+  /*! \brief The output operations in original data flow graph */
+  Array<Operation> outputs;
+  /*!
+   * \brief list of all stages for ops.
+   * The stages are sorted in dependency order.
+   */
+  Array<Stage> stages;
+  /*!
+   * \brief List of all stage groups.
+   */
+  Array<Stage> groups;
+  /*! \brief map of original operation to the stages */
+  Map<Operation, Stage> stage_map;
+  /*!
+   * \brief Internal stage map to map internal ops to stages.
+   *  This is created on demand and can be invalidated.
+   */
+  std::unordered_map<const Object*, Stage> op2stage_cache_;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("outputs", &outputs);
+    v->Visit("stages", &stages);
+    v->Visit("groups", &groups);
+    v->Visit("stage_map", &stage_map);
+  }
+
+  /*! \brief Initialize temp cache. */
+  void InitCache();
+  /*! \brief Invalidate temp cache. */
+  void InvalidateCache();
+
+  /*!
+   * \brief Check if the schedule contains an Operation.
+   * \param op The candidate Operation.
+   * \return true if the schedule has the Operation. Otherwise, false.
+   */
+  TVM_DLL bool Contain(const Operation& op) const;
+
+  /*!
+   * \brief Check if the schedule contains a Tensor.
+   * \param tensor The candidate tensor.
+   * \return true if the schedule has the tensor. Otherwise, false.
+   */
+  TVM_DLL bool Contain(const Tensor& tensor) const { return Contain(tensor->op); }
+
+  static constexpr const char* _type_key = "Schedule";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ScheduleNode, Object);
+};
+
+/*!
+ * \brief Create a schedule for array of ops(and their dependencies).
+ * \param ops The ops to be scheduled.
+ * \return sch The created Schedule.
+ */
+inline Schedule create_schedule(Array<Operation> ops) { return Schedule(ops); }
+
+/*! \brief node container for IterVar attr */
+class IterVarAttrNode : public Object {
+ public:
+  /*! \brief The iteration type. */
+  IterVarType iter_type{kDataPar};
+  /*! \brief The thread this iter Var binds, can be null */
+  IterVar bind_thread;
+  /*! \brief List of tensor to be prefetched in this loop */
+  Array<Tensor> prefetch_data;
+  /*! \brief The offset used in each prefetch */
+  Array<PrimExpr> prefetch_offset;
+  /*!
+   * \brief Tensor intrinsic used in tensorization,
+   *   when the axis is marked as Tensorized
+   */
+  TensorIntrin tensor_intrin;
+  /*! \brief Alignment factor of buffer dimension */
+  int dim_align_factor{0};
+  /*! \brief Alignment offset of buffer dimension */
+  int dim_align_offset{0};
+  /*!
+   * \brief Additional pragma keys, array of StringImm
+   */
+  Array<PrimExpr> pragma_keys;
+  /*!
+   * \brief Additional values of pragma, if any
+   */
+  Array<PrimExpr> pragma_values;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("iter_type", &iter_type);
+    v->Visit("bind_thread", &bind_thread);
+    v->Visit("prefetch_data", &prefetch_data);
+    v->Visit("prefetch_offset", &prefetch_offset);
+    v->Visit("tensor_intrin", &tensor_intrin);
+    v->Visit("dim_align_factor", &dim_align_factor);
+    v->Visit("dim_align_offset", &dim_align_offset);
+    v->Visit("pragma_keys", &pragma_keys);
+    v->Visit("pragma_values", &pragma_values);
+  }
+
+  static constexpr const char* _type_key = "IterVarAttr";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IterVarAttrNode, Object);
+};
+
+/*! \brief base node of iteration var */
+class IterVarRelationNode : public Object {
+ public:
+  static constexpr const char* _type_key = "IterVarRelation";
+  TVM_DECLARE_BASE_OBJECT_INFO(IterVarRelationNode, Object);
+};
+
+/*!
+ * \brief Split the parent domain into product of
+ *  outer and iter.
+ */
+class SplitNode : public IterVarRelationNode {
+ public:
+  /*! \brief The parent domain */
+  IterVar parent;
+  /*! \brief The outer domain */
+  IterVar outer;
+  /*! \brief The inner domain */
+  IterVar inner;
+  /*! \brief The split factor */
+  PrimExpr factor;
+  /*! \brief Number of parts, only factor or nparts can be given */
+  PrimExpr nparts;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("parent", &parent);
+    v->Visit("outer", &outer);
+    v->Visit("inner", &inner);
+    v->Visit("factor", &factor);
+    v->Visit("nparts", &nparts);
+  }
+
+  static constexpr const char* _type_key = "Split";
+  TVM_DECLARE_FINAL_OBJECT_INFO(SplitNode, IterVarRelationNode);
+};
+
+/*!
+ * \brief Managed reference to SplitNode
+ * \sa SplitNode
+ */
+class Split : public IterVarRelation {
+ public:
+  TVM_DLL Split(IterVar parent, IterVar outer, IterVar inner, PrimExpr factor, PrimExpr nparts);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Split, IterVarRelation, SplitNode);
+};
+
+/*!
+ * \brief Fuse two domains into one domain.
+ */
+class FuseNode : public IterVarRelationNode {
+ public:
+  /*! \brief The outer domain */
+  IterVar outer;
+  /*! \brief The inner domain */
+  IterVar inner;
+  /*! \brief The target domain */
+  IterVar fused;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("outer", &outer);
+    v->Visit("inner", &inner);
+    v->Visit("fused", &fused);
+  }
+
+  static constexpr const char* _type_key = "Fuse";
+  TVM_DECLARE_FINAL_OBJECT_INFO(FuseNode, IterVarRelationNode);
+};
+
+/*!
+ * \brief Managed reference to FuseNode
+ * \sa FuseNode
+ */
+class Fuse : public IterVarRelation {
+ public:
+  TVM_DLL Fuse(IterVar outer, IterVar inner, IterVar fused);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Fuse, IterVarRelation, FuseNode);
+};
+
+/*!
+ * \brief Rebase the iteration to make min to be 0.
+ *  This is useful to normalize the Schedule
+ *  to make every leaf variable's min to be 0.
+ */
+class RebaseNode : public IterVarRelationNode {
+ public:
+  /*! \brief The parent domain */
+  IterVar parent;
+  /*! \brief The inner domain */
+  IterVar rebased;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("parent", &parent);
+    v->Visit("rebased", &rebased);
+  }
+
+  static constexpr const char* _type_key = "Rebase";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RebaseNode, IterVarRelationNode);
+};
+
+/*!
+ * \brief Managed reference to RebaseNode
+ * \sa RebaseNode
+ */
+class Rebase : public IterVarRelation {
+ public:
+  TVM_DLL Rebase(IterVar parent, IterVar rebased);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Rebase, IterVarRelation, RebaseNode);
+};
+
+/*!
+ * \brief Singleton iterator [0, 1)
+ */
+class SingletonNode : public IterVarRelationNode {
+ public:
+  /*! \brief The singleton iterator */
+  IterVar iter;
+
+  void VisitAttrs(AttrVisitor* v) { v->Visit("iter", &iter); }
+
+  static constexpr const char* _type_key = "Singleton";
+  TVM_DECLARE_FINAL_OBJECT_INFO(SingletonNode, IterVarRelationNode);
+};
+
+/*!
+ * \brief Managed reference to SingletonNode
+ * \sa SingletonNode
+ */
+class Singleton : public IterVarRelation {
+ public:
+  TVM_DLL explicit Singleton(IterVar iter);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Singleton, IterVarRelation, SingletonNode);
+};
+
+/*!
+ * \brief Transform iterator according to some arbitrary expression.
+ */
+class TransformNode : public IterVarRelationNode {
+ public:
+  /*! \brief The loop variables that were replaced by the transformation.
+   *
+   * Prior to applying a layout transformation, these represent the
+   * loops to iterate over a tensor as it is being computed, following
+   * a row-major traversal of the tensor's original shape in the
+   * compute definition.
+   */
+  Array<IterVar> original_variables;
+
+  /*! \brief The variables generated by the transformation.
+   *
+   * After to applying a layout transformation, these represent the
+   * loops to iterate over a tensor as it is being computed, following
+   * a row-major traversal of the transformed shape of the tensor.
+   */
+  Array<IterVar> transformed_variables;
+
+  /*! \brief Map from the original variables to the transformed variables.
+   *
+   * Used to determine iterator ranges over the transformed variables.
+   */
+  IndexMap forward_transformation;
+
+  /*! \brief Map from transformed variables to the original variables
+   *
+   * Used to rewrite expressions containing the original loop iterators
+   * in terms of the transformed loop iterators.
+   */
+  IndexMap inverse_transformation;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("original_variables", &original_variables);
+    v->Visit("transformed_variables", &transformed_variables);
+    v->Visit("forward_transformation", &forward_transformation);
+    v->Visit("inverse_transformation", &inverse_transformation);
+  }
+
+  static constexpr const char* _type_key = "Transform";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TransformNode, IterVarRelationNode);
+};
+
+class Transform : public IterVarRelation {
+ public:
+  TVM_DLL explicit Transform(Array<IterVar> original_variables,
+                             Array<IterVar> transformed_variables, IndexMap forward_transformation,
+                             IndexMap inverse_transformation);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Transform, IterVarRelation, TransformNode);
+};
+
+/*! \brief Container for specialization conditions. */
+class SpecializedConditionNode : public Object {
+ public:
+  /*!
+   * \brief List of conditions in conjunctive joint form (CNF).
+   *   Each condition should be a simple expression, e.g., n > 16, m % 8 == 0, etc.,
+   *   where n, m are tvm::Var that represents a dimension in the tensor shape.
+   */
+  Array<PrimExpr> clauses;
+
+  void VisitAttrs(AttrVisitor* v) { v->Visit("clauses", &clauses); }
+
+  static constexpr const char* _type_key = "SpecializedCondition";
+  TVM_DECLARE_FINAL_OBJECT_INFO(SpecializedConditionNode, Object);
+};
+
+/*!
+ * \brief Specialized condition to enable op specialization
+ */
+class SpecializedCondition : public ObjectRef {
+ public:
+  /*!
+   * \brief construct from conditions
+   * \param conditions The clauses in the specialized condition.
+   */
+  TVM_DLL SpecializedCondition(Array<PrimExpr> conditions);  // NOLINT(*)
+
+  /*!
+   * \brief Get the current specialized condition.
+   * \return the current specialized condition.
+   */
+  TVM_DLL static SpecializedCondition Current();
+
+  TVM_DEFINE_OBJECT_REF_METHODS(SpecializedCondition, ObjectRef, SpecializedConditionNode);
+  class Internal;
+
+ private:
+  // enable with syntax.
+  friend class Internal;
+  friend class With<SpecializedCondition>;
+  /*! \brief Push a new specialized condition onto the thread local stack. */
+  TVM_DLL void EnterWithScope();
+  /*! \brief Pop a specialized condition off the thread local context stack. */
+  TVM_DLL void ExitWithScope();
+};
+
+// implementations
+inline const StageNode* Stage::operator->() const { return static_cast<const StageNode*>(get()); }
+inline StageNode* Stage::operator->() { return static_cast<StageNode*>(get_mutable()); }
+
+inline const ScheduleNode* Schedule::operator->() const {
+  return static_cast<const ScheduleNode*>(get());
+}
+inline ScheduleNode* Schedule::operator->() { return static_cast<ScheduleNode*>(get_mutable()); }
+
+inline const IterVarRelationNode* IterVarRelation::operator->() const {
+  return static_cast<const IterVarRelationNode*>(get());
+}
+
+inline const IterVarAttrNode* IterVarAttr::operator->() const {
+  return static_cast<const IterVarAttrNode*>(get());
+}
+
+}  // namespace te
+}  // namespace tvm
+#endif  // TVM_TE_SCHEDULE_H_
diff --git a/darknet_drp_ros/include/tvm/te/schedule_pass.h b/darknet_drp_ros/include/tvm/te/schedule_pass.h
new file mode 100644
index 0000000..3f9da5f
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/te/schedule_pass.h
@@ -0,0 +1,112 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/te/schedule_pass.h
+ * \brief  Collection of Schedule pass functions.
+ *
+ *  These passes works on the schedule hyper-graph
+ *  and infers information such as bounds, check conditions
+ *  read/write dependencies between the IterVar
+ */
+#ifndef TVM_TE_SCHEDULE_PASS_H_
+#define TVM_TE_SCHEDULE_PASS_H_
+
+#include <tvm/te/schedule.h>
+#include <tvm/tir/function.h>
+
+namespace tvm {
+namespace te {
+
+/*!
+ * \brief To automatically inline the element-wise operations.
+ *
+ * \param sch The schedule to be inlined.
+ */
+void AutoInlineElemWise(Schedule sch);
+
+/*!
+ * \brief To automatically inline the broadcast operations.
+ *
+ * \param sch The schedule to be inlined.
+ */
+void AutoInlineBroarcast(Schedule sch);
+
+/*!
+ * \brief To automatically inline operations with injective writes
+ *   (i.e. writes without reduction or sequential loops). Note
+ *   that in this case, guarantees about contiguity, transpose, stride,
+ *   alignemnt and memory footprint in general do not hold.
+ *
+ * \param sch The schedule to be inlined.
+ */
+TVM_DLL void AutoInlineInjective(Schedule sch);
+
+/*!
+ * \brief Infer the bound of all iteration variables relates to the schedule.
+ *
+ * \param sch The root schedule to infer all the bounds.
+ * \return the result bound of the iteration Variable
+ */
+Map<IterVar, Range> InferBound(const Schedule& sch);
+
+/*!
+ * \brief Verify if there is any argument bound to compact buffer.
+ *
+ * \param stmt The stmt to be verified.
+ * \return true if there is any buffer_bind_scope attribute found,
+ *        otherwise, false.
+ */
+bool VerifyCompactBuffer(const Stmt& stmt);
+
+/*!
+ * \brief Schedule s' dependent operations.
+ *
+ * \param s The schedule to be realized
+ * \param dom_map The domain of each iter vars.
+ * \param debug_keep_trivial_loop Whether keep trivial loops with extent of 1 during lowering.
+ *                                This is a debug feature for dataflow/axis analysis.
+ *                                Note: If this is true, The lowered IR may be incorrect,
+ *                                because we will also delete the init part of reduction
+ * \return the result Stmt
+ */
+Stmt ScheduleOps(Schedule s, Map<IterVar, Range> dom_map, bool debug_keep_trivial_loop);
+
+/*!
+ * \brief Postprocessing the Stmt generated by ScheduleOps to create
+ *        a PrimFunc that can then be used for further TIR optimizations.
+ *
+ *  Perform this translation before running any TIR optimizations.
+ *
+ *  List of actions taken by the function:
+ *  - Remove occurrences of te::Tensor, te::Operation in the IR
+ *    and replace them by corresponding IR nodes via tir::Buffer.
+ *  - Add annotation of extern buffers using the buffer_map field
+ *    in the PrimFunc type.
+ *
+ * \param arg_list Array of Tensor/Var/Buffer arguments to the function.
+ * \param body The body of the function.
+ * \param bindings potential Tensor to Buffer bindings for the Tensors in the body.
+ */
+PrimFunc SchedulePostProcToPrimFunc(Array<ObjectRef> arg_list, Stmt body,
+                                    Optional<Map<Tensor, Buffer>> bindings);
+
+}  // namespace te
+}  // namespace tvm
+#endif  // TVM_TE_SCHEDULE_PASS_H_
diff --git a/darknet_drp_ros/include/tvm/te/tensor.h b/darknet_drp_ros/include/tvm/te/tensor.h
new file mode 100644
index 0000000..30480e1
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/te/tensor.h
@@ -0,0 +1,280 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/te/tensor.h
+ * \brief Dataflow tensor object
+ */
+#ifndef TVM_TE_TENSOR_H_
+#define TVM_TE_TENSOR_H_
+
+#include <tvm/arith/bound.h>
+#include <tvm/tir/expr.h>
+#include <tvm/tir/op.h>
+
+#include <string>
+#include <type_traits>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+namespace te {
+
+using arith::IntSet;
+using namespace tvm::tir;
+
+// internal node container for Operation
+class OperationNode;
+class Tensor;
+
+/*! \brief Operation that produces tensors */
+class Operation : public ObjectRef {
+ public:
+  /*! \brief default constructor  */
+  Operation() {}
+  explicit Operation(ObjectPtr<Object> n) : ObjectRef(n) {}
+  /*!
+   * \brief access the internal node container
+   * \return the pointer to the internal node container
+   */
+  inline const OperationNode* operator->() const;
+  /*!
+   * \brief get the i-th output of the operation.
+   * \param i the output index.
+   * \return The i-th output.
+   */
+  TVM_DLL Tensor output(size_t i) const;
+  /*! \brief specify container node */
+  using ContainerType = OperationNode;
+};
+
+/*! \brief Node to represent a tensor */
+class TensorNode : public DataProducerNode {
+ public:
+  /*! \brief The shape of the tensor */
+  Array<PrimExpr> shape;
+  /*! \brief data type in the content of the tensor */
+  DataType dtype;
+  /*! \brief the source operation, can be None */
+  Operation op;
+  /*! \brief the output index from source operation */
+  int value_index{0};
+  /*! \brief constructor */
+  TensorNode() {}
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("shape", &shape);
+    v->Visit("dtype", &dtype);
+    v->Visit("op", &op);
+    v->Visit("value_index", &value_index);
+  }
+
+  Array<PrimExpr> GetShape() const final { return shape; }
+
+  DataType GetDataType() const final { return dtype; }
+
+  TVM_DLL String GetNameHint() const final;
+
+  static constexpr const char* _type_key = "Tensor";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TensorNode, DataProducerNode);
+};
+
+/*!
+ * \brief Tensor structure representing a possible input,
+ *  or intermediate computation result.
+ */
+class Tensor : public DataProducer {
+ private:
+  /*!
+   * \brief Helper for indexing operations into tensors
+   * \param indices The indices
+   * \param support_negative_indices Whether to normalize indices in the case of negative indices.
+   * \return the result expression representing tensor read.
+   */
+  inline PrimExpr IndexTensor(Array<PrimExpr> indices, bool support_negative_indices) const;
+
+ public:
+  TVM_DLL Tensor(Array<PrimExpr> shape, DataType dtype, Operation op, int value_index);
+  /*!
+   * \brief check if two tensors equals each other.
+   * \param other tensor to be checked.
+   * \return whether the two tensors equals each other.
+   */
+  inline bool operator==(const Tensor& other) const;
+  /*!
+   * \brief check if two tensors are different.
+   * \param other tensor to be checked.
+   * \return whether the two tensors are different.
+   */
+  inline bool operator!=(const Tensor& other) const;
+  /*! \return The dimension of the tensor */
+  inline size_t ndim() const;
+  /*!
+   * \brief Take elements from the tensor
+   * \param args The indices
+   * \return the result expression representing tensor read.
+   */
+  template <typename... Args>
+  inline PrimExpr operator()(Args&&... args) const {
+    Array<PrimExpr> indices{std::forward<Args>(args)...};
+    return operator()(indices);
+  }
+  /*!
+   * \brief Take elements from the tensor
+   * \param indices the indices.
+   * \return the result expression representing tensor read.
+   */
+  TVM_DLL PrimExpr operator()(Array<PrimExpr> indices) const;
+  /*!
+   * \brief Take elements from the tensor
+   * \param indices the indices.
+   * \return the result expression representing tensor read.
+   */
+  TVM_DLL PrimExpr operator()(Array<Var> indices) const;
+  /*!
+   * \brief Take elements from the tensor with support for negative indices.
+   * \param args The indices
+   * \return the result expression representing tensor read.
+   */
+  template <typename... Args>
+  TVM_DLL PrimExpr IndexWithNegativeIndices(Args&&... args) const {
+    Array<PrimExpr> indices{std::forward<Args>(args)...};
+    return IndexWithNegativeIndices(indices);
+  }
+  /*!
+   * \brief Take elements from the tensor with support for negative indices.
+   * \param indices the indices.
+   * \return the result expression representing tensor read.
+   */
+  TVM_DLL PrimExpr IndexWithNegativeIndices(Array<PrimExpr> indices) const;
+  /*!
+   * \brief Take elements from the tensor with support for negative indices.
+   * \param indices the indices.
+   * \return the result expression representing tensor read.
+   */
+  TVM_DLL PrimExpr IndexWithNegativeIndices(Array<Var> indices) const;
+
+  /*!
+   * \brief data structure to represent a slice that fixes first k coordinates.
+   *  This is used to enable syntax sugar of Tensor[x][y][z] to get the element.
+   */
+  class Slice {
+   public:
+    // construct via tensor and indices
+    Slice(const Tensor& tensor, std::vector<PrimExpr> indices)
+        : tensor_(tensor), indices_(indices) {}
+    /*!
+     * \brief get i-th slice from the current slice.
+     * \param i the index of the coordinate
+     * \return the subsequent slice.
+     */
+    inline Slice operator[](PrimExpr i) {
+      std::vector<PrimExpr> other = indices_;
+      other.emplace_back(i);
+      return Slice(tensor_, other);
+    }
+    /*!
+     * \brief Convert slice to expression.
+     *  This is only valid when all the coordinates are fully specified.
+     * \return the corresponding expression of this slice.
+     */
+    inline operator PrimExpr() const { return tensor_(indices_); }
+
+   private:
+    const Tensor& tensor_;
+    std::vector<PrimExpr> indices_;
+  };
+  /*!
+   * \brief get i-th slice from the current Tensor.
+   * \param i the index of the coordinate
+   * \return the subsequent slice.
+   */
+  inline Slice operator[](PrimExpr i) const { return Slice(*this, {i}); }
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Tensor, DataProducer, TensorNode);
+};
+
+// Implementations of inline functions
+inline size_t Tensor::ndim() const { return (*this)->shape.size(); }
+
+inline bool Tensor::operator==(const Tensor& other) const {
+  if (get() == other.get()) return true;
+  if (get() == nullptr || other.get() == nullptr) return false;
+  if ((*this)->op.defined() || other->op.defined()) {
+    return (*this)->op == other->op && (*this)->value_index == other->value_index;
+  } else {
+    return false;
+  }
+}
+
+inline bool Tensor::operator!=(const Tensor& other) const { return !(*this == other); }
+
+// macro to turn every operation of slice to expression
+#define DEFINE_OVERLOAD_SLICE_UNARY_OP(Op) \
+  inline PrimExpr operator Op(const Tensor::Slice& a) { return Op a.operator PrimExpr(); }
+
+#define DEFINE_OVERLOAD_SLICE_BINARY_OP(Op)                                     \
+  template <typename T>                                                         \
+  inline PrimExpr operator Op(const Tensor::Slice& a, const T& b) {             \
+    return a.operator PrimExpr() Op b;                                          \
+  }                                                                             \
+  template <typename T>                                                         \
+  inline PrimExpr operator Op(const T& a, const Tensor::Slice& b) {             \
+    return a Op b.operator PrimExpr();                                          \
+  }                                                                             \
+  inline PrimExpr operator Op(const Tensor::Slice& a, const Tensor::Slice& b) { \
+    return a.operator PrimExpr() Op b.operator PrimExpr();                      \
+  }
+
+DEFINE_OVERLOAD_SLICE_UNARY_OP(!);
+DEFINE_OVERLOAD_SLICE_UNARY_OP(-);
+DEFINE_OVERLOAD_SLICE_BINARY_OP(+);
+DEFINE_OVERLOAD_SLICE_BINARY_OP(-);
+DEFINE_OVERLOAD_SLICE_BINARY_OP(*);
+DEFINE_OVERLOAD_SLICE_BINARY_OP(==);
+DEFINE_OVERLOAD_SLICE_BINARY_OP(<=);
+DEFINE_OVERLOAD_SLICE_BINARY_OP(>=);
+DEFINE_OVERLOAD_SLICE_BINARY_OP(!=);
+DEFINE_OVERLOAD_SLICE_BINARY_OP(&&);
+DEFINE_OVERLOAD_SLICE_BINARY_OP(||);
+DEFINE_OVERLOAD_SLICE_BINARY_OP(>>);
+DEFINE_OVERLOAD_SLICE_BINARY_OP(<<);
+DEFINE_OVERLOAD_SLICE_BINARY_OP(>);  // NOLINT(*)
+DEFINE_OVERLOAD_SLICE_BINARY_OP(<);  // NOLINT(*)
+
+}  // namespace te
+}  // namespace tvm
+
+namespace std {
+template <>
+struct hash<::tvm::te::Operation> : public ::tvm::ObjectPtrHash {};
+
+template <>
+struct hash<::tvm::te::Tensor> {
+  std::size_t operator()(const ::tvm::te::Tensor& k) const {
+    ::tvm::ObjectPtrHash hasher;
+    if (k.defined() && k->op.defined()) {
+      return hasher(k->op);
+    } else {
+      return hasher(k);
+    }
+  }
+};
+}  // namespace std
+#endif  // TVM_TE_TENSOR_H_
diff --git a/darknet_drp_ros/include/tvm/te/tensor_intrin.h b/darknet_drp_ros/include/tvm/te/tensor_intrin.h
new file mode 100644
index 0000000..22f29de
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/te/tensor_intrin.h
@@ -0,0 +1,145 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/te/tensor_intrin.h
+ * \brief Tensor intrinsic operations.
+ */
+#ifndef TVM_TE_TENSOR_INTRIN_H_
+#define TVM_TE_TENSOR_INTRIN_H_
+
+#include <tvm/te/tensor.h>
+#include <tvm/tir/buffer.h>
+
+#include <string>
+
+namespace tvm {
+namespace te {
+
+/*! \brief Node to represent a Tensor intrinsic operator */
+class TensorIntrinNode : public Object {
+ public:
+  /*! \brief The name of the intrinsic */
+  std::string name;
+  /*! \brief The operation this intrinsics is carrying out */
+  Operation op;
+  /*! \brief List of inputs of operator, placeholder in postdfs order */
+  Array<Tensor> inputs;
+  /*!
+   * \brief Symbolic buffers of each output/input tensor
+   *  buffers[0:len(inputs)] are buffers of the inputs.
+   *  buffers[len(inputs):] are buffers of each output.
+   *
+   * \note When a field in Buffer is Var, it means we can be flexible
+   *  wrt that field and Var can occur in body.
+   *  When it is a constant, it means we can only take data in that shape.
+   */
+  Array<Buffer> buffers;
+  /*! \brief List of scalar variables, used in body. These placeholders
+   *  will be bound to expressions passed in when the TensorIntrin is called
+   * from a TensorComputeOp.
+   */
+  Array<Var> scalar_params;
+  /*! \brief The normal statement to execute the intrinsic */
+  Stmt body;
+  /*!
+   * \brief Special statement for reduction op, can be None
+   *  reset the value of output buffer to identity value.
+   */
+  Stmt reduce_init;
+  /*!
+   * \brief Special statement for reduction op, can be None
+   *  Reduce: do a reduction of current output buffer with the result.
+   */
+  Stmt reduce_update;
+  /*! \brief constructor */
+  TensorIntrinNode() {}
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("name", &name);
+    v->Visit("op", &op);
+    v->Visit("inputs", &inputs);
+    v->Visit("buffers", &buffers);
+    v->Visit("scalar_params", &scalar_params);
+    v->Visit("body", &body);
+    v->Visit("reduce_init", &reduce_init);
+    v->Visit("reduce_update", &reduce_update);
+  }
+
+  static constexpr const char* _type_key = "TensorIntrin";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TensorIntrinNode, Object);
+};
+
+/*!
+ * \brief Managed reference to TensorIntrinNode
+ * \sa TensorIntrinNode
+ */
+class TensorIntrin : public ObjectRef {
+ public:
+  TVM_DLL TensorIntrin(std::string name, Operation op, Array<Tensor> inputs, Array<Buffer> buffers,
+                       Array<Var> scalar_params, Stmt body, Stmt reduce_init, Stmt reduce_update);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(TensorIntrin, ObjectRef, TensorIntrinNode);
+};
+
+class TensorIntrinCallNode : public Object {
+ public:
+  /*! \brief the tensor intrinsic */
+  TensorIntrin intrin;
+  /*! \brief input tensors of the intrinsic */
+  Array<Tensor> tensors;
+  /*! \brief regions of input tensors */
+  Array<Region> regions;
+
+  /*!
+   * \brief IterVar on each reduction axis, if the
+   * intrin will use the reduce axis
+   */
+  Array<IterVar> reduce_axis;
+
+  /*! \brief scalar expression inputs */
+  Array<PrimExpr> scalar_inputs;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("intrin", &intrin);
+    v->Visit("tensors", &tensors);
+    v->Visit("regions", &regions);
+    v->Visit("reduce_axis", &reduce_axis);
+    v->Visit("scalar_inputs", &scalar_inputs);
+  }
+
+  static constexpr const char* _type_key = "TensorIntrinCall";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TensorIntrinCallNode, Object);
+};
+
+/*!
+ * \brief Managed reference to TensorIntrinCallNode
+ * \sa TensorIntrinCallNode
+ */
+class TensorIntrinCall : public ObjectRef {
+ public:
+  TVM_DLL TensorIntrinCall(TensorIntrin intrin, Array<Tensor> tensors, Array<Region> regions,
+                           Array<IterVar> reduce_axis, Array<PrimExpr> scalar_inputs);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(TensorIntrinCall, ObjectRef, TensorIntrinCallNode);
+};
+
+}  // namespace te
+}  // namespace tvm
+#endif  // TVM_TE_TENSOR_INTRIN_H_
diff --git a/darknet_drp_ros/include/tvm/tir/analysis.h b/darknet_drp_ros/include/tvm/tir/analysis.h
new file mode 100644
index 0000000..a8edc26
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/analysis.h
@@ -0,0 +1,335 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/tir/analysis.h
+ * \brief Analysis utilities and passes for TIR.
+ */
+#ifndef TVM_TIR_ANALYSIS_H_
+#define TVM_TIR_ANALYSIS_H_
+
+#include <tvm/ir/module.h>
+#include <tvm/ir/transform.h>
+#include <tvm/tir/expr.h>
+#include <tvm/tir/function.h>
+#include <tvm/tir/op_attr_types.h>
+#include <tvm/tir/stmt.h>
+
+#include <string>
+
+namespace tvm {
+namespace tir {
+
+/*!
+ * \brief Compare two expressions recursively and check if they are equal
+ *        to each other without var remapping.
+ *
+ *  This function does not remap variable bindings, it will not
+ *  return true for (let x = 1 in x + 1) vs (let y = 1 in y + 1), unless x.same_as(y).
+ *
+ *  Use StructuralEqual for such cases.
+ *
+ *  Due to the restriction of not remapping variables, this function can run
+ *  faster than StructuralEqual and can be used as a utility function during arithmetic
+ *  simplifications.
+ *
+ * \sa StructuralEqual
+ */
+struct ExprDeepEqual {
+ public:
+  TVM_DLL bool operator()(const PrimExpr& lhs, const PrimExpr& rhs) const;
+};
+
+/*!
+ * \brief Visit the PrimFuncs in the IRModule
+ * \tparam FLambda The type of the PrimFunc visitor
+ * \param mod The IRModule to be visited
+ * \param fvisit The visitor to the PrimFuncs in the IRModule
+ */
+template <class FLambda>
+inline void VisitPrimFuncs(const IRModule& mod, FLambda fvisit) {
+  for (const auto& kv : mod->functions) {
+    const BaseFunc& base_func = kv.second;
+    if (const auto* prim_func = base_func.as<PrimFuncNode>()) {
+      fvisit(prim_func);
+    }
+  }
+}
+
+/*!
+ * \brief Estimate the FLOPs of a TIR fragment.
+ * \param stmt The TIR fragment to be estimated.
+ * \return The estimated FLOPs.
+ */
+TVM_DLL double EstimateTIRFlops(const Stmt& stmt);
+
+/*!
+ * \brief Estimate the FLOPs of TIRs in an IRModule.
+ * \param mod The IRModule to be estimated.
+ * \return The estimated FLOPs.
+ */
+TVM_DLL double EstimateTIRFlops(const IRModule& mod);
+
+/*!
+ * \brief Find undefined vars in the statement.
+ * \param stmt The function to be checked.
+ * \param defs The vars that is defined.
+ * \return Array of undefined vars.
+ */
+TVM_DLL Array<Var> UndefinedVars(const Stmt& stmt, const Array<Var>& defs);
+
+/*!
+ * \brief Find undefined vars in the expression.
+ * \param expr The expression to be checked.
+ * \return Array of undefined vars.
+ */
+TVM_DLL Array<Var> UndefinedVars(const PrimExpr& expr);
+
+/*!
+ * \brief Analyze the side effect
+ * \param expr The expression to be checked.
+ *
+ * \return CallEffectKind, can be kPure, kReadState or kUpdateState
+ */
+TVM_DLL CallEffectKind SideEffect(const PrimExpr& expr);
+
+/*!
+ * \brief Whether the given Stmt uses any var in the given variable set.
+ * \param stmt The Stmt to be checked.
+ * \param vset_contains The check function to see if a var is in the variable set.
+ * \return Whether `stmt` uses any var in the given variable set.
+ */
+TVM_DLL bool UsesVar(const Stmt& stmt, std::function<bool(const VarNode*)> vset_contains);
+
+/*!
+ * \brief Whether the given PrimExpr uses any var in the given variable set.
+ * \param expr The PrimExpr to be checked.
+ * \param vset_contains The check function to see if var is in the variable set.
+ * \return Whether `expr` uses any var in the given variable set.
+ */
+TVM_DLL bool UsesVar(const PrimExpr& expr, std::function<bool(const VarNode*)> vset_contains);
+
+/*!
+ * \brief Verifies whether the IR stmt or Expr is in SSA form.
+ *  That is: each Var is defined and assigned once(in Let/For)
+ *
+ * \param func The function to be verified.
+ * \return Whether IR is in SSA form.
+ *
+ * \note All passes in TIR consume and produce SSA form.
+ */
+TVM_DLL bool VerifySSA(const PrimFunc& func);
+
+/*!
+ * \brief Verify if memory accesses are legal for a specific target device type.
+ *
+ *  In the case that tgt is cuda, if not all workload is bound with
+ *  threads, CPU code is generated that tries to access GPU memory,
+ *  which is illegal. This pass performs verification for this case.
+ *
+ * \param func The function to be verified.
+ * \return Success of memory verification.
+ */
+TVM_DLL bool VerifyMemory(const PrimFunc& func);
+
+/*!
+ * \brief Verify the correctness of a GPU code
+ *        It will check the whether the amount of memory usage or the number of threads
+ *        in a block exceeds the limit
+ * \param func The function to be checked
+ * \param constraints The dict to specify constraints to check.
+ *        Possible keys are
+ *
+ *        "max_local_memory_per_block": Total amount of local memory per block (in bytes).
+ *        "max_shared_memory_per_block": Total amount of shared memory per block (in bytes).
+ *        "max_threads_per_block": Maximum number of threads per block.
+ *        "max_thread_x": Maximum length of threadIdx.x.
+ *        "max_thread_y": Maximum length of threadIdx.y.
+ *        "max_thread_z": Maximum length of threadIdx.z.
+ *
+ *        If one key is missing in this argument, the pass won't check for that item.
+ * \return valid Whether it is a valid GPU code
+ *
+ */
+TVM_DLL bool VerifyGPUCode(const PrimFunc& func, Map<String, PrimExpr> constraints);
+
+/*!
+ * \brief Verifies that the VTCM usage of the given prim_func is within the provided limit.
+ * \param func The function to be checked.
+ * \param limit The limit to check.
+ * \return true if the VTCM usage is within the provided limit.
+ */
+TVM_DLL bool VerifyVTCMLimit(const PrimFunc& func, Integer limit);
+
+/*!
+ * \brief Auto detect the block access region according to its body stmt
+ *        It will detect the access region as an array in order of appearance in AST
+ * \param block The block to be detected
+ * \param buffer_var_map The outside buffers which may be accessed the block.
+ *                       It is a map from buffer var to the buffer.
+ * \return Array of access regions.
+ *         There are three arrays of BufferRegion:
+ *           - first: read regions
+ *           - second: write regions
+ *           - third: opaque regions
+ */
+TVM_DLL Array<Array<BufferRegion>> GetBlockAccessRegion(const Block& block,
+                                                        const Map<Var, Buffer>& buffer_var_map);
+
+/*!
+ * \brief Auto detect the block read/write region according to its body stmt. An opaque access will
+ *        be counted as both a read and a write access
+ * \param block The block to be detected
+ * \param buffer_var_map The outside buffers which may be accessed the block.
+ *                       It is a map from buffer var to the buffer
+ * \return An array only consisting of the read regions and write regions of the input block
+ */
+TVM_DLL Array<Array<BufferRegion>> GetBlockReadWriteRegion(const Block& block,
+                                                           const Map<Var, Buffer>& buffer_var_map);
+
+/*!
+ * \brief Calculate the expresion complexity based on number of symbols it contains.
+ * \param expr The expr to be calculated.
+ */
+TVM_DLL size_t CalculateExprComplexity(const PrimExpr& expr);
+
+/*!
+ * \brief Calculate the constants size in bytes needed by the TIR allocates inside the TIR PrimFunc
+ * \param func The TIR PrimFunc for which the constants size to be calculated
+ * \param constant_byte_alignment The byte alignment required for each constant allocated
+ */
+TVM_DLL size_t CalculateConstantBytes(const PrimFunc& func, const Integer& constant_byte_alignment);
+
+/*!
+ * \brief Calculate the workspace size in bytes needed by the TIR allocates inside the TIR PrimFunc
+ * \param func The TIR PrimFunc for which the workspace size to be calculated
+ * \param workspace_byte_alignment The byte alignment required for each tensor allocated in this
+ * workspace
+ */
+TVM_DLL size_t CalculateWorkspaceBytes(const PrimFunc& func,
+                                       const Integer& workspace_byte_alignment);
+
+/*!
+ * \brief Calculate the allocated memory per scope in bytes needed inside the TIR PrimFunc
+ * \param func The TIR PrimFunc for which the the allocated memory size to be calculated
+ */
+TVM_DLL tvm::Map<String, Integer> CalculateAllocatedBytes(const PrimFunc& func);
+
+/*!
+ * \brief Detect the lowest common ancestor(LCA) of buffer access, including both high-level
+ *        access(BufferLoad, BufferStore) and low-level access(Load, Store and opaque access).
+ *        The LCA may be a For loop or a Block.
+ * \param func The PrimFunc to be detected.
+ * \return The Map from buffer to the LCA of all access to it. The lca is function root if the
+ *         return stmt is NullOpt.
+ */
+TVM_DLL Map<Buffer, Optional<Stmt>> DetectBufferAccessLCA(const PrimFunc& func);
+
+/*!
+ * \brief Verify if the given TIR is well-formed. The verification includes:
+ *        - Check if expressions not contain vars that is defined outside the block.
+ * \param func The PrimFunc to be verified.
+ * \param assert_mode The indicator if it raises an error when the function is not well-formed.
+ * \return Whether it is a well-formed TIR function.
+ */
+TVM_DLL bool VerifyWellFormed(const PrimFunc& func, bool assert_mode = true);
+
+/*!
+ * \brief Find the entry function of the given IRModule, i.e, functions marked by
+ * `tir::attr::kIsEntryFunc`, whose name is `main` or being the only PrimeFunc.
+ * \param mod The IRModule to find the entry function.
+ * \param result_g_var The result GlobalVar of the entry function.
+ * \return The entry function.
+ */
+const PrimFuncNode* FindEntryFunc(const IRModule& mod, GlobalVar* result_g_var);
+
+/*!
+ * \brief Find the "anchor block" of the given module.
+ * We define the anchor block to be the block with (1) an init statement and (2) having
+ * the biggest flops count. The latter condition is only used when there are multiple blocks
+ * with an init statement.
+ * For example, if the input module is conv2d + fused spatial blocks, conv2d is the anchor block.
+ * The input module may not contain more than one such block. For example, a module having
+ * two conv2d is not allowed as an input.
+ * However, a module created from winograd convolution has multiple blocks with an init statement
+ * (input transform, batched GEMM, and output transform). We use the second condition, the flops
+ * count, to determine that the batched GEMM block is the anchor block.
+ * \param mod The input TIR module.
+ * \return The anchor block if found, nullptr otherwise.
+ */
+const tir::BlockNode* FindAnchorBlock(const IRModule& mod);
+
+// Pass variants of verification analysis
+// directly throws RuntimeError when verification fails.
+namespace transform {
+
+using tvm::transform::Pass;
+using tvm::transform::PassContext;
+
+/*!
+ * \brief Pass variant of VerifySSA.
+ *
+ * \returns The pass.
+ * \sa tvm::tir::VerifySSA
+ */
+TVM_DLL Pass VerifySSA();
+
+/*!
+ * \brief Pass variant of VerifyMemory.
+ *
+ * \returns The pass.
+ * \sa tvm::tir::VerifyMemory
+ */
+TVM_DLL Pass VerifyMemory();
+
+/*!
+ * \brief Pass variant of VerifyGPUCode.
+ *
+ * \param constraints The dict to specify constraints to check.
+ *
+ * \returns The pass.
+ * \sa tvm::tir::VerifyGPUCode
+ */
+TVM_DLL Pass VerifyGPUCode(Map<String, PrimExpr> constraints);
+
+/*!
+ * \brief Pass to checks if the size of the allocated vtcm memory satisfies the limit
+ *
+ * \param limit The limit to check.
+ *
+ * \returns The pass.
+ * \sa tvm::tir::CalculateAllocatedBytes
+ */
+TVM_DLL Pass VerifyVTCMLimit(const Integer& limit);
+
+/*!
+ * \brief Statically check TIR code for out of bounds array access.
+ *
+ * This analysis is conservative: it will only raise errors if it can prove
+ * that out of bounds access occurs. Cases that are uncertain do not raise
+ * errors.
+ *
+ * \returns The pass.
+ */
+TVM_DLL Pass OOBChecker();
+
+}  // namespace transform
+}  // namespace tir
+}  // namespace tvm
+#endif  // TVM_TIR_ANALYSIS_H_
diff --git a/darknet_drp_ros/include/tvm/tir/buffer.h b/darknet_drp_ros/include/tvm/tir/buffer.h
new file mode 100644
index 0000000..d7a2aec
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/buffer.h
@@ -0,0 +1,317 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/tir/buffer.h
+ * \brief Symbolic n-dimensional array, to represent a memory buffer.
+ */
+#ifndef TVM_TIR_BUFFER_H_
+#define TVM_TIR_BUFFER_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/tir/var.h>
+
+#include <string>
+
+namespace tvm {
+namespace tir {
+
+// forward declare Stmt
+class Stmt;
+
+/*! \brief buffer type */
+enum BufferType : int {
+  kDefault = 1,
+  // Maps buffer[i][j][k] -> buffer[i][0][k] if dimension i's shape equals 1.
+  kAutoBroadcast = 2,
+};
+
+/*! \brief Node to represent a buffer */
+class BufferNode : public Object {
+ public:
+  // Data fields.
+  /*!
+   * \brief The pointer to the head of the data
+   * \sa data_alignment The alignment of data in bytes.
+   */
+  Var data;
+  /*! \brief data type in the content of the tensor */
+  DataType dtype;
+  /*! \brief The type of the buffer prior to flattening
+   *
+   * This contains the shape as it is accessed by
+   * BufferLoad/BufferStore nodes, and used by the low-level code
+   * generators.
+   */
+  Array<PrimExpr> shape;
+  /*!
+   * \brief Separators between input axes when generating flattened output axes
+   *
+   * For buffers representing flat 1-d memory (e.g. any buffer in
+   * RAM), this should be an empty array.  For buffers representing
+   * non-flat memory, each entry in axis_separators should be the
+   * first input axis that is part of a new flattened axis.
+   */
+  Array<IntImm> axis_separators;
+  /*!
+   * \brief The strides of each dimension
+   *  This can be an empty array, indicating array is contiguous
+   */
+  Array<PrimExpr> strides;
+  /*! \brief The offset in terms of number of dtype elements (including lanes) */
+  PrimExpr elem_offset;
+  // Meta data
+  /*! \brief optional name of the buffer */
+  String name;
+  /*! \brief Alignment requirement of data pointer in bytes. */
+  int data_alignment;
+  /*!
+   * \brief Factor of elem_offset field,
+   *  elem_offset is guaranteed to be multiple of offset_factor.
+   */
+  int offset_factor;
+  /*! \brief buffer type */
+  BufferType buffer_type;
+  /*!
+   * \brief Span that points to the original source code.
+   *        Reserved debug information.
+   */
+  mutable Span span;
+  /*! \brief constructor */
+  BufferNode() {}
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("data", &data);
+    v->Visit("dtype", &dtype);
+    v->Visit("shape", &shape);
+    v->Visit("strides", &strides);
+    v->Visit("axis_separators", &axis_separators);
+    v->Visit("elem_offset", &elem_offset);
+    v->Visit("name", &name);
+    v->Visit("data_alignment", &data_alignment);
+    v->Visit("offset_factor", &offset_factor);
+    v->Visit("buffer_type", &buffer_type);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const BufferNode* other, SEqualReducer equal) const {
+    // Use DefEqual as buffer can define variables in its semantics,
+    // skip name as name is not important.
+    return equal.DefEqual(data, other->data) && equal(dtype, other->dtype) &&
+           equal.DefEqual(shape, other->shape) && equal.DefEqual(strides, other->strides) &&
+           equal.DefEqual(axis_separators, other->axis_separators) &&
+           equal.DefEqual(elem_offset, other->elem_offset) &&
+           equal(data_alignment, other->data_alignment) && equal(buffer_type, other->buffer_type);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce.DefHash(data);
+    hash_reduce(dtype);
+    hash_reduce.DefHash(shape);
+    hash_reduce.DefHash(strides);
+    hash_reduce.DefHash(elem_offset);
+    hash_reduce.DefHash(axis_separators);
+    hash_reduce(data_alignment);
+    hash_reduce(buffer_type);
+  }
+
+  /*! \return preferred index type for this buffer node */
+  DataType DefaultIndexType() const {
+    return shape.size() != 0 ? shape[0].dtype() : DataType::Int(32);
+  }
+
+  /*! \brief Determine the offset in the buffer of the given index.
+   *
+   * Returns the buffer offset, in number of elements of type dtype,
+   * without adjusting for number of lanes.  (e.g. The number of
+   * float16x4 elements in a buffer of type float16x4.)
+   */
+  Array<PrimExpr> ElemOffset(Array<PrimExpr> index) const;
+
+  static constexpr const char* _type_key = "tir.Buffer";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_FINAL_OBJECT_INFO(BufferNode, Object);
+};
+
+/*!
+ * \brief Buffer is a symbolic n-darray structure.
+ *  It is a composition of primitive symbolic types,
+ *  used to specify the memory layout of the Tensor used in program input.
+ */
+class Buffer : public ObjectRef {
+ public:
+  // User can specify data_alignment and offset_factor to be 0
+  // A default value will be picked.
+  TVM_DLL Buffer(Var data, DataType dtype, Array<PrimExpr> shape, Array<PrimExpr> strides,
+                 PrimExpr elem_offset, String name, int data_alignment, int offset_factor,
+                 BufferType buffer_type, Array<IntImm> axis_separators = {}, Span span = Span());
+
+  /*!
+   * \brief Return a new buffer that is equivalent with current one
+   *  but always add stride field.
+   * \return The strided version of the buffer.
+   */
+  TVM_DLL Buffer MakeStrideView() const;
+  /*!
+   * \brief Make a new symbolic buffer representing a slice of the buffer.
+   * \param begins The beginning position of each dimension.
+   * \param extents The extent of each dimension.
+   * \note This function will make target buffer as compact as possible.
+   *  If stride is not needed in the slice, it won't be presented
+   * \return the result buffer.
+   */
+  TVM_DLL Buffer MakeSlice(Array<PrimExpr> begins, Array<PrimExpr> extents) const;
+  /*!
+   * \brief Get access ptr to the entire buffer.
+   * \param access_mask The access mask
+   * \param ptr_type The type of the pointer.
+   * \param content_lanes The number of lanes for the (data) type.
+   * \param offset The offset of ptr.
+   * \param input_extent The extent of ptr.
+   */
+  TVM_DLL PrimExpr access_ptr(int access_mask, DataType ptr_type = DataType::Handle(),
+                              int content_lanes = 1, PrimExpr offset = IntImm(DataType::Int(32), 0),
+                              Optional<PrimExpr> input_extent = NullOpt) const;
+  /*!
+   * \brief Create an Expr that does a vector load at begin index.
+   * \param begin The beginning index
+   * \param dtype The data type to be loaded.
+   */
+  TVM_DLL PrimExpr vload(Array<PrimExpr> begin, DataType dtype) const;
+  /*!
+   * \brief Create a Stmt that does a vector store at begin index.
+   * \param begin The beginning index
+   * \param value The value to be stored.
+   */
+  TVM_DLL Stmt vstore(Array<PrimExpr> begin, PrimExpr value) const;
+
+  /*!
+   * \brief Get a flattened version of the buffer
+   */
+  Buffer GetFlattenedBuffer() const;
+
+  /*! \brief Determine the offset in the buffer of the given index.
+   *
+   * Returns the buffer offset, in number of elements of type dtype,
+   * without adjusting for number of lanes.  (e.g. The number of
+   * float16x4 elements in a buffer of type float16x4.)
+   */
+  Array<PrimExpr> OffsetOf(Array<PrimExpr> index) const;
+
+  /*!
+   * \brief Return the storage scope associated with this buffer.
+   */
+  TVM_DLL String scope() const;
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Buffer, ObjectRef, BufferNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(BufferNode);
+};
+
+/*!
+ * \brief Construct a new buffer given shape, and dtype.
+ * \param shape The shape of the buffer,
+ * \param dtype The content data type.
+ * \param name The name of the buffer
+ * \param storage_scope The storage scope associated with this buffer
+ * \param axis_separators Divisions defining the groups of axes that will be flattened together.
+ * \param span The location of this object in the source code.
+ * \return The created buffer.
+ * \sa Buffer for complete constructor.
+ */
+TVM_DLL Buffer decl_buffer(Array<PrimExpr> shape, DataType dtype = DataType::Float(32),
+                           String name = "buffer", String storage_scope = "",
+                           Array<IntImm> axis_separators = {}, Span span = Span());
+
+/*!
+ * \brief Base node for data producers.
+ *
+ *  A DataProducer stores necessary information(e.g. a tensor expression) to produce
+ *  a multi-dimensional array. The stored information is opaque to the TIR.
+ *  DataProducer can appear in high-level DSLs that are built on top of the TIR.
+ *
+ *  A valid TIR PrimFunc should not contain any DataProducer, high level DSLs should lower
+ *  all DataProducers to Buffers before TIR transformations.
+ *
+ * \sa tvm::te::Tensor
+ */
+class DataProducerNode : public Object {
+ public:
+  /*! \brief destructor. */
+  virtual ~DataProducerNode() {}
+  /*!
+   * \brief Get the shape of the result.
+   * \return The shape.
+   */
+  virtual Array<PrimExpr> GetShape() const = 0;
+  /*!
+   * \brief Get the data type of the result.
+   * \return The data type.
+   */
+  virtual DataType GetDataType() const = 0;
+  /*!
+   * \brief Get the name hint of the data producer.
+   * \return The data type.
+   */
+  virtual String GetNameHint() const = 0;
+
+  bool SEqualReduce(const DataProducerNode* other, SEqualReducer equal) const {
+    // because buffer producer is opaque, we just do pointer equality.
+    return this == other;
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {}
+
+  static constexpr const char* _type_key = "tir.DataProducer";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_BASE_OBJECT_INFO(DataProducerNode, Object);
+};
+
+/*!
+ * \brief Managed reference to DataProducerNode.
+ * \sa DataProducerNode
+ */
+class DataProducer : public ObjectRef {
+ public:
+  TVM_DEFINE_OBJECT_REF_METHODS(DataProducer, ObjectRef, DataProducerNode);
+};
+
+/*!
+ * \brief Creates TIR Buffer for provided parameters
+ * \param shape shape of the buffer
+ * \param dtype data type
+ * \param name buffer name
+ * \param data_alignment alignment requirement of data pointer in bytes
+ * \param offset_factor Factor of elem_offset field, elem_offset is guaranteed to be
+ *                      multiple of offset_factor
+                        User can specify data_alignment and offset_factor to be 0
+ *                      A default value will be picked.
+ * \param compact If the statement has already bound to a compact buffer.
+ * \param memory_scope memory scope of the buffer
+ */
+TVM_DLL tir::Buffer BufferWithOffsetAlignment(Array<PrimExpr> shape, DataType dtype,
+                                              std::string name, int data_alignment,
+                                              int offset_factor, bool compact,
+                                              std::string memory_scope = "");
+}  // namespace tir
+}  // namespace tvm
+#endif  // TVM_TIR_BUFFER_H_
diff --git a/darknet_drp_ros/include/tvm/tir/builtin.h b/darknet_drp_ros/include/tvm/tir/builtin.h
new file mode 100644
index 0000000..d830ea5
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/builtin.h
@@ -0,0 +1,775 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/tir/builtin.h
+ * \brief TIR builtin intrinsics.
+ *
+ * TIR builtin intrinsics are stored as tvm:Op.
+ * They are processed in the same way as we process Ops.
+ *
+ * It is not necessary to create a function for every Op,
+ * as we can obtain them through Op::Get.
+ *
+ * This file contains the most commonly used intrinsics or
+ * those that have special semantics and need compiler support.
+ */
+#ifndef TVM_TIR_BUILTIN_H_
+#define TVM_TIR_BUILTIN_H_
+
+#include <tvm/ir/op.h>
+#include <tvm/tir/expr.h>
+
+namespace tvm {
+namespace tir {
+
+/*! \brief Collection of builtin intrinsics as ops */
+namespace builtin {
+/*!
+ * \brief Return value.
+ */
+TVM_DLL const Op& ret();
+/*!
+ * \brief Reinterpret the value using the target type.
+ */
+TVM_DLL const Op& reinterpret();
+
+/*!
+ * \brief Marks a condition is likely going to happen.
+ */
+TVM_DLL const Op& likely();
+
+/*!
+ * \brief Bitwise and operator.
+ */
+TVM_DLL const Op& bitwise_and();
+
+/*!
+ * \brief Bitwise or operator.
+ */
+TVM_DLL const Op& bitwise_or();
+
+/*!
+ * \brief Bitwise xor operator.
+ */
+TVM_DLL const Op& bitwise_xor();
+
+/*!
+ * \brief Bitwise not operator.
+ */
+TVM_DLL const Op& bitwise_not();
+
+/*!
+ * \brief Left shift
+ */
+TVM_DLL const Op& shift_left();
+
+/*!
+ * \brief Right shift
+ */
+TVM_DLL const Op& shift_right();
+
+/*!
+ * \brief See pesudo code
+ *
+ *  Construct a big uint that may not be representable by int64
+ *
+ *  Expr large_uint_imm(uint32_t v0, uin32_t v1) {
+ *    return (v1 << 32) | v0;
+ *  }
+ */
+TVM_DLL const Op& large_uint_imm();
+
+/*!
+ * \brief Execute a multiplication between two Q-numbers x and y
+ * followed by a right shift s
+ * The default rounding rule is to the nearest value, rounding half up
+ * (i.e., round(x.1) = x and round (x.5) = x+1)
+ */
+TVM_DLL const Op& q_multiply_shift();
+
+/*!
+ * \brief Returns the address of an element in the buffer (see pseudocode below).
+ *
+ * The number of indices should match the dimensionality of the buffer
+ * being accessed.  If this operation occurs after buffer flattening,
+ * the number of indices must be supported by the target (i.e. N>1
+ * only on targets that support non-flat memory buffers).
+ *
+ *  Handle address_of(BufferLoad *op) {
+ *     return &op->buffer_var[op->indices[0], op->indices[1], ..., op->indices[N-1]];
+ *  }
+ */
+TVM_DLL const Op& address_of();
+
+/*!
+ * \brief Same as select, used for unsafe memory access.
+ *
+ *  Type tvm_if_then_else(cond, a, b) {
+ *    return cond ? a : b;
+ *  }
+ */
+TVM_DLL const Op& if_then_else();
+
+/*!
+ * \brief See pesudo code
+ *
+ *  bool isnullptr(void* handle) {
+ *     return handle == nullptr
+ *  }
+ */
+TVM_DLL const Op& isnullptr();
+
+/*!
+ * \brief Check if value is nan
+ */
+TVM_DLL const Op& isnan();
+
+/*!
+ * \brief Popcount
+ */
+TVM_DLL const Op& popcount();
+
+/*!
+ * \brief Fused multiply add
+ *
+ *  Type fma(a, b, c) {
+ *    return a * b + c;
+ *  }
+ */
+TVM_DLL const Op& fma();
+
+/*!
+ * \brief Call an extern C function with given name
+ *        and signature from the types of args in the runtime environment.
+ *
+ *  Type call_extern(name, args...) {
+ *     return dlsym(name)(args...);
+ *  }
+ *
+ * \note This intrinsic does not provide any type checking,
+ *       and is main used for backward compatibility reasons.
+ *       Always consider use pre-registered and typed tvm::Op first.
+ */
+TVM_DLL const Op& call_extern();
+
+/*!
+ * \brief Call an pure extern C function with given name
+ *        and signature from the types of args in the runtime environment.
+ *
+ *  Type call_pure_extern(name, args...) {
+ *     return dlsym(name)(args...);
+ *  }
+ *
+ * \note This intrinsic does not provide any type checking,
+ *       and is main used for backward compatibility reasons.
+ *       Always consider use pre-registered and typed tvm::Op first.
+ */
+TVM_DLL const Op& call_pure_extern();
+
+/*!
+ * \brief Call an LLVM intrinsic with a given intrinsic id
+ *        and signature from the types of args in the runtime environment.
+ *
+ *  Type call_llvm_pure_intrin(intrin_id, args...) {
+ *     return dlsym(name)(args...);
+ *  }
+ *
+ * \note This op does not provide any type checking.
+ */
+TVM_DLL const Op& call_llvm_intrin();
+
+/*!
+ * \brief Call an LLVM pure intrinsic with a given intrinsic id
+ *        and signature from the types of args in the runtime environment.
+ *
+ *  Type call_llvm_pure_intrin(intrin_id, args...) {
+ *     return dlsym(name)(args...);
+ *  }
+ *
+ * \note This op does not provide any type checking.
+ */
+TVM_DLL const Op& call_llvm_pure_intrin();
+
+/*!
+ * \brief Call an SPIRV pure GLSL450 intrinsic.
+ *
+ *  Type call_spirv_pure_glsl450(intrin_id, args...) {
+ *     return dlsym(name)(args...);
+ *  }
+ *
+ * \note This op does not provide any type checking.
+ */
+TVM_DLL const Op& call_spirv_pure_glsl450();
+
+// TODO(tvm-team) revisit the builtins below
+// some of them can simply become ops with special codegen attr.
+/*!
+ * \brief Prefetch a cacheline
+ */
+TVM_DLL const Op& prefetch();
+
+/*!
+ * \brief Get head access address with memory access pattern info.
+ *
+ *  This operator also marks range of the memory access
+ *  The offset and extent are in unit of the DType(including vectorization factor).
+ *  rw_mask is a bit_mask setting whether the access is a read(1) or write(2).
+ *  The access is assume to happen in the current expression.
+ *
+ *  PtrType tvm_access_ptr(Expr dtype, DType* data,
+ *                         int offset, int extent,
+ *                         int rw_mask) {
+ *    // DType == dtype.type();
+ *    return &data[offset];
+ *  }
+ */
+TVM_DLL const Op& tvm_access_ptr();
+
+/*!
+ * \brief Create a function local static handle that iniitalizes to nullptr.
+ *  can be used to cache function local static resources.
+ */
+TVM_DLL const Op& tvm_static_handle();
+
+/*!
+ * \brief Return a unique context id, used for hint of workspace separation.
+ *  Different context id ganrantees not having overlapping workspace.
+ */
+TVM_DLL const Op& tvm_context_id();
+
+/*!
+ * \brief tvm_tuple is not an actual function and cannot codegen.
+ *  It is used to represent tuple structure in value field of AttrStmt,
+ *  for the sake of giving hint to optimization.
+ *
+ *  Handle tvm_tuple(value0, value1, ..., value_n);
+ */
+TVM_DLL const Op& tvm_tuple();
+
+/*!
+ * \brief See pesudo code
+ *
+ *  Type tvm_struct_get(StructType* arr, int index, int field_id) {
+ *     return arr[index]->field;
+ *  }
+ * \sa TVMStructFieldKind
+ */
+TVM_DLL const Op& tvm_struct_get();
+
+/*!
+ * \brief See pesudo code
+ *
+ *  Handle tvm_struct_set(StructType* arr, int index, int field_id, value) {
+ *     arr[index]->field = value;
+ *  }
+ * \sa TVMStructFieldKind
+ */
+TVM_DLL const Op& tvm_struct_set();
+
+/*!
+ * \brief See pseudo code
+ * Type lookup_param(String param_name) {
+ *     return __tvm_param__param_name;
+ * }
+ */
+TVM_DLL const Op& lookup_param();
+
+/*!
+ * \brief See pesudo code
+ *
+ *  void tvm_throw_last_error() {
+ *    throw TVMGetLastError();
+ *  }
+ */
+TVM_DLL const Op& tvm_throw_last_error();
+
+/*!
+ * \brief See pesudo code
+ *
+ *  dtype in {shape, array, arg_value, arg_tcode}
+ *
+ *  Handle tvm_stack_alloca(string dtype, int num) {
+ *     return new on stack dtype[num];
+ *  }
+ */
+TVM_DLL const Op& tvm_stack_alloca();
+
+/*!
+ * \brief Allocate a shape tuple on stack, return the handle.
+ *
+ *  Handle tvm_stack_make_shape(list args) {
+ *     ret = alloca stack int64_t[len(args)];
+ *     for i in range(len(args)):
+ *        ret[i] = args[i]
+ *     return &ret[0];
+ *  }
+ */
+TVM_DLL const Op& tvm_stack_make_shape();
+
+/*!
+ * \brief Allocate a NDArray(DLTensor) on stack, return the handle.
+ *
+ *  Type tvm_stack_make_array(Expr data,
+ *                            Expr shape,
+ *                            Expr strides,
+ *                            Expr ndim,
+ *                            Expr dtype,
+ *                            Expr elem_offset) {
+ *     ret = alloca stack DLTensor();
+ *     ret->data = data;
+ *     ret->shape = shape;
+ *     ret->strides = strides != 0 ? strides : nullptr;
+ *     ret->ndim = ndim;
+ *     ret->dtype = dtype.type();
+ *     ret->byte_offset = elem_offset * sizeof(dtype);
+ *     return ret;
+ *  }
+ */
+TVM_DLL const Op& tvm_stack_make_array();
+
+/*!
+ * \brief See pesudo code
+ *
+ *  return_type tvm_call_packed(name, TVMValue* args) {
+ *     TVMValue ret_value;
+ *     int ret_code;
+ *     ModuleNode* env = GetCurrentEnv();
+ *     const PackedFunc* f = env->GetFuncFromEnv(name);
+ *     (*f)(args, type_code_of(args), len(args), &ret_value, &ret_code);
+ *     // return type can be int, float, handle.
+ *     return cast(return_type, ret_value.v_return_type);
+ *  }
+ */
+TVM_DLL const Op& tvm_call_packed();
+
+/*!
+ * \brief See pesudo code
+ *
+ * return_type tvm_call_packed(fname, TVMValue* args) {
+ * 	   int ret_code;
+ *     TVMValue ret_value;
+ *     (*fname)(args, type_code_of(args), len(args), &ret_value, &ret_code);
+ *     return cast(return_type, ret_value.v_return_type);
+ *  }
+ */
+TVM_DLL const Op& tvm_call_cpacked();
+
+/*!
+ * \brief See pesudo code
+ *
+ *  return_type tvm_call_trace_packed(name, TVMValue* args) {
+ *     ModuleNode* env = GetCurrentEnv();
+ *     const PackedFunc* f = env->GetFuncFromEnv(name);
+ *     (*f)(args, type_code_of(args), len(args));
+ *     // return type can be int, float, handle.
+ *     return cast(return_type, ret_value.v_return_type);
+ *  }
+ */
+TVM_DLL const Op& tvm_call_trace_packed();
+
+/*!
+ * \brief Checks the return value of another call is correct or returns a given value.
+ *
+ * \note  This is meant to serve a specific case for AOT code generator whilst this
+ *        cannot be fully represented in TIR.
+ *
+ *  Type tvm_check_return(expected, return_unexpected, nested_call) {
+ *     if (nested_call() != expected) {
+ *         return return_unexpected;
+ *     }
+ *  }
+ */
+TVM_DLL const Op& tvm_check_return();
+
+/*!
+ * \brief See pesudo code
+ *  Mark the content as thread local context, can get optimized
+ *  by only call the call once at thread start.
+ *
+ *  Do not allow nesting(getting a thread context from another).
+ *
+ *  Handle tvm_thread_context(Expr call) {
+ *     return call;
+ *  }
+ */
+TVM_DLL const Op& tvm_thread_context();
+
+/*!
+ * \brief Lowered version of call packed, the space of value and
+ *  type codes are explicitly allocated.
+ *
+ *  return_type tvm_call_packed_lowered(name,
+ *                                      TVMValue* value_stack,
+ *                                      int* tcode_stack,
+ *                                      int begin,
+ *                                      int end) {
+ *     ModuleNode* env = GetCurrentEnv();
+ *     const PackedFunc* f = env->GetFuncFromEnv(name);
+ *     f->CallPacked(TVMArgs(value_stack[begin:end],
+ *                           tcode_stack[begin:end]),
+ *                   TVMRetValue(value_stack + end, tcode_stack + end));
+ *     // return type can be int, float, handle.
+ *     return cast(return_type, load_return_from(tcode_stack + end))
+ *  }
+ */
+TVM_DLL const Op& tvm_call_packed_lowered();
+
+/*!
+ * \brief Lowered version of call c-packed, the space of value and
+ *  type codes are explicitly allocated.
+ *
+ *  int tvm_call_packed_lowered(fname,
+ *                              TVMValue* value_stack,
+ *                              int* tcode_stack,
+ *                              int begin,
+ *                              int end) {
+ *     fname(TVMArgs(value_stack[begin:end], tcode_stack[begin:end]),
+ *                   TVMRetValue(value_stack + end, tcode_stack + end));
+ *  }
+ */
+TVM_DLL const Op& tvm_call_cpacked_lowered();
+
+/*!
+ * \brief Lowered version of trace intrinsic, the space of value and
+ *  type codes are explicitly allocated. The return value is the
+ *  (end - 1) value on the stack.
+ *
+ *  return_type tvm_call_trace_packed_lowered(name,
+ *                                            TVMValue* value_stack,
+ *                                            int* tcode_stack,
+ *                                            int begin,
+ *                                            int end) {
+ *     ModuleNode* env = GetCurrentEnv();
+ *     const PackedFunc* f = env->GetFuncFromEnv(name);
+ *     f->CallPacked(TVMArgs(value_stack[begin:end],
+ *                           tcode_stack[begin:end]),
+ *                   TVMRetValue(value_stack + end, tcode_stack + end));
+ *     // return type can be int, float, handle.
+ *     return cast(return_type, load_return_from(tcode_stack + end))
+ *  }
+ */
+TVM_DLL const Op& tvm_call_trace_packed_lowered();
+
+/*!
+ * \brief See pseudo code
+ *
+ *  int tvm_storage_sync(std::string storage_scope) {
+ *     __sync(storage_scope);
+ *     return 0;
+ *  }
+ */
+TVM_DLL const Op& tvm_storage_sync();
+
+/*!
+ * \brief See pseudo code
+ *
+ *  Type tvm_warp_shuffle(mask, Type value, warp_id, width, warp_size) {
+ *    return (value passed in by warp indicated by this_warp_id);
+ *  }
+ *
+ *  Type tvm_warp_shuffle_up(mask, Type value, offset, width, warp_size) {
+ *    return (value passed in by warp indicated by this_warp_id - offset);
+ *  }
+ *
+ *  Type tvm_warp_shuffle_down(mask, Type value, offset, width, warp_size) {
+ *    return (value passed in by warp indicated by this_warp_id + offset);
+ *  }
+ *
+ *  unsigned tvm_warp_activemask() {
+ *    return (32-bit mask of currently active threads in the calling warp);
+ *  }
+ *
+ *  Parameter warp_id indicates the source thread ID in a warp.
+ *
+ *  Parameter offset indicates the relative distance to this_warp_id.
+ *
+ *  Parameter width indicates the number of threads involved in one
+ *  shuffle. See CUDA document for __shfl_sync, __shfl_up_sync,
+ *  __shfl_down_sync and __activemask.
+ *
+ *  Parameter warp_size is the size of a warp, which helps a backend
+ *  to determine wheter the width paramter is legal.
+ *
+ */
+TVM_DLL const Op& tvm_warp_shuffle();
+TVM_DLL const Op& tvm_warp_shuffle_up();
+TVM_DLL const Op& tvm_warp_shuffle_down();
+TVM_DLL const Op& tvm_warp_activemask();
+
+/*!
+ * \brief Initialize the global barrier.
+ *  Call this at beginning of kernel that need global barrier.
+ */
+TVM_DLL const Op& tvm_global_barrier_kinit();
+
+/*!
+ * \brief See pesudo code
+ *
+ *  void tvm_thread_allreduce(UIntImm size, Expr source0, ..., Expr cond,
+ *                            Var reduce_temp0, .., Var thread_idx1, ...) {
+ *     // constraint by the other thread_idx remain the same.
+ *     // reduce_temp is used to save intermediate result.
+ *     reduce_temp0, ... = reduce(combiner, source0, ..., cond
+ *       over [thread_idx1, thread_idx2] passed by any caller)
+ *  }
+ */
+TVM_DLL const Op& tvm_thread_allreduce();
+
+// TODO(tvm-team) TensorCore specific intrinsics should be directly registered under
+//                cuda. namespace and used through op.
+/*!
+ * \brief tvm intrinsic for tensor core load operators.
+ *
+ *  void tvm_load_matrix_sync(Var fragment, UIntImm m, UIntImm, n, UIntImm k,
+ *                            Expr index, Expr buffer_ptr, Expr stride,
+ *                            StringImm layout) {
+ *    // m, n, k are the shape of wmma fragment.
+ *    // Determine fragment layout(column-major or row major) by layout.
+ *    // fragments must be in 'wmma.matrix_a' or 'wmma.matrix_b' scope.
+ *    nvcuda::wmma::load_matrix_sync(fragment[index], buffer_ptr, stride);
+ *  }
+ */
+TVM_DLL const Op& tvm_load_matrix_sync();
+
+/*!
+ * \brief tvm intrinsic for tensor core mma_sync operators.
+ *
+ *  void tvm_mma_sync(Var fragment_d, Expr index_d,
+ *                    Var fragment_a, Expr index_a,
+ *                    Var fragment_b, Expr index_b,
+ *                    Var fragment_c, Expr index_c) {
+ *    nvcuda::wmma::mma_sync(fragment_d[index_d], fragment_a[index_a],
+ *                           fragment_b[index_b], fragment_c[index_c]);
+ *  }
+ */
+TVM_DLL const Op& tvm_mma_sync();
+
+/*!
+ * \brief tvm intrinsic for tensor core bmma_sync operators.
+ *
+ *  void tvm_bmma_sync(Var fragment_d, Expr index_d,
+ *                     Var fragment_a, Expr index_a,
+ *                     Var fragment_b, Expr index_b,
+ *                     Var fragment_c, Expr index_c) {
+ *    nvcuda::wmma::bmma_sync(fragment_d[index_d], fragment_a[index_a],
+ *                           fragment_b[index_b], fragment_c[index_c]);
+ *  }
+ */
+TVM_DLL const Op& tvm_bmma_sync();
+
+/*!
+ * \brief tvm intrinsic for tensor core fill_fragment operators.
+ *
+ *  void tvm_fill_fragment(Var fragment, UIntImm m, UIntImm, n, UIntImm k,
+ *                         Expr index, Expr value) {
+ *    // m, n, k are the shape of wmma fragment
+ *    // fragments must be in 'wmma.accumulator' scope.
+ *    nvcuda::wmma::fill_fragment(fragment[index], value);
+ *  }
+ */
+TVM_DLL const Op& tvm_fill_fragment();
+
+/*!
+ * \brief tvm intrinsic for tensor core store operators.
+ *
+ *  void tvm_store_matrix_sync(Var fragment, UIntImm m, UIntImm, n, UIntImm k,
+ *                             Expr index, Expr buffer_ptr, Expr stride,
+ *                             StringImm layout) {
+ *    // m, n, k are the shape of wmma fragment
+ *    // fragments must be in 'wmma.accumulator' scope.
+ *    nvcuda::wmma::store_matrix_sync(fragment[index], buffer_ptr, stride, layout);
+ *  }
+ */
+TVM_DLL const Op& tvm_store_matrix_sync();
+
+/*!
+ * \brief tvm intrinsic for ptx tensor core mma instructions.
+ *
+ *  void ptx_mma(StringImm shape, StringImm A_layout, StringImm B_layout,
+ *               StringImm A_dtype, StringImm B_dtype, StringImm C_dtype,
+ *               Var multiplicand_a, Expr a_index,
+ *               Var multiplicand_b, Expr b_index,
+ *               Var accumulator, Expr c_index, bool saturate);
+ */
+TVM_DLL const Op& ptx_mma();
+
+/*!
+ * \brief tvm intrinsic for sparse tensor core ptx instructions.
+ *
+ * void ptx_mma_sp(StringImm shape, StringImm A_layout, StringImm B_layout,
+ *                 StringImm A_dtype, StringImm B_dtype, StringImm C_dtype,
+ *                 Var multiplicand_a, Expr a_index,
+ *                 Var multiplicand_b, Expr b_index,
+ *                 Var accumulator, Expr c_index,
+ *                 Var metadata, Expr meta_index,
+ *                 Var sparse_selector, bool saturate);
+ */
+TVM_DLL const Op& ptx_mma_sp();
+
+/*!
+ * \brief tvm intrinsic for ptx load matrix from shared memory.
+ *
+ * void ptx_ldmatrix(Bool trans, IntImm num, StringImm type,
+ *                   Var local_ptr, Expr local_offset,
+ *                   Var smem_ptr, Expr smem_offset);
+ */
+TVM_DLL const Op& ptx_ldmatrix();
+
+/*!
+ * \brief tvm intrinsics for ptx async copy from global to shared memory
+ *
+ * void ptx_cp_async(Var shared_ptr, Expr shared_offset, Var global_ptr, Expr global_offset, size_t
+ * bytes);
+ *
+ */
+TVM_DLL const Op& ptx_cp_async();
+
+/*!
+ * \brief tvm intrinsics for ptx async copy commit and wait.
+ *
+ * void ptx_commit_group();
+ * void ptx_wait_group(int num);
+ *
+ */
+TVM_DLL const Op& ptx_commit_group();
+TVM_DLL const Op& ptx_wait_group();
+
+/*!
+ * \brief tvm intrinsic for storing the result of PTX MMA into a destination pointer.
+ *        For example, if each thread in a warp of size 32 has 4 elements from the result of
+ *        m16xn8xk16 MMA in its registers, this intrinsic can be used to store the result in a
+ *        16x8 region in shared or global memory.
+ *
+ *        There is no real PTX instruction that does that, but we want to hide details of
+ *        complex index manipulation behind this intrinsic to simplify TIR lowering passes (e.g.
+ *        LowerWarpMemory).
+ *
+ * void mma_store(IntImm m, IntImm n, Var dst_ptr, Var src_ptr, Expr src_offset, Var dst_stride);
+ */
+TVM_DLL const Op& mma_store();
+
+/*!
+ * \brief tvm intrinsic for zero-initalizing an MMA accumulation registor.
+ *        For example, if each thread in a warp of size 32 has 8 elements from the A matrix in
+ *        m16xn8xk16 MMA in its registers, this intrinsic can be used to zero-initialize its
+ *        4 accumulation registers.
+ *
+ *        There is no real PTX instruction that does that, but we introduce this intrinsic for the
+ *        same reason as mma_store above.
+ *
+ * void mma_fill(IntImm local_size, Var local_ptr, Expr offset);
+ */
+TVM_DLL const Op& mma_fill();
+
+// TODO(tvm-team) replace the usage of the vector operations by Shuffle.
+/*!
+ * \brief Get the high level half of the vector
+ */
+TVM_DLL const Op& vectorhigh();
+
+/*!
+ * \brief Get the low-level half of the vector
+ */
+TVM_DLL const Op& vectorlow();
+
+/*!
+ * \brief Concat two vectors.
+ */
+TVM_DLL const Op& vectorcombine();
+
+/*!
+ * \brief atomic add instruction, corresponding e.g. to atomicAdd in CUDA
+ */
+TVM_DLL const Op& atomic_add();
+/*!
+ * \brief Create an Nd memory allocation with storage scope
+ */
+TVM_DLL const Op& nd_mem_alloc_with_scope();
+
+/*!
+ * \brief Store to texture 2d memory
+ */
+TVM_DLL const Op& texture2d_store();
+
+/*!
+ * \brief Load from texture 2d memory
+ */
+TVM_DLL const Op& texture2d_load();
+
+/*!
+ * \brief Initiate a non-blocking DMA copy from source to destination
+ */
+TVM_DLL const Op& dma_copy();
+
+/*!
+ * \brief Wait until the number of DMAs in flight is less than or equal to some maximum
+ */
+TVM_DLL const Op& dma_wait();
+
+/*!
+ * \brief Provide a true statement that can be used for simplifications
+ *
+ * Compile-time representation of known constraints about function
+ * inputs.  This assumption is removed when lowering, and does not
+ * occur in codegen.
+ */
+TVM_DLL const Op& assume();
+
+/*!
+ * \brief Returns an initialized but arbitrary value
+ *
+ * Compile-time representation of memory locations whose values may be
+ * altered as a result of optimizations.
+ */
+TVM_DLL const Op& undef();
+
+/*!
+ * \brief Profiling intrinsic
+ */
+TVM_DLL const Op& start_profile_intrinsic();
+
+/*!
+ * \brief Profiling intrinsic
+ */
+TVM_DLL const Op& end_profile_intrinsic();
+
+/*! \brief The kind of structure field info used in intrinsic */
+enum TVMStructFieldKind : int {
+  // array head address
+  kArrAddr,
+  kArrData,
+  kArrShape,
+  kArrStrides,
+  kArrNDim,
+  kArrTypeCode,
+  kArrTypeBits,
+  kArrTypeLanes,
+  kArrByteOffset,
+  kArrDeviceId,
+  kArrDeviceType,
+  kArrKindBound_,
+  // TVMValue field
+  kTVMValueContent,
+  kTVMValueKindBound_
+};
+}  // namespace builtin
+}  // namespace tir
+}  // namespace tvm
+#endif  // TVM_TIR_BUILTIN_H_
diff --git a/darknet_drp_ros/include/tvm/tir/data_layout.h b/darknet_drp_ros/include/tvm/tir/data_layout.h
new file mode 100644
index 0000000..81c3e98
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/data_layout.h
@@ -0,0 +1,354 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/tir/data_layout.h
+ * \brief Layout expression to describe the data organization of a tensor.
+ *  And BijectiveLayout to mapping two data layouts between each other.
+ */
+#ifndef TVM_TIR_DATA_LAYOUT_H_
+#define TVM_TIR_DATA_LAYOUT_H_
+
+#include <tvm/tir/expr.h>
+#include <tvm/tir/op.h>
+
+#include <algorithm>
+#include <sstream>
+#include <string>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+namespace tir {
+
+class Layout;
+
+class LayoutAxis {
+ public:
+  static const LayoutAxis& Get(const char name);
+
+  // Get the singleton LayoutAxis using itvar->var->name_hint
+  static const LayoutAxis& Get(const tir::IterVar& itvar);
+
+  // Get the singleton LayoutAxis using name[0] (size of name must be 1).
+  static const LayoutAxis& Get(const std::string& name);
+
+  inline bool IsPrimal() const { return name_ >= 'A' && name_ <= 'Z'; }
+  inline std::string name() const { return std::string(1, name_); }
+
+  // if current axis is primal, switch the axis to its subordinate one,
+  // else switch to the primal.
+  inline const LayoutAxis& ToDual() const {
+    if (name_ >= 'A' && name_ <= 'Z') {
+      return LayoutAxis::Get(name_ - 'A' + 'a');
+    } else {
+      return LayoutAxis::Get(name_ - 'a' + 'A');
+    }
+  }
+
+  // return the primal axis. If it is already primal, return itself.
+  const LayoutAxis& ToPrimal() const { return IsPrimal() ? *this : ToDual(); }
+
+  // return the subordinate axis. If it is already subordinate, return itself.
+  const LayoutAxis& ToSubordinate() const { return IsPrimal() ? ToDual() : *this; }
+
+  inline bool operator==(const LayoutAxis& rhs) const { return name_ == rhs.name_; }
+
+  friend std::ostream& operator<<(std::ostream& os, const LayoutAxis& l) {
+    os << l.name();
+    return os;
+  }
+
+ private:
+  static const LayoutAxis UPPER_CASE[];
+  static const LayoutAxis LOWER_CASE[];
+  LayoutAxis(const LayoutAxis&);
+  LayoutAxis& operator=(const LayoutAxis&);
+  explicit LayoutAxis(const char name) : name_(name) {}
+
+  const char name_;
+};
+
+/*!
+ * \brief Layout is to describe how data is organized within an N-dimention tensor.
+ *  It is composed of upper cases, lower cases and numbers,
+ *  where upper case indicates a primal axis and
+ *  the corresponding lower case with factor size indicates the subordinate axis.
+ *  For example, NCHW16c can describe a 5-D tensor of
+ *  [batch_size, channel, height, width, channel_block].
+ *  Here subordinate axis channel_block=16 is the factor size of the primal axis C (channel).
+ *  Layout for scalar is defined, while both its name and axes have size 0.
+ */
+class LayoutNode : public Object {
+ public:
+  /*! \brief string representation of layout, "" for scalar. */
+  String name;
+  /*! \brief specify each axis of the layout,
+   *   in which the variable name is the name of the axis.
+   *   The IterVar's extent indicates the size of the axis,
+   *   it is a variable for a primal axis, but a constant for a subordinate axis.
+   *   Empty for scalar's layout.
+   */
+  Array<tir::IterVar> axes;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("name", &name);
+    v->Visit("axes", &axes);
+  }
+
+  static constexpr const char* _type_key = "tir.Layout";
+  TVM_DECLARE_FINAL_OBJECT_INFO(LayoutNode, Object);
+};
+
+/*!
+ * \brief Managed reference to LayoutNode
+ * \sa LayoutNode
+ */
+class Layout : public ObjectRef {
+ public:
+  explicit Layout(const Array<tir::IterVar>& axes);
+
+  /*! \brief construct from a string */
+  Layout(const tvm::String& name) : Layout(name.operator std::string()) {}  // NOLINT(*)
+
+  /*! \brief construct from a string */
+  Layout(const char* name) : Layout(std::string(name)) {}  // NOLINT(*)
+
+  /*!
+   * \brief construct from a string.
+   * \param name input in layout convention:
+   *        upper case indicates a dimension and
+   *        the corresponding lower case with factor size
+   *        indicates the split dimension.
+   *        return undefined layout if "__undef__" is passed.
+   */
+  TVM_DLL Layout(const std::string& name);  // NOLINT(*)
+
+  /*!
+   * \brief access the internal node container
+   * \return the pointer to the internal node container
+   */
+  LayoutNode* operator->() { return static_cast<LayoutNode*>(get_mutable()); }
+
+  /*!
+   * \brief Return an undefined layout.
+   * \return a (global) undefined layout.
+   */
+  static const Layout& Undef() {
+    static Layout undef;
+    return undef;
+  }
+
+  /*!
+   * \brief Returns a sub-layout which is the portion of the object
+   *        that starts at dimension \p pos and spans \p len dimensions
+   *        (or until the end of the layout, whichever comes first).
+   * \param pos The start position.
+   * \param len The length of the sub-layout. if 0, return layout of scalar
+   * \return A newly constructed Layout object.
+   */
+  Layout SubLayout(size_t pos, size_t len) const;
+
+  /*!
+   * \brief Split \p axis by \p size and put the sub-axis to position \p target_pos.
+   * \param axis The source axis to be split. It must be a primal-axis;
+   * \param target_pos The target position of the newly split subordinate-axis.
+   * \param factor size of the sub-dimension.
+   * \return A newly constructed Layout object.
+   */
+  Layout Split(const LayoutAxis& axis, size_t target_pos, int32_t factor) const;
+
+  /*! \return number of dimensions */
+  inline size_t ndim() const {
+    if (!defined()) return 0;
+    return operator->()->axes.size();
+  }
+
+  /*! \return number of super dimensions */
+  inline size_t ndim_primal() const {
+    if (!defined()) return 0;
+    size_t ct = 0;
+    for (auto x : operator->()->axes) {
+      if (LayoutAxis::Get(x).IsPrimal()) {
+        ct++;
+      }
+    }
+    return ct;
+  }
+
+  /*!
+   * \brief Returns a new layout where the dims have been expanded to match the primal dimensions.
+   * \param dst_layout The dst layout to which current layout has to be expanded.
+   * \return The expanded Layout.
+   */
+  inline Layout ExpandPrimal(const Layout& dst_layout) {
+    Layout new_src_layout;
+    // 1) Find the axis which are missing in the current layout. Make them the prefix.
+    std::string new_src_layout_str = "";
+    for (auto dst_axis : dst_layout->axes) {
+      if (LayoutAxis::Get(dst_axis).IsPrimal()) {
+        if (!this->Contains(LayoutAxis::Get(dst_axis))) {
+          new_src_layout_str += dst_axis->var->name_hint;
+        }
+      }
+    }
+    // 2) Now, add the primal axis of the current layout.
+    new_src_layout_str += this->name();
+    new_src_layout = Layout(new_src_layout_str);
+    return new_src_layout;
+  }
+
+  /*!
+   * \brief return the index of the input axis.
+   *        If it is not found in the layout or the layout is undefined,
+   *        return -1.
+   * \param axis the input axis.
+   * \return the index or -1 if not found.
+   */
+  inline int32_t IndexOf(const LayoutAxis& axis) const {
+    if (!this->defined()) return -1;
+    const auto axes = operator->()->axes;
+    for (size_t i = 0; i < axes.size(); ++i) {
+      if (axes[i]->var->name_hint == axis.name()) return static_cast<int32_t>(i);
+    }
+    return -1;
+  }
+
+  /*!
+   * \brief Get the factor size of the subordinate axis.
+   * \param axis the input primal-axis or subordinate-axis.
+   * \return the size of the subordinate-axis of \p axis (if \p axis is a primal-axis),
+   *         or the size of \p axis itself (if \p axis is a subordinate-axis).
+   *         Return -1 if \p axis is not in the layout the layout is undefined.
+   */
+  int32_t FactorOf(const LayoutAxis& axis) const;
+
+  /*!
+   * \brief Whether the layout contains an axis.
+   * \param axis axis to be checked.
+   * \return Whether the layout contains the axis.
+   */
+  bool Contains(const LayoutAxis& axis) const {
+    if (!defined()) return false;
+    for (const tir::IterVar var : operator->()->axes) {
+      if (var->var->name_hint == axis.name()) {
+        return true;
+      }
+    }
+    return false;
+  }
+
+  const LayoutAxis& operator[](int32_t i) const {
+    ICHECK(defined()) << "Try to access axis from an undefined layout.";
+    int32_t index = i < 0 ? static_cast<int32_t>(ndim() + i) : i;
+    ICHECK(index >= 0 && static_cast<size_t>(index) < ndim()) << "Invalid index " << i;
+    const tir::IterVar axis = operator->()->axes[index];
+    return LayoutAxis::Get(axis);
+  }
+
+  /*! \return the string description of the layout */
+  inline std::string name() const {
+    if (!defined()) return "__undef__";
+    return operator->()->name;
+  }
+
+  /*!
+   * \brief Whether the two layouts are equal.
+   * \param rhs Another layout.
+   * \return whether the two layouts are equal.
+   */
+  inline bool Equals(const Layout& rhs) const { return name() == rhs.name(); }
+
+  /*!
+   * \brief allow output string of layout to ostream
+   * \param os the output stream
+   * \param l the layout
+   * \return the ostream
+   */
+  friend std::ostream& operator<<(std::ostream& os, const Layout& l) {
+    os << l.name();
+    return os;
+  }
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Layout, ObjectRef, LayoutNode);
+};
+
+// Internal node container BijectiveLayout
+class BijectiveLayoutNode : public Object {
+ public:
+  /*! \brief Describes how source axes can be mapped to the destination axes,
+   *   e.g., [i0 / 16, i1, i0 % 16] can describe NC -> NC16n
+   */
+  Array<PrimExpr> index_forward_rule;
+  /*! \brief Describes how destination axes can be mapped to the source axes */
+  Array<PrimExpr> index_backward_rule;
+  /*! \brief Describes how source shapes can be mapped to the destination shapes */
+  Array<PrimExpr> shape_forward_rule;
+  /*! \brief Describes how destination shapes can be mapped to the source shapes */
+  Array<PrimExpr> shape_backward_rule;
+
+  /*! \brief The source layout */
+  Layout src_layout;
+  /*! \brief The destination layout */
+  Layout dst_layout;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("src_layout", &src_layout);
+    v->Visit("dst_layout", &dst_layout);
+    v->Visit("index_forward_rule", &index_forward_rule);
+    v->Visit("index_backward_rule", &index_backward_rule);
+    v->Visit("shape_forward_rule", &shape_forward_rule);
+    v->Visit("shape_backward_rule", &shape_backward_rule);
+  }
+
+  static constexpr const char* _type_key = "tir.BijectiveLayout";
+  TVM_DECLARE_FINAL_OBJECT_INFO(BijectiveLayoutNode, Object);
+};
+
+/*!
+ * \brief Bijective function mapping for data layout transformation.
+ *   Given two Layout, BijectiveLayout build and store the mapping rules,
+ *   provides API to transform N-dimention tensor from the source indices (i0, i1, .., im)
+ *   to the destination indices (j0, j1, .., jm).
+ */
+class BijectiveLayout : public ObjectRef {
+ public:
+  /*!
+   * \brief The constructor
+   * \param src_layout The source layout
+   * \param dst_layout The destination layout
+   */
+  TVM_DLL BijectiveLayout(Layout src_layout, Layout dst_layout);
+
+  // Given the source shape, infer the destination shape.
+  TVM_DLL Array<PrimExpr> ForwardShape(const Array<PrimExpr>& shape) const;
+  // Given the destination shape, recover the source shape.
+  TVM_DLL Array<PrimExpr> BackwardShape(const Array<PrimExpr>& dst_shape) const;
+  // Given the destination indices, infer the destination indices.
+  TVM_DLL Array<PrimExpr> ForwardIndex(const Array<PrimExpr>& index) const;
+  // Given the destination indices, recover the source indices.
+  TVM_DLL Array<PrimExpr> BackwardIndex(const Array<PrimExpr>& dst_index) const;
+
+  TVM_DEFINE_OBJECT_REF_METHODS(BijectiveLayout, ObjectRef, BijectiveLayoutNode);
+};
+
+}  // namespace tir
+}  // namespace tvm
+
+#endif  // TVM_TIR_DATA_LAYOUT_H_
diff --git a/darknet_drp_ros/include/tvm/tir/data_type_rewriter.h b/darknet_drp_ros/include/tvm/tir/data_type_rewriter.h
new file mode 100644
index 0000000..bf90aae
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/data_type_rewriter.h
@@ -0,0 +1,156 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file data_type_rewriter.h
+ * \brief Rewrite the data type of expressions.
+ */
+#ifndef TVM_TIR_DATA_TYPE_REWRITER_H_
+#define TVM_TIR_DATA_TYPE_REWRITER_H_
+
+#include <tvm/tir/stmt_functor.h>
+
+#include <unordered_map>
+
+namespace tvm {
+namespace tir {
+
+/*!
+ * \brief Legalize the data types of expressions to make sure they are consistent with other
+ * parts of the program.
+ *
+ * It enforces the following rules:
+ * - The data type of the index variable in a loop must be consistent with the data type of the loop
+ *  bounds.
+ * - The data type of the binary and ternary expressions must be consistent with the data types of
+ * each of their operands.
+ * - The data type of the bounds and binding values of block iter vars must be consistent with the
+ * data type of the block iter vars.
+ *
+ * Usually we enforce the consistency of data types when constructing the IR nodes. However, such
+ * inconsistency may happen as a result of IR mutation in some passes. This class can be used as
+ * base class of such passes to ensure the consistency of data types.
+ */
+class DataTypeLegalizer : public StmtExprMutator {
+ protected:
+  Stmt VisitStmt_(const ForNode* op) override;
+  Stmt VisitStmt_(const AttrStmtNode* op) override;
+  Stmt VisitStmt_(const BlockRealizeNode* op) override;
+  Stmt VisitStmt_(const BlockNode* op) override;
+  PrimExpr VisitExpr_(const SelectNode* op) override;
+  PrimExpr VisitExpr_(const RampNode* op) override;
+  PrimExpr VisitExpr_(const AddNode* op) override;
+  PrimExpr VisitExpr_(const SubNode* op) override;
+  PrimExpr VisitExpr_(const MulNode* op) override;
+  PrimExpr VisitExpr_(const DivNode* op) override;
+  PrimExpr VisitExpr_(const ModNode* op) override;
+  PrimExpr VisitExpr_(const FloorDivNode* op) override;
+  PrimExpr VisitExpr_(const FloorModNode* op) override;
+  PrimExpr VisitExpr_(const MinNode* op) override;
+  PrimExpr VisitExpr_(const MaxNode* op) override;
+  PrimExpr VisitExpr_(const EQNode* op) override;
+  PrimExpr VisitExpr_(const NENode* op) override;
+  PrimExpr VisitExpr_(const LTNode* op) override;
+  PrimExpr VisitExpr_(const LENode* op) override;
+  PrimExpr VisitExpr_(const GTNode* op) override;
+  PrimExpr VisitExpr_(const GENode* op) override;
+  PrimExpr VisitExpr_(const CallNode* op) override;
+  PrimExpr VisitExpr_(const CastNode* op) override;
+
+  using StmtExprMutator::VisitExpr_;
+  using StmtExprMutator::VisitStmt_;
+
+  // a map from IterVar before rewrite to that after rewrite,
+  // ensures one old IterVar maps to exactly one new IterVar
+  std::unordered_map<const IterVarNode*, IterVar> ivmap_;
+};
+
+/*!
+ * \brief Data type rewriter for buffer indices.
+ *
+ * Detect the components of buffer indices that should be considered for data type rewriting.
+ * This class doesn't perform actual rewriting of data types. During recursive visiting, the
+ * internal flags `is_enabled_` and `is_conditional_` are used to indicate whether the current
+ * expression is a buffer index or a conditional expression, which can be used in the sub-classes to
+ * implement different rewriting rules.
+ */
+class IndexDataTypeRewriter : public DataTypeLegalizer {
+ protected:
+  using Parent = DataTypeLegalizer;
+  using Parent::VisitExpr_;
+  using Parent::VisitStmt_;
+
+  Stmt VisitStmt_(const BlockRealizeNode* op) override;
+  Stmt VisitStmt_(const BlockNode* op) override;
+  Stmt VisitStmt_(const BufferStoreNode* op) override;
+  PrimExpr VisitExpr_(const BufferLoadNode* op) override;
+  Array<PrimExpr> VisitIndices(Array<PrimExpr> indices);
+  Stmt VisitStmt_(const IfThenElseNode* op) override;
+  Stmt VisitStmt_(const DeclBufferNode* op) override;
+  Stmt VisitStmt_(const AllocateNode* op) override;
+  PrimExpr VisitExpr_(const EQNode* op) override;
+  PrimExpr VisitExpr_(const NENode* op) override;
+  PrimExpr VisitExpr_(const LTNode* op) override;
+  PrimExpr VisitExpr_(const LENode* op) override;
+  PrimExpr VisitExpr_(const GTNode* op) override;
+  PrimExpr VisitExpr_(const GENode* op) override;
+  PrimExpr VisitExpr_(const CallNode* op) override;
+  Stmt VisitStmt_(const ForNode* op) override;
+
+  Buffer VisitBuffer(const Buffer& buffer);
+  Buffer GetRemappedBuffer(const Buffer& buffer);
+  Map<String, ObjectRef> VisitBlockAnnotations(const Map<String, ObjectRef>& annotations);
+  BufferRegion VisitBufferRegion(const BufferRegion& region);
+  IterVar VisitIterVar(const IterVar& iter_var);
+  // indicator of index expr to rewrite
+  bool is_enabled_{false};
+  // indicator of condition
+  bool is_condition_{false};
+
+  Map<Var, Var> var_remap_;
+  Map<Buffer, Buffer> buffer_remap_;
+};
+
+/*!
+ * \brief Normalize the data types of buffer shapes and indices to the same data type.
+ *
+ * This pass rewrites the data types of buffer shapes and indices to the specified data type. It
+ * assumes the specified data type is large enough to hold the original ranges of buffer shapes and
+ * indices.
+ */
+class IndexDataTypeNormalizer : public IndexDataTypeRewriter {
+ public:
+  explicit IndexDataTypeNormalizer(DataType target_data_type);
+  PrimFunc Rewrite(PrimFunc func);
+
+ protected:
+  using Parent = IndexDataTypeRewriter;
+  using Parent::VisitExpr_;
+  using Parent::VisitStmt_;
+  PrimExpr VisitExpr_(const IntImmNode* op) final;
+  PrimExpr VisitExpr_(const VarNode* op) final;
+  PrimExpr VisitExpr_(const CastNode* op) final;
+
+  DataType target_data_type_ = DataType::Int(64);
+};
+
+}  // namespace tir
+}  // namespace tvm
+
+#endif  // TVM_TIR_DATA_TYPE_REWRITER_H_
diff --git a/darknet_drp_ros/include/tvm/tir/expr.h b/darknet_drp_ros/include/tvm/tir/expr.h
new file mode 100644
index 0000000..689b1c0
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/expr.h
@@ -0,0 +1,1217 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/tir/expr.h
+ * \brief TIR expressions.
+ */
+// Acknowledgement: Many low-level IR nodes originate from Halide.
+#ifndef TVM_TIR_EXPR_H_
+#define TVM_TIR_EXPR_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/node/functor.h>
+#include <tvm/node/node.h>
+#include <tvm/runtime/c_runtime_api.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/container/map.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/runtime/data_type.h>
+#include <tvm/tir/buffer.h>
+#include <tvm/tir/var.h>
+
+#include <algorithm>
+#include <iostream>
+#include <limits>
+#include <string>
+#include <unordered_map>
+#include <utility>
+
+namespace tvm {
+namespace tir {
+
+using IntImmNode = tvm::IntImmNode;
+using FloatImmNode = tvm::FloatImmNode;
+
+/*! \brief String constants, only used in asserts. */
+class StringImmNode : public PrimExprNode {
+ public:
+  /*! \brief The constant value content. */
+  String value;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &dtype);
+    v->Visit("value", &value);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const StringImmNode* other, SEqualReducer equal) const {
+    return equal(value, other->value);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const { hash_reduce(value); }
+
+  static constexpr const char* _type_key = "tir.StringImm";
+  TVM_DECLARE_FINAL_OBJECT_INFO(StringImmNode, PrimExprNode);
+};
+
+/*!
+ * \brief Managed reference to StringImmNode.
+ * \sa StringImmNode
+ */
+class StringImm : public PrimExpr {
+ public:
+  TVM_DLL StringImm(String value, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(StringImm, PrimExpr, StringImmNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(StringImmNode);
+};
+
+/*!
+ * \brief Cast value from one data type to another.
+ * \note The lanes of value should keep fixed.
+ */
+class CastNode : public PrimExprNode {
+ public:
+  /*! \brief Original data type. */
+  PrimExpr value;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &dtype);
+    v->Visit("value", &value);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const CastNode* other, SEqualReducer equal) const {
+    return equal(dtype, other->dtype) && equal(value, other->value);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dtype);
+    hash_reduce(value);
+  }
+
+  static constexpr const char* _type_key = "tir.Cast";
+  TVM_DECLARE_FINAL_OBJECT_INFO(CastNode, PrimExprNode);
+};
+
+/*!
+ * \brief Managed reference to CastNode
+ * \sa CastNode
+ */
+class Cast : public PrimExpr {
+ public:
+  TVM_DLL Cast(DataType dtype, PrimExpr value, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(Cast, PrimExpr, CastNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(CastNode);
+};
+
+/*!
+ * \brief Base template to implement binary ops.
+ * \tparam T The type of the child class.
+ */
+template <typename T>
+class BinaryOpNode : public PrimExprNode {
+ public:
+  /*! \brief The left operand. */
+  PrimExpr a;
+  /*! \brief The right operand. */
+  PrimExpr b;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &(this->dtype));
+    v->Visit("a", &a);
+    v->Visit("b", &b);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const T* other, SEqualReducer equal) const {
+    return equal(dtype, other->dtype) && equal(a, other->a) && equal(b, other->b);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dtype);
+    hash_reduce(a);
+    hash_reduce(b);
+  }
+
+  TVM_DECLARE_FINAL_OBJECT_INFO(T, PrimExprNode);
+};
+
+/*! \brief a + b */
+class AddNode : public BinaryOpNode<AddNode> {
+ public:
+  static constexpr const char* _type_key = "tir.Add";
+};
+
+/*!
+ * \brief Managed reference to AddNode
+ * \sa AddNode
+ */
+class Add : public PrimExpr {
+ public:
+  TVM_DLL Add(PrimExpr a, PrimExpr b, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(Add, PrimExpr, AddNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(AddNode);
+};
+
+/*! \brief a - b */
+class SubNode : public BinaryOpNode<SubNode> {
+ public:
+  static constexpr const char* _type_key = "tir.Sub";
+};
+
+/*!
+ * \brief Managed reference to SubNode
+ * \sa SubNode
+ */
+class Sub : public PrimExpr {
+ public:
+  TVM_DLL Sub(PrimExpr a, PrimExpr b, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(Sub, PrimExpr, SubNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(SubNode);
+};
+
+/*! \brief a * b */
+class MulNode : public BinaryOpNode<MulNode> {
+ public:
+  static constexpr const char* _type_key = "tir.Mul";
+};
+
+/*!
+ * \brief Managed reference to MulNode
+ * \sa MulNode
+ */
+class Mul : public PrimExpr {
+ public:
+  TVM_DLL Mul(PrimExpr a, PrimExpr b, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(Mul, PrimExpr, MulNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(MulNode);
+};
+
+/*!
+ * \brief a / b in the C semnatics.
+ * \note For integer division, C standard uses trunc div.
+ */
+class DivNode : public BinaryOpNode<DivNode> {
+ public:
+  static constexpr const char* _type_key = "tir.Div";
+};
+
+/*!
+ * \brief Managed reference to DivNode
+ * \sa DivNode
+ */
+class Div : public PrimExpr {
+ public:
+  TVM_DLL Div(PrimExpr a, PrimExpr b, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(Div, PrimExpr, DivNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(DivNode);
+};
+
+/*!
+ * \brief a % b in the C semnatics.
+ * \note For integer division, C standard uses trunc div.
+ */
+class ModNode : public BinaryOpNode<ModNode> {
+ public:
+  static constexpr const char* _type_key = "tir.Mod";
+};
+
+/*!
+ * \brief Managed reference to ModNode
+ * \sa ModNode
+ */
+class Mod : public PrimExpr {
+ public:
+  TVM_DLL Mod(PrimExpr a, PrimExpr b, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(Mod, PrimExpr, ModNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(ModNode);
+};
+
+/*! \brief Floor division, floor(a/b) */
+class FloorDivNode : public BinaryOpNode<FloorDivNode> {
+ public:
+  static constexpr const char* _type_key = "tir.FloorDiv";
+};
+
+/*!
+ * \brief Managed reference to FloorDivNode
+ * \sa FloorDivNode
+ */
+class FloorDiv : public PrimExpr {
+ public:
+  TVM_DLL FloorDiv(PrimExpr a, PrimExpr b, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(FloorDiv, PrimExpr, FloorDivNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(FloorDivNode);
+};
+
+/*! \brief The remainder of the floordiv */
+class FloorModNode : public BinaryOpNode<FloorModNode> {
+ public:
+  static constexpr const char* _type_key = "tir.FloorMod";
+};
+
+/*!
+ * \brief Managed reference to FloorModNode
+ * \sa FloorModNode
+ */
+class FloorMod : public PrimExpr {
+ public:
+  TVM_DLL FloorMod(PrimExpr a, PrimExpr b, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(FloorMod, PrimExpr, FloorModNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(FloorModNode);
+};
+
+/*! \brief min(a, b) */
+class MinNode : public BinaryOpNode<MinNode> {
+ public:
+  static constexpr const char* _type_key = "tir.Min";
+};
+
+/*!
+ * \brief Managed reference to MinNode
+ * \sa MinNode
+ */
+class Min : public PrimExpr {
+ public:
+  TVM_DLL Min(PrimExpr a, PrimExpr b, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(Min, PrimExpr, MinNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(MinNode);
+};
+
+/*! \brief max(a, b) */
+class MaxNode : public BinaryOpNode<MaxNode> {
+ public:
+  static constexpr const char* _type_key = "tir.Max";
+};
+
+/*!
+ * \brief Managed reference to MaxNode
+ * \sa MaxNode
+ */
+class Max : public PrimExpr {
+ public:
+  TVM_DLL Max(PrimExpr a, PrimExpr b, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(Max, PrimExpr, MaxNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(MaxNode);
+};
+
+/*!
+ * \brief Base template to implement comparison ops.
+ * \tparam T The type of the child class.
+ */
+template <typename T>
+class CmpOpNode : public PrimExprNode {
+ public:
+  /*! \brief The left operand. */
+  PrimExpr a;
+  /*! \brief The right operand. */
+  PrimExpr b;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &(this->dtype));
+    v->Visit("a", &a);
+    v->Visit("b", &b);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const T* other, SEqualReducer equal) const {
+    return equal(dtype, other->dtype) && equal(a, other->a) && equal(b, other->b);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dtype);
+    hash_reduce(a);
+    hash_reduce(b);
+  }
+
+  TVM_DECLARE_FINAL_OBJECT_INFO(T, PrimExprNode);
+};
+
+/*! \brief a == b */
+class EQNode : public CmpOpNode<EQNode> {
+ public:
+  static constexpr const char* _type_key = "tir.EQ";
+};
+
+/*!
+ * \brief Managed reference to EQNode
+ * \sa EQNode
+ */
+class EQ : public PrimExpr {
+ public:
+  TVM_DLL EQ(PrimExpr a, PrimExpr b, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(EQ, PrimExpr, EQNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(EQNode);
+};
+
+/*! \brief a != b */
+class NENode : public CmpOpNode<NENode> {
+ public:
+  static constexpr const char* _type_key = "tir.NE";
+};
+
+/*!
+ * \brief Managed reference to NENode
+ * \sa NENode
+ */
+class NE : public PrimExpr {
+ public:
+  TVM_DLL NE(PrimExpr a, PrimExpr b, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(NE, PrimExpr, NENode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(NENode);
+};
+
+/*! \brief a < b */
+class LTNode : public CmpOpNode<LTNode> {
+ public:
+  static constexpr const char* _type_key = "tir.LT";
+};
+
+/*!
+ * \brief Managed reference to LTNode
+ * \sa LTNode
+ */
+class LT : public PrimExpr {
+ public:
+  TVM_DLL LT(PrimExpr a, PrimExpr b, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(LT, PrimExpr, LTNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(LTNode);
+};
+
+/*! \brief a <= b */
+struct LENode : public CmpOpNode<LENode> {
+ public:
+  static constexpr const char* _type_key = "tir.LE";
+};
+
+/*!
+ * \brief Managed reference to LENode
+ * \sa LENode
+ */
+class LE : public PrimExpr {
+ public:
+  TVM_DLL LE(PrimExpr a, PrimExpr b, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(LE, PrimExpr, LENode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(LENode);
+};
+
+/*! \brief a > b */
+class GTNode : public CmpOpNode<GTNode> {
+ public:
+  static constexpr const char* _type_key = "tir.GT";
+};
+
+/*!
+ * \brief Managed reference to GTNode
+ * \sa GTNode
+ */
+class GT : public PrimExpr {
+ public:
+  TVM_DLL GT(PrimExpr a, PrimExpr b, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(GT, PrimExpr, GTNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(GTNode);
+};
+
+/*! \brief a >= b */
+class GENode : public CmpOpNode<GENode> {
+ public:
+  static constexpr const char* _type_key = "tir.GE";
+};
+
+/*!
+ * \brief Managed reference to GENode
+ * \sa GENode
+ */
+class GE : public PrimExpr {
+ public:
+  TVM_DLL GE(PrimExpr a, PrimExpr b, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(GE, PrimExpr, GENode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(GENode);
+};
+
+/*! \brief a && b */
+class AndNode : public PrimExprNode {
+ public:
+  /*! \brief The left operand. */
+  PrimExpr a;
+  /*! \brief The right operand. */
+  PrimExpr b;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &(this->dtype));
+    v->Visit("a", &a);
+    v->Visit("b", &b);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const AndNode* other, SEqualReducer equal) const {
+    return equal(dtype, other->dtype) && equal(a, other->a) && equal(b, other->b);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dtype);
+    hash_reduce(a);
+    hash_reduce(b);
+  }
+
+  static constexpr const char* _type_key = "tir.And";
+  TVM_DECLARE_FINAL_OBJECT_INFO(AndNode, PrimExprNode);
+};
+
+/*!
+ * \brief Managed reference to AndNode
+ * \sa AndNode
+ */
+class And : public PrimExpr {
+ public:
+  TVM_DLL And(PrimExpr a, PrimExpr b, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(And, PrimExpr, AndNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(AndNode);
+};
+
+/*! \brief a || b */
+class OrNode : public PrimExprNode {
+ public:
+  /*! \brief The left operand. */
+  PrimExpr a;
+  /*! \brief The right operand. */
+  PrimExpr b;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &dtype);
+    v->Visit("a", &a);
+    v->Visit("b", &b);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const OrNode* other, SEqualReducer equal) const {
+    return equal(dtype, other->dtype) && equal(a, other->a) && equal(b, other->b);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dtype);
+    hash_reduce(a);
+    hash_reduce(b);
+  }
+
+  static constexpr const char* _type_key = "tir.Or";
+  TVM_DECLARE_FINAL_OBJECT_INFO(OrNode, PrimExprNode);
+};
+
+/*!
+ * \brief Managed reference to OrNode
+ * \sa OrNode
+ */
+class Or : public PrimExpr {
+ public:
+  TVM_DLL Or(PrimExpr a, PrimExpr b, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(Or, PrimExpr, OrNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(OrNode);
+};
+
+/*! \brief !a */
+class NotNode : public PrimExprNode {
+ public:
+  /*! \brief The input operand. */
+  PrimExpr a;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &dtype);
+    v->Visit("a", &a);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const NotNode* other, SEqualReducer equal) const {
+    return equal(dtype, other->dtype) && equal(a, other->a);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dtype);
+    hash_reduce(a);
+  }
+
+  static constexpr const char* _type_key = "tir.Not";
+  TVM_DECLARE_FINAL_OBJECT_INFO(NotNode, PrimExprNode);
+};
+
+/*!
+ * \brief Managed reference to NotNode
+ * \sa NotNode
+ */
+class Not : public PrimExpr {
+ public:
+  TVM_DLL Not(PrimExpr a, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(Not, PrimExpr, NotNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(NotNode);
+};
+
+/*!
+ * \brief return true_value if condition is true, otherwise return false_value.
+ * \note Both true_value and false_value could be evaluated
+ *       regardless of the condition value.
+ *       Do not use it to guard against out of bound access,
+ *       please use if_then_else instead.
+ */
+class SelectNode : public PrimExprNode {
+ public:
+  /*! \brief The condition */
+  PrimExpr condition;
+  /*! \brief value to be returned when condition is true. */
+  PrimExpr true_value;
+  /*! \brief value to be returned when condition is false. */
+  PrimExpr false_value;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &dtype);
+    v->Visit("condition", &condition);
+    v->Visit("true_value", &true_value);
+    v->Visit("false_value", &false_value);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const SelectNode* other, SEqualReducer equal) const {
+    return equal(dtype, other->dtype) && equal(condition, other->condition) &&
+           equal(true_value, other->true_value) && equal(false_value, other->false_value);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dtype);
+    hash_reduce(condition);
+    hash_reduce(true_value);
+    hash_reduce(false_value);
+  }
+
+  static constexpr const char* _type_key = "tir.Select";
+  TVM_DECLARE_FINAL_OBJECT_INFO(SelectNode, PrimExprNode);
+};
+
+/*!
+ * \brief Managed reference to SelectNode
+ * \sa SelectNode
+ */
+class Select : public PrimExpr {
+ public:
+  TVM_DLL Select(PrimExpr condition, PrimExpr true_value, PrimExpr false_value, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Select, PrimExpr, SelectNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(SelectNode);
+};
+
+/*!
+ * \brief Load value from the high dimension buffer.
+ *
+ * \code
+ *
+ *  value = buffer[i, j];
+ *
+ * \endcode
+ * \sa BufferStore
+ */
+class BufferLoadNode : public PrimExprNode {
+ public:
+  /*! \brief The buffer variable. */
+  Buffer buffer;
+  /*! \brief The indices location to be loaded. */
+  Array<PrimExpr> indices;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &(this->dtype));
+    v->Visit("buffer", &buffer);
+    v->Visit("indices", &indices);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const BufferLoadNode* other, SEqualReducer equal) const {
+    return equal(dtype, other->dtype) && equal(buffer, other->buffer) &&
+           equal(indices, other->indices);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dtype);
+    hash_reduce(buffer);
+    hash_reduce(indices);
+  }
+
+  static constexpr const char* _type_key = "tir.BufferLoad";
+  TVM_DECLARE_FINAL_OBJECT_INFO(BufferLoadNode, PrimExprNode);
+
+ private:
+  /*! \brief Set the dtype based on the buffer/indices
+   *
+   * Usually, the BufferLoad's dtype will be the same dtype as the
+   * buffer.  This may have a different number of lanes than the
+   * buffer's dtype if index values have more than 1 lane.
+   *
+   * This function should only be called during construction and after
+   * CopyOnWrite.  Friend class used here to restrict usage.
+   */
+  void LegalizeDType();
+  friend class BufferLoad;
+  friend class CustomDatatypesLowerer;
+  friend class VectorTypeRewriter;
+  friend class Vectorizer;
+};
+
+/*!
+ * \brief Managed reference to BufferLoadNode.
+ * \sa BufferLoadNode
+ */
+class BufferLoad : public PrimExpr {
+ public:
+  TVM_DLL explicit BufferLoad(Buffer buffer, Array<PrimExpr> indices, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(BufferLoad, PrimExpr, BufferLoadNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(BufferLoadNode);
+};
+
+/*!
+ * \brief Load value from the result produced by the producer.
+ *
+ * \note This node only appears in high-level DSLs that are built on top of the TIR.
+ *       It should not appear in a valid TIR PrimFunc. A high-level DSL needs to lower
+ *       this node before TIR transformations.
+ *
+ * \sa ProducerLoad, DataProducerNode
+ */
+class ProducerLoadNode : public PrimExprNode {
+ public:
+  /*! \brief The buffer producer. */
+  DataProducer producer;
+  /*! \brief The location arguments. */
+  Array<PrimExpr> indices;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &(this->dtype));
+    v->Visit("producer", &producer);
+    v->Visit("indices", &indices);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const ProducerLoadNode* other, SEqualReducer equal) const {
+    return equal(dtype, other->dtype) && equal(producer, other->producer) &&
+           equal(indices, other->indices);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dtype);
+    hash_reduce(producer);
+    hash_reduce(indices);
+  }
+
+  static constexpr const char* _type_key = "tir.ProducerLoad";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ProducerLoadNode, PrimExprNode);
+};
+
+/*!
+ * \brief Managed reference to ProducerLoadNode.
+ * \sa ProducerLoadNode
+ */
+class ProducerLoad : public PrimExpr {
+ public:
+  TVM_DLL explicit ProducerLoad(DataProducer producer, Array<PrimExpr> indices, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(ProducerLoad, PrimExpr, ProducerLoadNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(ProducerLoadNode);
+};
+
+/*!
+ * \brief Load the value from buffer_var.
+ *
+ *  Equivalent to ((DType*)buffer_var)[index]
+ *  where DType is the type specified by type().element_of().
+ *
+ *  For example, if type = float32x3, then the load will corresponds to
+ *
+ * \code
+ *
+ *  auto buffer = static_cast<float*>(buffer_var);
+ *  auto loaded_val = float32x3(buffer[index.v0], buffer[index.v1], buffer[index.v2]);
+ *
+ * \endcode
+ */
+class LoadNode : public PrimExprNode {
+ public:
+  /*! \brief The buffer variable. */
+  Var buffer_var;
+  /*! \brief The index locations to be loaded. */
+  PrimExpr index;
+  /*! \brief The predicate to mask which lanes would be loaded. */
+  PrimExpr predicate;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &dtype);
+    v->Visit("buffer_var", &buffer_var);
+    v->Visit("index", &index);
+    v->Visit("predicate", &predicate);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const LoadNode* other, SEqualReducer equal) const {
+    return equal(dtype, other->dtype) && equal(buffer_var, other->buffer_var) &&
+           equal(index, other->index) && equal(predicate, other->predicate);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dtype);
+    hash_reduce(buffer_var);
+    hash_reduce(index);
+    hash_reduce(predicate);
+  }
+
+  static constexpr const char* _type_key = "tir.Load";
+  TVM_DECLARE_FINAL_OBJECT_INFO(LoadNode, PrimExprNode);
+};
+
+/*!
+ * \brief Managed reference to LoadNode
+ * \sa LoadNode
+ */
+class Load : public PrimExpr {
+ public:
+  TVM_DLL Load(DataType dtype, Var buffer_var, PrimExpr index, PrimExpr predicate,
+               Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(Load, PrimExpr, LoadNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(LoadNode);
+};
+
+/*!
+ * \brief Construct a vector with lanes elements
+ *        where its i-th element equals base + i * stride.
+ *  This is useful to construct a index for a continuous vector load.
+ *
+ *  Examples:
+ *  - ramp(0, 1, 3) = [0, 1, 2]
+ *  - ramp(1, 2, 4) = [1, 3, 5, 7]
+ */
+class RampNode : public PrimExprNode {
+ public:
+  /*! \brief The base value. */
+  PrimExpr base;
+  /*! \brief The stride of each step. */
+  PrimExpr stride;
+  /*! \brief Total number of lanes. */
+  int lanes;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &dtype);
+    v->Visit("base", &base);
+    v->Visit("stride", &stride);
+    v->Visit("lanes", &lanes);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const RampNode* other, SEqualReducer equal) const {
+    return equal(dtype, other->dtype) && equal(base, other->base) && equal(stride, other->stride) &&
+           equal(lanes, other->lanes);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dtype);
+    hash_reduce(base);
+    hash_reduce(stride);
+    hash_reduce(lanes);
+  }
+
+  static constexpr const char* _type_key = "tir.Ramp";
+  TVM_DECLARE_FINAL_OBJECT_INFO(RampNode, PrimExprNode);
+};
+
+/*!
+ * \brief Managed reference to RampNode
+ * \sa RampNode
+ */
+class Ramp : public PrimExpr {
+ public:
+  TVM_DLL Ramp(PrimExpr base, PrimExpr stride, int lanes, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(Ramp, PrimExpr, RampNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(RampNode);
+};
+
+/*! \brief Create a vector where all the elements are value. */
+class BroadcastNode : public PrimExprNode {
+ public:
+  /*! \brief The base value. */
+  PrimExpr value;
+  /*! \brief The number of lanes. */
+  int lanes;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &dtype);
+    v->Visit("value", &value);
+    v->Visit("lanes", &lanes);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const BroadcastNode* other, SEqualReducer equal) const {
+    return equal(dtype, other->dtype) && equal(value, other->value) && equal(lanes, other->lanes);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dtype);
+    hash_reduce(value);
+    hash_reduce(lanes);
+  }
+
+  static constexpr const char* _type_key = "tir.Broadcast";
+  TVM_DECLARE_FINAL_OBJECT_INFO(BroadcastNode, PrimExprNode);
+};
+
+/*!
+ * \brief Managed reference to BroadcastNode
+ * \sa BroadcastNode
+ */
+class Broadcast : public PrimExpr {
+ public:
+  TVM_DLL Broadcast(PrimExpr value, int lanes, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(Broadcast, PrimExpr, BroadcastNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(BroadcastNode);
+};
+
+/*!
+ * \brief Let binding. Bind var to value then evaluate body.
+ */
+class LetNode : public PrimExprNode {
+ public:
+  /*! \brief The variable. */
+  Var var;
+  /*! \brief The value to be binded. */
+  PrimExpr value;
+  /*! \brief The result expression. */
+  PrimExpr body;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &dtype);
+    v->Visit("var", &var);
+    v->Visit("value", &value);
+    v->Visit("body", &body);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const LetNode* other, SEqualReducer equal) const {
+    return equal(dtype, other->dtype) && equal.DefEqual(var, other->var) &&
+           equal(value, other->value) && equal(body, other->body);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dtype);
+    hash_reduce.DefHash(var);
+    hash_reduce(value);
+    hash_reduce(body);
+  }
+
+  static constexpr const char* _type_key = "tir.Let";
+  TVM_DECLARE_FINAL_OBJECT_INFO(LetNode, PrimExprNode);
+};
+
+/*!
+ * \brief Managed reference to LetNode
+ * \sa LetNode
+ */
+class Let : public PrimExpr {
+ public:
+  TVM_DLL Let(Var var, PrimExpr value, PrimExpr body, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(Let, PrimExpr, LetNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(LetNode);
+};
+
+/*!
+ * \brief Call node.
+ */
+class CallNode : public PrimExprNode {
+ public:
+  /*!
+   * \brief The operator(function) being invoked
+   *
+   *  - It can be tvm::Op which corresponds to the primitive operators(intrinsics).
+   *  - It can also be another function in the IRModule (GlobalVar).
+   */
+  RelayExpr op;
+
+  /*! \brief The arguments. */
+  Array<PrimExpr> args;
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &dtype);
+    v->Visit("op", &op);
+    v->Visit("args", &args);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const CallNode* other, SEqualReducer equal) const {
+    return equal(dtype, other->dtype) && equal(op, other->op) && equal(args, other->args);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dtype);
+    hash_reduce(op);
+    hash_reduce(args);
+  }
+
+  static constexpr const char* _type_key = "tir.Call";
+  TVM_DECLARE_FINAL_OBJECT_INFO(CallNode, PrimExprNode);
+};
+
+/*!
+ * \brief Managed reference to CallNode
+ * \sa CallNode
+ */
+class Call : public PrimExpr {
+ public:
+  TVM_DLL Call(DataType dtype, RelayExpr op, Array<PrimExpr> args, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(Call, PrimExpr, CallNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(CallNode);
+};
+
+/*!
+ * \brief Shuffle instruction.
+ *  vec = concat(vectors)
+ *  result = (vec[indices[0]], vec[indices[1]] ...)
+ */
+class ShuffleNode : public PrimExprNode {
+ public:
+  /*! \brief the input vectors. */
+  Array<PrimExpr> vectors;
+  /*! \brief The indices of each element. */
+  Array<PrimExpr> indices;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &dtype);
+    v->Visit("vectors", &vectors);
+    v->Visit("indices", &indices);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const ShuffleNode* other, SEqualReducer equal) const {
+    return equal(dtype, other->dtype) && equal(vectors, other->vectors) &&
+           equal(indices, other->indices);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dtype);
+    hash_reduce(vectors);
+    hash_reduce(indices);
+  }
+
+  static constexpr const char* _type_key = "tir.Shuffle";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ShuffleNode, PrimExprNode);
+};
+
+/*!
+ * \brief Managed reference to ShuffleNode
+ * \sa ShuffleNode
+ */
+class Shuffle : public PrimExpr {
+ public:
+  TVM_DLL Shuffle(Array<PrimExpr> vectors, Array<PrimExpr> indices, Span span = Span());
+  TVM_DLL static PrimExpr Concat(Array<PrimExpr> vectors, Span span = Span());
+  TVM_DLL static PrimExpr ExtractElement(PrimExpr vector, int index, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Shuffle, PrimExpr, ShuffleNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(ShuffleNode);
+};
+
+// Reduce operator
+/*!
+ * \brief A commutative reducer node to represent a commutative
+ *  binary operator with identity element
+ */
+class CommReducerNode : public Object {
+ public:
+  /*! \brief The left argument of reducer */
+  Array<Var> lhs;
+  /*! \brief The right argument of reducer */
+  Array<Var> rhs;
+  /*! \brief The result of reducer */
+  Array<PrimExpr> result;
+  /*!
+   * \brief The identity element of reducer, which leaves other
+   *  elements unchanged when combined with it, with respect to
+   *  the binary operation of this reducer uses.
+   */
+  Array<PrimExpr> identity_element;
+  /*! \brief Function call operator to combine a and b */
+  Array<PrimExpr> operator()(Array<PrimExpr> a, Array<PrimExpr> b) const;
+  /*!
+   * \brief Span that points to the original source code.
+   *        Reserved debug information.
+   */
+  mutable Span span;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("lhs", &lhs);
+    v->Visit("rhs", &rhs);
+    v->Visit("result", &result);
+    v->Visit("identity_element", &identity_element);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const CommReducerNode* other, SEqualReducer equal) const {
+    return equal.DefEqual(lhs, other->lhs) && equal.DefEqual(rhs, other->rhs) &&
+           equal(result, other->result) && equal(identity_element, other->identity_element);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce.DefHash(lhs);
+    hash_reduce.DefHash(rhs);
+    hash_reduce(result);
+    hash_reduce(identity_element);
+  }
+
+  static constexpr const char* _type_key = "tir.CommReducer";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_FINAL_OBJECT_INFO(CommReducerNode, Object);
+};
+
+/*!
+ * \brief Managed reference to CommReducerNode
+ * \sa CommReducerNode
+ */
+class CommReducer : public ObjectRef {
+ public:
+  TVM_DLL CommReducer(Array<Var> lhs, Array<Var> rhs, Array<PrimExpr> result,
+                      Array<PrimExpr> identity_element, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(CommReducer, ObjectRef, CommReducerNode);
+};
+
+/*! \brief Reduction operator operator */
+class ReduceNode : public PrimExprNode {
+ public:
+  /*! \brief The commutative combiner */
+  CommReducer combiner;
+  /*! \brief The source operand */
+  Array<PrimExpr> source;
+  /*! \brief The init operand */
+  Array<PrimExpr> init;
+  /*! \brief The reduction axis */
+  Array<IterVar> axis;
+  /*!
+   * \brief Predicate on the reduction
+   *  Only add the body to reduction if condition is true.
+   */
+  PrimExpr condition;
+  /*! \brief the index of this reduce node */
+  int value_index;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &dtype);
+    v->Visit("combiner", &combiner);
+    v->Visit("source", &source);
+    v->Visit("init", &init);
+    v->Visit("axis", &axis);
+    v->Visit("condition", &condition);
+    v->Visit("value_index", &value_index);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const ReduceNode* other, SEqualReducer equal) const {
+    // check axis first so IterVars can define the necessary variables.
+    return equal(dtype, other->dtype) && equal(axis, other->axis) &&
+           equal(combiner, other->combiner) && equal(source, other->source) &&
+           equal(init, other->init) && equal(condition, other->condition) &&
+           equal(value_index, other->value_index);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dtype);
+    hash_reduce(axis);
+    hash_reduce(combiner);
+    hash_reduce(source);
+    hash_reduce(init);
+    hash_reduce(condition);
+    hash_reduce(value_index);
+  }
+
+  static constexpr const char* _type_key = "tir.Reduce";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ReduceNode, PrimExprNode);
+};
+
+/*!
+ * \brief Managed reference to ReduceNode
+ * \sa ReduceNode
+ */
+class Reduce : public PrimExpr {
+ public:
+  TVM_DLL Reduce(CommReducer combiner, Array<PrimExpr> src, Array<IterVar> rdom, PrimExpr condition,
+                 int value_index, Array<PrimExpr> init, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Reduce, PrimExpr, ReduceNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(ReduceNode);
+};
+
+/*! \brief Any shape. */
+class AnyNode : public PrimExprNode {
+ public:
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &dtype);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const AnyNode* other, SEqualReducer equal) const {
+    return equal(dtype, other->dtype);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {}
+
+  /*! \brief Convert to var. */
+  Var ToVar() const { return Var("any_dim", DataType::Int(32)); }
+
+  /*! \brief Convert to SizeVar. */
+  SizeVar ToSizeVar() const { return SizeVar("any_dim", DataType::Int(32)); }
+
+  static constexpr const char* _type_key = "tir.Any";
+  TVM_DECLARE_FINAL_OBJECT_INFO(AnyNode, PrimExprNode);
+};
+
+/*!
+ * \brief Managed reference to AnyNode
+ * \sa AnyNode
+ */
+class Any : public PrimExpr {
+ public:
+  TVM_DLL Any(Span span = Span());
+
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(Any, PrimExpr, AnyNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(AnyNode);
+};
+
+/*
+ * \brief Template function to convert Map to unordered_map
+ *  Sometimes useful for API gluing when internal uses unordered_map
+ * \param dmap The container map
+ * \return The corresponding unordered_map.
+ * \tparam K the key of the Map.
+ * \tparam V the value of the Map.
+ */
+template <typename K, typename V>
+inline std::unordered_map<K, V> as_unordered_map(const Map<K, V>& dmap) {
+  std::unordered_map<K, V> ret;
+  for (auto kv : dmap) {
+    ret[kv.first] = kv.second;
+  }
+  return ret;
+}
+}  // namespace tir
+}  // namespace tvm
+
+namespace std {
+template <>
+struct hash<::tvm::tir::IterVar> : public ::tvm::ObjectPtrHash {};
+}  // namespace std
+#endif  // TVM_TIR_EXPR_H_
diff --git a/darknet_drp_ros/include/tvm/tir/expr_functor.h b/darknet_drp_ros/include/tvm/tir/expr_functor.h
new file mode 100644
index 0000000..e148d58
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/expr_functor.h
@@ -0,0 +1,301 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/tir/expr_functor.h
+ *
+ * \brief Functors for tir expressions.
+ */
+#ifndef TVM_TIR_EXPR_FUNCTOR_H_
+#define TVM_TIR_EXPR_FUNCTOR_H_
+
+#include <tvm/node/functor.h>
+#include <tvm/tir/expr.h>
+
+#include <utility>
+
+namespace tvm {
+namespace tir {
+
+/*!
+ * \brief A dynamical functor that dispatches on in the first Expr argument.
+ *  You can use this as a more powerful Visitor, since it allows you to
+ *  define function signatures of Visit Function.
+ *
+ *  This helps you to avoid to book-keep return value of Visitor via state,
+ *  which can cause bugs easily when state is incorrectly maintained.
+ *
+ * \code
+ *  // A functor that set variable to b. and calculate results.
+ *  class MyExprFunctor
+ *    : public tir::ExprFunctor<int(const Expr&, int)> {
+ *   public:
+ *    int VisitExpr_(const Variable* op, int b) final {
+ *     return b;
+ *    }
+ *    int VisitExpr_(const IntImm* op, int b) final {
+ *      return op->value;
+ *    }
+ *    int VisitExpr_(const Add* op, int b) final {
+ *     return Visit(op->a, b) + Visit(op->b, b);
+ *    }
+ *  };
+ *  MyExprFunctor f;
+ *  Var x("x");
+ *  ICHECK_EQ(f(x + 1, 2), 3);
+ * \endcode
+ *
+ * \note Why do we need this more powerful Functor:
+ *
+ *  We often need to implement a transformer tasks.
+ *  Say we want to take Expr and transform it to some analysis result,
+ *  This easily be done incorrectly using plain Visitor. See IRVisitor's
+ *  document for possible error cases.
+ *
+ * \tparam FType function signiture
+ *  This type if only defined for FType with function signiture R(const Expr&, Args...)
+ */
+template <typename FType>
+class ExprFunctor;
+
+// functions to be overriden.
+#define EXPR_FUNCTOR_DEFAULT \
+  { return VisitExprDefault_(op, std::forward<Args>(args)...); }
+
+#define IR_EXPR_FUNCTOR_DISPATCH(OP)                                                       \
+  vtable.template set_dispatch<OP>([](const ObjectRef& n, TSelf* self, Args... args) {     \
+    return self->VisitExpr_(static_cast<const OP*>(n.get()), std::forward<Args>(args)...); \
+  });
+
+template <typename R, typename... Args>
+class ExprFunctor<R(const PrimExpr& n, Args...)> {
+ private:
+  using TSelf = ExprFunctor<R(const PrimExpr& n, Args...)>;
+  using FType = NodeFunctor<R(const ObjectRef& n, TSelf* self, Args...)>;
+
+ public:
+  /*! \brief the result type of this functor */
+  using result_type = R;
+  /*! \brief virtual destructor */
+  virtual ~ExprFunctor() {}
+  /*!
+   * \brief Same as call.
+   * \param n The expression node.
+   * \param args Additional arguments.
+   * \return The result of the call
+   */
+  R operator()(const PrimExpr& n, Args... args) {
+    return VisitExpr(n, std::forward<Args>(args)...);
+  }
+  /*!
+   * \brief The functor call.
+   * \param n The expression node.
+   * \param args Additional arguments.
+   * \return The result of the call
+   */
+  virtual R VisitExpr(const PrimExpr& n, Args... args) {
+    static FType vtable = InitVTable();
+    return vtable(n, this, std::forward<Args>(args)...);
+  }
+  // Functions that can be overriden by subclass
+  virtual R VisitExpr_(const VarNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const SizeVarNode* op, Args... args) {
+    return VisitExpr_(static_cast<const VarNode*>(op), std::forward<Args>(args)...);
+  }
+  virtual R VisitExpr_(const BufferLoadNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const ProducerLoadNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const LoadNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const LetNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const CallNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const AddNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const SubNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const MulNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const DivNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const ModNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const FloorDivNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const FloorModNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const MinNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const MaxNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const EQNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const NENode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const LTNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const LENode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const GTNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const GENode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const AndNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const OrNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const ReduceNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const CastNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const NotNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const SelectNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const RampNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const BroadcastNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const ShuffleNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const IntImmNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const FloatImmNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const StringImmNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExpr_(const AnyNode* op, Args... args) EXPR_FUNCTOR_DEFAULT;
+  virtual R VisitExprDefault_(const Object* op, Args...) {
+    LOG(FATAL) << "Do not have a default for " << op->GetTypeKey();
+  }
+
+ private:
+  // initialize the vtable.
+  static FType InitVTable() {
+    FType vtable;
+    // Set dispatch
+    IR_EXPR_FUNCTOR_DISPATCH(VarNode);
+    IR_EXPR_FUNCTOR_DISPATCH(SizeVarNode);
+    IR_EXPR_FUNCTOR_DISPATCH(LoadNode);
+    IR_EXPR_FUNCTOR_DISPATCH(BufferLoadNode);
+    IR_EXPR_FUNCTOR_DISPATCH(ProducerLoadNode);
+    IR_EXPR_FUNCTOR_DISPATCH(LetNode);
+    IR_EXPR_FUNCTOR_DISPATCH(CallNode);
+    IR_EXPR_FUNCTOR_DISPATCH(AddNode);
+    IR_EXPR_FUNCTOR_DISPATCH(SubNode);
+    IR_EXPR_FUNCTOR_DISPATCH(MulNode);
+    IR_EXPR_FUNCTOR_DISPATCH(DivNode);
+    IR_EXPR_FUNCTOR_DISPATCH(ModNode);
+    IR_EXPR_FUNCTOR_DISPATCH(FloorDivNode);
+    IR_EXPR_FUNCTOR_DISPATCH(FloorModNode);
+    IR_EXPR_FUNCTOR_DISPATCH(MinNode);
+    IR_EXPR_FUNCTOR_DISPATCH(MaxNode);
+    IR_EXPR_FUNCTOR_DISPATCH(EQNode);
+    IR_EXPR_FUNCTOR_DISPATCH(NENode);
+    IR_EXPR_FUNCTOR_DISPATCH(LTNode);
+    IR_EXPR_FUNCTOR_DISPATCH(LENode);
+    IR_EXPR_FUNCTOR_DISPATCH(GTNode);
+    IR_EXPR_FUNCTOR_DISPATCH(GENode);
+    IR_EXPR_FUNCTOR_DISPATCH(AndNode);
+    IR_EXPR_FUNCTOR_DISPATCH(OrNode);
+    IR_EXPR_FUNCTOR_DISPATCH(ReduceNode);
+    IR_EXPR_FUNCTOR_DISPATCH(CastNode);
+    IR_EXPR_FUNCTOR_DISPATCH(NotNode);
+    IR_EXPR_FUNCTOR_DISPATCH(SelectNode);
+    IR_EXPR_FUNCTOR_DISPATCH(RampNode);
+    IR_EXPR_FUNCTOR_DISPATCH(ShuffleNode);
+    IR_EXPR_FUNCTOR_DISPATCH(BroadcastNode);
+    IR_EXPR_FUNCTOR_DISPATCH(IntImmNode);
+    IR_EXPR_FUNCTOR_DISPATCH(FloatImmNode);
+    IR_EXPR_FUNCTOR_DISPATCH(StringImmNode);
+    IR_EXPR_FUNCTOR_DISPATCH(AnyNode);
+    return vtable;
+  }
+};
+
+#undef IR_EXPR_FUNCTOR_DISPATCH
+#undef EXPR_FUNCTOR_DEFAULT
+
+/*!
+ * \brief ExprVisitor
+ */
+class TVM_DLL ExprVisitor : public ExprFunctor<void(const PrimExpr&)> {
+ public:
+  using ExprFunctor::operator();
+
+ protected:
+  using ExprFunctor::VisitExpr;
+  // list of functions to override.
+  void VisitExpr_(const VarNode* op) override;
+  void VisitExpr_(const SizeVarNode* op) override;
+  void VisitExpr_(const LoadNode* op) override;
+  void VisitExpr_(const BufferLoadNode* op) override;
+  void VisitExpr_(const ProducerLoadNode* op) override;
+  void VisitExpr_(const LetNode* op) override;
+  void VisitExpr_(const CallNode* op) override;
+  void VisitExpr_(const AddNode* op) override;
+  void VisitExpr_(const SubNode* op) override;
+  void VisitExpr_(const MulNode* op) override;
+  void VisitExpr_(const DivNode* op) override;
+  void VisitExpr_(const ModNode* op) override;
+  void VisitExpr_(const FloorDivNode* op) override;
+  void VisitExpr_(const FloorModNode* op) override;
+  void VisitExpr_(const MinNode* op) override;
+  void VisitExpr_(const MaxNode* op) override;
+  void VisitExpr_(const EQNode* op) override;
+  void VisitExpr_(const NENode* op) override;
+  void VisitExpr_(const LTNode* op) override;
+  void VisitExpr_(const LENode* op) override;
+  void VisitExpr_(const GTNode* op) override;
+  void VisitExpr_(const GENode* op) override;
+  void VisitExpr_(const AndNode* op) override;
+  void VisitExpr_(const OrNode* op) override;
+  void VisitExpr_(const ReduceNode* op) override;
+  void VisitExpr_(const CastNode* op) override;
+  void VisitExpr_(const NotNode* op) override;
+  void VisitExpr_(const SelectNode* op) override;
+  void VisitExpr_(const RampNode* op) override;
+  void VisitExpr_(const BroadcastNode* op) override;
+  void VisitExpr_(const ShuffleNode* op) override;
+  void VisitExpr_(const IntImmNode* op) override;
+  void VisitExpr_(const FloatImmNode* op) override;
+  void VisitExpr_(const StringImmNode* op) override;
+  void VisitExpr_(const AnyNode* op) override;
+};
+
+/*!
+ * \brief ExprMutator that mutates expressions.
+ */
+class TVM_DLL ExprMutator : protected ExprFunctor<PrimExpr(const PrimExpr&)> {
+ public:
+  using ExprFunctor::operator();
+
+ protected:
+  using ExprFunctor::VisitExpr;
+  // list of functions to override.
+  PrimExpr VisitExpr_(const VarNode* op) override;
+  PrimExpr VisitExpr_(const SizeVarNode* op) override;
+  PrimExpr VisitExpr_(const LoadNode* op) override;
+  PrimExpr VisitExpr_(const BufferLoadNode* op) override;
+  PrimExpr VisitExpr_(const ProducerLoadNode* op) override;
+  PrimExpr VisitExpr_(const LetNode* op) override;
+  PrimExpr VisitExpr_(const CallNode* op) override;
+  PrimExpr VisitExpr_(const AddNode* op) override;
+  PrimExpr VisitExpr_(const SubNode* op) override;
+  PrimExpr VisitExpr_(const MulNode* op) override;
+  PrimExpr VisitExpr_(const DivNode* op) override;
+  PrimExpr VisitExpr_(const ModNode* op) override;
+  PrimExpr VisitExpr_(const FloorDivNode* op) override;
+  PrimExpr VisitExpr_(const FloorModNode* op) override;
+  PrimExpr VisitExpr_(const MinNode* op) override;
+  PrimExpr VisitExpr_(const MaxNode* op) override;
+  PrimExpr VisitExpr_(const EQNode* op) override;
+  PrimExpr VisitExpr_(const NENode* op) override;
+  PrimExpr VisitExpr_(const LTNode* op) override;
+  PrimExpr VisitExpr_(const LENode* op) override;
+  PrimExpr VisitExpr_(const GTNode* op) override;
+  PrimExpr VisitExpr_(const GENode* op) override;
+  PrimExpr VisitExpr_(const AndNode* op) override;
+  PrimExpr VisitExpr_(const OrNode* op) override;
+  PrimExpr VisitExpr_(const ReduceNode* op) override;
+  PrimExpr VisitExpr_(const CastNode* op) override;
+  PrimExpr VisitExpr_(const NotNode* op) override;
+  PrimExpr VisitExpr_(const SelectNode* op) override;
+  PrimExpr VisitExpr_(const RampNode* op) override;
+  PrimExpr VisitExpr_(const BroadcastNode* op) override;
+  PrimExpr VisitExpr_(const ShuffleNode* op) override;
+  PrimExpr VisitExpr_(const IntImmNode* op) override;
+  PrimExpr VisitExpr_(const FloatImmNode* op) override;
+  PrimExpr VisitExpr_(const StringImmNode* op) override;
+  PrimExpr VisitExpr_(const AnyNode* op) override;
+};
+
+}  // namespace tir
+}  // namespace tvm
+#endif  // TVM_TIR_EXPR_FUNCTOR_H_
diff --git a/darknet_drp_ros/include/tvm/tir/function.h b/darknet_drp_ros/include/tvm/tir/function.h
new file mode 100644
index 0000000..cf92f97
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/function.h
@@ -0,0 +1,329 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/tir/function.h
+ * \brief TIR Function.
+ */
+#ifndef TVM_TIR_FUNCTION_H_
+#define TVM_TIR_FUNCTION_H_
+
+#include <tvm/ir/function.h>
+#include <tvm/runtime/ndarray.h>
+#include <tvm/tir/buffer.h>
+#include <tvm/tir/expr.h>
+#include <tvm/tir/stmt.h>
+
+#include <string>
+
+namespace tvm {
+namespace tir {
+
+/*!
+ * \brief Primitive functions that contains TIR statements.
+ *
+ * The PrimFunc provides low-level code representation does not
+ * automatically manage
+ *
+ * \sa PrimFunc
+ */
+class PrimFuncNode : public BaseFuncNode {
+ public:
+  /*! \brief Function parameters */
+  Array<tir::Var> params;
+  /*! \brief The body of the function */
+  tir::Stmt body;
+  /*! \brief The return type of the function. */
+  Type ret_type;
+  /*!
+   * \brief Maps some parameters to specific Buffer data structures.
+   *
+   *  buffer_map provides a way to express data structure's field and shape
+   *  constraints. The provided information is used in the program analysis
+   *  and the code generation.
+   *
+   *  - It defines the vars in the Buffer (m, n) in the cases below when
+   *    they appears in the buffer_map for the first time.
+   *  - When a var appears multiple times, they translate into runtime
+   *    assertion to check the field constraint.
+   *
+   *  \code
+   *
+   *   # The corresponding fields of f are as follows
+   *   #
+   *   # - f.params = [a, b]
+   *   # - f.buffer_map = {a: A, b: B}
+   *   # - A = decl_buffer(shape=[m, n])
+   *   # - B = decl_buffer(shape=[m, n])
+   *
+   *   def f(a, b):
+   *       m, n = var(), var()
+   *       A = bind_buffer(a, shape=[m, n])
+   *       B = bind_buffer(b, shape=[m, n])
+   *       # body
+   *
+   *  \endcode
+   *
+   *  buffer_map is a sugar to express:
+   *  - Parameter unpacking: e.g. I can load a.shape[0] to get value of m
+   *  - Constraint checking: a.shape[0] must equal b.shape[0] because they
+   *    both corresponds to m.
+
+   *  While we could have express parameter unpacking and constraint using
+   *  normal statements, making buffer_map as first class citizen of PrimFunc
+   *  will make program analysis much easier.
+   *
+   *  Prior to buffer flattening, which is performed either in
+   *  StorageFlatten for TE-based schedules or in FlattenBuffer for
+   *  TIR-based schedules, these buffer objects are used directly in
+   *  the body of the function.  After buffer flattening, these buffer
+   *  objects remain unflattened for use in argument validation, but
+   *  all usage in the body of the function is done through a
+   *  flattened alias of the buffer.
+   */
+  Map<tir::Var, Buffer> buffer_map;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("params", &params);
+    v->Visit("body", &body);
+    v->Visit("ret_type", &ret_type);
+    v->Visit("buffer_map", &buffer_map);
+    v->Visit("attrs", &attrs);
+    v->Visit("span", &span);
+    v->Visit("_checked_type_", &checked_type_);
+  }
+
+  bool SEqualReduce(const PrimFuncNode* other, SEqualReducer equal) const {
+    // visit params and buffer_map first as they contains defs.
+    return equal.DefEqual(params, other->params) && equal(buffer_map, other->buffer_map) &&
+           equal(ret_type, other->ret_type) && equal(body, other->body) &&
+           equal(attrs, other->attrs);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce.DefHash(params);
+    hash_reduce(buffer_map);
+    hash_reduce(ret_type);
+    hash_reduce(body);
+    hash_reduce(attrs);
+  }
+  /*!
+   * \brief Return the derived function annotation of this function.
+   *
+   * \return The function type annotation.
+   * \note The function type annotation of PrimExpr is
+   *       directly derived from the Vars without the need of type inference.
+   */
+  TVM_DLL FuncType func_type_annotation() const;
+
+  static constexpr const char* _type_key = "tir.PrimFunc";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PrimFuncNode, BaseFuncNode);
+};
+
+/*!
+ * \brief Managed reference to PrimFuncNode.
+ * \sa PrimFuncNode
+ */
+class PrimFunc : public BaseFunc {
+ public:
+  /*!
+   * \brief Constructor
+   *
+   * \param params The parameters of the function.
+   *
+   * \param body The body of the function.
+   *
+   * \param ret_type The return type of the function.
+   *
+   * \param buffer_map The buffer map for parameter buffer unpacking.
+   * This contains buffer objects as they appear in the body of the
+   * PrimFunc.  (e.g. a buffer of shape ``[1024]`` originally
+   * generated as a tensor of shape ``[32, 32]``)
+   *
+   * \param attrs Additional function attributes.
+   *
+   * \param span The location of this object in the source code.
+   */
+  TVM_DLL PrimFunc(Array<tir::Var> params, Stmt body, Type ret_type = VoidType(),
+                   Map<tir::Var, Buffer> buffer_map = Map<tir::Var, Buffer>(),
+                   DictAttrs attrs = NullValue<DictAttrs>(), Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(PrimFunc, BaseFunc, PrimFuncNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(PrimFuncNode);
+};
+
+/*!
+ * \brief Tensor intrinsics for tensorization
+ */
+class TensorIntrinNode : public Object {
+ public:
+  /*! \brief The function to describe the computation. */
+  PrimFunc desc;
+  /*! \brief The function of the implementation for the execution. */
+  PrimFunc impl;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("desc", &desc);
+    v->Visit("impl", &impl);
+  }
+
+  static constexpr const char* _type_key = "tir.TensorIntrin";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TensorIntrinNode, Object);
+};
+
+/*!
+ * \brief Managed reference to TensorIntrinNode.
+ */
+class TensorIntrin : public ObjectRef {
+ public:
+  /*!
+   * \brief Constructor
+   * \param desc The function to describe the computation.
+   * \param impl The function of the implementation for the execution.
+   */
+  TVM_DLL explicit TensorIntrin(PrimFunc desc, PrimFunc impl);
+
+  /*!
+   * \brief Create and register a TensorIntrin. After registration, the TensorIntrin can be looked
+   * up with its name.
+   * \param name The name of the TensorIntrin to register
+   * \param intrin The TensorIntrin to register.
+   * \param override Whether override existing intrinsic.
+   * \throws This method throws an exception if the TensorIntrin with the specified name already
+   *         exists.
+   */
+  TVM_DLL static void Register(String name, TensorIntrin intrin, bool override = false);
+
+  /*!
+   * \brief Look up TensorIntrin by name. Raises an exception if not found.
+   * \param name The name of the TensorIntrin.
+   * \param allow_missing Whether to allow missing tensor intrin. If false, an exception is raised
+   *    if the tensor intrin is not found.
+   * \return The TensorIntrin with the specified name.
+   * \throws This method throws an exception if the TensorIntrin does not exist and allow_missing is
+   * false.
+   */
+  TVM_DLL static Optional<TensorIntrin> Get(String name, bool allow_missing = false);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(TensorIntrin, ObjectRef, TensorIntrinNode)
+};
+
+/*
+ * \brief Specialize parameters of PrimFunc.
+ * \param func The PrimFunc to be specialized.
+ * \param param_map The mapping from function params to the instance.
+ * \return The new function with parameter specialized.
+ * \note We can define a Meta TIR function with symbolic shape:
+ *
+ * \code
+ *  @T.prim_func
+ *  def mem_copy(a: T.handle, b: T.handle, m: T.int32, n: T.int32) -> None:
+ *      A = T.match_buffer(a, (m, n), "float32")
+ *      B = T.match_buffer(b, (m, n), "float32")
+ *      for i, j in T.grid(m, n):
+ *          with T.block():
+ *              vi, vj = T.axis.remap("SS", [i, j])
+ *              B[vi, vj] = A[vi, vj]
+ * \endcode
+ *
+ * Then we can make it specialized with given shapes or buffers.
+ *
+ * \code
+ *  a, _, m, n = mem_copy.params
+ *  func = mem_copy.specialize({a: tir.decl_buffer((16, 16))})
+ *  # or
+ *  func = mem_copy.specialize({n: 16, m: 16})
+ * \endcode
+ *
+ * \code {.language-id}
+ *  @T.prim_func
+ *  def mem_copy_16_16(a: T.handle, b: T.handle) -> None:
+ *      A = T.match_buffer(a, (16, 16), "float32")
+ *      B = T.match_buffer(b, (16, 16), "float32")
+ *      for i, j in T.grid(16, 16):
+ *          with T.block():
+ *              vi, vj = T.axis.remap("SS", [i, j])
+ *              B[vi, vj] = A[vi, vj]
+ * \endcode
+ */
+PrimFunc Specialize(PrimFunc func, const Map<Var, ObjectRef>& param_map);
+
+/*!
+ * \brief PrimFunc specific attribute names.
+ *
+ * \sa tvm::attr
+ */
+namespace attr {
+/*!
+ * \brief List of thread IterVar that a DeviceLaunch function corresponds to.
+ *
+ * Type: Array<tir::IterVar>
+ *
+ * We call a device kernel launch function f using the following convention:
+ *
+ * Call(f,
+ *      [arg1, arg2, ..., arg_n,
+ *       work_size_1, work_size_2, ... work_size_m, dyn_shmem_size])
+ *
+ * Here n = len(arg), m = len(work_size) = len(device_thread_axis).
+ *
+ * When kDeviceUseDynSharedMemory is not set, dyn_shmem_size argument is omitted.
+ *
+ * The list of device_thread_axis indicates how can be bind the
+ * work_size arguments to the corresponding threads.
+ *
+ * \sa tvm::CallingConv::kDeviceKernelLaunch
+ */
+constexpr const char* kDeviceThreadAxis = "tir.device_thread_axis";
+
+/*!
+ * \brief Whether or not use dynamic shared memory.
+ *
+ * Type: Integer
+ */
+constexpr const char* kDeviceUseDynSharedMemory = "tir.device_use_dyn_shared_memory";
+
+/*!
+ * \brief Whether to set noalias rule on the function arguments.
+ *
+ * Type: Integer
+ */
+constexpr const char* kNoAlias = "tir.noalias";
+
+/*!
+ * \brief Mark the function as the entry function of
+ *        the final generated runtime module.
+ *
+ * Type: Integer
+ *
+ * \note There can only be one entry function per module.
+ */
+constexpr const char* kIsEntryFunc = "tir.is_entry_func";
+
+/*!
+ * \brief Mark the function as the global function called from the host.
+ *
+ * Type: Integer
+ */
+constexpr const char* kIsGlobalFunc = "tir.is_global_func";
+
+}  // namespace attr
+}  // namespace tir
+}  // namespace tvm
+#endif  // TVM_TIR_FUNCTION_H_
diff --git a/darknet_drp_ros/include/tvm/tir/index_map.h b/darknet_drp_ros/include/tvm/tir/index_map.h
new file mode 100644
index 0000000..35a74d2
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/index_map.h
@@ -0,0 +1,223 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/tir/index_map.h
+ * \brief Defines a remapping of buffer indices
+ *
+ * For use with tvm::tir::Buffer.
+ */
+#ifndef TVM_TIR_INDEX_MAP_H_
+#define TVM_TIR_INDEX_MAP_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/runtime/container/array.h>
+#include <tvm/runtime/object.h>
+#include <tvm/tir/var.h>
+
+#include <utility>
+
+namespace tvm {
+namespace arith {
+class Analyzer;
+}
+}  // namespace tvm
+
+namespace tvm {
+namespace tir {
+
+/*!
+ * \brief Defines a mapping between two representations of indices
+ * into a buffer.
+ *
+ * This is primarily used for layout transformations of Buffer
+ * objects.
+ */
+class IndexMapNode : public Object {
+ public:
+  /*! \brief Variables representing the indices prior to remapping.
+   *
+   * If initial_indices is empty, then final_indices should also be
+   * empty, and no mapping is applied.
+   */
+  Array<Var> initial_indices;
+
+  /*!
+   * \brief Expressions defining the indices after remapping.
+   *
+   * These expressions should only be in terms of the initial_indices,
+   * and must be expressible as an IterSumExpr.  The mapping from
+   * initial_indices to final_indices must be injective.
+   *
+   * If final_indices is empty, then initial_indices should also be
+   * empty, and the map is an identity function.
+   */
+  Array<PrimExpr> final_indices;
+
+  /*!
+   * \brief The inverse index map.
+   *
+   * When this is defined, IndexMap::Inverse will return the
+   * pre-defined inverse index map.  Otherwise, the inverse index map
+   * will be computed on the fly.  It is the user's responsibility to
+   * ensure the correctness of the pre-defined inverse index map.
+   *
+   * \note ObjectRef is used here instead of IndexMap to avoid circular reference.
+   */
+  Optional<ObjectRef> inverse_index_map;
+
+  /*!
+   * \brief Default constructor
+   *
+   * Defines the mapping as an identity function, with initial_indices
+   * equal to the final indices.
+   */
+  IndexMapNode() {}
+
+  /*!
+   * \brief Map indices to the output space
+   *
+   * \param indices The indices in the input space.  Should contain
+   * one value for each variable in `initial_indices`.
+   *
+   * \param analyzer An optional analyzer to be used to simplify the
+   * resulting expressions.  If null, will use a fresh analyzer.
+   *
+   * \returns The indices in the output space.  Contains one value for
+   * each expression in `final_indices`.
+   */
+  Array<PrimExpr> MapIndices(const Array<PrimExpr>& indices,
+                             arith::Analyzer* analyzer = nullptr) const;
+
+  /*! \brief Map a memory range to the output space
+   *
+   * If contiguous memory locations in the input space are not
+   * necessarily contiguous in the output space (e.g. `lambda i:
+   * [8*(i%8) + (i//8)]`), then this will return the smallest range
+   * such that all valid indices are contained within the given range.
+   *
+   * \param ranges The ranges in the input space.  Should contain one
+   * value for each variable in `initial_indices`.
+   *
+   * \param analyzer An optional analyzer to be used to simplify the
+   * resulting expressions.  If null, will use a fresh analyzer.
+   *
+   * \returns The ranges in the output space.  Contains one value for
+   * each expression in `final_indices`.
+   */
+  Array<Range> MapRanges(const Array<Range>& ranges, arith::Analyzer* analyzer = nullptr) const;
+
+  /*! \brief Map a buffer shape to the output space
+   *
+   * \param shape The buffer shape in the input space.  Should contain
+   * one value for each variable in `initial_indices`.
+   *
+   * \param analyzer An optional analyzer to be used to simplify the
+   * resulting expressions.  If null, will use a fresh analyzer.
+   *
+   * \returns The buffer shape in the output space.  Contains one
+   * value for each expression in `final_indices`.
+   */
+  Array<PrimExpr> MapShape(const Array<PrimExpr>& shape, arith::Analyzer* analyzer = nullptr) const;
+
+  /* \brief Map an NDArray according to this index map
+   *
+   * \param arr_src The NDArray whose layout is transformed by this index map.
+   *
+   * \returns The transformed NDArray.
+   */
+  runtime::NDArray MapNDArray(runtime::NDArray arr_src) const;
+
+  /*!
+   * \brief Convert to string representation in Python.
+   * \return The stringified lambda expression in Python.
+   */
+  String ToPythonString() const;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("initial_indices", &initial_indices);
+    v->Visit("final_indices", &final_indices);
+    v->Visit("inverse_index_map", &inverse_index_map);
+  }
+
+  bool SEqualReduce(const IndexMapNode* other, SEqualReducer equal) const {
+    return equal.DefEqual(initial_indices, other->initial_indices) &&
+           equal(final_indices, other->final_indices);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce.DefHash(initial_indices);
+    hash_reduce(final_indices);
+  }
+
+  static constexpr const char* _type_key = "tir.IndexMap";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_FINAL_OBJECT_INFO(IndexMapNode, Object);
+};
+
+class IndexMap : public ObjectRef {
+ public:
+  /*!
+   * \brief The constructor
+   * \param initial_indices Variables representing the indices prior to remapping
+   * \param final_indices Expressions defining the indices after remapping.
+   * \param inverse_index_map The optional pre-defined inverse index map
+   */
+  IndexMap(Array<Var> initial_indices, Array<PrimExpr> final_indices,
+           Optional<IndexMap> inverse_index_map = NullOpt);
+
+  /*!
+   * \brief Create an index map from a packed function
+   * \param ndim The number of dimensions
+   * \param func The function to be applied
+   * \param inverse_index_map The optional pre-defined inverse index map
+   * \return The created index map
+   */
+  static IndexMap FromFunc(int ndim, runtime::TypedPackedFunc<Array<PrimExpr>(Array<Var>)> func,
+                           Optional<IndexMap> inverse_index_map = NullOpt);
+
+  /*! \brief Generate the inverse mapping.
+   *
+   * The range of the input indices is required in order to ensure
+   * that the transformation is bijective over the input domain.
+   *
+   * If the user has supplied an `inverse_index_map`, that map is
+   * assumed to be correct and bijective, and is returned.
+   */
+  IndexMap Inverse(Array<Range> initial_ranges) const;
+
+  /*! \brief Generate the inverse mapping.
+   *
+   * Determine the inverse, where the output range may contain
+   * addresses that do not correspond to an address in the input
+   * range.
+   *
+   * \return The inverted index map, along with the predicate for
+   * which the inverse maps to a valid range.
+   */
+  std::pair<IndexMap, PrimExpr> NonSurjectiveInverse(Array<Range> initial_ranges) const;
+
+  TVM_DEFINE_OBJECT_REF_METHODS(IndexMap, ObjectRef, IndexMapNode);
+};
+
+}  // namespace tir
+}  // namespace tvm
+
+#endif  // TVM_TIR_INDEX_MAP_H_
diff --git a/darknet_drp_ros/include/tvm/tir/op.h b/darknet_drp_ros/include/tvm/tir/op.h
new file mode 100644
index 0000000..9b48b0c
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/op.h
@@ -0,0 +1,1113 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/tir/op.h
+ * \brief Common operators defined for Expr.
+ *
+ * \note Most of the operator defined here perform simple constant folding
+ *   when the type is int32 or int64 for simplifying the index expressions.
+ */
+// Acknowledgement: Most operator APIs originate from Halide.
+#ifndef TVM_TIR_OP_H_
+#define TVM_TIR_OP_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/ir/op.h>
+#include <tvm/ir/type.h>
+#include <tvm/tir/expr.h>
+#include <tvm/tir/stmt.h>
+
+#include <algorithm>
+#include <limits>
+#include <type_traits>
+
+namespace tvm {
+
+// Most common operators can be overloaded by argument type(PrimExpr).
+// So we put them under the root namespace.
+//
+// We put more developer oriented APIs -- make_const and is_const under tir
+// as they are more specific to the tir namespace.
+
+/*!
+ * \brief Get the type of the expression under the unified type system.
+ *
+ * This function could return a more refined type than
+ * the runtime type provided by expr->dtype
+ *
+ * \param expr The input parameter.
+ * \return The result type.
+ *
+ * \sa tvm/ir/type.h for discussion about the relation between Type and runtime::DataType.
+ */
+TVM_DLL Type GetType(const PrimExpr& expr);
+
+/*!
+ * \brief Get the type corresponding to DataType
+ * \param dtype The data type
+ * \return The result type
+ *
+ * \sa tvm/ir/type.h for discussion about the relation between Type and runtime::DataType.
+ */
+TVM_DLL Type GetTypeFromRuntimeDataType(const DataType& dtype);
+
+/*!
+ * \brief Get the implied DataType for storing values with type during runtime.
+ *
+ * \param type The input type.
+ * \return The result runtime::DataType.
+ *
+ * \sa tvm/ir/type.h for discussion about the relation between Type and runtime::DataType.
+ */
+TVM_DLL runtime::DataType GetRuntimeDataType(const Type& type);
+
+/*!
+ * \brief Return the value.
+ *
+ * \param value The returned value.
+ * \param span The location of this operation in the source.
+ * \return The return expression.
+ */
+TVM_DLL PrimExpr ret(PrimExpr value, Span span = Span());
+
+/*!
+ * Query the maximum possible value of dtype.
+ * \param dtype The data type.
+ * \param span The location of this operation in the source.
+ * \return the maximum possible value in this format.
+ */
+TVM_DLL PrimExpr max_value(const DataType& dtype, Span span = Span());
+
+/*!
+ * Query the minimum possible value of dtype.
+ * \param dtype The data type.
+ * \param span The location of this operation in the source.
+ * \return the minimum possible value in this format.
+ */
+TVM_DLL PrimExpr min_value(const DataType& dtype, Span span = Span());
+
+/*!
+ * Get the value of infinity.
+ * \param dtype The data type.
+ * \param span The location of this operation in the source.
+ * \return the infinity value in this format.
+ */
+TVM_DLL PrimExpr infinity(const DataType& dtype, Span span = Span());
+
+/*!
+ * \brief cast value to type.
+ *
+ * \param t the target type.
+ * \param value The value
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note This function may return value if the type is the same.
+ */
+TVM_DLL PrimExpr cast(const DataType& t, PrimExpr value, Span span = Span());
+/*!
+ * \brief perform reinterpret cast value to type.
+ *
+ * \param t the target type.
+ * \param value The value
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note This function may return value if the type is the same.
+ */
+TVM_DLL PrimExpr reinterpret(const DataType& t, PrimExpr value, Span span = Span());
+/*!
+ * \brief add operator
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr add(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief subtraction operator
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr sub(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief negation.
+ *
+ * \param a input.
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr neg(PrimExpr a, Span span = Span());
+/*!
+ * \brief multiplication operator
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr mul(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief left shift operator
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr left_shift(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief right shift operator
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr right_shift(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief greater
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr greater(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief greater_equal
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr greater_equal(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief less
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr less(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief less_equal
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr less_equal(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief equal
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr equal(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief not_equal
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr not_equal(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief and
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note This operator does eager constant folding.
+ */
+TVM_DLL PrimExpr logical_and(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief or
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note This operator does eager constant folding.
+ */
+TVM_DLL PrimExpr logical_or(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief not
+ *
+ * \param a left operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note This operator does eager constant folding.
+ */
+TVM_DLL PrimExpr logical_not(PrimExpr a, Span span = Span());
+/*!
+ * \brief compute division in C semantics.
+ *
+ * a / b as in C/C++.
+ *
+ * When operands are integers, it directly corresponds to truncdiv.
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr div(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief compute trunc(a / b)
+ *
+ * This is the default integer division behavior in C.
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr truncdiv(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief compute the remainder of truncdiv
+ *
+ * This is the default integer division behavior in C.
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr truncmod(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief compute floor(a / b) where a and b are non-negative.
+ *
+ * Use this function for index split calculation.
+ *
+ * This function might take advantage of the fact
+ * that a and b are non-negative.
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr indexdiv(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief compute ceil(a / b) where a and b are non-negative.
+ *
+ * Use this function for shape split calculation.
+ *
+ * This function might take advantage of the fact
+ * that a and b are non-negative.
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       shape types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr shapediv(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief compute the remainder floor(a / b) where a and b are non-negative.
+ *
+ * Use this function for index split calculation.
+ * This function might take advantage of the fact
+ * that a and b are non-negative.
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr indexmod(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief compute floor(a / b)
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr floordiv(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief compute ceil(a / b)
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr ceildiv(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief compute the remainder of floordiv
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr floormod(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief take maximum of two values
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr max(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief take minimum of two values
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr min(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief take bitwise and of two values
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr bitwise_and(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief take bitwise or of two values
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr bitwise_or(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief take bitwise xor of two values
+ *
+ * \param a left operand
+ * \param b right operand
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr bitwise_xor(PrimExpr a, PrimExpr b, Span span = Span());
+/*!
+ * \brief take bitwise negation of two values
+ *
+ * \param a the input expression.
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr bitwise_neg(PrimExpr a, Span span = Span());
+/*!
+ * \brief Conditional expression.
+ *
+ * \param cond The condition
+ * \param true_value The value when results are true.
+ * \param false_value The value when results are false.
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * \note this function does eager constant folding for
+ *       index types(int32, int64) when possible.
+ */
+TVM_DLL PrimExpr if_then_else(PrimExpr cond, PrimExpr true_value, PrimExpr false_value,
+                              Span span = Span());
+/*!
+ * \brief Mark condition as likely.
+ * \param cond The condition
+ * \param span The location of this operation in the source.
+ * \return The marked expression.
+ */
+TVM_DLL PrimExpr likely(PrimExpr cond, Span span = Span());
+/*!
+ * \brief Calculate power(x, y)
+ * \param x The left operand.
+ * \param y The right operand.
+ * \param span The location of this operation in the source.
+ */
+TVM_DLL PrimExpr pow(PrimExpr x, PrimExpr y, Span span = Span());
+/*!
+ * \brief Calculate absolute value of x.
+ * \param x The input data
+ * \param span The location of this operation in the source.
+ *
+ * \return The aboslute value of input data x
+ */
+TVM_DLL PrimExpr abs(PrimExpr x, Span span = Span());
+/*!
+ * \brief Check if x is NaN.
+ * \param x The input data
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ */
+TVM_DLL PrimExpr isnan(PrimExpr x, Span span = Span());
+
+/*!
+ * \brief Check if x is finite.
+ * \param x The input data
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ */
+TVM_DLL PrimExpr isfinite(PrimExpr x, Span span = Span());
+
+/*!
+ * \brief Check if x is infinite.
+ * \param x The input data
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ */
+TVM_DLL PrimExpr isinf(PrimExpr x, Span span = Span());
+
+/*!
+ * \brief sum of source expression over axis
+ * \param source The source expression.
+ * \param axis List of iteration variables that will be used for reduction.
+ * \param init The value with which to initialize the output.
+ * \param span The location of this operation in the source.
+ * \return The result.
+ */
+TVM_DLL PrimExpr sum(PrimExpr source, Array<tir::IterVar> axis, Array<PrimExpr> init = {},
+                     Span span = Span());
+
+/*!
+ * \brief logical And of source expression over axis
+ * \param source The source expression.
+ * \param axis List of iteration variables that will be used for reduction.
+ * \param init The value with which to initialize the output.
+ * \param span The location of this operation in the source.
+ */
+TVM_DLL PrimExpr all(PrimExpr source, Array<tir::IterVar> axis, Array<PrimExpr> init = {},
+                     Span span = Span());
+
+/*!
+ * \brief logical Or of source expression over axis
+ * \param source The source expression.
+ * \param axis List of iteration variables that will be used for reduction.
+ * \param init The value with which to initialize the output.
+ * \param span The location of this operation in the source.
+ * \return The result.
+ */
+TVM_DLL PrimExpr any(PrimExpr source, Array<tir::IterVar> axis, Array<PrimExpr> init = {},
+                     Span span = Span());
+
+/*!
+ * \brief max of source expression over axis
+ * \param source The source expression.
+ * \param axis List of iteration variables that will be used for reduction.
+ * \param init The value with which to initialize the output.
+ * \param span The location of this operation in the source.
+ * \return The result.
+ */
+TVM_DLL PrimExpr max(PrimExpr source, Array<tir::IterVar> axis, Array<PrimExpr> init = {},
+                     Span span = Span());
+
+/*!
+ * \brief max of source expression over axis
+ * \param source The source expression.
+ * \param axis List of iteration variables that will be used for reduction.
+ * \param init The value with which to initialize the output.
+ * \param span The location of this operation in the source.
+ * \return The result.
+ */
+TVM_DLL PrimExpr min(PrimExpr source, Array<tir::IterVar> axis, Array<PrimExpr> init = {},
+                     Span span = Span());
+
+/*!
+ * \brief product of source expression over axis
+ * \param source The source expression.
+ * \param axis List of iteration variables that will be used for reduction.
+ * \param init The value with which to initialize the output.
+ * \param span The location of this operation in the source.
+ * \return The result.
+ */
+TVM_DLL PrimExpr prod(PrimExpr source, Array<tir::IterVar> axis, Array<PrimExpr> init = {},
+                      Span span = Span());
+
+/*!
+ * \brief Calculate floor(x)
+ * \param x The input expression.
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ */
+TVM_DLL PrimExpr floor(PrimExpr x, Span span = Span());
+
+/*!
+ * \brief Calculate ceil(x)
+ * \param x The input expression.
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ */
+TVM_DLL PrimExpr ceil(PrimExpr x, Span span = Span());
+
+/*!
+ * \brief Calculate round(x)
+ * \param x The input expression.
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ */
+TVM_DLL PrimExpr round(PrimExpr x, Span span = Span());
+
+/*!
+ * \brief Calculates std::nearbyint(x)
+ * \param x The input expression.
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ * This is a faster alternate to round.
+ */
+TVM_DLL PrimExpr nearbyint(PrimExpr x, Span span = Span());
+
+/*!
+ * \brief Calculate trunc(x)
+ * \param x The input expression.
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ */
+TVM_DLL PrimExpr trunc(PrimExpr x, Span span = Span());
+
+/*!
+ * \brief Construct a large uint constant by its low 32 bits and high 32bits.
+ * \param dtype The final data type.
+ * \param low The lower 32 bits.
+ * \param high The higher 32 bits.
+ * \param span The location of this operation in the source.
+ * \return The constructed expression.
+ */
+TVM_DLL PrimExpr LargeUIntImm(DataType dtype, int64_t low, int64_t high, Span span = Span());
+
+/*!
+ * \brief Execute a multiplication between two Q-numbers x and y
+ * followed by a right shift s. The mathematical expression is:
+ *
+ *    out = round(x*y*2^-s)
+ *
+ * Please note that the two Q-numbers x and y are supposed to have
+ * the same number of fractional bits q.
+ *
+ * More about Q-numbers here: https://en.wikipedia.org/wiki/Q_(number_format)
+ *
+ * The rounding rule is to the nearest value, rounding half up
+ * (i.e., round(x.1) = x and round (x.5) = x+1)
+ * \param x first Q-number
+ * \param y second Q-number
+ * \param q number of fractional bits in x and y. Needs to be > 0
+ * \param s integer right shift
+ * \param span The location of this operation in the source.
+ * \return The constructed expression.
+ */
+TVM_DLL PrimExpr q_multiply_shift(PrimExpr x, PrimExpr y, PrimExpr q, PrimExpr s,
+                                  Span span = Span());
+
+// Intrinsic operators
+#define TVM_DECLARE_INTRIN_UNARY(OpName)                                \
+  inline PrimExpr OpName(PrimExpr x, Span span = Span()) {              \
+    static const Op& op = Op::Get("tir." #OpName);                      \
+    if (x.dtype().is_bfloat16()) {                                      \
+      DataType bf16_dtype = x.dtype();                                  \
+      DataType fp32_dtype(kDLFloat, 32, bf16_dtype.lanes());            \
+      PrimExpr x_fp32 = tir::Cast(fp32_dtype, {x}, span);               \
+      PrimExpr result_fp32 = tir::Call(fp32_dtype, op, {x_fp32}, span); \
+      return tir::Cast(bf16_dtype, {result_fp32}, span);                \
+    } else {                                                            \
+      return tir::Call(x.dtype(), op, {x}, span);                       \
+    }                                                                   \
+  }
+
+TVM_DECLARE_INTRIN_UNARY(exp);
+TVM_DECLARE_INTRIN_UNARY(exp2);
+TVM_DECLARE_INTRIN_UNARY(exp10);
+TVM_DECLARE_INTRIN_UNARY(erf);
+TVM_DECLARE_INTRIN_UNARY(tanh);
+TVM_DECLARE_INTRIN_UNARY(sigmoid);
+TVM_DECLARE_INTRIN_UNARY(sqrt);
+TVM_DECLARE_INTRIN_UNARY(rsqrt);
+TVM_DECLARE_INTRIN_UNARY(log);
+TVM_DECLARE_INTRIN_UNARY(log2);
+TVM_DECLARE_INTRIN_UNARY(log10);
+TVM_DECLARE_INTRIN_UNARY(log1p);
+TVM_DECLARE_INTRIN_UNARY(popcount);
+TVM_DECLARE_INTRIN_UNARY(tan);
+TVM_DECLARE_INTRIN_UNARY(cos);
+TVM_DECLARE_INTRIN_UNARY(cosh);
+TVM_DECLARE_INTRIN_UNARY(sin);
+TVM_DECLARE_INTRIN_UNARY(sinh);
+TVM_DECLARE_INTRIN_UNARY(asin);
+TVM_DECLARE_INTRIN_UNARY(acos);
+TVM_DECLARE_INTRIN_UNARY(atan);
+TVM_DECLARE_INTRIN_UNARY(acosh);
+TVM_DECLARE_INTRIN_UNARY(asinh);
+TVM_DECLARE_INTRIN_UNARY(atanh);
+TVM_DECLARE_INTRIN_UNARY(clz);
+
+#define TVM_DECLARE_INTRIN_BINARY(OpName)                              \
+  inline PrimExpr OpName(PrimExpr x, PrimExpr y, Span span = Span()) { \
+    static const Op& op = Op::Get("tir." #OpName);                     \
+    return tir::Call(x.dtype(), op, {x, y}, span);                     \
+  }
+
+TVM_DECLARE_INTRIN_BINARY(atan2);
+TVM_DECLARE_INTRIN_BINARY(nextafter);
+TVM_DECLARE_INTRIN_BINARY(copysign);
+TVM_DECLARE_INTRIN_BINARY(hypot);
+TVM_DECLARE_INTRIN_BINARY(ldexp);
+
+namespace tir {
+
+/*!
+ * \brief Check if type is a pointer to a runtime element type.
+ * \param type The type to be checked.
+ * \param element_type The corresponding element type.
+ * \return The check results
+ */
+inline bool IsPointerType(const Type& type, const DataType& element_type) {
+  if (!type.defined()) return false;
+  if (const auto* ptr_type = type.as<PointerTypeNode>()) {
+    if (const auto* prim_type = ptr_type->element_type.as<PrimTypeNode>()) {
+      return prim_type->dtype == element_type;
+    }
+  }
+  return false;
+}
+
+/*!
+ * \brief Make a const value with certain data type.
+ * \param t The target type.
+ * \param value The input value
+ * \return the result expression.
+ * \tparam ValueType The constant value type
+ * \param span The location of this operation in the source.
+ */
+template <typename ValueType,
+          typename = typename std::enable_if<std::is_pod<ValueType>::value>::type>
+inline PrimExpr make_const(DataType t, ValueType value, Span span = Span());
+/*!
+ * \brief Make a const zero expr.
+ * \param t The target type.
+ * \param span The location of this operation in the source.
+ * \return the result expression.
+ */
+inline PrimExpr make_zero(DataType t, Span span = Span());
+/*!
+ * \brief Make a constant true expression.
+ * \param lanes The number of lanes in the bool
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ */
+inline PrimExpr const_true(int lanes = 1, Span span = Span()) {
+  return make_const(DataType::UInt(1, lanes), 1);
+}
+/*!
+ * \brief Make a constant false expression.
+ * \param lanes The number of lanes in the bool
+ * \param span The location of this operation in the source.
+ * \return The result expression.
+ */
+inline PrimExpr const_false(int lanes = 1, Span span = Span()) {
+  return make_const(DataType::UInt(1, lanes), 0);
+}
+/*!
+ * \brief Get x as constant int expression.
+ * \param x The expression
+ * \return the address to the int expression,
+ *         return nullptr, if x is not IntImm.
+ */
+inline const int64_t* as_const_int(const PrimExpr& x) {
+  if (!x.defined()) return nullptr;
+  if (const tir::IntImmNode* op = x.as<tir::IntImmNode>()) {
+    return &(op->value);
+  }
+
+  return nullptr;
+}
+
+/*!
+ * \brief Check whether x is a constant integer expression.
+ * \param x The input argument
+ * \param value the value to be compared against.
+ * \return whether x is constant expression.
+ */
+inline bool is_const_int(const PrimExpr& x, int64_t value);
+
+/*!
+ * \brief Check whether stmt is nop.
+ * \param stmt The input statement
+ * \return whether stmt is nop
+ */
+inline bool is_no_op(const tir::Stmt& stmt);
+
+/*!
+ * \brief Check whether x is a constant integer 1
+ * \param x The input argument.
+ * \note This only return true for integer types.
+ * \return whether x is constant 1
+ */
+inline bool is_one(const PrimExpr& x) { return is_const_int(x, 1); }
+
+/*!
+ * \brief Check whether x is a constant integer 0
+ * \param x The input argument
+ * \return whether x is constant 0
+ * \note This only return true for integer types.
+ */
+inline bool is_zero(const PrimExpr& x) { return is_const_int(x, 0); }
+
+/*!
+ * \brief Check whether x is an integer constant.
+ * \note This only return true for integer types.
+ * \return whether x is constant
+ */
+inline bool is_const_int(const PrimExpr& x);
+
+/*!
+ * \brief Check whether x is an integer/float constant.
+ * \note This only return true for integer types.
+ * \return whether x is constant
+ */
+inline bool is_const_number(const PrimExpr& x);
+
+/*!
+ * \brief Left fold.
+ * \param freduce The reduction function.
+ * \param init_value The initial value.
+ * \param values The values to be folded.
+ * \param span The location of the fold in the source.
+ * \return The result.
+ * \tparam FReduce The type of the reduction.
+ */
+template <typename FReduce>
+inline PrimExpr foldl(FReduce freduce, PrimExpr init_value, const Array<PrimExpr>& values,
+                      Span span = Span());
+
+/*!
+ * \brief Check whether x is a constant power of two
+ * If x is power of two, write the power to the shift.
+ *
+ * \param x The input expression.
+ * \param shift The output shift if x is power of two.
+ * \return whether x is constant power of two
+ */
+TVM_DLL bool is_const_power_of_two_integer(const PrimExpr& x, int* shift);
+
+// Implementation details after this
+inline bool is_const_int(const PrimExpr& x) { return as_const_int(x); }
+
+inline bool is_const_number(const PrimExpr& x) {
+  if (x.as<tir::IntImmNode>()) {
+    return true;
+  } else if (x.as<tir::FloatImmNode>()) {
+    return true;
+  } else if (const auto* op = x.as<tir::BroadcastNode>()) {
+    return (op->value->IsInstance<tir::IntImmNode>() || op->value->IsInstance<tir::FloatImmNode>());
+  }
+  return false;
+}
+
+inline bool is_positive_const(const PrimExpr& a) {
+  const int64_t* as_int = as_const_int(a);
+  return as_int && (*as_int > 0);
+}
+
+inline bool is_negative_const(const PrimExpr& a) {
+  const int64_t* as_int = as_const_int(a);
+  return as_int && (*as_int < 0);
+}
+
+inline bool is_const_int(const PrimExpr& x, int64_t value) {
+  const int64_t* as_int = as_const_int(x);
+  return as_int && (*as_int == value);
+}
+
+inline bool is_no_op(const tir::Stmt& stmt) {
+  if (!stmt.defined()) return true;
+  if (const auto* op = stmt.as<tir::EvaluateNode>()) {
+    return is_const_int(op->value);
+  }
+  if (const auto* op = stmt.as<tir::SeqStmtNode>()) {
+    return op->seq.size() == 0;
+  }
+  return false;
+}
+
+template <typename ValueType>
+inline PrimExpr MakeConstScalar(DataType t, ValueType value, Span span = Span()) {
+  if (t.is_int()) return IntImm(t, static_cast<int64_t>(value), span);
+  if (t.is_uint()) {
+    // Use IntImm if it is a small integer
+    uint64_t uval = static_cast<uint64_t>(value);
+    if (value < static_cast<ValueType>(0)) {
+      LOG(FATAL) << "cannot make uint from negative value " << value;
+    } else if (uval <= static_cast<uint64_t>(std::numeric_limits<int64_t>::max())) {
+      return IntImm(t, static_cast<int64_t>(value), span);
+    } else {
+      uint64_t mask = (static_cast<uint64_t>(1) << 32U) - 1U;
+      uint64_t low = uval & mask;
+      uint64_t high = uval >> 32U;
+      return LargeUIntImm(t, static_cast<int64_t>(low), static_cast<int64_t>(high), span);
+    }
+  }
+  if (t.is_float() || t.is_bfloat16()) return FloatImm(t, static_cast<double>(value), span);
+  // For now, we store const scalar values of custom datatypes within doubles; later, during the
+  // datatypes lowering pass, we will lower the value to its true representation in the format
+  // specified by the datatype.
+  // TODO(gus) when do we need to start worrying about doubles not being precise enough?
+  if (static_cast<uint8_t>(t.code()) >= static_cast<uint8_t>(DataType::kCustomBegin)) {
+    return FloatImm(t, static_cast<double>(value), span);
+  }
+  LOG(FATAL) << "cannot make const for type " << t;
+}
+
+template <>
+inline PrimExpr MakeConstScalar(DataType t, bool value, Span span) {
+  return MakeConstScalar(t, static_cast<int>(value), span);
+}
+
+template <typename ValueType, typename>
+inline PrimExpr make_const(DataType t, ValueType value, Span span) {
+  if (t.lanes() == 1) {
+    return MakeConstScalar(t, value, span);
+  } else {
+    return tir::Broadcast(MakeConstScalar(t.element_of(), value, span), t.lanes(), span);
+  }
+}
+
+inline PrimExpr make_zero(DataType t, Span span) {
+  if (t.is_handle()) {
+    return reinterpret(t, make_const(DataType::UInt(64), 0, span));
+  }
+  return make_const(t, 0, span);
+}
+
+template <typename FReduce>
+inline PrimExpr foldl(FReduce freduce, PrimExpr init_value, const Array<PrimExpr>& values,
+                      Span span) {
+  for (PrimExpr val : values) {
+    init_value = freduce(init_value, val, span);
+  }
+  return init_value;
+}
+
+}  // namespace tir
+
+// additional const expression overloading
+#define TVM_DEFINE_ASSIGN_OP_OVERLOAD(Name, OpFunc) \
+  inline PrimExpr Name(PrimExpr& a, PrimExpr b) {   \
+    a = OpFunc(a, b);                               \
+    return a;                                       \
+  }
+
+#define TVM_DEFINE_BINOP_CONST_VAL_OVERLOAD(Name)                                   \
+  inline PrimExpr Name(const PrimExpr& a, float b) { return Name(a, PrimExpr(b)); } \
+  inline PrimExpr Name(float a, const PrimExpr& b) { return Name(PrimExpr(a), b); } \
+  inline PrimExpr Name(int a, const PrimExpr& b) {                                  \
+    return Name(tir::make_const(b.dtype(), a), b);                                  \
+  }                                                                                 \
+  inline PrimExpr Name(const PrimExpr& a, int b) {                                  \
+    return Name(a, tir::make_const(a.dtype(), b));                                  \
+  }                                                                                 \
+  inline PrimExpr Name(const PrimExpr& a, double b) {                               \
+    return Name(a, tir::make_const(DataType::Float(64), b));                        \
+  }
+
+#define TVM_DEFINE_BINOP_CONST_VAL_OVERLOAD_SPANNED(Name)                 \
+  inline PrimExpr Name(const PrimExpr& a, float b, Span span = Span()) {  \
+    return Name(a, PrimExpr(b), span);                                    \
+  }                                                                       \
+  inline PrimExpr Name(float a, const PrimExpr& b, Span span = Span()) {  \
+    return Name(PrimExpr(a), b, span);                                    \
+  }                                                                       \
+  inline PrimExpr Name(int a, const PrimExpr& b, Span span = Span()) {    \
+    return Name(tir::make_const(b.dtype(), a), b, span);                  \
+  }                                                                       \
+  inline PrimExpr Name(const PrimExpr& a, int b, Span span = Span()) {    \
+    return Name(a, tir::make_const(a.dtype(), b), span);                  \
+  }                                                                       \
+  inline PrimExpr Name(const PrimExpr& a, double b, Span span = Span()) { \
+    return Name(a, tir::make_const(DataType::Float(64), b), span);        \
+  }
+
+#define TVM_DEFINE_LOGICAL_OP_CONST_VAL_OVERLOAD(Name)                             \
+  inline PrimExpr Name(const PrimExpr& a, bool b) { return Name(a, PrimExpr(b)); } \
+  inline PrimExpr Name(bool a, const PrimExpr& b) { return Name(PrimExpr(a), b); }
+
+#define TVM_DEFINE_LOGICAL_OP_CONST_VAL_OVERLOAD_SPANNED(Name)          \
+  inline PrimExpr Name(const PrimExpr& a, bool b, Span span = Span()) { \
+    return Name(a, PrimExpr(b), span);                                  \
+  }                                                                     \
+  inline PrimExpr Name(bool a, const PrimExpr& b, Span span = Span()) { \
+    return Name(PrimExpr(a), b, span);                                  \
+  }
+
+#define TVM_DEFINE_INT_OP_CONST_VAL_OVERLOAD(Name) \
+  inline PrimExpr Name(const PrimExpr& a, int b) { \
+    return Name(a, tir::make_const(a.dtype(), b)); \
+  }                                                \
+  inline PrimExpr Name(int a, const PrimExpr& b) { return Name(tir::make_const(b.dtype(), a), b); }
+
+#define TVM_DEFINE_INT_OP_CONST_VAL_OVERLOAD_SPANNED(Name)             \
+  inline PrimExpr Name(const PrimExpr& a, int b, Span span = Span()) { \
+    return Name(a, tir::make_const(a.dtype(), b), span);               \
+  }                                                                    \
+  inline PrimExpr Name(int a, const PrimExpr& b, Span span = Span()) { \
+    return Name(tir::make_const(b.dtype(), a), b, span);               \
+  }
+
+TVM_DEFINE_ASSIGN_OP_OVERLOAD(operator+=, operator+);
+TVM_DEFINE_ASSIGN_OP_OVERLOAD(operator-=, operator-);
+TVM_DEFINE_ASSIGN_OP_OVERLOAD(operator*=, operator*);
+TVM_DEFINE_BINOP_CONST_VAL_OVERLOAD(operator+);
+TVM_DEFINE_BINOP_CONST_VAL_OVERLOAD(operator-);
+TVM_DEFINE_BINOP_CONST_VAL_OVERLOAD(operator*);
+TVM_DEFINE_BINOP_CONST_VAL_OVERLOAD(operator>);  // NOLINT(*)
+TVM_DEFINE_BINOP_CONST_VAL_OVERLOAD(operator>=);
+TVM_DEFINE_BINOP_CONST_VAL_OVERLOAD(operator<);  // NOLINT(*)
+TVM_DEFINE_BINOP_CONST_VAL_OVERLOAD(operator<=);
+TVM_DEFINE_BINOP_CONST_VAL_OVERLOAD_SPANNED(max);
+TVM_DEFINE_BINOP_CONST_VAL_OVERLOAD_SPANNED(min);
+TVM_DEFINE_BINOP_CONST_VAL_OVERLOAD_SPANNED(div);
+TVM_DEFINE_BINOP_CONST_VAL_OVERLOAD_SPANNED(add);
+TVM_DEFINE_BINOP_CONST_VAL_OVERLOAD_SPANNED(sub);
+TVM_DEFINE_BINOP_CONST_VAL_OVERLOAD_SPANNED(mul);
+TVM_DEFINE_BINOP_CONST_VAL_OVERLOAD_SPANNED(greater);
+TVM_DEFINE_BINOP_CONST_VAL_OVERLOAD_SPANNED(greater_equal);
+TVM_DEFINE_BINOP_CONST_VAL_OVERLOAD_SPANNED(less);
+TVM_DEFINE_BINOP_CONST_VAL_OVERLOAD_SPANNED(less_equal);
+// integer related ops
+TVM_DEFINE_INT_OP_CONST_VAL_OVERLOAD_SPANNED(indexdiv);
+TVM_DEFINE_INT_OP_CONST_VAL_OVERLOAD_SPANNED(indexmod);
+TVM_DEFINE_INT_OP_CONST_VAL_OVERLOAD_SPANNED(truncdiv);
+TVM_DEFINE_INT_OP_CONST_VAL_OVERLOAD_SPANNED(truncmod);
+TVM_DEFINE_INT_OP_CONST_VAL_OVERLOAD_SPANNED(floordiv);
+TVM_DEFINE_INT_OP_CONST_VAL_OVERLOAD_SPANNED(floormod);
+TVM_DEFINE_INT_OP_CONST_VAL_OVERLOAD_SPANNED(right_shift);  // NOLINT(*)
+TVM_DEFINE_INT_OP_CONST_VAL_OVERLOAD_SPANNED(left_shift);   // NOLINT(*)
+TVM_DEFINE_INT_OP_CONST_VAL_OVERLOAD_SPANNED(bitwise_and);
+TVM_DEFINE_INT_OP_CONST_VAL_OVERLOAD_SPANNED(bitwise_or);
+TVM_DEFINE_INT_OP_CONST_VAL_OVERLOAD_SPANNED(bitwise_xor);
+TVM_DEFINE_INT_OP_CONST_VAL_OVERLOAD(operator>>);  // NOLINT(*)
+TVM_DEFINE_INT_OP_CONST_VAL_OVERLOAD(operator<<);  // NOLINT(*)
+TVM_DEFINE_INT_OP_CONST_VAL_OVERLOAD(operator&);
+TVM_DEFINE_INT_OP_CONST_VAL_OVERLOAD(operator|);
+TVM_DEFINE_INT_OP_CONST_VAL_OVERLOAD(operator^);
+// logical ops
+TVM_DEFINE_LOGICAL_OP_CONST_VAL_OVERLOAD(operator&&);
+TVM_DEFINE_LOGICAL_OP_CONST_VAL_OVERLOAD(operator||);
+TVM_DEFINE_LOGICAL_OP_CONST_VAL_OVERLOAD_SPANNED(logical_and);
+TVM_DEFINE_LOGICAL_OP_CONST_VAL_OVERLOAD_SPANNED(logical_or);
+
+/*!
+ * \brief Helper function to raise a compiler error about division ambiguity.
+ * \note The call to this function will always results in a compiler error.
+ * \tparam TA Any class type.
+ */
+template <typename TA>
+inline void DivAmbiguityError(const TA& a) {
+  constexpr bool div_ambiguity = !std::is_class<TA>::value;
+  static_assert(div_ambiguity,
+                "TVM supports multiple types of integer divisions, "
+                "please call div, indexdiv/indexmod, "
+                "floordiv/floormod or truncdiv/truncmod directly "
+                "to avoid ambiguity in the code. "
+                "Checkout these functions in tir/op.h.");
+}
+
+// The following code are not intended to be used in the codebase.
+// Instead, they generate clear compiler errors that ask developers
+// to use the specific division function.
+// The second template argument is necessary to make sure the
+// code compiles lazily by the compiler during invocation.
+template <typename TB>
+inline PrimExpr operator/(const PrimExpr& a, const TB& b) {
+  DivAmbiguityError(a);
+  return a;
+}
+
+template <typename TB>
+inline PrimExpr operator/=(const PrimExpr& a, const TB& b) {
+  DivAmbiguityError(a);
+  return a;
+}
+
+template <typename TB>
+inline PrimExpr operator%(const PrimExpr& a, const TB& b) {
+  DivAmbiguityError(a);
+  return a;
+}
+}  // namespace tvm
+#endif  // TVM_TIR_OP_H_
diff --git a/darknet_drp_ros/include/tvm/tir/op_attr_types.h b/darknet_drp_ros/include/tvm/tir/op_attr_types.h
new file mode 100644
index 0000000..2dc174f
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/op_attr_types.h
@@ -0,0 +1,130 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/tir/op_attr_types.h
+ * \brief Attribute types in the Op registry for TIR ops.
+ *
+ * These attributes can be set via OpRegEntry::set_attr
+ *
+ * \sa tvm/ir/op.h
+ */
+#ifndef TVM_TIR_OP_ATTR_TYPES_H_
+#define TVM_TIR_OP_ATTR_TYPES_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/runtime/container/string.h>
+#include <tvm/runtime/packed_func.h>
+
+#include <ostream>
+
+namespace tvm {
+namespace tir {
+/*!
+ * \brief Global symbol of the op after lowering.
+ */
+using TGlobalSymbol = String;
+
+/*!
+ * \brief Whether the op is overloaded for vector form.
+ */
+using TVectorizable = bool;
+
+/*!
+ * \brief The intrinsic lowering function for given op.
+ */
+using FLowerIntrinsic = runtime::TypedPackedFunc<PrimExpr(PrimExpr)>;
+
+/*!
+ * \brief The legalization function for given tir op.
+ */
+using FLegalize = runtime::TypedPackedFunc<PrimExpr(PrimExpr)>;
+
+/*!
+ * \brief The effect type of the call.
+ */
+enum class CallEffectKind : int {
+  /*! \brief Function corresponds to an annotation(e.g. likely) and can translate to identity. */
+  kExprAnnotation = 0,
+  /*!
+   * \brief Pure function that do not interacts
+   *        with any external state.
+   */
+  kPure = 1,
+  /*!
+   * \brief Function's that may read from states(e.g. RAM)
+   */
+  kReadState = 2,
+  /*!
+   * \brief Function that may read/write from states(e.g. RAM).
+   */
+  kUpdateState = 3,
+  /*!
+   * \brief Opaque function, cannot make any assumption
+   */
+  kOpaque = kUpdateState,
+  /*!
+   * \brief Special intrinsic to annotate call arguments info
+   *        only valid as a direct argument to a call.
+   */
+  kSpecialCallArg = 4,
+  /*!
+   * \brief Embed opaque information in the Expr, cannot be codegen.
+   */
+  kEmbedInfo = 5,
+  /*!
+   * \brief Function that changes control flow
+   */
+  kControlJump = 6,
+};
+
+inline std::ostream& operator<<(std::ostream& os, CallEffectKind side_effect) {
+  switch (side_effect) {
+    case CallEffectKind::kExprAnnotation:
+      return os << "kExprAnnotation";
+
+    case CallEffectKind::kPure:
+      return os << "kPure";
+
+    case CallEffectKind::kReadState:
+      return os << "kReadState";
+
+    case CallEffectKind::kUpdateState:
+      return os << "kUpdateState";
+
+    case CallEffectKind::kSpecialCallArg:
+      return os << "kSpecialCallArg";
+
+    case CallEffectKind::kEmbedInfo:
+      return os << "kEmbedInfo";
+
+    case CallEffectKind::kControlJump:
+      return os << "kControlJump";
+
+    default:
+      LOG(FATAL) << "Unknown CallEffectKind: " << static_cast<int>(side_effect);
+  }
+}
+
+/*! \brief Use integer to record the kind. */
+using TCallEffectKind = Integer;
+
+}  // namespace tir
+}  // namespace tvm
+#endif  // TVM_TIR_OP_ATTR_TYPES_H_
diff --git a/darknet_drp_ros/include/tvm/tir/schedule/block_scope.h b/darknet_drp_ros/include/tvm/tir/schedule/block_scope.h
new file mode 100644
index 0000000..be3e79a
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/schedule/block_scope.h
@@ -0,0 +1,273 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+/*!
+ * \file tvm/tir/schedule/block_scope.h
+ * \brief Definition of two pillar data structure for TensorIR scheduling: StmtSRef, BlockScope.
+ * \sa StmtSRefNode
+ * \sa BlockScopeNode
+ */
+#ifndef TVM_TIR_SCHEDULE_BLOCK_SCOPE_H_
+#define TVM_TIR_SCHEDULE_BLOCK_SCOPE_H_
+
+#include <tvm/tir/stmt.h>
+
+#include <unordered_map>
+
+namespace tvm {
+namespace tir {
+
+/*!
+ * \brief An object that refers to schedulable elements (block/for-loop) in TensorIR, aka "sref".
+ *
+ * Glossary
+ * - Block sref: A StmtSRef that points to a TensorIR block.
+ * - Loop sref: A StmtSRef that points to a TensorIR for loop.
+ * - Parent sref: The parent reference of an sref is the block or loop reference to the closest
+ schedulable statement. We define closest to be the nearest schedulable statement of an ancestor in
+ the AST.
+ * schedulable statement of its ancestors on the TensorIR AST.
+ * - Root sref: Sref to the root block. Every sref has exactly one parent sref except for root sref.
+ * - Sref tree: The parent-children-relationship of srefs that forms a tree, uniquely determined by
+ * the TensorIR AST.
+ */
+class StmtSRefNode : public Object {
+ public:
+  /*!
+   * \brief The block or `for` stmt the object refers to
+   * \note Non-owned reference (raw pointer) is used here, so that we can perform copy-on-write
+   * optimization on statements when possible. The strong reference is held in the ScheduleState.
+   */
+  const StmtNode* stmt;
+  /*! \brief The parent sref. */
+  StmtSRefNode* parent;
+  /*!
+   * \brief If the statement the sref points to is an element of a SeqStmt in the AST,
+   * then `seq_index` is set to its index; otherwise `seq_index` is -1
+   */
+  int64_t seq_index;
+
+  void VisitAttrs(AttrVisitor* v) {
+    // `stmt` is not visited
+    // `parent` is not visited
+    v->Visit("seq_index", &seq_index);
+  }
+
+  static constexpr const char* _type_key = "tir.StmtSRef";
+  TVM_DECLARE_FINAL_OBJECT_INFO(StmtSRefNode, Object);
+
+  /*! \brief Reset the object inplace to the invalid state */
+  void Reset() {
+    this->stmt = nullptr;
+    this->parent = nullptr;
+    this->seq_index = -1;
+  }
+
+  /*!
+   * \brief Get the referenced statement with proper type checking.
+   * It serves the same purpose as `ObjectRef::as`, but does not acquire strong reference to `stmt`
+   * \tparam StmtType The type that `this->stmt` to be downcasted to. Presumably
+   * tvm::tir::BlockNode or tvm::tir::ForNode
+   * \return nullptr if type check fails, otherwise the casted result for `this->stmt`
+   */
+  template <typename StmtType>
+  const StmtType* StmtAs() const {
+    if (stmt != nullptr && stmt->IsInstance<StmtType>()) {
+      return static_cast<const StmtType*>(stmt);
+    } else {
+      return nullptr;
+    }
+  }
+};
+
+/*!
+ * \brief Managed reference to StmtSRefNode
+ * \sa StmtSRefNode
+ */
+class StmtSRef : public ObjectRef {
+ public:
+  /*!
+   * \brief The constructor
+   * \param stmt The corresponding stmt node, can be either block or for loop.
+   * \param parent The parent sref.
+   * \param seq_index The location in an array if the parent of the stmt contains multiple children.
+   * -1 if the parent does not contain multiple children.
+   */
+  TVM_DLL explicit StmtSRef(const StmtNode* stmt, StmtSRefNode* parent, int64_t seq_index);
+
+  /*! \return The mutable pointer to the StmtSRefNode */
+  StmtSRefNode* get() const { return static_cast<StmtSRefNode*>(data_.get()); }
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(StmtSRef, ObjectRef, StmtSRefNode);
+
+ public:
+  /*!
+   * \return A special StmtSRef, which doesn't point to any stmt in the AST,
+   * only serving as a "mark" to hint compute-at to do the work of compute-inline
+   * \note This is only as a faked loop sref for compute-at and reverse-compute-at,
+   * i.e.
+   *
+   * compute-at(block, loop_sref):
+   *   compute-inline(block)                if loop_sref.same_as(InlineMark())
+   *   no-op                                if loop_sref.same_as(RootMark())
+   *   compute-at-impl(block, loop_sref)    otherwise
+   */
+  TVM_DLL static StmtSRef InlineMark();
+  /*!
+   * \return A special StmtSRef, which doesn't point to any stmt in the AST,
+   * only serving as a "mark" to hint compute-at to do nothing
+   * \note This is only as a faked loop sref for compute-at and reverse-compute-at,
+   * i.e.
+   *
+   * compute-at(block, loop_sref):
+   *   compute-inline(block)                if loop_sref.same_as(InlineMark())
+   *   no-op                                if loop_sref.same_as(RootMark())
+   *   compute-at-impl(block, loop_sref)    otherwise
+   */
+  TVM_DLL static StmtSRef RootMark();
+};
+
+/*!
+ * \brief Type of dependency. Right now we have 4 types of dependencies
+ * 1) Read-after-write (kRAW)
+ * 2) Write-after-write (kWAW)
+ * 3) Write-after-read (kWAR)
+ * 4) Opaque dependency (kOpaque)
+ */
+enum class DepKind : int32_t {
+  kRAW = 0,
+  kWAW = 1,
+  kWAR = 2,
+  kOpaque = 3,
+};
+
+/*!
+ * \brief A tuple (src, dst, kind) representing certain types of dependency.
+ * For example, (A, B, kRAW) means block B depends on block A, and the dependency kind is
+ * read-after-write, which means block B reads the result written by block A.
+ */
+class DependencyNode : public Object {
+ public:
+  /*! \brief The source of the dependency relation */
+  StmtSRef src;
+  /*! \brief The destination of the dependency relation */
+  StmtSRef dst;
+  /*! \brief The dependency kind */
+  DepKind kind;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("src", &src);
+    v->Visit("dst", &dst);
+    v->Visit("kind", &kind);
+  }
+
+  static constexpr const char* _type_key = "tir.Dependency";
+  TVM_DECLARE_FINAL_OBJECT_INFO(DependencyNode, Object);
+};
+
+/*!
+ * \brief Managed reference to DependencyNode
+ * \sa DependencyNode
+ */
+class Dependency : public ObjectRef {
+ public:
+  /*! \brief Constructor */
+  TVM_DLL explicit Dependency(StmtSRef src, StmtSRef dst, DepKind kind);
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(Dependency, ObjectRef, DependencyNode);
+};
+
+/*!
+ * \brief An object with 1-to-1 correspondence with each block reference in the sref tree.
+ * This data structure is used to track the producer-consumer dependencies between blocks.
+ * For example even leaf nodes have a scope node, even though they have no dependencies.
+ *
+ * Glossary:
+ * - Block scope: A contiguous subtree of the sref tree, rooted at each block sref,
+ * whose components are:
+ *   - scope root: a block sref
+ *   - internal srefs: loop srefs
+ *   - scope leaves: block srefs
+ * - Child block: The scope leaf blocks under the scope root or a specific internal sref
+ */
+class BlockScopeNode : public Object {
+ public:
+  /*!
+   * \brief Lookup table for the `src` of dependencies
+   * \note We intentionally didn't use tvm::Map as the data structure, because we need the values
+   * inside to be mutable so that they could be further maintained properly during transformations.
+   */
+  std::unordered_map<StmtSRef, Array<Dependency>, ObjectPtrHash, ObjectPtrEqual> src2deps;
+  /*! \brief Lookup table for the `dst` of dependencies */
+  std::unordered_map<StmtSRef, Array<Dependency>, ObjectPtrHash, ObjectPtrEqual> dst2deps;
+  /*! \brief The mapping from the buffer to the blocks who write it */
+  std::unordered_map<Buffer, Array<StmtSRef>, ObjectPtrHash, ObjectPtrEqual> buffer_writers;
+  /*!
+   * \brief This property indicates that the block scope (rooted at its corresponding block) is
+   * equivalent to of a stage pipeline. Under the following conditions:
+   *
+   * 1) The region cover property holds for every of its child blocks
+   * 2) No write-after-read dependency or opaque dependency, only read-after-write and
+   * write-after-write are allowed
+   * 3) All the statements in the scope are schedulable statements, i.e. Block and For
+   */
+  bool stage_pipeline{false};
+
+  void VisitAttrs(AttrVisitor* v) {}
+
+  static constexpr const char* _type_key = "tir.BlockScope";
+  TVM_DECLARE_FINAL_OBJECT_INFO(BlockScopeNode, Object);
+
+ public:
+  /******** Dependency ********/
+  /*!
+   * \brief Get all dependencies whose `src` equals `src`
+   * \param src The queried block
+   * \return The dependencies
+   */
+  TVM_DLL Array<Dependency> GetDepsBySrc(const StmtSRef& src) const;
+  /*!
+   * \brief Get all dependencies whose `dst` equals `dst`
+   * \param dst The queried block
+   * \return The dependencies
+   */
+  TVM_DLL Array<Dependency> GetDepsByDst(const StmtSRef& dst) const;
+};
+
+/*!
+ * \brief Managed reference to BlockScopeNode
+ * \sa BlockScopeNode
+ */
+class BlockScope : public ObjectRef {
+ public:
+  /*! \brief The constructor creating an empty block scope with on dependency information */
+  TVM_DLL BlockScope();
+  /*!
+   * \brief Create the object with the specific leaf blocks, and compute the dependency information
+   * between the leaf blocks.
+   * \param child_block_srefs The srefs to the leaf blocks
+   * \note We assume the leaf blocks are given in pre-DFS order
+   */
+  TVM_DLL explicit BlockScope(const Array<StmtSRef>& child_block_srefs);
+
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(BlockScope, ObjectRef, BlockScopeNode);
+};
+
+}  // namespace tir
+}  // namespace tvm
+
+#endif  // TVM_TIR_SCHEDULE_BLOCK_SCOPE_H_
diff --git a/darknet_drp_ros/include/tvm/tir/schedule/instruction.h b/darknet_drp_ros/include/tvm/tir/schedule/instruction.h
new file mode 100644
index 0000000..1af5ab0
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/schedule/instruction.h
@@ -0,0 +1,291 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_TIR_SCHEDULE_INSTRUCTION_H_
+#define TVM_TIR_SCHEDULE_INSTRUCTION_H_
+
+#include <tvm/node/reflection.h>
+
+#include <utility>
+
+namespace tvm {
+
+// Forward declaration
+template <typename, typename>
+class AttrRegistry;
+
+namespace tir {
+
+// Forward declaration
+class Schedule;
+
+/*!
+ * \brief Type of the functor that applies the instruction to a TensorIR schedule
+ * \param sch The schedule to be applied on
+ * \param inputs The input random variables
+ * \param attrs Instruction attributes
+ * \param decision Decisions made on the instruction
+ * \return The functor returns an array of output random variables
+ */
+using FInstructionApply = runtime::TypedPackedFunc<Array<ObjectRef>(
+    Schedule sch, const Array<ObjectRef>& inputs, const Array<ObjectRef>& attrs,
+    const Optional<ObjectRef>& decision)>;
+
+/*!
+ * \brief Type of the functor that converts the instruction to a statement in python syntax
+ * \param inputs Names of the input random variables
+ * \param attrs Instruction attributes
+ * \param decisions Decisions made on the instruction
+ * \param outputs Names of the output random variables
+ * \return A string representing the python api call
+ */
+using FInstructionAsPython = runtime::TypedPackedFunc<String(
+    const Array<ObjectRef>& inputs, const Array<ObjectRef>& attrs,
+    const Optional<ObjectRef>& decision, const Array<String>& outputs)>;
+
+/*!
+ * \brief Type of the functor that serialize its attributes to JSON
+ * \param attrs The attributes to be serialized
+ * \return An array, serialized attributes
+ * \note This functor is nullable
+ */
+using FInstructionAttrsAsJSON = runtime::TypedPackedFunc<ObjectRef(Array<ObjectRef> attrs)>;
+
+/*!
+ * \brief Type of the functor that deserialize its attributes from JSON
+ * \param json_attrs The attributes to be serialized
+ * \return An array, deserialized attributes
+ * \note This functor is nullable
+ */
+using FInstructionAttrsFromJSON = runtime::TypedPackedFunc<Array<ObjectRef>(ObjectRef json_attrs)>;
+
+/*!
+ * \brief Kind of an instruction, e.g. Split, Reorder, etc.
+ * Besides the name, every kind of instruction has its own properties, including:
+ * 1) A boolean indicating if the instruction is pure, i.e. change nothing in the schedule state
+ * 2) A functor that applies the instruction to a TensorIR schedule
+ * 3) A functor that converts the instruction to a statement in python syntax
+ * 4) A functor that serialize its attributes to JSON
+ * 5) A functor that deserialize its attributes from JSON
+ *
+ * Unlike `tvm::OpNode`, `InstructionKindNode` doesn't support unstructured properties,
+ * mainly because there is no such usecase yet to add any other property.
+ */
+class InstructionKindNode : public runtime::Object {
+ public:
+  /*! \brief The name of a kind of instructions */
+  String name;
+  /*!
+   * \brief Indicates if the instruction is pure, i.e. removing it alone doesn't mutate the schedule
+   * state. For example, the instruction `GetBlock` is pure because it changes
+   * nothing, while `ComputeInline` is not because removing it leads to a different resulting
+   * schedule.
+   */
+  bool is_pure{false};
+  /*! \brief A functor that applies the instruction to a TensorIR schedule */
+  FInstructionApply f_apply_to_schedule{nullptr};
+  /*! \brief A functor that converts the instruction to a statement in python syntax */
+  FInstructionAsPython f_as_python{nullptr};
+  /*!
+   * \brief A functor that serialize its attributes to JSON
+   * \note If the functor is null, it means no conversion is needed
+   */
+  FInstructionAttrsAsJSON f_attrs_as_json{nullptr};
+  /*!
+   * \brief A functor that deserialize its attributes from JSON
+   * \note If the functor is null, it means no conversion is needed
+   */
+  FInstructionAttrsFromJSON f_attrs_from_json{nullptr};
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("name", &name);
+    v->Visit("_is_pure", &is_pure);
+    // not visited: f_apply_to_schedule
+    // not visited: f_as_python
+    // not visited: f_attrs_as_json
+    // not visited: f_attrs_from_json
+  }
+
+  /*! \brief Checks if the instruction kind is EnterPostproc */
+  bool IsPostproc() const;
+
+  static constexpr const char* _type_key = "tir.InstructionKind";
+  TVM_DECLARE_FINAL_OBJECT_INFO(InstructionKindNode, runtime::Object);
+};
+
+/*!
+ * \brief Managed reference to InstructionKindNode
+ * \sa InstructionKindNode
+ */
+class InstructionKind : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief Retrieve an InstructionKind using its name
+   * \param name The registered name of the InstructionKind
+   * \return The InstructionKind retrieved
+   */
+  static InstructionKind Get(const String& name);
+  TVM_DEFINE_OBJECT_REF_METHODS(InstructionKind, runtime::ObjectRef, InstructionKindNode);
+};
+
+/*! \brief Schedule instructions each corresponds to a schedule primitive */
+class InstructionNode : public runtime::Object {
+ public:
+  /*! \brief The kind of the instruction */
+  InstructionKind kind;
+  /*!
+   * \brief The input random variables of the instruction, and the type of each element can be one
+   * of the following:
+   * - BlockRV
+   * - LoopRV
+   * - ExprRV
+   * - FloatImm
+   * - IntImm
+   * - String
+   * - null pointer
+   */
+  Array<ObjectRef> inputs;
+  /*!
+   * \brief The attributes of the instruction. Similar to attributes of an operator,
+   * attributes of an instruction are arbitrary constant metadata required by the instructions.
+   * For example, the name of the block to be retrieved in `GetBlock`.
+   */
+  Array<ObjectRef> attrs;
+  /*! \brief The output random variables of the instruction, and the type of each element can be one
+   * of the following:
+   * - BlockRV
+   * - LoopRV
+   * - ExprRV, atomic variables only, won't be constants or composite PrimExpr
+   */
+  Array<ObjectRef> outputs;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("kind", &kind);
+    v->Visit("inputs", &inputs);
+    v->Visit("attrs", &attrs);
+    v->Visit("outputs", &outputs);
+  }
+
+  static constexpr const char* _type_key = "tir.Instruction";
+  TVM_DECLARE_FINAL_OBJECT_INFO(InstructionNode, runtime::Object);
+};
+
+/*!
+ * \brief Managed reference to InstructionNode
+ * \sa InstructionNode
+ */
+class Instruction : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief Constructor
+   * \param kind The kind of the instruction
+   * \param inputs The input random variables of the instruction
+   * \param attrs The attributes of the instruction
+   * \param outputs The output random variables of the instruction
+   */
+  explicit Instruction(InstructionKind kind, Array<ObjectRef> inputs, Array<ObjectRef> attrs,
+                       Array<ObjectRef> outputs);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Instruction, runtime::ObjectRef, InstructionNode);
+};
+
+/*!
+ * \brief A helper macro to register InstructionKind, only used in `TVM_REGISTER_INST_KIND`
+ * \note This macro is not user-facing.
+ * \sa TVM_REGISTER_INST_KIND
+ */
+#define TVM_INST_KIND_REGISTER_VAR_DEF \
+  static DMLC_ATTRIBUTE_UNUSED ::tvm::tir::InstructionKindRegEntry& __make_##InstructionKind
+
+/*!
+ * \brief Register an InstructionKind
+ * \param InstructionKindName The name of the InstructionKind
+ *
+ * Example:
+ *
+ * \code
+ *
+ * TVM_REGISTER_INST_KIND("ComputeInline")
+ *     .set_is_pure(false)
+ *     .set_apply_to_schedule(ApplyToSchedule)
+ *     .set_attrs_as_json(AttrsAsJSON)
+ *     .set_attrs_from_json(AttrsFromJSON)
+ *     .set_as_python(AsPython);
+ *
+ * \endcode
+ */
+#define TVM_REGISTER_INST_KIND(InstructionKindName)             \
+  TVM_STR_CONCAT(TVM_INST_KIND_REGISTER_VAR_DEF, __COUNTER__) = \
+      ::tvm::tir::InstructionKindRegEntry::RegisterOrGet(InstructionKindName).set_name()
+
+/*! \brief An entry in the registry of InstructionKind */
+class InstructionKindRegEntry {
+ public:
+  static InstructionKindRegEntry& RegisterOrGet(const String& name);
+
+  InstructionKindRegEntry& set_name() {
+    get_mutable()->name = this->name;
+    return *this;
+  }
+
+  InstructionKindRegEntry& set_is_pure(bool is_pure) {
+    get_mutable()->is_pure = is_pure;
+    return *this;
+  }
+
+  InstructionKindRegEntry& set_apply_to_schedule(FInstructionApply f_apply_to_schedule) {
+    get_mutable()->f_apply_to_schedule = std::move(f_apply_to_schedule);
+    return *this;
+  }
+
+  InstructionKindRegEntry& set_as_python(FInstructionAsPython f_as_python) {
+    get_mutable()->f_as_python = std::move(f_as_python);
+    return *this;
+  }
+
+  InstructionKindRegEntry& set_attrs_as_json(FInstructionAttrsAsJSON f_attrs_as_json) {
+    get_mutable()->f_attrs_as_json = std::move(f_attrs_as_json);
+    return *this;
+  }
+
+  InstructionKindRegEntry& set_attrs_from_json(FInstructionAttrsFromJSON f_attrs_from_json) {
+    get_mutable()->f_attrs_from_json = std::move(f_attrs_from_json);
+    return *this;
+  }
+
+ private:
+  /*! \brief Private constructor, used only by AttrRegistry */
+  explicit InstructionKindRegEntry(uint32_t reg_index);
+  /*! \brief Get the mutable reference to the internal InstructionKind */
+  InstructionKindNode* get_mutable() const {
+    return const_cast<InstructionKindNode*>(inst_kind_.get());
+  }
+
+  /*! \brief The name of the registry entry */
+  String name;
+  /*! \brief The instruction kind */
+  InstructionKind inst_kind_;
+  template <typename, typename>
+  friend class ::tvm::AttrRegistry;
+  friend class InstructionKind;
+};
+
+}  // namespace tir
+}  // namespace tvm
+
+#endif  //  TVM_TIR_SCHEDULE_INSTRUCTION_H_
diff --git a/darknet_drp_ros/include/tvm/tir/schedule/schedule.h b/darknet_drp_ros/include/tvm/tir/schedule/schedule.h
new file mode 100644
index 0000000..8b22c17
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/schedule/schedule.h
@@ -0,0 +1,774 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_TIR_SCHEDULE_SCHEDULE_H_
+#define TVM_TIR_SCHEDULE_SCHEDULE_H_
+
+#include <tvm/support/random_engine.h>
+#include <tvm/tir/index_map.h>
+#include <tvm/tir/schedule/state.h>
+#include <tvm/tir/schedule/trace.h>
+
+namespace tvm {
+namespace tir {
+
+/*! \brief The level of detailed error message rendering */
+enum class ScheduleErrorRenderLevel : int32_t {
+  /*! \brief Render a detailed error message */
+  kDetail = 0,
+  /*! \brief Render the error in fast mode */
+  kFast = 1,
+  /*! \brief No error message at all */
+  kNone = 2,
+};
+
+/*! \brief Type of buffer index */
+enum class BufferIndexType : int32_t {
+  /*! \brief Index of a read buffer */
+  kRead = 0,
+  /*! \brief Index of a written buffer */
+  kWrite = 1,
+};
+
+/**************** Random variable: BlockRV ****************/
+
+/*! \brief A random variable that evaluates to a TensorIR block */
+class BlockRVNode : public runtime::Object {
+ public:
+  void VisitAttrs(tvm::AttrVisitor* v) {}
+  static constexpr const char* _type_key = "tir.BlockRV";
+  TVM_DECLARE_FINAL_OBJECT_INFO(BlockRVNode, runtime::Object);
+};
+
+/*!
+ * \brief Managed reference to BlockRVNode
+ * \sa BlockRVNode
+ */
+class BlockRV : public runtime::ObjectRef {
+ public:
+  /*! \brief Constructor */
+  TVM_DLL BlockRV();
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(BlockRV, runtime::ObjectRef, BlockRVNode);
+};
+
+/**************** Random variable: LoopRV ****************/
+
+/*! \brief A random variable that evaluates to a TensorIR for loop */
+class LoopRVNode : public runtime::Object {
+ public:
+  void VisitAttrs(tvm::AttrVisitor* v) {}
+  static constexpr const char* _type_key = "tir.LoopRV";
+  TVM_DECLARE_FINAL_OBJECT_INFO(LoopRVNode, runtime::Object);
+};
+
+/*!
+ * \brief Managed reference to LoopRVNode
+ * \sa LoopRVNode
+ */
+class LoopRV : public runtime::ObjectRef {
+ public:
+  /*! \brief Constructor */
+  TVM_DLL LoopRV();
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(LoopRV, runtime::ObjectRef, LoopRVNode);
+};
+
+/**************** Random variable: ExprRV ****************/
+
+/*! \brief An expr random variable */
+using ExprRV = PrimExpr;
+
+using ExprRVNode = PrimExprNode;
+
+/**************** The Schedule class ****************/
+
+class Schedule;
+
+/*! \brief The user-facing schedule class */
+class ScheduleNode : public runtime::Object {
+  friend class Schedule;
+
+ public:
+  virtual ~ScheduleNode() = default;
+
+  static constexpr const char* _type_key = "tir.Schedule";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ScheduleNode, runtime::Object);
+
+ public:
+  /*! \brief Get the IRModule associated with this schedule. */
+  virtual IRModule mod() const { return state()->mod; }
+  /*! \return The internal state of scheduling */
+  virtual ScheduleState state() const = 0;
+  /*! \return The internally maintained trace of scheduling program execution */
+  virtual Optional<Trace> trace() const = 0;
+  /*!
+   * \brief Instruct the schedule to work on a function in the IRModule.
+   *
+   * By default, the schedule works on the function with the name "main", or the only function in
+   * the IRModule if there is only one. If there is multiple functions in the IRModule, and none of
+   * their names are "main", users will have to call this method to explicitly specify which
+   * function to work on.
+   *
+   * This sugar function will guide the `GetBlock` method if its `func_name` is not specified.
+   *
+   * \param func_name The name of the function to be working on
+   *
+   * \sa GetBlock
+   */
+  virtual void WorkOn(const String& func_name) = 0;
+  /*!
+   * \brief Returns a copy of the schedule, including both its state and its symbol table,
+   * guaranteeing that
+   * 1) SRef tree is completely reconstructed;
+   * 2) The IRModule being scheduled is not modified;
+   * 3) All the random variables are valid in the copy, pointing to the corresponding sref
+   * reconstructed
+   */
+  virtual Schedule Copy() = 0;
+  /*!
+   * \brief Seed the randomness
+   * \param seed The new random seed, -1 if use device random, otherwise non-negative
+   */
+  virtual void Seed(support::LinearCongruentialEngine::TRandState seed) = 0;
+  /*! \brief Fork the random state */
+  virtual support::LinearCongruentialEngine::TRandState ForkSeed() = 0;
+
+ public:
+  /******** Lookup/Remove random variables ********/
+  /*!
+   * \brief Get the block corresponding to the specific BlockRV
+   * \param block_rv The BlockRV to be looked up
+   * \return The corresponding block
+   */
+  virtual Block Get(const BlockRV& block_rv) const = 0;
+  /*!
+   * \brief Get the for loop corresponding to the specific LoopRV
+   * \param loop_rv The LoopRV to be looked up
+   * \return The corresponding for loop
+   */
+  virtual For Get(const LoopRV& loop_rv) const = 0;
+  /*!
+   * \brief Get the expr corresponding to the specific random variable
+   * \param expr_rv The random variable to be looked up
+   * \return The corresponding expr
+   */
+  virtual PrimExpr Get(const ExprRV& expr_rv) const = 0;
+  /*!
+   * \brief Get the block sref corresponding to the specific BlockRV
+   * \param block_rv The BlockRV to be looked up
+   * \return The corresponding block sref
+   */
+  virtual StmtSRef GetSRef(const BlockRV& block_rv) const = 0;
+  /*!
+   * \brief Get the loop sref corresponding to the specific LoopRV
+   * \param loop_rv The LoopRV to be looked up
+   * \return The corresponding loop sref
+   */
+  virtual StmtSRef GetSRef(const LoopRV& loop_rv) const = 0;
+  /*!
+   * \brief Check the existance of a specific BlockRV
+   * \param block_rv The BlockRV to be looked up
+   * \return Whether the corresponding block exists
+   */
+  virtual bool HasBlock(const BlockRV& block_rv) const = 0;
+  /*!
+   * \brief Get the block/loop sref corresponding to the specific statement
+   * \param stmt The statement to be looked up
+   * \return The corresponding block/loop sref
+   */
+  virtual StmtSRef GetSRef(const StmtNode* stmt) const;
+  /*!
+   * \brief Get the block/loop sref corresponding to the specific statement
+   * \param stmt The statement to be looked up
+   * \return The corresponding block/loop sref
+   */
+  StmtSRef GetSRef(const Stmt& stmt) const { return this->GetSRef(stmt.get()); }
+  /*!
+   * \brief Remove a block random variable from the symbol table
+   * \param block_rv The random variable to be removed
+   */
+  virtual void RemoveRV(const BlockRV& block_rv) = 0;
+  /*!
+   * \brief Remove a loop random variable from the symbol table
+   * \param loop_rv The random variable to be removed
+   */
+  virtual void RemoveRV(const LoopRV& loop_rv) = 0;
+  /*!
+   * \brief Remove an integer random variable from the symbol table
+   * \param expr_rv The random variable to be removed
+   */
+  virtual void RemoveRV(const ExprRV& expr_rv) = 0;
+
+ public:
+  /******** Schedule: Sampling ********/
+  /*!
+   * \brief Sample an integer given the probability distribution
+   * \param candidates The candidates
+   * \param probs The probability distribution of the candidates
+   * \param decision The sampling decision
+   * \return The random variable sampled from candidates
+   */
+  virtual ExprRV SampleCategorical(const Array<Integer>& candidates, const Array<FloatImm>& probs,
+                                   Optional<Integer> decision = NullOpt) = 0;
+  /*!
+   * \brief Sample the factors to perfect tile a specific loop
+   * \param loop_rv The loop to be tiled
+   * \param n The number of tiles to be sampled
+   * \param max_innermost_factor The maximum tile size allowed to be sampled in the innermost loop
+   * \param decision The sampling decision
+   * \return A list of length `n`, the random perfect tile sizes sampled
+   */
+  virtual Array<ExprRV> SamplePerfectTile(const LoopRV& loop_rv, int n, int max_innermost_factor,
+                                          Optional<Array<Integer>> decision = NullOpt) = 0;
+  /*!
+   * \brief Sample a compute-at location of the given block
+   * \param block_rv The block whose compute-at location is to be sampled
+   * \param decision The sampling decision
+   * \return The sampled loop where the input block is to be computed at
+   */
+  virtual LoopRV SampleComputeLocation(const BlockRV& block_rv,
+                                       Optional<Integer> decision = NullOpt) = 0;
+
+  /******** Schedule: Get blocks & loops ********/
+  /*!
+   * \brief Retrieve a block in a specific function with its name
+   *
+   * By default, if `func_name` is not specified, the schedule will search for the block in the
+   * function that is currently being "worked on". To switch the function to be worked on, use
+   * `WorkOn` before calling this method.
+   *
+   * \param name The name of the block to be retrieved
+   * \param func_name The name of the function
+   * \return The block retrieved
+   * \note Indexing error is raised if 0 or multiple blocks exist with the specific name
+   *
+   * \sa WorkOn
+   */
+  virtual BlockRV GetBlock(const String& name, const Optional<String>& func_name = NullOpt) = 0;
+  /*!
+   * \brief Get the parent loops of the block in its scope, from outer to inner
+   * \param block_rv The query block
+   * \return A list of loops above the given block in its scope, from outer to inner
+   */
+  virtual Array<LoopRV> GetLoops(const BlockRV& block_rv) = 0;
+  /*!
+   * \brief Get the leaf blocks of a specific scope
+   * \param block_rv The block where the scope is rooted
+   * \return A list of child blocks
+   */
+  virtual Array<BlockRV> GetChildBlocks(const BlockRV& block_rv) = 0;
+  /*!
+   * \brief Get the leaf blocks of under a specific loop
+   * \param loop_rv The loop under which collecting is conducted
+   * \return A list of child blocks
+   */
+  virtual Array<BlockRV> GetChildBlocks(const LoopRV& loop_rv) = 0;
+  /*!
+   * \brief Get the producer of a specific block, under the same block scope
+   * \param block_rv The block in the query
+   * \return A list of blocks, the producers of the given block under the same scope of the given
+   * block
+   */
+  virtual Array<BlockRV> GetProducers(const BlockRV& block_rv) = 0;
+  /*!
+   * \brief Get the consumers of a specific block, under the same block scope
+   * \param block_rv The block to be queried
+   * \return A list of blocks, the consumers of the given block under the same scope of the given
+   * block
+   */
+  virtual Array<BlockRV> GetConsumers(const BlockRV& block_rv) = 0;
+  /******** Schedule: Transform loops ********/
+  /*!
+   * \brief Fuse a list of consecutive loops into one. It requires:
+   * 1) The loops can't have annotations or thread bindings.
+   * 2) The (i+1)-th loop must be the only child of the i-th loop.
+   * 3) All loops must start with 0.
+   * 4) The domain of a loop to be fused cannot depend on another loop to be fused.
+   * \param loop_rvs The loops to be fused
+   * \param preserve_unit_iters Whether or not to preserve unit iterators in block bindings
+   * \return The new loop after fusion
+   */
+  virtual LoopRV Fuse(const Array<LoopRV>& loop_rvs, bool preserve_unit_iters = true) = 0;
+  /*!
+   * \brief Split a loop into a list of consecutive loops. It requires:
+   * 1) The loop can't have annotation or thread binding.
+   * 2) The loop must start with 0.
+   * \param loop_rv The loop to be split
+   * \param factors The positive tiling factors, and at most one of which is `NullOpt`, which means
+   * that factor is inferred.
+   * \param preserve_unit_iters Whether or not to preserve unit iterators in block bindings
+   * \return The new loops after split
+   */
+  virtual Array<LoopRV> Split(const LoopRV& loop_rv, const Array<Optional<ExprRV>>& factors,
+                              bool preserve_unit_iters = true) = 0;
+  /*!
+   * \brief Reorder a list of loops. It doesn't require the loops to be consecutive.
+   * It requires:
+   * 1) The loops are in the same chain. That means: the loops can be ordered to [l_1, l_2, ... ,
+   *     l_n] where l_i is an ancestor of l_{i+1} and there are only single-branch loops between
+   *     l_1 and l_n (which also indicates they are under the same scope).
+   * 2) After reordering, the domain of an outer loop cannot depend on any of the inner loops.
+   * 3) For every block under the loop nests, its block binding must be affine, and the block
+   *    variables must be either data parallel or reduction.
+   * 4) No duplicated loops are allowed in the arguments.
+   * \param ordered_loop_rvs The loops in the new order
+   */
+  virtual void Reorder(const Array<LoopRV>& ordered_loop_rvs) = 0;
+  /*!
+   * \brief Create a new unit loop on top of the specific block.
+   * \param block_rv The block above which the new loop is created
+   * \return The new loop created
+   */
+  virtual LoopRV AddUnitLoop(const BlockRV& block_rv) = 0;
+  /*!
+   * \brief Create a new unit loop on top of the specific loop.
+   * \param loop_rv The loop above which the new loop is created
+   * \return The new loop created
+   */
+  virtual LoopRV AddUnitLoop(const LoopRV& loop_rv) = 0;
+  /******** Schedule: Manipulate ForKind ********/
+  /*!
+   * \brief Parallelize the input loop. It requires:
+   * 1) The scope block that the loop is in should have stage-pipeline property
+   * 2) All the blocks under the loop are complete blocks or reduction blocks, and have affine
+   * bindings
+   * 3) For each block under the loop, the loop can only be contained in data-parallel block iters'
+   * bindings
+   * \param loop_rv The loop to be parallelized
+   */
+  virtual void Parallel(const LoopRV& loop_rv) = 0;
+  /*!
+   * \brief Vectorize the input loop. It requires:
+   * 1) The scope block that the loop is in should have stage-pipeline property
+   * 2) All the blocks under the loop are complete blocks or reduction blocks, and have affine
+   * bindings
+   * 3) For each block under the loop, the loop can only be contained in data-parallel block iters'
+   * bindings
+   * \param loop_rv The loop to be vectorized
+   */
+  virtual void Vectorize(const LoopRV& loop_rv) = 0;
+  /*!
+   * \brief Bind the input loop to the given thread axis. It requires:
+   * 1) The scope block that the loop is in should have stage-pipeline property
+   * 2) All the blocks under the loop are complete blocks or reduction blocks, and have affine
+   * bindings
+   * 3) For each block under the loop, if the thread axis starts with "threadIdx`, the loop can only
+   * be contained in data-parallel block iter and reduction block iters' bindings. Otherwise the
+   * loop can only be contained in data-parallel block iters' bindings
+   * \param loop_rv The loop to be bound to the thread axis
+   * \param thread_axis The thread axis to be bound to the loop
+   */
+  virtual void Bind(const LoopRV& loop_rv, const String& thread_axis) = 0;
+  /*!
+   * \brief Unroll the input loop. It requires nothing
+   * \param loop_rv The loop to be unrolled
+   */
+  virtual void Unroll(const LoopRV& loop_rv) = 0;
+  /******** Schedule: Insert cache stages ********/
+  /*!
+   * \brief Create a block that reads a buffer region into a read cache. It requires:
+   * 1) There is at most one block who writes the buffer in the scope.
+   * 2) The scope block have stage-pipeline property.
+   * \param block_rv The consumer block of the target buffer.
+   * \param read_buffer_index The index of the buffer in block's read region.
+   * \param storage_scope The target storage scope.
+   * \param consumer_blocks An optional list of consumers of the cache to rewrite.
+   * \return The cache stage block.
+   */
+  virtual BlockRV CacheRead(const BlockRV& block_rv, int read_buffer_index,
+                            const String& storage_scope,
+                            const Array<BlockRV> consumer_blocks = {}) = 0;
+  /*!
+   * \brief Create a block that writes a buffer region into a write cache. It requires:
+   * 1) There is only one block who writes the target buffer.
+   * 2) The scope block have stage-pipeline property.
+   * \param block_rv The producer of the buffer
+   * \param write_buffer_index The index of the buffer in block's write region
+   * \param storage_scope The target storage scope
+   * \param consumer_blocks An optional list of consumers to read from cache directly.
+   * \return The cache stage block.
+   */
+  virtual BlockRV CacheWrite(const BlockRV& block_rv, int write_buffer_index,
+                             const String& storage_scope,
+                             const Array<BlockRV> consumer_blocks = {}) = 0;
+  /*!
+   * \brief Create 2 blocks that read&write a buffer region into a read/write cache.
+   * It requires the the target block both read & write the target buffer.
+   * \param block_rv The target block operates on the target buffer.
+   * \param read_buffer_index The index of the buffer in block's read region.
+   * \param storage_scope The target storage scope
+   * \return The cache stage blocks, cache read block together with cache write block.
+   */
+  virtual Array<BlockRV> CacheInplace(const BlockRV& block_rv, int read_buffer_index,
+                                      const String& storage_scope) = 0;
+  /*!
+   * \brief Create a block to cache precomputed index for later use.
+   * if there is no index computation, keep unchanged.
+   * \param block_rv The target block
+   * \param buffer_index The index of the target buffer in block's read region
+   * \return The cache stage blocks.
+   */
+  virtual Array<BlockRV> CacheIndex(const BlockRV& block_rv, int buffer_index) = 0;
+  /*!
+   * \brief Create a block that read/write a buffer region into a read/write cache with reindexing.
+   * The layout of the cache will be the same as by the iterators of the block that reads/writes the
+   * buffer. It requires:
+   * 1) There is only one block who reads/writes the target buffer
+   * 2) There is only one buffer load/store of this buffer in the block
+   * \param block_rv The block operates on the target buffer.
+   * \param buffer_index The index of the buffer in block's read or write region.
+   * \param buffer_index_type The type of the buffer index, kRead or kWrite.
+   * \return The reindex stage block.
+   */
+  virtual BlockRV ReIndex(const BlockRV& block_rv, int buffer_index,
+                          BufferIndexType buffer_index_type) = 0;
+  /******** Schedule: Compute location ********/
+  /*!
+   * \brief Move a producer block under the specific loop, and regenerate the
+   * loops induced by the block so that the buffer region produced by the producer block could
+   * cover those regions consumed by its consumer blocks under the given loop. It requires:
+   * 1) `block` and `loop` are under the same scope, `loop` is not the ancestor of `block`
+   * 2) The scope block has stage-pipeline property
+   * 3) The subtree of the scope block, where the given block is in, satisfies the compact dataflow
+   * condition. i.e. all the blocks in the scope block's subtree must be either complete block or
+   * reduction block
+   * 4) The block is not an output block with regard to the scope block, i.e. the buffers written by
+   * the block are allocated under the scope block
+   * 5) All the consumers of the block are under the given loop
+   * \param block_rv The block to be moved
+   * \param loop_rv The loop where the block to be moved under
+   * \param preserve_unit_loops Whether to keep the trivial loops whose extents are 1
+   * \param index The block index of the loop body subtree blocks:
+   * - `index = -1` means inserted into the last possible insertion point;
+   * - `index = -2` means inserted into the first possible insertion point;
+   * - Otherwise, `index` is a nonnegative number that indicates the insertion point
+   */
+  virtual void ComputeAt(const BlockRV& block_rv, const LoopRV& loop_rv, bool preserve_unit_loops,
+                         int index = -1) = 0;
+  /*!
+   * \brief Move a consumer block under the specific loop, and regenerate the
+   * loops induced by the block so that the buffer region consumed by the consumer block could
+   * cover those regions produced by its producer blocks under the given loop. It requires:
+   * 1) `block` and `loop` are under the same scope, `loop` is not the ancestor of `block`
+   * 2) The scope block has stage-pipeline property
+   * 3) The subtree of the scope block, where the given block is in, satisfies the compact dataflow
+   * condition. i.e. all the blocks in the scope block's subtree must be either complete block or
+   * reduction block
+   * 4) All the producers of the block are under the given loop
+   *
+   * \param block_rv The block to be moved
+   * \param loop_rv The loop where the block to be moved under
+   * \param preserve_unit_loops Whether to keep the trivial loops whose extents are 1
+   * \param index The block index of the loop body subtree blocks:
+   * - `index = -1` means inserted into the last possible insertion point;
+   * - `index = -2` means inserted into the first possible insertion point;
+   * - Otherwise, `index` is a nonnegative number that indicates the insertion point
+   */
+  virtual void ReverseComputeAt(const BlockRV& block_rv, const LoopRV& loop_rv,
+                                bool preserve_unit_loops, int index = -1) = 0;
+  /*!
+   * \brief Inline a block into its consumer(s). It requires:
+   * 1) The block is a complete non-root block, which only produces one buffer
+   * 2) The block must not be the only leaf in the scope.
+   * 3) The body of the block must be a BufferStore statement in the form of,
+   *    A[i, j, k, ...] = ...
+   * where the indices of the LHS are all distinct atomic variables,
+   * and no variables other than those indexing variables are allowed in the statement.
+   * \param block The block to be inlined to its consumer(s)
+   */
+  virtual void ComputeInline(const BlockRV& block) = 0;
+  /*!
+   * \brief Inline a block into its only producer. It requires:
+   * 1) The block is a complete non-root block, which only produces and consumers one buffer
+   * 2) The block must not be the only leaf in the scope.
+   * 3) The only producer of the block is a read-after-write producer and a complete non-root block
+   * 4) The body of the block must be a BufferStore statement in the form of,
+   *    B[f(i, j, k, ...)] = g(i, j, k, A[i, j, k, ...] ...)
+   * where the indices of each `BufferLoad` on the RHS are all distinct atomic variables,
+   * and no variables other than those indexing variables are allowed in the statement.
+   * \param block The block to be inlined to its producer
+   */
+  virtual void ReverseComputeInline(const BlockRV& block) = 0;
+  /******** Schedule: Reduction ********/
+  /*!
+   * \brief Decompose a reduction block into two separate blocks.
+   * a) The init block, which is translated from the init statement of the reduction block;
+   * b) The update block, which is the original block without init statement.
+   *
+   * The init block is inserted right before the given loop.
+   *
+   * The schedule primitive requires:
+   * 1) The input block is a reduction block.
+   * 2) The input loop is the ancestor of the block.
+   * 3) The input loop is not lower than all the loops related to reduce block var.
+   * \param block_rv The reduction block to be decomposed
+   * \param loop_rv The loop above which the init block is inserted before.
+   * \return The init block
+   */
+  virtual BlockRV DecomposeReduction(const BlockRV& block_rv, const LoopRV& loop_rv) = 0;
+  /*!
+   * \brief Factorize an associative reduction block by the specified loop.
+   * \details An associative reduction cannot be parallelized directly,
+   * because it leads to potential race condition during accumulation.
+   * Alternatively, the reduction could be factorized on a loop with the following steps:
+   * - Step 1: evenly slice the reduction into `n` separate chunks, where `n` is the loop extent
+   * - Step 2: compute the chunks separately and write the result into `n` intermediate buffers;
+   * - Step 3: accumulate the `n` separate buffer into the result buffer.
+   * Note that the Step 2 above introduces opportunities for parallelization.
+   * RFactor is a schedule primitive that implements the transformation described above.
+   * \param loop_rv The loop outside block we want to do rfactor
+   * \param factor_axis The position where the new dimension is placed in the new introduced rfactor
+   *                    buffer. Suppose the original reduction block writes to buffer `B` with
+   *                    ndim(B) dimensions, then `factor_axis` should be in range `[-ndim(B) - 1,
+   *                    ndim(B)]`, and the negative index will be normalized to a non-negative one
+   * \return The rfactor block
+   */
+  virtual BlockRV RFactor(const LoopRV& loop_rv, int factor_axis) = 0;
+  /******** Schedule: Block annotation ********/
+  /*!
+   * \brief Set alignment requirement for specific dimension such that
+   *        stride[axis] == k * factor + offset for some k. This is useful to set memory layout for
+   *        more friendly memory access pattern. For example, we can set alignment to be factor=2,
+   *        offset=1 to avoid bank conflict for thread access on higher dimension in GPU shared
+   *        memory.
+   * \param block_rv The producer block of the buffer
+   * \param buffer_index The index of the buffer in block's write region
+   * \param axis The dimension to be specified for alignment
+   * \param factor The factor multiple of alignment
+   * \param offset The required offset factor
+   */
+  virtual void StorageAlign(const BlockRV& block_rv, int buffer_index, int axis, int factor,
+                            int offset) = 0;
+  /*!
+   * \brief Set the storage scope of a buffer, where the buffer is specified by the a block and a
+   * write-index
+   * \param block_rv The producer block of the buffer
+   * \param buffer_index The index of the buffer in block's write region
+   * \param storage_scope The storage scope to be set
+   */
+  virtual void SetScope(const BlockRV& block_rv, int buffer_index, const String& storage_scope) = 0;
+  /******** Schedule: Blockize & Tensorize ********/
+  /*!
+   * \brief Convert the subtree rooted at a specific loop into a block.
+   * \param loop_rv the root of the subtree
+   * \param preserve_unit_iters Whether or not to preserve unit iterators in block bindings
+   * \return the new block
+   */
+  virtual BlockRV Blockize(const LoopRV& loop_rv, bool preserve_unit_iters = true) = 0;
+  /*!
+   * \brief Tensorize the computation enclosed by loop with the tensor intrin.
+   * \param loop_rv The loop to be tensorized
+   * \param intrin Name of the tensor intrinsic
+   * \param preserve_unit_iters Whether or not to preserve unit iterators in block bindings
+   */
+  virtual void Tensorize(const LoopRV& loop_rv, const String& intrin,
+                         bool preserve_unit_iters = true) = 0;
+  /*!
+   * \brief Tensorize the computation enclosed by loop with the tensor intrin.
+   * \param block_rv The block to be tensorized
+   * \param intrin Name of the tensor intrinsic
+   * \param preserve_unit_iters Whether or not to preserve unit iterators in block bindings
+   */
+  virtual void Tensorize(const BlockRV& block_rv, const String& intrin,
+                         bool preserve_unit_iters = true) = 0;
+
+  /******** Schedule: Annotation ********/
+  /*!
+   * \brief Annotate a loop with a key value pair
+   * \param loop_rv The loop to be annotated
+   * \param ann_key The annotation key
+   * \param ann_val The annotation value, a string or a ExprRV
+   */
+  virtual void Annotate(const LoopRV& loop_rv, const String& ann_key, const ObjectRef& ann_val) = 0;
+  /*!
+   * \brief Annotate a block with a key value pair
+   * \param block_rv The block to be annotated
+   * \param ann_key The annotation key
+   * \param ann_val The annotation value, a string or a ExprRV
+   */
+  virtual void Annotate(const BlockRV& block_rv, const String& ann_key,
+                        const ObjectRef& ann_val) = 0;
+  /*!
+   * \brief Unannotate a loop's annotation with key ann_key
+   * \param loop_rv The loop to be unannotated
+   * \param ann_key The annotation key
+   */
+  virtual void Unannotate(const LoopRV& loop_rv, const String& ann_key) = 0;
+  /*!
+   * \brief Unannotate a block's annotation with key ann_key
+   * \param block_rv The block to be unannotated
+   * \param ann_key The annotation key
+   */
+  virtual void Unannotate(const BlockRV& block_rv, const String& ann_key) = 0;
+
+  /******** Schedule: Layout transformation ********/
+  /*!
+   * \brief Apply a transformation represented by IndexMap to buffer
+   * \details The indices and the access region to the target buffer is transformed by the given
+   * index_map. The index_map is used to infer the new shape of the buffer. Buffer must be either
+   * a function parameter, or allocated in a block (it cannot be a buffer subregion created via
+   * 'match_buffer').
+   * \param block_rv The block that accesses the target buffer.
+   * \param buffer_index The index of the buffer in block's read or write region.
+   * \param buffer_index_type The type of the buffer index, kRead or kWrite.
+   * \param index_map The transformation to apply.
+   *
+   * \param pad_value The value to write into padding introduced by
+   *    the transformation.  If the schedule contains a producer block
+   *    for the specified buffer, the pad value will be written as
+   *    part of the producer block if possible, or after the producer
+   *    block otherwise.  Otherwise, if the buffer is an input, will
+   *    insert an annotation block to state that the padding contains
+   *    the known value.
+   *
+   *    Note: If applied to an input buffer, the calling scope is
+   *    responsible for ensuring that the pad_value is present.
+   *    Algebraic symplifications, branch elimination, and other
+   *    optimizations may assume that this precondition is met, and
+   *    may result in incorrect results being returned.
+   */
+  virtual void TransformLayout(const BlockRV& block_rv, int buffer_index,
+                               BufferIndexType buffer_index_type, const IndexMap& index_map,
+                               const Optional<IndexMap>& pad_value = NullOpt) = 0;
+
+  /*!
+   * \brief Apply a transformation represented by IndexMap to block
+   * \details The block iters and the block body are transformed by the given index_map.
+   * Outer loops corresponding to each new block iter are regenerated.
+   * The index_map is required to be bijective affine since we need its inverse mapping.
+   * \param block_rv The block to be transformed
+   * \param index_map The transformation to apply.
+   */
+  virtual void TransformBlockLayout(const BlockRV& block_rv, const IndexMap& index_map) = 0;
+
+  /*!
+   * \brief Set the axis separator of a buffer, where the buffer is specified by a block and a read
+   * or write index
+   * \param block_rv The block that accesses the target buffer.
+   * \param buffer_index The index of the buffer in block's read or write region.
+   * \param buffer_index_type The type of the buffer index, kRead or kWrite.
+   * \param axis_separators The axis separator of the buffer
+   */
+  virtual void SetAxisSeparator(const BlockRV& block_rv, int buffer_index,
+                                BufferIndexType buffer_index_type,
+                                const Array<IntImm>& axis_separators) = 0;
+
+  /******** Schedule: Padding ********/
+  /*!
+   * \brief Decompose a padding block into a block filling const pad values and a block
+   * writing in-bound values.
+   * \param block_rv The block that match the padding pattern.
+   * \param loop_rv The loop above which the const filling block is inserted before.
+   * \return The const pad value filling block.
+   */
+  virtual BlockRV DecomposePadding(const BlockRV& block_rv, const LoopRV& loop_rv) = 0;
+
+  /*!
+   * \brief Pad the computation of Einsum.
+   * \param block_rv The block that matches the Einsum pattern.
+   * \param padding The padding for each block iter.
+   * \details This schedule primitives identifies the Einsum pattern in the block body, and find its
+   * producer blocks. It then pads the computation of the Einsum pattern and its producer blocks.
+   * The output buffer and the producer buffer is resized according to the padding size. It requires
+   * the output buffer and the producer buffer to be allocated inside the PrimFunc.
+   *
+   * The padding is a list of non-negative integers, each element corresponds to the padding for
+   * each block iter in the order of block iters. The block and its producer blocks should have
+   * trivial bindings, i.e. each block iter is bound to a single loop variable. After padding, the
+   * block iter extent and the corresponding outer loop is extended by the padding size.
+   *
+   * The size of the producer buffers are infered from the padding size of the Einsum computation.
+   * The producer buffers are padded by the initial value of the corresponding reduction.
+   */
+  virtual void PadEinsum(const BlockRV& block_rv, const Array<Integer>& padding) = 0;
+
+  /******** Schedule: Buffer transformation ********/
+  /*!
+   * \brief Compute the target buffer via rolling buffering.
+   * \details This primitive selects the outermost rollable axis with a positive bound overlap that
+   * appears in the block's ancestor loops as `rolling axis`, fold and circularize the buffer along
+   * the rolling dimension, append block predicate to avoid recomputing overlapping elements.
+   * It requires:
+   * 1) The buffer to be an intermediate buffer defined via `alloc_buffer`.
+   * 2) The LCA of the producer and consumer of the buffer is a for loop, typically,
+   *    the producer and consumer of the buffer are cascaded through compute_at.
+   * 3) The access region of the buffer has at least one dimension that contains
+   *    a positive bound overlap.
+   * \param block_rv The producer block of the buffer.
+   * \param write_buffer_index The index of the buffer in block's write region.
+   */
+  virtual void RollingBuffer(const BlockRV& block_rv, int write_buffer_index) = 0;
+
+  /******** Schedule: Misc ********/
+  /*! \brief A no-op that marks the start of postprocessing phase of scheduling */
+  virtual void EnterPostproc() = 0;
+};
+
+/*!
+ * \brief Managed reference to ScheduleNode
+ *
+ * A schedule is a set of transformations that change the order of computation but
+ * preserve the semantics of computation. Some example of schedules:
+ * 1) Split a loop into two;
+ * 2) Reorder two loops;
+ * 3) Inline the computation of a specific buffer into its consumer
+ *
+ * The schedule class stores auxiliary information to schedule correctly and efficiently.
+ *
+ * Link to tutorial: https://tvm.apache.org/docs/tutorials/language/schedule_primitives.html
+ *
+ * \sa ScheduleNode
+ */
+class Schedule : public runtime::ObjectRef {
+ public:
+  /*!
+   * \brief Construct a concrete TensorIR schedule from an IRModule
+   * \param mod The IRModule to be scheduled
+   * \param seed The seed value for schedule's random state
+   * \param debug_mask Do extra correctness checking after the class creation
+   * and each time after calling the Replace method.
+   * \param error_render_level The level of error rendering
+   * \return The concrete schedule created
+   * \sa ScheduleDebugMask
+   * \note The checks performed includes:
+   * 1) VerifySRefTree
+   * 2) VerifyCachedFlags
+   */
+  TVM_DLL static Schedule Concrete(IRModule mod, support::LinearCongruentialEngine::TRandState seed,
+                                   int debug_mask, ScheduleErrorRenderLevel error_render_level);
+  /*!
+   * \brief Construct a traced concrete TensorIR schedule from an IRModule
+   * \param mod The IRModule to be scheduled
+   * \param seed The seed value for schedule's random state
+   * \param debug_mask Do extra correctness checking after the class creation
+   * and each time after calling the Replace method.
+   * \param error_render_level The level of error rendering
+   * \return The concrete schedule created
+   * \sa ScheduleDebugMask
+   * \note The checks performed include:
+   * 1) VerifySRefTree
+   * 2) VerifyCachedFlags
+   */
+  TVM_DLL static Schedule Traced(IRModule mod, support::LinearCongruentialEngine::TRandState seed,
+                                 int debug_mask, ScheduleErrorRenderLevel error_render_level);
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(Schedule, runtime::ObjectRef, ScheduleNode);
+};
+
+}  // namespace tir
+}  // namespace tvm
+
+#endif  // TVM_TIR_SCHEDULE_SCHEDULE_H_
diff --git a/darknet_drp_ros/include/tvm/tir/schedule/state.h b/darknet_drp_ros/include/tvm/tir/schedule/state.h
new file mode 100644
index 0000000..201d78f
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/schedule/state.h
@@ -0,0 +1,209 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+/*!
+ * \file tvm/tir/schedule/state.h
+ * \brief This file defines ScheduleState, the core data structure of TensorIR scheduling.
+ */
+#ifndef TVM_TIR_SCHEDULE_STATE_H_
+#define TVM_TIR_SCHEDULE_STATE_H_
+
+#include <tvm/ir/module.h>
+#include <tvm/tir/function.h>
+#include <tvm/tir/schedule/block_scope.h>
+
+#include <unordered_map>
+#include <utility>
+
+namespace tvm {
+namespace tir {
+
+/*!
+ * \brief The information about a TensorIR block, it contains two categories of information
+ * 1) Info on the block scope rooted at a specific block, including dependency tracking,
+ * flags indicating if the scope is a stage pipeline, etc.
+ * 2) Info on the block itself, including if the block has a quasi-affine binding, if the regions it
+ * reads are completely covered by their producers, etc.
+ */
+struct BlockInfo {
+  /*! \brief Property of a block scope rooted at the block, storing dependencies in the scope */
+  BlockScope scope{nullptr};
+  // The properties below are information about the current block realization under its parent scope
+  /*! \brief Property of a block, indicating the block realization binding is quasi-affine */
+  bool affine_binding{false};
+  /*!
+   * \brief Property of a block, indicating each of the block's read regions is fully
+   * produced by its producers
+   */
+  bool region_cover{false};
+
+  BlockInfo() = default;
+
+  explicit BlockInfo(BlockScope scope, bool affine_binding = false, bool region_cover = false)
+      : scope(std::move(scope)),         //
+        affine_binding(affine_binding),  //
+        region_cover(region_cover) {}
+};
+
+/*!
+ * \brief The bitmask of the debug flag in the ScheduleStateNode.
+ * \sa ScheduleStateNode
+ */
+enum ScheduleDebugMask : uint32_t {
+  /*! \brief Verify the correctness of the sref tree */
+  kVerifySRefTree = 1,
+  /*! \brief Verify the correctness of affine_binding, region_cover and stage_pipeline */
+  kVerifyCachedFlags = 2,
+};
+
+/*!
+ * \brief The state of scheduling, which exposes a `Replace` method as
+ * the primary interface for all the scheduling primitives to manipulate the TensorIR.
+ *
+ * The data structure contains the following information
+ * 1) The AST being scheduled (mod)
+ * 2) The sref tree of schedulable statements (indicated by the srefs)
+ * 3) The dependency information of each block scope (block_info)
+ * 4) A reverse mapping from the AST nodes to that in the sref tree (stmt2ref)
+ * 5) A debug flag, if set, extra checking is enabled (debug_mask)
+ */
+class ScheduleStateNode : public Object {
+ public:
+  /*! \brief The AST of the module being scheduled */
+  IRModule mod;
+  /*!
+   * \brief Mapping from a block sref to its correpsonding BlockInfo,
+   * tracking the dependency inside the block scope,
+   * and storing necessary information flags for scheduling
+   */
+  std::unordered_map<StmtSRef, BlockInfo, ObjectPtrHash, ObjectPtrEqual> block_info;
+  /*! \brief The reverse mapping from block/for-loop to their corresponding srefs */
+  std::unordered_map<const StmtNode*, StmtSRef> stmt2ref;
+  /*!
+   * \brief Do extra correctness checking after the class creation
+   * and each time after calling the Replace method.
+   * \sa ScheduleDebugMask
+   */
+  int debug_mask;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("mod", &mod);
+    // `block_info` is not visited
+    // `stmt2ref` is not visited
+    v->Visit("debug_mask", &debug_mask);
+  }
+  /*!
+   * \brief Replace the part of the AST, as being pointed to by `src_sref`,
+   * with a specific statement `tgt_stmt`, and maintain the sref tree accordingly.
+   * Replace will try to perform copy on write as much as possible when the ScheduleState holds
+   * the only copy to the IRModule and IR nodes.
+   *
+   * Only 3 types of replacements are allowed: from `src_sref->stmt` to `tgt_stmt`.
+   * 1) Block -> Block
+   * 2) Loop -> Loop
+   * 3) Loop -> BlockRealize
+   *
+   * \param src_sref The sref to the statement to be replaced
+   * \param tgt_stmt The statement to be replaced in
+   * \param block_sref_reuse Maps an old block (to be replaced in the subtree under
+   * `src_sref->stmt`) to a new block (replaced to, in the subtree under `tgt_stmt`), and enforces
+   * reuse of srefs between them (rather than create new srefs) i.e. after being replaced, the sref
+   * that points to the old block will point to the new one
+   * \note The reuse of loop srefs are detected automatically according to the reuse of loop vars.
+   */
+  TVM_DLL void Replace(const tir::StmtSRef& src_sref, const Stmt& tgt_stmt,
+                       const Map<Block, Block>& block_sref_reuse);
+  /*!
+   * \brief Trigger the verification according to the `debug_mask` bitmask.
+   * 1) If the bitmask `kVerifySRefTree` is on, verify the correctness of the sref tree.
+   * 2) If the bitmask `kVerifyCachedFlags` is on, verify the correctness of `affine_binding`,
+   * `region_cover` and `stage_pipeline`
+   */
+  TVM_DLL void DebugVerify() const;
+
+  static constexpr const char* _type_key = "tir.ScheduleState";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ScheduleStateNode, Object);
+
+  /******** Property of blocks ********/
+  /*! \brief Returns the BlockInfo correpsonding to the block sref */
+  TVM_DLL BlockInfo GetBlockInfo(const StmtSRef& block_sref) const;
+  /*!
+   * \brief Recalculate the BlockInfo recursively under stmt.
+   * If stmt is a Block itself, we will not reset its affine binding flag unless it doesn't
+   * have block vars, since the affine flag depends on the outer scope of stmt.
+   */
+  TVM_DLL void UpdateScopeBlockInfo(const Stmt& stmt);
+  /*!
+   * \brief Get the BlockScope correpsonding to the sref of scope root block
+   * \param scope_root The block sref to be retrieved
+   * \return The corresponding BlockScope
+   */
+  BlockScope GetBlockScope(const StmtSRef& scope_root) const {
+    return GetBlockInfo(scope_root).scope;
+  }
+  /*!
+   * \brief Check a cached flag indicating if the specific block has quasi-affine bindings
+   * \param block_sref The block sref to be checked
+   * \return A boolean flag indicating if the block has quasi-affine bindings
+   */
+  bool IsAffineBlockBinding(const StmtSRef& block_sref) const {
+    return GetBlockInfo(block_sref).affine_binding;
+  }
+  /*!
+   * \brief Check a cached flag indicating if each of the specific consumer block's read region
+   * is fully produced by its producers
+   * \param consumer_block_sref The specific consumer block
+   * \return A boolean flag indicating if the block has quasi-affine bindings
+   */
+  bool IsRegionCoveredConsumer(const StmtSRef& consumer_block_sref) const {
+    return GetBlockInfo(consumer_block_sref).region_cover;
+  }
+  /*!
+   * \brief Check a cached flag indicating if a block scope is an equivalence of a stage pipeline
+   * \param scope_root The block sref to be retrieved
+   * \return The corresponding BlockScope
+   */
+  bool IsStagePipeline(const StmtSRef& scope_root) const {
+    return GetBlockScope(scope_root)->stage_pipeline;
+  }
+};
+
+/*!
+ * \brief Managed reference to ScheduleStateNode
+ * \sa ScheduleStateNode
+ */
+class ScheduleState : public ObjectRef {
+ public:
+  /*!
+   * \brief Construct a schedule state from an IRModule
+   * \param mod The IRModule to be scheduled
+   * \param debug_mask Do extra correctness checking after the class creation
+   * and each time after calling the Replace method.
+   */
+  TVM_DLL explicit ScheduleState(IRModule mod, int debug_mask = 0);
+
+  /*! \return The mutable pointer to the ScheduleStateNode */
+  ScheduleStateNode* get() const { return static_cast<ScheduleStateNode*>(data_.get()); }
+
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(ScheduleState, ObjectRef, ScheduleStateNode);
+};
+
+}  // namespace tir
+}  // namespace tvm
+
+#endif  // TVM_TIR_SCHEDULE_STATE_H_
diff --git a/darknet_drp_ros/include/tvm/tir/schedule/trace.h b/darknet_drp_ros/include/tvm/tir/schedule/trace.h
new file mode 100644
index 0000000..b6b3b57
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/schedule/trace.h
@@ -0,0 +1,164 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+#ifndef TVM_TIR_SCHEDULE_TRACE_H_
+#define TVM_TIR_SCHEDULE_TRACE_H_
+
+#include <tvm/tir/schedule/instruction.h>
+
+namespace tvm {
+namespace tir {
+
+// Forward declaration
+class Trace;
+
+/*!
+ * \brief A callback that allows users to mutate decisions on the fly
+ * when applying instructions. The signature of the callback is:
+ * \param inst The instruction
+ * \param inputs The input random variables
+ * \param attrs The attributes
+ * \param decision The original decision
+ * \return A new decision
+ */
+using FTraceDecisionProvider = runtime::TypedPackedFunc<ObjectRef(
+    const Instruction& inst, const Array<ObjectRef>& inputs, const Array<ObjectRef>& attrs,
+    const Optional<ObjectRef>& decision)>;
+
+/*!
+ * \brief An execution trace of a scheduling program
+ *
+ * A trace has two parts:
+ * 1) The instructions invoked so far in the program execution
+ * 2) The random decisions made upon those instructions, if any
+ *
+ * A trace can be serialized to:
+ * 1) Roundtrippable JSON format: can be saved to file and loaded back
+ * 2) Python syntax: allows users to copy-paste the trace to reproduce the scheduling process
+ *
+ * A trace can be applied to a TensorIR schedule by re-applying all its instructions possibly with
+ * their decisions accordingly. Re-sampling is invoked if a sampling instruction doesn't have its
+ * corresponding decision; Otherwise the existing decision will be reused accordingly.
+ */
+class TraceNode : public runtime::Object {
+ public:
+  /*! \brief The instructions invoked so far in the program execution */
+  Array<Instruction> insts;
+  /*! \brief The random decisions made upon those instructions */
+  Map<Instruction, ObjectRef> decisions;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("insts", &insts);
+    v->Visit("decisions", &decisions);
+  }
+
+  static constexpr const char* _type_key = "tir.Trace";
+  TVM_DECLARE_FINAL_OBJECT_INFO(TraceNode, runtime::Object);
+
+ public:
+  /*!
+   * \brief Retrieve the decision made on a specific instruction
+   * \param inst The instruction whose decision is to be retrieved
+   * \return The corresponding decision; NullOpt if there is no decision made on the instruction
+   */
+  Optional<ObjectRef> GetDecision(const Instruction& inst) const;
+  /*!
+   * \brief Append a new instruction to the trace
+   * \param inst The new instruction to be appended
+   */
+  void Append(Instruction inst);
+  /*!
+   * \brief Append a new instruction with a random decision to the trace
+   * \param inst The new instruction to be appended
+   * \param decision The random decision made on this instruction
+   * The type of `decision` depends on the instruction, e.g.
+   * the decision of `SamplePerfectTile` has type `Array<IntImm>`
+   */
+  void Append(Instruction inst, ObjectRef decision);
+  /*!
+   * \brief Remove the last instruction, along with the decision made on that instruction, if any
+   * \return The instruction removed; NullOpt if the trace is empty
+   */
+  Optional<Instruction> Pop();
+  /*!
+   * \brief Apply the trace to a TensorIR schedule
+   * \param sch The schedule to be applied onto
+   * \param remove_postproc If postprocessing instructions are removed
+   * \param decision_provider A callback that allows users to mutate decisions on the fly
+   * when applying instructions.
+   * \sa FTraceDecisionProvider
+   */
+  void ApplyToSchedule(Schedule sch, bool remove_postproc,
+                       FTraceDecisionProvider decision_provider = nullptr) const;
+  /*!
+   * \brief Serialize the trace as a JSON-style object
+   * \param remove_postproc If postprocessing instructions are removed
+   * \return The JSON-style object
+   */
+  ObjectRef AsJSON(bool remove_postproc) const;
+  /*!
+   * \brief Serialize the trace as a sequence of python statements
+   * \param remove_postproc If postprocessing instructions are removed
+   * \return A sequence of python statements
+   */
+  Array<String> AsPython(bool remove_postproc) const;
+  /*!
+   * \brief Create a new trace with an instruction whose decision is changed,
+   * assuming this instruction exists in the resulting trace
+   * \param inst The instruction whose decision is to be changed
+   * \param decision The decision to be changed to
+   * \param remove_postproc If postprocessing instructions are removed
+   * \return The new trace with the decision changed
+   */
+  Trace WithDecision(Instruction inst, ObjectRef decision, bool remove_postproc) const;
+  /*!
+   * \brief Simplify the trace with dead-code elimination
+   * \param remove_postproc If postprocessing instructions are removed
+   * \return A simplified trace
+   */
+  Trace Simplified(bool remove_postproc) const;
+};
+
+/*!
+ * \brief Managed reference to TraceNode
+ * \sa TraceNode
+ */
+class Trace : public runtime::ObjectRef {
+ public:
+  /*! \brief Default constructor. Creating an empty trace. */
+  Trace();
+  /*!
+   * \brief Constructor. Creating a trace from existing instructions and their decisions
+   * \param insts The instructions used
+   * \param decisions The decisions made in sampling
+   */
+  explicit Trace(Array<Instruction> insts, Map<Instruction, ObjectRef> decisions);
+  /*!
+   * \brief Apply a JSON-serialized trace to a TensorIR schedule
+   * \param json The JSON-serialized trace
+   * \param sch The TensorIR schedule
+   */
+  static void ApplyJSONToSchedule(ObjectRef json, Schedule sch);
+
+  TVM_DEFINE_MUTABLE_NOTNULLABLE_OBJECT_REF_METHODS(Trace, runtime::ObjectRef, TraceNode);
+};
+
+}  // namespace tir
+}  // namespace tvm
+
+#endif  // TVM_TIR_SCHEDULE_TRACE_H_
diff --git a/darknet_drp_ros/include/tvm/tir/stmt.h b/darknet_drp_ros/include/tvm/tir/stmt.h
new file mode 100644
index 0000000..dc257b1
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/stmt.h
@@ -0,0 +1,1656 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+/*!
+ * \file tvm/tir/stmt.h
+ * \brief TIR statements.
+ */
+// Acknowledgement: Many low-level stmts originate from Halide.
+#ifndef TVM_TIR_STMT_H_
+#define TVM_TIR_STMT_H_
+
+#include <tvm/tir/expr.h>
+
+#include <string>
+#include <type_traits>
+#include <utility>
+#include <vector>
+
+namespace tvm {
+namespace tir {
+
+/*! \brief Base node of all statements. */
+class StmtNode : public Object {
+ public:
+  /*!
+   * \brief Span that points to the original source code.
+   *        Reserved debug information.
+   */
+  mutable Span span;
+
+  StmtNode() = default;
+  explicit StmtNode(Span span) : span(span) {}
+
+  static constexpr const char* _type_key = "tir.Stmt";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  static constexpr const uint32_t _type_child_slots = 15;
+  TVM_DECLARE_BASE_OBJECT_INFO(StmtNode, Object);
+};
+
+/*! \brief Container of all statements */
+class Stmt : public ObjectRef {
+ public:
+  TVM_DEFINE_OBJECT_REF_METHODS(Stmt, ObjectRef, StmtNode);
+};
+
+/*!
+ * \brief Let binding, bind var to value, then run body.
+ */
+class LetStmtNode : public StmtNode {
+ public:
+  /*! \brief The variable. */
+  Var var;
+  /*! \brief The value to be binded. */
+  PrimExpr value;
+  /*! \brief The body block. */
+  Stmt body;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("var", &var);
+    v->Visit("value", &value);
+    v->Visit("body", &body);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const LetStmtNode* other, SEqualReducer equal) const {
+    return equal.DefEqual(var, other->var) && equal(value, other->value) &&
+           equal(body, other->body);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce.DefHash(var);
+    hash_reduce(value);
+    hash_reduce(body);
+  }
+
+  static constexpr const char* _type_key = "tir.LetStmt";
+  TVM_DECLARE_FINAL_OBJECT_INFO(LetStmtNode, StmtNode);
+};
+
+/*!
+ * \brief Managed reference to LetStmtNode.
+ * \sa LetStmtNode
+ */
+class LetStmt : public Stmt {
+ public:
+  TVM_DLL LetStmt(Var var, PrimExpr value, Stmt body, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(LetStmt, Stmt, LetStmtNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(LetStmtNode);
+};
+
+/*!
+ * \brief Define certain auxiliary attribute for the body to be a symbolic value.
+ *  This provide auxiliary information for IR passes that transforms body.
+ *
+ *  In terms of effect, this is equivalent to Block(Evaluate(value), body).
+ *
+ *  Examples of possible usage:
+ *    - Bound of function, variables.
+ *    - Hint which block corresponds to a parallel region.
+ */
+class AttrStmtNode : public StmtNode {
+ public:
+  /*! \brief this is attribute about certain node */
+  ObjectRef node;
+  /*! \brief the type key of the attribute */
+  String attr_key;
+  /*! \brief The attribute value, value is well defined at current scope. */
+  PrimExpr value;
+  /*! \brief The body statement to be executed */
+  Stmt body;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("node", &node);
+    v->Visit("attr_key", &attr_key);
+    v->Visit("value", &value);
+    v->Visit("body", &body);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const AttrStmtNode* other, SEqualReducer equal) const {
+    return equal(node, other->node) && equal(attr_key, other->attr_key) &&
+           equal(value, other->value) && equal(body, other->body);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(node);
+    hash_reduce(attr_key);
+    hash_reduce(value);
+    hash_reduce(body);
+  }
+
+  static constexpr const char* _type_key = "tir.AttrStmt";
+  TVM_DECLARE_FINAL_OBJECT_INFO(AttrStmtNode, StmtNode);
+};
+
+/*!
+ * \brief Managed reference to AttrStmtNode.
+ * \sa AttrStmtNode
+ */
+class AttrStmt : public Stmt {
+ public:
+  TVM_DLL AttrStmt(ObjectRef node, String attr_key, PrimExpr value, Stmt body, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(AttrStmt, Stmt, AttrStmtNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(AttrStmtNode);
+};
+
+/*!
+ * \brief Assert condition, if an error occurs, return the error message.
+ */
+class AssertStmtNode : public StmtNode {
+ public:
+  /*! \brief Condition to be checked. */
+  PrimExpr condition;
+  /*! \brief Error message when assertion failed. */
+  PrimExpr message;
+  /*!
+   * \brief Body which this assertion holds true.
+   *  Will be executed after the assertion.
+   */
+  Stmt body;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("condition", &condition);
+    v->Visit("message", &message);
+    v->Visit("body", &body);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const AssertStmtNode* other, SEqualReducer equal) const {
+    return equal(condition, other->condition) && equal(message, other->message) &&
+           equal(body, other->body);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(condition);
+    hash_reduce(message);
+    hash_reduce(body);
+  }
+
+  static constexpr const char* _type_key = "tir.AssertStmt";
+  TVM_DECLARE_FINAL_OBJECT_INFO(AssertStmtNode, StmtNode);
+};
+
+/*!
+ * \brief Managed reference to AssertStmtNode.
+ * \sa AssertStmtNode
+ */
+class AssertStmt : public Stmt {
+ public:
+  TVM_DLL AssertStmt(PrimExpr condition, PrimExpr message, Stmt body, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(AssertStmt, Stmt, AssertStmtNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(AssertStmtNode);
+};
+
+/*!
+ * \brief Store value to the buffer.
+ *
+ *  Equivalent to ((DType*)buffer_var)[index] = value.
+ *  where DType is the type specified by type().element_of().
+ *
+ *  For example, if type = float32x3, then the store will corresponds to
+ *
+ * \code
+ *
+ *  auto buffer = static_cast<float*>(buffer_var);
+ *  buffer[index.v0] = value.v0;
+ *  buffer[index.v1] = value.v1;
+ *  buffer[index.v2] = value.v2;
+ *
+ * \endcode
+ * \sa LoadNode
+ */
+class StoreNode : public StmtNode {
+ public:
+  /*! \brief The buffer variable. */
+  Var buffer_var;
+  /*! \brief The value to be stored. */
+  PrimExpr value;
+  /*! \brief The index locations to be stored. */
+  PrimExpr index;
+  /*! \brief The predicate to mask which lanes would be stored. */
+  PrimExpr predicate;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("buffer_var", &buffer_var);
+    v->Visit("value", &value);
+    v->Visit("index", &index);
+    v->Visit("predicate", &predicate);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const StoreNode* other, SEqualReducer equal) const {
+    return equal(buffer_var, other->buffer_var) && equal(value, other->value) &&
+           equal(index, other->index) && equal(predicate, other->predicate);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(buffer_var);
+    hash_reduce(value);
+    hash_reduce(index);
+    hash_reduce(predicate);
+  }
+
+  static constexpr const char* _type_key = "tir.Store";
+  TVM_DECLARE_FINAL_OBJECT_INFO(StoreNode, StmtNode);
+};
+
+/*!
+ * \brief Managed reference to StoreNode.
+ * \sa StoreNode
+ */
+class Store : public Stmt {
+ public:
+  TVM_DLL Store(Var buffer_var, PrimExpr value, PrimExpr index, PrimExpr predicate,
+                Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Store, Stmt, StoreNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(StoreNode);
+};
+
+/*!
+ * \brief Store value to the high dimension buffer.
+ *
+ * \code
+ *
+ *  buffer[i, j] = value;
+ *
+ * \endcode
+ * \sa BufferLoad
+ */
+class BufferStoreNode : public StmtNode {
+ public:
+  /*! \brief The buffer variable. */
+  Buffer buffer;
+  /*! \brief The value to be stored. */
+  PrimExpr value;
+  /*! \brief The indices location to be stored. */
+  Array<PrimExpr> indices;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("buffer", &buffer);
+    v->Visit("value", &value);
+    v->Visit("indices", &indices);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const BufferStoreNode* other, SEqualReducer equal) const {
+    return equal(buffer, other->buffer) && equal(value, other->value) &&
+           equal(indices, other->indices);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(buffer);
+    hash_reduce(value);
+    hash_reduce(indices);
+  }
+
+  static constexpr const char* _type_key = "tir.BufferStore";
+  TVM_DECLARE_FINAL_OBJECT_INFO(BufferStoreNode, StmtNode);
+};
+
+/*!
+ * \brief Managed reference to BufferStoreNode.
+ * \sa BufferStoreNode
+ */
+class BufferStore : public Stmt {
+ public:
+  TVM_DLL explicit BufferStore(Buffer buffer, PrimExpr value, Array<PrimExpr> indices,
+                               Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(BufferStore, Stmt, BufferStoreNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(BufferStoreNode);
+};
+
+/*!
+ * \brief Annotate the region where the buffer need to
+ *  be read and write in the body.
+ *  We only need to allocate the space for the corresponding region.
+ *
+ * \note There should be at most one BufferRealize for each buffer.
+ *       BufferRealize is not necessary for external buffers,
+ *       since they are assumed to be fully allocated.
+ *
+ * \sa BufferLoad, BufferStore
+ */
+class BufferRealizeNode : public StmtNode {
+ public:
+  /*! \brief The buffer variable. */
+  Buffer buffer;
+  /*! \brief Bounds to be realized */
+  Array<Range> bounds;
+  /*! \brief Only realize if condition holds. */
+  PrimExpr condition;
+  /*! \brief The body of realization. */
+  Stmt body;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("buffer", &buffer);
+    v->Visit("bounds", &bounds);
+    v->Visit("condition", &condition);
+    v->Visit("body", &body);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const BufferRealizeNode* other, SEqualReducer equal) const {
+    return equal(buffer, other->buffer) && equal(bounds, other->bounds) &&
+           equal(condition, other->condition) && equal(body, other->body);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(buffer);
+    hash_reduce(bounds);
+    hash_reduce(condition);
+    hash_reduce(body);
+  }
+
+  BufferRealizeNode() = default;
+  BufferRealizeNode(Buffer buffer, Array<Range> bounds, PrimExpr condition, Stmt body,
+                    Span span = Span())
+      : StmtNode(span), buffer(buffer), bounds(bounds), condition(condition), body(body) {}
+
+  static constexpr const char* _type_key = "tir.BufferRealize";
+  TVM_DECLARE_FINAL_OBJECT_INFO(BufferRealizeNode, StmtNode);
+};
+
+/*!
+ * \brief Managed reference to BufferRealizeNode.
+ * \sa BufferRealizeNode
+ */
+class BufferRealize : public Stmt {
+ public:
+  TVM_DLL explicit BufferRealize(Buffer buffer, Array<Range> bounds, PrimExpr condition, Stmt body,
+                                 Span span = Span());
+
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(BufferRealize, Stmt, BufferRealizeNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(BufferRealizeNode);
+};
+
+/*!
+ * \brief Store value into mult-dimensional array that will be read by the consumer
+ *        of the producer.
+ *
+ * \note This node only appears in high-level DSLs that are built on top of the TIR.
+ *       It should not appear in a valid TIR PrimFunc. A high-level DSL needs to lower
+ *       this node before TIR transformations.
+ *
+ * \sa DataProducer
+ */
+class ProducerStoreNode : public StmtNode {
+ public:
+  /*! \brief The producer to store the results into. */
+  DataProducer producer;
+  /*! \brief The value to be stored. */
+  PrimExpr value;
+  /*! \brief The index arguments of the function. */
+  Array<PrimExpr> indices;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("producer", &producer);
+    v->Visit("value", &value);
+    v->Visit("indices", &indices);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const ProducerStoreNode* other, SEqualReducer equal) const {
+    return equal(producer, other->producer) && equal(value, other->value) &&
+           equal(indices, other->indices);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(producer);
+    hash_reduce(value);
+    hash_reduce(indices);
+  }
+
+  static constexpr const char* _type_key = "tir.ProducerStore";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ProducerStoreNode, StmtNode);
+};
+
+/*!
+ * \brief Managed reference to ProducerStoreNode.
+ * \sa ProducerStoreNode
+ */
+class ProducerStore : public Stmt {
+ public:
+  TVM_DLL ProducerStore(DataProducer producer, PrimExpr value, Array<PrimExpr> indices,
+                        Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(ProducerStore, Stmt, ProducerStoreNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(ProducerStoreNode);
+};
+
+/*!
+ * \brief Annotate the bounds where the data produced by the producer
+ *  need to be written and read in body.
+ *  We will need to allocate space for the corresponding regions.
+ *
+ * \note This node only appears in high-level DSLs that are built on top of the TIR.
+ *       It should not appear in a valid TIR PrimFunc. A high-level DSL needs to lower
+ *       this node before TIR transformations.
+ *
+ * \sa DataProducer
+ */
+class ProducerRealizeNode : public StmtNode {
+ public:
+  /*! \brief The producer that produces the data. */
+  DataProducer producer;
+  /*! \brief Bounds to be realized. */
+  Region bounds;
+  /*! \brief Only realize if condition holds. */
+  PrimExpr condition;
+  /*! \brief The body of realization. */
+  Stmt body;
+  /*! \brief The storage scope associated with this realization. */
+  String storage_scope;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("producer", &producer);
+    v->Visit("bounds", &bounds);
+    v->Visit("condition", &condition);
+    v->Visit("body", &body);
+    v->Visit("storage_scope", &storage_scope);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const ProducerRealizeNode* other, SEqualReducer equal) const {
+    return equal(producer, other->producer) && equal(bounds, other->bounds) &&
+           equal(condition, other->condition) && equal(body, other->body) &&
+           equal(storage_scope, other->storage_scope);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(producer);
+    hash_reduce(bounds);
+    hash_reduce(condition);
+    hash_reduce(body);
+    hash_reduce(storage_scope);
+  }
+
+  static constexpr const char* _type_key = "tir.ProducerRealize";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ProducerRealizeNode, StmtNode);
+};
+
+/*!
+ * \brief Managed reference to ProducerRealizeNode.
+ * \sa ProducerRealizeNode
+ */
+class ProducerRealize : public Stmt {
+ public:
+  TVM_DLL ProducerRealize(DataProducer producer, Region bounds, PrimExpr condition, Stmt body,
+                          String storage_scope = "", Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(ProducerRealize, Stmt, ProducerRealizeNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(ProducerRealizeNode);
+};
+
+/*!
+ * \brief Allocate a buffer that can be used in body.
+ */
+class AllocateNode : public StmtNode {
+ public:
+  /*! \brief The buffer variable. */
+  Var buffer_var;
+  /*! \brief The type of the buffer. */
+  DataType dtype;
+  /*! \brief The extents of the buffer. */
+  Array<PrimExpr> extents;
+  /*! \brief Only allocate buffer when condition is satisfied. */
+  PrimExpr condition;
+  /*! \brief The body to be executed. */
+  Stmt body;
+  /*!
+   * \brief Additional annotations about the allocation.
+   *
+   *  These annotations can be used as auxiliary hint
+   *  to future transformations.
+   */
+  Map<String, ObjectRef> annotations;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("buffer_var", &buffer_var);
+    v->Visit("dtype", &dtype);
+    v->Visit("extents", &extents);
+    v->Visit("condition", &condition);
+    v->Visit("body", &body);
+    v->Visit("annotations", &annotations);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const AllocateNode* other, SEqualReducer equal) const {
+    return equal.DefEqual(buffer_var, other->buffer_var) && equal(dtype, other->dtype) &&
+           equal(extents, other->extents) && equal(condition, other->condition) &&
+           equal(body, other->body) && equal(annotations, other->annotations);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce.DefHash(buffer_var);
+    hash_reduce(dtype);
+    hash_reduce(extents);
+    hash_reduce(condition);
+    hash_reduce(body);
+    hash_reduce(annotations);
+  }
+
+  /*!
+   * \brief If the buffer size is constant, return the size.
+   *        Otherwise return 0.
+   * \return The result.
+   */
+  int64_t ConstantAllocationSize() const { return ConstantAllocationSize(extents); }
+  /*!
+   * \brief If the buffer size is constant, return the size.
+   *        Otherwise return 0.
+   * \param extents The extents of the buffer.
+   * \return The result.
+   */
+  TVM_DLL static int64_t ConstantAllocationSize(const Array<PrimExpr>& extents);
+
+  static constexpr const char* _type_key = "tir.Allocate";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_FINAL_OBJECT_INFO(AllocateNode, StmtNode);
+};
+
+/*!
+ * \brief Managed reference to AllocateNode.
+ * \sa AllocateNode
+ */
+class Allocate : public Stmt {
+ public:
+  TVM_DLL Allocate(Var buffer_var, DataType dtype, Array<PrimExpr> extents, PrimExpr condition,
+                   Stmt body, Map<String, ObjectRef> annotations = Map<String, ObjectRef>(),
+                   Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Allocate, Stmt, AllocateNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(AllocateNode);
+};
+
+/*!
+ * \brief Allocate a buffer that can be used in body.
+ */
+class AllocateConstNode : public StmtNode {
+ public:
+  /*! \brief The buffer variable. */
+  Var buffer_var;
+  /*! \brief The optional data associated to the constant.
+   */
+  Optional<runtime::NDArray> data;
+  /*!
+   * \brief If the PrimFunc containing the Stmt is added to IRModule, this is an optional index
+   * to indicate the index within "constants" attribute, that is a Array<NDArray> of IRModule.
+   */
+  Optional<Integer> irmod_storage_idx;
+  /*! \brief The type of the buffer. */
+  DataType dtype;
+  /*! \brief The extents of the buffer. */
+  Array<PrimExpr> extents;
+  /*! \brief The body to be executed. */
+  Stmt body;
+  /*!
+   * \brief Additional annotations about the allocation.
+   *
+   *  These annotations can be used as auxiliary hint
+   *  to future transformations.
+   */
+  Map<String, ObjectRef> annotations;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("buffer_var", &buffer_var);
+    v->Visit("data", &data);
+    v->Visit("irmod_storage_idx", &irmod_storage_idx);
+    v->Visit("dtype", &dtype);
+    v->Visit("extents", &extents);
+    v->Visit("body", &body);
+    v->Visit("annotations", &annotations);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const AllocateConstNode* other, SEqualReducer equal) const {
+    return equal.DefEqual(buffer_var, other->buffer_var) && equal(dtype, other->dtype) &&
+           equal(extents, other->extents) && equal(data, other->data) && equal(body, other->body) &&
+           equal(annotations, other->annotations);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce.DefHash(buffer_var);
+    hash_reduce(dtype);
+    hash_reduce(extents);
+    hash_reduce(body);
+    hash_reduce(annotations);
+    hash_reduce(data);
+  }
+
+  /*!
+   * \brief If the buffer size is constant, return the size.
+   *        Otherwise return 0.
+   * \return The result.
+   */
+  int64_t ConstantAllocationSize() const { return ConstantAllocationSize(extents); }
+  /*!
+   * \brief If the buffer size is constant, return the size.
+   *        Otherwise return 0.
+   * \param extents The extents of the buffer.
+   * \return The result.
+   */
+  TVM_DLL static int64_t ConstantAllocationSize(const Array<PrimExpr>& extents);
+
+  static constexpr const char* _type_key = "tir.AllocateConst";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_FINAL_OBJECT_INFO(AllocateConstNode, StmtNode);
+};
+
+/*!
+ * \brief Managed reference to AllocateConstNode.
+ * \sa AllocateConstNode
+ */
+class AllocateConst : public Stmt {
+ public:
+  /* The constructor to create a IRNode with constant data
+   * depending on the type of ObjectRef, it will either
+   * create AllocateConstNode with irmod_storage_idx or data
+   */
+  TVM_DLL AllocateConst(Var buffer_var, DataType dtype, Array<PrimExpr> extents,
+                        ObjectRef data_or_idx, Stmt body,
+                        Map<String, ObjectRef> annotations = Map<String, ObjectRef>(),
+                        Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(AllocateConst, Stmt, AllocateConstNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(AllocateConstNode);
+};
+
+/*! \brief Declare a buffer that can be used in the body */
+class DeclBufferNode : public StmtNode {
+ public:
+  /*! \brief The buffer being declared */
+  Buffer buffer;
+  /*! \brief The body to be executed */
+  Stmt body;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("buffer", &buffer);
+    v->Visit("body", &body);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const DeclBufferNode* other, SEqualReducer equal) const {
+    return equal(buffer, other->buffer) && equal(body, other->body);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(buffer);
+    hash_reduce(body);
+  }
+
+  static constexpr const char* _type_key = "tir.DeclBuffer";
+  TVM_DECLARE_FINAL_OBJECT_INFO(DeclBufferNode, StmtNode);
+};
+
+/*! \brief Managed reference to DeclBufferNode */
+class DeclBuffer : public Stmt {
+ public:
+  TVM_DLL DeclBuffer(Buffer buffer, Stmt body, Span span = Span());
+  TVM_DEFINE_OBJECT_REF_METHODS(DeclBuffer, Stmt, DeclBufferNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(DeclBufferNode);
+};
+
+/*!
+ * \brief The container of seq statement.
+ *        Represent a sequence of statements.
+ */
+class SeqStmtNode : public StmtNode {
+ public:
+  /*! \brief internal sequence content. */
+  Array<Stmt> seq;
+
+  /*! \return get the size of the sequence */
+  size_t size() const { return seq.size(); }
+  /*!
+   * \brief Get the index-th element in the sequence.
+   */
+  Stmt operator[](size_t index) const { return seq[index]; }
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("seq", &seq);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const SeqStmtNode* other, SEqualReducer equal) const {
+    return equal(seq, other->seq);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const { hash_reduce(seq); }
+
+  static constexpr const char* _type_key = "tir.SeqStmt";
+  TVM_DECLARE_FINAL_OBJECT_INFO(SeqStmtNode, StmtNode);
+};
+
+/*! \brief Sequence statement. */
+class SeqStmt : public Stmt {
+ public:
+  /*!
+   * \brief Construct SeqStmt.
+   * \param seq The sequence.
+   * \param span The location of this object in the source code.
+   */
+  TVM_DLL explicit SeqStmt(Array<Stmt> seq, Span span = Span());
+
+  /*! \return get the size of the sequence */
+  size_t size() const { return operator->()->size(); }
+  /*!
+   * \brief Get the index-th element in the sequence.
+   */
+  Stmt operator[](size_t index) const { return (*(operator->()))[index]; }
+  /*!
+   * \brief Construct a sequence statement by flattening
+   *        all the arrays and sequences in the arguments
+   *        recursively.
+   *
+   * - When an argument is nullptr, it will be ignored.
+   * - When an argument is an array or a SeqStmt, it will be flattened recursively.
+   * - A normal Stmt will be appended to the end of the sequence.
+   *
+   * \note This function can directly return an element
+   *       if it is the only element in the sequence.
+   *
+   * \param seq_args The list of arguments to be flattened.
+   * \tparam Args arguments
+   * \return The constructed statement
+   */
+  template <typename... Args>
+  static Stmt Flatten(Args&&... seq_args) {
+    Array<Stmt> seq;
+    runtime::detail::for_each(Flattener(&seq), std::forward<Args>(seq_args)...);
+    if (seq.size() == 1) return seq[0];
+    return SeqStmt(seq);
+  }
+  /*! \brief Helper class to flatten sequence of arguments into Array. */
+  class Flattener {
+   public:
+    explicit Flattener(Array<Stmt>* seq) : seq_(seq) {}
+
+    void operator()(size_t i, const Stmt& stmt) const {
+      if (!stmt.defined()) return;
+      if (auto* op = stmt.as<SeqStmtNode>()) {
+        operator()(0, op->seq);
+      } else {
+        seq_->push_back(stmt);
+      }
+    }
+
+    template <typename T>
+    void operator()(size_t i, const T& seq) const {
+      for (auto v : seq) {
+        this->operator()(0, v);
+      }
+    }
+
+   private:
+    Array<Stmt>* seq_;
+  };
+
+  TVM_DEFINE_OBJECT_REF_METHODS(SeqStmt, Stmt, SeqStmtNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(SeqStmtNode);
+};
+
+/*!
+ * \brief IfThenElse statment.
+ */
+class IfThenElseNode : public StmtNode {
+ public:
+  /*! \brief The condition. */
+  PrimExpr condition;
+  /*! \brief The branch to be executed when condition is true. */
+  Stmt then_case;
+  /*! \brief The branch to be executed when condition is false, can be null. */
+  Optional<Stmt> else_case;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("condition", &condition);
+    v->Visit("then_case", &then_case);
+    v->Visit("else_case", &else_case);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const IfThenElseNode* other, SEqualReducer equal) const {
+    return equal(condition, other->condition) && equal(then_case, other->then_case) &&
+           equal(else_case, other->else_case);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(condition);
+    hash_reduce(then_case);
+    hash_reduce(else_case);
+  }
+
+  static constexpr const char* _type_key = "tir.IfThenElse";
+  TVM_DECLARE_FINAL_OBJECT_INFO(IfThenElseNode, StmtNode);
+};
+
+/*!
+ * \brief Managed reference to IfThenElseNode.
+ * \sa IfThenElseNode
+ */
+class IfThenElse : public Stmt {
+ public:
+  TVM_DLL IfThenElse(PrimExpr condition, Stmt then_case, Optional<Stmt> else_case = NullOpt,
+                     Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(IfThenElse, Stmt, IfThenElseNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(IfThenElseNode);
+};
+
+/*!
+ * \brief Evaluates an expression.
+ *  This is mostly used for putting a Call node into Stmt.
+ *
+ *  If value do not have side-effect, this node can be safely removed.
+ */
+class EvaluateNode : public StmtNode {
+ public:
+  /*! \brief The expression to be evaluated. */
+  PrimExpr value;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("value", &value);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const EvaluateNode* other, SEqualReducer equal) const {
+    return equal(value, other->value);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const { hash_reduce(value); }
+
+  static constexpr const char* _type_key = "tir.Evaluate";
+  TVM_DECLARE_FINAL_OBJECT_INFO(EvaluateNode, StmtNode);
+};
+
+/*!
+ * \brief Managed reference to EvaluateNode.
+ * \sa EvaluateNode
+ */
+class Evaluate : public Stmt {
+ public:
+  TVM_DLL explicit Evaluate(PrimExpr value, Span span = Span());
+
+  explicit Evaluate(int value, Span span = Span()) : Evaluate(PrimExpr(value), span) {}
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Evaluate, Stmt, EvaluateNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(EvaluateNode);
+};
+
+/*!
+ * \brief The kind of the loop.
+ *
+ *  ForKind can change the control flow semantics
+ *  of the loop. So the kind field needs to be considered
+ *  in all TIR passes.
+ */
+enum class ForKind : int {
+  /*! \brief default semantics -- serial execution. */
+  kSerial = 0,
+  /*! \brief Parallel execution on CPU. */
+  kParallel = 1,
+  /*!
+   * \brief Vector SIMD loop.
+   *  The loop body will be vectorized.
+   */
+  kVectorized = 2,
+  /*! \brief The loop body must be unrolled. */
+  kUnrolled = 3,
+  /*!
+   * \brief The loop variable is bound to a thread in
+   * an environment. In the final stage of lowering,
+   * the loop is simply removed and the loop variable is
+   * mapped to the corresponding context thread.
+   */
+  kThreadBinding = 4
+};
+
+/*!
+ * \brief A for loop, with poissible type annotations.
+ *
+ * \code
+ *
+ *  for (loop_var = min; loop_var < min + extent; ++loop_var) {
+ *    // body
+ *  }
+ * \endcode
+ */
+class ForNode : public StmtNode {
+ public:
+  /*! \brief The loop variable. */
+  Var loop_var;
+  /*! \brief The minimum value of iteration. */
+  PrimExpr min;
+  /*! \brief The extent of the iteration. */
+  PrimExpr extent;
+  /*! \brief The kind of the for loop. */
+  ForKind kind;
+  /*! \brief The body of the for loop. */
+  Stmt body;
+  /*!
+   * \brief Only valid when kind == ForKind::kThreadBinding
+   * The context thread that this loop variable bounds to.
+   */
+  Optional<IterVar> thread_binding;
+  /*!
+   * \brief Additional annotations about the loop.
+   *
+   *  These annotations can be used as auxiliary hint
+   *  to future transformations. An annotation should
+   *  not change the control flow semantics of the loop
+   *  and can be ignored in most passes.
+   */
+  Map<String, ObjectRef> annotations;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("loop_var", &loop_var);
+    v->Visit("min", &min);
+    v->Visit("extent", &extent);
+    v->Visit("kind", &kind);
+    v->Visit("body", &body);
+    v->Visit("thread_binding", &thread_binding);
+    v->Visit("annotations", &annotations);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const ForNode* other, SEqualReducer equal) const {
+    return equal.DefEqual(loop_var, other->loop_var) && equal(min, other->min) &&
+           equal(extent, other->extent) && equal(kind, other->kind) && equal(body, other->body) &&
+           equal(thread_binding, other->thread_binding) && equal(annotations, other->annotations);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce.DefHash(loop_var);
+    hash_reduce(min);
+    hash_reduce(extent);
+    hash_reduce(kind);
+    hash_reduce(body);
+    hash_reduce(thread_binding);
+    hash_reduce(annotations);
+  }
+
+  static constexpr const char* _type_key = "tir.For";
+  TVM_DECLARE_FINAL_OBJECT_INFO(ForNode, StmtNode);
+};
+
+/*!
+ * \brief Managed reference to ForNode.
+ * \sa ForNode
+ */
+class For : public Stmt {
+ public:
+  TVM_DLL For(Var loop_var, PrimExpr min, PrimExpr extent, ForKind kind, Stmt body,
+              Optional<IterVar> thread_binding = NullOpt,
+              Map<String, ObjectRef> annotations = Map<String, ObjectRef>(), Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(For, Stmt, ForNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(ForNode);
+};
+
+/*!
+ * \brief A While loop
+ *
+ * \code
+ *
+ *  while (condition)
+ *    body
+ *
+ * \endcode
+ */
+class WhileNode : public StmtNode {
+ public:
+  /*! \brief The termination condition. */
+  PrimExpr condition;
+  /*! \brief The body of the while loop. */
+  Stmt body;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("condition", &condition);
+    v->Visit("body", &body);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const WhileNode* other, SEqualReducer equal) const {
+    return equal(condition, other->condition) && equal(body, other->body);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(condition);
+    hash_reduce(body);
+  }
+
+  static constexpr const char* _type_key = "tir.While";
+  TVM_DECLARE_FINAL_OBJECT_INFO(WhileNode, StmtNode);
+};
+
+/*!
+ * \brief Managed reference to WhileNode.
+ * \sa WhileNode
+ */
+class While : public Stmt {
+ public:
+  TVM_DLL While(PrimExpr condition, Stmt body, Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(While, Stmt, WhileNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(WhileNode);
+};
+
+/*!
+ * \brief A prefetch hint for a buffer
+ */
+class PrefetchNode : public StmtNode {
+ public:
+  /*! \brief The function to be prefetched. */
+  Buffer buffer;
+  /*! \brief Bounds to be prefetched. */
+  Array<Range> bounds;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("buffer", &buffer);
+    v->Visit("bounds", &bounds);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const PrefetchNode* other, SEqualReducer equal) const {
+    return equal(buffer, other->buffer) && equal(bounds, other->bounds);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(buffer);
+    hash_reduce(bounds);
+  }
+
+  PrefetchNode() = default;
+  PrefetchNode(Buffer buffer, Array<Range> bounds, Span span = Span())
+      : StmtNode(span), buffer(buffer), bounds(bounds) {}
+
+  static constexpr const char* _type_key = "tir.Prefetch";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PrefetchNode, StmtNode);
+};
+
+/*!
+ * \brief Managed reference to PrefetchNode.
+ * \sa PrefetchNode
+ */
+class Prefetch : public Stmt {
+ public:
+  TVM_DLL explicit Prefetch(Buffer buffer, Array<Range> bounds, Span span = Span());
+
+  TVM_DEFINE_NOTNULLABLE_OBJECT_REF_METHODS(Prefetch, Stmt, PrefetchNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(PrefetchNode);
+};
+
+/*!
+ * \brief Representing the region of multi-dimensional buffer access.
+ */
+class BufferRegionNode : public Object {
+ public:
+  /*! \brief The buffer of the buffer region. */
+  Buffer buffer;
+  /*! \brief The region array of the buffer region. */
+  Array<Range> region;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("buffer", &buffer);
+    v->Visit("region", &region);
+  }
+
+  bool SEqualReduce(const BufferRegionNode* other, SEqualReducer equal) const {
+    return equal(buffer, other->buffer) && equal(region, other->region);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(buffer);
+    hash_reduce(region);
+  }
+
+  static constexpr const char* _type_key = "tir.BufferRegion";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_FINAL_OBJECT_INFO(BufferRegionNode, Object);
+};
+
+/*!
+ * \brief Managed reference to BufferRegionNode.
+ * \sa BufferRegionNode
+ */
+class BufferRegion : public ObjectRef {
+ public:
+  TVM_DLL explicit BufferRegion(Buffer buffer, Array<Range> region);
+
+  /*!
+   * \brief Create a BufferRegion which is full region of the given buffer.
+   * \param buffer The buffer to generate full BufferRegion.
+   * \return The BufferRegion which covers all region of the given buffer
+   */
+  TVM_DLL static BufferRegion FullRegion(Buffer buffer);
+
+  /*!
+   * \brief Create a BufferRegion which is a single point of the given buffer.
+   * \param buffer The buffer to generate single point BufferRegion.
+   * \param indices The access point indices of the buffer
+   * \return The BufferRegion which is the single point of the given buffer.
+   */
+  TVM_DLL static BufferRegion FromPoint(Buffer buffer, Array<PrimExpr> indices);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(BufferRegion, ObjectRef, BufferRegionNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(BufferRegionNode);
+};
+
+/*!
+ * \brief Match introduces a constraint that the source buffer region can be remapped to the data
+ * layout specified by the buffer field. The constraint can be checked in later part of lowering (or
+ * optionally during runtime).
+ *
+ * MatchBufferRegion provides a mechanism to represent data layout and compactness constraints in
+ * low-level hardware primitives in the IR and defer the check after the sequence of
+ * transformations.
+ */
+class MatchBufferRegionNode : public Object {
+ public:
+  /*! \brief The target buffer. */
+  Buffer buffer;
+  /*! \brief The source buffer region. */
+  BufferRegion source;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("buffer", &buffer);
+    v->Visit("source", &source);
+  }
+
+  bool SEqualReduce(const MatchBufferRegionNode* other, SEqualReducer equal) const {
+    return equal(buffer, other->buffer) && equal(source, other->source);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(buffer);
+    hash_reduce(source);
+  }
+
+  static constexpr const char* _type_key = "tir.MatchBufferRegion";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_FINAL_OBJECT_INFO(MatchBufferRegionNode, Object);
+};
+
+/*!
+ * \brief Managed reference to MatchBufferRegionNode.
+ * \sa MatchBufferRegionNode
+ */
+class MatchBufferRegion : public ObjectRef {
+ public:
+  TVM_DLL explicit MatchBufferRegion(Buffer buffer, BufferRegion source);
+
+  TVM_DEFINE_OBJECT_REF_METHODS(MatchBufferRegion, ObjectRef, MatchBufferRegionNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(MatchBufferRegionNode);
+};
+
+/*!
+ * \brief A block is a basic schedule unit in TIR.
+ * \note Block's body is parameterized by iter vars.
+ * \code
+ *
+ *  with T.block(name):
+ *      v0 = T.axis.S(domain, value0)
+ *      v1 = T.axis.R(domain, value1)
+ *      ...
+ *      T.reads([buffer0[start:end, ...], ...])
+ *      T.writes([buffer1[start:end, ...], ...])
+ *      T.where(predicate)
+ *      buffer2 = T.alloc_buffer(shape, dtype)
+ *      buffer3 = T.match_buffer(source_buffer[start:end, ...])
+ *      T.attr({attr_key: attr_value, ...})
+ *      with T.init():
+ *          // init body
+ *      // body
+ *
+ * \endcode
+ */
+class BlockNode : public StmtNode {
+ public:
+  /*! \brief The variables of the block. */
+  Array<IterVar> iter_vars;
+  /*! \brief The read buffer regions of the block. */
+  Array<BufferRegion> reads;
+  /*! \brief The write buffer regions of the block. */
+  Array<BufferRegion> writes;
+  /*! \brief The name_hint of the block. */
+  String name_hint;
+  /*! \brief The body of the block. */
+  Stmt body;
+  /*!
+   * \brief The init statement is executed during the first iteration of reduction loops in a
+   *  reduction block. The optional init field allows us to represent initialization and
+   *  reduction update in a single block and transform them collectively.
+   *  We also provide primitives to decompose the init into a separate block during scheduling.
+   *  Init field is `NullOpt` if there is no reduction iter_vars
+   */
+  Optional<Stmt> init;
+  /*! \brief The buffer allocated in the block. */
+  Array<Buffer> alloc_buffers;
+  /*! \brief The match buffer regions. */
+  Array<MatchBufferRegion> match_buffers;
+  /*! \brief The annotation of the block. */
+  Map<String, ObjectRef> annotations;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("iter_vars", &iter_vars);
+    v->Visit("reads", &reads);
+    v->Visit("writes", &writes);
+    v->Visit("name_hint", &name_hint);
+    v->Visit("body", &body);
+    v->Visit("init", &init);
+    v->Visit("alloc_buffers", &alloc_buffers);
+    v->Visit("match_buffers", &match_buffers);
+    v->Visit("annotations", &annotations);
+  }
+
+  bool SEqualReduce(const BlockNode* other, SEqualReducer equal) const {
+    // Need first reduce iter_vars, alloc_buffers and match_buffers to define new vars
+    return equal.DefEqual(iter_vars, other->iter_vars) &&
+           equal(alloc_buffers, other->alloc_buffers) &&
+           equal(match_buffers, other->match_buffers) && equal(reads, other->reads) &&
+           equal(writes, other->writes) && equal(body, other->body) && equal(init, other->init) &&
+           equal(annotations, other->annotations);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce.DefHash(iter_vars);
+    hash_reduce(alloc_buffers);
+    hash_reduce(match_buffers);
+    hash_reduce(reads);
+    hash_reduce(writes);
+    hash_reduce(body);
+    hash_reduce(init);
+    hash_reduce(annotations);
+  }
+
+  static constexpr const char* _type_key = "tir.Block";
+  TVM_DECLARE_FINAL_OBJECT_INFO(BlockNode, StmtNode);
+};
+
+/*!
+ * \brief Managed reference to BlockNode.
+ * \sa BlockNode
+ */
+class Block : public Stmt {
+ public:
+  TVM_DLL explicit Block(Array<IterVar> iter_vars, Array<BufferRegion> reads,
+                         Array<BufferRegion> writes, String name_hint, Stmt body,
+                         Optional<Stmt> init = NullOpt,
+                         Array<Buffer> alloc_buffers = Array<Buffer>(),
+                         Array<MatchBufferRegion> match_buffers = Array<MatchBufferRegion>(),
+                         Map<String, ObjectRef> annotations = Map<String, ObjectRef>(),
+                         Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(Block, Stmt, BlockNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(BlockNode);
+};
+
+/*!
+ * \brief A block realization node represents execution of the block at the binding values.
+ */
+class BlockRealizeNode : public StmtNode {
+ public:
+  /*! \brief The corresponding values of the iter vars. */
+  Array<PrimExpr> iter_values;
+  /*!
+   * \brief The predicate of the block realization, the block will only be executed when the
+   * predicate is true.
+   */
+  PrimExpr predicate;
+  /*! \brief The block to be realized. */
+  Block block;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("iter_values", &iter_values);
+    v->Visit("predicate", &predicate);
+    v->Visit("block", &block);
+  }
+
+  bool SEqualReduce(const BlockRealizeNode* other, SEqualReducer equal) const {
+    return equal(iter_values, other->iter_values) && equal(predicate, other->predicate) &&
+           equal(block, other->block);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(iter_values);
+    hash_reduce(predicate);
+    hash_reduce(block);
+  }
+
+  static constexpr const char* _type_key = "tir.BlockRealize";
+  TVM_DECLARE_FINAL_OBJECT_INFO(BlockRealizeNode, StmtNode);
+};
+
+/*!
+ * \brief Managed reference to BlockRealizeNode
+ * \sa BlockRealizeNode
+ */
+class BlockRealize : public Stmt {
+ public:
+  TVM_DLL explicit BlockRealize(Array<PrimExpr> iter_values, PrimExpr predicate, Block block,
+                                Span span = Span());
+
+  TVM_DEFINE_OBJECT_REF_METHODS(BlockRealize, Stmt, BlockRealizeNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(BlockRealizeNode);
+};
+
+/*! \brief namespace of possible attributes in AttrStmt.attr_key */
+namespace attr {
+// The above attr does not pass to ir stage.
+/*! \brief Mark launching extent of thread, used by device API. */
+constexpr const char* thread_extent = "thread_extent";
+/*! \brief Mark launching of a virtual thread. */
+constexpr const char* virtual_thread = "virtual_thread";
+/*! \brief Mark region is processed by a co-proccesor */
+constexpr const char* coproc_scope = "coproc_scope";
+/*!
+ * \brief Mark region creates coprocessor micro ops,
+ *  can be reused if corresponding variable is independent.
+ */
+constexpr const char* coproc_uop_scope = "coproc_uop_scope";
+/*! \brief Mark the scope as volatile access for certain handle. */
+constexpr const char* volatile_scope = "volatile_scope";
+/*!
+ * \brief Mark the scope as generated by extern primitive.
+ *  such scope can contain arbitrary ir program and we need to be careful
+ *  when make certain assumptions about the structure of the program.
+ */
+constexpr const char* extern_scope = "extern_scope";
+/*!
+ * \brief Mark the scope as when computation start to happen
+ *  This can hint some code generator to create a new function for compute.
+ */
+constexpr const char* compute_scope = "compute_scope";
+/*! \brief Mark storage alignment requirement of buffers */
+constexpr const char* storage_alignment = "storage_alignment";
+/*! \brief Mark storage scope of realization */
+constexpr const char* realize_scope = "realize_scope";
+/*! \brief The allocation device for global malloc in host. */
+constexpr const char* device_id = "device_id";
+/*! \brief The device type. */
+constexpr const char* device_type = "device_type";
+/*! \brief Mark of loop scope */
+constexpr const char* loop_scope = "loop_scope";
+/*! \brief Mark of reduce scope */
+constexpr const char* reduce_scope = "reduce_scope";
+/*! \brief Pragma: auto-unroll, max_step */
+constexpr const char* pragma_auto_unroll_max_step = "pragma_auto_unroll_max_step";
+/*! \brief Pragma: unroll explicit */
+constexpr const char* pragma_unroll_explicit = "pragma_unroll_explicit";
+/*! \brief Mark region is guarded by the pragma extension */
+constexpr const char* pragma_scope_prefix = "pragma_";
+/*! \brief Import C source or file into the final code gen module */
+constexpr const char* pragma_import_c = "pragma_import_c";
+/*! \brief Import llvm source or file into the final code gen module */
+constexpr const char* pragma_import_llvm = "pragma_import_llvm";
+/*! \brief Try to modify the AST to support Tensor Core */
+constexpr const char* pragma_tensor_core = "pragma_tensor_core";
+/*!
+ * \brief Mark of prefetch scope, value=offset,
+ *  run prefetch of Tensor on the current loop scope
+ */
+constexpr const char* prefetch_scope = "prefetch_scope";
+/*!
+ * \brief Marks the layout transforms to be used for a tensor.
+ *
+ * Only applies to a DataProducer, as it should be made part of the
+ * PrimFunc attributes for TIR.
+ */
+constexpr const char* layout_transforms = "layout_transforms";
+/*!
+ * \brief Marks the physical axis separators
+ *
+ * Only applies to a DataProducer, as it should be made part of the
+ * Buffer definition in a PrimFunc.  See `BufferNode::axis_separators`
+ * for more details.
+ */
+constexpr const char* axis_separators = "axis_separators";
+/*!
+ * \brief Marks production of double buffer data
+ */
+constexpr const char* double_buffer_scope = "double_buffer_scope";
+/*!
+ * \brief Marks region used by double buffer write
+ */
+constexpr const char* double_buffer_write = "double_buffer_write";
+/*! \brief Mark realization for rolling buffer optimization */
+constexpr const char* rolling_buffer_scope = "rolling_buffer_scope";
+/*! \brief Mark of scan update scope */
+constexpr const char* scan_update_scope = "scan_update_scope";
+/*! \brief Mark of scan init scope */
+constexpr const char* scan_init_scope = "scan_init_scope";
+/*!
+ * \brief Mark alignment of buffer dimension
+ *  stmt.node is Tensor
+ *  stmt.value is tvm_tuple(dim, align, offset)
+ *  This gives hint to require stride of dim to be k * align + offset.
+ */
+constexpr const char* buffer_dim_align = "buffer_dim_align";
+/*! \brief Mark stores/loads with theirs bounds.  */
+constexpr const char* buffer_bound = "buffer_bound";
+/*!
+ * \brief Bind the buffer specification to the region of the op
+ *  When this scope occurs, the stmt.node is a Array<NodeRef> = [buffer, tensor]
+ *  stmt.value is a tvm_tuple(min0, extent0, min1, extent1, ...).
+ *  The scope represents that we need to bind the storage region of tensor to buffer.
+ *  This will affect replacement of some variables inside the scope that
+ *  corresponds to field of buffer to be the actual expressions of tensor during
+ *  storage flattening phase.
+ */
+constexpr const char* buffer_bind_scope = "buffer_bind_scope";
+// Pipeline related attributes
+/*! \brief channel read scope */
+constexpr const char* channel_read_scope = "channel_read_scope";
+/*! \brief Advance step of channel after end of scope */
+constexpr const char* channel_read_advance = "channel_read_advance";
+/*! \brief channel write scope */
+constexpr const char* channel_write_scope = "channel_write_scope";
+/*! \brief Advance step of channel after end of scope */
+constexpr const char* channel_write_advance = "channel_write_advance";
+/*! \brief pipeline stage scope, implies always execution */
+constexpr const char* pipeline_stage_scope = "pipeline_stage_scope";
+/*! \brief pipeline execution scope, implies the scope can be pipelined. */
+constexpr const char* pipeline_exec_scope = "pipeline_exec_scope";
+
+/*!
+ * \brief Mark that it is in the device scope.
+ */
+constexpr const char* device_scope = "device_scope";
+
+/*!
+ * \brief Mark that the attached statement runs asynchronously.
+ */
+constexpr const char* async_scope = "async_scope";
+
+/*!
+ * \brief Annotations for invoking and synchronizing asynchronous operations.
+
+ * Synchronization is done in terms of "queue": It is an abstract entity associated
+ * with each asynchronous unit, and it tracks invocations and completions of asynchronous
+ * operations in the FIFO order.
+ *
+ * Similarly to PTX instructions commit_group and wait_group, these annotations express
+ * synchronization by "counting":
+ *
+ * async_commit_queue(i): Group one or more invocations of async operations in the given scope,
+ * and "commit" (or push) them to the queue i. A group of operations committed together is
+ * awaited as one chunk. Groups committed to the same queue complete in the FIFO order.
+ *
+ * async_wait_queue(i, N): Block until only N most recent committed groups are still in-flight at
+ * the queue i. N does not have to be a constant, but some backends may require a constant count.
+*/
+constexpr const char* async_commit_queue_scope = "async_commit_queue_scope";
+constexpr const char* async_wait_queue_scope = "async_wait_queue_scope";
+constexpr const char* async_wait_inflight_count = "async_wait_inflight_count";
+
+/*!
+ * \brief Mark that the shape of TensorCore fragment
+ */
+constexpr const char* fragment_shape = "fragment_shape";
+
+/*!
+ * \brief Mark that the layout of TensorCore fragment
+ */
+constexpr const char* fragment_layout = "fragment_layout";
+
+/*!
+ * \brief Mark that the kernel is hand threaded and doesn't need syncs inserted
+ */
+constexpr const char* hand_threaded = "hand_threaded";
+
+/*!
+ * \brief Mark whether the script-completer need to fill in missing access region
+ *        during script parsing.
+ * \note The result should be a integer mask with range [0, 4).
+ *       if (mask & 1) the read region should be detected,
+ *       if (mask & 2) the write region should be detected.
+ */
+constexpr const char* script_parsing_detect_access = "tir.script_parsing_detect_access";
+
+/*!
+ * \brief Mark that the loop should be partitioned.
+ */
+constexpr const char* pragma_loop_partition_hint = "pragma_loop_partition_hint";
+
+/*! \brief Mark the stage of a statement in the software pipeline */
+constexpr const char* software_pipeline_stage = "software_pipeline_stage";
+
+/*! \brief Mark the order of a statement in the software pipeline */
+constexpr const char* software_pipeline_order = "software_pipeline_order";
+
+/*! \brief List stages in the software pipeline that should run asynchronously
+ * \note All statements in the provided stages are assumed to have asynchronous
+ *       semantics (e.g. CUDA async global to shared memory copy).
+ */
+constexpr const char* software_pipeline_async_stages = "software_pipeline_async_stages";
+
+/*! \brief Mark the buffers which is const access and can be transformed layout. */
+constexpr const char* layout_free_buffers = "layout_free_buffers";
+
+/*! \brief Mark the local stage for the shared memory access should be added. */
+constexpr const char* manifest_shared_memory_local_stage = "tir.manifest_shared_memory_local_stage";
+
+/*! \brief Mark the tiling structure of blocks that are applied by rule Multi-Level-Tiling */
+constexpr const char* meta_schedule_tiling_structure = "meta_schedule.tiling_structure";
+
+/*!
+ * \brief Mark that the loop should be further skip and bound to environment threads to enable
+ * cooperative fetching.
+ */
+constexpr const char* meta_schedule_cooperative_fetch = "meta_schedule.cooperative_fetch";
+
+/*! \brief The allowed range of thread extent in thread bindings */
+constexpr const char* meta_schedule_thread_extent_low_inclusive =
+    "meta_schedule.thread_extent_low_inclusive";
+
+/*! \brief The allowed range of thread extent in thread bindings */
+constexpr const char* meta_schedule_thread_extent_high_inclusive =
+    "meta_schedule.thread_extent_high_inclusive";
+
+/*! \brief Mark the block whose producer needs to be applied by rule Random-Compute-Location */
+constexpr const char* meta_schedule_random_compute_producer =
+    "meta_schedule.random_compute_producer";
+
+/*! \brief Mark auto-parallel setting on the block. */
+constexpr const char* meta_schedule_parallel = "meta_schedule.parallel";
+
+/*! \brief Mark auto-vectorize setting on the block. */
+constexpr const char* meta_schedule_vectorize = "meta_schedule.vectorize";
+
+/*! \brief Mark auto-unroll setting on the block. */
+constexpr const char* meta_schedule_unroll_explicit = "meta_schedule.unroll_explicit";
+
+/*! \brief Mark auto-unroll setting on the block. */
+constexpr const char* meta_schedule_unroll_implicit = "meta_schedule.unroll_implicit";
+
+/*! \brief Mark that a block should be further rewritten using tensorization. */
+constexpr const char* meta_schedule_auto_tensorize = "meta_schedule.auto_tensorize";
+
+/*! \brief Mark that a block is a preprocessor block for layout rewrite. */
+constexpr const char* meta_schedule_layout_rewrite_preproc = "meta_schedule.layout_rewrite_preproc";
+/*!
+ * \brief Mark that the init statement of a block should be further rewritten using tensorization.
+ */
+constexpr const char* meta_schedule_auto_tensorize_init = "meta_schedule.auto_tensorize_init";
+
+/*!
+ * \brief Mark that a block is executed by a warp. This implies the extend of threadIdx.x is
+ * warp size.
+ */
+constexpr const char* warp_execution = "warp_execution";
+
+/*!
+ * \brief Check if attr_key is a pragma key extension
+ * \param attr_key The attr key to be compared
+ * \return true if it is a pragma key
+ */
+inline bool IsPragmaKey(const std::string& attr_key) {
+  return attr_key.compare(0, 7, "pragma_") == 0;
+}
+
+}  // namespace attr
+/*!
+ * \brief Create a type annotation expression
+ * \param dtype The data type
+ * \param span The location of this object in the source code.
+ * \return Expr a expression with dtype.
+ */
+TVM_DLL PrimExpr TypeAnnotation(DataType dtype, Span span = Span());
+
+// overload printing of for type.
+TVM_DLL std::ostream& operator<<(std::ostream& os, ForKind kind);
+
+// inline implementations
+inline const char* ForKind2String(ForKind t) {
+  switch (t) {
+    case ForKind::kSerial:
+      return "serial";
+    case ForKind::kParallel:
+      return "parallel";
+    case ForKind::kVectorized:
+      return "vectorized";
+    case ForKind::kUnrolled:
+      return "unroll";
+    case ForKind::kThreadBinding:
+      return "thread_binding";
+  }
+  LOG(FATAL) << "Unknown ForKind" << t;
+}
+
+}  // namespace tir
+}  // namespace tvm
+#endif  // TVM_TIR_STMT_H_
diff --git a/darknet_drp_ros/include/tvm/tir/stmt_functor.h b/darknet_drp_ros/include/tvm/tir/stmt_functor.h
new file mode 100644
index 0000000..3adb186
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/stmt_functor.h
@@ -0,0 +1,490 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/tir/stmt_functor.h
+ *
+ * \brief Functors for tir stmts
+ *        utility functions to call common functors.
+ */
+#ifndef TVM_TIR_STMT_FUNCTOR_H_
+#define TVM_TIR_STMT_FUNCTOR_H_
+
+#include <tvm/node/functor.h>
+#include <tvm/tir/expr.h>
+#include <tvm/tir/expr_functor.h>
+#include <tvm/tir/function.h>
+#include <tvm/tir/stmt.h>
+
+#include <unordered_map>
+#include <utility>
+
+namespace tvm {
+namespace tir {
+/*!
+ * \brief Same as ExprFunctor except it is applied on statements
+ * \tparam FType The function signature.
+ * \sa ExprFunctor
+ */
+template <typename FType>
+class StmtFunctor;
+
+#define STMT_FUNCTOR_DEFAULT \
+  { return VisitStmtDefault_(op, std::forward<Args>(args)...); }
+
+#define IR_STMT_FUNCTOR_DISPATCH(OP)                                                       \
+  vtable.template set_dispatch<OP>([](const ObjectRef& n, TSelf* self, Args... args) {     \
+    return self->VisitStmt_(static_cast<const OP*>(n.get()), std::forward<Args>(args)...); \
+  });
+
+template <typename R, typename... Args>
+class StmtFunctor<R(const Stmt& n, Args... args)> {
+ private:
+  using TSelf = StmtFunctor<R(const Stmt& n, Args... args)>;
+  using FType = NodeFunctor<R(const ObjectRef& n, TSelf* self, Args... args)>;
+
+ public:
+  /*! \brief the result type of this functor */
+  using result_type = R;
+  /*! \brief virtual destructor */
+  virtual ~StmtFunctor() {}
+  /*!
+   * \brief Same as call.
+   * \param n The stmt node.
+   * \param args Additional arguments.
+   * \return The result of the call
+   */
+  R operator()(const Stmt& n, Args... args) { return VisitStmt(n, std::forward<Args>(args)...); }
+  /*!
+   * \brief The functor call.
+   * \param n The stmt node.
+   * \param args Additional arguments.
+   * \return The result of the call
+   */
+  virtual R VisitStmt(const Stmt& n, Args... args) {
+    static FType vtable = InitVTable();
+    return vtable(n, this, std::forward<Args>(args)...);
+  }
+  // Functions that can be overriden by subclass
+  virtual R VisitStmt_(const LetStmtNode* op, Args... args) STMT_FUNCTOR_DEFAULT;
+  virtual R VisitStmt_(const AttrStmtNode* op, Args... args) STMT_FUNCTOR_DEFAULT;
+  virtual R VisitStmt_(const IfThenElseNode* op, Args... args) STMT_FUNCTOR_DEFAULT;
+  virtual R VisitStmt_(const ForNode* op, Args... args) STMT_FUNCTOR_DEFAULT;
+  virtual R VisitStmt_(const WhileNode* op, Args... args) STMT_FUNCTOR_DEFAULT;
+  virtual R VisitStmt_(const AllocateNode* op, Args... args) STMT_FUNCTOR_DEFAULT;
+  virtual R VisitStmt_(const AllocateConstNode* op, Args... args) STMT_FUNCTOR_DEFAULT;
+  virtual R VisitStmt_(const DeclBufferNode* op, Args... args) STMT_FUNCTOR_DEFAULT;
+  virtual R VisitStmt_(const StoreNode* op, Args... args) STMT_FUNCTOR_DEFAULT;
+  virtual R VisitStmt_(const BufferStoreNode* op, Args... args) STMT_FUNCTOR_DEFAULT;
+  virtual R VisitStmt_(const BufferRealizeNode* op, Args... args) STMT_FUNCTOR_DEFAULT;
+  virtual R VisitStmt_(const AssertStmtNode* op, Args... args) STMT_FUNCTOR_DEFAULT;
+  virtual R VisitStmt_(const ProducerStoreNode* op, Args... args) STMT_FUNCTOR_DEFAULT;
+  virtual R VisitStmt_(const ProducerRealizeNode* op, Args... args) STMT_FUNCTOR_DEFAULT;
+  virtual R VisitStmt_(const PrefetchNode* op, Args... args) STMT_FUNCTOR_DEFAULT;
+  virtual R VisitStmt_(const SeqStmtNode* op, Args... args) STMT_FUNCTOR_DEFAULT;
+  virtual R VisitStmt_(const EvaluateNode* op, Args... args) STMT_FUNCTOR_DEFAULT;
+  virtual R VisitStmt_(const BlockNode* op, Args... args) STMT_FUNCTOR_DEFAULT;
+  virtual R VisitStmt_(const BlockRealizeNode* op, Args... args) STMT_FUNCTOR_DEFAULT;
+  virtual R VisitStmtDefault_(const Object* op, Args...) {
+    LOG(FATAL) << "Do not have a default for " << op->GetTypeKey();
+  }
+
+ private:
+  // initialize the vtable.
+  static FType InitVTable() {
+    FType vtable;
+    IR_STMT_FUNCTOR_DISPATCH(LetStmtNode);
+    IR_STMT_FUNCTOR_DISPATCH(AttrStmtNode);
+    IR_STMT_FUNCTOR_DISPATCH(IfThenElseNode);
+    IR_STMT_FUNCTOR_DISPATCH(ForNode);
+    IR_STMT_FUNCTOR_DISPATCH(WhileNode);
+    IR_STMT_FUNCTOR_DISPATCH(AllocateNode);
+    IR_STMT_FUNCTOR_DISPATCH(AllocateConstNode);
+    IR_STMT_FUNCTOR_DISPATCH(DeclBufferNode);
+    IR_STMT_FUNCTOR_DISPATCH(StoreNode);
+    IR_STMT_FUNCTOR_DISPATCH(AssertStmtNode);
+    IR_STMT_FUNCTOR_DISPATCH(ProducerStoreNode);
+    IR_STMT_FUNCTOR_DISPATCH(ProducerRealizeNode);
+    IR_STMT_FUNCTOR_DISPATCH(PrefetchNode);
+    IR_STMT_FUNCTOR_DISPATCH(SeqStmtNode);
+    IR_STMT_FUNCTOR_DISPATCH(EvaluateNode);
+    IR_STMT_FUNCTOR_DISPATCH(BufferStoreNode);
+    IR_STMT_FUNCTOR_DISPATCH(BufferRealizeNode);
+    IR_STMT_FUNCTOR_DISPATCH(BlockNode);
+    IR_STMT_FUNCTOR_DISPATCH(BlockRealizeNode);
+    return vtable;
+  }
+};
+
+#undef IR_STMT_FUNCTOR_DISPATCH
+#undef STMT_FUNCTOR_DEFAULT
+
+/*!
+ * \brief StmtVisitor.
+ */
+class TVM_DLL StmtVisitor : protected StmtFunctor<void(const Stmt&)> {
+ public:
+  using StmtFunctor::operator();
+
+ protected:
+  using StmtFunctor::VisitStmt;
+  /*!
+   * \brief Visitor to Exprs, can be overriden
+   *        to do recursive changes to Exprs.
+   * \note A common pattern is to call ExprVisitor here,
+   *       or have a class sub-class both StmtVisitor and ExprVisitor
+   *       and redirect Visit to ExprMutator::VisitExpr(Expr)
+   */
+  virtual void VisitExpr(const PrimExpr& e) {}
+  // statement visitor
+  void VisitStmt_(const AttrStmtNode* op) override;
+  void VisitStmt_(const IfThenElseNode* op) override;
+  void VisitStmt_(const LetStmtNode* op) override;
+  void VisitStmt_(const ForNode* op) override;
+  void VisitStmt_(const WhileNode* op) override;
+  void VisitStmt_(const AllocateNode* op) override;
+  void VisitStmt_(const AllocateConstNode* op) override;
+  void VisitStmt_(const DeclBufferNode* op) override;
+  void VisitStmt_(const StoreNode* op) override;
+  void VisitStmt_(const BufferStoreNode* op) override;
+  void VisitStmt_(const BufferRealizeNode* op) override;
+  void VisitStmt_(const AssertStmtNode* op) override;
+  void VisitStmt_(const ProducerStoreNode* op) override;
+  void VisitStmt_(const ProducerRealizeNode* op) override;
+  void VisitStmt_(const PrefetchNode* op) override;
+  void VisitStmt_(const SeqStmtNode* op) override;
+  void VisitStmt_(const EvaluateNode* op) override;
+  void VisitStmt_(const BlockNode* op) override;
+  void VisitStmt_(const BlockRealizeNode* op) override;
+};
+
+/*!
+ * \brief StmtMutator that mutates the statements.
+ */
+class TVM_DLL StmtMutator : protected StmtFunctor<Stmt(const Stmt&)> {
+ public:
+  /*!
+   * \brief Mutate stmt.
+   * \param stmt The input statement to be mutated.
+   * \return The result of the call
+   * \note It is important that stmt is passed by value.
+   *       so copy on write can be triggered correctly.
+   *       do mutator(std::move(stmt)) or when copy elison is triggered.
+   */
+  Stmt operator()(Stmt stmt) {
+    allow_copy_on_write_ = true;
+    return VisitStmt(stmt);
+  }
+
+ protected:
+  // We perform copy on write optimizations on the StmtMutator
+  // so that an unique copy of parent can be mutated inplace
+  // when some of its children changed.
+  // We only do such optimization for Stmt nests(instead of Exprs) for now
+  // as Stmt's parent state is more likely remain unchanged when one of
+  // its child block changes.
+  /*!
+   * \brief Internal state to indicate whether copy on write is enabled.
+   *  COW is enabled iff all the parents of the node are unique.
+   */
+  bool allow_copy_on_write_{false};
+  /*!
+   * \brief Perform copy on write on node.
+   *
+   *  If CopyOnWrite is allowed, directly return
+   *  a strong reference to the node container.
+   *  Otherwise, return a copy of the node.
+   *
+   * \return The result object pointer.
+   */
+  template <typename TNode>
+  ObjectPtr<TNode> CopyOnWrite(const TNode* node) {
+    static_assert(std::is_base_of<StmtNode, TNode>::value,
+                  "StmtMutator:: CopyOnWrite requires us to track uniqueness of all parent "
+                  "nodes during the recursion. Because the child classes do not necessarily "
+                  "check the Array, Expr and other structures during the visit, it is only safe to "
+                  "call this function with StmtNodes for now. "
+                  "Please create a new node directly in other cases.");
+    if (allow_copy_on_write_) {
+      // return the old node.
+      return runtime::GetObjectPtr<TNode>(const_cast<TNode*>(node));
+    } else {
+      // Make a new copy of the node.
+      // need to rely on the default copy constructor
+      return runtime::make_object<TNode>(*node);
+    }
+  }
+  /*!
+   * \brief Internal mutator that everyone calls.
+   * \note To override mutate's behavior, override VisitExpr instead.
+   * \param stmt The input stmt.
+   * \return The mutated results.
+   */
+  Stmt VisitStmt(const Stmt& stmt) override {
+    if (allow_copy_on_write_ && !stmt.unique()) {
+      allow_copy_on_write_ = false;
+      Stmt ret = StmtFunctor::VisitStmt(stmt);
+      allow_copy_on_write_ = true;
+      return ret;
+    } else {
+      return StmtFunctor::VisitStmt(stmt);
+    }
+  }
+  /*!
+   * \brief Visitor to Exprs, can be overriden
+   *        to do recursive changes to Exprs.
+   * \note A common pattern is to call ExprMutator here,
+   *       or have a class sub-class both StmtMutator and ExprMutator
+   *       and redirect Mutate to ExprMutator::Mutate(Expr)
+   */
+  virtual PrimExpr VisitExpr(const PrimExpr& e) { return e; }
+  // statement visitor
+  Stmt VisitStmt_(const AttrStmtNode* op) override;
+  Stmt VisitStmt_(const IfThenElseNode* op) override;
+  Stmt VisitStmt_(const LetStmtNode* op) override;
+  Stmt VisitStmt_(const ForNode* op) override;
+  Stmt VisitStmt_(const WhileNode* op) override;
+  Stmt VisitStmt_(const AllocateNode* op) override;
+  Stmt VisitStmt_(const AllocateConstNode* op) override;
+  Stmt VisitStmt_(const DeclBufferNode* op) override;
+  Stmt VisitStmt_(const StoreNode* op) override;
+  Stmt VisitStmt_(const BufferStoreNode* op) override;
+  Stmt VisitStmt_(const BufferRealizeNode* op) override;
+  Stmt VisitStmt_(const AssertStmtNode* op) override;
+  Stmt VisitStmt_(const ProducerStoreNode* op) override;
+  Stmt VisitStmt_(const ProducerRealizeNode* op) override;
+  Stmt VisitStmt_(const PrefetchNode* op) override;
+  Stmt VisitStmt_(const SeqStmtNode* op) override;
+  Stmt VisitStmt_(const EvaluateNode* op) override;
+  Stmt VisitStmt_(const BlockNode* op) override;
+  Stmt VisitStmt_(const BlockRealizeNode* op) override;
+  /*!
+   * \brief Alternative advance method for SeqStmtNode.
+   *
+   *  This function can be called when a child class override
+   *  VisitStmt_(const SeqStmtNode*) to introduce
+   *  the special behavior to visit
+   *
+   * \param op The sequence.
+   * \param flatten_before_visit Whether to flatten the sequence before visit.
+   * \param fmutate The mutate function, can be nullptr, which defaults to Visit.
+   * \return The mutated result.
+   */
+  Stmt VisitSeqStmt_(const SeqStmtNode* op, bool flatten_before_visit,
+                     std::function<Stmt(const Stmt&)> fmutate = nullptr);
+
+  // internal helper.
+  class Internal;
+};
+
+/*!
+ * \brief Visitor that recursively visit stmts and exprs on them.
+ */
+class StmtExprVisitor : public StmtVisitor, public ExprVisitor {
+ public:
+  using StmtVisitor::operator();
+  using ExprVisitor::operator();
+
+ protected:
+  using ExprVisitor::VisitExpr;
+  using StmtVisitor::VisitStmt;
+
+  void VisitExpr(const PrimExpr& e) override { return ExprVisitor::VisitExpr(e); }
+};
+
+/*!
+ * \brief Mutator that recursively mutates stmts and exprs on them.
+ */
+class StmtExprMutator : public StmtMutator, public ExprMutator {
+ public:
+  using StmtMutator::operator();
+  using ExprMutator::operator();
+
+ protected:
+  using ExprMutator::VisitExpr;
+  using StmtMutator::VisitExpr;
+
+  PrimExpr VisitExpr(const PrimExpr& e) override { return ExprMutator::VisitExpr(e); }
+};
+
+/*!
+ * \brief recursively visit the ir nodes in post DFS order, and transform it
+ *
+ * \param stmt The ir to be transformed.
+ * \param preorder The function called in before recursive mutation
+ *          If preorder returns None, then the transform will proceed to recursive call.
+ *          If preorder returns a not None Stmt/Expr, the transformer will simply return it and
+ *          won't do further recursion.
+ * \param postorder The function called after recursive mutation.
+ *          The recursive mutation result is passed to postorder for further mutation.
+ * \param only_enable List of runtime::String.
+ *          If it is null, all IRNode will call preorder/postorder
+ *          If it is not null, preorder/postorder will only be called
+ *          when the IRNode's type key is in the list.
+ */
+TVM_DLL Stmt IRTransform(Stmt stmt, const runtime::PackedFunc& preorder,
+                         const runtime::PackedFunc& postorder,
+                         Optional<Array<String>> only_enable = NullOpt);
+
+/*!
+ * \brief Recursively visit the ir in post DFS order node, apply fvisit
+ * Each node is guaranteed to be visited only once.
+ * \param node The ir to be visited.
+ * \param fvisit The visitor function to be applied.
+ */
+TVM_DLL void PostOrderVisit(const ObjectRef& node, std::function<void(const ObjectRef&)> fvisit);
+
+/*!
+ * \brief Substitute the var specified by vmap.
+ * \param stmt The source statement to be substituted
+ * \param vmap returns a new value if re-mapping is needed, otherwise returns nullptr.
+ * \return The converted form.
+ */
+TVM_DLL Stmt Substitute(Stmt stmt, std::function<Optional<PrimExpr>(const Var& var)> vmap);
+
+/*!
+ * \brief Substitute the var specified by vmap.
+ * \param expr The source statement to be substituted
+ * \param vmap returns a new value if re-mapping is needed, otherwise returns nullptr.
+ * \return The result.
+ */
+TVM_DLL PrimExpr Substitute(PrimExpr expr, std::function<Optional<PrimExpr>(const Var& var)> vmap);
+
+/*!
+ * \brief Substitute the var specified by vmap.
+ * \param region The object whose vars are to be substituted
+ * \param vmap The map of new values.
+ * \return The result.
+ */
+TVM_DLL Array<Range> Substitute(const Array<Range>& region, const Map<Var, PrimExpr>& vmap);
+
+/*!
+ * \brief Sugar for substitute via a given map.
+ * \param input The input to be updated.
+ * \param value_map The map of new values.
+ * \return The result.
+ * \tparam T the input type, can be PrimExpr or Stmt.
+ */
+template <typename T>
+inline auto Substitute(T input, const Map<Var, PrimExpr>& value_map) {
+  auto vmap = [&](const Var& var) -> Optional<PrimExpr> {
+    auto it = value_map.find(var);
+    if (it != value_map.end()) return (*it).second;
+    return Optional<PrimExpr>(nullptr);
+  };
+  return Substitute(std::move(input), vmap);
+}
+
+/*!
+ * \brief Sugar for substitute via a given map.
+ * \param input The input to be updated.
+ * \param value_map The map of new values.
+ * \return The result.
+ * \tparam T the input type, can be PrimExpr or Stmt.
+ */
+template <typename T>
+inline T Substitute(T input, const std::unordered_map<const VarNode*, PrimExpr>& value_map) {
+  auto vmap = [&](const Var& var) -> Optional<PrimExpr> {
+    auto it = value_map.find(var.get());
+    if (it != value_map.end()) return (*it).second;
+    return Optional<PrimExpr>(nullptr);
+  };
+  return Substitute(std::move(input), vmap);
+}
+
+/*!
+ * \brief Substitute the var specified by vmap and legalize data types after substitution.
+ * \param stmt The source statement to be substituted
+ * \param vmap returns a new value if re-mapping is needed, otherwise returns nullptr.
+ *
+ * Unlike `Substitute`, this allows the substitution to change the data type of the expression.
+ *
+ * \sa Substitute
+ * \return The result.
+ */
+TVM_DLL Stmt SubstituteWithDataTypeLegalization(Stmt stmt,
+                                                std::function<Optional<PrimExpr>(const Var&)> vmap);
+
+/*!
+ * \brief Substitute the var specified by vmap and legalize data types after substitution.
+ * \param expr The source statement to be substituted
+ * \param vmap returns a new value if re-mapping is needed, otherwise returns nullptr.
+ *
+ * Unlike `Substitute`, this allows the substitution to change the data type of the expression.
+ *
+ * \sa Substitute
+ * \return The result.
+ */
+TVM_DLL PrimExpr SubstituteWithDataTypeLegalization(
+    PrimExpr expr, std::function<Optional<PrimExpr>(const Var&)> vmap);
+
+/*!
+ * \brief Recursively visit the IR in pre DFS order node, apply fvisit.
+ * If fvisit returns false, it won't visit the children of the node.
+ * \param stmt_or_expr The ir to be visited.
+ * \param fvisit The visitor function to be applied. If fvisit returns false, it won't visit the
+ * children of the node
+ */
+TVM_DLL void PreOrderVisit(const ObjectRef& stmt_or_expr,
+                           const std::function<bool(const ObjectRef&)>& fvisit);
+
+/*!
+ * \brief Renew the definition nodes for a TIR, including Var, Buffer and IterVar.
+ *        This pass works as a simple DeepCopy to duplicate a function with different Vars and
+ *        Buffers but the same behavior
+ * \param func The input PrimFunc.
+ * \return The renewed func.
+ */
+TVM_DLL PrimFunc RenewDefs(const PrimFunc& func);
+
+/*!
+ * \brief Check if the statement contains the specified node type.
+ *
+ * This utility potentially walks the entire statement, and should
+ * therefore not be used if it could otherwise be merged with another
+ * pass.
+ *
+ * \param stmt The statement to be searched
+ * \return Whether stmt contains Node
+ */
+template <typename Node, typename = std::enable_if_t<std::is_base_of_v<StmtNode, Node>>>
+bool ContainsNode(const Stmt& stmt) {
+  struct Visitor : StmtVisitor {
+    // Early bail-out, if we already found the node.
+    void VisitStmt(const Stmt& stmt) final {
+      if (contains_node) {
+        return;
+      }
+      StmtVisitor::VisitStmt(stmt);
+    }
+
+    void VisitStmt_(const Node* block) override { contains_node = true; }
+
+    bool contains_node{false};
+  };
+
+  Visitor visitor;
+  visitor(stmt);
+  return visitor.contains_node;
+}
+
+}  // namespace tir
+}  // namespace tvm
+
+#endif  // TVM_TIR_STMT_FUNCTOR_H_
diff --git a/darknet_drp_ros/include/tvm/tir/transform.h b/darknet_drp_ros/include/tvm/tir/transform.h
new file mode 100644
index 0000000..4837256
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/transform.h
@@ -0,0 +1,703 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/tir/transform.h
+ * \brief TIR specific transformation passes.
+ */
+#ifndef TVM_TIR_TRANSFORM_H_
+#define TVM_TIR_TRANSFORM_H_
+
+#include <tvm/ir/transform.h>
+#include <tvm/target/target.h>
+#include <tvm/tir/expr.h>
+#include <tvm/tir/function.h>
+
+#include <string>
+#include <vector>
+
+namespace tvm {
+namespace tir {
+namespace transform {
+
+using tvm::transform::Pass;
+using tvm::transform::PassContext;
+using tvm::transform::PassContextNode;
+using tvm::transform::PassInfo;
+using tvm::transform::PassInfoNode;
+using tvm::transform::PassNode;
+using tvm::transform::Sequential;
+
+/*
+ * \brief Create a function pass that optimizes PrimFuncs.
+ *
+ * \param pass_func The packed function that contains the optimization.
+ * \param opt_level The optimization level of the function pass.
+ * \param name The name of the function pass.
+ * \param required The list of the passes that the function pass is dependent on.
+ *
+ * \return The created function pass.
+ */
+TVM_DLL Pass CreatePrimFuncPass(
+    const runtime::TypedPackedFunc<PrimFunc(PrimFunc, IRModule, PassContext)>& pass_func,
+    int opt_level, String name, tvm::Array<String> required);
+
+/*!
+ * \brief Inject prefetch instructions into stmt.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass InjectPrefetch();
+
+// TODO(tvm-team): consolidate configs to the PassContext
+/*!
+ * \brief Flatten the multi-dimensional read/write
+ *  to single dimensional Load/Store
+ *
+ * \param cache_line_size The size of CPU cache line.
+ * \param create_bound_attribute Whether to create bound attributes.
+ *
+ * \return The Pass
+ */
+TVM_DLL Pass StorageFlatten(int cache_line_size, bool create_bound_attribute = false);
+
+/*!
+ * \brief Inject copy intrinsics with optional pad.
+ *
+ * \param pragma_key The pragma key for hint of copy.
+ * \param fintrin The function with signature
+ *
+ *   Stmt fintrin(Buffer src,
+ *                Buffer dst,
+ *                Array<Expr> pad_before,
+ *                Array<Expr> pad_after,
+ *                Expr pad_value)
+ * \return The pass.
+ */
+TVM_DLL Pass InjectCopyIntrin(String pragma_key, runtime::PackedFunc fintrin);
+
+/*!
+ * \brief Detect and insert sync points to co-processor.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass CoProcSync();
+
+/*!
+ * \brief Lift common attrs with attr_key to outer scope.
+ *
+ * \param attr_key The attribute key to be checked.
+ * \return The pass.
+ */
+TVM_DLL Pass LiftAttrScope(String attr_key);
+
+/*!
+ * \brief partition loops in the stmt.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass LoopPartition();
+
+/*!
+ * \brief Lower vectorization loops.
+ *
+ * \param enable_vectorize Whether vectorization is enabled.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass VectorizeLoop(bool enable_vectorize = true);
+
+/*!
+ * \brief Inject virtual thread loops.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass InjectVirtualThread();
+
+/*!
+ * \brief Inject double buffer statements.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass InjectDoubleBuffer();
+
+/*!
+ * \brief Rewrite storage allocation pattern.
+ *  Moves the allocation to outer most possible scope.
+ *  Trying to share space between allocations to make
+ *  a static allocation plan when possible.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass StorageRewrite();
+
+/*!
+ * \brief unroll the constant loop marked by unroll.
+ * This pass also automatically attach pragma unroll tag to loops which meets the standard.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass UnrollLoop();
+
+/*!
+ * \brief Remove No Op from the Stmt.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass RemoveNoOp();
+
+/*!
+ * \brief Detect and rewrite unsafe select that contains memory access.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass RewriteUnsafeSelect();
+
+/*!
+ * \brief Run arithmetic simplifications on the statements and expressions.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass Simplify();
+
+/*!
+ * \brief Instruments bound checkers.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass InstrumentBoundCheckers();
+
+/*!
+ * \brief Transform the high-level PrimFunc to a low-level version
+ *        that can be used as an API function.
+ *
+ *
+ *  The main task of this function is to create code to :
+ *   - Map the values in the api_args to Var that is required by body.
+ *   - Insert assertions to check type/value of the passed arguments.
+ *
+ * \note
+ *  The function signature have two cases
+ *
+ *  let num_packed_args = len(api_args);
+ *
+ *  if num_packed_args is zero:
+ *     f()
+ *
+ *  if num_packed_args is not zero:
+ *       f(TVMArg* packed_args, int* packed_arg_type_ids, int num_packed_args,
+ *         api_arg_k, api_arg_k+1, ... api_arg_n,
+ *         TVMValue* out_ret_val, int* out_ret_tcode)
+ *
+ *       where n == len(api_args), k == num_packed_args
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass MakePackedAPI();
+
+/*!
+ * \brief Transform the high-level PrimFunc to a C signature that can be used
+ *   to call the operator directly.
+ *
+ *  The main task of this function is to create code that maps the values in the
+ *  api_args to Var that is required by body
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass MakeUnpackedAPI();
+
+/*!
+ * \brief Remap the thread axis
+ *
+ *  This can be used to get equivalent program which uses
+ *  threadIdx.y in place of threadIdx.x by passing
+ *  {"threadIdx.x": thread_axis("threadIdx.y")}
+ *
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass RemapThreadAxis(Map<String, IterVar> axis_map);
+
+/*!
+ * \brief Lower custom datatypes.
+ *
+ * See tvm::datatypes::Registry for more information on adding custom datatypes.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass LowerCustomDatatypes();
+
+/*!
+ * \brief Decorate all the function's body as device function.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass DecorateDeviceScope();
+
+/*!
+ * \brief Split the function into a host function and device functions.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass SplitHostDevice();
+
+/*!
+ * \brief skip assert stmt.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass SkipAssert();
+
+/*!
+ * \brief Insert sync between parallel read/write of shared buffers.
+ *
+ * \param storage_scope The storage scope considered.
+ * \return The pass.
+ */
+TVM_DLL Pass ThreadSync(String storage_scope);
+
+/*!
+ * \brief Lower cross thread alleduce.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass LowerThreadAllreduce();
+
+/*!
+ * \brief Infer the TensorCore fragment infomation using tensor intrinsics
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass InferFragment();
+
+/*!
+ * \brief This annotation is for nodes to be disabled for builtin lowering
+ */
+static constexpr const char* kDisableLowerTVMBuiltin = "disable_lower_builtin";
+
+/*!
+ * \brief Lower builtin intrinsics.
+ * \return The pass.
+ */
+TVM_DLL Pass LowerTVMBuiltin();
+
+/*!
+ * \brief Lower the target specific function intrinsics in each of the function.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass LowerIntrin();
+
+/*!
+ * \brief Lower warp memory access to low-level device related function calls.
+ * \return The pass.
+ */
+TVM_DLL Pass LowerWarpMemory();
+
+/*!
+ * \brief Lower attached storage access information on device.
+ *
+ * \note Run this pass after all storage access analysis finish.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass LowerDeviceStorageAccessInfo();
+
+/*!
+ * \brief Combine context calls in the host function.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass CombineContextCall();
+
+/*!
+ * \brief Narrow down PrimExpr datatype in stmt to target_bits.
+ *
+ * \param target_bits The target bits
+ *
+ * \note Run this pass after storage flatten.
+ * \return The pass.
+ */
+TVM_DLL Pass NarrowDataType(int target_bits);
+
+/*!
+ * \brief Legalize bf16 typed Ops. Add a cast to fp32
+ *   before Ops, then add a cast back to bf16.
+ * \return The pass.
+ */
+TVM_DLL Pass BF16Legalize();
+
+/*!
+ * \brief Rewrite the pointer content type of arguments,
+ *  as well as Alloc internal to the function to use
+ *  the most frequently accessed type for load/store
+ *  to avoid pointer casting in backend when possible.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass PointerValueTypeRewrite();
+
+/*!
+ * \brief Hoist loop-invariant IfThenElse nodes to
+ * outside the elligible loops.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass HoistIfThenElse();
+
+/*!
+ * \brief Hoist loop-invariant expressions nodes to
+ * outside the elligible loops.
+ *
+ * Can hoist conditionals used in IfThenElse statements and
+ * expressions, bindings of variables in Let statements and
+ * expressions, or boolean expressions, configurable to enable/disable
+ * each hoistable type.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass HoistExpression();
+
+/*!
+ * \brief Lower cross-thread reduction from thread
+ * bindings to intrinsic function calls.
+ * \return The pass.
+ */
+TVM_DLL Pass LowerCrossThreadReduction();
+
+/*!
+ * \brief Lower block init stmt into IfThenElse stmts
+ * \return The pass.
+ */
+TVM_DLL Pass LowerInitBlock();
+
+/*!
+ * \brief Locate the buffer allocation to the exact position (usually is
+ *        the lca of buffer access). This pass will inject opaque block
+ *        with alloc_buffers at the allocation site.
+ * \return The pass.
+ */
+TVM_DLL Pass PlanAndUpdateBufferAllocationLocation();
+
+/*!
+ * \brief Substitute all the block vars with the PrimExprs they are bound to, indicated by the
+ *        corresponding iter_values in BlockRealize, for opaque blocks by removing all
+ *.        the iter_values in BlockRealize and iter_vars in Block.
+ * \return The pass.
+ */
+TVM_DLL Pass ConvertBlocksToOpaque();
+
+/*!
+ * \brief Compact the buffer access region by removing the buffer regions that are not accessed,
+ *        i.e. narrowing the buffer shape and adjust the access region if necessary.
+ *
+ * Before narrowing, `B` is a `[16, 16]` buffer, but only a skinny vector `B[i, 0:16]` is accessed.
+ *
+ *  \code
+ *
+ *  for i in range(0, 16):
+ *      with T.block():
+ *          B = T.alloc_buffer(16, 16)
+ *          for j in range(0, 16):
+ *              B[i, j] = A[i, j] + 1
+ *          for j in range(0, 16):
+ *              C[i, j] = B[i, j] + 1
+ *
+ *  \endcode
+ *
+ * This pass narrows the buffer shape and adjust its accessed region accordingly.
+ * In this particular case, because only a `1 * 16` vector of `B` is accessed,
+ * the pass narrows `B` to shape `[1, 16]`, and changes the access to `B[i, j]` to `B[0, j]`.
+ *
+ *  \code
+ *
+ *  for i in range(0, 16):
+ *      with T.block():
+ *          B = T.alloc_buffer(1, 16)
+ *          for j in range(0, 16):
+ *              B[0, j] = A[i, j] + 1
+ *          for j in range(0, 16):
+ *              C[i, j] = B[0, j] + 1
+ *
+ *  \endcode
+ *
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass CompactBufferAllocation();
+
+/*!
+ * This pass legalizes packed calls by wrapping their arguments into TVMValues
+ */
+TVM_DLL Pass LegalizePackedCalls();
+
+/*!
+ * \brief Remove match buffers inside the block. Also, it will validate the binding.
+ * \return The pass.
+ */
+TVM_DLL Pass LowerMatchBuffer();
+
+/*!
+ * \brief Remove the block to ensure that the TIR can not be scheduled again.
+ * \return The pass.
+ */
+TVM_DLL Pass LowerOpaqueBlock();
+
+/*!
+ * \brief Flatten the multi-dimensional BufferLoad and BufferStore to single dimensional
+ *        BufferLoad/BufferStore for the TIR not contains opaque block.
+ * \return The pass.
+ */
+TVM_DLL Pass FlattenBuffer();
+
+/*
+ * \brief Flatten the multi-dimensional read/write
+ *  to two dimensional texture Load/Store and realize
+ *  texture buffer allocations.
+ *
+ * \return The Pass
+ */
+TVM_DLL Pass TextureFlatten();
+
+/*
+ * \brief Lower VTCM allocations
+ *
+ * \return The Pass
+ */
+TVM_DLL Pass LowerVtcmAlloc();
+
+/*!
+ * \brief Lower Async TIR primitives to DMA copy and wait builtins
+ */
+TVM_DLL Pass LowerAsyncDMA();
+
+/*!
+ * \brief Implements a Common Subexpression Elimination (CSE) for TIR
+ *        which introduces let-in bindings for duplicated sub-expressions.
+ * \param enable_cse_tir Whether common subexpression elimination is enabled.
+ * \param identify_equiv_terms Whether equivalent terms should be identified.
+ * \return The pass.
+ */
+TVM_DLL Pass CommonSubexprElimTIR(bool enable_cse_tir = true, bool identify_equiv_terms = false);
+
+/*!
+ * \brief Unify all the thread bindings for "blockIdx.x/y/z", "threadIdx.x/y/z", and
+ *        "vthread.x/y/z". Before the unification, two vars that are bound to a thread axis (e.g.,
+ *        "threadIdx.x") use different IterVars and variables in their AttrStmts. After the
+ *        unification, we use a consolidated IterVar and a variable for them.
+ * \return The pass.
+ * \note `vthread` is a legacy behavior that will be deprecated, though thread bindings of `vthread`
+ *       are still also unified in this pass. Please use `vthread.x`, `vthread.y` and `vthread.z`
+ *       instead.
+ */
+TVM_DLL Pass UnifyThreadBinding();
+
+/*!
+ *  A pass to merge multiple TIR-level dynamic shared memory allocations into one
+ */
+TVM_DLL Pass MergeDynamicSharedMemoryAllocations();
+
+/*!
+ * \brief This pass is post-scheduling pass to convert all
+ *        Parallel For loops to Serial ones. This is run
+ *        to attain lesser memory and/or executor/backend
+ *        does not support parallel launch of For loops.
+ * \return The pass.
+ */
+TVM_DLL Pass ConvertForLoopsToSerial();
+
+/*!
+ * \brief This is the unified static memory planner pass that will
+ * plan for memory intra- and inter- PrimFuncs together. The pass
+ * requires all the function to be PrimFuncs including the main.
+ * \return The pass.
+ */
+TVM_DLL Pass UnifiedStaticMemoryPlanner();
+
+/*!
+ * \brief This pass transforms annotated loops into pipelined ones where producers and consumers
+ * are overlapped with the information provided in loop annotations, which enables optimization
+ * techniques like prefetching and pipeline parallelism.
+ *
+ * The pipeline scope consists of the direct children of the annotated loop (ignoring BlockRealize,
+ * Block, SeqStmt), and the number of children is denoted by `n` in the documentation.
+ *
+ * The following annotations are used to guide the loop transformation:
+ *
+ * 1) Loop annotation `software_pipeline_stage` defines the pipeline stage.
+ * An array of `n` integers, and each element should be in range [0, max_stage],
+ * where max_stage is the maximum (inclusive) stage.
+ * 2) Loop annotation `software_pipeline_order` defines the pipeline order.
+ * An array of `n` integers, a permutation of [0, 1, ..., num_components - 1];
+ * 3) Block annotation `double_buffer_scope` controls certain buffer sizes to allow decoupling of
+ * read/write dependency. It's an integer index of the write regions of the block.
+ *
+ * Every annotated loop is transformed into a loop with three blocks as its direct children:
+ *
+ * 1) Prologue block, where components whose stage is less than `max_stage` is executed;
+ *
+ * 2) Body block, where all the components are executed;
+ *
+ * 3) Epilogue block, where only components whose stage is greater than 0 will be executed.
+ * The execution order is controlled by the annotation `software_pipeline_order`,
+ * and thus could be different than the original order.
+ *
+ * Note: For nested software pipelines, the inner software pipeline will be generated first,
+ * which may affect the number of the direct children of the outer loop.
+ * In this case, the annotations for the outer software
+ * pipeline should include the result of the inner software pipeline,
+ * which is the three blocks as discussed above.
+ * Example:
+ *
+ * Before this pass, the TIR is:
+ *
+ * \code{.py}
+ * @T.prim_func
+ * def before_transform(A: T.Buffer[(16, 16), "float32"], C: T.Buffer[(16, 16), "float32"]) -> None:
+ *     for tx in T.thread_binding(0, 16, thread="threadIdx.x"):
+ *         for i in T.serial(0, 16,
+ *                           annotations={"software_pipeline_stage": [0, 1],
+ *                                        "software_pipeline_order": [0, 1]}
+ *                          ):
+ *             with T.block():
+ *                 T.reads(A[tx, i])
+ *                 T.writes(C[tx, i])
+ *                 B = T.alloc_buffer((16, 1), dtype="float32", scope="shared")
+ *                 with T.block("B"):
+ *                     T.reads(A[tx, i])
+ *                     T.writes(B[tx, 0])
+ *                     B[tx, 0] = A[tx, i] * T.float32(2)
+ *                 with T.block("C"):
+ *                     T.reads(B[tx, 0])
+ *                     T.writes(C[tx, i])
+ *                     C[tx, i] = B[tx, 0] + T.float32(1)
+ * \endcode
+ *
+ * The TIR above annotates the loop as a two-stage pipeline with no reordering.
+ * After applying this pass, the TIR is transformed into:
+ *
+ * \code{.py}
+ * @T.prim_func
+ * def after_transform(A: T.Buffer[(16, 16), "float32"], C: T.Buffer[(16, 16), "float32"]) -> None:
+ *     for tx in T.thread_binding(0, 16, thread="threadIdx.x"):
+ *         with T.block():
+ *             T.reads([A[tx, 0:16]])
+ *             T.writes([C[tx, 0:16]])
+ *             B = T.alloc_buffer([2, 16, 1], dtype="float32", scope="shared")
+ *             with T.block("prologue"):
+ *                 T.reads([A[tx, 0]])
+ *                 T.writes([B[0, tx, 0]])
+ *                 B[0, tx, 0] = A[tx, 0] * T.float32(2)
+ *             with T.block("body"):
+ *                 T.reads([A[tx, 1:16], B[0:2, tx, 0]])
+ *                 T.writes([B[0:2, tx, 0], C[tx, 0:15]])
+ *                 for i in T.serial(0, 15):
+ *                     with T.block("B"):
+ *                         T.reads([A[tx, i + 1]])
+ *                         T.writes([B[(i + 1) % 2, tx, 0]])
+ *                         B[(i + 1) % 2, tx, 0] = A[tx, i + 1] * T.float32(2)
+ *                     with T.block("C"):
+ *                         T.reads([B[i % 2, tx, 0]])
+ *                         T.writes([C[tx, i]])
+ *                         C[tx, i] = B[i % 2, tx, 0] + T.float32(1)
+ *             with T.block("epilogue"):
+ *                 T.reads([B[1, tx, 0]])
+ *                 T.writes([C[tx, 15]])
+ *                 C[tx, 15] = B[1, tx, 0] + T.float32(1)
+ * \endcode
+ *
+ * The original loop has two blocks, B and C, as its direct children. The loop annotations indicate
+ * that block B has stage == 0, order == 0, block C has stage == 1, order == 1. Therefore, block B
+ * should be executed in advance of block C by one iteration. The order 0 and 1 specifies the order
+ * of block B and C inside the body block inside the result TIR.
+ *
+ * \return The IR transform pass.
+ */
+TVM_DLL Pass InjectSoftwarePipeline();
+
+TVM_DLL Pass BindParams(const Array<runtime::NDArray>& constants);
+
+/*!
+ * \brief Pass to collect tir non-scalar constants into module's 'Constants' attribute.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass ExtractPrimFuncConstants();
+
+/*!
+ * \brief Renormalize the split pattern from floordiv(floormod()) to floormod(floordiv())
+ * \return The pass.
+ */
+TVM_DLL Pass RenormalizeSplitPattern();
+
+/*!
+ * \brief Annotate a PrimFunc with a given target.
+ * \return The pass.
+ */
+TVM_DLL Pass BindTarget(Target target);
+
+/*!
+ * \brief Set a PrimFunc as the entry point if it is only function in IRModule.
+ * \return The pass.
+ */
+TVM_DLL Pass AnnotateEntryFunc();
+
+/*!
+ * \brief Filter PrimFuncs with a given condition.
+ * \return The pass.
+ */
+TVM_DLL Pass Filter(runtime::TypedPackedFunc<bool(PrimFunc)> fcond);
+
+/*!
+ * \brief Pass to rewrite global to shared memory copy on CUDA with asyncronous copy.
+ * \return The pass.
+ */
+TVM_DLL Pass InjectPTXAsyncCopy();
+
+/*!
+ * \brief Remove the weight layout rewrite block
+ * \param skip_ndarray_rewrite If True, exact rewrite of NDArray, according to the given index map,
+ *  will be skipped. Only the shape of the NDArray is transformed correctly, and the content of
+ *  the destination array will be filled with random values.
+ *
+ *  When this pass is called many times during MetaSchedule tuning, the raw data of NDArray,
+ *  before and after rewrite, does not matter. Since NDArray layout rewrite, using IndexMap's
+ *  MapNDArray, is currently slow, skipping the exact rewrite is sometimes necessary.
+ *
+ * \return The pass.
+ */
+TVM_DLL Pass RemoveWeightLayoutRewriteBlock(bool skip_ndarray_rewrite = false);
+
+/*!
+ * \brief Add the explicit local stage for the shared memory access on GPU.
+ * \return The pass.
+ */
+TVM_DLL Pass ManifestSharedMemoryLocalStage();
+
+/*!
+ * \brief Insert intrinsic calls to instrument function and loop level profiling.
+ * \return The pass.
+ */
+TVM_DLL Pass InstrumentProfileIntrinsics();
+
+}  // namespace transform
+}  // namespace tir
+}  // namespace tvm
+
+#endif  // TVM_TIR_TRANSFORM_H_
diff --git a/darknet_drp_ros/include/tvm/tir/usmp/algo/greedy.h b/darknet_drp_ros/include/tvm/tir/usmp/algo/greedy.h
new file mode 100644
index 0000000..8f0ed87
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/usmp/algo/greedy.h
@@ -0,0 +1,85 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file include/tvm/tir/usmp/algo/greedy.h
+ * \brief This header file contains helper methods used in greedy algorithms
+ * for planning  memory for USMP
+ */
+#pragma once
+#include <tvm/arith/analyzer.h>
+#include <tvm/runtime/device_api.h>
+#include <tvm/tir/builtin.h>
+#include <tvm/tir/function.h>
+#include <tvm/tir/stmt_functor.h>
+#include <tvm/tir/usmp/utils.h>
+
+#include <unordered_map>
+#include <vector>
+
+namespace tvm {
+namespace tir {
+namespace usmp {
+namespace algo {
+
+/*!
+ * \brief This is the base class for Greedy Algorithms where the sorting
+ * is specialized in the extended classes based on the greedy criteria.
+ */
+class GreedyBase {
+ public:
+  GreedyBase() {}
+  /*!
+   * \brief This function should be implemented by the extended classes to sort the BufferInfo
+   * objects based on a criteria and then calling PostSortAllocation.
+   */
+  virtual Map<BufferInfo, PoolAllocation> PlanMemory(const Array<BufferInfo>& buffer_info_arr) = 0;
+
+ protected:
+  /*!
+   * \brief Rounds up the offset to satisfy the alignement requirement
+   */
+  size_t round_up_to_byte_alignment(const size_t& non_aligned_byte_offset,
+                                    const int& byte_alignment);
+
+  /*!
+   * \brief A helper function check whether a offset is valid given the constraints
+   */
+  bool IsValidPlacement(const PoolInfo& candidate_pool, const size_t& next_offset,
+                        const size_t& size_bytes);
+
+  /*!
+   * \brief Selects a pool for placement in the given set of ordered pool candidates
+   */
+  PoolInfo SelectPlacementPool(
+      const BufferInfo& buf_info,
+      const std::unordered_map<PoolInfo, size_t, ObjectPtrHash, ObjectPtrEqual>& pool_offsets);
+
+  /*!
+   * \brief This is the base allocation function that works on sorted BufferInfo objects based
+   * on the greedy heuristic. The sorting algorithm has to be called before calling this.
+   */
+  Map<BufferInfo, PoolAllocation> PostSortAllocation(
+      const std::vector<BufferInfo>& buffer_info_vec);
+};
+
+}  // namespace algo
+}  // namespace usmp
+}  // namespace tir
+}  // namespace tvm
diff --git a/darknet_drp_ros/include/tvm/tir/usmp/algorithms.h b/darknet_drp_ros/include/tvm/tir/usmp/algorithms.h
new file mode 100644
index 0000000..54431b5
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/usmp/algorithms.h
@@ -0,0 +1,84 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tir/usmp/algorithms.h
+ * \brief The memory planning algorithm for USMP
+ */
+
+#ifndef TVM_TIR_USMP_ALGORITHMS_H_
+#define TVM_TIR_USMP_ALGORITHMS_H_
+
+#include <tvm/tir/usmp/utils.h>
+
+namespace tvm {
+namespace tir {
+namespace usmp {
+namespace algo {
+
+/*!
+ * \brief The Greedy-by-Size algorithm to plan memory
+ *
+ * This will perform a greedy algorithm in deciding the offsets
+ * within provided Pools, using the size of the buffer.
+ *
+ * \return A Map of BufferInfo objects and their associated PoolAllocation
+ */
+Map<BufferInfo, PoolAllocation> GreedyBySize(const Array<BufferInfo>& buffer_info_arr,
+                                             const Integer& memory_pressure);
+
+/*!
+ * \brief The Greedy-by-Conflicts algorithm to plan memory
+ *
+ * This will perform a greedy algorithm in deciding the offsets
+ * within provided Pools, using the number of liveness conflicts of the buffer.
+ *
+ * \return A Map of BufferInfo objects and their associated PoolAllocation
+ */
+Map<BufferInfo, PoolAllocation> GreedyByConflicts(const Array<BufferInfo>& buffer_info_arr,
+                                                  const Integer& memory_pressure);
+/*!
+ *\brief The Hill-Climb algoritm to plan memory
+ *
+ * This will perform an attempt to utilize probabalistic approach to memory
+ * allocation. Typically better than greedy family, but quite slow due to large
+ * number of iterations.
+ *
+ * \return A Map of BufferInfo objects and their associated PoolAllocation
+ */
+Map<BufferInfo, PoolAllocation> HillClimb(const Array<BufferInfo>& buffer_info_arr,
+                                          const Integer& memory_pressure);
+
+/*!
+ * \brief The Hill-Climb algorithm to plan memory
+ *
+ * This will perform a hill climbing algorithm in deciding the offsets
+ * within provided Pools.
+ *
+ * \return A Map of BufferInfo objects and their associated PoolAllocation
+ */
+Map<BufferInfo, PoolAllocation> HillClimb(const Array<BufferInfo>& buffer_info_arr,
+                                          const Integer& memory_pressure);
+
+}  // namespace algo
+}  // namespace usmp
+}  // namespace tir
+}  // namespace tvm
+
+#endif  // TVM_TIR_USMP_ALGORITHMS_H_
diff --git a/darknet_drp_ros/include/tvm/tir/usmp/analysis.h b/darknet_drp_ros/include/tvm/tir/usmp/analysis.h
new file mode 100644
index 0000000..a24851d
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/usmp/analysis.h
@@ -0,0 +1,49 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tir/usmp/analysis.h
+ * \brief The analysis passes for TIR-based Unified Static Memory Planner
+ */
+
+#ifndef TVM_TIR_USMP_ANALYSIS_H_
+#define TVM_TIR_USMP_ANALYSIS_H_
+
+#include <tvm/tir/function.h>
+#include <tvm/tir/usmp/utils.h>
+
+namespace tvm {
+namespace tir {
+namespace usmp {
+
+/*!
+ * \brief Extract BufferInfo objects from a TIR IRModule
+ *
+ * This pass would extract the buffer information of allocate nodes
+ * including liveness conflict with other buffer info objects.
+ *
+ * \return A Map of BufferInfo objects and their associated Stmts
+ */
+BufferInfoAnalysis ExtractBufferInfo(const PrimFunc& main_func, const IRModule& mod);
+
+}  // namespace usmp
+}  // namespace tir
+}  // namespace tvm
+
+#endif  // TVM_TIR_USMP_ANALYSIS_H_
diff --git a/darknet_drp_ros/include/tvm/tir/usmp/transform.h b/darknet_drp_ros/include/tvm/tir/usmp/transform.h
new file mode 100644
index 0000000..ccb6844
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/usmp/transform.h
@@ -0,0 +1,75 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tir/usmp/transform.h
+ * \brief The transform passes for TIR-based Unified Static Memory Planner
+ */
+
+#ifndef TVM_TIR_USMP_TRANSFORM_H_
+#define TVM_TIR_USMP_TRANSFORM_H_
+
+#include <tvm/tir/usmp/utils.h>
+
+namespace tvm {
+namespace tir {
+namespace usmp {
+namespace transform {
+
+using Pass = tvm::transform::Pass;
+
+/*!
+ * \brief Convert the analyzed PoolAllocation to offsets from pool variables
+ *
+ * This pass would convert the main function to accept pool variables as an input
+ * that get passed onto the operator PrimFuncs. Furthermore, the static allocations
+ * will be converted to offsets within the pool variable.
+ *
+ * \return the pass
+ */
+TVM_DLL Pass ConvertPoolAllocationsToOffsets(const Map<tir::Stmt, PoolAllocation>& pool_allocations,
+                                             Bool emit_tvmscript_printable = Bool(false));
+
+/*!
+ * \brief Assign PoolInfo objects to tir.allocate nodes depending on the PrimFunc's target
+ *
+ * This pass would assign default PoolInfo objects to allocate nodes that are not otherwise
+ * annotated, depending on pool info supplied for each target.
+ *
+ * \return the pass
+ */
+TVM_DLL Pass AssignPoolInfo();
+
+/*!
+ * \brief This pass creates Allocate nodes for I/O tensors
+ *
+ * If the user wants to place the I/O tensors in the workspace, this pass is required to be
+ * run. In doing so, it will create Allocate nodes for I/O tensors to be planned, and be removed
+ * from function arguments.
+ *
+ * \return the pass
+ */
+TVM_DLL Pass CreateAllocatesForIO();
+
+}  // namespace transform
+}  // namespace usmp
+}  // namespace tir
+}  // namespace tvm
+
+#endif  // TVM_TIR_USMP_TRANSFORM_H_
diff --git a/darknet_drp_ros/include/tvm/tir/usmp/utils.h b/darknet_drp_ros/include/tvm/tir/usmp/utils.h
new file mode 100644
index 0000000..59430ee
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/usmp/utils.h
@@ -0,0 +1,325 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tir/usmp/utils.h
+ * \brief Utilities for Unified Static Memory Planner
+ */
+
+#ifndef TVM_TIR_USMP_UTILS_H_
+#define TVM_TIR_USMP_UTILS_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/ir/memory_pools.h>
+#include <tvm/runtime/device_api.h>
+#include <tvm/target/target.h>
+#include <tvm/tir/stmt.h>
+
+namespace tvm {
+
+/*!
+ * \brief PassContext option to enable the USMP
+ */
+constexpr const char* kUSMPEnableOption = "tir.usmp.enable";
+/*!
+ * \brief PassContext option to select the memory planning algorithm in USMP
+ */
+constexpr const char* kUSMPAlgorithmOption = "tir.usmp.algorithm";
+/*!
+ * \brief PassContext option to enable placing I/O tensors in the workspace
+ */
+constexpr const char* kUSMPUseWorkspaceIO = "tir.usmp.use_workspace_io";
+/*!
+ * \brief PassContext option to specify a custom memory planning algorithm in USMP.
+ * The algorithm should be provided as registered PackedFunc with the name tir.usmp.algorithm.NAME
+ */
+constexpr const char* kUSMPCustomAlgorithmOption = "tir.usmp.custom_algorithm";
+
+namespace tir {
+namespace usmp {
+/*!
+ * \brief A special kind to distinguish between I/O tensors to the model
+ * and intermediate tensors of the model
+ */
+enum class BufferInfoKind { kIntermediate = 0, kInput = 1, kOutput = 2 };
+
+/*!
+ * \brief Describes an abstract memory buffer that will get allocated inside a pool.
+ * The actual memory buffer in represented by PoolAllocationNode after static memory planning.
+ *
+ * See also for relay-level counterparts:
+ * relay::StorageToken (graph_plan_memory.cc)
+ * relay::backend::StorageInfoNode (relay/backend/utils.h)
+ * Region (python/tvm/relay/transform/memory_plan.py)
+ */
+struct BufferInfoNode : public Object {
+  /*! \brief The name of the buffer var */
+  String name_hint;
+  /*! \brief The size in terms of bytes */
+  Integer size_bytes;
+  /*! \brief The pool candidates that this buffer can get pooled to*/
+  Array<PoolInfo> pool_candidates;
+  /*! \brief The byte alignment required for buffers that will placed within the pool */
+  Integer alignment;
+  /*! \brief The liveness conflicting other buffer info objects */
+  Array<ObjectRef> conflicts;
+  /*! \brief Whether BufferInfo object retains info about IO tensors or intermediaries */
+  BufferInfoKind kind;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("name_hint", &name_hint);
+    v->Visit("size_bytes", &size_bytes);
+    v->Visit("pool_candidates", &pool_candidates);
+    v->Visit("alignment", &alignment);
+    v->Visit("conflicts", &conflicts);
+    v->Visit("kind", &kind);
+  }
+
+  bool SEqualReduce(const BufferInfoNode* other, SEqualReducer equal) const {
+    return equal(name_hint, other->name_hint) && equal(size_bytes, other->size_bytes) &&
+           equal(pool_candidates, other->pool_candidates) && equal(alignment, other->alignment) &&
+           equal(conflicts, other->conflicts) && equal(kind, other->kind);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(name_hint);
+    hash_reduce(size_bytes);
+    hash_reduce(alignment);
+    hash_reduce(conflicts);
+    hash_reduce(pool_candidates);
+    hash_reduce(kind);
+  }
+  /*!
+   * \brief Set the liveness conflicts of this BufferInfo
+   *
+   * \param conflicting_buffer_info_objs An array of BufferInfo that conflicts in liveness
+   */
+  TVM_DLL void SetConflicts(Array<ObjectRef> conflicting_buffer_info_objs);
+
+  static constexpr const char* _type_key = "tir.usmp.BufferInfo";
+  TVM_DECLARE_FINAL_OBJECT_INFO(BufferInfoNode, Object);
+};
+
+class BufferInfo : public ObjectRef {
+ public:
+  TVM_DLL BufferInfo(String name_hint, Integer size_bytes, Array<PoolInfo> pool_candidates,
+                     Integer alignment = runtime::kDefaultWorkspaceAlignment,
+                     BufferInfoKind kind = BufferInfoKind::kIntermediate);
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(BufferInfo, ObjectRef, BufferInfoNode);
+};
+
+/*!
+ * \brief This is a composite node that is produced by extract_buffer_info
+ * analysis pass that contains useful global information that could be useful
+ * for memory planning algorithms.
+ */
+struct BufferInfoAnalysisNode : public Object {
+  /*! \brief The BufferInfo object and its associated TIR statement */
+  Map<BufferInfo, tir::Stmt> buffer_info_stmts;
+  /*! \brief This represent maximum amount of memory being used at
+   * any point of time in the inference. This value is largely the
+   * best allocation an algorithm could achieve. Due to
+   * the complexities of conflict graphs, it would not be feasible
+   * to achieve this value, practically. However, it can be useful
+   * for iterative algorithms to know this value to define termination
+   * criteria.*/
+  Integer memory_pressure;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("buffer_info_stmts", &buffer_info_stmts);
+    v->Visit("memory_pressure", &memory_pressure);
+  }
+
+  bool SEqualReduce(const BufferInfoAnalysisNode* other, SEqualReducer equal) const {
+    return equal(buffer_info_stmts, other->buffer_info_stmts) &&
+           equal(memory_pressure, other->memory_pressure);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(buffer_info_stmts);
+    hash_reduce(memory_pressure);
+  }
+};
+
+class BufferInfoAnalysis : public ObjectRef {
+ public:
+  TVM_DLL BufferInfoAnalysis(Map<BufferInfo, tir::Stmt> buffer_info_stmts, Integer memory_pressure);
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(BufferInfoAnalysis, ObjectRef, BufferInfoAnalysisNode);
+};
+
+/*!
+ * \brief The pool allocation produced after the USMP algorithm
+ */
+struct PoolAllocationNode : public Object {
+  /*! \brief The assigned WorkspacePoolInfo or ConstantPoolInfo object */
+  PoolInfo pool_info;
+  /*! \brief The byte offset within the pool*/
+  Integer byte_offset;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("pool_info", &pool_info);
+    v->Visit("byte_offset", &byte_offset);
+  }
+
+  bool SEqualReduce(const PoolAllocationNode* other, SEqualReducer equal) const {
+    return equal(pool_info, other->pool_info) && equal(byte_offset, other->byte_offset);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(pool_info);
+    hash_reduce(byte_offset);
+  }
+
+  static constexpr const char* _type_key = "tir.usmp.PoolAllocation";
+  TVM_DECLARE_FINAL_OBJECT_INFO(PoolAllocationNode, Object);
+};
+
+class PoolAllocation : public ObjectRef {
+ public:
+  TVM_DLL PoolAllocation(PoolInfo pool_info, Integer byte_offset);
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(PoolAllocation, ObjectRef, PoolAllocationNode);
+};
+
+/*!
+ * \brief This object contains information post-allocation for PoolInfo objects
+ */
+struct AllocatedPoolInfoNode : public Object {
+  /*! \brief The assigned PoolInfo object */
+  PoolInfo pool_info;
+  /*! \brief The allocated size into this pool */
+  Integer allocated_size;
+  /*! \brief An optional associated pool Var index of PrimFunc params*/
+  Optional<Integer> pool_var_idx;
+
+  void VisitAttrs(tvm::AttrVisitor* v) {
+    v->Visit("pool_info", &pool_info);
+    v->Visit("allocated_size", &allocated_size);
+    v->Visit("pool_var_idx", &pool_var_idx);
+  }
+
+  bool SEqualReduce(const AllocatedPoolInfoNode* other, SEqualReducer equal) const {
+    return equal(pool_info, other->pool_info) && equal(allocated_size, other->allocated_size) &&
+           equal(pool_var_idx, other->pool_var_idx);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(pool_info);
+    hash_reduce(allocated_size);
+    hash_reduce(pool_var_idx);
+  }
+
+  static constexpr const char* _type_key = "tir.usmp.AllocatedPoolInfo";
+  TVM_DECLARE_FINAL_OBJECT_INFO(AllocatedPoolInfoNode, Object);
+};
+
+class AllocatedPoolInfo : public ObjectRef {
+ public:
+  TVM_DLL AllocatedPoolInfo(PoolInfo pool_info, Integer allocated_size,
+                            Integer pool_var_idx = Integer());
+  TVM_DEFINE_MUTABLE_OBJECT_REF_METHODS(AllocatedPoolInfo, ObjectRef, AllocatedPoolInfoNode);
+};
+
+/*!
+ * \brief Convert the IR-bound BufferInfo map to an array of BufferInfo
+ *
+ * \param buffer_info_map IR-bound BufferInfo map
+ */
+Array<BufferInfo> ConvertToArrayOfBufferInfo(const Map<BufferInfo, Stmt>& buffer_info_map);
+
+/*!
+ * \brief Calculate workspace required to execute a IRModule with main expressed in TIR
+ *
+ * \param mod the IRModule with TIR-based main function
+ */
+Integer CalculateModuleWorkspaceSize(const IRModule& mod);
+
+/*!
+ * \brief The allocate node attribute to indicate candidate memory pools.
+ * This needs to be kept in sync with CANDIDATE_MEMORY_POOL_ATTR in
+ * python/tvm/tir/usmp/utils.py.
+ */
+static constexpr const char* kPoolCandidatesAllocateAttr = "candidate_memory_pools";
+
+/*!
+ * \brief The allocate node attribute to indicate it is being used to hold
+ * an input tensor, that needs to be initialized with.
+ */
+static constexpr const char* kInputTensorAllocate = "input_tensor";
+
+/*!
+ * \brief The allocate node attribute to indicate it is being used to hold
+ * an output tensor.
+ */
+static constexpr const char* kOutputTensorAllocate = "output_tensor";
+
+/*!
+ * \brief Calculate the size of the extents in bytes
+ *
+ * \param op the allocate node
+ */
+Integer CalculateExtentsSize(const AllocateNode* op);
+
+/*!
+ * \brief Calculate the size of the extents in bytes
+ *
+ * \param op the allocate const node
+ */
+Integer CalculateExtentsSize(const AllocateConstNode* op);
+
+/*!
+ * \brief Joins the Stmt nodes with PoolAllocation objects
+ *
+ * \param buffer_info_to_stmt the map of BufferInfo objects to Stmt nodes
+ * \param buffer_info_to_pool_allocation the map of BufferInfo objects to PoolAllocation objects
+ */
+Map<Stmt, PoolAllocation> AssignStmtPoolAllocations(
+    const Map<BufferInfo, Stmt>& buffer_info_to_stmt,
+    const Map<BufferInfo, PoolAllocation>& buffer_info_to_pool_allocation);
+
+/*!
+ * \brief Obtains I/O tensor names to their PoolAllocation objects
+ *
+ * \param buffer_info_to_pool_allocation the map of BufferInfo objects to PoolAllocation objects
+ *
+ * This function will obtain pool allocations for I/O tensors if that had been planned
+ */
+Map<String, PoolAllocation> GetIOPoolAllocations(
+    const Map<BufferInfo, PoolAllocation>& buffer_info_to_pool_allocation);
+
+}  // namespace usmp
+}  // namespace tir
+
+namespace attr {
+/*!
+ * \brief This is a BaseFunc attribute to indicate which input var represent
+ * a PoolInfo Object in the form of a Map<Var, PoolInfo>.
+ */
+static constexpr const char* kPoolArgs = "pool_args";
+
+/*!
+ * \brief This is a IRModule attribute that contains I/O Tensor names to pool
+ * allocations.
+ */
+static constexpr const char* kIOTensorPoolAllocations = "io_tensor_pool_allocations";
+
+}  // namespace attr
+
+}  // namespace tvm
+
+#endif  // TVM_TIR_USMP_UTILS_H_
diff --git a/darknet_drp_ros/include/tvm/tir/var.h b/darknet_drp_ros/include/tvm/tir/var.h
new file mode 100644
index 0000000..0dadd3d
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/tir/var.h
@@ -0,0 +1,342 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tvm/tir/var.h
+ * \brief Variables in the TIR.
+ */
+#ifndef TVM_TIR_VAR_H_
+#define TVM_TIR_VAR_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/node/node.h>
+#include <tvm/runtime/data_type.h>
+
+#include <string>
+
+namespace tvm {
+namespace tir {
+
+/*!
+ * \brief A variable node in the IR.
+ *
+ * A variable is uniquely identified by its address.
+ *
+ * Each variable is only bound once in the following nodes:
+ * - Allocate
+ * - For
+ * - Let
+ * - LetStmt
+ */
+class VarNode : public PrimExprNode {
+ public:
+  /*!
+   * \brief The hint to the variable name.
+   * \note Each variable is uniquely identified by its address.
+   */
+  String name_hint;
+  /*!
+   * \brief type annotation of the variable.
+   *
+   * It is an optional field that provides a refined type of the variable than dtype.
+   *
+   * \sa tvm/ir/type.h for discussion of relations between runtime::DataType and Type.
+   */
+  Type type_annotation;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dtype", &dtype);
+    v->Visit("name", &name_hint);
+    v->Visit("type_annotation", &type_annotation);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const VarNode* other, SEqualReducer equal) const {
+    if (!equal(dtype, other->dtype)) return false;
+    if (!equal(type_annotation, other->type_annotation)) return false;
+    return equal.FreeVarEqualImpl(this, other);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dtype);
+    hash_reduce(type_annotation);
+    hash_reduce.FreeVarHashImpl(this);
+  }
+
+  static constexpr const char* _type_key = "tir.Var";
+  static constexpr const uint32_t _type_child_slots = 1;
+  TVM_DECLARE_BASE_OBJECT_INFO(VarNode, PrimExprNode);
+};
+
+/*! \brief a named variable in TIR */
+class Var : public PrimExpr {
+ public:
+  explicit Var(ObjectPtr<Object> n) : PrimExpr(n) {}
+  /*!
+   * \brief Constructor
+   * \param name_hint variable name
+   * \param dtype data type
+   * \param span The location of this object in the source code.
+   */
+  TVM_DLL explicit Var(String name_hint = "v", DataType dtype = DataType::Int(32),
+                       Span span = Span());
+  /*!
+   * \brief Constructor which provides a more detailed type annotation.
+   * \param name_hint variable name.
+   * \param type_annotation The type annotation.
+   * \param span The location of this object in the source code.
+   */
+  TVM_DLL explicit Var(String name_hint, Type type_annotation, Span span = Span());
+  /*!
+   * \brief Make a new copy of var with same type, append suffix
+   * \param suffix The suffix to be appended.
+   * \return the new Var copy
+   */
+  TVM_DLL Var copy_with_suffix(const String& suffix) const;
+  /*!
+   * \brief Make a new copy of the variable with specified dtype
+   * \param dtype The specified dtype
+   * \return The new variable
+   */
+  TVM_DLL Var copy_with_dtype(DataType dtype) const;
+
+  /*!
+   * \brief Get pointer to the internal value.
+   * \return the corresponding Variable.
+   */
+  const VarNode* operator->() const { return get(); }
+  /*!
+   * \brief Get pointer to the internal value.
+   * \return the corresponding Variable.
+   */
+  const VarNode* get() const { return static_cast<const VarNode*>(data_.get()); }
+  /*! \brief type indicate the container type */
+  using ContainerType = VarNode;
+};
+
+/*!
+ * \brief A variable node represent a tensor index size,
+ * whose value must be non-negative.
+ */
+class SizeVarNode : public VarNode {
+ public:
+  static constexpr const char* _type_key = "tir.SizeVar";
+  TVM_DECLARE_FINAL_OBJECT_INFO(SizeVarNode, VarNode);
+};
+
+/*! \brief a named variable represents a tensor index size */
+class SizeVar : public Var {
+ public:
+  explicit SizeVar(ObjectPtr<Object> n) : Var(n) {}
+  /*!
+   * \brief constructor
+   * \param name_hint variable name
+   * \param t data type
+   * \param span The location of this object in the source code.
+   */
+  TVM_DLL explicit SizeVar(String name_hint = "s", DataType t = DataType::Int(32),
+                           Span span = Span());
+  /*!
+   * \brief Get pointer to the internal value.
+   * \return the corresponding Variable.
+   */
+  const SizeVarNode* operator->() const { return get(); }
+  /*!
+   * \brief Get pointer to the internal value.
+   * \return the corresponding Variable.
+   */
+  const SizeVarNode* get() const { return static_cast<const SizeVarNode*>(data_.get()); }
+  /*! \brief type indicate the container type */
+  using ContainerType = SizeVarNode;
+};
+
+using Region = Array<Range>;
+
+/*!
+ * \brief Type of iteration variable.
+ *  Each IterVar have a specific type.
+ *
+ *  The type of iter var can be overriden via
+ *  stage.iter_var_attrs given they are compatible.
+ */
+enum IterVarType : int {
+  /*!
+   * \brief Data parallel iteration.
+   *  This normally corresponds to axis of Tensor.
+   *  Allow all IterVar manipulations.
+   *
+   * \note This does not mean the loop
+   *  have to be executed in parallel fashion.
+   */
+  kDataPar = 0,
+  /*!
+   * \brief The IterVar itself is a thread-index
+   *  of a fixed thread launching group.
+   *  Note that this is already assumed to be parallelized.
+   *
+   *  Disallow: split/fuse/vectorize/parallel
+   */
+  kThreadIndex = 1,
+  /*!
+   * \brief Communicative reduction.
+   *  Cannot be directly parallelized.
+   *
+   *  Disallow: parallel/vectorize
+   */
+  kCommReduce = 2,
+  /*!
+   * \brief Serial loops with loop carry dependency,
+   *  the iteration must execute in order.
+   *  Cannot be re-ordered.
+   *
+   *  Disallow: reorder/parallel/vectorize
+   */
+  kOrdered = 3,
+  /*!
+   * \brief IterVar is opaque,
+   *
+   *  May not corresponds to any generated loop
+   *  Disallow all IterVar manipulations and compute_at
+   *
+   * \note This is usually used to implement composite op
+   *  or external op, where the
+   */
+  kOpaque = 4,
+  // The following are possible additional
+  // types that are provided during schedule
+  /*!
+   * \brief The execution is unrolled.
+   */
+  kUnrolled = 5,
+  /*!
+   * \brief The loop is vectorized.
+   */
+  kVectorized = 6,
+  /*!
+   * \brief The loop is parallelized.
+   */
+  kParallelized = 7,
+  /*!
+   * \brief Marks boundary of tensorization intrinsic.
+   */
+  kTensorized = 8
+};
+
+/*!
+ * \brief An iteration variable representing an iteration
+ *  over a one dimensional interval.
+ *
+ *  The dtype of the extent of the `dom` of the IterVar must match the dtype of the internal Var.
+ */
+class IterVarNode : public Object {
+ public:
+  /*!
+   * \brief the domain of iteration, if known, can be None
+   *  For the intermediate schedule node, before schedule.
+   */
+  Range dom;
+  /*! \brief The looping variable */
+  Var var;
+  /*! \brief The type of the IterVar */
+  IterVarType iter_type;
+  /*!
+   * \brief additional tag on the iteration variable,
+   *  set this if this is binded already to a known thread tag.
+   */
+  String thread_tag;
+  /*!
+   * \brief Span that points to the original source code.
+   *        Reserved debug information.
+   */
+  mutable Span span;
+
+  void VisitAttrs(AttrVisitor* v) {
+    v->Visit("dom", &dom);
+    v->Visit("var", &var);
+    v->Visit("iter_type", &iter_type);
+    v->Visit("thread_tag", &thread_tag);
+    v->Visit("span", &span);
+  }
+
+  bool SEqualReduce(const IterVarNode* other, SEqualReducer equal) const {
+    return equal(dom, other->dom) && equal.DefEqual(var, other->var) &&
+           equal(iter_type, other->iter_type) && equal(thread_tag, other->thread_tag);
+  }
+
+  void SHashReduce(SHashReducer hash_reduce) const {
+    hash_reduce(dom);
+    hash_reduce.DefHash(var);
+    hash_reduce(iter_type);
+    hash_reduce(thread_tag);
+  }
+
+  static constexpr const char* _type_key = "tir.IterVar";
+  static constexpr const bool _type_has_method_sequal_reduce = true;
+  static constexpr const bool _type_has_method_shash_reduce = true;
+  TVM_DECLARE_FINAL_OBJECT_INFO(IterVarNode, Object);
+};
+
+/*!
+ * \brief Iteration Variable,
+ *  represents an iteration over an integer interval.
+ *
+ *  The dtype of the extent of the `dom` of the IterVar must match the dtype of the internal Var.
+ */
+class IterVar : public ObjectRef {
+ public:
+  TVM_DLL IterVar(Range dom, Var var, IterVarType iter_type, String thread_tag = "",
+                  Span span = Span());
+  /*!
+   * \return the corresponding var in the IterVar.
+   */
+  inline operator PrimExpr() const;
+
+  TVM_DEFINE_OBJECT_REF_METHODS(IterVar, ObjectRef, IterVarNode);
+  TVM_DEFINE_OBJECT_REF_COW_METHOD(IterVarNode);
+};
+
+// inline implementations
+inline IterVar::operator PrimExpr() const { return (*this)->var; }
+
+inline const char* IterVarType2String(IterVarType t) {
+  switch (t) {
+    case kDataPar:
+      return "DataPar";
+    case kThreadIndex:
+      return "ThreadIndex";
+    case kCommReduce:
+      return "CommReduce";
+    case kOrdered:
+      return "Ordered";
+    case kOpaque:
+      return "Opaque";
+    case kUnrolled:
+      return "Unrolled";
+    case kVectorized:
+      return "Vectorized";
+    case kParallelized:
+      return "Parallelized";
+    case kTensorized:
+      return "Tensorized";
+  }
+  return "Unknown";
+}
+}  // namespace tir
+}  // namespace tvm
+#endif  // TVM_TIR_VAR_H_
diff --git a/darknet_drp_ros/include/tvm/topi/broadcast.h b/darknet_drp_ros/include/tvm/topi/broadcast.h
new file mode 100644
index 0000000..d27b6f1
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/broadcast.h
@@ -0,0 +1,478 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \brief Broadcast op constructions
+ * \file topi/broadcast.h
+ */
+#ifndef TVM_TOPI_BROADCAST_H_
+#define TVM_TOPI_BROADCAST_H_
+
+#include <tvm/topi/detail/broadcast.h>
+#include <tvm/topi/detail/constant_utils.h>
+#include <tvm/topi/tags.h>
+
+#include <algorithm>
+#include <string>
+
+namespace tvm {
+namespace topi {
+
+/*!
+ * \brief Creates an operation that broadcasts a tensor into a compatible
+ * shape according to numpy's rules
+ *
+ * \param t The input tensor
+ * \param output_shape The target output shape, must be compatible
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is a broadcast operation
+ */
+inline tvm::te::Tensor broadcast_to(const tvm::te::Tensor& t,
+                                    const tvm::Array<tvm::PrimExpr>& output_shape,
+                                    std::string name = "T_broadcast_to",
+                                    std::string tag = kBroadcast) {
+  ICHECK_GE(output_shape.size(), t->shape.size())
+      << "Not a broadcast, output dimensionality smaller than input.\noutput: " << output_shape
+      << "\nvs\ninput: " << t;
+  auto bh = detail::BroadcastShape(output_shape, t->shape);
+  ICHECK_EQ(output_shape.size(), bh.common_shape.size());
+  Array<PrimExpr> oshape;
+  for (size_t i = 0; i < output_shape.size(); ++i) {
+    if (output_shape[i].as<tir::IntImmNode>() == nullptr) {
+      oshape.push_back(output_shape[i]);
+    } else {
+      ICHECK(topi::detail::EqualCheck(output_shape[i], bh.common_shape[i]));
+      oshape.push_back(bh.common_shape[i]);
+    }
+  }
+  auto l = [&](tvm::Array<tvm::tir::Var> ovars) {
+    return t(detail::InputIndexFromBroadcast(ovars, t, bh.vars2, bh.all_vars));
+  };
+  return tvm::te::compute(oshape, l, name, tag);
+}
+
+#define TOPI_DEFINE_BCAST_OP(Name, ComputeRule)                                                   \
+  inline tvm::PrimExpr Name(const tvm::PrimExpr& a, const tvm::PrimExpr& b) { ComputeRule; }      \
+  inline tvm::te::Tensor Name(const tvm::te::Tensor& A, const tvm::te::Tensor& B,                 \
+                              std::string name = "T_" #Name, std::string tag = kBroadcast) {      \
+    auto l = [](tvm::PrimExpr a, tvm::PrimExpr b) { ComputeRule; };                               \
+    return detail::WithBroadcast(l, A, B, name, tag);                                             \
+  }                                                                                               \
+  inline tvm::te::Tensor Name(const tvm::te::Tensor& A, const tvm::PrimExpr& B,                   \
+                              std::string name = "T_" #Name, std::string tag = kElementWise) {    \
+    auto l = [](tvm::PrimExpr a, tvm::PrimExpr b) { ComputeRule; };                               \
+    return tvm::te::compute(                                                                      \
+        A->shape, [&](const ::tvm::Array<::tvm::tir::Var>& i) { return l(A(i), B); }, name, tag); \
+  }                                                                                               \
+  inline tvm::te::Tensor Name(const tvm::PrimExpr& A, const tvm::te::Tensor& B,                   \
+                              std::string name = "T_" #Name, std::string tag = kElementWise) {    \
+    auto l = [&](tvm::PrimExpr a, tvm::PrimExpr b) { ComputeRule; };                              \
+    return tvm::te::compute(                                                                      \
+        B->shape, [&](const ::tvm::Array<::tvm::tir::Var>& i) { return l(A, B(i)); }, name, tag); \
+  }
+
+#define TOPI_DEFINE_OP_OVERLOAD(Name, OpName)                                       \
+  inline tvm::te::Tensor Name(const tvm::te::Tensor& A, const tvm::te::Tensor& B) { \
+    return topi::OpName(A, B);                                                      \
+  }                                                                                 \
+  inline tvm::te::Tensor Name(const tvm::PrimExpr& A, const tvm::te::Tensor& B) {   \
+    return topi::OpName(A, B);                                                      \
+  }                                                                                 \
+  inline tvm::te::Tensor Name(const tvm::te::Tensor& A, const tvm::PrimExpr& B) {   \
+    return topi::OpName(A, B);                                                      \
+  }
+
+/*!
+ * \fn logical_and
+ * \brief Compute A && B with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(logical_and, { return a && b; });
+TOPI_DEFINE_OP_OVERLOAD(operator&&, logical_and);
+
+/*!
+ * \fn logical_or
+ * \brief Compute A || B with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(logical_or, { return a || b; });
+TOPI_DEFINE_OP_OVERLOAD(operator||, logical_or);
+
+/*!
+ * \fn logical_xor
+ * \brief Compute A ^ B with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(logical_xor, { return a ^ b; });
+
+/*!
+ * \fn bitwise_and
+ * \brief Compute A & B with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(bitwise_and, { return a & b; });
+TOPI_DEFINE_OP_OVERLOAD(operator&, bitwise_and);
+
+/*!
+ * \fn bitwise_or
+ * \brief Compute A | B with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(bitwise_or, { return a | b; });
+TOPI_DEFINE_OP_OVERLOAD(operator|, bitwise_or);
+
+/*!
+ * \fn bitwise_xor
+ * \brief Compute A ^ B with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(bitwise_xor, { return a ^ b; });
+TOPI_DEFINE_OP_OVERLOAD(operator^, bitwise_xor);
+
+/*!
+ * \fn add
+ * \brief Compute A + B with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(add, { return a + b; });
+TOPI_DEFINE_OP_OVERLOAD(operator+, add);
+
+/*!
+ * \fn subtract
+ * \brief Compute A - B with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(subtract, { return a - b; });
+TOPI_DEFINE_OP_OVERLOAD(operator-, subtract);
+
+/*!
+ * \fn multiply
+ * \brief Compute A * B with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(multiply, { return a * b; });
+TOPI_DEFINE_OP_OVERLOAD(operator*, multiply);
+
+/*!
+ * \fn divide
+ * \brief Compute A / B with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(divide, { return div(a, b); });
+
+/*!
+ * \fn floor divide
+ * \brief Compute floor(A / B) with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(floor_divide, {
+  if (a.dtype().is_int() || a.dtype().is_uint()) {
+    return floordiv(a, b);
+  } else {
+    return floor(div(a, b));
+  }
+});
+
+/*!
+ * \fn trunc divide
+ * \brief Compute trunc(A / B) with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(trunc_divide, {
+  if (a.dtype().is_int() || a.dtype().is_uint()) {
+    return truncdiv(a, b);
+  } else {
+    return trunc(div(a, b));
+  }
+});
+
+/*!
+ * \fn mod
+ * \brief Compute A % B with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(mod, { return truncmod(a, b); });
+
+/*!
+ * \fn floor mod
+ * \brief Compute A - floor_div(A, B) * B with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(floor_mod, {
+  if (a.dtype().is_int() || a.dtype().is_uint()) {
+    return floormod(a, b);
+  } else {
+    return a - floor_divide(a, b) * b;
+  }
+});
+
+/*!
+ * \fn trunc mod
+ * \brief Compute A - trunc_div(A, B) * B with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(trunc_mod, {
+  if (a.dtype().is_int() || a.dtype().is_uint()) {
+    return truncmod(a, b);
+  } else {
+    return a - trunc_divide(a, b) * b;
+  }
+});
+
+/*!
+ * \fn maximum
+ * \brief Compute maximum(A, B) with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(maximum, { return tvm::max(a, b); });
+
+/*!
+ * \fn minimum
+ * \brief Compute minimum(A, B) with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(minimum, { return tvm::min(a, b); });
+
+/*!
+ * \fn power
+ * \brief Compute power(A, B) with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(power, { return tvm::pow(a, b); });
+
+/*!
+ * \fn left_shift
+ * \brief Compute A << B with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(left_shift, { return a << b; });
+TOPI_DEFINE_OP_OVERLOAD(operator<<, left_shift);
+
+/*!
+ * \fn right_shift
+ * \brief Compute A >> B with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(right_shift, { return a >> b; });
+TOPI_DEFINE_OP_OVERLOAD(operator>>, right_shift);
+
+/*!
+ * \fn greater
+ * \brief Compute (A > B) with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(greater, { return (a > b); });
+
+/*!
+ * \fn less
+ * \brief Compute (A < B) with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(less, { return (a < b); });
+
+/*!
+ * \fn equal
+ * \brief Compute (A == B) with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(equal, { return (a == b); });
+
+/*!
+ * \fn not_equal
+ * \brief Compute (A != B) with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(not_equal, { return (a != b); });
+
+/*!
+ * \fn greater_equal
+ * \brief Compute (A >= B) with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(greater_equal, { return (a >= b); });
+
+/*!
+ * \fn less_equal
+ * \brief Compute (A <= B) with auto-broadcasting.
+ *
+ * \param A The first tensor, or Expr
+ * \param B The second tensor, or Expr
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The result.
+ */
+TOPI_DEFINE_BCAST_OP(less_equal, { return (a <= b); });
+
+}  // namespace topi
+}  // namespace tvm
+
+#endif  // TVM_TOPI_BROADCAST_H_
diff --git a/darknet_drp_ros/include/tvm/topi/contrib/cublas.h b/darknet_drp_ros/include/tvm/topi/contrib/cublas.h
new file mode 100644
index 0000000..3032643
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/contrib/cublas.h
@@ -0,0 +1,88 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \brief External function interface to cuBLAS libraries
+ * \file cublas.h
+ */
+#ifndef TVM_TOPI_CONTRIB_CUBLAS_H_
+#define TVM_TOPI_CONTRIB_CUBLAS_H_
+
+#include <tvm/te/operation.h>
+#include <tvm/topi/detail/extern.h>
+
+namespace tvm {
+namespace topi {
+namespace contrib {
+
+using namespace tvm::te;
+using namespace topi::detail;
+/*!
+ * \brief Create an op that multiplies lhs and rhs with cuBLAS
+ *
+ * \param lhs The left matrix operand
+ * \param rhs The right matrix operand
+ * \param transa Whether to transpose lhs
+ * \param transb Whether to transpose rhs
+ *
+ * \return The output tensor
+ */
+inline Tensor cublas_matmul(const Tensor& lhs, const Tensor& rhs, bool transa, bool transb) {
+  auto n = transa ? lhs->shape[1] : lhs->shape[0];
+  auto m = transb ? rhs->shape[0] : rhs->shape[1];
+
+  return make_extern(
+      {{n, m}}, {lhs->dtype}, {lhs, rhs},
+      [&](Array<Buffer> ins, Array<Buffer> outs) {
+        return call_packed({StringImm("tvm.contrib.cublas.matmul"), pack_buffer(ins[0]),
+                            pack_buffer(ins[1]), pack_buffer(outs[0]), transa, transb});
+      },
+      "C", "", {})[0];
+}
+
+/*!
+ * \brief Create an op that multiplies batch matrices
+ *        lhs and rhs with cuBLAS
+ *
+ * \param lhs The left matrix operand
+ * \param rhs The right matrix operand
+ * \param transa Whether to transpose lhs
+ * \param transb Whether to transpose rhs
+ *
+ * \return The output tensor
+ */
+inline Tensor cublas_batch_matmul(const Tensor& lhs, const Tensor& rhs, bool transa, bool transb) {
+  auto b = lhs->shape[0];
+  auto n = transa ? lhs->shape[2] : lhs->shape[1];
+  auto m = transb ? rhs->shape[1] : rhs->shape[2];
+
+  return make_extern(
+      {{b, n, m}}, {lhs->dtype}, {lhs, rhs},
+      [&](Array<Buffer> ins, Array<Buffer> outs) {
+        return call_packed({StringImm("tvm.contrib.cublas.batch_matmul"), pack_buffer(ins[0]),
+                            pack_buffer(ins[1]), pack_buffer(outs[0]), transa, transb});
+      },
+      "C", "", {})[0];
+}
+
+}  // namespace contrib
+}  // namespace topi
+}  // namespace tvm
+
+#endif  // TVM_TOPI_CONTRIB_CUBLAS_H_
diff --git a/darknet_drp_ros/include/tvm/topi/contrib/rocblas.h b/darknet_drp_ros/include/tvm/topi/contrib/rocblas.h
new file mode 100644
index 0000000..4f0b887
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/contrib/rocblas.h
@@ -0,0 +1,85 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \brief External function interface to rocBLAS libraries
+ * \file tags.h
+ */
+#ifndef TVM_TOPI_CONTRIB_ROCBLAS_H_
+#define TVM_TOPI_CONTRIB_ROCBLAS_H_
+
+#include <tvm/te/operation.h>
+#include <tvm/topi/detail/extern.h>
+
+namespace tvm {
+namespace topi {
+namespace contrib {
+
+using namespace tvm::te;
+/*!
+ * \brief Create an op that multiplies lhs and rhs with rocBLAS
+ *
+ * \param lhs The left matrix operand
+ * \param rhs The right matrix operand
+ * \param transa Whether to transpose lhs
+ * \param transb Whether to transpose rhs
+ *
+ * \return The output tensor
+ */
+inline Tensor rocblas_matmul(const Tensor& lhs, const Tensor& rhs, bool transa, bool transb) {
+  auto n = transa ? lhs->shape[1] : lhs->shape[0];
+  auto m = transb ? rhs->shape[0] : rhs->shape[1];
+
+  return make_extern(
+      {{n, m}}, {lhs->dtype}, {lhs, rhs},
+      [&](Array<Buffer> ins, Array<Buffer> outs) {
+        return call_packed({StringImm("tvm.contrib.rocblas.matmul"), pack_buffer(ins[0]),
+                            pack_buffer(ins[1]), pack_buffer(outs[0]), transa, transb});
+      },
+      "C", "", {})[0];
+}
+/*!
+ * \brief Create an op that batch multiplies lhs and rhs with rocBLAS
+ *
+ * \param lhs The left matrix operand  e.g. (batch_size, M, K)
+ * \param rhs The right matrix operand e.g. (batch_size, K, N)
+ * \param transa Whether to transpose lhs
+ * \param transb Whether to transpose rhs
+ *
+ * \return The output tensor
+ */
+inline Tensor rocblas_batch_matmul(const Tensor& lhs, const Tensor& rhs, bool transa, bool transb) {
+  auto batch_size = lhs->shape[0];
+  auto n = transa ? lhs->shape[2] : lhs->shape[1];
+  auto m = transb ? rhs->shape[1] : rhs->shape[2];
+
+  return make_extern(
+      {{batch_size, n, m}}, {lhs->dtype}, {lhs, rhs},
+      [&](Array<Buffer> ins, Array<Buffer> outs) {
+        return call_packed({StringImm("tvm.contrib.rocblas.batch_matmul"), pack_buffer(ins[0]),
+                            pack_buffer(ins[1]), pack_buffer(outs[0]), transa, transb});
+      },
+      "C", "", {})[0];
+}
+
+}  // namespace contrib
+}  // namespace topi
+}  // namespace tvm
+
+#endif  // TVM_TOPI_CONTRIB_ROCBLAS_H_
diff --git a/darknet_drp_ros/include/tvm/topi/cuda/dense.h b/darknet_drp_ros/include/tvm/topi/cuda/dense.h
new file mode 100644
index 0000000..7fd3107
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/cuda/dense.h
@@ -0,0 +1,154 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file cuda/dense.h
+ * \brief CUDA schedule for dense operation
+ */
+#ifndef TVM_TOPI_CUDA_DENSE_H_
+#define TVM_TOPI_CUDA_DENSE_H_
+
+#include <tvm/target/generic_func.h>
+#include <tvm/te/operation.h>
+#include <tvm/te/schedule_pass.h>
+#include <tvm/topi/contrib/cublas.h>
+#include <tvm/topi/detail/array_utils.h>
+#include <tvm/topi/generic/extern.h>
+#include <tvm/topi/nn/dense.h>
+#include <tvm/topi/tags.h>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+
+namespace cuda {
+/*!
+ * \brief Implementation of dense for CUDA backend
+ *
+ * \param target The target device
+ * \param data Tensor with shape [batch, in_dim]
+ * \param weight Tensor with shape [out_dim, in_dim]
+ * \param bias Tensor with shape [out_dim]. Optional; to omit bias, pass Tensor()
+ * \param out_dtype Output data type. Used for mixed precision.
+ *
+ * \return Tensor with shape [batch, out_dim]
+ */
+inline tvm::te::Tensor dense_cuda(const Target& target, const tvm::te::Tensor& data,
+                                  const tvm::te::Tensor& weight, const tvm::te::Tensor& bias,
+                                  const DataType& out_dtype) {
+  ICHECK_EQ(data->shape.size(), 2) << "dense requires 2-D data";
+  ICHECK_EQ(weight->shape.size(), 2) << "dense requires 2-D weight";
+  if (bias.defined()) {
+    ICHECK_EQ(bias->shape.size(), 1) << "dense requires 1-D bias";
+  }
+
+  auto batch = data->shape[0];
+  auto in_dim = data->shape[1];
+  auto out_dim = weight->shape[0];
+
+  if (target->GetLibs().count("cublas")) {
+    ICHECK_EQ(data->dtype, out_dtype) << "Mixed precision not supported.";
+    auto mm = topi::contrib::cublas_matmul(data, weight, false, true);
+    if (bias.defined()) {
+      mm = tvm::te::compute(
+          {batch, out_dim}, [&](Var i, Var j) { return mm(i, j) + bias(j); }, "tensor", kBroadcast);
+    }
+
+    return mm;
+  } else {
+    return topi::nn::dense(data, weight, bias, out_dtype);
+  }
+}
+
+/*!
+ * \brief Create a CUDA schedule for dense
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+inline Schedule schedule_dense(const Target& target, const Array<Tensor>& outs) {
+  if (target->kind->name == "cuda" && target->GetLibs().count("cublas")) {
+    return topi::generic::schedule_extern(target, outs);
+  }
+
+  Array<Operation> out_ops;
+  for (auto t : outs) {
+    out_ops.push_back(t->op);
+  }
+  auto s = create_schedule(out_ops);
+
+  auto _schedule = [&](const Tensor& dense) {
+    auto num_thread = 64;
+    auto k = dense->op.as<ComputeOpNode>()->reduce_axis[0];
+    IterVar ko, kf;
+    s[dense].split(k, num_thread, &ko, &kf);
+    auto dense_f = s.rfactor(dense, kf)[0];
+
+    Tensor out;
+    if (detail::contains(s->outputs, dense->op)) {
+      out = dense;
+    } else {
+      out = outs[0]->op.output(0);
+      s[dense].compute_at(s[out], s[out]->op.as<ComputeOpNode>()->axis[1]);
+    }
+    s[out].bind(s[out]->op.as<ComputeOpNode>()->axis[0],
+                tvm::te::thread_axis(Range(), "blockIdx.y"));
+    s[out].bind(s[out]->op.as<ComputeOpNode>()->axis[1],
+                tvm::te::thread_axis(Range(), "blockIdx.x"));
+
+    auto tx = s[dense]->op.as<ComputeOpNode>()->reduce_axis[0];
+    auto thread_x = tvm::te::thread_axis(Range(), "threadIdx.x");
+    s[dense].bind(tx, thread_x);
+    s[dense_f].compute_at(s[dense], tx);
+    s[dense].set_store_predicate(static_cast<PrimExpr>(thread_x) == 0);
+    s[out].set_store_predicate(static_cast<PrimExpr>(thread_x) == 0);
+  };
+
+  std::function<void(Operation)> traverse;
+  traverse = [&](const Operation& op) {
+    // Inline all one-to-one-mapping operators except the last stage (output)
+    if (is_broadcast(op->tag)) {
+      if (!detail::contains(s->outputs, op)) {
+        s[op].compute_inline();
+      }
+      for (auto tensor : op->InputTensors()) {
+        if (tensor->op->InputTensors().size() > 0) {
+          traverse(tensor->op);
+        }
+      }
+    } else if (op->tag == "dense") {
+      // If tag starts with global_pool
+      auto dense = op.output(0);
+      _schedule(dense);
+    } else {
+      LOG(ERROR) << "Unsupported operator " << op->tag;
+    }
+  };
+
+  traverse(outs[0]->op);
+  return s;
+}
+
+}  // namespace cuda
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_CUDA_DENSE_H_
diff --git a/darknet_drp_ros/include/tvm/topi/cuda/injective.h b/darknet_drp_ros/include/tvm/topi/cuda/injective.h
new file mode 100644
index 0000000..79ec338
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/cuda/injective.h
@@ -0,0 +1,83 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file cuda/injective.h
+ * \brief CUDA schedule for injective operations
+ */
+#ifndef TVM_TOPI_CUDA_INJECTIVE_H_
+#define TVM_TOPI_CUDA_INJECTIVE_H_
+
+#include <tvm/target/generic_func.h>
+#include <tvm/te/operation.h>
+#include <tvm/te/schedule_pass.h>
+#include <tvm/topi/detail/fuse.h>
+#include <tvm/topi/tags.h>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+
+namespace cuda {
+
+/*!
+ * \brief Updates an existing schedule for the given injective ops.
+ *
+ * \param sch The schedule to update.
+ * \param out The tensor representing the injective op.
+ *
+ * \return The updated schedule.
+ */
+inline Schedule schedule_injective_from_existing(Schedule sch, const Tensor& out) {
+  auto fused = detail::Fuse(sch[out], sch[out]->op.as<ComputeOpNode>()->axis);
+  auto target = Target::Current(false);
+  int num_thread = target->GetAttr<Integer>("max_num_threads").value().IntValue();
+  IterVar bx, tx;
+  sch[out].split(fused, num_thread, &bx, &tx);
+  sch[out].bind(bx, thread_axis(Range(), "blockIdx.x"));
+  sch[out].bind(tx, thread_axis(Range(), "threadIdx.x"));
+  return sch;
+}
+
+/*!
+ * \brief Create a CUDA schedule for the given output tensors.
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+inline Schedule schedule_injective(const Target& target, const Array<Tensor>& outs) {
+  Array<Operation> out_ops;
+  for (auto t : outs) {
+    out_ops.push_back(t->op);
+  }
+  auto s = create_schedule(out_ops);
+  tvm::te::AutoInlineInjective(s);
+  for (auto out : outs) {
+    schedule_injective_from_existing(s, out);
+  }
+  return s;
+}
+
+}  // namespace cuda
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_CUDA_INJECTIVE_H_
diff --git a/darknet_drp_ros/include/tvm/topi/cuda/pooling.h b/darknet_drp_ros/include/tvm/topi/cuda/pooling.h
new file mode 100644
index 0000000..92be031
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/cuda/pooling.h
@@ -0,0 +1,187 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file cuda/pooling.h
+ * \brief CUDA schedule for pooling operations
+ */
+#ifndef TVM_TOPI_CUDA_POOLING_H_
+#define TVM_TOPI_CUDA_POOLING_H_
+
+#include <tvm/target/generic_func.h>
+#include <tvm/te/operation.h>
+#include <tvm/te/schedule_pass.h>
+#include <tvm/topi/detail/array_utils.h>
+#include <tvm/topi/detail/fuse.h>
+#include <tvm/topi/tags.h>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+
+namespace cuda {
+
+/*!
+ * \brief Create a CUDA schedule for pool
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+inline Schedule schedule_pool(const Target& target, const Array<Tensor>& outs) {
+  Array<Operation> out_ops;
+  for (auto t : outs) {
+    out_ops.push_back(t->op);
+  }
+  auto s = create_schedule(out_ops);
+
+  auto _schedule = [&](const Tensor& padded_input, const Tensor& pool) {
+    if (padded_input->op->IsInstance<ComputeOpNode>()) {
+      s[padded_input].compute_inline();
+    }
+    int num_thread = target->GetAttr<Integer>("max_num_threads").value().IntValue();
+    Tensor out;
+    Tensor OL;
+    if (detail::contains(s->outputs, pool->op)) {
+      out = pool;
+      OL = s.cache_write(pool, "local");
+    } else {
+      out = outs[0]->op.output(0);
+      s[pool].set_scope("local");
+    }
+    auto fused = detail::Fuse(s[out], s[out]->op.as<ComputeOpNode>()->axis);
+    IterVar bx, tx;
+    s[out].split(fused, num_thread, &bx, &tx);
+    s[out].bind(bx, tvm::te::thread_axis(Range(), "blockIdx.x"));
+    s[out].bind(tx, tvm::te::thread_axis(Range(), "threadIdx.x"));
+    if (detail::contains(s->outputs, pool->op)) {
+      s[OL].compute_at(s[out], tx);
+    } else {
+      s[pool].compute_at(s[out], tx);
+    }
+  };
+
+  std::function<void(Operation)> traverse;
+  traverse = [&](const Operation& op) {
+    // Inline all one-to-one-mapping operators except the last stage (output)
+    if (is_broadcast(op->tag)) {
+      if (!detail::contains(s->outputs, op)) {
+        s[op].compute_inline();
+      }
+      for (auto tensor : op->InputTensors()) {
+        if (tensor->op->InputTensors().size() > 0) {
+          traverse(tensor->op);
+        }
+      }
+    } else if (op->tag.rfind("pool", 0) == 0) {
+      // If tag starts with pool
+      auto padded_input = op->InputTensors()[0];
+      auto pool = op.output(0);
+      _schedule(padded_input, pool);
+    } else {
+      LOG(ERROR) << "Unsupported operator " << op->tag;
+    }
+  };
+
+  traverse(outs[0]->op);
+  return s;
+}
+
+/*!
+ * \brief Create a CUDA schedule for global_pool
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+inline Schedule schedule_global_pool(const Target& target, const Array<Tensor>& outs) {
+  Array<Operation> out_ops;
+  for (auto t : outs) {
+    out_ops.push_back(t->op);
+  }
+  auto s = create_schedule(out_ops);
+
+  auto _schedule = [&](const Tensor& pool) {
+    auto num_thread = 8;
+    auto block_x = tvm::te::thread_axis(Range(), "blockIdx.x");
+    auto block_y = tvm::te::thread_axis(Range(), "blockIdx.y");
+    auto thread_x = tvm::te::thread_axis(Range(0, num_thread), "threadIdx.x");
+    auto thread_y = tvm::te::thread_axis(Range(0, num_thread), "threadIdx.y");
+    Tensor out;
+    Tensor OL;
+    if (detail::contains(s->outputs, pool->op)) {
+      out = pool;
+      OL = s.cache_write(pool, "local");
+    } else {
+      out = outs[0]->op.output(0);
+      s[pool].set_scope("local");
+    }
+
+    auto i = s[out]->op.as<ComputeOpNode>()->axis[0];
+    auto c = s[out]->op.as<ComputeOpNode>()->axis[1];
+
+    IterVar by, ty;
+    s[out].split(i, num_thread, &by, &ty);
+    IterVar bx, tx;
+    s[out].split(c, num_thread, &bx, &tx);
+    s[out].reorder({by, bx, ty, tx});
+    s[out].bind(ty, thread_y);
+    s[out].bind(tx, thread_x);
+    s[out].bind(by, block_y);
+    s[out].bind(bx, block_x);
+
+    if (detail::contains(s->outputs, pool->op)) {
+      s[OL].compute_at(s[out], tx);
+    } else {
+      s[pool].compute_at(s[out], tx);
+    }
+  };
+
+  std::function<void(Operation)> traverse;
+  traverse = [&](const Operation& op) {
+    // Inline all one-to-one-mapping operators except the last stage (output)
+    if (is_broadcast(op->tag)) {
+      if (!detail::contains(s->outputs, op)) {
+        s[op].compute_inline();
+      }
+      for (auto tensor : op->InputTensors()) {
+        if (tensor->op->InputTensors().size() > 0) {
+          traverse(tensor->op);
+        }
+      }
+    } else if (op->tag.rfind("global_pool", 0) == 0) {
+      // If tag starts with global_pool
+      auto pool = op.output(0);
+      _schedule(pool);
+    } else {
+      LOG(ERROR) << "Unsupported operator " << op->tag;
+    }
+  };
+
+  traverse(outs[0]->op);
+  return s;
+}
+
+}  // namespace cuda
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_CUDA_POOLING_H_
diff --git a/darknet_drp_ros/include/tvm/topi/cuda/reduction.h b/darknet_drp_ros/include/tvm/topi/cuda/reduction.h
new file mode 100644
index 0000000..b1905d8
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/cuda/reduction.h
@@ -0,0 +1,199 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file cuda/reduction.h
+ * \brief CUDA schedule for reduction operations
+ */
+#ifndef TVM_TOPI_CUDA_REDUCTION_H_
+#define TVM_TOPI_CUDA_REDUCTION_H_
+
+#include <tvm/target/generic_func.h>
+#include <tvm/te/operation.h>
+#include <tvm/te/schedule_pass.h>
+#include <tvm/topi/detail/fuse.h>
+#include <tvm/topi/tags.h>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+
+namespace cuda {
+/*!
+ * \brief Schedule a given reduce operation.
+ *
+ * \param target The target to generate a schedule for.
+ * \param op The operation representing the injective operation.
+ * \param sch The schedule to apply this scheduling to
+ * \param is_idx_reduce Pass true to schedule a reduce op that returns
+ * an index, such as argmax or argmin.
+ *
+ * \return The schedule given by sch
+ */
+Schedule ScheduleReduce(const Target& target, Operation op, Schedule sch,
+                        bool is_idx_reduce = false) {
+  Tensor data_out;
+  Tensor data_in;
+
+  if (!is_idx_reduce) {
+    data_in = op->InputTensors()[0];
+    data_out = op.output(0);
+  } else {
+    data_out = op->InputTensors()[0];
+  }
+
+  auto out_stage = sch[data_out];
+  ICHECK_GT(out_stage->op.as<ComputeOpNode>()->reduce_axis.size(), 0)
+      << "reduce_axis must be greater than zero";
+
+  bool all_reduce;
+  int num_thread;
+  IterVar block_x, thread_x, thread_y;
+
+  if (out_stage->op.as<ComputeOpNode>()->axis.size() > 0) {
+    all_reduce = false;
+    num_thread = 32;
+    if (target->kind->name == "opencl" || target->kind->name == "metal") {
+      // Without this, CL_INVALID_WORK_GROUP_SIZE occurs with python tests.
+      // Don't know why.
+      num_thread = 16;
+    }
+    block_x = tvm::te::thread_axis(Range(), "blockIdx.x");
+    thread_x = tvm::te::thread_axis(Range(0, num_thread), "threadIdx.x");
+    thread_y = tvm::te::thread_axis(Range(0, num_thread), "threadIdx.y");
+  } else {
+    all_reduce = true;
+    num_thread = target->GetAttr<Integer>("max_num_threads").value().IntValue();
+    thread_x = tvm::te::thread_axis(Range(0, num_thread), "threadIdx.x");
+  }
+
+  auto fused_reduce = detail::Fuse(out_stage, out_stage->op.as<ComputeOpNode>()->reduce_axis);
+
+  IterVar ko, ki;
+  out_stage.split(fused_reduce, num_thread, &ko, &ki);
+  auto data_out_rf = sch.rfactor(data_out, ki)[0];
+  auto tx = out_stage->op.as<ComputeOpNode>()->reduce_axis[0];
+  out_stage.bind(tx, thread_x);
+  sch[data_out_rf].compute_at(out_stage, tx);
+
+  Tensor real_output;
+  Tensor temp_idx_input, temp_val_input;
+  if (is_idx_reduce) {
+    real_output = op.output(0);
+    temp_idx_input = data_out->op.output(0);
+    temp_val_input = data_out->op.output(1);
+  } else {
+    real_output = data_out;
+  }
+
+  auto stage_real = sch[real_output];
+  if (!all_reduce) {
+    // Fuse and split the axis
+    auto fused_outer = detail::Fuse(stage_real, stage_real->op.as<ComputeOpNode>()->axis);
+    IterVar bx, outer_in;
+    stage_real.split(fused_outer, num_thread, &bx, &outer_in);
+
+    // Bind the axes to threads and blocks
+    stage_real.bind(outer_in, thread_y);
+    stage_real.bind(bx, block_x);
+    if (is_idx_reduce) {
+      sch[temp_idx_input].compute_at(stage_real, outer_in);
+      sch[temp_val_input].compute_at(stage_real, outer_in);
+    }
+  } else {
+    if (is_idx_reduce) {
+      sch[temp_idx_input].compute_at(stage_real, stage_real->op.as<ComputeOpNode>()->axis[0]);
+      sch[temp_val_input].compute_at(stage_real, stage_real->op.as<ComputeOpNode>()->axis[0]);
+    }
+  }
+
+  stage_real.set_store_predicate(static_cast<PrimExpr>(thread_x) == 0);
+  return sch;
+}
+
+/*!
+ * \brief Recursively traverse operator inputs, setting injective inputs
+ * to be computed inline.
+ *
+ * \param s The schedule we are building
+ * \param op The current op in the traversal
+ */
+void TraverseBeforeReduce(Schedule s, Operation op) {
+  if (op->IsInstance<PlaceholderOpNode>()) {
+    return;
+  } else if (is_injective(op->tag)) {
+    s[op].compute_inline();
+    for (auto tensor : op->InputTensors()) {
+      TraverseBeforeReduce(s, tensor->op);
+    }
+  } else {
+    LOG(ERROR) << "Unsupported operator " << op->tag;
+  }
+}
+
+/*!
+ * \brief Schedule a reduce op, then invoke TraverseBeforeReduce on each
+ * of the op's inputs.
+ *
+ * \param target The target to generate a schedule for.
+ * \param s The schedule we are building
+ * \param op The reduce op
+ */
+void TraverseAfterReduce(const Target& target, Schedule s, Operation op) {
+  if (is_broadcast(op->tag)) {
+    LOG(ERROR) << "Elementwise op after reduce is not yet supported";
+  } else if (op->tag == kCommReduce) {
+    ScheduleReduce(target, op, s, false);
+    for (auto tensor : op->InputTensors()) {
+      TraverseBeforeReduce(s, tensor->op);
+    }
+  } else if (op->tag == kCommReduceIdx) {
+    ScheduleReduce(target, op, s, true);
+    for (auto tensor : op->InputTensors()[0]->op->InputTensors()) {
+      TraverseBeforeReduce(s, tensor->op);
+    }
+  } else {
+    LOG(ERROR) << "Unsupported operator " << op->tag;
+  }
+}
+
+/*!
+ * \brief Create a CUDA schedule for a reduce operation.
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+Schedule schedule_reduce(const Target& target, Array<Tensor> outs) {
+  ICHECK_EQ(outs.size(), 1) << "outs must have size 1";
+  Array<Operation> out_ops;
+  for (auto t : outs) {
+    out_ops.push_back(t->op);
+  }
+  auto s = create_schedule(out_ops);
+  TraverseAfterReduce(target, s, outs[0]->op);
+  return s;
+}
+
+}  // namespace cuda
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_CUDA_REDUCTION_H_
diff --git a/darknet_drp_ros/include/tvm/topi/cuda/softmax.h b/darknet_drp_ros/include/tvm/topi/cuda/softmax.h
new file mode 100644
index 0000000..19613cb
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/cuda/softmax.h
@@ -0,0 +1,103 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file cuda/injective.h
+ * \brief CUDA schedule for injective operations
+ */
+#ifndef TVM_TOPI_CUDA_SOFTMAX_H_
+#define TVM_TOPI_CUDA_SOFTMAX_H_
+
+#include <tvm/target/generic_func.h>
+#include <tvm/te/operation.h>
+#include <tvm/te/schedule_pass.h>
+#include <tvm/topi/detail/fuse.h>
+#include <tvm/topi/tags.h>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+
+namespace cuda {
+
+/*!
+ * \brief Create a CUDA schedule for the given softmax output tensors.
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+inline Schedule schedule_softmax(const Target& target, const Array<Tensor>& outs) {
+  Array<Operation> out_ops;
+  for (auto t : outs) {
+    out_ops.push_back(t->op);
+  }
+  auto s = create_schedule(out_ops);
+
+  auto softmax = outs[0];
+  tvm::te::Tensor max_elem;
+  tvm::te::Tensor expsum;
+  tvm::te::Tensor exp;
+  bool has_exp = false;
+
+  auto tag = softmax->op.as<ComputeOpNode>()->tag;
+  if (tag == "softmax_output") {
+    expsum = softmax->op->InputTensors()[1];
+    exp = softmax->op->InputTensors()[0];
+    max_elem = s[exp]->op->InputTensors()[1];
+    has_exp = true;
+  } else if (tag == "log_softmax_output") {
+    max_elem = softmax->op->InputTensors()[1];
+    expsum = softmax->op->InputTensors()[2];
+  } else {
+    LOG(ERROR) << "Tag is expected to be softmax_output or log_softmax_output. Got " << tag;
+  }
+
+  int num_thread = 64;
+  auto block_x = tvm::te::thread_axis(Range(), "blockIdx.x");
+  auto thread_x = tvm::te::thread_axis(Range(0, num_thread), "threadIdx.x");
+
+  if (has_exp) {
+    s[exp].bind(exp->op.as<ComputeOpNode>()->axis[0], block_x);
+  }
+
+  s[max_elem].bind(max_elem->op.as<ComputeOpNode>()->axis[0], block_x);
+
+  auto k = expsum->op.as<ComputeOpNode>()->reduce_axis[0];
+  IterVar ko, ki;
+  s[expsum].split(k, num_thread, &ko, &ki);
+  auto EF = s.rfactor(expsum, ki)[0];
+  s[expsum].bind(s[expsum]->op.as<ComputeOpNode>()->axis[0], block_x);
+  s[expsum].bind(s[expsum]->op.as<ComputeOpNode>()->reduce_axis[0], thread_x);
+  s[EF].compute_at(s[expsum], s[expsum]->op.as<ComputeOpNode>()->reduce_axis[0]);
+  s[expsum].set_store_predicate(thread_x->var == 0);
+
+  IterVar tx, xi;
+  s[softmax].split_by_nparts(softmax->op.as<ComputeOpNode>()->axis[1], num_thread, &tx, &xi);
+  s[softmax].bind(tx, thread_x);
+
+  return s;
+}
+
+}  // namespace cuda
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_CUDA_SOFTMAX_H_
diff --git a/darknet_drp_ros/include/tvm/topi/detail/array_utils.h b/darknet_drp_ros/include/tvm/topi/detail/array_utils.h
new file mode 100644
index 0000000..89c9856
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/detail/array_utils.h
@@ -0,0 +1,56 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file array_utils.h
+ * \brief Utility functions for handling arrays
+ */
+#ifndef TVM_TOPI_DETAIL_ARRAY_UTILS_H_
+#define TVM_TOPI_DETAIL_ARRAY_UTILS_H_
+
+#include <tvm/te/operation.h>
+
+namespace tvm {
+namespace topi {
+namespace detail {
+
+using namespace tvm::te;
+
+/*!
+ * \brief Search an array for a specific item
+ *
+ * \param array The array to search
+ * \param item The item to search for
+ *
+ * \return True iff the given array contains the given item.
+ */
+template <typename T>
+inline bool contains(Array<T> array, T item) {
+  for (auto& i : array) {
+    if (i == item) {
+      return true;
+    }
+  }
+  return false;
+}
+
+}  // namespace detail
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_DETAIL_ARRAY_UTILS_H_
diff --git a/darknet_drp_ros/include/tvm/topi/detail/broadcast.h b/darknet_drp_ros/include/tvm/topi/detail/broadcast.h
new file mode 100644
index 0000000..c861fbb
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/detail/broadcast.h
@@ -0,0 +1,156 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \brief Detail broadcast.
+ * \file topi/detail/broadcast.h
+ */
+#ifndef TVM_TOPI_DETAIL_BROADCAST_H_
+#define TVM_TOPI_DETAIL_BROADCAST_H_
+
+#include <tvm/te/operation.h>
+#include <tvm/topi/detail/constant_utils.h>
+
+#include <algorithm>
+#include <deque>
+#include <string>
+
+namespace tvm {
+namespace topi {
+namespace detail {
+
+struct BroadcastHelper {
+  std::deque<tvm::PrimExpr> common_shape;
+  std::deque<tvm::tir::Var> all_vars;
+  std::deque<tvm::tir::Var> vars1;
+  std::deque<tvm::tir::Var> vars2;
+};
+
+static inline DataType CommonType(DataType type1, DataType type2) {
+  ICHECK(type1.is_scalar() && type2.is_scalar());
+  ICHECK(type1.code() == type2.code());
+  return DataType(type1.code(), std::max(type1.bits(), type2.bits()), /*lanes=*/1);
+}
+
+inline BroadcastHelper BroadcastShape(const tvm::Array<tvm::PrimExpr>& shape1,
+                                      const tvm::Array<tvm::PrimExpr>& shape2) {
+  BroadcastHelper bh;
+  int s1_size = shape1.size();
+  int s2_size = shape2.size();
+  tvm::PrimExpr one(1);
+  int i;
+
+  auto cast_if_needed = [](DataType to_type, PrimExpr expr) {
+    return to_type != expr.dtype() ? cast(to_type, expr) : expr;
+  };
+
+  for (i = 1; i <= std::min(s1_size, s2_size); ++i) {
+    // TODO(@icemelon9): Need to revisit this part
+    const IntImmNode* static_size1 = shape1[s1_size - i].as<IntImmNode>();
+    const IntImmNode* static_size2 = shape2[s2_size - i].as<IntImmNode>();
+    DataType common_type = CommonType(shape1[s1_size - i].dtype(), shape2[s2_size - i].dtype());
+
+    bh.all_vars.push_front(tvm::tir::Var("dim", common_type));
+    if (topi::detail::EqualCheck(shape1[s1_size - i], shape2[s2_size - i])) {
+      bh.common_shape.push_front(cast_if_needed(common_type, shape1[s1_size - i]));
+      bh.vars1.push_front(bh.all_vars[0]);
+      bh.vars2.push_front(bh.all_vars[0]);
+    } else if (topi::detail::EqualCheck(one, shape1[s1_size - i])) {
+      ICHECK(!topi::detail::EqualCheck(one, shape2[s2_size - i]));
+      bh.common_shape.push_front(cast_if_needed(common_type, shape2[s2_size - i]));
+      bh.vars2.push_front(bh.all_vars[0]);
+    } else if (topi::detail::EqualCheck(one, shape2[s2_size - i])) {
+      bh.common_shape.push_front(cast_if_needed(common_type, shape1[s1_size - i]));
+      bh.vars1.push_front(bh.all_vars[0]);
+    } else if (!static_size1 && !static_size2) {
+      bh.common_shape.push_front(
+          cast_if_needed(common_type, max(shape1[s1_size - i], shape2[s2_size - i])));
+      bh.vars1.push_front(bh.all_vars[0]);
+      bh.vars2.push_front(bh.all_vars[0]);
+    } else if (!static_size1) {
+      bh.common_shape.push_front(cast_if_needed(common_type, shape2[s2_size - i]));
+      bh.vars2.push_front(bh.all_vars[0]);
+      bh.vars1.push_front(bh.all_vars[0]);
+    } else if (!static_size2) {
+      bh.common_shape.push_front(cast_if_needed(common_type, shape1[s1_size - i]));
+      bh.vars1.push_front(bh.all_vars[0]);
+      bh.vars2.push_front(bh.all_vars[0]);
+    } else {
+      ICHECK(false) << "Incompatible broadcast dims: " << shape1[s1_size - i] << " and "
+                    << shape2[s2_size - i]
+                    << " in: " << tvm::Array<tvm::PrimExpr>(shape1.begin(), shape1.end()) << " and "
+                    << tvm::Array<tvm::PrimExpr>(shape2.begin(), shape2.end());
+    }
+  }
+  // Remaining dimensions whether on shape1 or shape2 can always be completed
+  auto max_size = std::max(s1_size, s2_size);
+  auto& shape = (s1_size > s2_size) ? shape1 : shape2;
+  auto& vars = (s1_size > s2_size) ? bh.vars1 : bh.vars2;
+  for (; i <= max_size; ++i) {
+    bh.all_vars.push_front(tvm::tir::Var("v", shape[max_size - 1].dtype()));
+    bh.common_shape.push_front(shape[max_size - i]);
+    vars.push_front(bh.all_vars[0]);
+  }
+  return bh;
+}
+
+inline tvm::Array<tvm::PrimExpr> InputIndexFromBroadcast(
+    const tvm::Array<tvm::tir::Var>& ovars, const tvm::te::Tensor& T,
+    const std::deque<tvm::tir::Var>& my_vars, const std::deque<tvm::tir::Var>& all_vars) {
+  tvm::Array<tvm::PrimExpr> ivars;
+  ICHECK_EQ(ovars.size(), all_vars.size());
+  // N^2, could use a map but NBD.
+  size_t expected_dims = T->shape.size();
+  for (size_t i = 0; i < ovars.size(); ++i) {
+    bool found = false;
+    for (size_t j = 0; j < my_vars.size(); ++j) {
+      if (all_vars[i].same_as(my_vars[j])) {
+        ivars.push_back(ovars[i]);
+        found = true;
+        break;
+      }
+    }
+    // Only inject 0 here if we have not yet reached the dimension of I
+    // (i.e. this must be a 1)
+    if (!found && (ovars.size() - i) <= expected_dims) {
+      ivars.push_back(tvm::tir::make_zero(ovars[i].dtype()));
+    }
+  }
+  ICHECK(expected_dims == ivars.size());
+  return ivars;
+}
+
+template <typename FBinaryExpr>
+inline tvm::te::Tensor WithBroadcast(FBinaryExpr op, const tvm::te::Tensor& A,
+                                     const tvm::te::Tensor& B, const std::string& name = "tensor",
+                                     const std::string& tag = "") {
+  auto bh = BroadcastShape(A->shape, B->shape);
+  auto l = [&](tvm::Array<tvm::tir::Var> ovars) {
+    return op(A(InputIndexFromBroadcast(ovars, A, bh.vars1, bh.all_vars)),
+              B(InputIndexFromBroadcast(ovars, B, bh.vars2, bh.all_vars)));
+  };
+  return tvm::te::compute(tvm::Array<tvm::PrimExpr>(bh.common_shape.begin(), bh.common_shape.end()),
+                          l, name, tag);
+}
+
+}  // namespace detail
+}  // namespace topi
+}  // namespace tvm
+
+#endif  // TVM_TOPI_DETAIL_BROADCAST_H_
diff --git a/darknet_drp_ros/include/tvm/topi/detail/constant_utils.h b/darknet_drp_ros/include/tvm/topi/detail/constant_utils.h
new file mode 100644
index 0000000..95e68f5
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/detail/constant_utils.h
@@ -0,0 +1,144 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file constant_utils.h
+ * \brief Utility functions for handling constants in TVM expressions
+ */
+#ifndef TVM_TOPI_DETAIL_CONSTANT_UTILS_H_
+#define TVM_TOPI_DETAIL_CONSTANT_UTILS_H_
+
+#include <tvm/arith/analyzer.h>
+#include <tvm/te/operation.h>
+#include <tvm/tir/analysis.h>
+#include <tvm/tir/expr.h>
+
+#include <string>
+#include <vector>
+
+namespace tvm {
+namespace topi {
+namespace detail {
+
+using namespace tvm::te;
+
+/*!
+ * \brief Test whether the given Expr is a constant integer
+ *
+ * \param expr the Expr to query
+ *
+ * \return true if the given expr is a constant int or uint, false otherwise.
+ */
+inline bool IsConstInt(PrimExpr expr) { return expr->IsInstance<tvm::tir::IntImmNode>(); }
+
+/*!
+ * \brief Test whether the given Array has every element as constant integer.
+ * Undefined elements are also treat as constants.
+ *
+ * \param array the array to query
+ *
+ * \return true if every element in array is constant int or uint, false otherwise.
+ */
+inline bool IsConstIntArray(Array<PrimExpr> array) {
+  bool is_const_int = true;
+  for (auto const& elem : array) {
+    is_const_int &= !elem.defined() || elem->IsInstance<tvm::tir::IntImmNode>();
+  }
+  return is_const_int;
+}
+
+/*!
+ * \brief Get the value of the given constant integer expression. An error
+ * is logged if the given expression is not a constant integer.
+ *
+ * \param expr The expression to get the value of
+ *
+ * \return The integer value.
+ */
+inline int64_t GetConstInt(PrimExpr expr) {
+  if (expr->IsInstance<tvm::IntImmNode>()) {
+    return expr.as<tvm::IntImmNode>()->value;
+  }
+  LOG(ERROR) << "expr must be a constant integer";
+  return -1;
+}
+
+/*!
+ * \brief Get the value of all the constant integer expressions in the given array
+ *
+ * \param exprs The array of expressions to get the values of
+ * \param var_name The name to be used when logging an error in the event that any
+ * of the expressions are not constant integers.
+ *
+ * \return A vector of the integer values
+ */
+inline std::vector<int> GetConstIntValues(Array<PrimExpr> exprs, const std::string& var_name) {
+  std::vector<int> result;
+  if (!exprs.defined()) return result;
+  for (auto expr : exprs) {
+    ICHECK(IsConstInt(expr)) << "All elements of " << var_name << " must be constant integers";
+    result.push_back(GetConstInt(expr));
+  }
+  return result;
+}
+
+/*!
+ * \brief Get the value of all the constant integer expressions in the given array
+ *
+ * \param exprs The array of expressions to get the values of
+ * \param var_name The name to be used when logging an error in the event that any
+ * of the expressions are not constant integers.
+ *
+ * \return A vector of the int64_t values
+ */
+inline std::vector<int64_t> GetConstInt64Values(Array<PrimExpr> exprs,
+                                                const std::string& var_name) {
+  std::vector<int64_t> result;
+  if (!exprs.defined()) return result;
+  for (auto expr : exprs) {
+    ICHECK(IsConstInt(expr)) << "All elements of " << var_name << " must be constant integers";
+    result.push_back(GetConstInt(expr));
+  }
+  return result;
+}
+
+/*!
+ * \brief Check whether the two expressions are equal or not, if not simplify the expressions and
+ * check again
+ * \note This is stronger equality check than tvm::tir::Equal
+ * \param lhs First expression
+ * \param rhs Second expression
+ * \return result True if both expressions are equal, else false
+ */
+inline bool EqualCheck(PrimExpr lhs, PrimExpr rhs) {
+  tvm::tir::ExprDeepEqual expr_equal;
+  bool result = expr_equal(lhs, rhs);
+  if (!result) {
+    PrimExpr t = tvm::arith::Analyzer().Simplify(lhs - rhs);
+    if (const IntImmNode* i = t.as<IntImmNode>()) {
+      result = i->value == 0;
+    }
+  }
+  return result;
+}
+
+}  // namespace detail
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_DETAIL_CONSTANT_UTILS_H_
diff --git a/darknet_drp_ros/include/tvm/topi/detail/extern.h b/darknet_drp_ros/include/tvm/topi/detail/extern.h
new file mode 100644
index 0000000..dee4bf7
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/detail/extern.h
@@ -0,0 +1,150 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file detail/extern.h
+ * \brief Helpers for using external functions
+ */
+#ifndef TVM_TOPI_DETAIL_EXTERN_H_
+#define TVM_TOPI_DETAIL_EXTERN_H_
+
+#include <tvm/te/operation.h>
+#include <tvm/tir/builtin.h>
+
+#include <string>
+#include <vector>
+
+namespace tvm {
+namespace topi {
+namespace detail {
+
+using namespace tvm::te;
+
+/*!
+ * \brief Construct a buffer to pass to an external function
+ *
+ * \param shape The shape of the buffer
+ * \param dtype The type of the buffer elements
+ * \param name The name of the buffer
+ *
+ * \return The Buffer object
+ */
+inline Buffer DeclExternBuffer(Array<PrimExpr> shape, DataType dtype, std::string name) {
+  auto data = var(name, DataType::Handle());
+  auto elem_offset = PrimExpr();
+  return Buffer(data, dtype, shape, Array<PrimExpr>(), elem_offset, name, -1, 0, kDefault);
+}
+
+/*!
+ * \brief A function which constructs an Expr representing the invocation of an external
+ * function. The function expects two arguments: an array of Buffers holding the input
+ * tensor values, and a pre-allocated array of Buffers to be filled with the outputs.
+ */
+using FExtern = std::function<PrimExpr(Array<Buffer>, Array<Buffer>)>;
+
+/*!
+ * \brief Create tensors representing the result of invoking an external function.
+ * This function will create the necessary buffers to hold input and output tensor values.
+ *
+ * \param out_shapes An array where each element is the shape of the corresponding output tensor.
+ * \param out_types An array where each element is the dtype of the corresponding output tensor.
+ * \param inputs An array of input Tensors
+ * \param fextern A function that constructs an Expr representing the invocation of
+ * the external function given the input and output buffers.
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ * \param attrs The additional auxiliary attributes of the operation.
+ *
+ * \return An array of Tensors representing the outputs of the function invocation. There will
+ * be one output Tensor for each element of out_shapes, with dtype equal to the corresponding
+ * element of out_types.
+ */
+inline Array<Tensor> make_extern(const Array<Array<PrimExpr>>& out_shapes,
+                                 const std::vector<DataType>& out_types,
+                                 const Array<Tensor>& inputs, FExtern fextern, std::string name,
+                                 std::string tag, ::tvm::Map<String, ObjectRef> attrs) {
+  ICHECK_EQ(out_shapes.size(), out_types.size())
+      << "make_extern: out_shapes and out_types must have equal size";
+
+  Array<Buffer> input_placeholders;
+  for (auto t : inputs) {
+    input_placeholders.push_back(DeclExternBuffer(t->shape, t->dtype, t->op->name));
+  }
+  Array<Buffer> output_placeholders;
+  for (size_t i = 0; i < out_shapes.size(); ++i) {
+    output_placeholders.push_back(DeclExternBuffer(out_shapes[i], out_types[i], name));
+  }
+
+  auto body = fextern(input_placeholders, output_placeholders);
+  auto body_stmt = tvm::tir::Evaluate(body);
+
+  auto op = ExternOp(name, tag, attrs, inputs, input_placeholders, output_placeholders, body_stmt);
+
+  Array<Tensor> outputs;
+  for (size_t i = 0; i < output_placeholders.size(); ++i) {
+    outputs.push_back(op.output(i));
+  }
+  return outputs;
+}
+
+/*!
+ * \brief This function is used to create a DLTensor structure on the stack to
+ * be able to pass a symbolic buffer as arguments to TVM PackedFunc
+ *
+ * \param buf The buffer to pack
+ *
+ * \return An expression representing the pack operation
+ */
+inline PrimExpr pack_buffer(Buffer buf) {
+  ICHECK_GT(buf->shape.size(), 0) << "buf shape must have at least one element";
+  auto shape =
+      tvm::tir::Call(DataType::Handle(), tvm::tir::builtin::tvm_stack_make_shape(), buf->shape);
+  PrimExpr strides;
+  if (buf->strides.size() > 0) {
+    strides =
+        tvm::tir::Call(DataType::Handle(), tvm::tir::builtin::tvm_stack_make_shape(), buf->shape);
+  } else {
+    strides = 0;
+  }
+  Array<PrimExpr> pack_args{buf->data,
+                            shape,
+                            strides,
+                            make_const(DataType::Int(32), static_cast<int64_t>(buf->shape.size())),
+                            make_const(buf->dtype, 0),
+                            buf->elem_offset};
+  return tvm::tir::Call(DataType::Handle(), tvm::tir::builtin::tvm_stack_make_array(), pack_args);
+}
+
+/*!
+ * \brief Construct an Expr representing the invocation of a PackedFunc
+ *
+ * \param args An array containing the registered name of the PackedFunc followed
+ * by the arguments to pass to the PackedFunc when called. The first element of the
+ * array must be a constant string expression.
+ *
+ * \return An expression representing the invocation
+ */
+inline PrimExpr call_packed(Array<PrimExpr> args) {
+  return tvm::tir::Call(DataType::Int(32), tvm::tir::builtin::tvm_call_packed(), args);
+}
+
+}  // namespace detail
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_DETAIL_EXTERN_H_
diff --git a/darknet_drp_ros/include/tvm/topi/detail/fuse.h b/darknet_drp_ros/include/tvm/topi/detail/fuse.h
new file mode 100644
index 0000000..7305cce
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/detail/fuse.h
@@ -0,0 +1,52 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file fuse.h
+ * \brief Fuse operation
+ */
+#ifndef TVM_TOPI_DETAIL_FUSE_H_
+#define TVM_TOPI_DETAIL_FUSE_H_
+
+#include <tvm/te/operation.h>
+
+namespace tvm {
+namespace topi {
+namespace detail {
+
+using namespace tvm::te;
+
+/*!
+ * \brief Fuse all of the given args
+ *
+ * \param stage The stage in which to apply the fuse
+ * \param args The iteration variables to be fused
+ *
+ * \return The fused iteration variable
+ */
+inline IterVar Fuse(Stage stage, const Array<IterVar>& args) {
+  IterVar res;
+  stage.fuse(args, &res);
+  return res;
+}
+
+}  // namespace detail
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_DETAIL_FUSE_H_
diff --git a/darknet_drp_ros/include/tvm/topi/detail/pad_utils.h b/darknet_drp_ros/include/tvm/topi/detail/pad_utils.h
new file mode 100644
index 0000000..96eb49a
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/detail/pad_utils.h
@@ -0,0 +1,61 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file pad_utils.h
+ * \brief Padding helpers
+ */
+#ifndef TVM_TOPI_DETAIL_PAD_UTILS_H_
+#define TVM_TOPI_DETAIL_PAD_UTILS_H_
+
+#include <tvm/te/operation.h>
+#include <tvm/tir/expr.h>
+#include <tvm/tir/op.h>
+
+#include <vector>
+
+namespace tvm {
+namespace topi {
+namespace detail {
+
+using namespace tvm::te;
+
+/*!
+ * \brief Get padding size for each side given padding height and width
+ *
+ * \param pad_h The amount to pad each of the top and bottom sides
+ * \param pad_w The amount to pad each of the left and right sides
+ *
+ * \return An array of 4 elements, representing padding sizes for
+ * each individual side. The array is in the order { top, left, bottom, right }
+ */
+inline Array<PrimExpr> GetPadTuple(PrimExpr pad_h, PrimExpr pad_w) {
+  pad_h *= 2;
+  pad_w *= 2;
+
+  auto pad_top = indexdiv(pad_h + 1, 2);
+  auto pad_left = indexdiv(pad_w + 1, 2);
+
+  return {pad_top, pad_left, pad_h - pad_top, pad_w - pad_left};
+}
+
+}  // namespace detail
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_DETAIL_PAD_UTILS_H_
diff --git a/darknet_drp_ros/include/tvm/topi/detail/ravel_unravel.h b/darknet_drp_ros/include/tvm/topi/detail/ravel_unravel.h
new file mode 100644
index 0000000..e91d6af
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/detail/ravel_unravel.h
@@ -0,0 +1,83 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file ravel_unravel.h
+ * \brief Index ravel and unraval operations
+ */
+#ifndef TVM_TOPI_DETAIL_RAVEL_UNRAVEL_H_
+#define TVM_TOPI_DETAIL_RAVEL_UNRAVEL_H_
+
+#include <tvm/te/operation.h>
+
+#include <vector>
+
+namespace tvm {
+namespace topi {
+namespace detail {
+
+using namespace tvm::te;
+
+/*!
+ * \brief Flatten the indices to 1D
+ *
+ * \param indices The input coordinates
+ * \param shape Shape of the tensor
+ *
+ * \return The index after flattening
+ */
+inline PrimExpr RavelIndex(Array<PrimExpr> indices, Array<PrimExpr> shape) {
+  ICHECK_EQ(indices.size(), shape.size()) << "indices and shape must have equal size";
+  if (indices.size() == 0U) {
+    return 0;
+  }
+  PrimExpr idx;
+  for (size_t i = 0; i < indices.size(); ++i) {
+    if (i == 0) {
+      idx = indices[i];
+    } else {
+      idx = idx * shape[i] + indices[i];
+    }
+  }
+  return idx;
+}
+
+/*!
+ * \brief Convert flattened index to coordinate array
+ *
+ * \param idx The 1D index
+ * \param shape Shape of the tensor
+ *
+ * \return The coordinate corresponding to the 1D index
+ */
+inline Array<PrimExpr> UnravelIndex(PrimExpr idx, Array<PrimExpr> shape) {
+  std::vector<PrimExpr> indices;
+
+  for (int i = static_cast<int>(shape.size()) - 1; i >= 0; --i) {
+    indices.push_back(indexmod(idx, shape[i]));
+    idx = indexdiv(idx, shape[i]);
+  }
+  std::reverse(indices.begin(), indices.end());
+  return indices;
+}
+
+}  // namespace detail
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_DETAIL_RAVEL_UNRAVEL_H_
diff --git a/darknet_drp_ros/include/tvm/topi/detail/strided_slice.h b/darknet_drp_ros/include/tvm/topi/detail/strided_slice.h
new file mode 100644
index 0000000..a69f8f9
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/detail/strided_slice.h
@@ -0,0 +1,156 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file strided_slice.h
+ * \brief Utility functions for strided_slice op
+ */
+#ifndef TVM_TOPI_DETAIL_STRIDED_SLICE_H_
+#define TVM_TOPI_DETAIL_STRIDED_SLICE_H_
+
+#include <tvm/tir/expr.h>
+
+#include <algorithm>
+#include <limits>
+#include <string>
+#include <tuple>
+#include <vector>
+
+#include "constant_utils.h"
+
+namespace tvm {
+namespace topi {
+namespace detail {
+
+using namespace tvm::te;
+
+inline int64_t CanonicalizeIndex(int64_t index, int64_t extent, int64_t stride) {
+  int64_t begin_range = stride < 0 ? -1 : 0;
+  int64_t end_range = stride < 0 ? extent - 1 : extent;
+  if (index < 0) {
+    index += extent;
+  }
+  return std::min(std::max(index, begin_range), end_range);
+}
+
+inline std::tuple<std::vector<int64_t>, std::vector<int64_t>, std::vector<int64_t>> ConvertToVec(
+    const Array<Integer>& begin, const Array<Integer>& end, const Array<Integer>& strides,
+    std::string slice_mode) {
+  std::vector<int64_t> stride_vec(strides.size(), 1);
+  if (slice_mode == "end") {
+    for (size_t i = 0; i < strides.size(); ++i) {
+      ICHECK(strides[i].defined());
+      stride_vec[i] = GetConstInt(strides[i]);
+    }
+  }
+  const int64_t max_range = std::numeric_limits<int64_t>::max();
+  std::vector<int64_t> begin_vec;
+  for (size_t i = 0; i < begin.size(); ++i) {
+    if (!begin[i].defined()) {
+      // value=None
+      begin_vec.push_back(stride_vec[i] > 0 ? 0 : max_range);
+    } else {
+      begin_vec.push_back(GetConstInt(begin[i]));
+    }
+  }
+  std::vector<int64_t> end_vec;
+  for (size_t i = 0; i < end.size(); ++i) {
+    // allow end to be None
+    if (!end[i].defined()) {
+      end_vec.push_back(stride_vec[i] < 0 ? 0 : max_range);
+    } else if (slice_mode == "size") {
+      int64_t end_val = GetConstInt(end[i]);
+      if (end_val < 0) {
+        end_vec.push_back(stride_vec[i] < 0 ? 0 : max_range);
+      } else {
+        end_vec.push_back(begin_vec[i] + end_val);
+      }
+    } else {
+      end_vec.push_back(GetConstInt(end[i]));
+    }
+  }
+  return std::make_tuple(begin_vec, end_vec, stride_vec);
+}
+
+inline Array<PrimExpr> StridedSliceCanonicalizeBegin(const Array<PrimExpr>& ishape,
+                                                     const std::vector<int64_t>& begin,
+                                                     const std::vector<int64_t>& strides,
+                                                     const Array<Integer>& axes, DataType dtype,
+                                                     std::string slice_mode = "end") {
+  Array<PrimExpr> begin_expr;
+  for (size_t i = 0; i < axes.size(); ++i) {
+    if (ishape[axes[i].IntValue()]->IsInstance<tvm::IntImmNode>()) {
+      int64_t dim_i = GetConstInt(ishape[axes[i].IntValue()]);
+      int64_t begin_i = CanonicalizeIndex(begin[i], dim_i, strides[i]);
+      begin_expr.push_back(make_const(dtype, begin_i));
+    } else {
+      auto idim = ishape[axes[i].IntValue()];
+      auto b_expr = make_const(dtype, begin[i]);
+      PrimExpr b = begin[i] < 0 ? b_expr + idim : b_expr;
+      auto s = strides[i];
+      if (s < 0) {
+        b = tvm::min(b, idim - 1);
+      } else {
+        b = tvm::if_then_else(b < 0, 0, b);
+      }
+      begin_expr.push_back(b);
+    }
+  }
+  return begin_expr;
+}
+
+inline Array<PrimExpr> StridedSliceOutputShape(const Array<PrimExpr>& ishape,
+                                               const std::vector<int64_t>& begin,
+                                               const std::vector<int64_t>& end,
+                                               const std::vector<int64_t>& strides,
+                                               const Array<Integer>& axes, std::string slice_mode,
+                                               const Array<PrimExpr>& begin_canonicalized,
+                                               bool use_any = false) {
+  const size_t src_tensor_dim = ishape.size();
+  Array<PrimExpr> out_shape;
+  for (size_t i = 0; i < src_tensor_dim; ++i) {
+    out_shape.push_back(ishape[i]);
+  }
+
+  for (size_t i = 0; i < axes.size(); ++i) {
+    if (ishape[axes[i].IntValue()]->IsInstance<tvm::IntImmNode>()) {
+      const int64_t dim_i = GetConstInt(ishape[axes[i].IntValue()]);
+      ICHECK(begin_canonicalized[i]->IsInstance<tvm::IntImmNode>());
+      int64_t begin_i = GetConstInt(begin_canonicalized[i]);
+      int64_t end_i = CanonicalizeIndex(end[i], dim_i, strides[i]);
+      int interval = std::abs(end_i - begin_i);
+      int slice_size =
+          static_cast<int>((interval + std::abs(strides[i]) - 1) / std::abs(strides[i]));
+      ICHECK(strides[i] < 0 ? (end_i <= begin_i) : (begin_i <= end_i))
+          << ": Input [Begin=" << begin[i] << ", End=" << end[i] << "] is invalid for axis=" << i;
+      out_shape.Set(axes[i].IntValue(), cast(out_shape[i].dtype(), PrimExpr(slice_size)));
+    } else if (use_any) {
+      out_shape.Set(axes[i].IntValue(), tvm::tir::Any());
+    } else {
+      out_shape.Set(axes[i].IntValue(), tvm::tir::Var("dim", out_shape[i]->dtype));
+    }
+  }
+
+  return out_shape;
+}
+
+}  // namespace detail
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_DETAIL_STRIDED_SLICE_H_
diff --git a/darknet_drp_ros/include/tvm/topi/detail/tensor_utils.h b/darknet_drp_ros/include/tvm/topi/detail/tensor_utils.h
new file mode 100644
index 0000000..397c70c
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/detail/tensor_utils.h
@@ -0,0 +1,147 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file tensor_utils.h
+ * \brief Utility functions for handling tensor
+ */
+#ifndef TVM_TOPI_DETAIL_TENSOR_UTILS_H_
+#define TVM_TOPI_DETAIL_TENSOR_UTILS_H_
+
+#include <tvm/te/operation.h>
+
+#include <vector>
+namespace tvm {
+namespace topi {
+namespace detail {
+
+using namespace tvm::te;
+
+/*!
+ * \brief Check whether input shape has dimension of size 0;
+ *
+ * \param x Input shape
+ *
+ * \return True if the input shape is empty.
+ */
+inline bool is_empty_shape(const Array<PrimExpr>& x) {
+  bool is_empty = false;
+  for (const auto& dim : x) {
+    if (auto int_dim = dim.as<IntImmNode>()) {
+      if (int_dim->value == 0) {
+        is_empty = true;
+        break;
+      }
+    }
+  }
+  return is_empty;
+}
+
+/*!
+ * \brief Sample a point in a tensor using bilinear interpolation.
+ *
+ * \param input The input tensor.
+ * \param indices The index of the target point, which can be fractional
+ * \param max_y The maximum of y dimension
+ * \param max_x The maximum of x dimension
+ *
+ * \return The interpolated value in the given index.
+ */
+inline PrimExpr bilinear_sample_nchw(const Tensor& input, const Array<PrimExpr>& indices,
+                                     const PrimExpr max_y, const PrimExpr max_x) {
+  auto batch_id = indices[0];
+  auto channel_id = indices[1];
+  auto in_y = indices[2];
+  auto in_x = indices[3];
+
+  auto y_low = tvm::cast(DataType::Int(32), tvm::floor(in_y));
+  auto y_high = y_low + 1;
+
+  auto x_low = tvm::cast(DataType::Int(32), tvm::floor(in_x));
+  auto x_high = x_low + 1;
+
+  auto wy_h = in_y - y_low;
+  auto wx_h = in_x - x_low;
+  auto wy_l = 1 - wy_h;
+  auto wx_l = 1 - wx_h;
+
+  PrimExpr val = 0;
+  std::vector<std::vector<PrimExpr>> wx_xp{{wx_l, x_low}, {wx_h, x_high}};
+  std::vector<std::vector<PrimExpr>> wy_yp{{wy_l, y_low}, {wy_h, y_high}};
+  for (auto wx_xp_ele : wx_xp) {
+    for (auto wy_yp_ele : wy_yp) {
+      auto wx = wx_xp_ele[0];
+      auto xp = wx_xp_ele[1];
+      auto wy = wy_yp_ele[0];
+      auto yp = wy_yp_ele[1];
+      val += tvm::if_then_else(0 <= yp && yp <= max_y && 0 <= xp && xp <= max_x,
+                               wx * wy * input(batch_id, channel_id, yp, xp), 0);
+    }
+  }
+  return val;
+}
+
+/*!
+ * \brief Sample a point in a tensor using bilinear interpolation.
+ *
+ * \param input The input tensor.
+ * \param indices The index of the target point, which can be fractional
+ * \param max_y The maximum of y dimension
+ * \param max_x The maximum of x dimension
+ *
+ * \return The interpolated value in the given index.
+ */
+inline PrimExpr bilinear_sample_nhwc(const Tensor& input, const Array<PrimExpr>& indices,
+                                     const PrimExpr max_y, const PrimExpr max_x) {
+  auto batch_id = indices[0];
+  auto channel_id = indices[3];
+  auto in_y = indices[1];
+  auto in_x = indices[2];
+
+  auto y_low = tvm::cast(DataType::Int(32), tvm::floor(in_y));
+  auto y_high = y_low + 1;
+
+  auto x_low = tvm::cast(DataType::Int(32), tvm::floor(in_x));
+  auto x_high = x_low + 1;
+
+  auto wy_h = in_y - y_low;
+  auto wx_h = in_x - x_low;
+  auto wy_l = 1 - wy_h;
+  auto wx_l = 1 - wx_h;
+
+  PrimExpr val = 0;
+  std::vector<std::vector<PrimExpr>> wx_xp{{wx_l, x_low}, {wx_h, x_high}};
+  std::vector<std::vector<PrimExpr>> wy_yp{{wy_l, y_low}, {wy_h, y_high}};
+  for (auto wx_xp_ele : wx_xp) {
+    for (auto wy_yp_ele : wy_yp) {
+      auto wx = wx_xp_ele[0];
+      auto xp = wx_xp_ele[1];
+      auto wy = wy_yp_ele[0];
+      auto yp = wy_yp_ele[1];
+      val += tvm::if_then_else(0 <= yp && yp <= max_y && 0 <= xp && xp <= max_x,
+                               wx * wy * input(batch_id, yp, xp, channel_id), 0);
+    }
+  }
+  return val;
+}
+
+}  // namespace detail
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_DETAIL_TENSOR_UTILS_H_
diff --git a/darknet_drp_ros/include/tvm/topi/einsum.h b/darknet_drp_ros/include/tvm/topi/einsum.h
new file mode 100644
index 0000000..5e7813f
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/einsum.h
@@ -0,0 +1,96 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file topi/einsum.h
+ * \brief Einstein summation op
+ */
+#ifndef TVM_TOPI_EINSUM_H_
+#define TVM_TOPI_EINSUM_H_
+
+#define LABELRANGE 128
+#define NPY_MAXDIMS 16
+#define NPY_MAXARGS 16
+
+#include <tvm/te/operation.h>
+#include <tvm/tir/data_layout.h>
+#include <tvm/topi/detail/constant_utils.h>
+#include <tvm/topi/detail/ravel_unravel.h>
+#include <tvm/topi/detail/tensor_utils.h>
+#include <tvm/topi/tags.h>
+
+#include <algorithm>
+#include <bitset>
+#include <iterator>
+#include <string>
+#include <tuple>
+#include <unordered_set>
+#include <vector>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+using namespace topi::detail;
+
+/*!
+ * \brief Compute the shape of the output.
+ * \param subscripts input subscripts.
+ * \param operands operand tensors.
+ *
+ * \return the shape of the output.
+ */
+Array<PrimExpr> InferEinsumShape(const std::string& subscripts,
+                                 const std::vector<Array<PrimExpr>>& operands);
+
+/*!
+ * \brief Evaluates the Einstein summation convention on the operands.
+ *
+ * \param subscripts_str Specifies the subscripts for summation as comma separated list of
+ * subscript labels.
+ * \param inputs Arrays for the operation.
+ * \param name The name of the operation.
+ * \param tag The tag to mark the operation.
+ *
+ * \return The calculation based on the Einstein summation convention.
+ */
+Tensor einsum(const std::string& subscripts_str, const Array<Tensor> inputs,
+              std::string name = "T_einsum", std::string tag = kEinsum);
+
+struct EinsumEquation {
+  /*!
+   * \brief Create EinsumEquation from a string.
+   * The result will be converted to the explicit mode of Einsum if it is in implicit mode.
+   * \return The created EinsumEquation.
+   */
+  static EinsumEquation FromString(const std::string& equation);
+  using Label = char;
+  using Subscript = std::vector<Label>;
+  // Special label value for ellipsis. The value is chosen to be less than any other letters so make
+  // sorting easier.
+  static constexpr Label kEllipsis = '\0';
+  // The input subscripts for each operand of the Einsum operator.
+  std::vector<Subscript> inputs;
+  // The output subscript of the Einsum equation.
+  Subscript output;
+};
+
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_EINSUM_H_
diff --git a/darknet_drp_ros/include/tvm/topi/elemwise.h b/darknet_drp_ros/include/tvm/topi/elemwise.h
new file mode 100644
index 0000000..f26105c
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/elemwise.h
@@ -0,0 +1,548 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file elemwise.h
+ * \brief Elementwise op constructions
+ */
+#ifndef TVM_TOPI_ELEMWISE_H_
+#define TVM_TOPI_ELEMWISE_H_
+
+#include <tvm/tir/builtin.h>
+#include <tvm/tir/expr.h>
+#include <tvm/topi/tags.h>
+
+#include <algorithm>
+#include <string>
+
+#include "broadcast.h"
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+
+// Unary intrinsic operators
+#define TOPI_DECLARE_UNARY_OP(OpName)                                                   \
+  inline Tensor OpName(const Tensor& x, std::string name = "T_" #OpName,                \
+                       std::string tag = kElementWise) {                                \
+    return compute(                                                                     \
+        x->shape, [&](const Array<Var>& i) { return ::tvm::OpName(x(i)); }, name, tag); \
+  }
+
+TOPI_DECLARE_UNARY_OP(exp);
+TOPI_DECLARE_UNARY_OP(erf);
+TOPI_DECLARE_UNARY_OP(sigmoid);
+TOPI_DECLARE_UNARY_OP(sqrt);
+TOPI_DECLARE_UNARY_OP(log);
+TOPI_DECLARE_UNARY_OP(log2);
+TOPI_DECLARE_UNARY_OP(log10);
+TOPI_DECLARE_UNARY_OP(floor);
+TOPI_DECLARE_UNARY_OP(ceil);
+TOPI_DECLARE_UNARY_OP(round);
+TOPI_DECLARE_UNARY_OP(trunc);
+TOPI_DECLARE_UNARY_OP(abs);
+TOPI_DECLARE_UNARY_OP(cos);
+TOPI_DECLARE_UNARY_OP(cosh);
+TOPI_DECLARE_UNARY_OP(tan);
+TOPI_DECLARE_UNARY_OP(sin);
+TOPI_DECLARE_UNARY_OP(sinh);
+TOPI_DECLARE_UNARY_OP(acos);
+TOPI_DECLARE_UNARY_OP(acosh);
+TOPI_DECLARE_UNARY_OP(asin);
+TOPI_DECLARE_UNARY_OP(asinh);
+TOPI_DECLARE_UNARY_OP(atan);
+TOPI_DECLARE_UNARY_OP(atanh);
+TOPI_DECLARE_UNARY_OP(isnan);
+TOPI_DECLARE_UNARY_OP(tanh);
+TOPI_DECLARE_UNARY_OP(isfinite);
+TOPI_DECLARE_UNARY_OP(isinf);
+
+/*!
+ * \brief Fast_tanh_float implementation from Eigen
+ * https://github.com/eigenteam/eigen-git-mirror/blob/master/Eigen/src/Core/MathFunctionsImpl.h#L26
+ */
+inline Tensor fast_tanh_float(const Tensor& in, std::string name, std::string tag) {
+  // Clamp the inputs to the range [-9, 9] since anything outside
+  // this range is +/-1.0f in single-precision.
+  auto x = maximum(make_const(in->dtype, -9.0), minimum(make_const(in->dtype, 9.0), in));
+
+  // The monomial coefficients of the numerator polynomial (odd).
+  auto alpha_1 = make_const(in->dtype, 4.89352455891786e-03);
+  auto alpha_3 = make_const(in->dtype, 6.37261928875436e-04);
+  auto alpha_5 = make_const(in->dtype, 1.48572235717979e-05);
+  auto alpha_7 = make_const(in->dtype, 5.12229709037114e-08);
+  auto alpha_9 = make_const(in->dtype, -8.60467152213735e-11);
+  auto alpha_11 = make_const(in->dtype, 2.00018790482477e-13);
+  auto alpha_13 = make_const(in->dtype, -2.76076847742355e-16);
+
+  // The monomial coefficients of the denominator polynomial (even).
+  auto beta_0 = make_const(in->dtype, 4.89352518554385e-03);
+  auto beta_2 = make_const(in->dtype, 2.26843463243900e-03);
+  auto beta_4 = make_const(in->dtype, 1.18534705686654e-04);
+  auto beta_6 = make_const(in->dtype, 1.19825839466702e-06);
+
+  return compute(
+      x->shape,
+      [&](const Array<Var>& i) {
+        auto x2 = x(i) * x(i);
+        auto p = x2 * alpha_13 + alpha_11;
+        p = x2 * p + alpha_9;
+        p = x2 * p + alpha_7;
+        p = x2 * p + alpha_5;
+        p = x2 * p + alpha_3;
+        p = x2 * p + alpha_1;
+        p = x(i) * p;
+
+        auto q = x2 * beta_6 + beta_4;
+        q = x2 * q + beta_2;
+        q = x2 * q + beta_0;
+        return p / q;
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Creates an operation that returns hyperbolic tanh of a given tensor
+ *
+ * \param x The input tensor
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is tanh
+ */
+inline Tensor fast_tanh(const Tensor& x, std::string name = "T_fast_tanh",
+                        std::string tag = kElementWise) {
+  if (x->dtype == DataType::Float(32)) {
+    // invoke fast_tanh_float implementation
+    return fast_tanh_float(x, name, tag);
+  } else {
+    // fallback to default implementation
+    return compute(
+        x->shape, [&](const Array<Var>& i) { return ::tvm::tanh(x(i)); }, name, tag);
+  }
+}
+
+/*!
+ * \brief Creates an operation that returns identity of a given tensor
+ *
+ * \param x The input tensor
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the identity operation
+ */
+inline Tensor identity(const Tensor& x, std::string name = "T_identity",
+                       std::string tag = kElementWise) {
+  return compute(
+      x->shape, [&](const Array<Var>& i) { return x(i); }, name, tag);
+}
+
+/*!
+ * \brief Creates an operation that returns the negation of a given tensor
+ *
+ * \param x The input tensor
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the negation operation
+ */
+inline Tensor negative(const Tensor& x, std::string name = "T_negative",
+                       std::string tag = kElementWise) {
+  return compute(
+      x->shape, [&](const Array<Var>& i) { return -x(i); }, name, tag);
+}
+
+/*!
+ * \brief Creates an operation that returns the logical NOT of a given tensor
+ *
+ * \param x The input tensor
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the logical NOT operation
+ */
+inline Tensor logical_not(const Tensor& x, std::string name = "T_logical_not",
+                          std::string tag = kElementWise) {
+  return compute(
+      x->shape, [&](const Array<Var>& i) { return !x(i); }, name, tag);
+}
+
+/*!
+ * \brief Creates an operation that returns the bitwise NOT of a given tensor
+ *
+ * \param x The input tensor
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the bitwise NOT operation
+ */
+inline Tensor bitwise_not(const Tensor& x, std::string name = "T_bitwise_not",
+                          std::string tag = kElementWise) {
+  return compute(
+      x->shape, [&](const Array<Var>& i) { return ~x(i); }, name, tag);
+}
+
+/*!
+ * \brief Returns the sign of the tensor
+ *
+ * \param x The input tensor
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the sign
+ */
+inline Tensor sign(const Tensor& x, std::string name = "T_sign", std::string tag = kElementWise) {
+  return compute(
+      x->shape,
+      [&](const Array<Var>& i) {
+        PrimExpr zero = make_zero(x->dtype);
+        PrimExpr one = make_const(x->dtype, 1);
+        PrimExpr minus_one = make_const(x->dtype, -1);
+        auto s1 = tvm::tir::Select((x(i) < zero), minus_one, zero);
+        auto s2 = tvm::tir::Select((x(i) > zero), one, s1);
+        return s2;
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Creates an operation that returns rsqrt of a given tensor
+ *
+ * \param x The input tensor
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the rsqrt operation
+ */
+inline Tensor rsqrt(const Tensor& x, std::string name = "tensor", std::string tag = kElementWise) {
+  return compute(
+      x->shape,
+      [&](const Array<Var>& i) {
+        PrimExpr one = make_const(x->dtype, 1);
+        return one / tvm::sqrt(x(i));
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Creates an operation that clips each element of a tensor to
+ * the interval [a_min, a_max]
+ *
+ * \param x The input tensor
+ * \param a_min The inclusive lower bound of the interval
+ * \param a_max The inclusive upper bound of the interval
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the clip operation
+ */
+inline Tensor clip(const Tensor& x, const PrimExpr& a_min, const PrimExpr& a_max,
+                   std::string name = "T_clip", std::string tag = kElementWise) {
+  return compute(
+      x->shape,
+      [&](const Array<Var>& i) {
+        auto min_val = tvm::cast(x->dtype, a_min);
+        auto max_val = tvm::cast(x->dtype, a_max);
+        return tvm::max(tvm::min(x(i), max_val), min_val);  // NOLINT(*)
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Cast each element of x to the given type. If expr is
+ * scalar and type is a corresponding vector type, a
+ * Broadcast is generated, otherwise a Cast is generated.
+ *
+ * \param x The input tensor
+ * \param type The type to cast to
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the cast operation
+ */
+inline Tensor cast(const Tensor& x, DataType type, std::string name = "T_cast",
+                   std::string tag = kElementWise) {
+  return compute(
+      x->shape,
+      [&](const Array<Var>& i) -> PrimExpr {
+        auto expr = x(i);
+        if (expr.dtype().code() == type.code() && expr.dtype().bits() == type.bits()) {
+          if (expr.dtype().lanes() == type.lanes()) {
+            return expr;
+          } else if (expr.dtype().lanes() == 1 && type.lanes() > 1) {
+            return tvm::tir::Broadcast(expr, type.lanes());
+          }
+        }
+
+        return tvm::cast(type, x(i));
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Reinterpret each element of x to the given type.
+
+ * \param x The input tensor
+ * \param type The type to cast to
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the reinterpret operation
+ */
+inline Tensor reinterpret(const Tensor& x, DataType type, std::string name = "tensor",
+                          std::string tag = kElementWise) {
+  return compute(
+      x->shape,
+      [&](const Array<Var>& i) {
+        return tvm::tir::Call(type, tvm::tir::builtin::reinterpret(), {x(i)});
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Creates an operation that sum each element of a tensor
+ *
+ * \param xs The input tensor array
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the sum operation
+ */
+inline Tensor elemwise_sum(const Array<Tensor>& xs, std::string name = "T_elemwise_sum",
+                           std::string tag = kElementWise) {
+  ICHECK_GT(xs.size(), 0) << "elemwise sum must have at least one input tensor.";
+  return compute(
+      xs[0]->shape,
+      [&](const Array<Var>& i) {
+        auto sum_expr = xs[0](i);
+        for (size_t j = 1; j < xs.size(); j++) {
+          sum_expr = sum_expr + xs[j](i);
+        }
+        return sum_expr;
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Creates an operation that fill a tensor with fill_value
+ *
+ * \param shape The shape of a tensor
+ * \param dtype The Type of fill_value
+ * \param fill_value The value to be filled
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the full operation
+ */
+inline Tensor full(const Array<PrimExpr>& shape, DataType dtype, const PrimExpr fill_value,
+                   std::string name = "T_full", std::string tag = kElementWise) {
+  PrimExpr ev = cast(dtype, fill_value);
+  if (!ev.defined()) {
+    LOG(ERROR) << "Can't cast fill_value to " << dtype;
+  }
+  return compute(
+      shape, [&](const Array<Var>& i) { return ev; }, name, tag);
+}
+
+/*!
+ * \brief Creates an operation that construct a tensor with same shape as input tensor,
+ * then fill a tensor with fill_value
+ *
+ * \param x The input tensor
+ * \param fill_value The value to be filled
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op memeber is the full_like operation
+ */
+inline Tensor full_like(const Tensor& x, const PrimExpr fill_value,
+                        std::string name = "T_full_like", std::string tag = kElementWise) {
+  PrimExpr ev = cast(x->dtype, fill_value);
+  return compute(
+      x->shape, [&](const Array<Var>& i) { return ev; }, name, tag);
+}
+
+/*!
+ * \brief Fast exponential function implementation
+ *
+ * \param _x The input tensor
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is exponent operation
+ *
+ * \note Function computes:
+ * log2(e^x) = x * log2(e) * log2(2) =>
+ * log2(e^x) = log2(2^(x*log2(e))) =>
+ * e^x = 2^(x*log2(e))
+ * Splitting power x*log2(e) into integer and fractional parts:
+ * e^(n+f) = e^n * e^f
+ * n = floor(x*log2(e) + 1/2)
+ * f = x - n * ln(2)
+ * exp(x) = 2^n * exp(y)
+ * Approximation for fractional part:
+ * y = exp(f) = 1 + 2 * P(x**2)/(Q(x**2) - P(x**2))
+ */
+inline Tensor fast_exp_float32(const Tensor& _x, std::string name, std::string tag) {
+  auto x_hi = make_const(DataType::Float(32), 88.3762626647950f);
+  auto x_lo = make_const(DataType::Float(32), -88.3762626647949f);
+  auto log2e = make_const(DataType::Float(32), 1.44269504088896341f);
+  auto ln2 = make_const(DataType::Float(32), 0.6931471805599453f);
+  PrimExpr p[6] = {make_const(DataType::Float(32), 1.9875691500E-4f),
+                   make_const(DataType::Float(32), 1.3981999507E-3f),
+                   make_const(DataType::Float(32), 8.3334519073E-3f),
+                   make_const(DataType::Float(32), 4.1665795894E-2f),
+                   make_const(DataType::Float(32), 1.6666665459E-1f),
+                   make_const(DataType::Float(32), 5.0000001201E-1f)};
+  auto one = make_const(DataType::Float(32), 1.0f);
+  auto one_half = make_const(DataType::Float(32), 0.5f);
+  auto b = make_const(DataType::Float(32), 127.0f);
+
+  return compute(
+      _x->shape,
+      [&](const Array<Var>& i) {
+        // clamp x
+        auto x = ::tvm::max(::tvm::min(_x(i), x_hi), x_lo);
+        // integer part
+        auto n = ::tvm::floor(x * log2e + one_half);
+        // fractional part
+        auto f = x - n * ln2;
+        auto y =
+            (((((p[0] * f + p[1]) * f + p[2]) * f + p[3]) * f + p[4]) * f + p[5]) * f * f + f + one;
+        // Return 2^m * exp(r).
+        auto ef =
+            tvm::reinterpret(DataType::Float(32), ::tvm::cast(DataType::Int(32), n + b) << 23);
+        return ::tvm::max(ef * y, _x(i));  // NOLINT(*)
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Fast exponential function implementation
+ *
+ * \param x The input tensor
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is exponent operation
+ *
+ */
+inline Tensor fast_exp(const Tensor& x, std::string name = "T_fast_exp",
+                       std::string tag = kElementWise) {
+  if (x->dtype == DataType::Float(32)) {
+    auto ret = fast_exp_float32(x, name, tag);
+    return ret;
+  } else {
+    return compute(
+        x->shape, [&](const Array<Var>& i) { return ::tvm::exp(x(i)); }, name, tag);
+  }
+}
+
+/*!
+ * \brief Fast_erf_float expression from Eigen
+ * https://github.com/eigenteam/eigen-git-mirror/blob/master/unsupported/Eigen/src/SpecialFunctions/SpecialFunctionsImpl.h#L290
+ * \param arg The input expression.
+ * \param bits The number of bits in the type.
+ */
+inline PrimExpr fast_erf_float_expr(PrimExpr arg, int bits) {
+  auto plus_4 = make_const(DataType::Float(bits), 4.f);
+  auto minus_4 = make_const(DataType::Float(bits), -4.f);
+
+  // The monomial coefficients of the numerator polynomial (odd).
+  auto alpha_1 = make_const(DataType::Float(bits), -1.60960333262415e-02f);
+  auto alpha_3 = make_const(DataType::Float(bits), -2.95459980854025e-03f);
+  auto alpha_5 = make_const(DataType::Float(bits), -7.34990630326855e-04f);
+  auto alpha_7 = make_const(DataType::Float(bits), -5.69250639462346e-05f);
+  auto alpha_9 = make_const(DataType::Float(bits), -2.10102402082508e-06f);
+  auto alpha_11 = make_const(DataType::Float(bits), 2.77068142495902e-08f);
+  auto alpha_13 = make_const(DataType::Float(bits), -2.72614225801306e-10f);
+
+  // The monomial coefficients of the denominator polynomial (even).
+  auto beta_0 = make_const(DataType::Float(bits), -1.42647390514189e-02f);
+  auto beta_2 = make_const(DataType::Float(bits), -7.37332916720468e-03f);
+  auto beta_4 = make_const(DataType::Float(bits), -1.68282697438203e-03f);
+  auto beta_6 = make_const(DataType::Float(bits), -2.13374055278905e-04f);
+  auto beta_8 = make_const(DataType::Float(bits), -1.45660718464996e-05f);
+
+  // clamp x
+  auto x = tvm::max(tvm::min(arg, plus_4), minus_4);
+  auto x2 = x * x;
+
+  // Evaluate the numerator polynomial p.
+  auto p = x2 * alpha_13 + alpha_11;
+  p = x2 * p + alpha_9;
+  p = x2 * p + alpha_7;
+  p = x2 * p + alpha_5;
+  p = x2 * p + alpha_3;
+  p = x2 * p + alpha_1;
+  p = x * p;
+
+  // Evaluate the denominator polynomial p.
+  auto q = x2 * beta_8 + beta_6;
+  q = x2 * q + beta_4;
+  q = x2 * q + beta_2;
+  q = x2 * q + beta_0;
+
+  return p / q;
+}
+
+/*!
+ * \brief Fast_erf_float expression from Eigen
+ */
+inline Tensor fast_erf_float32(const Tensor& data, std::string name, std::string tag) {
+  return compute(
+      data->shape, [&](const Array<Var>& i) { return fast_erf_float_expr(data(i), 32); }, name,
+      tag);
+}
+
+/*!
+ * \brief Fast_erf_float expression from Eigen for float16.
+ */
+inline Tensor fast_erf_float16(const Tensor& data, std::string name, std::string tag) {
+  return compute(
+      data->shape, [&](const Array<Var>& i) { return fast_erf_float_expr(data(i), 16); }, name,
+      tag);
+}
+
+/*!
+ * \brief Fast erf implementation
+ *
+ * \param x The input tensor
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is erf operation
+ */
+inline Tensor fast_erf(const Tensor& x, std::string name = "T_fast_erf",
+                       std::string tag = kElementWise) {
+  if (x->dtype == DataType::Float(32)) {
+    auto ret = fast_erf_float32(x, name, tag);
+    return ret;
+  } else if (x->dtype == DataType::Float(16)) {
+    auto ret = fast_erf_float16(x, name, tag);
+    return ret;
+  } else {
+    return topi::erf(x);
+  }
+}
+
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_ELEMWISE_H_
diff --git a/darknet_drp_ros/include/tvm/topi/generic/default.h b/darknet_drp_ros/include/tvm/topi/generic/default.h
new file mode 100644
index 0000000..752b6ad
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/generic/default.h
@@ -0,0 +1,83 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file generic/default.h
+ * \brief Generic default schedule
+ */
+#ifndef TVM_TOPI_GENERIC_DEFAULT_H_
+#define TVM_TOPI_GENERIC_DEFAULT_H_
+
+#include <tvm/target/generic_func.h>
+#include <tvm/te/operation.h>
+#include <tvm/te/schedule_pass.h>
+#include <tvm/topi/detail/fuse.h>
+#include <tvm/topi/tags.h>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+
+namespace generic {
+/*!
+ * \brief Create a generic default schedule for the given output tensors.
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+inline Schedule default_schedule(const Target& target, const Array<Tensor>& outs) {
+  Array<Operation> out_ops;
+  for (auto t : outs) {
+    out_ops.push_back(t->op);
+  }
+  auto s = create_schedule(out_ops);
+  return s;
+}
+
+/*!
+ * \brief Create a generic default schedule for the given output tensors, and apply
+ * auto inline
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+inline Schedule default_schedule_auto_inline(const Target& target, const Array<Tensor>& outs) {
+  Array<Operation> out_ops;
+  for (auto t : outs) {
+    out_ops.push_back(t->op);
+  }
+  auto s = create_schedule(out_ops);
+  auto x = outs[0];
+  tvm::te::AutoInlineInjective(s);
+  auto axis = s[x]->op.as<ComputeOpNode>()->axis;
+  if (axis.size() > 0) {
+    detail::Fuse(s[x], axis);
+  }
+  return s;
+}
+
+}  // namespace generic
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_GENERIC_DEFAULT_H_
diff --git a/darknet_drp_ros/include/tvm/topi/generic/extern.h b/darknet_drp_ros/include/tvm/topi/generic/extern.h
new file mode 100644
index 0000000..0f1f408
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/generic/extern.h
@@ -0,0 +1,69 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file generic/extern.h
+ * \brief Schedule for extern followed by injective ops
+ */
+#ifndef TVM_TOPI_GENERIC_EXTERN_H_
+#define TVM_TOPI_GENERIC_EXTERN_H_
+
+#include <tvm/target/generic_func.h>
+#include <tvm/te/operation.h>
+#include <tvm/te/schedule_pass.h>
+#include <tvm/topi/detail/fuse.h>
+#include <tvm/topi/generic/injective.h>
+#include <tvm/topi/tags.h>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+
+namespace generic {
+/*!
+ * \brief Schedule an extern op followed by injective operations
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the op.
+ */
+inline Schedule schedule_extern(const Target& target, const Array<Tensor>& outs) {
+  Array<Operation> out_ops;
+  for (auto t : outs) {
+    out_ops.push_back(t->op);
+  }
+  auto s = create_schedule(out_ops);
+
+  tvm::te::AutoInlineInjective(s);
+  for (auto out : outs) {
+    if (out->op->IsInstance<ExternOpNode>()) {
+      continue;
+    }
+    tvm::GenericFunc::Get("schedule_injective_from_existing")(s, out);
+  }
+
+  return s;
+}
+
+}  // namespace generic
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_GENERIC_EXTERN_H_
diff --git a/darknet_drp_ros/include/tvm/topi/generic/injective.h b/darknet_drp_ros/include/tvm/topi/generic/injective.h
new file mode 100644
index 0000000..c48c03e
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/generic/injective.h
@@ -0,0 +1,77 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file generic/injective.h
+ * \brief Generic schedule for injective operations
+ */
+#ifndef TVM_TOPI_GENERIC_INJECTIVE_H_
+#define TVM_TOPI_GENERIC_INJECTIVE_H_
+
+#include <tvm/target/generic_func.h>
+#include <tvm/te/operation.h>
+#include <tvm/te/schedule_pass.h>
+#include <tvm/topi/detail/fuse.h>
+#include <tvm/topi/tags.h>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+
+namespace generic {
+
+/*!
+ * \brief Updates an existing schedule for the given injective ops.
+ *
+ * \param sch The schedule to update.
+ * \param out The tensor representing the injective op.
+ *
+ * \return The updated schedule.
+ */
+inline Schedule schedule_injective_from_existing(Schedule sch, const Tensor& out) {
+  detail::Fuse(sch[out], sch[out]->op.as<ComputeOpNode>()->axis);
+  return sch;
+}
+
+/*!
+ * \brief Create a generic schedule for the given injective ops.
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+inline Schedule schedule_injective(const Target& target, const Array<Tensor>& outs) {
+  Array<Operation> out_ops;
+  for (auto t : outs) {
+    out_ops.push_back(t->op);
+  }
+  auto s = create_schedule(out_ops);
+  tvm::te::AutoInlineInjective(s);
+  auto x = outs[0];
+  schedule_injective_from_existing(s, x);
+
+  return s;
+}
+
+}  // namespace generic
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_GENERIC_INJECTIVE_H_
diff --git a/darknet_drp_ros/include/tvm/topi/nn.h b/darknet_drp_ros/include/tvm/topi/nn.h
new file mode 100644
index 0000000..90c1c09
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/nn.h
@@ -0,0 +1,695 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \brief NN op constructions
+ * \file topi/nn.h
+ */
+#ifndef TVM_TOPI_NN_H_
+#define TVM_TOPI_NN_H_
+
+#include <tvm/arith/analyzer.h>
+#include <tvm/te/operation.h>
+#include <tvm/tir/expr.h>
+#include <tvm/tir/op.h>
+#include <tvm/topi/detail/constant_utils.h>
+#include <tvm/topi/reduction.h>
+#include <tvm/topi/tags.h>
+#include <tvm/topi/transform.h>
+
+#include <algorithm>
+#include <string>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+
+/*!
+ * \brief Creates an operation that performs a rectified linear unit
+ *
+ * \param t The input tensor
+ * \param threshold The relu threshold (default 0)
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the relu operation
+ */
+template <typename T>
+inline tvm::te::Tensor relu(const tvm::te::Tensor& t, T threshold = static_cast<T>(0),
+                            std::string name = "T_relu", std::string tag = kElementWise) {
+  return tvm::te::compute(
+      t->shape,
+      [&](const tvm::Array<tvm::tir::Var>& i) {
+        auto threshold_const = tvm::tir::make_const(t->dtype, threshold);
+        return tvm::max(t(i), threshold_const);
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Creates an operation that performs a leaky rectified linear unit
+ *
+ * \param t The input tensor
+ * \param alpha The slope for the small gradient when t < 0
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the leaky relu operation
+ */
+inline tvm::te::Tensor leaky_relu(const tvm::te::Tensor& t, double alpha = 0.1,
+                                  std::string name = "T_leaky_relu",
+                                  std::string tag = kElementWise) {
+  return tvm::te::compute(
+      t->shape,
+      [&](const tvm::Array<tvm::tir::Var>& i) {
+        auto value = t(i);
+        auto calpha = tvm::tir::make_const(value.dtype(), alpha);
+        return tvm::tir::Select(value > 0, value, value * calpha);
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Creates an operation that performs a parametric rectified linear unit
+ *
+ * \param x The input data tensor
+ * \param slope The channel-wise slope tensor
+ * \param axis The axis where the channel data needs to be applied
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the parametric relu operation
+ */
+inline tvm::te::Tensor prelu(const tvm::te::Tensor& x, const tvm::te::Tensor& slope,
+                             const int axis = 1, std::string name = "T_prelu",
+                             std::string tag = kBroadcast) {
+  ICHECK((size_t)axis < x->shape.size()) << "Wrong axis (" << axis << ")value. ";
+  ICHECK(topi::detail::GetConstInt(slope->shape[0]) == topi::detail::GetConstInt(x->shape[axis]))
+      << "Wrong slope shape received.";
+
+  return tvm::te::compute(
+      x->shape,
+      [&](const tvm::Array<tvm::tir::Var>& indices) {
+        auto xval = x(indices);
+        return tvm::tir::Select(xval > 0, xval, xval * slope(indices[axis]));
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Creates an operation that performs padding
+ *
+ * \param t The input tensor
+ * \param pad_before An Array of Expr describing the padding before the
+ * respective iterator
+ * \param pad_after An Array of Expr describing the padding after the
+ * respective iterator
+ * \param pad_value The value to fill padding elements with
+ * \param pad_mode Padding type to use.
+ * "constant" pads with constant_value;
+ * "edge" pads using the edge values of the input array;
+ * "reflect" pads by reflecting values with respect to the edges.
+ * \param dyn_output_shape Output shape of the pad op, default nullptr.
+ * You only need to pass this in if the shape was evaluated dynamically.
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the padding operation
+ *
+ * \note
+ *  The pad_after Array must either be empty or have the same length as
+ *  pad_before
+ *  When pad_after is empty, it takes the same values as pad_before (symmetric
+ *  padding)
+ *  The pad Array applies from the leading dimensions and skips missing
+ *  trailing dimensions:
+ *
+ *      pad(t(i, j, k), {1}, {0}) returns the equivalent operation for
+ *          the following pseudocode:
+ *              for i in [1, t.shape[0] + 2]:
+ *                  for i in [1, t.shape[0] + 2]:
+ *                      for i in [1, t.shape[0] + 2]:
+ *                         name(i,j,k) =
+ *                             (1 <= i <= t.shape[0] + 1) ?
+ *                                 t(i-1, j, k) : 0;
+ *
+ *
+ */
+inline tvm::te::Tensor pad(const tvm::te::Tensor& t, const tvm::Array<tvm::PrimExpr>& pad_before,
+                           tvm::Array<tvm::PrimExpr> pad_after = tvm::Array<tvm::PrimExpr>(),
+                           PrimExpr pad_value = PrimExpr(), std::string name = "T_pad",
+                           std::string tag = kElementWise, std::string pad_mode = "constant",
+                           const Array<PrimExpr>* dyn_output_shape = nullptr) {
+  if (pad_after.size() < pad_before.size()) {
+    for (size_t i = pad_after.size(); i < pad_before.size(); ++i) {
+      pad_after.push_back(pad_before[i]);
+    }
+  }
+
+  arith::Analyzer analyzer;
+  ICHECK_GE(pad_before.size(), 1);
+  ICHECK_EQ(pad_before.size(), pad_after.size());
+  tvm::Array<tvm::PrimExpr> pad_before_int32;
+  tvm::Array<tvm::PrimExpr> pad_after_int32;
+
+  for (const auto& ele : pad_before) {
+    pad_before_int32.push_back(tvm::cast(tvm::DataType::Int(32), ele));
+  }
+  for (const auto& ele : pad_after) {
+    pad_after_int32.push_back(tvm::cast(tvm::DataType::Int(32), ele));
+  }
+
+  tvm::Array<tvm::PrimExpr> output_shape;
+  if (dyn_output_shape == nullptr) {
+    for (size_t i = 0; i < t->shape.size(); ++i) {
+      if (i >= pad_before.size()) {
+        output_shape.push_back(t->shape[i]);
+      } else {
+        output_shape.push_back(
+            analyzer.Simplify(t->shape[i] + pad_before_int32[i] + pad_after_int32[i]));
+      }
+    }
+  } else {
+    for (size_t i = 0; i < dyn_output_shape->size(); i++) {
+      output_shape.push_back((*dyn_output_shape)[i]);
+    }
+  }
+
+  if (!pad_value.defined()) {
+    pad_value = tvm::tir::make_const(t->dtype, 0);
+  }
+
+  auto l = [&](tvm::Array<tvm::tir::Var> ovars) {
+    tvm::Array<tvm::PrimExpr> indices;
+    tvm::Array<tvm::PrimExpr> sel;
+    tvm::Array<tvm::PrimExpr> pad_idx;
+    for (size_t i = 0; i < t->shape.size(); ++i) {
+      if (i >= pad_before_int32.size()) {
+        indices.push_back(ovars[i]);
+        continue;
+      }
+      if (!topi::detail::EqualCheck(pad_before_int32[i], 0)) {
+        sel.push_back(ovars[i] >= pad_before_int32[i]);
+        indices.push_back(ovars[i] - pad_before_int32[i]);
+      } else {
+        indices.push_back(ovars[i]);
+      }
+      if (!topi::detail::EqualCheck(pad_after_int32[i], 0)) {
+        sel.push_back(analyzer.Simplify(ovars[i] < pad_before_int32[i] + t->shape[i]));
+      }
+      if (pad_mode == "edge") {
+        pad_idx.push_back(
+            tvm::if_then_else(ovars[i] < pad_before[i], 0,
+                              tvm::if_then_else(ovars[i] >= pad_before[i] + t->shape[i],
+                                                t->shape[i] - 1, ovars[i] - pad_before[i])));
+      } else if (pad_mode == "reflect") {
+        pad_idx.push_back(
+            tvm::if_then_else(ovars[i] < pad_before[i], pad_before[i] - ovars[i],
+                              tvm::if_then_else(ovars[i] >= pad_before[i] + t->shape[i],
+                                                t->shape[i] * 2 - ovars[i] + pad_before[i] - 2,
+                                                ovars[i] - pad_before[i])));
+      }
+    }
+    if (sel.size() != 0) {
+      if (pad_mode == "constant") {
+        return tvm::if_then_else(
+            foldl([](PrimExpr a, PrimExpr b, Span span) { return tvm::logical_and(a, b, span); },
+                  const_true(1), sel),
+            t(indices), pad_value);
+      } else if (pad_mode == "edge" || pad_mode == "reflect") {
+        return tvm::if_then_else(
+            foldl([](PrimExpr a, PrimExpr b, Span span) { return tvm::logical_and(a, b, span); },
+                  const_true(1), sel),
+            t(indices), t(pad_idx));
+      }
+    }
+    return t(indices);
+  };
+  return tvm::te::compute(output_shape, l, name, tag);
+}
+
+/*!
+ * \brief Creates an operation that performs a 2-D convolution with an
+ * NCHW-layout
+ *
+ * \param I The 4-D input tensor
+ * \param W The 4-D weight tensor
+ * \param pad_h A static constant padding amount applied to the height of the
+ * image, before and after (symmetric padding)
+ * \param pad_w A static constant padding amount applied to the width of the
+ * image, before and after (symmetric padding)
+ * \param stride_h A static constant striding amount applied to the height of
+ * the image, before and after (symmetric padding)
+ * \param stride_w A static constant strindingamount applied to the width of
+ * the image, before and after (symmetric padding)
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the 2-D convolution operation (NCHW
+ * layout)
+ */
+inline tvm::te::Tensor conv2d_nchw(const tvm::te::Tensor& I, const tvm::te::Tensor& W,
+                                   int pad_h = 0, int pad_w = 0, int stride_h = 1, int stride_w = 1,
+                                   std::string name = "T_conv2d_nchw",
+                                   std::string tag = kConv2dNCHW) {
+  ICHECK_EQ(4, I->shape.size());
+  ICHECK_EQ(4, W->shape.size());
+  auto pH = I->shape[2];
+  auto pW = I->shape[3];
+  tvm::Array<tvm::PrimExpr> output_shape{
+      I->shape[0],                                                    // B
+      W->shape[0],                                                    // O
+      indexdiv(I->shape[2] - W->shape[2] + 2 * pad_h, stride_h) + 1,  // H
+      indexdiv(I->shape[3] - W->shape[3] + 2 * pad_w, stride_w) + 1   // W
+  };
+  auto i = tvm::te::reduce_axis(tvm::Range{0, I->shape[1]}, "i");
+  auto kh = tvm::te::reduce_axis(tvm::Range{0, W->shape[2]}, "kh");
+  auto kw = tvm::te::reduce_axis(tvm::Range{0, W->shape[3]}, "kw");
+  auto T =
+      (pad_h == 0 && pad_w == 0) ? I : pad(I, {tvm::PrimExpr(0), tvm::PrimExpr(0), pad_h, pad_w});
+  auto l = [&](tvm::tir::Var b, tvm::tir::Var o, tvm::tir::Var h, tvm::tir::Var w) {
+    return tvm::sum(T(b, i, stride_h * h + kh, stride_w * w + kw) * W(o, i, kh, kw), {i, kh, kw});
+  };
+  return tvm::te::compute(output_shape, l, name, tag);
+}
+
+/*!
+ * \brief Creates an operation for 2-D convolution layer with an HWCN-layout
+ *
+ * \param I The 4-D input tensor
+ * \param W The 4-D weight tensor
+ * \param pad_h A static constant padding amount applied to the height of the
+ * image, before and after (symmetric padding)
+ * \param pad_w A static constant padding amount applied to the width of the
+ * image, before and after (symmetric padding)
+ * \param stride_h A static constant striding amount applied to the height of
+ * the image, before and after (symmetric padding)
+ * \param stride_w A static constant strindingamount applied to the width of
+ * the image, before and after (symmetric padding)
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the 2-D convolution operation
+ * (HWCN layout)
+ */
+inline tvm::te::Tensor conv2d_hwcn(const tvm::te::Tensor& I, const tvm::te::Tensor& W,
+                                   int pad_h = 0, int pad_w = 0, int stride_h = 1, int stride_w = 1,
+                                   std::string name = "T_conv2d_hwcn",
+                                   std::string tag = kConv2dHWCN) {
+  ICHECK_EQ(4, I->shape.size());
+  ICHECK_EQ(4, W->shape.size());
+  auto pH = I->shape[2];
+  auto pW = I->shape[3];
+  tvm::Array<tvm::PrimExpr> output_shape{
+      indexdiv(I->shape[2] - W->shape[2] + 2 * pad_h, stride_h) + 1,  // H
+      indexdiv(I->shape[3] - W->shape[3] + 2 * pad_w, stride_w) + 1,  // W
+      I->shape[2],                                                    // B
+      W->shape[3]                                                     // O
+  };
+  auto i = tvm::te::reduce_axis(tvm::Range{0, I->shape[3]}, "i");
+  auto kh = tvm::te::reduce_axis(tvm::Range{0, W->shape[0]}, "kh");
+  auto kw = tvm::te::reduce_axis(tvm::Range{0, W->shape[1]}, "kw");
+  auto T = (pad_h == 0 && pad_w == 0) ? I : pad(I, {pad_h, pad_w});
+  auto l = [&](tvm::tir::Var b, tvm::tir::Var o, tvm::tir::Var h, tvm::tir::Var w) {
+    return tvm::sum(T(stride_h * h + kh, stride_w * w + kw, i, b) * W(kh, kw, i, o), {i, kh, kw});
+  };
+  return tvm::te::compute(output_shape, l, name, tag);
+}
+
+/*!
+ * \brief Creates an operation that performs a 2-D depthwise convolution with
+ * an NCHW-layout
+ *
+ * \param I The 4-D input tensor
+ * \param W The 4-D weight tensor
+ * \param pad_h A static constant padding amount applied to the height of the
+ * image, before and after (symmetric padding)
+ * \param pad_w A static constant padding amount applied to the width of the
+ * image, before and after (symmetric padding)
+ * \param stride_h A static constant striding amount applied to the height of
+ * the image, before and after (symmetric padding)
+ * \param stride_w A static constant strindingamount applied to the width of
+ * the image, before and after (symmetric padding)
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the 2-D depthwise convolution operation
+ * (NCHW layout)
+ */
+inline tvm::te::Tensor depthwise_conv2d_nchw(const tvm::te::Tensor& I, const tvm::te::Tensor& W,
+                                             int pad_h = 0, int pad_w = 0, int stride_h = 1,
+                                             int stride_w = 1,
+                                             std::string name = "T_depthwise_conv2d_nchw",
+                                             std::string tag = kDepthwiseConv2dNCHW) {
+  ICHECK_EQ(4, I->shape.size());
+  ICHECK_EQ(4, W->shape.size());
+  auto pH = I->shape[2];
+  auto pW = I->shape[3];
+  auto pCM = W->shape[1];  // channel_multiplier
+  tvm::Array<tvm::PrimExpr> output_shape{
+      I->shape[0],                                                    // B
+      W->shape[1],                                                    // O
+      indexdiv(I->shape[2] - W->shape[2] + 2 * pad_h, stride_h) + 1,  // H
+      indexdiv(I->shape[3] - W->shape[3] + 2 * pad_w, stride_w) + 1   // W
+  };
+  auto i = tvm::te::reduce_axis(tvm::Range{0, I->shape[1]}, "i");
+  auto kh = tvm::te::reduce_axis(tvm::Range{0, W->shape[2]}, "kh");
+  auto kw = tvm::te::reduce_axis(tvm::Range{0, W->shape[3]}, "kw");
+  auto T =
+      (pad_h == 0 && pad_w == 0) ? I : pad(I, {tvm::PrimExpr(0), tvm::PrimExpr(0), pad_h, pad_w});
+  auto l = [&](tvm::tir::Var b, tvm::tir::Var o, tvm::tir::Var h, tvm::tir::Var w) {
+    return tvm::sum(T(b, indexdiv(i, pCM), stride_h * h + kh, stride_w * w + kw) *
+                        W(indexdiv(i, pCM), indexmod(o, pCM), kh, kw),
+                    {i, kh, kw});
+  };
+  return tvm::te::compute(output_shape, l, name, tag);
+}
+
+inline tvm::te::Tensor depthwise_conv2d_nhwc(const tvm::te::Tensor& I, const tvm::te::Tensor& W,
+                                             int pad_h = 0, int pad_w = 0, int stride_h = 1,
+                                             int stride_w = 1,
+                                             std::string name = "T_depthwise_conv2d_nhwc",
+                                             std::string tag = kDepthwiseConv2dNHWC) {
+  ICHECK_EQ(4, I->shape.size());
+  ICHECK_EQ(4, W->shape.size());
+  auto pH = I->shape[1];
+  auto pW = I->shape[2];
+  auto pCM = W->shape[1];  // channel_multiplier
+  tvm::Array<tvm::PrimExpr> output_shape{
+      I->shape[0],                                                    // B
+      indexdiv(I->shape[1] - W->shape[1] + 2 * pad_h, stride_h) + 1,  // H
+      indexdiv(I->shape[2] - W->shape[2] + 2 * pad_w, stride_w) + 1,  // W
+      W->shape[3],                                                    // O
+  };
+  auto i = tvm::te::reduce_axis(tvm::Range{0, I->shape[3]}, "i");
+  auto kh = tvm::te::reduce_axis(tvm::Range{0, W->shape[0]}, "kh");
+  auto kw = tvm::te::reduce_axis(tvm::Range{0, W->shape[1]}, "kw");
+  auto T =
+      (pad_h == 0 && pad_w == 0) ? I : pad(I, {tvm::PrimExpr(0), pad_h, pad_w, tvm::PrimExpr(0)});
+  auto l = [&](tvm::tir::Var b, tvm::tir::Var h, tvm::tir::Var w, tvm::tir::Var o) {
+    return tvm::sum(T(b, stride_h * h + kh, stride_w * w + kw, indexdiv(i, pCM)) *
+                        W(kh, kw, indexdiv(i, pCM), indexmod(o, pCM)),
+                    {kh, kw, i});
+  };
+  return tvm::te::compute(output_shape, l, name, tag);
+}
+
+/*!
+ * \brief Creates an operation that performs a 2-D group convolution with
+ * an NGCHW-layout
+ *
+ * \param I The 5-D input tensor
+ * \param W The 5-D weight tensor
+ * \param pad_h A static constant padding amount applied to the height of the
+ * image, before and after (symmetric padding)
+ * \param pad_w A static constant padding amount applied to the width of the
+ * image, before and after (symmetric padding)
+ * \param stride_h A static constant striding amount applied to the height of
+ * the image, before and after (symmetric padding)
+ * \param stride_w A static constant strindingamount applied to the width of
+ * the image, before and after (symmetric padding)
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the 2-D groupconvolution operation
+ * (NCHW layout)
+ */
+inline tvm::te::Tensor group_conv2d_ngchw(const tvm::te::Tensor& I, const tvm::te::Tensor& W,
+                                          int pad_h = 0, int pad_w = 0, int stride_h = 1,
+                                          int stride_w = 1,
+                                          std::string name = "T_group_conv2d_ngchw",
+                                          std::string tag = kGroupConv2d) {
+  ICHECK_EQ(5, I->shape.size());
+  ICHECK_EQ(5, W->shape.size());
+  auto pH = I->shape[2];
+  auto pW = I->shape[3];
+  tvm::Array<tvm::PrimExpr> output_shape{
+      I->shape[0],                                                    // B
+      I->shape[1],                                                    // G
+      W->shape[2],                                                    // O
+      indexdiv(I->shape[3] - W->shape[3] + 2 * pad_h, stride_h) + 1,  // H
+      indexdiv(I->shape[4] - W->shape[4] + 2 * pad_w, stride_w) + 1   // W
+  };
+  auto i = tvm::te::reduce_axis(tvm::Range{0, I->shape[2]}, "i");
+  auto kh = tvm::te::reduce_axis(tvm::Range{0, W->shape[3]}, "kh");
+  auto kw = tvm::te::reduce_axis(tvm::Range{0, W->shape[4]}, "kw");
+
+  auto T = (pad_h == 0 && pad_w == 0)
+               ? I
+               : pad(I, {tvm::PrimExpr(0), tvm::PrimExpr(0), tvm::PrimExpr(0), pad_h, pad_w});
+  auto l = [&](tvm::Array<tvm::tir::Var> args) {
+    tvm::tir::Var b = args[0];
+    tvm::tir::Var g = args[1];
+    tvm::tir::Var o = args[2];
+    tvm::tir::Var h = args[3];
+    tvm::tir::Var w = args[4];
+    return tvm::sum(I(b, g, i, stride_h * h + kh, stride_w * w + kw) * W(g, i, o, kh, kw),
+                    {i, kh, kw});
+  };
+  return tvm::te::compute(output_shape, l, name, tag);
+}
+
+/*!
+ * \brief Divide spatial dimensions of the input into a grid of blocks.
+ *
+ * \param data The input tensor.
+ * \param block_shape The size of the spatial block.
+ * \param pad_before The zero-padding size before each spatial dimension.
+ * \param pad_after The zero-padding size after each spatial dimension.
+ * \param pad_value The value used for padding.
+ * \param name The name of the operation.
+ * \param tag The tag to mark the operation.
+ *
+ * \return A Tensor whose op member is the space_to_batch_nd operation
+ */
+inline tvm::te::Tensor space_to_batch_nd(const tvm::te::Tensor& data,
+                                         const tvm::Array<Integer>& block_shape,
+                                         const tvm::Array<tvm::PrimExpr>& pad_before,
+                                         const tvm::Array<tvm::PrimExpr>& pad_after,
+                                         PrimExpr pad_value = PrimExpr(),
+                                         std::string name = "space_to_batch_nd",
+                                         std::string tag = kInjective) {
+  tvm::te::Tensor padded_t;
+  CHECK_EQ(pad_before.size(), pad_after.size());
+  CHECK_EQ(block_shape.size(), pad_before.size())
+      << "Paddings must be provided for each spatial dimension";
+  tvm::Array<tvm::PrimExpr> pad_before_int32;
+  tvm::Array<tvm::PrimExpr> pad_after_int32;
+
+  // pad size for batch dimension is 0
+  pad_before_int32.push_back(tvm::cast(tvm::DataType::Int(32), 0));
+  pad_after_int32.push_back(tvm::cast(tvm::DataType::Int(32), 0));
+  // insert pad sizes given for spatial dimensions
+  for (const auto& ele : pad_before) {
+    pad_before_int32.push_back(tvm::cast(tvm::DataType::Int(32), ele));
+  }
+  for (const auto& ele : pad_after) {
+    pad_after_int32.push_back(tvm::cast(tvm::DataType::Int(32), ele));
+  }
+
+  // pad the input with paddings provided
+  if (!pad_value.defined()) {
+    pad_value = tvm::tir::make_const(data->dtype, 0);
+  }
+  padded_t = pad(data, pad_before_int32, pad_after_int32, pad_value);
+
+  auto input_shape = data->shape;
+  auto padded_shape = padded_t->shape;
+
+  // infer shapes
+  tvm::Array<PrimExpr> r_shape;
+  tvm::Array<Integer> axis;
+  tvm::Array<PrimExpr> o_shape;
+
+  size_t num_block_dims = block_shape.size();
+  int batch = static_cast<int>(GetConstInt(input_shape[0]));
+  tvm::PrimExpr block_shape_prod(1);
+  r_shape.push_back(batch);
+
+  for (size_t i = 1; i <= num_block_dims; i++) {
+    int padded_input = static_cast<int>(GetConstInt(padded_shape[i]));
+    int block_size = static_cast<int>(GetConstInt(block_shape[i - 1]));
+    CHECK_EQ((padded_input % block_size), 0)
+        << "(" << i
+        << ")th "
+           "Input dimension after padding ("
+        << padded_input << ")"
+        << " must be divisible by its block size (" << block_size << ")";
+
+    r_shape.push_back(div(padded_shape[i], block_shape[i - 1]));
+    r_shape.push_back(block_shape[i - 1]);
+    block_shape_prod *= block_shape[i - 1];
+    axis.push_back(Integer(r_shape.size() - 1));  // index of block_shape[i - 1]
+  }
+
+  size_t n = axis.size();
+  axis.push_back(0);  // batch is at index 0
+  // index of (padded_shape[i] / block_shape[i - 1]) in r_shape
+  for (size_t i = 0; i < n; i++) {
+    axis.push_back(static_cast<int>(GetConstInt(axis[i] - 1)));
+  }
+  o_shape.push_back(tvm::PrimExpr(batch) * block_shape_prod);
+  for (size_t i = 1; i <= num_block_dims; i++) {
+    o_shape.push_back(div(padded_shape[i], block_shape[i - 1]));
+  }
+  // append remaining shape
+  for (size_t i = num_block_dims + 1; i < input_shape.size(); i++) {
+    r_shape.push_back(input_shape[i]);
+    axis.push_back(Integer(r_shape.size() - 1));  // index of remaining shape in r_shape
+    o_shape.push_back(input_shape[i]);
+  }
+
+  tvm::te::Tensor output = reshape(padded_t, r_shape);
+  output = transpose(output, axis);
+  output = reshape(output, o_shape);
+
+  return output;
+}
+
+/*!
+ * \brief Reshape the batch dimension into spatial dimensions.
+ *
+ * \param data The input tensor.
+ * \param block_shape The size of the spatial block.
+ * \param crop_begin_list The begin crop size for each spatial dimension.
+ * \param crop_end_list The end crop size for each spatial dimension.
+ * \param name The name of the operation.
+ * \param tag The tag to mark the operation.
+ *
+ * \return A Tensor whose op member is the batch_to_space_nd operation
+ */
+inline tvm::te::Tensor batch_to_space_nd(const tvm::te::Tensor& data,
+                                         const tvm::Array<Integer>& block_shape,
+                                         const tvm::Array<tvm::PrimExpr>& crop_begin_list,
+                                         const tvm::Array<tvm::PrimExpr>& crop_end_list,
+                                         std::string name = "batch_to_space_nd",
+                                         std::string tag = kInjective) {
+  // Construct shapes for reshape and transpose operation
+  Array<PrimExpr> in_shape = data->shape;
+  Array<PrimExpr> r_shape;
+  Array<Integer> axis;
+  size_t num_block_dims = block_shape.size();
+  size_t num_input_dims = in_shape.size();
+  tvm::PrimExpr block_shape_prod(1);
+  int batch = static_cast<int>(GetConstInt(in_shape[0]));
+
+  for (size_t i = 0; i < num_block_dims; i++) {
+    r_shape.push_back(block_shape[i]);
+    block_shape_prod *= block_shape[i];
+  }
+  axis.push_back(Integer(r_shape.size()));  // axis of (batch / block_shape_prod)
+  r_shape.push_back(batch / block_shape_prod);
+
+  for (size_t i = 1; i < num_input_dims; i++) {
+    axis.push_back(Integer(r_shape.size()));  // axis of in_shape[i]
+    if (axis.size() < (num_block_dims + num_input_dims)) {
+      axis.push_back(Integer(r_shape.size() - (num_block_dims + 1)));  // axis of block_shape[i]
+    }
+    r_shape.push_back(in_shape[i]);
+  }
+
+  Array<PrimExpr> r_p_shape;
+  r_p_shape.push_back(batch / block_shape_prod);
+  for (size_t i = 1; i <= num_block_dims; i++) {
+    r_p_shape.push_back(in_shape[i] * block_shape[i - 1]);
+  }
+  for (size_t i = num_block_dims + 1; i < num_input_dims; i++) {
+    r_p_shape.push_back(in_shape[i]);
+  }
+
+  tvm::te::Tensor out;
+  out = reshape(data, r_shape);
+  out = transpose(out, axis);
+  out = reshape(out, r_p_shape);
+
+  // Crop the start and end of dimensions of out
+  Array<Integer> begin_idx, end_idx, strides;
+  for (size_t i = 0; i < r_p_shape.size(); ++i) {
+    strides.push_back(Integer(1));
+    if (i > 0 && i <= num_block_dims) {
+      // prepare begin and end index for spatial dimensions
+      int begin_i = static_cast<int>(GetConstInt(crop_begin_list[i - 1]));
+      int end_i = static_cast<int>(GetConstInt(crop_end_list[i - 1]));
+      int out_i = static_cast<int>(GetConstInt(r_p_shape[i]));
+      CHECK_GT(out_i, (begin_i + end_i))
+          << "Incorrect crop sizes for (" << i << ")th dim, can not crop more than"
+          << " output size" << out_i << " vs " << (begin_i + end_i);
+      begin_idx.push_back(begin_i);
+      end_idx.push_back(out_i - end_i);
+    } else {
+      // ignore the batch and remaining dimension
+      begin_idx.push_back(Integer(0));
+      end_idx.push_back(static_cast<int>(GetConstInt(r_p_shape[i])));
+    }
+  }
+
+  out = strided_slice(out, begin_idx, end_idx, strides);
+  return out;
+}
+
+/*!
+ * \brief Negative log likelihood loss.
+ *
+ * \param predictions The prediction tensor.
+ * \param targets The target tensor.
+ * \param weights A manual rescaling weight given to each class.
+ * \param reduction The reduction method to apply to the output.
+ * \param ignore_index The target value to ignore.
+ * \param name The name of the operation.
+ * \param tag The tag to mark the operation.
+ *
+ * \return The negative log likelihood loss of the predictions and targets.
+ */
+inline Tensor nll_loss(const Tensor& predictions, const Tensor& targets, const Tensor& weights,
+                       std::string reduction = "mean", int ignore_index = -100,
+                       const std::string name = "nll_loss", const std::string tag = kBroadcast) {
+  auto T = tvm::te::compute(
+      targets->shape,
+      [&](const tvm::Array<tvm::tir::Var>& target_indices) {
+        auto c = targets(target_indices);
+        tvm::Array<tvm::PrimExpr> pred_indices;
+        pred_indices.push_back(target_indices[0]);  // batch index
+        pred_indices.push_back(c);                  // class index
+        for (size_t i = 1; i < target_indices.size(); i++) {
+          pred_indices.push_back(target_indices[i]);  // indices for multidimensional loss
+        }
+        return tvm::tir::Select(c != ignore_index, -predictions(pred_indices) * weights(c),
+                                tvm::tir::make_const(predictions->dtype, 0));
+      },
+      name, tag);
+  if (reduction == "mean") {
+    auto W = tvm::te::compute(
+        targets->shape,
+        [&](const tvm::Array<tvm::tir::Var>& target_indices) {
+          auto c = targets(target_indices);
+          return tvm::tir::Select(c != ignore_index, weights(c),
+                                  tvm::tir::make_const(predictions->dtype, 0));
+        },
+        name, tag);
+    return topi::divide(topi::sum(T, {}), topi::sum(W, {}));
+  } else if (reduction == "sum") {
+    return topi::sum(T, {});
+  } else {  // reduction == "none"
+    return T;
+  }
+}
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_NN_H_
diff --git a/darknet_drp_ros/include/tvm/topi/nn/bias_add.h b/darknet_drp_ros/include/tvm/topi/nn/bias_add.h
new file mode 100644
index 0000000..03c026c
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/nn/bias_add.h
@@ -0,0 +1,58 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \brief bias_add op constructions
+ * \file nn/bias_add.h
+ */
+#ifndef TVM_TOPI_NN_BIAS_ADD_H_
+#define TVM_TOPI_NN_BIAS_ADD_H_
+
+#include <tvm/te/operation.h>
+#include <tvm/topi/broadcast.h>
+#include <tvm/topi/tags.h>
+#include <tvm/topi/transform.h>
+
+#include <string>
+
+namespace tvm {
+namespace topi {
+namespace nn {
+
+/*!
+ * \brief Creates an operation that calculates data + bias
+ *
+ * \param data Tensor with shape [batch, in_dim]
+ * \param bias Tensor with shape [batch].
+ * \param axis The axis to add the bias to.
+ * \return Tensor with shape [batch, in_dim]
+ */
+inline tvm::te::Tensor bias_add(const tvm::te::Tensor& data, const tvm::te::Tensor& bias,
+                                int axis) {
+  int data_ndim = data->shape.size();
+  if (axis < 0) {
+    axis += data_ndim;
+  }
+  int num_newaxis = data_ndim - axis - 1;
+  return add(data, (num_newaxis ? expand_dims(bias, 1, num_newaxis) : bias));
+}
+}  // namespace nn
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_NN_BIAS_ADD_H_
diff --git a/darknet_drp_ros/include/tvm/topi/nn/bnn.h b/darknet_drp_ros/include/tvm/topi/nn/bnn.h
new file mode 100644
index 0000000..815b8a2
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/nn/bnn.h
@@ -0,0 +1,125 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \brief Binary op constructions
+ * \file nn/bnn.h
+ */
+#ifndef TVM_TOPI_NN_BNN_H_
+#define TVM_TOPI_NN_BNN_H_
+
+#include <tvm/arith/analyzer.h>
+#include <tvm/te/operation.h>
+#include <tvm/topi/detail/constant_utils.h>
+#include <tvm/topi/tags.h>
+
+#include <string>
+
+namespace tvm {
+namespace topi {
+namespace nn {
+
+using namespace tvm::te;
+
+/*!
+ * \brief Binarization and bit-packing along a certain axis.
+ *
+ * \param data N-D tensor, can be any layout
+ * \param axis The axis along which to do binarization and bit-packing. This axis
+ * must have a size equal to an integer multiple of 32.
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return Output tensor with dtype uint32
+ */
+inline tvm::te::Tensor binarize_pack(const tvm::te::Tensor& data, int axis,
+                                     std::string name = "PackedInput",
+                                     std::string tag = "binarize_pack") {
+  auto ishape = data->shape;
+  ICHECK_EQ(GetConstInt(ishape[axis]) % 32, 0)
+      << "binarize_pack: axis size must be a multiple of 32";
+
+  arith::Analyzer analyzer;
+  auto n = ishape.size();
+  Array<PrimExpr> oshape;
+  for (size_t i = 0; i < n; ++i) {
+    oshape.push_back(i == static_cast<size_t>(axis) ? analyzer.Simplify(indexdiv(ishape[i], 32))
+                                                    : ishape[i]);
+  }
+
+  return tvm::te::compute(
+      oshape,
+      [&](const Array<Var>& indices) {
+        Array<PrimExpr> start_idx;
+        for (size_t i = 0; i < n; ++i) {
+          start_idx.push_back(i == static_cast<size_t>(axis) ? indices[i] * 32
+                                                             : static_cast<PrimExpr>(indices[i]));
+        }
+        auto packed = make_const(DataType::UInt(32), 0);
+        for (size_t j = 0; j < 32; ++j) {
+          Array<PrimExpr> idx;
+          for (size_t i = 0; i < n; ++i) {
+            idx.push_back(i == static_cast<size_t>(axis) ? start_idx[i] + static_cast<int>(j)
+                                                         : start_idx[i]);
+          }
+          auto sign = tvm::cast(DataType::UInt(32), data(idx) >= 0);
+          packed = (packed | sign);
+          if (j == 31) {
+            return packed;
+          }
+          packed = packed << 1;
+        }
+        return packed;  // never reached, but suppress compiler warning
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Binary matrix multiplication using xor and bit-count
+ *
+ * \param data Tensor with shape [batch, in_dim], dtype is uint32
+ * \param weight Tensor with shape [out_dim, in_dim], dtype is uint32
+ *
+ * \return Tensor with shape [batch, out_dim], dtype is float32
+ */
+inline tvm::te::Tensor binary_dense(const tvm::te::Tensor& data, const tvm::te::Tensor& weight) {
+  ICHECK_EQ(data->shape.size(), 2) << "binary_dense requires 2-D data";
+  ICHECK_EQ(weight->shape.size(), 2) << "binary_dense requires 2-D weight";
+  ICHECK_EQ(data->dtype, DataType::UInt(32)) << "binary_dense requires uint32 data";
+  ICHECK_EQ(weight->dtype, DataType::UInt(32)) << "binary_dense requires uint32 weight";
+
+  auto batch = data->shape[0];
+  auto in_dim = data->shape[1];
+  auto out_dim = weight->shape[0];
+
+  auto k = tvm::te::reduce_axis(Range(0, in_dim), "k");
+  auto matmul = tvm::te::compute(
+      {batch, out_dim},
+      [&](Var i, Var j) { return tvm::sum(popcount(data(i, k) ^ weight(j, k)), {k}); }, "tensor",
+      "binary_dense");
+
+  return tvm::te::compute(
+      {batch, out_dim}, [&](Var i, Var j) { return 32 * in_dim - 2.0f * matmul(i, j); }, "tensor",
+      kElementWise);
+}
+
+}  // namespace nn
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_NN_BNN_H_
diff --git a/darknet_drp_ros/include/tvm/topi/nn/dense.h b/darknet_drp_ros/include/tvm/topi/nn/dense.h
new file mode 100644
index 0000000..113002d
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/nn/dense.h
@@ -0,0 +1,81 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \brief Dense op constructions
+ * \file nn/dense.h
+ */
+#ifndef TVM_TOPI_NN_DENSE_H_
+#define TVM_TOPI_NN_DENSE_H_
+
+#include <tvm/te/operation.h>
+#include <tvm/topi/tags.h>
+
+#include <string>
+
+namespace tvm {
+namespace topi {
+namespace nn {
+
+using namespace tvm::te;
+
+/*!
+ * \brief Creates an operation that calculates data * weight^T + bias
+ *
+ * \param data Tensor with shape [batch, in_dim]
+ * \param weight Tensor with shape [out_dim, in_dim]
+ * \param bias Tensor with shape [out_dim]. Optional; to omit bias, pass Tensor()
+ * \param out_dtype Output data type. Used for mixed precision.
+ *
+ * \return Tensor with shape [batch, out_dim]
+ */
+inline tvm::te::Tensor dense(const tvm::te::Tensor& data, const tvm::te::Tensor& weight,
+                             const tvm::te::Tensor& bias, const DataType& out_dtype) {
+  ICHECK_EQ(data->shape.size(), 2) << "dense requires 2-D data";
+  ICHECK_EQ(weight->shape.size(), 2) << "dense requires 2-D weight";
+  if (bias.defined()) {
+    ICHECK_EQ(bias->shape.size(), 1) << "dense requires 1-D bias";
+  }
+
+  auto batch = data->shape[0];
+  auto in_dim = data->shape[1];
+  auto out_dim = weight->shape[0];
+
+  auto k = tvm::te::reduce_axis(Range(0, in_dim), "k");
+  auto matmul = tvm::te::compute(
+      {batch, out_dim},
+      [&](Var i, Var j) {
+        return tvm::sum(tvm::cast(out_dtype, data(i, k)) * tvm::cast(out_dtype, weight(j, k)), {k});
+      },
+      "tensor", "dense");
+
+  if (bias.defined()) {
+    matmul = tvm::te::compute(
+        {batch, out_dim},
+        [&](Var i, Var j) { return matmul(i, j) + tvm::cast(out_dtype, bias(j)); }, "tensor",
+        kBroadcast);
+  }
+
+  return matmul;
+}
+
+}  // namespace nn
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_NN_DENSE_H_
diff --git a/darknet_drp_ros/include/tvm/topi/nn/dilate.h b/darknet_drp_ros/include/tvm/topi/nn/dilate.h
new file mode 100644
index 0000000..3369316
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/nn/dilate.h
@@ -0,0 +1,109 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \brief Dilate op constructions
+ * \file nn/dilate.h
+ */
+#ifndef TVM_TOPI_NN_DILATE_H_
+#define TVM_TOPI_NN_DILATE_H_
+
+#include <tvm/arith/analyzer.h>
+#include <tvm/te/operation.h>
+#include <tvm/topi/tags.h>
+
+#include <string>
+
+namespace tvm {
+namespace topi {
+namespace nn {
+
+using namespace tvm::te;
+
+/*!
+ * \brief Create a new expression of the logical and of all
+ * conditions in the arguments.
+ *
+ * \param args The arguments to find the logical conjunction of
+ *
+ * \return The logical conjunction expression
+ */
+PrimExpr all(Array<PrimExpr> args) {
+  ICHECK_GT(args.size(), 0) << "all requires at least one argument";
+
+  PrimExpr ret = args[0];
+  for (size_t i = 1; i < args.size(); ++i) {
+    ret = ret && args[i];
+  }
+  return ret;
+}
+
+/*!
+ * \brief Dilate data with given dilation value (0 by default).
+ *
+ * \param x The input tensor, this can have any number of
+ * dimensions and any layout.
+ * \param strides Dilation stride for each dimension. Stride 1
+ * means no dilation.
+ * \param dilation_value Value used to dilate the input.
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return The output tensor.
+ */
+inline Tensor dilate(const Tensor& x, Array<PrimExpr> strides, double dilation_value,
+                     std::string name = "tensor", std::string tag = kInjective) {
+  auto n = x->shape.size();
+  ICHECK_EQ(n, strides.size()) << "strides size (" << strides.size()
+                               << ") must match dimension of x (" << n << ")";
+
+  Array<PrimExpr> out_shape;
+  arith::Analyzer analyzer;
+  for (size_t i = 0; i < n; ++i) {
+    out_shape.push_back(
+        analyzer.Simplify((x->shape[i] - 1) * cast(DataType::Int(32), strides[i] + 1)));
+  }
+
+  return tvm::te::compute(
+      out_shape,
+      [&](const Array<Var>& indices) {
+        Array<PrimExpr> not_zero;
+        Array<PrimExpr> index_tuple;
+        for (size_t i = 0; i < n; ++i) {
+          if (IsConstInt(strides[i]) && GetConstInt(strides[i]) == 1) {
+            index_tuple.push_back(indices[i]);
+          } else {
+            index_tuple.push_back(indexdiv(indices[i], strides[i]));
+            not_zero.push_back((indexmod(indices[i], strides[i])) == 0);
+          }
+        }
+        if (not_zero.size() > 0) {
+          auto all_not_zero = all(not_zero);
+          return tvm::if_then_else(all_not_zero, x(index_tuple),
+                                   make_const(x->dtype, dilation_value));
+        }
+        return x(index_tuple);
+      },
+      name, tag);
+}
+
+}  // namespace nn
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_NN_DILATE_H_
diff --git a/darknet_drp_ros/include/tvm/topi/nn/flatten.h b/darknet_drp_ros/include/tvm/topi/nn/flatten.h
new file mode 100644
index 0000000..cd96d30
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/nn/flatten.h
@@ -0,0 +1,84 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \brief Softmax op constructions
+ * \file nn/flatten.h
+ */
+#ifndef TVM_TOPI_NN_FLATTEN_H_
+#define TVM_TOPI_NN_FLATTEN_H_
+
+#include <tvm/te/operation.h>
+#include <tvm/topi/detail/constant_utils.h>
+#include <tvm/topi/tags.h>
+
+#include <string>
+#include <vector>
+
+namespace tvm {
+namespace topi {
+namespace nn {
+
+using namespace tvm::te;
+
+/*!
+ * \brief Flattens the input tensor into a 2-D tensor by collapsing higher dimensions.
+ * This requires the input tensor to have constant sized dimensions.
+ *
+ * \param x The input tensor.
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A 2-D tensor.
+ */
+inline Tensor flatten(const Tensor& x, std::string name = "tensor", std::string tag = kInjective) {
+  auto ishape = x->shape;
+  PrimExpr dim = 1;
+  for (size_t i = 1; i < ishape.size(); ++i) {
+    dim = dim * ishape[i];
+  }
+
+  Array<PrimExpr> oshape({ishape[0], dim});
+
+  std::vector<PrimExpr> extra_shape;
+  for (size_t i = 1; i < ishape.size(); ++i) {
+    extra_shape.push_back(ishape[i]);
+  }
+  std::reverse(extra_shape.begin(), extra_shape.end());
+
+  return tvm::te::compute(
+      oshape,
+      [&](Var i, Var j) {
+        PrimExpr idx = j;
+        std::vector<PrimExpr> index;
+        for (auto s : extra_shape) {
+          index.push_back(indexmod(idx, s));
+          idx = indexdiv(idx, s);
+        }
+        index.push_back(i);
+        std::reverse(index.begin(), index.end());
+        return x(index);
+      },
+      name, tag);
+}
+
+}  // namespace nn
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_NN_FLATTEN_H_
diff --git a/darknet_drp_ros/include/tvm/topi/nn/layer_norm.h b/darknet_drp_ros/include/tvm/topi/nn/layer_norm.h
new file mode 100644
index 0000000..93e5582
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/nn/layer_norm.h
@@ -0,0 +1,117 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \brief layer normalization op constructions
+ * \file nn/layer_norm.h
+ */
+#ifndef TVM_TOPI_NN_LAYER_NORM_H_
+#define TVM_TOPI_NN_LAYER_NORM_H_
+
+#include <tvm/te/operation.h>
+#include <tvm/topi/tags.h>
+
+#include <string>
+
+namespace tvm {
+namespace topi {
+namespace nn {
+
+using namespace tvm::te;
+
+/*!
+ * \brief Layer normalization.
+ * \param data N-D tensor with shape [d_0, d_1, ..., d_{N-1}]
+ * \param gamma K-D tensor with shape [r_0, r_1, ..., r_{K-1}] where K == len(axis) and
+ *              d_{axis_k} == r_k
+ * \param beta Optional, K-D tensor with shape [r_0, r_1, ..., r_{K-1}] where
+ *             d_{axis_k} == r_k
+ * \param axis The axis to normalize over.
+ * \param epsilon The epsilon value to avoid division by zero.
+ * \param name The name of the operation.
+ * \param tag The tag to mark the operation.
+ * \return The normalized tensor, with the same shape as data.
+ */
+inline Tensor layer_norm(const Tensor& data, const Tensor& gamma, const Tensor& beta,
+                         const Array<Integer>& axis, double epsilon,
+                         std::string name = "T_layer_norm", std::string tag = kInjective) {
+  // sum x and x^2
+  auto ndim = data->shape.size();
+  ICHECK_NE(ndim, 0) << "Cannot reduce a 0 dim Tensor";
+  auto real_axis = GetRealAxis(static_cast<int>(ndim), axis);
+  auto reduce_axes = MakeReduceAxes(real_axis, data);
+  auto target_shape =
+      MakeReduceTargetShape(real_axis, data, /*keepdims=*/false, /*atleast1d=*/true);
+  auto func = MakeTupleSumReducer();
+
+  auto compute = [ndim, &real_axis, &reduce_axes, &func, &data](const Array<Var>& indices) {
+    Array<PrimExpr> eval_range;
+    int arg_counter = 0;
+    int red_counter = 0;
+
+    for (size_t i = 0; i < ndim; ++i) {
+      if (std::find(real_axis.begin(), real_axis.end(), i) != real_axis.end()) {
+        // real_axis contains i
+        eval_range.push_back(reduce_axes[red_counter]);
+        red_counter++;
+      } else {
+        eval_range.push_back(indices[arg_counter]);
+        arg_counter++;
+      }
+    }
+    auto square = [](const PrimExpr& x) { return x * x; };
+    return func({data(eval_range), square(data(eval_range))}, reduce_axes, nullptr);
+  };
+
+  auto temp_x_x2 =
+      tvm::te::compute(target_shape, compute, data->op->name + "_red_temp", kCommReduce);
+
+  auto temp_x = temp_x_x2[0];
+  auto temp_x2 = temp_x_x2[1];
+
+  auto reduce_extent = make_const(data->dtype, 1);
+  for (int i : real_axis) {
+    reduce_extent *= data->shape[i];
+  }
+  auto layer_norm_func = [&](const Array<Var>& indices) {
+    Array<Var> reduce_indices, non_reduce_indices;
+    for (int i = 0, n = static_cast<int>(indices.size()); i < n; ++i) {
+      if (std::find(real_axis.begin(), real_axis.end(), i) != real_axis.end()) {
+        reduce_indices.push_back(indices[i]);
+      } else {
+        non_reduce_indices.push_back(indices[i]);
+      }
+    }
+    auto mean = temp_x(non_reduce_indices) / reduce_extent;
+    auto var = temp_x2(non_reduce_indices) / reduce_extent - mean * mean;
+    auto layer_norm = (data(indices) - mean) * tvm::rsqrt(var + make_const(var->dtype, epsilon));
+    layer_norm = topi::multiply(layer_norm, gamma(reduce_indices));
+    if (beta.defined()) {
+      layer_norm = topi::add(layer_norm, beta(reduce_indices));
+    }
+    return layer_norm;
+  };
+  return tvm::te::compute(data->shape, layer_norm_func, name, tag);
+}
+
+}  // namespace nn
+}  // namespace topi
+}  // namespace tvm
+
+#endif  // TVM_TOPI_NN_LAYER_NORM_H_
diff --git a/darknet_drp_ros/include/tvm/topi/nn/local_response_norm.h b/darknet_drp_ros/include/tvm/topi/nn/local_response_norm.h
new file mode 100644
index 0000000..a9d7225
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/nn/local_response_norm.h
@@ -0,0 +1,96 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \brief local response normalization op constructions
+ * \file nn/local_response_norm.h
+ */
+#ifndef TVM_TOPI_NN_LOCAL_RESPONSE_NORM_H_
+#define TVM_TOPI_NN_LOCAL_RESPONSE_NORM_H_
+
+#include <tvm/te/operation.h>
+#include <tvm/topi/tags.h>
+
+#include <string>
+
+namespace tvm {
+namespace topi {
+namespace nn {
+
+using namespace tvm::te;
+
+/*!
+ * \brief Local response normalization inference operator
+ *
+ * \param data The input tensor. 4-D shape NCHW or NHWC
+ * \param size Integer to define normalisation window size
+ * \param axis Input data layout channel axis
+ * \param alpha Float scaling factor
+ * \param beta Exponent value
+ * \param bias Offset to avoid dividing by zero
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the Local response normalization operation
+ */
+inline Tensor lrn(const Tensor& data, int size, int axis = 1, float alpha = 0.0001,
+                  float beta = 0.75, float bias = 2, std::string name = "tensor",
+                  std::string tag = kBroadcast) {
+  ICHECK_EQ(data->shape.size(), 4) << "LRN requires 4-D input";
+  ICHECK_EQ(size % 2, 1) << "size should be odd number";
+  ICHECK(axis == 1 || axis == 3) << "axis should be 1 or 3 for NCHW and NHWC";
+  ICHECK(data->dtype.is_float()) << "datatype should be float";
+  auto input_shape = data->shape;
+  Array<PrimExpr> pad_before{0, 0, 0, 0};
+  Array<PrimExpr> pad_after{0, 0, 0, 0};
+  pad_before.Set(axis, static_cast<PrimExpr>(size / 2));
+  pad_after.Set(axis, static_cast<PrimExpr>(size / 2));
+  auto pad_data = pad(data, pad_before, pad_after, 0, "pad_data");
+  auto rxs = tvm::te::reduce_axis(Range(0, size), "rxs");
+  Tensor sqr_sum;
+  if (axis == 1) {
+    sqr_sum = tvm::te::compute(
+        input_shape,
+        [&](Var i, Var l, Var j, Var k) {
+          return tvm::sum(pad_data(i, l + rxs, j, k) * pad_data(i, l + rxs, j, k), {rxs});
+        },
+        "tensor", "sqr_sum");
+  } else if (axis == 3) {
+    sqr_sum = tvm::te::compute(
+        input_shape,
+        [&](Var i, Var l, Var j, Var k) {
+          return tvm::sum(pad_data(i, l, j, k + rxs) * pad_data(i, l, j, k + rxs), {rxs});
+        },
+        "tensor", "sqr_sum");
+  }
+  PrimExpr alpha_imm = tvm::te::make_const(data->dtype, alpha);
+  PrimExpr beta_imm = tvm::te::make_const(data->dtype, beta);
+  PrimExpr bias_imm = tvm::te::make_const(data->dtype, bias);
+  auto sqrt_sum_up = tvm::te::compute(
+      input_shape,
+      [&](Var i, Var j, Var k, Var l) {
+        return tvm::pow(bias_imm + (div(alpha_imm * sqr_sum(i, j, k, l), size)), beta_imm);
+      },
+      "tensor", kElementWise);
+  return topi::divide(data, sqrt_sum_up);
+}
+}  // namespace nn
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_NN_LOCAL_RESPONSE_NORM_H_
diff --git a/darknet_drp_ros/include/tvm/topi/nn/mapping.h b/darknet_drp_ros/include/tvm/topi/nn/mapping.h
new file mode 100644
index 0000000..d6a8716
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/nn/mapping.h
@@ -0,0 +1,77 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \brief Mapping op constructions
+ * \file nn/mapping.h
+ */
+#ifndef TVM_TOPI_NN_MAPPING_H_
+#define TVM_TOPI_NN_MAPPING_H_
+
+#include <tvm/te/operation.h>
+#include <tvm/topi/tags.h>
+
+#include <string>
+
+namespace tvm {
+namespace topi {
+namespace nn {
+
+using namespace tvm::te;
+
+/*!
+ * \brief Scale and shift with NCHW order
+ *
+ * \param x The input tensor.
+ * \param scale Scale tensor, 1-D of size channel
+ * \param shift Shift tensor, 1-D of size channel
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the scale shift operation
+ */
+inline Tensor scale_shift_nchw(const Tensor& x, const Tensor& scale, const Tensor& shift,
+                               std::string name = "ScaleShift", std::string tag = kBroadcast) {
+  return tvm::te::compute(
+      x->shape, [&](Var b, Var c, Var h, Var w) { return x(b, c, h, w) * scale(c) + shift(c); },
+      name, tag);
+}
+
+/*!
+ * \brief Scale and shift with NHWC order
+ *
+ * \param x The input tensor.
+ * \param scale Scale tensor, 1-D of size channel
+ * \param shift Shift tensor, 1-D of size channel
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the scale shift operation
+ */
+inline Tensor scale_shift_nhwc(const Tensor& x, const Tensor& scale, const Tensor& shift,
+                               std::string name = "ScaleShift", std::string tag = kBroadcast) {
+  return tvm::te::compute(
+      x->shape, [&](Var b, Var h, Var w, Var c) { return x(b, h, w, c) * scale(c) + shift(c); },
+      name, tag);
+}
+
+}  // namespace nn
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_NN_MAPPING_H_
diff --git a/darknet_drp_ros/include/tvm/topi/nn/pooling.h b/darknet_drp_ros/include/tvm/topi/nn/pooling.h
new file mode 100644
index 0000000..3503584
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/nn/pooling.h
@@ -0,0 +1,794 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \brief Pooling op constructions
+ * \file nn/pooling.h
+ */
+#ifndef TVM_TOPI_NN_POOLING_H_
+#define TVM_TOPI_NN_POOLING_H_
+
+#include <tvm/arith/analyzer.h>
+#include <tvm/topi/detail/pad_utils.h>
+#include <tvm/topi/nn.h>
+#include <tvm/topi/reduction.h>
+#include <tvm/topi/tags.h>
+
+#include <algorithm>
+#include <string>
+#include <vector>
+
+namespace tvm {
+namespace topi {
+namespace nn {
+
+using namespace tvm::te;
+
+/*! \brief Pooling type */
+enum PoolType : int {
+  kAvgPool,
+  kMaxPool,
+};
+
+inline Tensor pool_grad_impl(const Tensor& out_grad, const Tensor& x,
+                             const Array<PrimExpr>& kernel_size, const Array<PrimExpr>& stride_size,
+                             const Array<PrimExpr>& padding_size, PoolType pool_type,
+                             bool ceil_mode, const size_t height_axis, const size_t width_axis,
+                             bool count_include_pad) {
+  ICHECK(out_grad->shape.size() >= 2) << "Pooling grad output must >= 2-D (H, W)";
+  ICHECK(x->shape.size() >= 2) << "Pooling input must >= 2-D (H, W)";
+  ICHECK_EQ(kernel_size.size(), 2) << "Pooling kernel_size must have 2 elements";
+  ICHECK_EQ(stride_size.size(), 2) << "Pooling stride_size must have 2 elements";
+  ICHECK_EQ(padding_size.size(), 4) << "Pooling padding_size must have 4 elements";
+
+  auto kernel_height = cast(DataType::DataType::Int(32), kernel_size[0]);
+  auto kernel_width = cast(DataType::DataType::Int(32), kernel_size[1]);
+  auto stride_height = cast(DataType::DataType::Int(32), stride_size[0]);
+  auto stride_width = cast(DataType::DataType::Int(32), stride_size[1]);
+
+  auto height = cast(DataType::DataType::Int(32), x->shape[height_axis]);
+  auto width = cast(DataType::DataType::Int(32), x->shape[width_axis]);
+
+  auto pad_top = cast(DataType::DataType::Int(32), padding_size[0]);
+  auto pad_left = cast(DataType::DataType::Int(32), padding_size[1]);
+  auto pad_bottom = cast(DataType::DataType::Int(32), padding_size[2]);
+  auto pad_right = cast(DataType::DataType::Int(32), padding_size[3]);
+
+  if (ceil_mode) {
+    // Additional padding to ensure we do ceil instead of floor when
+    // dividing by stride.
+    pad_bottom += stride_height - 1;
+    pad_right += stride_width - 1;
+  }
+
+  Array<PrimExpr> pad_before(std::vector<PrimExpr>(x->shape.size(), 0));
+  pad_before.Set(height_axis, pad_top);
+  pad_before.Set(width_axis, pad_left);
+
+  Array<PrimExpr> pad_after(std::vector<PrimExpr>(x->shape.size(), 0));
+  pad_after.Set(height_axis, pad_bottom);
+  pad_after.Set(width_axis, pad_right);
+  arith::Analyzer analyzer;
+  auto out_height =
+      analyzer.Simplify((height - kernel_height + pad_top + pad_bottom) / stride_height + 1);
+  auto out_width =
+      analyzer.Simplify((width - kernel_width + pad_left + pad_right) / stride_width + 1);
+
+  auto dheight = tvm::te::reduce_axis(Range(0, kernel_height), "dh");
+  auto dwidth = tvm::te::reduce_axis(Range(0, kernel_width), "dw");
+
+  Array<PrimExpr> data_shape = x->shape;
+  for (size_t i = 0; i < data_shape.size(); ++i) {
+    data_shape.Set(i, cast(DataType::DataType::Int(32), data_shape[i]));
+  }
+
+  Array<PrimExpr> out_shape = data_shape;
+  out_shape.Set(height_axis, out_height);
+  out_shape.Set(width_axis, out_width);
+
+  const int64_t* padding_h0 = as_const_int(pad_top);
+  const int64_t* padding_w0 = as_const_int(pad_left);
+  const int64_t* padding_h1 = as_const_int(pad_bottom);
+  const int64_t* padding_w1 = as_const_int(pad_right);
+  const bool do_pad = ((padding_h0 && *padding_h0) || (padding_w0 && *padding_w0)) ||
+                      ((padding_h1 && *padding_h1) || (padding_w1 && *padding_w1));
+
+  if (pool_type == kMaxPool) {
+    Array<PrimExpr> ravel_shape{data_shape.begin(), data_shape.end()};
+    ravel_shape.Set(height_axis, ravel_shape[height_axis] + pad_top + pad_bottom);
+    ravel_shape.Set(width_axis, ravel_shape[width_axis] + pad_left + pad_right);
+
+    auto windowh =
+        tvm::te::reduce_axis(Range(0, (kernel_height + stride_height - 1) / stride_height), "wh");
+    auto windoww =
+        tvm::te::reduce_axis(Range(0, (kernel_width + stride_width - 1) / stride_width), "ww");
+
+    auto argmax = MakeArgmaxReducer();
+    auto pad_x = do_pad ? pad(x, pad_before, pad_after, tvm::min_value(x->dtype), "pad_temp") : x;
+
+    auto mp_argmax = tvm::te::compute(
+        out_shape,
+        [&](const Array<Var>& inds) {
+          Array<PrimExpr> window_inds{inds.begin(), inds.end()};
+          window_inds.Set(height_axis, inds[height_axis] * stride_height + dheight);
+          window_inds.Set(width_axis, inds[width_axis] * stride_width + dwidth);
+          auto idx = detail::RavelIndex(window_inds, ravel_shape);
+          return argmax({idx, pad_x(window_inds)}, {dheight, dwidth}, nullptr);
+        },
+        "maxpool_grad_argmax", kCommReduceIdx);
+
+    auto mp_inds = mp_argmax[0];
+
+    return tvm::te::compute(
+        data_shape,
+        [&](const Array<Var>& inds) {
+          Array<PrimExpr> pad_inds{inds.begin(), inds.end()};
+          pad_inds.Set(height_axis, pad_inds[height_axis] + pad_top);
+          pad_inds.Set(width_axis, pad_inds[width_axis] + pad_left);
+          auto idx = detail::RavelIndex(pad_inds, ravel_shape);
+
+          Array<PrimExpr> out_idx{inds.begin(), inds.end()};
+          out_idx.Set(height_axis, (inds[height_axis] + pad_top) / stride_height - windowh);
+          out_idx.Set(width_axis, (inds[width_axis] + pad_left) / stride_width - windoww);
+
+          PrimExpr out_idx_lower_h = tir::Select(
+              pad_inds[height_axis] < kernel_height, make_const(DataType::DataType::Int(32), 0),
+              (pad_inds[height_axis] - kernel_height) / stride_height + 1);
+          PrimExpr out_idx_lower_w = tir::Select(
+              pad_inds[width_axis] < kernel_width, make_const(DataType::DataType::Int(32), 0),
+              (pad_inds[width_axis] - kernel_width) / stride_width + 1);
+
+          return tvm::sum(
+              tvm::if_then_else(tir::And(tir::And(out_idx[height_axis] >= out_idx_lower_h,
+                                                  out_idx[width_axis] >= out_idx_lower_w),
+                                         mp_inds(out_idx) == idx),
+                                out_grad(out_idx), make_const(x->dtype, 0)),
+              {windowh, windoww});
+        },
+        "T_pool_grad", "pool_grad_max");
+  } else if (pool_type == kAvgPool) {
+    auto windowh =
+        tvm::te::reduce_axis(Range(0, (kernel_height + stride_height - 1) / stride_height), "wh");
+    auto windoww =
+        tvm::te::reduce_axis(Range(0, (kernel_width + stride_width - 1) / stride_width), "ww");
+    return tvm::te::compute(
+        data_shape,
+        [&](const Array<Var>& inds) {
+          PrimExpr pad_h_idx = inds[height_axis] + pad_top;
+          PrimExpr pad_w_idx = inds[width_axis] + pad_left;
+
+          // output indices whose pooling windows cover current input element (can be out-of-bound)
+          Array<PrimExpr> out_idx{inds.begin(), inds.end()};
+          out_idx.Set(height_axis, (pad_h_idx / stride_height - windowh));
+          out_idx.Set(width_axis, (pad_w_idx / stride_width - windoww));
+
+          PrimExpr out_idx_lower_h =
+              tir::Select(pad_h_idx < kernel_height, make_const(DataType::Int(32), 0),
+                          (pad_h_idx - kernel_height) / stride_height + 1);
+          PrimExpr out_idx_lower_w =
+              tir::Select(pad_w_idx < kernel_width, make_const(DataType::Int(32), 0),
+                          (pad_w_idx - kernel_width) / stride_width + 1);
+
+          PrimExpr divide_factor;  // number of pooled elements
+          if (count_include_pad) {
+            divide_factor = kernel_height * kernel_width;
+          } else {
+            PrimExpr h_start = out_idx[height_axis] * stride_height - pad_top;
+            PrimExpr w_start = out_idx[width_axis] * stride_width - pad_left;
+
+            PrimExpr h_end = min(h_start + kernel_height, height);
+            PrimExpr w_end = min(w_start + kernel_width, width);
+            h_start = max(h_start, make_const(DataType::Int(32), 0));
+            w_start = max(w_start, make_const(DataType::Int(32), 0));
+            divide_factor =
+                max((h_end - h_start) * (w_end - w_start), make_const(DataType::Int(32), 1));
+          }
+          return tvm::sum(
+              tvm::if_then_else(tir::And(tir::And(out_idx[height_axis] >= out_idx_lower_h,
+                                                  out_idx[height_axis] < out_height),
+                                         tir::And(out_idx[width_axis] >= out_idx_lower_w,
+                                                  out_idx[width_axis] < out_width)),
+                                out_grad(out_idx) / divide_factor, make_const(out_grad->dtype, 0)),
+              {windowh, windoww});
+        },
+        "T_pool_grad", "pool_grad_avg");
+  } else {
+    LOG(ERROR) << "Unrecognized pool_type: " << pool_type;
+    return Tensor();
+  }
+}
+
+inline bool find_depth_height_width(const std::string& layout, int* depth_axis, int* height_axis,
+                                    int* width_axis) {
+  *depth_axis = -1;
+  *height_axis = -1;
+  *width_axis = -1;
+  int curr_idx = 0;
+  for (size_t i = 0; i < layout.size(); ++i) {
+    if ((layout[i] >= 'A' && layout[i] <= 'Z') || (layout[i] >= 'a' && layout[i] <= 'z')) {
+      if (layout[i] == 'D') {
+        if (*depth_axis != -1) return false;
+        *depth_axis = curr_idx;
+      } else if (layout[i] == 'H') {
+        if (*height_axis != -1) return false;
+        *height_axis = curr_idx;
+      } else if (layout[i] == 'W') {
+        if (*width_axis != -1) return false;
+        *width_axis = curr_idx;
+      } else if (layout[i] == 'd' || layout[i] == 'h' || layout[i] == 'w') {
+        // do not support split on height or width, e.g., NCHW16w
+        return false;
+      }
+      ++curr_idx;
+    }
+  }
+  if (*depth_axis == -1 || *height_axis == -1 || *width_axis == -1) return false;
+  return true;
+}
+
+inline bool find_height_width(const std::string& layout, int* height_axis, int* width_axis) {
+  int dummy;
+  ICHECK_EQ(find_depth_height_width(layout, &dummy, height_axis, width_axis), false);
+  if (*height_axis != -1 && *width_axis != -1) {
+    return true;
+  }
+  return false;
+}
+
+inline bool find_width(const std::string& layout, int* width_axis) {
+  int dummy;
+  ICHECK_EQ(find_depth_height_width(layout, &dummy, &dummy, width_axis), false);
+  if (*width_axis != -1) {
+    return true;
+  }
+  return false;
+}
+
+/*!
+ * \brief Calculate gradient of pooling on height and width dimension of data.
+ *        It decides the height and width dimension according to the layout string,
+ *        in which 'W' and 'H' means width and height respectively.
+ *        Width and height dimension cannot be split.
+ *        For example, NCHW, NCHW16c, etc. are valid for pool,
+ *        while NCHW16w, NCHW16h are not.
+ *        See \a layout for more information of the layout string convention.
+ * \param out_grad The output gradient tensor.
+ * \param x The input tensor.
+ * \param kernel_size Vector of two ints: {kernel_height, kernel_width}
+ * \param stride_size Vector of two ints: {stride_height, stride_width}
+ * \param padding_size Vector of two ints: {padding_height, padding_width}
+ * \param pool_type The type of pooling operator
+ * \param ceil_mode Whether to use ceil when calculating the output size
+ * \param layout The input layout. Pooling supports any layout as long as 'H' and 'W' appear.
+ *        The layout is supposed to be composed of upper cases, lower cases and (optional) numbers,
+ *        where upper case indicates a dimension and
+ *        the corresponding lower case (with factor size) indicates the split dimension.
+ *        For example, NCHW16c can describe a 5-D tensor of
+ *        [batch_size, channel, height, width, channel_block].
+ *        (in which factor size `16` will not be used in pooling but for other operators,
+ *        it can be used to decide the output shape).
+ *        Since pooling does not care about the factor size of dimensions
+ *        other than `H` and `W`, one can pass `NCHWc` as well.
+ * \param  count_include_pad Whether include padding in the calculation when pool_type is 'avg'
+ *
+ *
+ * \return The output tensor in the same layout
+ */
+inline Tensor pool_grad(const Tensor& out_grad, const Tensor& x, const Array<PrimExpr>& kernel_size,
+                        const Array<PrimExpr>& stride_size, const Array<PrimExpr>& padding_size,
+                        PoolType pool_type, bool ceil_mode, const std::string& layout = "NCHW",
+                        bool count_include_pad = true) {
+  int height_axis = -1, width_axis = -1;
+  ICHECK(find_height_width(layout, &height_axis, &width_axis)) << "Unsupported layout " << layout;
+  return pool_grad_impl(out_grad, x, kernel_size, stride_size, padding_size, pool_type, ceil_mode,
+                        height_axis, width_axis, count_include_pad);
+}
+
+inline PrimExpr start_index(const Var& out_index, const PrimExpr& odim, const PrimExpr& idim) {
+  return indexdiv(out_index * idim, odim);
+}
+
+inline PrimExpr end_index(const Var& out_index, const PrimExpr& odim, const PrimExpr& idim) {
+  PrimExpr tmp = indexdiv((out_index + 1) * idim, odim);
+  return tvm::tir::Select(indexmod((out_index + 1) * idim, odim) == 0, tmp, tmp + 1);
+}
+
+/*!
+ * \brief Perform adaptive pooling on N dimensional data
+ *
+ * \param x The input tensor
+ * \param output_size int vector of size in each dimension
+ * \param pool_type The type of pooling operator
+ * \param axes indices of each dimension
+ *
+ * \return The output tensor in same layout order
+ */
+inline Tensor adaptive_pool_impl(const Tensor& x, const Array<PrimExpr>& output_size,
+                                 PoolType pool_type, const std::vector<int>& axes) {
+  const auto n_dim = output_size.size();
+  ICHECK_EQ(axes.size(), n_dim) << "The number of axes not equal to the in/out dimension";
+
+  Array<PrimExpr> data_shape = x->shape;
+  for (size_t i = 0; i < data_shape.size(); ++i) {
+    data_shape.Set(i, cast(DataType::DataType::Int(32), data_shape[i]));
+  }
+  Array<PrimExpr> out_shape = data_shape;
+  Array<PrimExpr> in_size, out_size;
+  for (size_t i = 0; i < n_dim; ++i) {
+    in_size.push_back(data_shape[axes[i]]);
+    out_size.push_back(cast(DataType::Int(32), output_size[i]));
+    out_shape.Set(axes[i], out_size[i]);
+  }
+
+  auto get_iter_vars = [=](const Array<Var>& output, bool reduce_indices) {
+    Array<PrimExpr> indices;
+    for (size_t i = 0; i < output.size(); ++i) indices.push_back(output[i]);
+    Array<tir::IterVar> reduce_axes;
+    for (size_t i = 0; i < n_dim; ++i) {
+      auto i_start = start_index(output[axes[i]], out_size[i], in_size[i]);
+      auto i_end = end_index(output[axes[i]], out_size[i], in_size[i]);
+      auto rv_name = "rv" + std::to_string(i);
+      auto rv_axis = tvm::te::reduce_axis(Range(0, i_end - i_start), rv_name);
+      reduce_axes.push_back(rv_axis);
+      if (reduce_indices) {
+        indices.Set(axes[i], i_start + rv_axis);
+      }
+    }
+    return std::make_tuple(indices, reduce_axes);
+  };
+
+  Map<String, ObjectRef> attrs;
+  if (pool_type == kMaxPool) {
+    attrs.Set("schedule_rule", tvm::runtime::String("meta_schedule.adaptive_pool_max"));
+    return tvm::te::compute(
+        out_shape,
+        [&](const Array<Var>& output) {
+          Array<PrimExpr> indices;
+          Array<tir::IterVar> reduce_axes;
+          std::tie(indices, reduce_axes) = get_iter_vars(output, true);
+          return tvm::max(x(indices), reduce_axes);  // NOLINT(*)
+        },
+        "adaptive_pool_max", "adaptive_pool_max", attrs);
+  } else if (pool_type == kAvgPool) {
+    attrs.Set("schedule_rule", tvm::runtime::String("meta_schedule.adaptive_pool_avg"));
+    auto pool_sum = tvm::te::compute(
+        out_shape,
+        [&](const Array<Var>& output) {
+          Array<PrimExpr> indices;
+          Array<tir::IterVar> reduce_axes;
+          std::tie(indices, reduce_axes) = get_iter_vars(output, true);
+          return tvm::sum(x(indices), reduce_axes);
+        },
+        "adaptive_pool_sum", "adaptive_pool_sum");
+
+    return tvm::te::compute(
+        out_shape,
+        [&](const Array<Var>& output) {
+          Array<PrimExpr> indices;
+          Array<tir::IterVar> reduce_axes;
+          std::tie(indices, reduce_axes) = get_iter_vars(output, false);
+
+          PrimExpr divide_factor = tvm::cast(x->dtype, 1);
+          for (size_t i = 0; i < n_dim; ++i) {
+            divide_factor *= tvm::cast(x->dtype, reduce_axes[i]->dom->extent);
+          }
+
+          return div(pool_sum(indices), divide_factor);
+        },
+        "adaptive_pool_avg", kElementWise, attrs);
+  } else {
+    LOG(ERROR) << "Unrecognized pool_type: " << pool_type;
+    return x;
+  }
+}
+
+/*!
+ * \brief Adaptively perform pooling on height and width dimension of data.
+ *        The pooling kernel and stride sizes are automatically chosen for desired output sizes.
+ *        It decides the height and width dimension according to the layout string,
+ *        in which 'W' and 'H' means width and height respectively.
+ *        Width and height dimension cannot be split.
+ *        For example, NCHW, NCHW16c, etc. are valid for pool,
+ *        while NCHW16w, NCHW16h are not.
+ *        See \a layout for more information of the layout string convention.
+ *
+ * \param x The input tensor
+ * \param output_size Vector of two ints: {output_height, output_width}
+ * \param pool_type The type of pooling operator
+ * \param layout The input layout. Pooling supports any layout as long as 'H' and 'W' appear.
+ *        The layout is supposed to be composed of upper cases, lower cases and (optional) numbers,
+ *        where upper case indicates a dimension and
+ *        the corresponding lower case (with factor size) indicates the split dimension.
+ *        For example, NCHW16c can describe a 5-D tensor of
+ *        [batch_size, channel, height, width, channel_block].
+ *        (in which factor size `16` will not be used in pooling but for other operators,
+ *        it can be used to decide the output shape).
+ *        Since pooling does not care about the factor size of dimensions
+ *        other than `H` and `W`, one can pass `NCHWc` as well.
+ *
+ * \return The output tensor in same layout order
+ */
+inline Tensor adaptive_pool(const Tensor& x, const Array<PrimExpr>& output_size, PoolType pool_type,
+                            const std::string& layout = "NCHW") {
+  int height_axis = -1, width_axis = -1;
+  ICHECK(find_height_width(layout, &height_axis, &width_axis)) << "Unsupported layout " << layout;
+  return adaptive_pool_impl(x, output_size, pool_type, {height_axis, width_axis});
+}
+
+/*!
+ * \brief Adaptively perform pooling on three dimensional data.
+ *        See the two dimensional version above for details.
+ * \param x The input tensor
+ * \param output_size Vector of three ints: {output_depth, output_height, output_width}
+ * \param pool_type The type of pooling operator
+ * \param layout The input layout. The default is "NCDHW".
+ */
+inline Tensor adaptive_pool3d(const Tensor& x, const Array<PrimExpr>& output_size,
+                              PoolType pool_type, const std::string& layout = "NCDHW") {
+  int depth_axis = -1, height_axis = -1, width_axis = -1;
+  ICHECK(find_depth_height_width(layout, &depth_axis, &height_axis, &width_axis))
+      << "Unsupported layout " << layout;
+  return adaptive_pool_impl(x, output_size, pool_type, {depth_axis, height_axis, width_axis});
+}
+
+/*!
+ * \brief Adaptively perform pooling on one dimensional data.
+ *        See the two dimensional version above for details.
+ * \param x The input tensor
+ * \param output_size Vector of one int: {output_width}
+ * \param pool_type The type of pooling operator
+ * \param layout The input layout. The default is "NCW".
+ */
+inline Tensor adaptive_pool1d(const Tensor& x, const Array<PrimExpr>& output_size,
+                              PoolType pool_type, const std::string& layout = "NCW") {
+  int width_axis = -1;
+  ICHECK(find_width(layout, &width_axis)) << "Unsupported layout " << layout;
+  return adaptive_pool_impl(x, output_size, pool_type, {width_axis});
+}
+
+/*!
+ * \brief Perform global pooling on height and width dimension of data.
+ *        It decides the height and width dimension according to the layout string,
+ *        in which 'W' and 'H' means width and height respectively.
+ *        Width and height dimension cannot be split.
+ *        For example, NCHW, NCHW16c, ... are valid for global_pool,
+ *        while NCHW16w, NCHW16h are not.
+ *        See \a layout for more information of the layout string convention.
+ *
+ * \param x The input tensor represent as layout
+ * \param pool_type The type of pooling operator
+ * \param layout The input layout. global-pooling supports any layout as long as 'H' and 'W' appear.
+ *        The layout is supposed to be composed of upper cases, lower cases and (optional) numbers,
+ *        where upper case indicates a dimension and
+ *        the corresponding lower case (with factor size) indicates the sub-dimension.
+ *        For example, `NCHW16c` can describe a 5-D tensor of
+ *        [batch_size, channel, height, width, channel_block].
+ *        (in which factor size `16` will not be used in pooling but for other operators,
+ *        it can be used to decide the output shape).
+ *        Since pooling does not care about the factor size of
+ *        dimensions other than `H` and `W`, one can pass `NCHWc` as well.
+ *
+ * \return The output tensor in same layout with height and width dimension size of 1.
+ *         e.g., for NCHW, the output shape will be [batch, channel, 1, 1]
+ */
+inline Tensor global_pool(const Tensor& x, PoolType pool_type, const std::string& layout = "NCHW") {
+  return adaptive_pool(x, Array<PrimExpr>{1, 1}, pool_type, layout);
+}
+
+/*!
+ * \brief Perform pooling on N-dimension of data.
+ *
+ * \param x The input tensor
+ * \param kernel_size Vector of N ints
+ * \param stride_size Vector of N ints
+ * \param dilation_size Vector of N ints
+ * \param padding_size Vector of N*2 ints [head_pad_d1, head_pad_d2, ...,
+ *        head_pad_dN, tail_pad_d1, tail_pad_d2, ..., tail_pad_dN]
+ * \param pool_type The type of pooling operator
+ * \param ceil_mode Whether to use ceil when calculating the output size
+ * \param axis Vector of indices for the N dimensions
+ * \param count_include_pad Whether include padding in the calculation
+ *
+ * \return The output tensor in same layout order
+ */
+inline Tensor pool_impl_nd(const Tensor& x, const Array<PrimExpr>& kernel_size,
+                           const Array<PrimExpr>& stride_size, const Array<PrimExpr>& dilation_size,
+                           const Array<PrimExpr>& padding_size, PoolType pool_type, bool ceil_mode,
+                           const std::vector<int>& axis, bool count_include_pad) {
+  int k_size = kernel_size.size();
+  int x_size = x->shape.size();
+  ICHECK_EQ(stride_size.size(), k_size) << "Pooling stride_size must have same elements as kernel";
+  ICHECK_EQ(padding_size.size(), k_size * 2) << "Pooling padding_size must has double elements of"
+                                                " kernel";
+  ICHECK_EQ(axis.size(), k_size) << "axis must have same elements as kernel";
+
+  Array<IterVar> daxis;
+  std::vector<PrimExpr> kernel(k_size);
+  std::vector<PrimExpr> stride(k_size);
+  std::vector<PrimExpr> dilation(k_size);
+  std::vector<PrimExpr> pad_head(k_size);
+  std::vector<PrimExpr> pad_tail(k_size);
+  std::vector<PrimExpr> offset(k_size, 0);
+  Array<PrimExpr> pad_before(std::vector<PrimExpr>(x_size, 0));
+  Array<PrimExpr> pad_after(std::vector<PrimExpr>(x_size, 0));
+  Array<PrimExpr> data_shape = x->shape;
+  for (size_t i = 0; i < data_shape.size(); ++i) {
+    data_shape.Set(i, cast(DataType::DataType::Int(32), data_shape[i]));
+  }
+  Array<PrimExpr> out_shape = data_shape;
+
+  bool do_pad = false;
+  for (int i = 0; i < k_size; i++) {
+    int ii = axis[i];
+    kernel[i] = cast(DataType::Int(32), kernel_size[i]);
+    stride[i] = cast(DataType::Int(32), stride_size[i]);
+    dilation[i] = cast(DataType::Int(32), dilation_size[i]);
+    pad_head[i] = cast(DataType::Int(32), padding_size[i]);
+    pad_tail[i] = cast(DataType::Int(32), padding_size[i + k_size]);
+
+    if (ceil_mode) {
+      // The offset[i] is an additional padding to ensure we do ceil instead of floor when
+      // dividing by stride.
+      // In the case of ceil_mode=True and count_include_pad=True,
+      // in order to obtain the correct boundary,
+      // we also need to use the offset[i] to eliminate this extra padding.
+      offset[i] = stride[i] - 1;
+      pad_tail[i] += offset[i];
+    }
+
+    const int64_t* padding0 = as_const_int(pad_head[i]);
+    const int64_t* padding1 = as_const_int(pad_tail[i]);
+    do_pad = do_pad || (padding0 && *padding0) || (padding1 && *padding1);
+
+    daxis.push_back(tvm::te::reduce_axis(Range(0, kernel[i]), "rv" + std::to_string(i)));
+
+    pad_before.Set(ii, pad_head[i]);
+    pad_after.Set(ii, pad_tail[i]);
+
+    arith::Analyzer analyzer;
+
+    PrimExpr numerator =
+        data_shape[ii] - (kernel[i] - 1) * dilation[i] - 1 + pad_head[i] + pad_tail[i];
+    auto out_dim = analyzer.Simplify(indexdiv(numerator, stride[i]) + 1);
+    out_shape.Set(ii, out_dim);
+  }
+
+  Map<String, ObjectRef> attrs;
+  if (pool_type == kMaxPool) {
+    auto temp = do_pad ? pad(x, pad_before, pad_after, tvm::min_value(x->dtype), "pad_temp") : x;
+    attrs.Set("schedule_rule", tvm::runtime::String("meta_schedule.pool_max"));
+    return tvm::te::compute(
+        out_shape,
+        [&](const Array<Var>& output) {
+          Array<PrimExpr> indices;
+          for (const Var& var : output) indices.push_back(var);
+
+          for (int i = 0; i < k_size; i++) {
+            int ii = axis[i];
+            indices.Set(ii, output[ii] * stride[i] + daxis[i] * dilation[i]);
+          }
+          return tvm::max(temp(indices), daxis);
+        },
+        "pool_max", "pool_max", attrs);
+  } else if (pool_type == kAvgPool) {
+    attrs.Set("schedule_rule", tvm::runtime::String("meta_schedule.pool_avg"));
+    // Pad the inputs
+    auto temp = do_pad ? pad(x, pad_before, pad_after, 0, "pad_temp") : x;
+
+    // TVM compute for summing the pooling window.
+    auto pool_sum = tvm::te::compute(
+        out_shape,
+        [&](const Array<Var>& output) {
+          Array<PrimExpr> indices;
+          for (const Var& var : output) indices.push_back(var);
+
+          for (int i = 0; i < k_size; i++) {
+            int ii = axis[i];
+            indices.Set(ii, output[ii] * stride[i] + daxis[i] * dilation[i]);
+          }
+          return tvm::sum(temp(indices), daxis);
+        },
+        "pool_sum", "pool_sum");
+
+    // TVM compute for dividing the reduced window sum by kernel size.
+    return tvm::te::compute(
+        out_shape,
+        [&](const Array<Var>& output) {
+          Array<PrimExpr> indices;
+          for (const Var& var : output) indices.push_back(var);
+          if (count_include_pad) {
+            std::vector<PrimExpr> start(k_size);
+            std::vector<PrimExpr> end(k_size);
+            auto num_el = make_const(DataType::Int(32), 1);
+            for (int i = 0; i < k_size; i++) {
+              int ii = axis[i];
+              start[i] = output[ii] * stride[i] - pad_head[i];
+              // When computing the output shape in ceil_mode,
+              // we have added the extra padding of offset[i],
+              // so now in order to calculate the correct boundary ,
+              // we need to substract the offset[i].
+              end[i] = start[i] + (kernel[i] - 1) * dilation[i];
+              end[i] = min(end[i], data_shape[ii] + pad_tail[i] - 1 - offset[i]);
+              num_el *= (end[i] - start[i]) / dilation[i] + 1;
+            }
+            return div(pool_sum(indices), num_el);
+          } else {
+            std::vector<PrimExpr> start(k_size);
+            std::vector<PrimExpr> end(k_size);
+            auto num_el = make_const(DataType::Int(32), 1);
+            for (int i = 0; i < k_size; i++) {
+              int ii = axis[i];
+
+              // Let start and end contain the first and last index of our Tensor
+              // along the relevant dimension we use in our calculation.
+              // Assume indices -1, -2 represent the padding before (tail) and
+              // len(arr), len(arr) + 1 represent the padding after (head).
+              start[i] = output[ii] * stride[i] - pad_head[i];
+              end[i] = start[i] + (kernel[i] - 1) * dilation[i];
+
+              // if start[i] < 0, e.g. we start on a tail padded number this will be a positive
+              // number that represents the number of steps along the dilated kernel to reach a
+              // non-padded value. Otherwise this should be 0.
+              PrimExpr jumps_to_non_pad = (dilation[i] - 1 - start[i]) / dilation[i];
+              jumps_to_non_pad = max(jumps_to_non_pad, make_const(DataType::Int(32), 0));
+
+              end[i] = min(end[i], data_shape[ii] - 1);
+              num_el *= (end[i] - (start[i] + dilation[i] * jumps_to_non_pad)) / dilation[i] + 1;
+            }
+
+            PrimExpr divide_factor = max(num_el, make_const(DataType::Int(32), 1));
+            return div(pool_sum(indices), divide_factor);
+          }
+        },
+        "pool_avg", kElementWise, attrs);
+  } else {
+    LOG(ERROR) << "Unrecognized pool_type: " << pool_type;
+    return x;
+  }
+}
+
+/*!
+ * \brief Perform pooling on the width dimension of data.
+ *        Width axis is determined by the layout string
+ *        in which 'W' means width.
+ *        Width dimension cannot be split.
+ *        For example, NCW, NCW16c, etc. are valid for pool,
+ *        while NCW16w is not.
+ *        See \a layout for more information of the layout string convention.
+ * \param x The input tensor.
+ * \param kernel_size Vector of one int: {kernel_width}
+ * \param stride_size Vector of one int: {stride_width}
+ * \param dilation_size Vector of one int: {dilation_width}
+ * \param padding_size Vector of two ints: {head_pad_width, tail_pad_width}
+ * \param pool_type The type of pooling operator
+ * \param ceil_mode Whether to use ceil when calculating the output size
+ * \param layout The input layout. Pooling supports any layout as long as 'W' appears.
+ *        The layout is supposed to be composed of upper cases, lower cases and (optional) numbers,
+ *        where upper case indicates a dimension and
+ *        the corresponding lower case (with factor size) indicates the split dimension.
+ *        For example, NCW16c can describe a 4-D tensor of
+ *        [batch_size, channel, width, channel_block].
+ *        (in which factor size `16` will not be used in pooling but for other operators,
+ *        it can be used to decide the output shape).
+ *        Since pooling does not care about the factor size of dimensions
+ *        other than `W`, one can pass `NCWc` as well.
+ * \param  count_include_pad Whether include padding in the calculation when pool_type is 'avg'
+ *
+ *
+ * \return The output tensor in the same layout
+ */
+inline Tensor pool1d(const Tensor& x, const Array<PrimExpr>& kernel_size,
+                     const Array<PrimExpr>& stride_size, const Array<PrimExpr>& dilation_size,
+                     const Array<PrimExpr>& padding_size, PoolType pool_type, bool ceil_mode,
+                     const std::string& layout = "NCW", bool count_include_pad = true) {
+  int width_axis = -1;
+  ICHECK(find_width(layout, &width_axis)) << "Unsupported layout " << layout;
+  std::vector<int> axis = {width_axis};
+  return pool_impl_nd(x, kernel_size, stride_size, dilation_size, padding_size, pool_type,
+                      ceil_mode, axis, count_include_pad);
+}
+
+/*!
+ * \brief Perform pooling on height and width dimension of data.
+ *        It decides the height and width dimension according to the layout string,
+ *        in which 'W' and 'H' means width and height respectively.
+ *        Width and height dimension cannot be split.
+ *        For example, NCHW, NCHW16c, etc. are valid for pool,
+ *        while NCHW16w, NCHW16h are not.
+ *        See \a layout for more information of the layout string convention.
+ * \param x The input tensor.
+ * \param kernel_size Vector of two ints: {kernel_height, kernel_width}
+ * \param stride_size Vector of two ints: {stride_height, stride_width}
+ * \param dilation_size Vector of two ints: {dilation_height, dilation_width}
+ * \param padding_size Vector of two ints: {padding_height, padding_width}
+ * \param pool_type The type of pooling operator
+ * \param ceil_mode Whether to use ceil when calculating the output size
+ * \param layout The input layout. Pooling supports any layout as long as 'H' and 'W' appear.
+ *        The layout is supposed to be composed of upper cases, lower cases and (optional) numbers,
+ *        where upper case indicates a dimension and
+ *        the corresponding lower case (with factor size) indicates the split dimension.
+ *        For example, NCHW16c can describe a 5-D tensor of
+ *        [batch_size, channel, height, width, channel_block].
+ *        (in which factor size `16` will not be used in pooling but for other operators,
+ *        it can be used to decide the output shape).
+ *        Since pooling does not care about the factor size of dimensions
+ *        other than `H` and `W`, one can pass `NCHWc` as well.
+ * \param  count_include_pad Whether include padding in the calculation when pool_type is 'avg'
+ *
+ *
+ * \return The output tensor in the same layout
+ */
+inline Tensor pool2d(const Tensor& x, const Array<PrimExpr>& kernel_size,
+                     const Array<PrimExpr>& stride_size, const Array<PrimExpr>& dilation_size,
+                     const Array<PrimExpr>& padding_size, PoolType pool_type, bool ceil_mode,
+                     const std::string& layout = "NCHW", bool count_include_pad = true) {
+  int height_axis = -1, width_axis = -1;
+  ICHECK(find_height_width(layout, &height_axis, &width_axis)) << "Unsupported layout " << layout;
+  std::vector<int> axis = {height_axis, width_axis};
+  return pool_impl_nd(x, kernel_size, stride_size, dilation_size, padding_size, pool_type,
+                      ceil_mode, axis, count_include_pad);
+}
+
+/*!
+ * \brief Perform pooling on depth, height and width dimension of data.
+ *        It decides the depth, height and width dimension according to the layout string,
+ *        in which 'D', 'W' and 'H' means depth, width and height respectively.
+ *        Depth, Width and height dimension cannot be split.
+ *        For example, NCDHW, NCDHW16c, etc. are valid for pool,
+ *        while NCDHW16d, NCDHW16w or NCDHW16h are not.
+ *        See \a layout for more information of the layout string convention.
+ * \param x The input tensor.
+ * \param kernel_size Vector of three ints: {kernel_depth, kernel_height, kernel_width}
+ * \param stride_size Vector of three ints: {stride_depth, stride_height, stride_width}
+ * \param dilation_size Vector of three ints: {dilation_depth, dilation_height, dilation_width}
+ * \param padding_size Vector of six ints: {head_pad_depth, head_pad_height, head_pad_width,
+ *        tail_pad_depth, tail_pad_height, tail_pad_width}
+ * \param pool_type The type of pooling operator
+ * \param ceil_mode Whether to use ceil when calculating the output size
+ * \param layout The input layout. Pooling supports any layout as long as 'D', 'H' and 'W' appear.
+ *        The layout is supposed to be composed of upper cases, lower cases and (optional) numbers,
+ *        where upper case indicates a dimension and
+ *        the corresponding lower case (with factor size) indicates the split dimension.
+ *        For example, NCDHW16c can describe a 6-D tensor of
+ *        [batch_size, channel, depth, height, width, channel_block].
+ *        (in which factor size `16` will not be used in pooling but for other operators,
+ *        it can be used to decide the output shape).
+ *        Since pooling does not care about the factor size of dimensions
+ *        other than `D`, `H` and `W`, one can pass `NCDHWc` as well.
+ * \param  count_include_pad Whether include padding in the calculation when pool_type is 'avg'
+ *
+ *
+ * \return The output tensor in the same layout
+ */
+inline Tensor pool3d(const Tensor& x, const Array<PrimExpr>& kernel_size,
+                     const Array<PrimExpr>& stride_size, const Array<PrimExpr>& dilation_size,
+                     const Array<PrimExpr>& padding_size, PoolType pool_type, bool ceil_mode,
+                     const std::string& layout = "NCDHW", bool count_include_pad = true) {
+  int depth_axis = -1, height_axis = -1, width_axis = -1;
+  ICHECK(find_depth_height_width(layout, &depth_axis, &height_axis, &width_axis))
+      << "Unsupported layout " << layout;
+  std::vector<int> axis = {depth_axis, height_axis, width_axis};
+  return pool_impl_nd(x, kernel_size, stride_size, dilation_size, padding_size, pool_type,
+                      ceil_mode, axis, count_include_pad);
+}
+
+}  // namespace nn
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_NN_POOLING_H_
diff --git a/darknet_drp_ros/include/tvm/topi/nn/softmax.h b/darknet_drp_ros/include/tvm/topi/nn/softmax.h
new file mode 100644
index 0000000..3af6b9b
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/nn/softmax.h
@@ -0,0 +1,149 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \brief Softmax op constructions
+ * \file nn/softmax.h
+ */
+#ifndef TVM_TOPI_NN_SOFTMAX_H_
+#define TVM_TOPI_NN_SOFTMAX_H_
+
+#include <tvm/te/operation.h>
+#include <tvm/topi/reduction.h>
+#include <tvm/topi/tags.h>
+
+#include <algorithm>
+#include <string>
+
+namespace tvm {
+namespace topi {
+namespace nn {
+
+using namespace tvm::te;
+
+/*!
+ * \brief Softmax activation
+ *
+ * \param x The input tensor. Can be any dimension
+ * \param axis The channel axis along which softmax is performed
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the softmax operation
+ */
+inline Tensor softmax(const Tensor& x, int axis = -1, std::string name = "tensor",
+                      std::string tag = "softmax_output") {
+  auto input_shape = x->shape;
+  auto ndim = input_shape.size();
+  if (axis < 0) {
+    axis = ndim + axis;
+  }
+  ICHECK_LT(axis, ndim) << "axis parameter should be less than input dim";
+
+  auto k1 = tvm::te::reduce_axis(Range(0, input_shape[axis]), "k1");
+  auto k2 = tvm::te::reduce_axis(Range(0, input_shape[axis]), "k2");
+  auto reduced_shape = MakeReduceTargetShape({axis}, x, false, false);
+
+  tvm::Map<String, ObjectRef> attrs;
+  attrs.Set("axis", Integer(axis));
+
+  auto insert_reduce_index = [axis, ndim](const Array<Var>& indices, const IterVar& reduce_index) {
+    Array<PrimExpr> eval_range;
+    int arg_counter = 0;
+    for (size_t i = 0; i < ndim; ++i) {
+      if (static_cast<int>(i) == axis) {
+        eval_range.push_back(reduce_index);
+      } else {
+        eval_range.push_back(indices[arg_counter++]);
+      }
+    }
+    return eval_range;
+  };
+
+  auto get_non_reduce_indices = [axis, ndim](const Array<Var>& indices) {
+    Array<PrimExpr> non_reduce_indices;
+    for (size_t i = 0; i < ndim; ++i) {
+      if (static_cast<int>(i) != axis) non_reduce_indices.push_back(indices[i]);
+    }
+    return non_reduce_indices;
+  };
+
+  auto _compute_max = [&](const Array<Var>& indices) {
+    auto eval_range = insert_reduce_index(indices, k1);
+    return topi::MaxOp(x(eval_range), {k1});
+  };
+
+  auto _compute_exp = [&](const Tensor& max_elem, const Array<Var>& indices) {
+    auto non_reduce_indices = get_non_reduce_indices(indices);
+    return tvm::exp(x(indices) - max_elem(non_reduce_indices));
+  };
+
+  auto _compute_expsum = [&](const Tensor& exp, const Array<Var>& indices) {
+    auto eval_range = insert_reduce_index(indices, k2);
+    return tvm::sum(exp(eval_range), {k2});
+  };
+
+  auto _normalize = [&](const Tensor& exp, const Tensor& expsum, const Array<Var>& indices) {
+    auto non_reduce_indices = get_non_reduce_indices(indices);
+    return exp(indices) / expsum(non_reduce_indices);
+  };
+
+  auto max_elem = tvm::te::compute(reduced_shape, _compute_max);
+  auto exp = tvm::te::compute(
+      input_shape, [&](const Array<Var>& indices) { return _compute_exp(max_elem, indices); });
+  auto expsum = tvm::te::compute(
+      reduced_shape, [&](const Array<Var>& indices) { return _compute_expsum(exp, indices); });
+  return tvm::te::compute(
+      input_shape, [&](const Array<Var>& indices) { return _normalize(exp, expsum, indices); },
+      name, tag, attrs);
+}
+
+/*!
+ * \brief Log softmax activation
+ *
+ * \param x The input tensor. 2-D where log softmax is performed along the second dimension
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the log softmax operation
+ */
+inline Tensor log_softmax(const Tensor& x, std::string name = "tensor",
+                          std::string tag = "log_softmax_output") {
+  ICHECK_EQ(x->shape.size(), 2) << "Log softmax requires 2-D input";
+
+  PrimExpr m = x->shape[0];
+  PrimExpr n = x->shape[1];
+
+  auto k = tvm::te::reduce_axis(Range(0, n), "k");
+  auto max_elem =
+      tvm::te::compute({m}, [&](Var i) { return tvm::max(x(i, k), Array<IterVar>{k}); });
+  k = tvm::te::reduce_axis(Range(0, n), "k");
+
+  auto expsum =
+      tvm::te::compute({m}, [&](Var i) { return tvm::sum(tvm::exp(x(i, k) - max_elem(i)), {k}); });
+
+  return tvm::te::compute(
+      x->shape, [&](Var i, Var j) { return x(i, j) - max_elem(i) - tvm::log(expsum(i)); }, name,
+      tag);
+}
+
+}  // namespace nn
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_NN_SOFTMAX_H_
diff --git a/darknet_drp_ros/include/tvm/topi/reduction.h b/darknet_drp_ros/include/tvm/topi/reduction.h
new file mode 100644
index 0000000..5e79bd4
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/reduction.h
@@ -0,0 +1,598 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file topi/reduction.h
+ * \brief Reduction op constructors
+ */
+#ifndef TVM_TOPI_REDUCTION_H_
+#define TVM_TOPI_REDUCTION_H_
+
+#include <tvm/te/operation.h>
+#include <tvm/topi/broadcast.h>
+#include <tvm/topi/detail/constant_utils.h>
+#include <tvm/topi/detail/ravel_unravel.h>
+#include <tvm/topi/elemwise.h>
+#include <tvm/topi/tags.h>
+#include <tvm/topi/transform.h>
+
+#include <algorithm>
+#include <iterator>
+#include <string>
+#include <vector>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+
+/*! \brief The operation to use for CommReduce */
+using FReduce = std::function<PrimExpr(PrimExpr source, const Array<IterVar>& axis,
+                                       Array<PrimExpr> init, Span span)>;
+
+/*! \brief The operation to use for CommReduceIdx */
+using FCommReduce = std::function<Array<PrimExpr>(Array<PrimExpr> exprs, const Array<IterVar>& axis,
+                                                  PrimExpr* condition)>;
+
+/*!
+ * \brief Convert a reduction axis which could be empty or have negative
+ * elements into a real axis with valid dimension indices.
+ *
+ * \param ndim Number of dimensions in the target.
+ * \param axis The axis parameter.
+ *
+ * \return A non-empty sorted array of valid dimension indices, with no duplicates.
+ * If the input axis is empty, the result will be an axis including all dimensions.
+ * If any input element is negative, it will be treated as an offset from the
+ * last dimension (same as python indexing rules).
+ */
+inline std::vector<int> GetRealAxis(int ndim, const Array<Integer>& axis) {
+  std::vector<int> real_axis;
+  if (!axis.defined() || axis.size() == 0) {
+    for (int i = 0; i < ndim; ++i) {
+      real_axis.push_back(i);
+    }
+  } else {
+    // Use a set so duplicates are removed and the dims are sorted
+    for (auto elem : axis) {
+      int64_t val = elem->value;
+      if (val < 0) {
+        val += ndim;
+      }
+      ICHECK_LE(val, ndim) << " exceeds the maximum dimension " << ndim;
+      ICHECK_GE(val, 0);
+      real_axis.push_back(static_cast<int>(val));
+    }
+    std::sort(real_axis.begin(), real_axis.end());
+    real_axis.resize(std::unique(real_axis.begin(), real_axis.end()) - real_axis.begin());
+  }
+  return real_axis;
+}
+
+/*! \brief Enumerate the axes for a reduce op */
+inline Array<IterVar> MakeReduceAxes(const std::vector<int>& real_axis, const Tensor& data) {
+  Array<IterVar> reduce_axes;
+  for (auto i : real_axis) {
+    std::string name = "k" + std::to_string(i);
+    reduce_axes.push_back(tvm::te::reduce_axis(Range(0, data->shape[i]), name));
+  }
+  return reduce_axes;
+}
+
+/*! \brief Calculate the target shape for a reduce op */
+inline Array<PrimExpr> MakeReduceTargetShape(const std::vector<int>& real_axis, const Tensor& data,
+                                             bool keepdims, bool atleast1d) {
+  auto ndim = data->shape.size();
+  Array<PrimExpr> target_shape;
+  if (keepdims) {
+    for (size_t i = 0; i < ndim; ++i) {
+      if (std::find(real_axis.begin(), real_axis.end(), i) != real_axis.end()) {
+        // real_axis contains i
+        target_shape.push_back(1);
+      } else {
+        target_shape.push_back(data->shape[i]);
+      }
+    }
+  } else {
+    for (size_t i = 0; i < ndim; ++i) {
+      if (std::find(real_axis.begin(), real_axis.end(), i) == real_axis.end()) {
+        // real_axis does not contain i
+        target_shape.push_back(data->shape[i]);
+      }
+    }
+  }
+  if (target_shape.size() == 0 && atleast1d) {
+    target_shape.push_back(1);
+  }
+  return target_shape;
+}
+
+/*!
+ * \brief Create a reduction operation.
+ *
+ * \param data The input tensor.
+ * \param func The reduction function eg. tvm::sum
+ * \param target_shape The output Tensor shape.
+ * \param reduce_axes The real axes along which the reduction is performed.
+ * \param squeeze_axes The real axes to squeeze. Unsqueezed, reduced axes will
+ *                     have shape 1 in the output tensor.
+ * \param span The location of this reducer in the source.
+ *
+ * \return The result tensor.
+ */
+inline Tensor DoCommReduce(const Tensor& data, FReduce func, const Array<PrimExpr>& target_shape,
+                           const std::vector<int>& reduce_axes,
+                           const std::vector<int>& squeeze_axes, Span span = Span()) {
+  auto r_axes = MakeReduceAxes(reduce_axes, data);
+  auto compute = [&](const Array<Var>& indices) {
+    Array<PrimExpr> eval_range;
+    Array<Var> eval_indices;
+    int arg_counter = 0;
+    int red_counter = 0;
+
+    for (size_t i = 0; i < data->shape.size(); ++i) {
+      bool squeeze_i = std::find(squeeze_axes.begin(), squeeze_axes.end(), i) != squeeze_axes.end();
+      if (std::find(reduce_axes.begin(), reduce_axes.end(), i) != reduce_axes.end()) {
+        // real_axis contains i
+        eval_range.push_back(r_axes[red_counter]);
+        eval_indices.push_back(r_axes[red_counter]->var);
+        red_counter++;
+        arg_counter += !squeeze_i;
+        continue;
+      }
+      eval_range.push_back(indices[arg_counter]);
+      arg_counter++;
+    }
+
+    return func(data(eval_range), r_axes, {}, span);
+  };
+
+  return tvm::te::compute(target_shape, compute, data->op->name + "_red", kCommReduce);
+}
+
+/*!
+ * \brief Create a reduction operation.
+ *
+ * \param data The input tensor.
+ * \param axis The axes along which the reduction is performed.
+ * \param func The reduction function eg. tvm::sum
+ * \param keepdims If this is set to true, the axes which are reduced are
+ * left in the result as dimensions with size one. This enables the result
+ * to broadcast correctly against the input array.
+ * \param atleast1d Whether the output need to be atleast1d.
+ *
+ * \return The result tensor.
+ */
+inline Tensor CommReduce(const Tensor& data, const Array<Integer>& axis, FReduce func,
+                         bool keepdims, bool atleast1d) {
+  auto ndim = data->shape.size();
+  ICHECK_NE(ndim, 0) << "Cannot reduce a 0 dim Tensor";
+  auto real_axis = GetRealAxis(static_cast<int>(ndim), axis);
+  auto target_shape = MakeReduceTargetShape(real_axis, data, keepdims, atleast1d);
+  return DoCommReduce(data, func, target_shape, real_axis,
+                      keepdims ? std::vector<int>() : real_axis);
+}
+
+/*!
+ * \brief Create an index reduction operation.
+ *
+ * \param data The input tensor.
+ * \param axis The axes along which the reduction is performed.
+ * \param func The reduction function
+ * \param keepdims If this is set to true, the axes which are reduced are
+ * left in the result as dimensions with size one. This enables the result
+ * to broadcast correctly against the input array.
+ * \param atleast1d Whether the output need to be atleast1d.
+ *
+ * \return The result tensor.
+ */
+inline Tensor CommReduceIdx(const Tensor& data, const Array<Integer>& axis, FCommReduce func,
+                            bool keepdims, bool atleast1d) {
+  auto ndim = data->shape.size();
+  ICHECK_NE(ndim, 0) << "Cannot reduce a 0 dim Tensor";
+  auto real_axis = GetRealAxis(static_cast<int>(ndim), axis);
+  auto reduce_axes = MakeReduceAxes(real_axis, data);
+  auto target_shape = MakeReduceTargetShape(real_axis, data, keepdims, atleast1d);
+
+  auto compute = [ndim, keepdims, &real_axis, &reduce_axes, &func,
+                  &data](const Array<Var>& indices) {
+    Array<PrimExpr> eval_range;
+    Array<PrimExpr> eval_indices;
+    int arg_counter = 0;
+    int red_counter = 0;
+
+    for (size_t i = 0; i < ndim; ++i) {
+      if (std::find(real_axis.begin(), real_axis.end(), i) != real_axis.end()) {
+        // real_axis contains i
+        eval_range.push_back(reduce_axes[red_counter]);
+        eval_indices.push_back(reduce_axes[red_counter]->var);
+        red_counter++;
+      } else {
+        if (!keepdims) {
+          eval_range.push_back(indices[arg_counter]);
+          arg_counter++;
+        } else {
+          eval_range.push_back(indices[i]);
+        }
+      }
+    }
+
+    Array<PrimExpr> ravel_shape;
+    for (auto i : real_axis) {
+      ravel_shape.push_back(data->shape[i]);
+    }
+    auto idx = detail::RavelIndex(eval_indices, ravel_shape);
+    return func({idx, data(eval_range)}, reduce_axes, nullptr);
+  };
+
+  auto temp_idx_val =
+      tvm::te::compute(target_shape, compute, data->op->name + "_red_temp", kCommReduceIdx);
+  auto temp_idx = temp_idx_val[0];
+  auto temp_val = temp_idx_val[1];
+  return tvm::te::compute(
+      target_shape, [&temp_idx](const Array<Var>& indices) { return temp_idx(indices); },
+      data->op->name + "_red", kCommReduceIdx);
+}
+
+/*! \brief A combiner function for a reduction */
+using FCombine = std::function<Array<PrimExpr>(Array<Var> lhs, Array<Var> rhs)>;
+
+/*! \brief An initializer function for a reduction */
+using FIdentity = std::function<Array<PrimExpr>(std::vector<DataType> types)>;
+
+/*!
+ * \brief Create a commutative reducer for a reduction
+ *
+ * \param fcombine A function to combine exprs
+ * \param fidentity A function to initialize elements
+ * \param name The name of the operation
+ *
+ * \return A reducer function which creates a reduce expression over an axis.
+ */
+inline FCommReduce MakeCommReducer(FCombine fcombine, FIdentity fidentity,
+                                   std::string name = "reduce") {
+  return [fcombine, fidentity, name](Array<PrimExpr> exprs, const Array<IterVar>& axis,
+                                     PrimExpr* condition) {
+    Array<Var> lhs, rhs;
+    std::vector<DataType> dtypes;
+
+    for (size_t i = 0; i < exprs.size(); ++i) {
+      auto dtype = exprs[i].dtype();
+      dtypes.push_back(dtype);
+      lhs.push_back(var(name + "_lhs_" + std::to_string(i), dtype));
+      rhs.push_back(var(name + "_rhs_" + std::to_string(i), dtype));
+    }
+
+    auto result = fcombine(lhs, rhs);
+    auto id_elem = fidentity(dtypes);
+    auto cond = condition != nullptr ? *condition : tir::const_true();
+
+    auto combiner = tvm::tir::CommReducer(lhs, rhs, result, id_elem);
+    Array<PrimExpr> outputs;
+    for (size_t i = 0; i < exprs.size(); ++i) {
+      outputs.push_back(tvm::tir::Reduce(combiner, exprs, axis, cond, static_cast<int>(i), {}));
+    }
+    return outputs;
+  };
+}
+
+/*! \brief Wrap tvm::min to ensure we get the correct overload */
+inline PrimExpr MinOp(PrimExpr source, Array<IterVar> axis, Array<PrimExpr> init = {},
+                      Span span = Span()) {
+  return tvm::min(source, axis, init, span);
+}
+
+/*! \brief Wrap tvm::max to ensure we get the correct overload */
+inline PrimExpr MaxOp(PrimExpr source, Array<IterVar> axis, Array<PrimExpr> init = {},
+                      Span span = Span()) {
+  return tvm::max(source, axis, init, span);  // NOLINT(*)
+}
+
+/*! \brief Wrap tvm::prod to ensure we get the correct overload */
+inline PrimExpr ProdOp(PrimExpr source, Array<IterVar> axis, Array<PrimExpr> init = {},
+                       Span span = Span()) {
+  return tvm::prod(source, axis, init, span);  // NOLINT(*)
+}
+
+/*!
+ * \brief Creates an operation that sums array elements over a given axis
+ *
+ * \param data The input tensor
+ * \param axis The axis to sum over. If axis is empty, the operation will
+ * sum over all elements of the array.
+ * \param keepdims If this is set to true, the axes which are reduced are
+ * left in the result as dimensions with size one. This enables the result
+ * to broadcast correctly against the input array.
+ * \param atleast1d Whether the output need to be atleast1d.
+ *
+ * \return A Tensor whose op member is the sum operation
+ */
+inline Tensor sum(const Tensor& data, const Array<Integer>& axis, bool keepdims = false,
+                  bool atleast1d = false) {
+  return CommReduce(data, axis, tvm::sum, keepdims, atleast1d);
+}
+
+inline Tensor collapse_sum(const Tensor& data, Array<PrimExpr> target_shape) {
+  ICHECK_GE(data->shape.size(), target_shape.size());
+  auto ishape = detail::GetConstIntValues(data->shape, "ishape");
+  auto oshape = detail::GetConstIntValues(target_shape, "oshape");
+
+  std::vector<int> reduce_axes;
+  std::vector<int> squeeze_axes;
+  for (int i_ax = ishape.size() - 1, o_ax = oshape.size() - 1; i_ax >= 0; --i_ax) {
+    if (o_ax >= 0 && ishape[i_ax] == oshape[o_ax]) {
+      --o_ax;
+      continue;
+    }
+    reduce_axes.push_back(i_ax);
+    if (o_ax < 0) {  // squeeze o_ax if was added during expansion
+      squeeze_axes.push_back(i_ax);
+    } else if (oshape[o_ax] == 1) {
+      --o_ax;
+    }
+  }
+
+  if (reduce_axes.size() == 0) return topi::identity(data, "tensor", kCommReduce);
+
+  std::reverse(reduce_axes.begin(), reduce_axes.end());
+  std::reverse(squeeze_axes.begin(), squeeze_axes.end());
+  return DoCommReduce(data, tvm::sum, target_shape, reduce_axes, squeeze_axes);
+}
+
+/*!
+ * \brief Creates an operation that computes the logical AND of elements
+ * over a given axis
+ *
+ * \param data The input boolean tensor
+ * \param axis The axes to reduce. If axis is empty, the operation will
+ * perform logical AND over all elements of the array.
+ * \param keepdims If this is set to true, the axes which are reduced are
+ * left in the result as dimensions with size one. This enables the result
+ * to broadcast correctly against the input array.
+ * \param atleast1d Whether the output need to be atleast1d.
+ *
+ * \return A Tensor whose op member is the all operation
+ */
+inline Tensor all(const Tensor& data, const Array<Integer>& axis, bool keepdims = false,
+                  bool atleast1d = false) {
+  return CommReduce(data, axis, tvm::all, keepdims, atleast1d);
+}
+
+/*!
+ * \brief Creates an operation that computes the logical OR of elements
+ * over a given axis
+ *
+ * \param data The input boolean tensor
+ * \param axis The axes to reduce. If axis is empty, the operation will
+ * perform logical OR over all elements of the array.
+ * \param keepdims If this is set to true, the axes which are reduced are
+ * left in the result as dimensions with size one. This enables the result
+ * to broadcast correctly against the input array.
+ * \param atleast1d Whether the output need to be atleast1d.
+ *
+ * \return A Tensor whose op member is the all operation
+ */
+inline Tensor any(const Tensor& data, const Array<Integer>& axis, bool keepdims = false,
+                  bool atleast1d = false) {
+  return CommReduce(data, axis, tvm::any, keepdims, atleast1d);
+}
+
+/*!
+ * \brief Creates an operation that finds the minimum of elements over
+ * a given axis.
+ *
+ * \param data The input tensor
+ * \param axis The axis to find the minimum over. If axis is empty, the
+ * operation will find the minimum over all elements of the array.
+ * \param keepdims If this is set to true, the axes which are reduced are
+ * left in the result as dimensions with size one. This enables the result
+ * to broadcast correctly against the input array.
+ * \param atleast1d Whether the output need to be atleast1d.
+ *
+ * \return A Tensor whose op member is the min operation
+ */
+inline Tensor min(const Tensor& data, const Array<Integer>& axis, bool keepdims = false,
+                  bool atleast1d = false) {
+  return CommReduce(data, axis, MinOp, keepdims, atleast1d);
+}
+
+/*!
+ * \brief Creates an operation that finds the maximum of elements over
+ * a given axis.
+ *
+ * \param data The input tensor
+ * \param axis The axis to find the maximum over. If axis is empty, the
+ * operation will find the maximum over all elements of the array.
+ * \param keepdims If this is set to true, the axes which are reduced are
+ * left in the result as dimensions with size one. This enables the result
+ * to broadcast correctly against the input array.
+ * \param atleast1d Whether the output need to be atleast1d.
+ *
+ * \return A Tensor whose op member is the max operation
+ */
+inline Tensor max(const Tensor& data, const Array<Integer>& axis, bool keepdims = false,
+                  bool atleast1d = false) {
+  return CommReduce(data, axis, MaxOp, keepdims, atleast1d);
+}
+
+inline FCommReduce MakeArgminReducer(bool select_last_index = false) {
+  // Create a Commutative Reducer with a comparison operation, and method to get the initial value.
+  auto fcombine = [=](Array<Var> lhs, Array<Var> rhs) {
+    Array<PrimExpr> result;
+
+    // Casting to avoid operator ambiguity
+    PrimExpr lhs_idx = static_cast<PrimExpr>(lhs[0]);
+    PrimExpr rhs_idx = static_cast<PrimExpr>(rhs[0]);
+    PrimExpr lhs_val = static_cast<PrimExpr>(lhs[1]);
+    PrimExpr rhs_val = static_cast<PrimExpr>(rhs[1]);
+
+    // These variables compare the actual values of the array
+    auto is_smaller = lhs_val < rhs_val;
+    auto is_same = lhs_val == rhs_val;
+
+    // This checks if the indices are correct for the reduction. E.g. for select_last_index
+    // it gives precedence for later indices of the same element and precedence for sooner
+    // indices if not select_last_index;
+    PrimExpr proper_index;
+    if (select_last_index) {
+      proper_index = lhs_idx > rhs_idx;
+    } else {
+      proper_index = lhs_idx < rhs_idx;
+    }
+
+    PrimExpr update_index = is_smaller || (is_same && proper_index);
+    result.push_back(tvm::tir::Select(update_index, lhs[0], rhs[0]));  // idx
+    result.push_back(tvm::tir::Select(is_smaller, lhs[1], rhs[1]));    // val
+    return result;
+  };
+  auto fidentity = [&](std::vector<DataType> types) {
+    Array<PrimExpr> result;
+    result.push_back(tvm::tir::make_const(types[0], -1));  // idx
+    result.push_back(tvm::max_value(types[1]));            // val
+    return result;
+  };
+  return MakeCommReducer(fcombine, fidentity, "argmin");
+}
+
+/*!
+ * \brief Creates an operation that finds the indices of the minimum
+ * values over a given axis.
+ *
+ * \param data The input tensor
+ * \param axis The axis along which the argmin is performed. If axis is empty,
+ * the operation will find the minimum index over all elements of the array.
+ * \param keepdims If this is set to true, the axes which are reduced are
+ * left in the result as dimensions with size one. This enables the result
+ * to broadcast correctly against the input array.
+ * \param atleast1d Whether the output need to be atleast1d.
+ * \param select_last_index Whether to select the last index if the minimum element
+ * appears multiple times, else select the first index.
+ *
+ * \return A Tensor whose op member is the argmin operation
+ */
+inline Tensor argmin(const Tensor& data, const Array<Integer>& axis, bool keepdims = false,
+                     bool atleast1d = false, bool select_last_index = false) {
+  auto reducer = MakeArgminReducer(select_last_index);
+  return CommReduceIdx(data, axis, reducer, keepdims, atleast1d);
+}
+
+inline FCommReduce MakeArgmaxReducer(bool select_last_index = false) {
+  // Create a Commutative Reducer with a comparison operation, and method to get the initial value.
+  auto fcombine = [=](Array<Var> lhs, Array<Var> rhs) {
+    Array<PrimExpr> result;
+
+    // Casting to avoid operator ambiguity
+    PrimExpr lhs_idx = static_cast<PrimExpr>(lhs[0]);
+    PrimExpr rhs_idx = static_cast<PrimExpr>(rhs[0]);
+    PrimExpr lhs_val = static_cast<PrimExpr>(lhs[1]);
+    PrimExpr rhs_val = static_cast<PrimExpr>(rhs[1]);
+
+    // These variables compare the actual values of the array
+    auto is_bigger = lhs_val > rhs_val;
+    auto is_same = lhs_val == rhs_val;
+
+    // This checks if the indices are correct for the reduction. E.g. for select_last_index
+    // it gives precedence for later indices of the same element and precedence for sooner
+    // indices if not select_last_index;
+    PrimExpr proper_index;
+    if (select_last_index) {
+      proper_index = lhs_idx > rhs_idx;
+    } else {
+      proper_index = lhs_idx < rhs_idx;
+    }
+
+    PrimExpr update_index = is_bigger || (is_same && proper_index);
+    result.push_back(tvm::tir::Select(update_index, lhs[0], rhs[0]));  // idx
+    result.push_back(tvm::tir::Select(is_bigger, lhs[1], rhs[1]));     // val
+    return result;
+  };
+  auto fidentity = [&](std::vector<DataType> types) {
+    Array<PrimExpr> result;
+    result.push_back(tvm::tir::make_const(types[0], -1));  // idx
+    result.push_back(tvm::min_value(types[1]));            // val
+    return result;
+  };
+  return MakeCommReducer(fcombine, fidentity, "argmax");
+}
+
+/*!
+ * \brief Creates an operation that finds the indices of the maximum
+ * values over a given axis.
+ *
+ * \param data The input tensor
+ * \param axis The axis along which the argmax is performed. If axis is empty,
+ * the operation will find the maximum index over all elements of the array.
+ * \param keepdims If this is set to true, the axes which are reduced are
+ * left in the result as dimensions with size one. This enables the result
+ * to broadcast correctly against the input array.
+ * \param atleast1d Whether the output need to be atleast1d.
+ * \param select_last_index Whether to select the last index if the maximum element
+ * appears multiple times, else select the first index.
+ * \return A Tensor whose op member is the argmax operation
+ */
+inline Tensor argmax(const Tensor& data, const Array<Integer>& axis, bool keepdims = false,
+                     bool atleast1d = false, bool select_last_index = false) {
+  auto reducer = MakeArgmaxReducer(select_last_index);
+  return CommReduceIdx(data, axis, reducer, keepdims, atleast1d);
+}
+
+/*!
+ * \brief Creates product operation over given axis.
+ *
+ * \param data The input tensor
+ * \param axis The axis to do product over. If axis is empty, the
+ * operation will do the product over all elements of the array.
+ * \param keepdims If this is set to true, the axes which are reduced are
+ * left in the result as dimensions with size one. This enables the result
+ * to broadcast correctly against the input array.
+ * \param atleast1d Whether the output need to be atleast1d.
+ *
+ * \return A Tensor whose op member is the prod operation
+ */
+inline Tensor prod(const Tensor& data, const Array<Integer>& axis, bool keepdims = false,
+                   bool atleast1d = false) {
+  return CommReduce(data, axis, ProdOp, keepdims, atleast1d);
+}
+
+/*!
+ * \brief Create communitive reducer summing over tuples
+ */
+inline FCommReduce MakeTupleSumReducer() {
+  auto fcombine = [](Array<Var> lhs, Array<Var> rhs) {
+    Array<PrimExpr> result;
+    ICHECK_EQ(lhs.size(), rhs.size());
+    result.reserve(lhs.size());
+    for (size_t i = 0; i < lhs.size(); ++i) {
+      result.push_back(lhs[i] + rhs[i]);
+    }
+    return result;
+  };
+  auto fidentity = [](std::vector<DataType> types) {
+    Array<PrimExpr> result;
+    for (size_t i = 0; i < types.size(); ++i) {
+      result.push_back(tvm::tir::make_const(types[i], 0));
+    }
+    return result;
+  };
+  return MakeCommReducer(fcombine, fidentity, "tuple_sum");
+}
+
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_REDUCTION_H_
diff --git a/darknet_drp_ros/include/tvm/topi/rocm/dense.h b/darknet_drp_ros/include/tvm/topi/rocm/dense.h
new file mode 100644
index 0000000..b861e6c
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/rocm/dense.h
@@ -0,0 +1,99 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file rocm/dense.h
+ * \brief rocm schedule for dense operation
+ */
+#ifndef TVM_TOPI_ROCM_DENSE_H_
+#define TVM_TOPI_ROCM_DENSE_H_
+
+#include <tvm/target/generic_func.h>
+#include <tvm/te/operation.h>
+#include <tvm/topi/contrib/rocblas.h>
+#include <tvm/topi/cuda/dense.h>
+#include <tvm/topi/detail/array_utils.h>
+#include <tvm/topi/generic/extern.h>
+#include <tvm/topi/nn/dense.h>
+#include <tvm/topi/tags.h>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+
+namespace rocm {
+/*!
+ * \brief Implementation of dense for rocm backend
+ *
+ * \param target The target device
+ * \param data Tensor with shape [batch, in_dim]
+ * \param weight Tensor with shape [out_dim, in_dim]
+ * \param bias Tensor with shape [out_dim]. Optional; to omit bias, pass Tensor()
+ * \param out_dtype Output data type. Used for mixed precision.
+ *
+ * \return Tensor with shape [batch, out_dim]
+ */
+inline tvm::te::Tensor dense_rocm(const Target& target, const tvm::te::Tensor& data,
+                                  const tvm::te::Tensor& weight, const tvm::te::Tensor& bias,
+                                  const DataType& out_dtype) {
+  ICHECK_EQ(data->shape.size(), 2) << "dense requires 2-D data";
+  ICHECK_EQ(weight->shape.size(), 2) << "dense requires 2-D weight";
+  if (bias.defined()) {
+    ICHECK_EQ(bias->shape.size(), 1) << "dense requires 1-D bias";
+  }
+
+  auto batch = data->shape[0];
+  auto in_dim = data->shape[1];
+  auto out_dim = weight->shape[0];
+
+  if (target->GetLibs().count("rocblas")) {
+    ICHECK_EQ(data->dtype, out_dtype) << "Mixed precision not supported.";
+    auto mm = topi::contrib::rocblas_matmul(data, weight, false, true);
+    if (bias.defined()) {
+      mm = tvm::te::compute(
+          {batch, out_dim}, [&](Var i, Var j) { return mm(i, j) + bias(j); }, "tensor", kBroadcast);
+    }
+
+    return mm;
+  } else {
+    return topi::nn::dense(data, weight, bias, out_dtype);
+  }
+}
+
+/*!
+ * \brief Create a rocm schedule for dense
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+inline Schedule schedule_dense(const Target& target, const Array<Tensor>& outs) {
+  if (target->kind->name == "rocm" && target->GetLibs().count("rocblas")) {
+    return topi::generic::schedule_extern(target, outs);
+  }
+
+  return topi::cuda::schedule_dense(target, outs);
+}
+
+}  // namespace rocm
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_ROCM_DENSE_H_
diff --git a/darknet_drp_ros/include/tvm/topi/rocm/injective.h b/darknet_drp_ros/include/tvm/topi/rocm/injective.h
new file mode 100644
index 0000000..295d930
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/rocm/injective.h
@@ -0,0 +1,67 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file rocm/injective.h
+ * \brief rocm schedule for injective operations
+ */
+#ifndef TVM_TOPI_ROCM_INJECTIVE_H_
+#define TVM_TOPI_ROCM_INJECTIVE_H_
+
+#include <tvm/target/generic_func.h>
+#include <tvm/te/operation.h>
+#include <tvm/topi/cuda/injective.h>
+#include <tvm/topi/detail/fuse.h>
+#include <tvm/topi/tags.h>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+
+namespace rocm {
+
+/*!
+ * \brief Updates an existing schedule for the given injective ops.
+ *
+ * \param sch The schedule to update.
+ * \param out The tensor representing the injective op.
+ *
+ * \return The updated schedule.
+ */
+inline Schedule schedule_injective_from_existing(Schedule sch, const Tensor& out) {
+  return topi::cuda::schedule_injective_from_existing(sch, out);
+}
+
+/*!
+ * \brief Create a rocm schedule for the given output tensors.
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+inline Schedule schedule_injective(const Target& target, const Array<Tensor>& outs) {
+  return topi::cuda::schedule_injective(target, outs);
+}
+
+}  // namespace rocm
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_ROCM_INJECTIVE_H_
diff --git a/darknet_drp_ros/include/tvm/topi/rocm/pooling.h b/darknet_drp_ros/include/tvm/topi/rocm/pooling.h
new file mode 100644
index 0000000..993c32b
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/rocm/pooling.h
@@ -0,0 +1,68 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file rocm/pooling.h
+ * \brief rocm schedule for pooling operations
+ */
+#ifndef TVM_TOPI_ROCM_POOLING_H_
+#define TVM_TOPI_ROCM_POOLING_H_
+
+#include <tvm/target/generic_func.h>
+#include <tvm/te/operation.h>
+#include <tvm/topi/cuda/pooling.h>
+#include <tvm/topi/detail/array_utils.h>
+#include <tvm/topi/detail/fuse.h>
+#include <tvm/topi/tags.h>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+
+namespace rocm {
+
+/*!
+ * \brief Create a rocm schedule for pool
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+inline Schedule schedule_pool(const Target& target, const Array<Tensor>& outs) {
+  return topi::cuda::schedule_pool(target, outs);
+}
+
+/*!
+ * \brief Create a rocm schedule for global_pool
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+inline Schedule schedule_global_pool(const Target& target, const Array<Tensor>& outs) {
+  return topi::cuda::schedule_global_pool(target, outs);
+}
+
+}  // namespace rocm
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_ROCM_POOLING_H_
diff --git a/darknet_drp_ros/include/tvm/topi/rocm/reduction.h b/darknet_drp_ros/include/tvm/topi/rocm/reduction.h
new file mode 100644
index 0000000..7beda17
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/rocm/reduction.h
@@ -0,0 +1,54 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file rocm/reduction.h
+ * \brief rocm schedule for reduction operations
+ */
+#ifndef TVM_TOPI_ROCM_REDUCTION_H_
+#define TVM_TOPI_ROCM_REDUCTION_H_
+
+#include <tvm/target/generic_func.h>
+#include <tvm/te/operation.h>
+#include <tvm/topi/cuda/reduction.h>
+#include <tvm/topi/detail/fuse.h>
+#include <tvm/topi/tags.h>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+
+namespace rocm {
+/*!
+ * \brief Create a rocm schedule for a reduce operation.
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+Schedule schedule_reduce(const Target& target, Array<Tensor> outs) {
+  return topi::cuda::schedule_reduce(target, outs);
+}
+
+}  // namespace rocm
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_ROCM_REDUCTION_H_
diff --git a/darknet_drp_ros/include/tvm/topi/rocm/softmax.h b/darknet_drp_ros/include/tvm/topi/rocm/softmax.h
new file mode 100644
index 0000000..a2ffd2c
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/rocm/softmax.h
@@ -0,0 +1,55 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file rocm/injective.h
+ * \brief ROCM schedule for injective operations
+ */
+#ifndef TVM_TOPI_ROCM_SOFTMAX_H_
+#define TVM_TOPI_ROCM_SOFTMAX_H_
+
+#include <tvm/target/generic_func.h>
+#include <tvm/te/operation.h>
+#include <tvm/topi/cuda/softmax.h>
+#include <tvm/topi/detail/fuse.h>
+#include <tvm/topi/tags.h>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+
+namespace rocm {
+
+/*!
+ * \brief Create a rocm schedule for the given softmax output tensors.
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+inline Schedule schedule_softmax(const Target& target, const Array<Tensor>& outs) {
+  return topi::cuda::schedule_softmax(target, outs);
+}
+
+}  // namespace rocm
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_ROCM_SOFTMAX_H_
diff --git a/darknet_drp_ros/include/tvm/topi/tags.h b/darknet_drp_ros/include/tvm/topi/tags.h
new file mode 100644
index 0000000..c3641ae
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/tags.h
@@ -0,0 +1,59 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \brief Tag definitions
+ * \file tags.h
+ */
+#ifndef TVM_TOPI_TAGS_H_
+#define TVM_TOPI_TAGS_H_
+
+#include <string>
+
+namespace tvm {
+namespace topi {
+
+constexpr auto kElementWise = "elemwise";
+constexpr auto kInjective = "injective";
+constexpr auto kCommReduce = "comm_reduce";
+constexpr auto kCommReduceIdx = "comm_reduce_idx";
+constexpr auto kBroadcast = "broadcast";
+constexpr auto kMatMul = "matmul";
+constexpr auto kConv2dNCHW = "conv2d_nchw";
+constexpr auto kConv2dHWCN = "conv2d_hwcn";
+constexpr auto kDepthwiseConv2dNCHW = "depthwise_conv2d_nchw";
+constexpr auto kDepthwiseConv2dNHWC = "depthwise_conv2d_nhwc";
+constexpr auto kDepthwiseConv2dBackInputNHWC = "depthwise_conv2d_back_input_nhwc";
+constexpr auto kDepthwiseConv2dBackWeightNHWC = "depthwise_conv2d_back_weight_nhwc";
+constexpr auto kEinsum = "einsum";
+constexpr auto kGroupConv2d = "group_conv2d";
+
+inline bool is_broadcast(std::string tag) {
+  return tag.rfind(kElementWise, 0) == 0 || tag.rfind(kBroadcast, 0) == 0;
+}
+
+inline bool is_injective(std::string tag) {
+  return tag.rfind(kElementWise, 0) == 0 || tag.rfind(kBroadcast, 0) == 0 ||
+         tag.rfind(kInjective, 0) == 0;
+}
+
+}  // namespace topi
+}  // namespace tvm
+
+#endif  // TVM_TOPI_TAGS_H_
diff --git a/darknet_drp_ros/include/tvm/topi/transform.h b/darknet_drp_ros/include/tvm/topi/transform.h
new file mode 100644
index 0000000..4c96ed4
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/transform.h
@@ -0,0 +1,2021 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file topi/transform.h
+ * \brief Transform op constructors
+ */
+#ifndef TVM_TOPI_TRANSFORM_H_
+#define TVM_TOPI_TRANSFORM_H_
+
+#include <tvm/te/operation.h>
+#include <tvm/tir/data_layout.h>
+#include <tvm/tir/index_map.h>
+#include <tvm/topi/broadcast.h>
+#include <tvm/topi/detail/broadcast.h>
+#include <tvm/topi/detail/constant_utils.h>
+#include <tvm/topi/detail/ravel_unravel.h>
+#include <tvm/topi/detail/strided_slice.h>
+#include <tvm/topi/detail/tensor_utils.h>
+#include <tvm/topi/tags.h>
+
+#include <algorithm>
+#include <iterator>
+#include <limits>
+#include <string>
+#include <unordered_set>
+#include <vector>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+using namespace topi::detail;
+
+/*!
+ * \brief Creates an operation to slide a window over the input x.
+ *
+ * \param x The input tensor.
+ * \param axis What axis the window begins sliding over. Window will be slid
+ * over this axis and all following axes. The axis value determines the window
+ * shape (and thus, the number of strides): window shape and strides must both
+ * be of length `data.ndim-axis`.
+ * \param window_shape The window shape to form over the input. Window shape
+ * must be of length `data.ndim-axis`.
+ * \param strides How to stride the window along each dimension. Strides must be
+ * of length `data.ndim-axis`.
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the sliding_window operation
+ */
+inline Tensor sliding_window(const Tensor& x, int axis, Array<Integer> window_shape,
+                             Array<Integer> strides, std::string name = "T_sliding_window",
+                             std::string tag = "") {
+  CHECK_GE(axis, 0);
+  auto _axis = size_t(axis);
+  CHECK_LT(_axis, x->shape.size()) << "axis must be a valid dimension index of x.";
+  CHECK_EQ(x->shape.size() - _axis, window_shape.size())
+      << "There must be a window shape for every dimension of x "
+      << "over which we are sliding the window.";
+  CHECK_EQ(strides.size(), window_shape.size()) << "Windows and strides should be the same length.";
+
+  // Compute the new shape.
+  Array<PrimExpr> new_shape;
+  // Dimensions up until `axis` remain the same.
+  for (size_t i = 0; i < _axis; ++i) {
+    new_shape.push_back(x->shape[i]);
+  }
+
+  // New dimensions which result from sliding the window in each dimension. One new dimension per
+  // window dimension.
+  for (size_t i = 0; i < window_shape.size(); ++i) {
+    // Length of the shape along this dimension.
+    auto dim_len = x->shape[_axis + i];
+    // Length of the window along this dimension.
+    auto window_len = window_shape[i];
+    // Strides along this dimension.
+    auto stride = strides[i];
+
+    new_shape.push_back(floordiv(dim_len - (window_len - 1) + stride - 1, stride));
+  }
+
+  // Dimensions comprising the window.
+  for (size_t i = 0; i < window_shape.size(); ++i) {
+    new_shape.push_back(window_shape[i]);
+  }
+
+  ICHECK(new_shape.size() == _axis + 2 * window_shape.size());
+
+  return compute(
+      new_shape,
+      [&](const Array<Var>& indices) {
+        // The index at which to index the old tensor x.
+        Array<PrimExpr> idx;
+
+        // Dimensions up until `axis` remain the same.
+        for (size_t i = 0; i < _axis; ++i) {
+          idx.push_back(indices[i]);
+        }
+
+        for (size_t i = 0; i < window_shape.size(); ++i) {
+          // Which window in this dimension we are indexing.
+          auto window_idx = indices[_axis + i];
+          // Which index within the window we are indexing.
+          auto idx_within_window = indices[_axis + window_shape.size() + i];
+          // Stride value for this dimension.
+          auto stride = strides[i];
+
+          idx.push_back(window_idx * stride + idx_within_window);
+        }
+
+        ICHECK(idx.size() == x->shape.size());
+
+        return x(idx);
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Creates an operation to insert new dimensions of length 1
+ *
+ * \param x The input tensor
+ * \param axis The index of the first new dimension (allows negative
+ * indices as offsets from the last dimension)
+ * \param num_newaxis The number of new dimensions to insert
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the dim expansion operation
+ */
+inline Tensor expand_dims(const Tensor& x, int axis, int num_newaxis = 1,
+                          std::string name = "T_expand_dims", std::string tag = kBroadcast) {
+  int ndim = static_cast<int>(x->shape.size());
+  ICHECK(-ndim - 1 <= axis && axis <= ndim)
+      << "expand_dims only accepts `axis` in [-data.ndim - 1, data.ndim]"
+      << ", but got axis = " << axis << ", and data.ndim = " << ndim;
+  ICHECK(num_newaxis >= 0) << "expand_dims only accepts `num_newaxis >= 0`"
+                           << ", but got num_newaxis = " << num_newaxis;
+  if (axis < 0) {
+    // Calculate offset from last dimension
+    axis = ndim + axis + 1;
+  }
+  Array<PrimExpr> new_shape;
+  for (size_t i = 0; i < static_cast<size_t>(axis); ++i) {
+    new_shape.push_back(x->shape[i]);
+  }
+  for (size_t i = 0; i < static_cast<size_t>(num_newaxis); ++i) {
+    new_shape.push_back(1);
+  }
+  for (size_t i = axis; i < x->shape.size(); ++i) {
+    new_shape.push_back(x->shape[i]);
+  }
+
+  return compute(
+      new_shape,
+      [&](const Array<Var>& indices) {
+        Array<PrimExpr> idx;
+        for (size_t i = 0; i < static_cast<size_t>(axis); ++i) {
+          idx.push_back(indices[i]);
+        }
+        for (size_t i = axis + num_newaxis; i < indices.size(); ++i) {
+          idx.push_back(indices[i]);
+        }
+        return x(idx);
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Permute the dimensions of an array
+ *
+ * \param x The input tensor
+ * \param axes The indices of the permutation. If this is empty,
+ * the dimensions will be reversed.
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the transpose operation
+ */
+inline Tensor transpose(const Tensor& x, Array<Integer> axes, std::string name = "T_transpose",
+                        std::string tag = kInjective) {
+  if (!axes.defined() || axes.size() == 0) {
+    axes = Array<Integer>();
+    for (int i = static_cast<int>(x->shape.size()) - 1; i >= 0; --i) {
+      axes.push_back(i);
+    }
+  }
+
+  Array<PrimExpr> new_shape;
+  for (size_t i = 0; i < axes.size(); ++i) {
+    int axis = static_cast<int>(axes[i]->value);
+    int new_axis = axis;
+    if (axis < 0) {
+      new_axis = static_cast<int>(x->shape.size()) + axis;
+      axes.Set(i, new_axis);
+    }
+    ICHECK((new_axis >= 0) && (new_axis < static_cast<int>(x->shape.size())))
+        << "axis=" << axis << " is invalid for the " << static_cast<int>(x->shape.size())
+        << "-dimensional input tensor";
+
+    for (size_t j = 0; j < axes.size(); ++j) {
+      if (i != j) {
+        ICHECK(new_axis != static_cast<int>(axes[j]->value)) << "repeated axis in transpose";
+      }
+    }
+    new_shape.push_back(x->shape[new_axis]);
+  }
+
+  return compute(
+      new_shape,
+      [&](const Array<Var>& indices) {
+        std::vector<PrimExpr> idx;
+        for (size_t i = 0; i < axes.size(); ++i) {
+          idx.push_back(1);
+        }
+        for (size_t i = 0; i < axes.size(); ++i) {
+          int axis = static_cast<int>(axes[i]->value);
+          idx[axis] = indices[i];
+        }
+        return x(idx);
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Reverse the tensor for variable length slices.
+ * Input is first sliced along batch axis and then elements are reversed along seq axis.
+ *
+ * \param x The input tensor
+ * \param seq_lengths A 1D Tensor with length x.dims[batch_axis]. Optional Tensor() can be passed.
+ * If not defined batch axis is ignored and tensor is reversed along seq_axis.
+ * \param seq_axis The axis along which the elements will be reveresed
+ * \param batch_axis The axis along which the tensor will be sliced
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the reverse_sequence operation
+ */
+inline Tensor reverse_sequence(const Tensor& x, const Tensor& seq_lengths, int seq_axis = 1,
+                               int batch_axis = 0, std::string name = "T_reverse_sequence",
+                               std::string tag = kInjective) {
+  size_t src_tensor_dim = x->shape.size();
+  int seq_axis_inp = seq_axis;
+
+  if (seq_lengths.defined()) {
+    size_t seq_lengths_dim = seq_lengths->shape.size();
+    int batch_axis_inp = batch_axis;
+    if (batch_axis < 0) {
+      batch_axis = static_cast<int>(x->shape.size()) + batch_axis;
+    }
+
+    ICHECK(seq_lengths_dim == 1) << "seq_lengths should be 1D vector";
+
+    ICHECK(GetConstInt(seq_lengths->shape[0]) == GetConstInt(x->shape[batch_axis]))
+        << "For reverse_sequnece seq_lengths size should match with dimension of batch axis"
+        << ", but got dimension of batch_axis = " << GetConstInt(x->shape[batch_axis])
+        << ", and seq_length size = " << GetConstInt(seq_lengths->shape[0]);
+
+    ICHECK((0 <= batch_axis) && (batch_axis < static_cast<int>(x->shape.size())))
+        << "batch_axis=" << batch_axis_inp << " is invalid for the "
+        << static_cast<int>(x->shape.size()) << "-dimensional input tensor";
+  }
+
+  if (seq_axis < 0) {
+    seq_axis = static_cast<int>(x->shape.size()) + seq_axis;
+  }
+  ICHECK((0 <= seq_axis) && (seq_axis < static_cast<int>(x->shape.size())))
+      << "seq_axis=" << seq_axis_inp << " is invalid for the " << static_cast<int>(x->shape.size())
+      << "-dimensional input tensor";
+
+  auto func = [&](const Array<Var>& indices) {
+    Array<PrimExpr> real_indices;
+    for (size_t i = 0; i < src_tensor_dim; ++i) {
+      if (i == static_cast<size_t>(seq_axis)) {
+        if (seq_lengths.defined()) {
+          auto len = seq_lengths(indices[batch_axis]);
+          auto idx = if_then_else(
+              len <= 1 || len <= indices[i], indices[i],
+              if_then_else(len > x->shape[i], x->shape[i] - 1 - indices[i], len - 1 - indices[i]));
+          real_indices.push_back(idx);
+        } else {
+          real_indices.push_back(x->shape[i] - 1 - indices[i]);
+        }
+      } else {
+        real_indices.push_back(indices[i]);
+      }
+    }
+    return x(real_indices);
+  };
+
+  return compute(x->shape, func, name, tag);
+}
+
+/*!
+ * \brief Reshape a tensor
+ *
+ * \param x The input tensor
+ * \param newshape The new shape
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the reshape operation
+ */
+inline Tensor reshape(const Tensor& x, Array<PrimExpr> newshape, std::string name = "T_reshape",
+                      std::string tag = kInjective) {
+  auto x_shape = x->shape;
+  Array<PrimExpr> target_shape;
+
+  for (const auto& ele : newshape) {
+    if (ele.as<IntImmNode>()) {
+      target_shape.push_back(cast(DataType::Int(32), ele));
+    } else {
+      target_shape.push_back(ele);
+    }
+  }
+
+  // If either the input shape or the target shape contains a zero, return an empty tensor.
+  if (is_empty_shape(target_shape) || is_empty_shape(x->shape)) {
+    return compute(
+        target_shape, [&](const Array<Var>& indices) { return tvm::cast(x->dtype, 0); }, name, tag);
+  } else {
+    return compute(
+        target_shape,
+        [&](const Array<Var>& indices) {
+          return x(UnravelIndex(
+              RavelIndex(Array<PrimExpr>{indices.begin(), indices.end()}, target_shape), x_shape));
+        },
+        name, tag);
+  }
+}
+
+/*!
+ * \brief Converts a flat index or array of flat indices into a tuple of coordinate arrays
+ *
+ * \param x The input tensor having indices.
+ * \param shape The shape tensor
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor of coordinate arrays.
+ */
+
+inline Tensor unravel_index(const Tensor& x, const Tensor& shape, std::string name = "T_unravel",
+                            std::string tag = kInjective) {
+  auto x_shape = x->shape;
+  auto shape_shape = shape->shape;
+
+  Array<PrimExpr> oshape;
+  oshape.push_back(shape_shape[0]);
+  if (x_shape.size() != 0) {
+    oshape.push_back(x_shape[0]);
+  }
+
+  auto func = [&](const Array<Var>& indices) {
+    auto i = indices[0];
+    std::vector<PrimExpr> indices_divs;
+    PrimExpr ret = 0;
+    PrimExpr cur_val = 0;
+    PrimExpr index_val = 0;
+
+    if (x_shape.size() != 0) {
+      index_val = x[indices[1]];
+    } else {
+      index_val = x();
+    }
+    indices_divs.push_back(index_val);
+    for (int v = GetConstInt(shape_shape[0]) - 1; v >= 0; --v) {
+      ret = tvm::if_then_else(i == v, indexmod(indices_divs.back(), shape[v]), ret);
+      cur_val = indexdiv(indices_divs.back(), shape[v]);
+      indices_divs.push_back(cur_val);
+    }
+    return ret;
+  };
+
+  return compute(oshape, func, name, tag);
+}
+
+/*!
+ * \brief Remove size 1 dimensions from the shape of a tensor.
+ * The removed dimensions must have a constant size of 1.
+ *
+ * \param x The input tensor
+ * \param axis Indices of the dimensions to remove. If this is None,
+ * all entries with a constant size of 1 will be removed.
+ * \param atleast1d Whether the output need to be atleast1d.
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the squeeze operation
+ */
+inline Tensor squeeze(const Tensor& x, Array<Integer> axis, bool atleast1d = false,
+                      std::string name = "T_squeeze", std::string tag = kInjective) {
+  auto ndim = x->shape.size();
+  std::vector<int> axis_val;
+  if (!axis.defined()) {
+    for (size_t i = 0; i < ndim; ++i) {
+      if (IsConstInt(x->shape[i]) && GetConstInt(x->shape[i]) == 1) {
+        axis_val.push_back(static_cast<int>(i));
+      }
+    }
+  } else {
+    for (size_t i = 0; i < axis.size(); ++i) {
+      int64_t val = axis[i]->value;
+      if (val < 0) {
+        val += static_cast<int>(x->shape.size());
+      }
+      if (IsConstInt(x->shape[val])) {
+        ICHECK_EQ(GetConstInt(x->shape[val]), 1) << "Dimension " << val << " must have size 1";
+      }
+      axis_val.push_back(val);
+    }
+  }
+
+  std::unordered_set<int> axis_set(axis_val.begin(), axis_val.end());
+
+  Array<PrimExpr> out_shape;
+  for (size_t i = 0; i < ndim; ++i) {
+    if (axis_set.count(static_cast<int>(i)) == 0) {
+      out_shape.push_back(x->shape[i]);
+    }
+  }
+  if (out_shape.size() == 0 && atleast1d) {
+    out_shape.push_back(1);
+  }
+
+  return compute(
+      out_shape,
+      [&](const Array<Var>& indices) {
+        Array<PrimExpr> real_indices;
+        int flag = 0;
+        for (size_t i = 0; i < ndim; ++i) {
+          if (axis_set.count(static_cast<int>(i)) == 0) {
+            real_indices.push_back(indices[i - flag]);
+          } else {
+            real_indices.push_back(0);
+            flag += 1;
+          }
+        }
+        return x(real_indices);
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Join a sequence of tensors along an existing axis
+ *
+ * \param inputs The input tensors
+ * \param axis The axis along which the tensors will be joined
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the concatenate operation
+ */
+inline Tensor concatenate(const Array<Tensor>& inputs, int axis = 0, std::string name = "T_concat",
+                          std::string tag = kInjective) {
+  int ndim = static_cast<int>(inputs[0]->shape.size());
+  ICHECK(-ndim <= axis && axis < ndim) << "concatenate only accepts `axis` in [-ndim, ndim)"
+                                       << ", but got axis = " << axis << ", and ndim = " << ndim;
+  if (axis < 0) {
+    axis += ndim;
+  }
+  ICHECK_LT(axis, inputs[0]->shape.size()) << "axis out of bounds";
+
+  Array<PrimExpr> axis_sizes;
+  for (auto t : inputs) {
+    axis_sizes.push_back(t->shape[axis]);
+  }
+  arith::Analyzer analyzer;
+  PrimExpr join_size = axis_sizes[0];
+  for (size_t i = 1; i < axis_sizes.size(); ++i) {
+    join_size += axis_sizes[i];
+  }
+  join_size = analyzer.Simplify(join_size);
+  Array<PrimExpr> out_shape;
+  for (size_t i = 0; i < inputs[0]->shape.size(); ++i) {
+    out_shape.push_back(i == static_cast<size_t>(axis) ? join_size : inputs[0]->shape[i]);
+  }
+
+  return compute(
+      out_shape,
+      [&](const Array<Var>& indices) {
+        auto ret = inputs[0](indices);
+        auto ind = indices[axis];
+        for (size_t i = 0; i < inputs.size() - 1; ++i) {
+          ind -= axis_sizes[i];
+
+          Array<PrimExpr> idx;
+          for (size_t i = 0; i < static_cast<size_t>(axis); ++i) {
+            idx.push_back(indices[i]);
+          }
+          idx.push_back(ind);
+          for (size_t i = axis + 1; i < indices.size(); ++i) {
+            idx.push_back(indices[i]);
+          }
+
+          ret = tvm::if_then_else(ind >= 0, inputs[i + 1](idx), ret);
+        }
+        return ret;
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Join a sequence of tensors along a new axis.
+ *
+ * \param inputs The input tensors
+ * \param axis The axis along which the tensors will be stacked
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the stack operation
+ */
+inline Tensor stack(const Array<Tensor>& inputs, int axis = 0, std::string name = "T_stack",
+                    std::string tag = kInjective) {
+  int ndim = static_cast<int>(inputs[0]->shape.size());
+  ICHECK(-ndim - 1 <= axis && axis <= ndim)
+      << "stack only accepts `axis` in [-ndim, ndim)"
+      << ", but got axis = " << axis << ", and ndim = " << ndim;
+  if (axis < 0) {
+    axis += ndim + 1;
+  }
+  ICHECK_LT(axis, inputs[0]->shape.size() + 1) << "axis out of bounds";
+
+  const int stack_size = static_cast<int>(inputs.size());
+  Array<PrimExpr> out_shape;
+  for (size_t i = 0; i < static_cast<size_t>(axis); ++i) out_shape.push_back(inputs[0]->shape[i]);
+  out_shape.push_back(stack_size);
+  for (size_t i = static_cast<size_t>(axis); i < static_cast<size_t>(ndim); ++i)
+    out_shape.push_back(inputs[0]->shape[i]);
+
+  return compute(
+      out_shape,
+      [&](const Array<Var>& indices) {
+        Array<PrimExpr> idx;
+        for (size_t i = 0; i < indices.size(); ++i)
+          if (i != static_cast<size_t>(axis)) idx.push_back(indices[i]);
+        auto ind = indices[axis];
+        auto ret = inputs[0](idx);
+        for (int i = 0; i < static_cast<int>(inputs.size() - 1); ++i) {
+          ret = tvm::if_then_else(ind == i + 1, inputs[i + 1](idx), ret);
+        }
+        return ret;
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Split a tensor into multiple sub-tensors
+ *
+ * \param x The input tensor
+ * \param split_indices The indices to split the input at. This must be in ascending
+ * order.
+ * \param axis The axis to split along.
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the split operation
+ */
+inline Array<Tensor> split(const Tensor& x, Array<PrimExpr> split_indices, int axis,
+                           std::string name = "T_split", std::string tag = kInjective) {
+  if (axis < 0) {
+    axis += static_cast<int>(x->shape.size());
+  }
+  ICHECK_LT(axis, x->shape.size()) << "axis out of bounds";
+
+  auto src_axis_size = x->shape[axis];
+  std::vector<PrimExpr> begin_ids;
+  begin_ids.push_back(0);
+
+  for (auto idx : split_indices) {
+    auto idx_node = idx.as<IntImmNode>();
+    auto back_node = begin_ids.back().as<IntImmNode>();
+    if (idx_node && back_node) {
+      ICHECK_GT(idx_node->value, back_node->value) << "split_indices must be sorted";
+    }
+    begin_ids.push_back(idx);
+  }
+
+  Array<Array<PrimExpr>> out_shapes;
+  for (size_t i = 0; i < begin_ids.size(); ++i) {
+    PrimExpr out_axis_size;
+    if (i == begin_ids.size() - 1) {
+      out_axis_size = src_axis_size - begin_ids[i];
+    } else {
+      out_axis_size = begin_ids[i + 1] - begin_ids[i];
+    }
+
+    Array<PrimExpr> shape;
+    for (size_t i = 0; i < static_cast<size_t>(axis); ++i) {
+      shape.push_back(x->shape[i]);
+    }
+    shape.push_back(out_axis_size);
+    for (size_t i = axis + 1; i < x->shape.size(); ++i) {
+      shape.push_back(x->shape[i]);
+    }
+
+    out_shapes.push_back(shape);
+  }
+
+  Array<Tensor> result;
+  for (size_t i = 0; i < begin_ids.size(); ++i) {
+    result.push_back(compute(
+        out_shapes[i],
+        [&](const Array<Var>& indices) {
+          auto begin = begin_ids[i];
+          Array<PrimExpr> real_indices;
+          for (size_t j = 0; j < static_cast<size_t>(axis); ++j) {
+            real_indices.push_back(indices[j]);
+          }
+          real_indices.push_back(indices[axis] + begin);
+          for (size_t j = axis + 1; j < indices.size(); ++j) {
+            real_indices.push_back(indices[j]);
+          }
+
+          return x(real_indices);
+        },
+        name, tag));
+  }
+
+  return result;
+}
+
+/*!
+ * \brief strided_slice of a tensor where begin/end/stride can be mixed static and dynamic
+ *
+ * \param x The input tensor
+ * \param begin The indices to begin with in the slicing
+ * \param end Indices indicating end of the slice
+ * \param strides Specifies the stride values, it can be negative
+ * in that case, the input tensor will be reversed in that particular axis
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the dynamic_strided_slice operation
+ */
+inline Tensor dynamic_strided_slice(const Tensor& x, const Array<PrimExpr>& begin,
+                                    const Array<PrimExpr>& end, const Array<PrimExpr>& strides,
+                                    std::string name = "T_dynamic_strided_slice",
+                                    std::string tag = kInjective) {
+  const size_t src_tensor_dim = x->shape.size();
+  ICHECK_LE(begin.size(), src_tensor_dim);
+  ICHECK_LE(end.size(), src_tensor_dim);
+  ICHECK_LE(strides.size(), src_tensor_dim);
+  ICHECK_EQ(begin.size(), end.size());
+  ICHECK_EQ(begin.size(), strides.size());
+
+  const size_t num_slice_axes = begin.size();
+  Array<PrimExpr> out_shape;
+
+  for (size_t i = 0; i < num_slice_axes; ++i) {
+    auto d = indexdiv(end[i] - begin[i], strides[i]);
+    if (d->IsInstance<tvm::IntImmNode>()) {
+      // Preserve static dimension if possible
+      out_shape.push_back(d);
+    } else {
+      out_shape.push_back(tvm::tir::Var("dim"));
+    }
+  }
+
+  for (size_t i = num_slice_axes; i < src_tensor_dim; ++i) {
+    out_shape.push_back(x->shape[i]);
+  }
+
+  return te::compute(
+      out_shape,
+      [&](const Array<tvm::tir::Var>& indices) {
+        Array<PrimExpr> real_indices;
+        for (size_t i = 0; i < num_slice_axes; ++i) {
+          real_indices.push_back(indices[i] * strides[i] + tvm::min(begin[i], x->shape[i] - 1));
+        }
+        // keep input dim
+        for (size_t i = num_slice_axes; i < src_tensor_dim; ++i) {
+          real_indices.push_back(indices[i]);
+        }
+        return x(real_indices);
+      },
+      name, tag);
+}
+
+/*!
+ * \brief strided_slice of a tensor with dynamic begin/end/stride
+ *
+ * \param x The input tensor
+ * \param begin The indices to begin with in the slicing
+ * \param end Indices indicating end of the slice
+ * \param strides Specifies the stride values, it can be negative
+ * in that case, the input tensor will be reversed in that particular axis
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the dynamic_strided_slice operation
+ */
+inline te::Tensor dynamic_strided_slice(const te::Tensor& x, const te::Tensor& begin,
+                                        const te::Tensor& end, const te::Tensor& strides,
+                                        std::string name = "T_strided_slice_dynamic",
+                                        std::string tag = topi::kInjective) {
+  const int64_t num_dynamic_axes = begin->shape[0].as<IntImmNode>()->value;
+  ICHECK_EQ(end->shape[0].as<IntImmNode>()->value, num_dynamic_axes);
+  ICHECK_EQ(strides->shape[0].as<IntImmNode>()->value, num_dynamic_axes);
+
+  Array<PrimExpr> begin_expr, end_expr, strides_expr;
+  for (int64_t i = 0; i < num_dynamic_axes; ++i) {
+    auto i64_ind = IntImm(DataType::Int(64), i);
+    begin_expr.push_back(begin(i64_ind));
+    end_expr.push_back(end(i64_ind));
+    strides_expr.push_back(strides(i64_ind));
+  }
+  return dynamic_strided_slice(x, begin_expr, end_expr, strides_expr, name, tag);
+}
+
+/*!
+ * \brief Calcluate the output shape of strided_slice, the entry point for Relay type relation
+ *
+ * \param ishape The input tensor shape
+ * \param begin The indices to begin with in the slicing
+ * \param end Indices indicating end of the slice
+ * \param strides Specifies the stride values, it can be negative
+ * in that case, the input tensor will be reversed in that particular axis
+ * \param axes Axes along which slicing is applied. When it is specified, the length of begin, end,
+ * strides, and axes argument must be equal
+ * \param slice_mode Specifies the slice mode
+ *
+ * \return The output shape of strided_slice using the arguments above
+ */
+inline Array<PrimExpr> StridedSliceOutputShape(
+    const Array<PrimExpr>& ishape, const Array<Integer>& begin, const Array<Integer>& end,
+    const Array<Integer>& strides, const Array<Integer>& axes, const std::string& slice_mode) {
+  ICHECK(axes.size() == begin.size() && axes.size() == end.size() && axes.size() == strides.size());
+  std::vector<int64_t> begin_vec, end_vec, strides_vec;
+  std::tie(begin_vec, end_vec, strides_vec) = ConvertToVec(begin, end, strides, slice_mode);
+  auto begin_canonicalized = StridedSliceCanonicalizeBegin(ishape, begin_vec, strides_vec, axes,
+                                                           begin[0]->dtype, slice_mode);
+  return StridedSliceOutputShape(ishape, begin_vec, end_vec, strides_vec, axes, slice_mode,
+                                 begin_canonicalized, true);
+}
+
+/*!
+ * \brief strided_slice of a tensor
+ *
+ * \param x The input tensor
+ * \param begin The indices to begin with in the slicing
+ * \param end Indices indicating end of the slice
+ * \param strides Specifies the stride values, it can be negative
+ * in that case, the input tensor will be reversed in that particular axis
+ * \param axes Axes along which slicing is applied. When it is specified, the length of begin, end,
+ * strides, and axes argument must be equal
+ * \param slice_mode Specifies the slice mode
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the sstrided_slice operation
+ */
+inline Tensor strided_slice_with_axes(const Tensor& x, const Array<Integer>& begin,
+                                      const Array<Integer>& end, const Array<Integer>& strides,
+                                      const Array<Integer>& axes, std::string slice_mode = "end",
+                                      std::string name = "T_strided_slice_with_axes",
+                                      std::string tag = kInjective) {
+  const size_t src_tensor_dim = x->shape.size();
+  ICHECK(axes.size() <= src_tensor_dim);
+  ICHECK(axes.size() == begin.size() && axes.size() == end.size() && axes.size() == strides.size());
+
+  std::vector<int64_t> begin_vec, end_vec, strides_vec;
+  std::tie(begin_vec, end_vec, strides_vec) = ConvertToVec(begin, end, strides, slice_mode);
+
+  auto begin_expr = StridedSliceCanonicalizeBegin(x->shape, begin_vec, strides_vec, axes,
+                                                  begin[0]->dtype, slice_mode);
+  auto out_shape = StridedSliceOutputShape(x->shape, begin_vec, end_vec, strides_vec, axes,
+                                           slice_mode, begin_expr);
+
+  return te::compute(
+      out_shape,
+      [&](const Array<tir::Var>& indices) {
+        Array<PrimExpr> real_indices;
+        for (size_t i = 0; i < out_shape.size(); ++i) real_indices.push_back(indices[i]);
+        for (size_t i = 0; i < axes.size(); ++i) {
+          auto stride = make_const(strides[i].dtype(), strides_vec[i]);
+          PrimExpr ind = indices[axes[i].IntValue()] * stride + begin_expr[i];
+          real_indices.Set(axes[i].IntValue(), ind);
+        }
+        return x(real_indices);
+      },
+      name, tag);
+}
+
+/*!
+ * \brief strided_slice of a tensor
+ *
+ * \param x The input tensor
+ * \param begin The indices to begin with in the slicing
+ * \param end Indices indicating end of the slice
+ * \param strides Specifies the stride values, it can be negative
+ * in that case, the input tensor will be reversed in that particular axis
+ * \param slice_mode Specifies the slice mode
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the strided_slice operation
+ */
+inline Tensor strided_slice(const Tensor& x, const Array<Integer>& begin, const Array<Integer>& end,
+                            const Array<Integer>& strides, std::string slice_mode = "end",
+                            std::string name = "T_strided_slice", std::string tag = kInjective) {
+  size_t src_tensor_dim = static_cast<size_t>(x->shape.size());
+  Array<Integer> axes;
+  for (size_t i = 0; i < src_tensor_dim; ++i) axes.push_back(i);
+  Array<Integer> begin_full(begin);
+  Array<Integer> end_full(end);
+  Array<Integer> strides_full(strides);
+
+  const IntImm one = IntImm(DataType::Int(64), 1);
+  const IntImm zero = IntImm(DataType::Int(64), 0);
+  const IntImm max_range = IntImm(DataType::Int(64), std::numeric_limits<int64_t>::max());
+
+  for (size_t i = strides.size(); i < src_tensor_dim; ++i) {
+    strides_full.push_back(one);
+  }
+  for (size_t i = begin.size(); i < src_tensor_dim; ++i) {
+    begin_full.push_back(GetConstInt(strides_full[i]) > 0 ? zero : max_range);
+  }
+  for (size_t i = end.size(); i < src_tensor_dim; ++i) {
+    end_full.push_back(GetConstInt(strides_full[i]) < 0 ? zero : max_range);
+  }
+
+  return strided_slice_with_axes(x, begin_full, end_full, strides_full, axes, slice_mode, name,
+                                 tag);
+}
+
+/*!
+ * \brief Split a tensor into a number of sub-tensors
+ *
+ * \param x The input tensor
+ * \param num_sections The number of sections to split the tensor into.
+ * this must be an integer factor of the size of the axis being split.
+ * \param axis The axis to split along.
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the split operation
+ */
+inline Array<Tensor> split_sections(const Tensor& x, int num_sections, int axis,
+                                    std::string name = "T_split_sections",
+                                    std::string tag = kInjective) {
+  if (axis < 0) {
+    axis += static_cast<int>(x->shape.size());
+  }
+  ICHECK_LT(axis, x->shape.size()) << "axis out of bounds";
+
+  auto src_axis_size = x->shape[axis];
+
+  ICHECK_GT(num_sections, 0) << "Slice count must be > 0";
+
+  if (auto node = src_axis_size.as<IntImmNode>()) {
+    ICHECK_EQ(node->value % num_sections, 0)
+        << "num_sections must be an integer factor of the size of axis " << axis << " ("
+        << node->value << ")";
+  }
+
+  Array<PrimExpr> split_indices;
+  auto seg_size = indexdiv(src_axis_size, num_sections);
+  for (int i = 0; i < num_sections; ++i) {
+    // region at index 0 is added by split()
+    if (i != 0) {
+      split_indices.push_back(seg_size * i);
+    }
+  }
+
+  return split(x, split_indices, axis, name, tag);
+}
+
+/*!
+ * \brief Take elements from an flattened input array when axis is None.
+ *
+ * \param a The source array.
+ * \param indices The indices of the values to extract.
+ * \param batch_dims The number of batch dimensions.
+ * \param mode The mode of the operation.
+ * \param name The name of the operation.
+ * \param mode The mode of to handle out of bound indices.
+ * \param tag The tag to mark the operation.
+ *
+ * \return A Tensor whose op member is the take operation
+ */
+inline Tensor take(const Tensor& a, const Tensor& indices, int batch_dims,
+                   std::string mode = "clip", std::string name = "T_take",
+                   std::string tag = kInjective) {
+  Array<PrimExpr> a_shape = a->shape;
+  Array<PrimExpr> out_shape = indices->shape;
+  PrimExpr a_size = 1;
+  for (size_t i = 0; i < a_shape.size(); ++i) {
+    a_size = a_size * a_shape[i];
+  }
+
+  if (mode == "clip") {
+    return compute(
+        out_shape,
+        [&](const Array<Var>& out_index) {
+          auto idx = tvm::min(tvm::max(0, indices(out_index)), a_size - 1);
+          return a(UnravelIndex(idx, a_shape));
+        },
+        name, tag);
+  } else if (mode == "fast") {
+    LOG(WARNING) << "Fast mode segfaults when there are out-of-bounds indices. "
+                    "Make sure input indices are in bound";
+    return compute(
+        out_shape,
+        [&](const Array<Var>& out_index) { return a(UnravelIndex(indices(out_index), a_shape)); },
+        name, tag);
+  } else {  // mode == "wrap"
+    return compute(
+        out_shape,
+        [&](const Array<Var>& out_index) {
+          auto idx = truncmod(truncmod(indices(out_index), a_size) + a_size, a_size);
+          return a(UnravelIndex(idx, a_shape));
+        },
+        name, tag);
+  }
+}
+
+/*!
+ * \brief Mask the out-of-boundary elements of each sequence.
+ *
+ * \param data The source array.
+ * \param valid_length The real length of each sequence.
+ * \param mask_value The masking value.
+ * \param axis The axis of the temporal dimension of the sequence
+ * \param name The name of the operation.
+ * \param tag The tag to mark the operation.
+ *
+ * \return A Tensor whose op member is the sequence_mask operation
+ */
+inline Tensor sequence_mask(const Tensor& data, const Tensor& valid_length, double mask_value,
+                            int axis, std::string name = "T_sequence_mask",
+                            std::string tag = kInjective) {
+  ICHECK(axis == 0 || axis == 1) << "axis must be either 0 or 1";
+  ICHECK_EQ(valid_length->shape.size(), 1) << "valid_length must have ndim=1, i.e., (batch_size,).";
+  auto length_dim = data->shape[axis];
+  auto batch_dim = data->shape[1 - axis];
+  Array<PrimExpr> out_shape = data->shape;
+  Tensor out = compute(
+      out_shape,
+      [&](const Array<Var>& out_index) {
+        Array<PrimExpr> len_index;
+        auto tid = out_index[axis];
+        auto bid = out_index[1 - axis];
+        len_index.push_back(bid);
+        PrimExpr ret =
+            tvm::if_then_else(tvm::cast(valid_length->dtype, tid) >= valid_length(len_index),
+                              tvm::tir::make_const(data->dtype, mask_value), data(out_index));
+        return ret;
+      },
+      name, tag);
+  return out;
+}
+
+/*!
+ * \brief Take elements from an array along an axis.
+ *
+ * \param a The source array.
+ * \param indices The indices of the values to extract.
+ * \param batch_dims The number of batch dimensions. By default is 0.
+ * \param axis The axis over which to select values. By default,
+ * the flattened input array is used.
+ * \param mode The mode for handling out of bound indices.
+ * \param name The name of the operation.
+ * \param tag The tag to mark the operation.
+ *
+ * \return A Tensor whose op member is the take operation
+ */
+inline Tensor take(const Tensor& a, const Tensor& indices, int batch_dims, int axis,
+                   std::string mode = "clip", std::string name = "T_take",
+                   std::string tag = kInjective) {
+  if (axis < 0) {
+    axis += static_cast<int>(a->shape.size());
+  }
+  ICHECK_GE(axis, 0) << "axis out of bounds";
+  ICHECK_LT(axis, a->shape.size()) << "axis out of bounds";
+  auto axis_dim = a->shape[axis];
+  int indices_len = static_cast<int>(indices->shape.size());
+
+  int batch_dims_ = batch_dims;
+  if (batch_dims_ != 0) {
+    ICHECK_GE(batch_dims_, -static_cast<int>(indices->shape.size())) << "batch_dims out of bounds";
+    ICHECK_LE(batch_dims_, indices->shape.size()) << "batch_dims out of bounds";
+
+    if (batch_dims_ < 0) {
+      batch_dims_ = indices->shape.size() + batch_dims_;
+    }
+
+    ICHECK_LT(batch_dims_, a->shape.size()) << "batch_dims out of bounds";
+    ICHECK_LE(batch_dims_, axis) << "batch_dims must be less than or equal to axis";
+    for (int i = 0; i < batch_dims_; ++i) {
+      auto addr1 = a->shape[i];
+      auto addr2 = indices->shape[i];
+      auto v1 = static_cast<IntImm*>(&addr1)->get()->value;
+      auto v2 = static_cast<IntImm*>(&addr2)->get()->value;
+      ICHECK_EQ(v1, v2) << "a.shape[" << i << "] should be equal to indices.shape[" << i << "]";
+    }
+  }
+
+  // The result shape is a.shape[:axis] + indices.shape[batch_dims:] +
+  // a.shape[axis + 1:].
+
+  Array<PrimExpr> out_shape;
+  for (int i = 0; i < batch_dims_; ++i) {
+    out_shape.push_back(a->shape[i]);
+  }
+  for (int i = batch_dims_; i < axis; ++i) {
+    out_shape.push_back(a->shape[i]);
+  }
+  for (size_t i = static_cast<size_t>(batch_dims_); i < indices->shape.size(); ++i) {
+    out_shape.push_back(indices->shape[i]);
+  }
+  for (size_t i = axis + 1; i < a->shape.size(); ++i) {
+    out_shape.push_back(a->shape[i]);
+  }
+
+  if (mode == "clip") {
+    if (batch_dims_ == 0) {
+      return compute(
+          out_shape,
+          [&](const Array<Var>& out_index) {
+            Array<PrimExpr> indices_position;
+            for (size_t j = axis; j < static_cast<size_t>(axis + indices_len); ++j) {
+              indices_position.push_back(out_index[j]);
+            }
+            Array<PrimExpr> real_indices;
+            for (size_t j = 0; j < static_cast<size_t>(axis); ++j) {
+              real_indices.push_back(out_index[j]);
+            }
+            auto idx = tvm::min(tvm::max(0, indices(indices_position)), axis_dim - 1);
+            real_indices.push_back(idx);
+            for (size_t j = axis + indices_len; j < out_index.size(); ++j) {
+              real_indices.push_back(out_index[j]);
+            }
+            return a(real_indices);
+          },
+          name, tag);
+    } else {
+      return compute(
+          out_shape,
+          [&](const Array<Var>& out_index) {
+            Array<PrimExpr> indices_position;
+            for (size_t j = 0; j < static_cast<size_t>(batch_dims_); ++j) {
+              indices_position.push_back(out_index[j]);
+            }
+            for (size_t j = axis; j < static_cast<size_t>(axis + indices_len - batch_dims_); ++j) {
+              indices_position.push_back(out_index[j]);
+            }
+            Array<PrimExpr> real_indices;
+            for (size_t j = 0; j < static_cast<size_t>(axis); ++j) {
+              real_indices.push_back(out_index[j]);
+            }
+            auto idx = tvm::min(tvm::max(0, indices(indices_position)), axis_dim - 1);
+            real_indices.push_back(idx);
+            for (size_t j = axis + indices_len - batch_dims_; j < out_index.size(); ++j) {
+              real_indices.push_back(out_index[j]);
+            }
+            return a(real_indices);
+          },
+          name, tag);
+    }
+  } else if (mode == "fast") {
+    LOG(WARNING) << "Fast mode segfaults when there are out-of-bounds indices. "
+                    "Make sure input indices are in bound";
+    return compute(
+        out_shape,
+        [&](const Array<Var>& out_index) {
+          Array<PrimExpr> indices_position;
+          for (size_t j = axis; j < static_cast<size_t>(axis + indices_len); ++j) {
+            indices_position.push_back(out_index[j]);
+          }
+          Array<PrimExpr> real_indices;
+          for (size_t j = 0; j < static_cast<size_t>(axis); ++j) {
+            real_indices.push_back(out_index[j]);
+          }
+          real_indices.push_back(indices(indices_position));
+          for (size_t j = axis + indices_len; j < out_index.size(); ++j) {
+            real_indices.push_back(out_index[j]);
+          }
+          return a(real_indices);
+        },
+        name, tag);
+  } else {  // mode == "wrap"
+    return compute(
+        out_shape,
+        [&](const Array<Var>& out_index) {
+          Array<PrimExpr> indices_position;
+          for (size_t j = axis; j < static_cast<size_t>(axis + indices_len); ++j) {
+            indices_position.push_back(out_index[j]);
+          }
+          Array<PrimExpr> real_indices;
+          for (size_t j = 0; j < static_cast<size_t>(axis); ++j) {
+            real_indices.push_back(out_index[j]);
+          }
+          auto idx = truncmod(truncmod(indices(indices_position), axis_dim) + axis_dim, axis_dim);
+          real_indices.push_back(idx);
+          for (size_t j = axis + indices_len; j < out_index.size(); ++j) {
+            real_indices.push_back(out_index[j]);
+          }
+          return a(real_indices);
+        },
+        name, tag);
+  }
+}
+
+/*!
+ * \brief Return the elements, either from x or y, depending on the condition.
+ *
+ * \param condition The condition array.
+ * \param x First array to be selected.
+ * \param y Second array to be selected.
+ * \param name The name of the operation.
+ * \param tag The tag to mark the operation.
+ *
+ * \return A Tensor selected from x or y depending on condition.
+ */
+inline Tensor where(const Tensor& condition, const Tensor& x, const Tensor& y,
+                    std::string name = "T_where", std::string tag = kBroadcast) {
+  ICHECK_EQ(x->dtype, y->dtype) << "x and y must have the same dtype: " << x->dtype << " vs "
+                                << y->dtype;
+  auto get_out_shape = [&]() {
+    auto bh1 = detail::BroadcastShape(x->shape, y->shape);
+    Array<PrimExpr> common_shape1(bh1.common_shape.begin(), bh1.common_shape.end());
+    auto bh2 = detail::BroadcastShape(condition->shape, common_shape1);
+    Array<PrimExpr> common_shape2(bh2.common_shape.begin(), bh2.common_shape.end());
+    return common_shape2;
+  };
+
+  auto oshape = get_out_shape();
+
+  auto c_bh = detail::BroadcastShape(condition->shape, oshape);
+  auto x_bh = detail::BroadcastShape(x->shape, oshape);
+  auto y_bh = detail::BroadcastShape(y->shape, oshape);
+
+  auto select = [&](tvm::Array<tvm::tir::Var> ovars) {
+    auto c = condition(InputIndexFromBroadcast(ovars, condition, c_bh.vars1, c_bh.all_vars));
+    auto true_val = x(InputIndexFromBroadcast(ovars, x, x_bh.vars1, x_bh.all_vars));
+    auto false_val = y(InputIndexFromBroadcast(ovars, y, y_bh.vars1, y_bh.all_vars));
+    return tvm::tir::Select(c != 0, true_val, false_val);
+  };
+
+  return compute(oshape, select, name, tag);
+}
+
+/*!
+ * \brief Creates an operation to repeat elements of an array
+ *
+ * \param x The input tensor
+ * \param repeats The number of repetitions for each element
+ * \param axis The axis along which to repeat values (allows
+ * negative indices as offsets from the last dimension)
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the repeat operation
+ */
+inline Tensor repeat(const Tensor& x, int repeats, int axis, std::string name = "T_repeat",
+                     std::string tag = kBroadcast) {
+  int ndim = static_cast<int>(x->shape.size());
+  ICHECK(-ndim - 1 <= axis && axis <= ndim)
+      << "repeat only accepts `axis` in [-data.ndim - 1, data.ndim]"
+      << ", but got axis = " << axis << ", and data.ndim = " << ndim;
+  ICHECK(repeats >= 1) << "repeat only accepts `repeats >= 1`"
+                       << ", but got repeats = " << repeats;
+  if (axis < 0) {
+    // Calculate offset from last dimension
+    axis += ndim;
+  }
+  Array<PrimExpr> new_shape;
+  for (size_t i = 0; i < static_cast<size_t>(axis); ++i) {
+    new_shape.push_back(x->shape[i]);
+  }
+  new_shape.push_back(repeats * x->shape[axis]);
+  for (size_t i = axis + 1; i < x->shape.size(); ++i) {
+    new_shape.push_back(x->shape[i]);
+  }
+
+  return compute(
+      new_shape,
+      [&](const Array<Var>& indices) {
+        Array<PrimExpr> idx;
+        for (size_t i = 0; i < static_cast<size_t>(axis); ++i) {
+          idx.push_back(indices[i]);
+        }
+        idx.push_back(indexdiv(indices[axis], repeats));
+        for (size_t i = axis + 1; i < indices.size(); ++i) {
+          idx.push_back(indices[i]);
+        }
+        return x(idx);
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Creates an operation to tile elements of an array
+ *
+ * \param x The input tensor
+ * \param reps The number of times for repeating the tensor
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the tile operation
+ */
+inline Tensor tile(const Tensor& x, Array<Integer> reps, std::string name = "T_tile",
+                   std::string tag = kBroadcast) {
+  size_t ndim = x->shape.size();
+  size_t rdim = reps.size();
+  size_t tdim = (ndim > rdim) ? ndim : rdim;
+  Array<PrimExpr> data_shape;
+  Array<PrimExpr> reps_shape;
+  Array<PrimExpr> new_shape;
+  if (ndim == rdim) {
+    for (size_t i = 0; i < ndim; ++i) {
+      data_shape.push_back(x->shape[i]);
+      reps_shape.push_back(reps[i]);
+    }
+  } else if (ndim > rdim) {
+    for (size_t i = 0; i < ndim; ++i) data_shape.push_back(x->shape[i]);
+    for (size_t i = 0; i < (ndim - rdim); ++i) reps_shape.push_back(1);
+    for (size_t i = 0; i < rdim; ++i) reps_shape.push_back(reps[i]);
+  } else {
+    for (size_t i = 0; i < (rdim - ndim); ++i) data_shape.push_back(1);
+    for (size_t i = 0; i < ndim; ++i) data_shape.push_back(x->shape[i]);
+    for (size_t i = 0; i < rdim; ++i) reps_shape.push_back(reps[i]);
+  }
+  for (size_t i = 0; i < tdim; ++i) new_shape.push_back(data_shape[i] * reps_shape[i]);
+
+  if (is_empty_shape(new_shape)) {
+    return compute(
+        new_shape, [&](const Array<Var>& indices) { return tvm::cast(x->dtype, 0); }, name, tag);
+  } else {
+    return compute(
+        new_shape,
+        [&](const Array<Var>& indices) {
+          Array<PrimExpr> idx;
+          if (ndim >= rdim) {
+            for (size_t i = 0; i < ndim; ++i) idx.push_back(indexmod(indices[i], x->shape[i]));
+          } else {
+            for (size_t i = 0; i < ndim; ++i)
+              idx.push_back(indexmod(indices[rdim - ndim + i], x->shape[i]));
+          }
+          return x(idx);
+        },
+        name, tag);
+  }
+}
+
+/*!
+ * \brief Creates an operation to tile elements of an array
+ *
+ * \param x The input tensor
+ * \param new_shape The shape of the output after tiling
+ * \param rdim The rank of the reps, provided by caller
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the tile operation
+ */
+inline Tensor dyn_tile(const Tensor& x, Array<PrimExpr> new_shape, size_t rdim,
+                       std::string name = "T_tile", std::string tag = kBroadcast) {
+  size_t ndim = x->shape.size();
+  if (is_empty_shape(new_shape)) {
+    return compute(
+        new_shape, [&](const Array<Var>& indices) { return tvm::cast(x->dtype, 0); }, name, tag);
+  } else {
+    return compute(
+        new_shape,
+        [&](const Array<Var>& indices) {
+          Array<PrimExpr> idx;
+          if (ndim >= rdim) {
+            for (size_t i = 0; i < ndim; ++i) {
+              idx.push_back(indexmod(indices[i], x->shape[i]));
+            }
+          } else {
+            for (size_t i = 0; i < ndim; ++i) {
+              idx.push_back(indexmod(indices[rdim - ndim + i], x->shape[i]));
+            }
+          }
+          return x(idx);
+        },
+        name, tag);
+  }
+}
+
+/*!
+ * \brief Gather values along given axis from given indices.
+ *
+ * \param data The input data to the operator.
+ * \param axis The axis along which to index.
+ * \param indices The indices of values to gather.
+ * \param name The name of the operation.
+ * \param tag The tag to mark the operation.
+ *
+ * \return A Tensor whose op member is the gather operation
+ */
+inline Tensor gather(const Tensor& data, int axis, const Tensor& indices,
+                     std::string name = "T_gather", std::string tag = kInjective) {
+  size_t ndim_d = data->shape.size();
+  size_t ndim_i = indices->shape.size();
+  ICHECK_GE(ndim_d, 1) << "Cannot gather from a scalar.";
+  ICHECK_EQ(ndim_d, ndim_i);
+  if (axis < 0) {
+    axis += ndim_d;
+  }
+  ICHECK_GE(axis, 0);
+  ICHECK_LT(axis, ndim_d);
+  if (indices->shape[axis].as<IntImmNode>()) {
+    size_t indices_dim_i = static_cast<size_t>(GetConstInt(indices->shape[axis]));
+    ICHECK_GE(indices_dim_i, 1);
+  }
+  ICHECK(indices->dtype.is_int() || indices->dtype.is_uint());
+
+  Array<PrimExpr> out_shape;
+  for (size_t i = 0; i < ndim_i; ++i) {
+    out_shape.push_back(indices->shape[i]);
+  }
+
+  return compute(
+      out_shape,
+      [&](const Array<Var>& out_index) {
+        Array<PrimExpr> indices_position;
+        for (size_t i = 0; i < ndim_i; ++i) {
+          indices_position.push_back(out_index[i]);
+        }
+        Array<PrimExpr> real_indices;
+        for (size_t i = 0; i < ndim_i; ++i) {
+          if (i == static_cast<size_t>(axis)) {
+            real_indices.push_back(indices(indices_position));
+          } else {
+            real_indices.push_back(indices_position[i]);
+          }
+        }
+        return data(real_indices);
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Gather elements from a n-dimension array.
+ *
+ * \param data The source array.
+ * \param indices The indices of the values to extract.
+ * \param batch_dims The number of batch dimensions.
+ * \param name The name of the operation.
+ * \param tag The tag to mark the operation.
+ *
+ * \return A Tensor whose op member is the gather_nd operation
+ */
+inline Tensor gather_nd(const Tensor& data, const Tensor& indices, int batch_dims = 0,
+                        std::string name = "T_gather_nd", std::string tag = kInjective) {
+  size_t ndim_d = data->shape.size();
+  size_t ndim_i = indices->shape.size();
+  ICHECK_GE(ndim_i, 1) << "indices tensor must have at least 1 dimensions";
+  size_t indices_dim0 = static_cast<size_t>(GetConstInt(indices->shape[0]));
+  ICHECK_LE(indices_dim0, ndim_d) << "dim 0 of indices tensor must be no more "
+                                  << "than dimensions of data tensor";
+  Array<PrimExpr> out_shape;
+  for (size_t i = 1; i < ndim_i; ++i) {
+    out_shape.push_back(indices->shape[i]);
+  }
+  for (size_t i = indices_dim0 + batch_dims; i < ndim_d; ++i) {
+    out_shape.push_back(data->shape[i]);
+  }
+  return compute(
+      out_shape,
+      [&](const Array<Var>& out_index) {
+        Array<PrimExpr> indices_position;
+        indices_position.push_back(0);
+        for (size_t i = 0; i < ndim_i - 1; ++i) {
+          indices_position.push_back(out_index[i]);
+        }
+        Array<PrimExpr> real_indices;
+        for (size_t i = 0; i < static_cast<size_t>(batch_dims); ++i) {
+          real_indices.push_back(out_index[i]);
+        }
+        for (size_t i = 0; i < indices_dim0; ++i) {
+          indices_position.Set(0, make_const(DataType::Int(32), i));
+          if (indices->dtype.is_int() || indices->dtype.is_uint()) {
+            real_indices.push_back(indices(indices_position));
+          } else {
+            real_indices.push_back(tvm::cast(tvm::DataType::Int(32), indices(indices_position)));
+          }
+        }
+        if (real_indices.size() == ndim_d) {
+          return data(real_indices);
+        }
+        for (size_t i = ndim_i - 1; i < out_index.size(); ++i) {
+          real_indices.push_back(out_index[i]);
+        }
+        return data(real_indices);
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Creates an operation that calculates a matrix multiplication
+ *  (row-major notation):
+ *      A(i, k) * B(k, j), if trans_a == trans_b
+ *          the usual transposed combinations, otherwise
+ *
+ * \param A The matrix A
+ * \param B The matrix B
+ * \param trans_a Is A's layout transposed?
+ * \param trans_b Is B's layout transposed?
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the matmul operation
+ */
+inline tvm::te::Tensor matmul(const tvm::te::Tensor& A, const tvm::te::Tensor& B,
+                              bool trans_a = false, bool trans_b = false,
+                              std::string name = "T_matmul", std::string tag = kMatMul) {
+  tvm::Array<tvm::PrimExpr> output_shape{A->shape[trans_a ? 1 : 0], B->shape[trans_b ? 0 : 1]};
+  auto k = tvm::te::reduce_axis(tvm::Range{0, A->shape[trans_a ? 0 : 1]}, "k");
+  auto l = [&](tvm::tir::Var i, tvm::tir::Var j) {
+    return tvm::sum((trans_a ? A[k][i] : A[i][k]) * (trans_b ? B[j][k] : B[k][j]), {k});
+  };
+  return tvm::te::compute(output_shape, l, name, tag);
+}
+
+/*!
+ * \brief A generalization of matrix multiplication to tensors.
+ *
+ * \param A The tensor A
+ * \param B The tensor B
+ * \param axes The number of the dimensions to reduce over
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor computing the result
+ */
+inline Tensor tensordot(const Tensor& A, const tvm::te::Tensor& B, int axes = 2,
+                        std::string name = "T_tensordot", std::string tag = kMatMul) {
+  ICHECK_GE(A->shape.size(), axes);
+  ICHECK_GE(B->shape.size(), axes);
+
+  Array<PrimExpr> output_shape(A->shape.begin(), A->shape.end() + (-axes));
+  for (auto it = B->shape.begin() + axes; it != B->shape.end(); ++it) output_shape.push_back(*it);
+
+  Array<IterVar> iter_vars;
+  for (int i = 0; i < axes; ++i)
+    iter_vars.push_back(reduce_axis(Range(0, B->shape[i]), "k" + std::to_string(i)));
+
+  auto func = [&A, &B, &iter_vars, axes](const Array<Var>& input_indices) {
+    Array<PrimExpr> A_indices(input_indices.begin(),
+                              input_indices.begin() + (A->shape.size() - axes));
+    for (auto& v : iter_vars) A_indices.push_back(v);
+
+    Array<PrimExpr> B_indices;
+    for (auto& v : iter_vars) B_indices.push_back(v);
+
+    auto it = input_indices.begin() + (A->shape.size() - axes);
+    for (; it != input_indices.end(); ++it) B_indices.push_back(*it);
+
+    // Some passes don't like reductions with empty axis, so avoid it here
+    if (iter_vars.empty()) {
+      return A(A_indices) * B(B_indices);
+    } else {
+      return sum(A(A_indices) * B(B_indices), iter_vars);
+    }
+  };
+
+  return compute(output_shape, func, name, tag);
+}
+
+/*!
+ * \brief A generalization of matrix multiplication to tensors.
+ *
+ * \param A The tensor A
+ * \param B The tensor B
+ * \param A_axes The indices of the dimensions of tensor A to reduce over
+ * \param B_axes The indices of the dimensions of tensor B to reduce over
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor computing the result
+ */
+inline Tensor tensordot(const Tensor& A, const tvm::te::Tensor& B, Array<PrimExpr> A_axes,
+                        Array<PrimExpr> B_axes, std::string name = "T_tensordot",
+                        std::string tag = kMatMul) {
+  ICHECK_EQ(A_axes.size(), B_axes.size());
+
+  auto A_axes_val = GetConstIntValues(A_axes, "A_axes");
+  auto B_axes_val = GetConstIntValues(B_axes, "B_axes");
+
+  Array<PrimExpr> output_shape;
+  for (unsigned i = 0; i < A->shape.size(); ++i)
+    if (std::find(A_axes_val.begin(), A_axes_val.end(), i) == A_axes_val.end())
+      output_shape.push_back(A->shape[i]);
+  for (unsigned i = 0; i < B->shape.size(); ++i)
+    if (std::find(B_axes_val.begin(), B_axes_val.end(), i) == B_axes_val.end())
+      output_shape.push_back(B->shape[i]);
+
+  Array<IterVar> iter_vars;
+  for (unsigned i = 0; i < B_axes_val.size(); ++i)
+    iter_vars.push_back(reduce_axis(Range(0, B->shape[B_axes_val[i]]), "k" + std::to_string(i)));
+
+  auto func = [&A, &B, &iter_vars, A_axes_val, B_axes_val](const Array<Var>& input_indices) {
+    int idx_input = 0;
+    Array<PrimExpr> A_indices;
+    for (unsigned i = 0; i < A->shape.size(); ++i) {
+      auto axes_pos = std::find(A_axes_val.begin(), A_axes_val.end(), i);
+      if (axes_pos == A_axes_val.end()) {
+        A_indices.push_back(input_indices[idx_input++]);
+      } else {
+        A_indices.push_back(iter_vars[axes_pos - A_axes_val.begin()]);
+      }
+    }
+
+    Array<PrimExpr> B_indices;
+    for (unsigned i = 0; i < B->shape.size(); ++i) {
+      auto axes_pos = std::find(B_axes_val.begin(), B_axes_val.end(), i);
+      if (axes_pos == B_axes_val.end()) {
+        B_indices.push_back(input_indices[idx_input++]);
+      } else {
+        B_indices.push_back(iter_vars[axes_pos - B_axes_val.begin()]);
+      }
+    }
+    return sum(A(A_indices) * B(B_indices), iter_vars);
+  };
+  return compute(output_shape, func, name, tag);
+}
+
+inline Tensor arange(const PrimExpr& start, const PrimExpr& stop, const PrimExpr& step,
+                     DataType dtype, std::string name = "T_arange", std::string tag = kInjective) {
+  PrimExpr num_elem = tvm::cast(
+      tvm::DataType::Int(32), tvm::ceil(tvm::cast(tvm::DataType::Float(32), stop - start) / step));
+  Array<PrimExpr> shape;
+  return compute(
+      {num_elem},
+      [&](const Array<Var>& indices) { return tvm::cast(dtype, start + step * indices[0]); }, name,
+      tag);
+}
+
+/*!
+ * \brief Produce grids by expanding input over dimensions defined by other inputs
+ *
+ * \param inputs The input tensors
+ * \param indexing The indexing mode, either "xy" or "ij"
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the meshgrid operation
+ */
+inline Array<Tensor> meshgrid(const Array<Tensor>& inputs, const std::string& indexing,
+                              std::string name = "T_meshgrid", std::string tag = kInjective) {
+  const bool cartesian_indexing = indexing == "xy" && inputs.size() >= 2;
+  Array<PrimExpr> out_shape;
+  for (size_t i = 0; i < inputs.size(); ++i) {
+    const int src_index = (cartesian_indexing && i < 2) ? 1 - i : i;
+    out_shape.push_back(inputs[src_index]->shape.size() == 0 ? 1 : inputs[src_index]->shape[0]);
+  }
+  Array<Tensor> result;
+  for (size_t i = 0; i < inputs.size(); ++i) {
+    result.push_back(compute(
+        out_shape,
+        [&](const Array<Var>& indices) {
+          const int src_index = (cartesian_indexing && i < 2) ? 1 - i : i;
+          auto ndim = inputs[i]->GetShape().size();
+          Array<PrimExpr> real_indices = {};
+          if (ndim > 0) {
+            real_indices = {indices[src_index]};
+          }
+          return inputs[i](real_indices);
+        },
+        name, tag));
+  }
+  return result;
+}
+
+/*!
+ * \brief Transform the layout according to \p src_layout and \p dst_layout
+ * \param src the source input.
+ * \param src_layout the source layout.
+ * \param dst_layout the destination layout.
+ * \param name output tensor name.
+ * \param tag output tensor tag.
+ * \return A tensor with shape in \p dst_layout
+ */
+inline Tensor layout_transform(const Tensor& src, const std::string& src_layout,
+                               const std::string& dst_layout,
+                               const std::string name = "T_layout_trans",
+                               const std::string tag = kInjective) {
+  Layout src_layout_struct(src_layout);
+  Layout dst_layout_struct(dst_layout);
+
+  if (src_layout_struct.Equals(dst_layout_struct)) {
+    return src;
+  }
+
+  ICHECK(src_layout_struct.defined() && dst_layout_struct.defined())
+      << "cannot convert from/to undefined layout";
+
+  auto layout_converter = tir::BijectiveLayout(src_layout_struct, dst_layout_struct);
+  ICHECK(layout_converter.defined())
+      << "cannot convert from " << src_layout << " to " << dst_layout;
+
+  Array<PrimExpr> dst_shape = layout_converter.ForwardShape(src->shape);
+
+  return compute(
+      dst_shape,
+      [&](const Array<Var>& dst_indices) {
+        Array<PrimExpr> dst_indices_expr(dst_indices.begin(), dst_indices.end());
+        Array<PrimExpr> src_indices = layout_converter.BackwardIndex(dst_indices_expr);
+        PrimExpr in_range = PrimExpr(1) > PrimExpr(0);  // init with dtype=bool and value=true
+        for (size_t i = 0; i < src.ndim(); ++i) {
+          in_range = in_range && (src_indices[i] < src->shape[i]);
+        }
+        return if_then_else(in_range, src(src_indices), tvm::cast(src->dtype, PrimExpr(0)));
+      },
+      name, tag);
+}
+
+/*! \brief Utility function for auto_scheduler_layout_transform */
+inline void parse_auto_scheduler_layout(const String& layout, Array<PrimExpr>* shape,
+                                        std::vector<std::string>* axes) {
+  int32_t factor = 0;
+  std::string axis = "";
+  for (char c : std::string(layout)) {
+    if (c >= 'A' && c <= 'z') {
+      axis += c;
+      if (factor != 0) {
+        shape->push_back(factor);
+        factor = 0;
+      }
+    } else if (c >= '0' && c <= '9') {
+      factor = factor * 10 + c - '0';
+      if (!axis.empty()) {
+        axes->push_back(axis);
+        axis = "";
+      }
+    } else {
+      LOG(FATAL) << "Invalid layout " << layout;
+    }
+  }
+  if (!axis.empty()) {
+    axes->push_back(axis);
+  }
+}
+
+/*!
+ * \brief Transform the auto-scheduler generated layout according to
+ *        \p src_layout and \p dst_layout
+ * \param src the source input.
+ * \param src_layout the source layout.
+ * \param dst_layout the destination layout.
+ * \param name output tensor name.
+ * \param tag output tensor tag.
+ * \return A tensor with shape in \p dst_layout
+ */
+inline Tensor auto_scheduler_layout_transform(const Tensor& src, const String& src_layout,
+                                              const String& dst_layout,
+                                              const String name = "T_auto_scheduler_layout_trans",
+                                              const String tag = kInjective) {
+  Array<PrimExpr> src_shape;
+  std::vector<std::string> src_axes;
+  Array<PrimExpr> dst_shape;
+  std::vector<std::string> dst_axes;
+
+  parse_auto_scheduler_layout(src_layout, &src_shape, &src_axes);
+  parse_auto_scheduler_layout(dst_layout, &dst_shape, &dst_axes);
+  return compute(
+      dst_shape,
+      [&](const Array<Var>& dst_indices) {
+        Array<PrimExpr> dst_indices_expr(dst_indices.begin(), dst_indices.end());
+        Array<PrimExpr> src_indices;
+        for (const std::string& src_axis : src_axes) {
+          PrimExpr src_index = 0;
+          CHECK_EQ(dst_indices_expr.size(), dst_axes.size());
+          for (size_t i = 0; i < dst_axes.size(); ++i) {
+            if (dst_axes[i] == src_axis) {
+              src_index = src_index * dst_shape[i] + dst_indices_expr[i];
+            }
+          }
+          src_indices.push_back(src_index);
+        }
+        return src(src_indices);
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Transform the meta-schedule generated layout according to TIR's IndexMap
+ * \param src the source input.
+ * \param index_map The TIR IndexMap
+ * \param name output tensor name.
+ * \param tag output tensor tag.
+ * \return A tensor. The layout transformation method
+ * \note Example:
+ *
+ * For the indexing pattern below:
+ *
+ *  for i in range(32):
+ *    for j in range(64):
+ *      load A[
+ *        i / 16 *  4 + j / 16,
+ *        i % 16 * 16 + j % 16,
+ *      ]
+ *
+ *  The corresponding indexing pattern in TIR is:
+ *
+ *    A[i, j] => A'[i / 4, j / 16, i % 4, j % 16]
+ *
+ *  which converts the pattern to:
+ *
+ *  for i in range(32):
+ *    for j in range(64):
+ *      load A'[
+ *        i / 16 + j / 64,
+ *        i % 16,
+ *        j % 64 / 16,
+ *        j % 16,
+ *      ]
+ *
+ *  In this case, the transformation pattern is:
+ *    A'[a, b, c, d] = A[a * 4 + c, b * 16 + d]
+ */
+inline Tensor meta_schedule_layout_transform(const Tensor& src, const tir::IndexMap& index_map,
+                                             const String name = "T_meta_schedule_layout_trans",
+                                             const String tag = kInjective) {
+  Array<Range> iter_domain;
+  iter_domain.reserve(src->shape.size());
+  for (const PrimExpr& e : src->shape) {
+    iter_domain.push_back(Range::FromMinExtent(make_zero(e->dtype), e));
+  }
+  Array<PrimExpr> post_transform_shape = index_map->MapShape(src->shape);
+  return compute(
+      post_transform_shape,
+      [src, inv = index_map.Inverse(iter_domain)](const Array<Var>& indices) -> PrimExpr {
+        return src(inv->MapIndices(Array<PrimExpr>{indices.begin(), indices.end()}));
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Get the shape of input tensor.
+ * \param src the input tensor.
+ * \param dtype the type of the elements in the tensor.
+ * \param name output tensor name.
+ * \param tag output tensor tag.
+ * \return Tensor of input shape.
+ */
+inline Tensor shape(const Tensor& src, DataType dtype, const std::string name = "T_shape",
+                    const std::string tag = kInjective) {
+  int ndim = static_cast<int>(src->shape.size());
+  Array<PrimExpr> out_shape{ndim};
+  return compute(
+      out_shape,
+      [&](const Array<Var>& indices) {
+        auto idx = indices[0];
+        PrimExpr ret = 0;
+        for (int i = 0; i < ndim; ++i) {
+          ret = tvm::if_then_else(idx == i, src->shape[i], ret);
+        }
+        return tvm::cast(dtype, ret);
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Get the size of input tensor.
+ * \param src the input tensor.
+ * \param dtype the type of the elements in the tensor.
+ * \param name output tensor name.
+ * \param tag output tensor tag.
+ * \return Tensor of input shape.
+ */
+inline Tensor ndarray_size(const Tensor& src, const DataType& dtype,
+                           const std::string& name = "ndarray_size",
+                           const std::string& tag = kInjective) {
+  int ndim = static_cast<int>(src->shape.size());
+  Array<PrimExpr> out_ndarray_size = {};
+  return compute(
+      out_ndarray_size,
+      [&](const Array<Var>& indices) {
+        PrimExpr ret = 1;
+        for (int i = 0; i < ndim; ++i) {
+          ret *= src->shape[i];
+        }
+        return tvm::cast(dtype, ret);
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Returns a one-hot tensor where the locations repsented by indices take value on_value,
+    other locations take value off_value.
+ * \param indices locations to set to on_value.
+ * \param on_value value that locations represented by indices take on.
+ * \param off_value value that other locations take on.
+ * \param depth depth of the one-hot dimension.
+ * \param axis axis to fill.
+ * \param dtype data type of the output tensor.
+ * \param oshape shape of the output tensor.
+ * \param name output tensor name.
+ * \param tag output tensor tag.
+ * \return one-hot tensor.
+ */
+inline Tensor one_hot(const Tensor& indices, const PrimExpr on_value, const PrimExpr off_value,
+                      int depth, int axis, const DataType& dtype,
+                      Array<PrimExpr> oshape = Array<PrimExpr>(),
+                      const std::string name = "T_one_hot", const std::string tag = kInjective) {
+  int true_axis = (axis == -1) ? indices->shape.size() : axis;
+  if (oshape.size() == 0) {
+    int ndim = indices->shape.size() + 1;
+    int indices_index = 0;
+    for (int i = 0; i < ndim; i++) {
+      if (i == true_axis) {
+        oshape.push_back(Integer(depth));
+      } else {
+        oshape.push_back(indices->shape[indices_index++]);
+      }
+    }
+  }
+
+  PrimExpr on_value_cast = cast(dtype, on_value);
+  PrimExpr off_value_cast = cast(dtype, off_value);
+  return compute(
+      oshape,
+      [&](const Array<Var>& iter_vars) {
+        Array<Var> indices_indices;
+        for (size_t i = 0; i < iter_vars.size(); i++) {
+          if (static_cast<int>(i) == true_axis) {
+            continue;
+          }
+
+          indices_indices.push_back(iter_vars[i]);
+        }
+
+        auto idx = iter_vars[true_axis];
+        return tir::Select(indices(indices_indices) == idx, on_value_cast, off_value_cast);
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Get a dense tensor.
+ * \param sparse_indices sparse_indices[i] contains sparse_values[i] will be placed.
+ * \param output_shape is the shape of the dense output tensor .
+ * \param sparse_values is a 0-D or 1-D tensor. Values for each row of sparse_indices.
+ * \param default_value is a 0-D tensor. Defaults to zero.
+ * \param name output tensor name.
+ * \param tag output tensor tag.
+ * \return Tensor of output_shape.
+ */
+inline Tensor sparse_to_dense(const Tensor& sparse_indices, const Array<PrimExpr>& output_shape,
+                              const Tensor& sparse_values, const PrimExpr& default_value,
+                              const std::string name = "T_sparse_to_dense",
+                              const std::string tag = kInjective) {
+  ICHECK(sparse_indices->dtype.is_int()) << "sparse_indices only accepts integer values";
+  ICHECK_LE(sparse_indices->shape.size(), 3)
+      << "sparse_indices tensor should be 0D, 1D, or 2D only";
+  ICHECK_LE(sparse_values->shape.size(), 2) << "sparse_values tensor should be 0D or 1D only";
+
+  const auto rank_sparse_indices = static_cast<int>(sparse_indices->shape.size());
+  Array<PrimExpr> oshape;
+  for (auto l : output_shape) {
+    oshape.push_back(l);
+  }
+  return compute(
+      oshape,
+      [&](const Array<Var>& indices) {
+        PrimExpr ret = default_value;
+        if (0 == rank_sparse_indices) {
+          ret = if_then_else(indices[0] == sparse_indices(), sparse_values(), ret);
+        } else if (1 == rank_sparse_indices) {
+          for (int j = 0; j < GetConstInt(sparse_indices->shape[0]); j++) {
+            ret = if_then_else(indices[0] == sparse_indices[j], sparse_values[j], ret);
+          }
+        } else {
+          for (int j = 0; j < GetConstInt(sparse_indices->shape[0]); j++) {
+            PrimExpr aggregate_condition;
+            for (int k = 0; k < GetConstInt(sparse_indices->shape[1]); k++) {
+              PrimExpr comparision = indices[k] == sparse_indices[j][k];
+              aggregate_condition = 0 == k ? comparision : aggregate_condition && comparision;
+            }
+            ret = if_then_else(aggregate_condition, sparse_values[j], ret);
+          }
+        }
+        return ret;
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Returns a tensor with the diagonal of input tensor replaced with the provided diagonals.
+ * \param input input tensor.
+ * \param diagonal values to be filled in the diagonals.
+ * \param k1 lower limit (included) of the range of diagonals.
+ * \param k2 upper limit (included) of the range of diagonals.
+ * \param super_diag_right_align bool, true iff super-diagonal is right aligned (left-padded).
+ * \param sub_diag_right_align bool, true iff sub-diagonal is right aligned (left-padded).
+ * \param name output tensor name.
+ * \param tag output tensor tag.
+ * \return new tensor with given diagonal values.
+ */
+inline Tensor matrix_set_diag(const Tensor& input, const Tensor& diagonal, int k1, int k2,
+                              bool super_diag_right_align, bool sub_diag_right_align,
+                              const std::string name = "T_matrix_set_diag",
+                              const std::string tag = kInjective) {
+  size_t ndim = input->shape.size() - 1;
+
+  bool only_one_diagonal = k1 == k2;
+
+  return compute(
+      input->shape,
+      [&](const Array<Var>& iter_vars) {
+        auto get_diag = [&]() {
+          Array<PrimExpr> diagonal_indices;
+          PrimExpr k, offset = 0;
+          for (size_t i = 0; i < ndim - 1; i++) {
+            diagonal_indices.push_back(iter_vars[i]);
+          }
+          if (only_one_diagonal) {
+            k = k1;
+          } else {
+            // Determining which diagonal/sub-diagonal/super-diagonal it is
+            k = iter_vars[ndim] - iter_vars[ndim - 1];
+            diagonal_indices.push_back(k2 - k);
+
+            // Calculating the offset in diagonal tensor for this diagonal
+            auto get_offset = [&](PrimExpr M, PrimExpr N) {
+              // offset = max_diagonal_length - diagonal_length
+              return diagonal->shape[diagonal->shape.size() - 1] - if_then_else(M < N, M, N);
+            };
+            offset = if_then_else(
+                k >= 0,
+                super_diag_right_align ? get_offset(input->shape[ndim] - k, input->shape[ndim - 1])
+                                       : 0,
+                sub_diag_right_align ? get_offset(input->shape[ndim], input->shape[ndim - 1] + k)
+                                     : 0);
+          }
+          diagonal_indices.push_back(if_then_else(k >= 0, iter_vars[ndim - 1], iter_vars[ndim]) +
+                                     offset);
+          return diagonal(diagonal_indices);
+        };
+        return if_then_else((PrimExpr)iter_vars[ndim] - iter_vars[ndim - 1] >= k1,
+                            if_then_else((PrimExpr)iter_vars[ndim] - iter_vars[ndim - 1] <= k2,
+                                         get_diag(), input(iter_vars)),
+                            input(iter_vars));
+      },
+      name, tag);
+}
+
+/*!
+ * \brief Numpy style advanced indexing with tensor.
+ * \param data is input data.
+ * \param indices is list of indexing tensors.
+ * \param name output tensor name.
+ * \param tag output tensor tag.
+ * \return Output tensor.
+ */
+inline Tensor adv_index(const Tensor& data, const Array<Tensor>& indices,
+                        const std::string name = "advanced_index",
+                        const std::string tag = kInjective) {
+  ICHECK_LE(indices.size(), data->shape.size()) << "too many indices for data!";
+  Array<PrimExpr> oshape;
+  Array<PrimExpr> broadcast_shape;
+  Array<Tensor> bindices;
+
+  broadcast_shape = indices[0]->shape;
+  for (size_t i = 1; i < indices.size(); ++i) {
+    auto bh = detail::BroadcastShape(broadcast_shape, indices[i]->shape);
+    broadcast_shape = Array<PrimExpr>(bh.common_shape.begin(), bh.common_shape.end());
+  }
+  if (indices.size() == 1) {
+    // quick path
+    bindices = indices;
+  } else {
+    // Do broadcast for indices
+    for (size_t i = 0; i < indices.size(); ++i) {
+      bindices.push_back(broadcast_to(indices[i], broadcast_shape));
+    }
+  }
+
+  for (const auto& dim : broadcast_shape) {
+    oshape.push_back(dim);
+  }
+  for (size_t i = indices.size(); i < data->shape.size(); ++i) {
+    oshape.push_back(data->shape[i]);
+  }
+
+  return compute(
+      oshape,
+      [&](const Array<Var>& iter_var) {
+        Array<PrimExpr> tensor_indices;
+        for (size_t i = 0; i < broadcast_shape.size(); ++i) {
+          tensor_indices.push_back(iter_var[i]);
+        }
+
+        Array<PrimExpr> real_indices;
+        for (size_t i = 0; i < bindices.size(); ++i) {
+          real_indices.push_back(bindices[i](tensor_indices));
+        }
+        for (size_t i = broadcast_shape.size(); i < iter_var.size(); ++i) {
+          real_indices.push_back(iter_var[i]);
+        }
+
+        return data(real_indices);
+      },
+      name, tag);
+}
+
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_TRANSFORM_H_
diff --git a/darknet_drp_ros/include/tvm/topi/utils.h b/darknet_drp_ros/include/tvm/topi/utils.h
new file mode 100644
index 0000000..60dc3a6
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/utils.h
@@ -0,0 +1,47 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \brief Topi utility function
+ * \file topi/utils.h
+ */
+#ifndef TVM_TOPI_UTILS_H_
+#define TVM_TOPI_UTILS_H_
+
+#include <tvm/ir/expr.h>
+#include <tvm/runtime/packed_func.h>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::runtime;
+
+/*! \brief Canonicalize an argument that may be Array<Expr> or int to Array<Expr> */
+inline Array<Integer> ArrayOrInt(TVMArgValue arg) {
+  if (arg.type_code() == kDLInt || arg.type_code() == kDLUInt) {
+    Array<Integer> result;
+    result.push_back(arg.operator int());
+    return result;
+  } else {
+    return arg;
+  }
+}
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_UTILS_H_
diff --git a/darknet_drp_ros/include/tvm/topi/vision/reorg.h b/darknet_drp_ros/include/tvm/topi/vision/reorg.h
new file mode 100644
index 0000000..381272b
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/vision/reorg.h
@@ -0,0 +1,81 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \brief Reorg op constructions
+ * \file vision/reorg.h
+ */
+#ifndef TVM_TOPI_VISION_REORG_H_
+#define TVM_TOPI_VISION_REORG_H_
+
+#include <tvm/te/operation.h>
+#include <tvm/topi/detail/constant_utils.h>
+#include <tvm/topi/reduction.h>
+#include <tvm/topi/tags.h>
+#include <tvm/topi/transform.h>
+
+#include <algorithm>
+#include <string>
+
+namespace tvm {
+namespace topi {
+namespace vision {
+
+using namespace tvm::te;
+
+/*!
+ * \brief Reorg operation
+ *
+ * \param data The input tensor. Can be any dimension
+ * \param stride The input integer used as stride in reorg operation
+ * \param name The name of the operation
+ * \param tag The tag to mark the operation
+ *
+ * \return A Tensor whose op member is the reorg operation
+ */
+inline Tensor reorg(const Tensor& data, int stride = 1, std::string name = "tensor",
+                    std::string tag = "reorg_output") {
+  auto input_shape = data->shape;
+
+  int batch = GetConstInt(input_shape[0]);
+  int c_in = GetConstInt(input_shape[1]);
+  int h_in = GetConstInt(input_shape[2]);
+  int w_in = GetConstInt(input_shape[3]);
+  int out_c = c_in / (stride * stride);
+
+  auto out = tvm::te::compute(
+      input_shape,
+      [&](Var b, Var k, Var j, Var i) {
+        return data(b * stride * stride, indexmod(k, out_c) * stride * stride,
+                    (j * stride + indexdiv(indexdiv(k, out_c), stride)) * stride,
+                    (i * stride + indexmod(indexdiv(k, out_c), stride)));
+      },
+      name, tag);
+
+  out_c = c_in * stride * stride;
+  int out_h = h_in / stride;
+  int out_w = w_in / stride;
+
+  Array<PrimExpr> out_shape = {batch, out_c, out_h, out_w};
+  return reshape(out, out_shape);
+}
+}  // namespace vision
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_VISION_REORG_H_
diff --git a/darknet_drp_ros/include/tvm/topi/x86/bnn.h b/darknet_drp_ros/include/tvm/topi/x86/bnn.h
new file mode 100644
index 0000000..c8a7235
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/x86/bnn.h
@@ -0,0 +1,131 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file x86/bnn.h
+ * \brief x86 schedule for binary operations
+ */
+#ifndef TVM_TOPI_X86_BNN_H_
+#define TVM_TOPI_X86_BNN_H_
+
+#include <tvm/target/generic_func.h>
+#include <tvm/te/operation.h>
+#include <tvm/topi/detail/fuse.h>
+#include <tvm/topi/tags.h>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+
+namespace x86 {
+/*!
+ * \brief Create a generic schedule for binarize_pack
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+inline Schedule schedule_binarize_pack(const Target& target, const Array<Tensor>& outs) {
+  Array<Operation> out_ops;
+  for (auto t : outs) {
+    out_ops.push_back(t->op);
+  }
+  auto s = create_schedule(out_ops);
+
+  auto _schedule = [&](const Tensor& out) {
+    s[out].parallel(out->op.as<ComputeOpNode>()->axis[0]);
+  };
+
+  std::function<void(Operation)> traverse;
+  traverse = [&](const Operation& op) {
+    if (op->tag == "binarize_pack") {
+      _schedule(op.output(0));
+    } else {
+      LOG(ERROR) << "Unsupported operator " << op->tag;
+    }
+  };
+
+  traverse(outs[0]->op);
+  return s;
+}
+
+/*!
+ * \brief Create a generic schedule for binary_dense
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+inline Schedule schedule_binary_dense(const Target& target, const Array<Tensor>& outs) {
+  Array<Operation> out_ops;
+  for (auto t : outs) {
+    out_ops.push_back(t->op);
+  }
+  auto s = create_schedule(out_ops);
+
+  auto _schedule = [&](const Tensor& A, const Tensor& B, const Tensor& C) {
+    IterVar co, ci;
+    s[C].split(s[C]->op.as<ComputeOpNode>()->reduce_axis[0], 8, &co, &ci);
+    s[C].parallel(s[C]->op.as<ComputeOpNode>()->axis[0]);
+
+    Tensor out;
+    if (detail::contains(s->outputs, C->op)) {
+      out = C;
+    } else {
+      out = outs[0]->op.output(0);
+    }
+
+    IterVar xo, xi;
+    s[out].split(out->op.as<ComputeOpNode>()->axis[1], 8, &xo, &xi);
+    s[out].vectorize(xi);
+  };
+
+  std::function<void(Operation)> traverse;
+  traverse = [&](const Operation& op) {
+    // Inline all one-to-one-mapping operators except the last stage (output)
+    if (is_broadcast(op->tag)) {
+      if (!detail::contains(s->outputs, op)) {
+        s[op].compute_inline();
+      }
+      for (auto tensor : op->InputTensors()) {
+        if (tensor->op->InputTensors().size() > 0) {
+          traverse(tensor->op);
+        }
+      }
+    } else if (op->tag == "binary_dense") {
+      auto output = op.output(0);
+      auto data = op->InputTensors()[0];
+      auto weight = op->InputTensors()[1];
+      _schedule(data, weight, output);
+    } else {
+      LOG(ERROR) << "Unsupported operator " << op->tag;
+    }
+  };
+
+  traverse(outs[0]->op);
+  return s;
+}
+
+}  // namespace x86
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_X86_BNN_H_
diff --git a/darknet_drp_ros/include/tvm/topi/x86/default.h b/darknet_drp_ros/include/tvm/topi/x86/default.h
new file mode 100644
index 0000000..9c98560
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/x86/default.h
@@ -0,0 +1,105 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file x86/default.h
+ * \brief default x86 schedule
+ */
+#ifndef TVM_TOPI_X86_DEFAULT_H_
+#define TVM_TOPI_X86_DEFAULT_H_
+
+#include <tvm/target/generic_func.h>
+#include <tvm/te/operation.h>
+#include <tvm/te/schedule_pass.h>
+#include <tvm/topi/detail/fuse.h>
+#include <tvm/topi/tags.h>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+
+namespace x86 {
+/*!
+ * \brief Helper to create a default x86 schedule for the given ops.
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ * \param auto_inline Whether to apply the auto inline step.
+ *
+ * \return A schedule for the given ops.
+ */
+inline Schedule MakeDefaultSchedule(const Target& target, const Array<Tensor>& outs,
+                                    bool auto_inline) {
+  Array<Operation> out_ops;
+  for (auto t : outs) {
+    out_ops.push_back(t->op);
+  }
+  auto s = create_schedule(out_ops);
+  auto x = outs[0];
+  auto axis = s[x]->op.as<ComputeOpNode>()->axis;
+
+  if (auto_inline) {
+    tvm::te::AutoInlineInjective(s);
+    if (axis.size() > 0) {
+      detail::Fuse(s[x], axis);
+    }
+    return s;
+  }
+
+  if (axis.size() == 4) {
+    auto n = axis[0];
+    auto c = axis[1];
+    auto fused = detail::Fuse(s[x], {n, c});  // for nhwc layout, fuse n and h
+    s[x].parallel(fused);
+  } else {
+    s[x].parallel(axis[0]);
+  }
+
+  return s;
+}
+
+/*!
+ * \brief Create a default x86 schedule for the given ops.
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+inline Schedule default_schedule(const Target& target, const Array<Tensor>& outs) {
+  return MakeDefaultSchedule(target, outs, false);
+}
+
+/*!
+ * \brief Create a default x86 schedule for the given ops, with auto inline
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+inline Schedule default_schedule_auto_inline(const Target& target, const Array<Tensor>& outs) {
+  return MakeDefaultSchedule(target, outs, true);
+}
+
+}  // namespace x86
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_X86_DEFAULT_H_
diff --git a/darknet_drp_ros/include/tvm/topi/x86/injective.h b/darknet_drp_ros/include/tvm/topi/x86/injective.h
new file mode 100644
index 0000000..16eaee6
--- /dev/null
+++ b/darknet_drp_ros/include/tvm/topi/x86/injective.h
@@ -0,0 +1,85 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+/*!
+ * \file x86/injective.h
+ * \brief x86 schedule for injective ops
+ */
+#ifndef TVM_TOPI_X86_INJECTIVE_H_
+#define TVM_TOPI_X86_INJECTIVE_H_
+
+#include <tvm/target/generic_func.h>
+#include <tvm/te/operation.h>
+#include <tvm/topi/detail/fuse.h>
+#include <tvm/topi/tags.h>
+
+namespace tvm {
+namespace topi {
+
+using namespace tvm::te;
+
+namespace x86 {
+
+/*!
+ * \brief Updates an existing schedule for the given injective ops.
+ *
+ * \param sch The schedule to update.
+ * \param out The tensor representing the injective op.
+ *
+ * \return The updated schedule.
+ */
+inline Schedule schedule_injective_from_existing(Schedule sch, const Tensor& out) {
+  auto axis = sch[out]->op.as<ComputeOpNode>()->axis;
+  if (axis.size() == 4) {
+    auto n = axis[0];
+    auto c = axis[1];
+    auto fused = detail::Fuse(sch[out], {n, c});  // for nhwc layout, fuse n and h
+    sch[out].parallel(fused);
+  } else {
+    sch[out].parallel(axis[0]);
+  }
+  return sch;
+}
+
+/*!
+ * \brief Create an x86 schedule for the given injective ops.
+ *
+ * \param target The target to generate a schedule for.
+ * \param outs The output tensors.
+ *
+ * \return A schedule for the given ops.
+ */
+inline Schedule schedule_injective(const Target& target, const Array<Tensor>& outs) {
+  Array<Operation> out_ops;
+  for (auto t : outs) {
+    out_ops.push_back(t->op);
+  }
+  auto s = create_schedule(out_ops);
+  tvm::te::AutoInlineInjective(s);
+
+  auto x = outs[0];
+  schedule_injective_from_existing(s, x);
+
+  return s;
+}
+
+}  // namespace x86
+}  // namespace topi
+}  // namespace tvm
+#endif  // TVM_TOPI_X86_INJECTIVE_H_
diff --git a/darknet_drp_ros/launch/darknet_drp_ros_launch.py b/darknet_drp_ros/launch/darknet_drp_ros_launch.py
new file mode 100644
index 0000000..f1ae8ca
--- /dev/null
+++ b/darknet_drp_ros/launch/darknet_drp_ros_launch.py
@@ -0,0 +1,23 @@
+import os
+
+from ament_index_python.packages import get_package_share_directory
+
+from launch import LaunchDescription
+from launch.actions import DeclareLaunchArgument, IncludeLaunchDescription, SetEnvironmentVariable
+from launch.launch_description_sources import PythonLaunchDescriptionSource
+from launch.substitutions import LaunchConfiguration
+from launch_ros.actions import Node
+
+def generate_launch_description():
+
+  drpai_cmd = Node(
+    package='darknet_drp_ros',
+    executable='darknet_drp_ros',
+    name='darknet_drp_ros',
+    output='screen')
+
+  ld = LaunchDescription()
+
+  ld.add_action(drpai_cmd)
+
+  return ld
diff --git a/darknet_ros/package.xml b/darknet_drp_ros/package.xml
similarity index 94%
rename from darknet_ros/package.xml
rename to darknet_drp_ros/package.xml
index 9df4490..fd6f58c 100644
--- a/darknet_ros/package.xml
+++ b/darknet_drp_ros/package.xml
@@ -1,7 +1,7 @@
 <?xml version="1.0"?>
 <?xml-model href="http://download.ros.org/schema/package_format3.xsd" schematypens="http://www.w3.org/2001/XMLSchema"?>
 <package format="3">
-  <name>darknet_ros</name>
+  <name>darknet_drp_ros</name>
   <version>1.1.4</version>
   <description>Darknet is an open source neural network framework that runs on CPU and GPU. You only look once (YOLO) is a state-of-the-art, real-time object detection system.</description>
   <maintainer email="marko.bjelonic@mavt.ethz.ch">Marko Bjelonic</maintainer>
@@ -18,7 +18,6 @@
   <depend>image_transport</depend>
   <depend>cv_bridge</depend>
   <depend>sensor_msgs</depend>
-  <depend>darknet_ros_msgs</depend>
   <depend>ament_index_cpp</depend>
 
   <test_depend>ament_lint_common</test_depend>
diff --git a/darknet_drp_ros/src/MeraDrpRuntimeWrapper.cpp b/darknet_drp_ros/src/MeraDrpRuntimeWrapper.cpp
new file mode 100644
index 0000000..cce238b
--- /dev/null
+++ b/darknet_drp_ros/src/MeraDrpRuntimeWrapper.cpp
@@ -0,0 +1,231 @@
+/*
+ * Original Code (C) Copyright Edgecortix, Inc. 2022
+ * Modified Code (C) Copyright Renesas Electronics Corporation 2023　
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ *
+ */
+#include <tvm/runtime/module.h>
+#include <tvm/runtime/packed_func.h>
+#include <tvm/runtime/registry.h>
+#include <tvm/runtime/profiling.h>
+
+#include <fstream>
+#include <regex>
+#include <dirent.h>
+#include "MeraDrpRuntimeWrapper.h"
+
+// ROS
+#include "rclcpp/rclcpp.hpp"
+
+template <typename T>
+static std::vector<T> LoadBinary(const std::string& bin_file) {
+  std::ifstream file(bin_file.c_str(), std::ios::in | std::ios::binary);
+  if (!file.is_open()) {
+    RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "unable to open file %s", bin_file.c_str());
+  }
+
+  file.seekg(0, file.end);
+  const uint32_t file_size = static_cast<uint32_t>(file.tellg());
+  file.seekg(0, file.beg);
+
+  const auto file_buffer = std::unique_ptr<char>(new char[file_size]);
+  file.read(file_buffer.get(), file_size);
+
+  if (file.bad() || file.fail()) {
+    RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "error occured while reading the file");
+  }
+
+  file.close();
+
+  auto ptr = reinterpret_cast<T*>(file_buffer.get());
+  const auto num_elements = file_size / sizeof(T);
+  return std::vector<T>(ptr, ptr + num_elements);
+}
+
+MeraDrpRuntimeWrapper::MeraDrpRuntimeWrapper() {
+  //device_type = kDLCPU;
+  device_type = kDLDrpAi;
+  device_id = 0;
+};
+
+MeraDrpRuntimeWrapper::~MeraDrpRuntimeWrapper() = default;
+
+bool MeraDrpRuntimeWrapper::LoadModel(const std::string& model_dir, uint32_t start_address){
+    device_type = kDLCPU;
+
+    return LoadModel(model_dir, (uint64_t)start_address);
+}
+
+bool MeraDrpRuntimeWrapper::LoadModel(const std::string& model_dir, uint64_t start_address = 0x00) {
+    RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "Loading json data...");
+    const std::string json_file(model_dir + "/deploy.json");
+    std::ifstream json_in(json_file.c_str(), std::ios::in);
+    std::string json_data((std::istreambuf_iterator<char>(json_in)), std::istreambuf_iterator<char>());
+    json_in.close();
+
+    #if 0
+    if(json_data.find("drp") == json_data.npos && device_type != kDLCPU){
+        LOG(INFO) <<"Break! this model is Not for DRP-AI retry as CPU Only";
+        return false;
+    }
+    #else
+    if(json_data.find("drp") == json_data.npos && device_type != kDLCPU){
+        LOG(INFO) <<"try as CPU Only";
+        device_type = kDLCPU;
+    }
+    #endif
+
+    RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "Loading runtime module...");
+    tvm::runtime::Module mod_syslib = tvm::runtime::Module::LoadFromFile(model_dir + "/deploy.so");
+    mod = (*tvm::runtime::Registry::Get("tvm.graph_executor_debug.create"))(
+      json_data, mod_syslib, device_type, device_id);
+
+    RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "Loading parameters...");
+    tvm::runtime::PackedFunc load_params = mod.GetFunction("load_params");
+    auto params_data = LoadBinary<char>(model_dir + "/deploy.params");
+    TVMByteArray params_arr;
+    params_arr.data = params_data.data();
+    params_arr.size = params_data.size();
+    load_params(params_arr);
+    tvm::runtime::PackedFunc set_start_address = mod.GetFunction("set_start_address");
+    if(set_start_address != nullptr){
+      set_start_address(start_address);
+    }
+    return true;
+}
+
+template <typename T>
+void MeraDrpRuntimeWrapper::SetInput(int input_index, const T* data_ptr) {
+    RCLCPP_DEBUG(rclcpp::get_logger("darknet_drp_ros"), "Loading input...");
+
+    tvm::runtime::PackedFunc get_input = mod.GetFunction("get_input");
+    tvm::runtime::NDArray xx = get_input(input_index);
+    auto in_shape = xx.Shape();
+    int64_t in_size = 1;
+    for (unsigned long i = 0; i < in_shape.size(); ++i) {
+      in_size *= in_shape[i];
+    }
+
+    DLDevice ctx;
+    ctx.device_id = device_id;
+    ctx.device_type = DLDeviceType(device_type);
+
+    auto input_array = tvm::runtime::NDArray::Empty(in_shape, xx.DataType(), ctx);
+    auto input_data = (T*)(input_array->data);
+    std::memcpy(input_data, data_ptr, sizeof(T) * in_size);
+    tvm::runtime::PackedFunc set_input = mod.GetFunction("set_input");
+    set_input(input_index, input_array);
+}
+template void MeraDrpRuntimeWrapper::SetInput<float>(int input_index, const float*);
+template void MeraDrpRuntimeWrapper::SetInput<unsigned short>(int input_index, const unsigned short*);
+
+void MeraDrpRuntimeWrapper::Run() {
+    mod.GetFunction("run")();
+}
+
+void MeraDrpRuntimeWrapper::Run(int freq_index) {
+    mod.GetFunction("run")(freq_index);
+}
+
+void MeraDrpRuntimeWrapper::ProfileRun(const std::string& profile_table, const std::string& profile_csv) {
+    tvm::runtime::PackedFunc profile = mod.GetFunction("profile");
+    tvm::runtime::Array<tvm::runtime::profiling::MetricCollector> collectors;
+    tvm::runtime::profiling::Report report = profile(collectors);
+
+    std::string rep_table = report->AsTable();
+    std::ofstream ofs_table (profile_table, std::ofstream::out);
+    ofs_table << rep_table << std::endl;
+    ofs_table.close();
+
+    std::string rep_csv = report->AsCSV();
+    std::ofstream ofs_csv (profile_csv, std::ofstream::out);
+    ofs_csv << rep_csv << std::endl;
+    ofs_csv.close();
+}
+
+void MeraDrpRuntimeWrapper::ProfileRun(const std::string& profile_table, const std::string& profile_csv, int freq_index) {
+    tvm::runtime::PackedFunc profile = mod.GetFunction("profile");
+    tvm::runtime::Array<tvm::runtime::profiling::MetricCollector> collectors;
+    tvm::runtime::profiling::Report report = profile(collectors, freq_index);
+
+    std::string rep_table = report->AsTable();
+    std::ofstream ofs_table (profile_table, std::ofstream::out);
+    ofs_table << rep_table << std::endl;
+    ofs_table.close();
+
+    std::string rep_csv = report->AsCSV();
+    std::ofstream ofs_csv (profile_csv, std::ofstream::out);
+    ofs_csv << rep_csv << std::endl;
+    ofs_csv.close();
+}
+
+int MeraDrpRuntimeWrapper::GetNumInput(std::string model_dir) {
+    // TVM does not support api to get number input of model.
+    // This function calculate input number base on convention
+    // of input data name (input_xyz.bin)
+    DIR *dir;
+    dirent *diread;
+    int num_input = 0;
+    if ((dir = opendir(model_dir.c_str())) != nullptr) {
+      while ((diread = readdir(dir)) != nullptr) {
+        std::string file_name(diread->d_name);
+        if (std::regex_match(file_name, std::regex("(input_)(.*)(bin)") )) {
+          num_input++;
+        }
+      }
+      closedir(dir);
+    } else {
+      RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "Can not open model dir : %s", model_dir.c_str());
+    }
+
+    return num_input;
+}
+
+InOutDataType MeraDrpRuntimeWrapper::GetInputDataType(int index) {
+    tvm::runtime::PackedFunc get_input = mod.GetFunction("get_input");
+    tvm::runtime::NDArray input_info = get_input(index);
+    InOutDataType data_type = InOutDataType::OTHER;
+    if (input_info.DataType().is_float() && input_info.DataType().bits() == 32) {
+      data_type = InOutDataType::FLOAT32;
+    } else if (input_info.DataType().is_float() && input_info.DataType().bits() == 16) {
+      data_type = InOutDataType::FLOAT16;
+    }
+    return data_type;
+  }
+
+int MeraDrpRuntimeWrapper::GetNumOutput() {
+    return mod.GetFunction("get_num_outputs")();
+  }
+
+std::tuple<InOutDataType, void*, int64_t> MeraDrpRuntimeWrapper::GetOutput(int index) {
+    tvm::runtime::PackedFunc get_output = mod.GetFunction("get_output");
+    tvm::runtime::NDArray out = get_output(index);
+    int64_t out_size = 1;
+    for ( unsigned long i = 0; i < out.Shape().size(); ++i) {
+      out_size *= out.Shape()[i];
+    }
+
+    InOutDataType data_type = InOutDataType::OTHER;
+    if (out.DataType().is_float() && out.DataType().bits() == 32) {
+      data_type = InOutDataType::FLOAT32;
+    } else if (out.DataType().is_float() && out.DataType().bits() == 16) {
+      data_type = InOutDataType::FLOAT16;
+    }
+    return std::make_tuple(data_type, reinterpret_cast<void*>(out->data), out_size);
+}
diff --git a/darknet_drp_ros/src/MeraDrpRuntimeWrapper.h b/darknet_drp_ros/src/MeraDrpRuntimeWrapper.h
new file mode 100644
index 0000000..8e2465f
--- /dev/null
+++ b/darknet_drp_ros/src/MeraDrpRuntimeWrapper.h
@@ -0,0 +1,54 @@
+/*
+ * Original Code (C) Copyright Edgecortix, Inc. 2022
+ * Modified Code (C) Copyright Renesas Electronics Corporation 2023　
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ *
+*/
+#include <tvm/runtime/module.h>
+
+enum class InOutDataType {
+  FLOAT32,
+  FLOAT16,
+  OTHER
+};
+
+class MeraDrpRuntimeWrapper {
+ public:
+  MeraDrpRuntimeWrapper();
+  ~MeraDrpRuntimeWrapper();
+
+  bool LoadModel(const std::string& model_dir, uint32_t start_address);
+  bool LoadModel(const std::string& model_dir, uint64_t start_address);
+  template <typename T>
+  void SetInput(int input_index, const T* data_ptr);
+  void Run();
+  void Run(int freq_index);
+  void ProfileRun(const std::string& profile_table, const std::string& profile_csv);
+  void ProfileRun(const std::string& profile_table, const std::string& profile_csv, int freq_index);
+  int GetNumInput(std::string model_dir);
+  InOutDataType GetInputDataType(int index);
+  int GetNumOutput();
+
+  std::tuple<InOutDataType, void*, int64_t> GetOutput(int index);
+
+ private:
+  int device_type;
+  int device_id;
+  tvm::runtime::Module mod;
+};
diff --git a/darknet_drp_ros/src/PreRuntime.h b/darknet_drp_ros/src/PreRuntime.h
new file mode 100644
index 0000000..af2e9a6
--- /dev/null
+++ b/darknet_drp_ros/src/PreRuntime.h
@@ -0,0 +1,473 @@
+/*
+ * Original Code (C) Copyright Renesas Electronics Corporation 2023
+ *　
+ *  *1 DRP-AI TVM is powered by EdgeCortix MERA(TM) Compiler Framework.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ *
+ */
+
+/***********************************************************************************************************************
+* File Name    : PreRuntime.h
+* Version      : 1.1.0
+* Description  : PreRuntime Header file
+***********************************************************************************************************************/
+#pragma once
+
+#ifndef PRERUNTIME_H
+#define PRERUNTIME_H
+/***********************************************************************************************************************
+* Include
+***********************************************************************************************************************/
+#include <linux/drpai.h>
+#include <iostream>
+#include <fstream>
+#include <cstdio>
+#include <string>
+#include <stdio.h>
+#include <stdlib.h>
+#include <unistd.h>
+#include <fcntl.h>
+#include <sys/ioctl.h>
+#include <sys/mman.h>
+#include <sys/stat.h>
+#include <termios.h>
+#include <errno.h>
+#include <vector>
+#include <map>
+#include <fstream>
+#include <iostream>
+#include <iomanip>
+#include <string>
+#include <unordered_map>
+#include <cstring>
+#include <float.h>
+#include <signal.h>
+#include <cmath>
+
+#include <builtin_fp16.h>
+/***********************************************************************************************************************
+* Macro
+***********************************************************************************************************************/
+#define BUF_SIZE        (1024)
+#define NUM_OBJ_FILE    (6)
+#define INDEX_I         (0)
+#define INDEX_D         (1)
+#define INDEX_C         (2)
+#define INDEX_P         (3)
+#define INDEX_A         (4)
+#define INDEX_W         (5)
+#define DRPAI_TIMEOUT   (5)
+
+/*Uncomment to enable displaying the debug console log*/
+// #define DEBUG_LOG
+
+/*Error List*/
+#define PRE_SUCCESS         (0)
+#define PRE_ERROR           (1)
+#define PRE_ERROR_UI        (-1)
+
+/* Library Name */
+#define LIB_CONVYUV2RGB     ("conv_yuv2rgb")
+#define LIB_RESIZE_HWC      ("resize_hwc")
+#define LIB_IMAGESCALER     ("imagescaler")
+#define LIB_TRANSPOSE       ("transpose")
+#define LIB_CASTFP16_FP32   ("cast_fp16_fp32")
+#define LIB_CONVX2GRAY      ("conv_x2gray")
+#define LIB_CROP            ("crop")
+#define LIB_ARGMINMAX       ("argminmax")
+
+/* Param Info ID */
+#define OP_HEAD             ("OFFSET_ADD:")
+#define OP_LAYER_NAME       ("layer_name:")
+#define OP_LIB              ("drp_lib:")
+#define PRAM_HEAD           ("Param:")
+#define PARAM_VALUE         ("Value:")
+#define PARAM_OFFSET        ("offset:")
+#define PARAM_SIZE          ("size:")
+
+/* Param name */
+#define P_RADDR             ("raddr")
+#define P_WADDR             ("waddr")
+#define P_IMG_IWIDTH        ("IMG_IWIDHT")
+#define P_IMG_IHEIGHT       ("IMG_IHEIGHT")
+#define P_IMG_OWIDTH        ("IMG_OWIDTH")
+#define P_IMG_OHEIGHT       ("IMG_OHEIGHT")
+#define P_INPUT_YUV_FORMAT  ("INPUT_YUV_FORMAT")
+#define P_DOUT_RGB_FORMAT   ("DOUT_RGB_FORMAT")
+#define P_RESIZE_ALG        ("RESIZE_ALG")
+#define P_DATA_TYPE         ("DATA_TYPE")
+#define P_ADD_ADDR          ("ADD_ADDR")
+#define P_MUL_ADDR          ("MUL_ADDR")
+#define P_DOUT_RGB_ORDER    ("DOUT_RGB_ORDER")
+#define P_WORD_SIZE         ("WORD_SIZE")
+#define P_IS_CHW2HWC        ("IS_CHW2HWC")
+#define P_CAST_MODE         ("CAST_MODE")
+#define P_CROP_POS_X        ("CROP_POS_X")
+#define P_CROP_POS_Y        ("CROP_POS_Y")
+#define P_DIN_FORMAT        ("DIN_FORMAT")
+#define P_DOUT_RGB_FORMAT   ("DOUT_RGB_FORMAT")
+#define P_IMG_ICH           ("IMG_ICH")
+#define P_IMG_OCH           ("IMG_OCH")
+
+/* Other related values */
+#define FORMAT_YUYV_422     (0x0000)
+#define FORMAT_YVYU_422     (0x0001)
+#define FORMAT_UYUV_422     (0x0002)
+#define FORMAT_VUYY_422     (0x0003)
+#define FORMAT_YUYV_420     (0x1000)
+#define FORMAT_UYVY_420     (0x1001)
+#define FORMAT_YV12_420     (0x1002)
+#define FORMAT_IYUV_420     (0x1003)
+#define FORMAT_NV12_420     (0x1004)
+#define FORMAT_NV21_420     (0x1005)
+#define FORMAT_IMC1_420     (0x1006)
+#define FORMAT_IMC2_420     (0x1007)
+#define FORMAT_IMC3_420     (0x1008)
+#define FORMAT_IMC4_420     (0x1009)
+#define FORMAT_GRAY         (0xFFFC)
+#define FORMAT_BGR          (0xFFFD)
+#define FORMAT_RGB          (0xFFFE)
+#define FORMAT_UNKNOWN      (0xFFFF)
+
+/* Format in string. Only used when DEBUG_LOG is ON */
+#define FORMAT_YUYV_422_STR ("YUYV_422")
+#define FORMAT_YVYU_422_STR ("YVYU_422")
+#define FORMAT_UYUV_422_STR ("UYUV_422")
+#define FORMAT_VUYY_422_STR ("VUYY_422")
+#define FORMAT_YUYV_420_STR ("YVYU_420")
+#define FORMAT_UYVY_420_STR ("UYVY_420")
+#define FORMAT_YV12_420_STR ("YV12_420")
+#define FORMAT_IYUV_420_STR ("IYUV_420")
+#define FORMAT_NV12_420_STR ("NV12_420")
+#define FORMAT_NV21_420_STR ("NV21_420")
+#define FORMAT_IMC1_420_STR ("IMC1_420")
+#define FORMAT_IMC2_420_STR ("IMC2_420")
+#define FORMAT_IMC3_420_STR ("IMC3_420")
+#define FORMAT_IMC4_420_STR ("IMC4_420")
+#define FORMAT_GRAY_STR     ("GRAY")
+#define FORMAT_BGR_STR      ("BGR")
+#define FORMAT_RGB_STR      ("RGB")
+#define FORMAT_UNKNOWN_STR  ("UNKNOWN")
+/* Format in string. Only used when DEBUG_LOG is ON */
+static const std::unordered_map<uint16_t, std::string> format_string_table = 
+{ 
+    {FORMAT_YUYV_422, FORMAT_YUYV_422_STR},
+    {FORMAT_YVYU_422 , FORMAT_YVYU_422_STR},
+    {FORMAT_UYUV_422 , FORMAT_UYUV_422_STR},
+    {FORMAT_VUYY_422 , FORMAT_VUYY_422_STR},
+    {FORMAT_YUYV_420 , FORMAT_YUYV_420_STR},
+    {FORMAT_UYVY_420 , FORMAT_UYVY_420_STR},
+    {FORMAT_YV12_420 , FORMAT_YV12_420_STR},
+    {FORMAT_IYUV_420 , FORMAT_IYUV_420_STR},
+    {FORMAT_NV12_420 , FORMAT_NV12_420_STR},
+    {FORMAT_NV21_420 , FORMAT_NV21_420_STR},
+    {FORMAT_IMC1_420 , FORMAT_IMC1_420_STR},
+    {FORMAT_IMC2_420 , FORMAT_IMC2_420_STR},
+    {FORMAT_IMC3_420 , FORMAT_IMC3_420_STR},
+    {FORMAT_IMC4_420 , FORMAT_IMC4_420_STR},
+    {FORMAT_GRAY , FORMAT_GRAY_STR},
+    {FORMAT_BGR , FORMAT_BGR_STR},
+    {FORMAT_RGB , FORMAT_RGB_STR},
+    {FORMAT_UNKNOWN , FORMAT_UNKNOWN_STR}
+};
+
+/*If FORMAT_* >> BIT_YUV is 1, YUV420.
+  If 0, YUV422. 
+  >1 otherwise.*/
+#define BIT_YUV             (12)
+
+#define DIN_FORMAT_RGB      (0x1000)
+#define DIN_FORMAT_BGR      (0x1001)
+
+#define NUM_C_YUV           (2)
+#define NUM_C_RGB_BGR       (3)
+#define NUM_C_GRAY          (1)
+
+#define ALG_NEAREST         (0)
+#define ALG_BILINEAR        (1)
+#define INVALID_ADDR        (0xFFFFFFFF)
+#define INVALID_SHAPE       (0xFFFF)
+#define INVALID_FORMAT      (FORMAT_UNKNOWN)
+#define INVALID_RESIZE_ALG  (0xFF)
+
+#define MIN_INPUT_W_BOUND   (0)
+#define MIN_INPUT_H_BOUND   (0)
+#define MIN_RESIZE_W_BOUND  (2)
+#define MIN_RESIZE_H_BOUND  (2)
+#define MAX_RESIZE_W_BOUND  (4096)
+#define MAX_RESIZE_H_BOUND  (4096)
+#define MIN_CROP_W_BOUND    (0)
+#define MIN_CROP_H_BOUND    (0)
+
+#define MODE_PRE            (0)
+#define MODE_POST           (1)
+/***********************************************************************************************************************
+* Struct and related function
+***********************************************************************************************************************/
+
+/* For dynamic allocation support of DRP-AI Object files */
+typedef struct
+{
+    std::string   directory_name;
+    uint64_t      start_address;
+    unsigned long object_files_size;
+    unsigned long data_in_addr;
+    unsigned long data_in_size;
+    unsigned long data_out_addr;
+    unsigned long data_out_size;
+} st_drpai_data_t;
+
+typedef struct
+{
+    unsigned long desc_aimac_addr;
+    unsigned long desc_aimac_size;
+    unsigned long desc_drp_addr;
+    unsigned long desc_drp_size;
+    unsigned long drp_param_addr;
+    unsigned long drp_param_size;
+    unsigned long data_in_addr;
+    unsigned long data_in_size;
+    unsigned long data_addr;
+    unsigned long data_size;
+    unsigned long work_addr;
+    unsigned long work_size;
+    unsigned long data_out_addr;
+    unsigned long data_out_size;
+    unsigned long drp_config_addr;
+    unsigned long drp_config_size;
+    unsigned long weight_addr;
+    unsigned long weight_size;
+    unsigned long aimac_param_cmd_addr;
+    unsigned long aimac_param_cmd_size;
+    unsigned long aimac_param_desc_addr;
+    unsigned long aimac_param_desc_size;
+    unsigned long aimac_cmd_addr;
+    unsigned long aimac_cmd_size;
+} st_addr_info_t;
+
+
+typedef struct
+{
+    int             drpai_fd = -1;
+    st_drpai_data_t data_inout;
+    st_addr_info_t  drpai_address;
+} drpai_handle_t;
+
+typedef struct
+{
+    uint16_t pre_in_shape_w = INVALID_SHAPE;
+    uint16_t pre_in_shape_h = INVALID_SHAPE;
+    uint64_t pre_in_addr    = INVALID_ADDR;
+    uint16_t pre_in_format  = INVALID_FORMAT;
+    uint16_t pre_out_format = INVALID_FORMAT;
+    uint8_t resize_alg      = INVALID_RESIZE_ALG;
+    uint16_t resize_w       = INVALID_SHAPE;
+    uint16_t resize_h       = INVALID_SHAPE;
+    float cof_add[3]        = { -FLT_MAX, -FLT_MAX, -FLT_MAX };
+    float cof_mul[3]        = { -FLT_MAX, -FLT_MAX, -FLT_MAX };
+    uint16_t crop_tl_x      = INVALID_SHAPE;
+    uint16_t crop_tl_y      = INVALID_SHAPE;
+    uint16_t crop_w         = INVALID_SHAPE;
+    uint16_t crop_h         = INVALID_SHAPE;
+} s_preproc_param_t;
+
+typedef struct
+{
+    std::string name;
+    uint32_t value;
+    uint16_t offset;
+    uint16_t size;
+} s_op_param_t;
+
+typedef struct
+{
+    std::string name;
+    std::string lib;
+    uint16_t offset;
+    std::vector<s_op_param_t> param_list;
+} s_op_t;
+
+static void clear_param(s_op_param_t* data)
+{
+    data->name = "";
+    data->value = 0;
+    data->offset = 0;
+    data->size = 0;
+}
+
+static void clear_op(s_op_t* data)
+{
+    data->name = "";
+    data->lib = "";
+    data->offset = 0;
+    data->param_list.clear();
+}
+
+static std::string setW(std::string const &str, int n)
+{
+    std::ostringstream oss;
+    oss << std::left<<std::setw(n) << str;
+    return oss.str();
+}
+static void print_preproc_param(const s_preproc_param_t data, uint8_t mode=MODE_PRE)
+{
+    std::cout <<"PreProcessing Parameter List " <<std::endl;
+    std::cout <<"  pre_in_shape_w = "<<std::setw(8)<<std::dec<<data.pre_in_shape_w <<std::endl;
+    std::cout <<"  pre_in_shape_h = "<<std::setw(8)<<std::dec<<data.pre_in_shape_h <<std::endl;
+    std::cout <<"  pre_in_addr    = "<<std::setw(8)<<std::hex <<data.pre_in_addr <<std::endl;
+    if (!mode)
+    {
+        std::cout <<"  pre_in_format  = "<<std::setw(8)<<std::hex <<data.pre_in_format <<"("<<format_string_table.at(data.pre_in_format)<<")"<<std::endl;
+        std::cout <<"  pre_out_format = "<<std::setw(8)<<std::hex <<data.pre_out_format <<"("<<format_string_table.at(data.pre_out_format)<<")"<<std::endl;
+        std::cout <<"  resize_alg     = "<<std::setw(8)<<std::dec <<(int) data.resize_alg <<std::endl;
+        std::cout <<"  resize_w       = "<<std::setw(8)<<std::dec <<(int) data.resize_w <<std::endl;
+        std::cout <<"  resize_h       = "<<std::setw(8)<<std::dec <<(int) data.resize_h <<std::endl;
+        std::cout <<"  cof_add        = ";
+        std::cout << std::fixed<<std::setw(5)<<std::setprecision(4)<<(float)data.cof_add[0];
+        if (FORMAT_GRAY !=data.pre_out_format)
+        {
+            std::cout <<", "<< std::setw(5)<<std::setprecision(4)<<(float)data.cof_add[1];
+            std::cout <<", "<< std::setw(5)<<std::setprecision(4)<<(float)data.cof_add[2];
+        }
+        std::cout << std::endl <<"  cof_mul        = ";
+        std::cout << std::fixed<<std::setw(5)<<std::setprecision(4)<<(float)data.cof_mul[0];
+        if (FORMAT_GRAY !=data.pre_out_format)
+        {
+            std::cout << ", "<<std::setw(5)<<std::setprecision(4)<<(float)data.cof_mul[1];
+            std::cout << ", "<<std::setw(5)<<std::setprecision(4)<<(float)data.cof_mul[2];
+        }
+        std::cout << std::endl;
+        std::cout <<"  crop_tl_x      = "<<std::setw(8)<<std::dec <<(int) data.crop_tl_x <<std::endl;
+        std::cout <<"  crop_tl_y      = "<<std::setw(8)<<std::dec <<(int) data.crop_tl_y <<std::endl;
+        std::cout <<"  crop_w         = "<<std::setw(8)<<std::dec <<(int) data.crop_w <<std::endl;
+        std::cout <<"  crop_h         = "<<std::setw(8)<<std::dec <<(int) data.crop_h <<std::endl;
+    }
+}
+
+/***********************************************************************************************************************
+* PreRuntime Class
+***********************************************************************************************************************/
+class PreRuntime {
+    public:
+        PreRuntime();
+        ~PreRuntime();
+
+        uint8_t Load(const std::string pre_dir, uint64_t start_addr);
+        uint8_t Load(const std::string pre_dir, uint32_t start_addr = INVALID_ADDR, uint8_t mode = MODE_PRE);
+        int     SetInput(void *indata);
+        uint8_t Pre(s_preproc_param_t* param, void** out_ptr, uint32_t* out_size);
+        uint8_t Pre(void** out_ptr, uint32_t* out_size, uint64_t phyaddr);
+        int     Occupied_size;
+
+    private:
+        /*Internal parameter value holder*/
+        s_preproc_param_t internal_param_val;
+        /*Internal output buffer*/
+        void* internal_buffer = NULL;
+        /*Internal output buffer size*/
+        uint32_t internal_buffer_size = 0;
+        /*DRP-AI Driver dynamic allocation function*/
+        drpai_handle_t drpai_obj_info;
+        drpai_data_t drpai_data0;
+        std::string obj_prefix = "pp";
+        /*Buffer to store drp_param.bin data*/
+        std::vector<uint8_t> param_data;
+        /*Buffer to store weight.dat data*/
+        std::vector<uint8_t> weight_data;
+        /*List to store parmeter information, i.e., address, offset, size.*/
+        std::vector<s_op_t> param_info;
+        uint8_t run_mode;
+        /*Variables for internal in/out information */
+        uint16_t pre_out_shape_w = (uint16_t) INVALID_SHAPE;
+        uint16_t pre_out_shape_h = (uint16_t) INVALID_SHAPE;
+        uint16_t pre_in_shape_c   = (uint16_t) FORMAT_UNKNOWN;
+        uint16_t pre_out_shape_c  = (uint16_t) FORMAT_UNKNOWN;
+        uint8_t pre_in_type_size  = 0;
+        uint8_t pre_out_type_size = 0;
+        /*Flags to figure out whether operators are included in Pre-Runtime Object files*/
+        bool crop_included      = false;
+        bool resize_included    = false;
+        bool normalize_included = false;
+        
+        /*Since ADRCONV cannot delete just any entry, a means to reconfigure everything became necessary.*/
+        uint64_t start_addr_v2h;
+        uint64_t mapped_in_addr_v2h;
+
+        /*Supported Format*/
+        const uint16_t supported_format_in[17] = 
+        { 
+            FORMAT_YUYV_422,
+            FORMAT_YVYU_422,
+            FORMAT_UYUV_422,
+            FORMAT_VUYY_422,
+            FORMAT_YUYV_420,
+            FORMAT_UYVY_420,
+            FORMAT_YV12_420,
+            FORMAT_IYUV_420,
+            FORMAT_NV12_420,
+            FORMAT_NV21_420,
+            FORMAT_IMC1_420,
+            FORMAT_IMC2_420,
+            FORMAT_IMC3_420,
+            FORMAT_IMC4_420,
+            FORMAT_GRAY,
+            FORMAT_RGB,
+            FORMAT_BGR 
+        };
+        const uint16_t supported_format_out[3] = 
+        { 
+            FORMAT_GRAY, 
+            FORMAT_RGB, 
+            FORMAT_BGR 
+        };
+        /*Functions*/
+        uint8_t ReadAddrmapTxt(std::string addr_file);
+        uint8_t WritePrerunData(const std::string dir);
+        uint8_t LoadFileToMemDynamic(std::string data, unsigned long offset, unsigned long size, uint32_t file_type);
+        uint8_t LoadFileToMemDynamic(std::string data, unsigned long offset, unsigned long size);
+        uint8_t LoadDataToMem(std::vector<uint8_t> *data, unsigned long from, unsigned long size);
+        uint8_t LoadDataToMem(std::vector<uint8_t> data, unsigned long from, unsigned long size);
+        uint8_t ReadFileData(std::vector<uint8_t> *data, std::string file, unsigned long size);
+        uint8_t ReadFileData(std::vector<uint8_t> &data, std::string file, unsigned long size);
+        uint8_t GetResult(unsigned long output_addr, unsigned long output_size);
+        uint8_t ParseParamInfo(const std::string info_file);
+        uint8_t LoadParamInfo();
+        uint8_t UpdateParamToDynamic(uint32_t start_addr);
+        
+        int8_t  UpdateParamData(const s_preproc_param_t param);
+        int8_t  UpdateWeightData(const s_preproc_param_t param);
+
+        void    UpdateInputShape(const uint16_t w, const uint16_t h);
+        void    UpdateResizeShape(const uint16_t w, const uint16_t h);
+        void    UpdateResizeAlg(const uint8_t val);
+        void    UpdateFormat(const uint16_t input_val, const uint16_t output_val);
+        uint8_t UpdateCoefficient(const float* cof_add, const float* cof_mul);
+        void    UpdateCropParam(const uint16_t tl_x, const uint16_t tl_y, const uint16_t w, const uint16_t h);
+
+        bool    IsDifferentFmInternal(const float* cof_add, const float* cof_mul);
+        void    WriteValue(uint16_t offset, uint32_t value, uint8_t size);
+        bool    IsInSupportedList(uint16_t format, uint8_t is_input);
+        bool    IsSupportedFormat(const s_preproc_param_t param, uint16_t format_in, uint16_t format_out);
+        uint32_t GetStartAddress(uint32_t addr, drpai_data_t drpai_data);
+        uint64_t GetStartAddress(uint64_t addr, drpai_data_t drpai_data);
+        bool    StartsWith(std::string str, std::string prefix);
+        double  timedifference_msec(struct timespec t0, struct timespec t1);
+};
+
+#endif //PRERUNTIME_H
diff --git a/darknet_drp_ros/src/PreRuntimeV2H.cpp b/darknet_drp_ros/src/PreRuntimeV2H.cpp
new file mode 100644
index 0000000..814d737
--- /dev/null
+++ b/darknet_drp_ros/src/PreRuntimeV2H.cpp
@@ -0,0 +1,839 @@
+/*
+ * Original Code (C) Copyright Renesas Electronics Corporation 2023
+ *　
+ *  *1 DRP-AI TVM is powered by EdgeCortix MERA(TM) Compiler Framework.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ *
+ */
+
+/***********************************************************************************************************************
+* File Name    : PreRuntime.cpp
+* Version      : 1.1.0
+* Description  : PreRuntime Source file
+***********************************************************************************************************************/
+
+#include <fstream>
+#include <regex>
+#include <dirent.h>
+#include "PreRuntime.h"
+
+// ROS
+#include "rclcpp/rclcpp.hpp"
+
+PreRuntime::PreRuntime()
+{
+}
+
+PreRuntime::~PreRuntime()
+{
+    /*Free internal output buffer*/
+    if(NULL != internal_buffer)
+    {
+        free(internal_buffer);
+    }
+    /*Close DRP-AI Driver*/
+    if (0 <= drpai_obj_info.drpai_fd )
+    {
+        errno = 0;
+        if (PRE_SUCCESS != close(drpai_obj_info.drpai_fd ))
+        {
+            RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to close DRP-AI Driver : errno=%d",errno);
+        }
+    }
+}
+
+/*****************************************
+* Function Name : timedifference_msec
+* Description   : Function to compute the processing time in mili-seconds
+* Arguments     : t0 = processing start time
+*                 t1 = processing end time
+* Return value  : processing time in mili-seconds
+******************************************/
+double PreRuntime::timedifference_msec(struct timespec t0, struct timespec t1)
+{
+    return (t1.tv_sec - t0.tv_sec) * 1000.0 + (t1.tv_nsec - t0.tv_nsec) / 1000.0 / 1000.0;
+}
+
+/*****************************************
+* Function Name : ReadAddrmapTxt
+* Description   : Loads address and size of DRP-AI Object files into struct addr.
+* Arguments     : addr_file = filename of addressmap file (from DRP-AI Object files)
+* Return value  : 0 if succeeded
+*                 not 0 otherwise
+******************************************/
+uint8_t PreRuntime::ReadAddrmapTxt(std::string addr_file)
+{
+    std::string str;
+    unsigned long l_addr = 0;
+    unsigned long l_size = 0;
+    std::string element, a, s;
+    errno = 0;
+
+    std::ifstream ifs(addr_file);
+    if (ifs.fail())
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to open Address Map List %s: errno=%d",addr_file.c_str(),errno);
+        return PRE_ERROR;
+    }
+
+    while(getline(ifs, str))
+    {
+        std::istringstream iss(str);
+        iss >> element >> a >> s;
+        l_addr = strtol(a.c_str(), NULL, 16);
+        l_size = strtol(s.c_str(), NULL, 16);
+
+        if ("drp_config" == element)
+        {
+            drpai_obj_info.drpai_address.drp_config_addr = l_addr;
+            drpai_obj_info.drpai_address.drp_config_size = l_size;
+
+        }
+        else if ("desc_aimac" == element || "aimac_desc" == element)
+        {
+            drpai_obj_info.drpai_address.desc_aimac_addr = l_addr;
+            drpai_obj_info.drpai_address.desc_aimac_size = l_size;      
+        }
+        else if ("desc_drp" == element || "drp_desc" == element)
+        {
+            drpai_obj_info.drpai_address.desc_drp_addr = l_addr;
+            drpai_obj_info.drpai_address.desc_drp_size = l_size;
+        }
+        else if ("drp_param" == element)
+        {
+            drpai_obj_info.drpai_address.drp_param_addr = l_addr;
+            drpai_obj_info.drpai_address.drp_param_size = l_size;
+        }
+        else if ("weight" == element)
+        {
+            drpai_obj_info.drpai_address.weight_addr = l_addr;
+            drpai_obj_info.drpai_address.weight_size = l_size;
+            
+        }
+        else if ("data_in" == element)
+        {
+            drpai_obj_info.drpai_address.data_in_addr = l_addr;
+            drpai_obj_info.drpai_address.data_in_size = l_size;
+        }
+        else if ("data" == element)
+        {
+            drpai_obj_info.drpai_address.data_addr = l_addr;
+            drpai_obj_info.drpai_address.data_size = l_size;
+        }
+        else if ("data_out" == element)
+        {
+            drpai_obj_info.drpai_address.data_out_addr = l_addr;
+            drpai_obj_info.drpai_address.data_out_size = l_size;
+        }
+        else if ("work" == element)
+        {
+            drpai_obj_info.drpai_address.work_addr = l_addr;
+            drpai_obj_info.drpai_address.work_size = l_size;
+        }
+        else if ("aimac_param_cmd" == element)
+        {
+            drpai_obj_info.drpai_address.aimac_param_cmd_addr = l_addr;
+            drpai_obj_info.drpai_address.aimac_param_cmd_size = l_size;
+        }
+        else if ("aimac_param_desc" == element)
+        {
+            drpai_obj_info.drpai_address.aimac_param_desc_addr = l_addr;
+            drpai_obj_info.drpai_address.aimac_param_desc_size = l_size;
+        }
+        else if ("aimac_cmd" == element)
+        {
+            drpai_obj_info.drpai_address.aimac_cmd_addr = l_addr;
+            drpai_obj_info.drpai_address.aimac_cmd_size = l_size;
+        }
+        else
+        {
+            /*Ignore other space*/
+        }
+
+    }
+
+    ifs.close();
+    return PRE_SUCCESS;
+}
+
+uint8_t PreRuntime::WritePrerunData(const std::string dir)
+{
+    std::string str;
+    std::string element, a, s;
+    uint8_t ret;
+    errno = 0;
+
+
+    std::vector<uint8_t> config_data;
+    std::string fname = dir+"/drp_config.mem";
+    ret = ReadFileData(&config_data, fname, drpai_obj_info.drpai_address.drp_config_size);
+    if ( PRE_SUCCESS < ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to read file %s/drp_config.mem",dir.c_str());
+        return PRE_ERROR;
+    }
+    /*Load weight data to memory using non-dynamic function.*/
+    ret = LoadDataToMem(&config_data, drpai_obj_info.drpai_address.drp_config_addr + drpai_obj_info.data_inout.start_address, drpai_obj_info.drpai_address.drp_config_size);
+    if ( PRE_SUCCESS != ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to write file data %s/drp_config.mem",dir.c_str());
+        return PRE_ERROR;
+    }
+
+
+    std::vector<uint8_t> aimac_desc_data;
+    ret = ReadFileData(&aimac_desc_data, dir+"/aimac_desc.bin", drpai_obj_info.drpai_address.desc_aimac_size);
+    if ( PRE_SUCCESS < ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to read file %s/aimac_desc.bin",dir.c_str());
+        return PRE_ERROR;
+    }
+    /*Load weight data to memory using non-dynamic function.*/
+    ret = LoadDataToMem(&aimac_desc_data, drpai_obj_info.drpai_address.desc_aimac_addr + drpai_obj_info.data_inout.start_address, drpai_obj_info.drpai_address.desc_aimac_size);
+    if ( PRE_SUCCESS != ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to write file data %s/aimac_desc.bin",dir.c_str());
+        return PRE_ERROR;
+    }
+
+    std::vector<uint8_t> drp_desc_data;
+    ret = ReadFileData(&drp_desc_data, dir+"/drp_desc.bin", drpai_obj_info.drpai_address.desc_drp_size);
+    if ( PRE_SUCCESS < ret )
+    {
+       RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to read file %s/drp_desc.bin",dir.c_str());
+       return PRE_ERROR;
+    }
+    ret = LoadDataToMem(&drp_desc_data, drpai_obj_info.drpai_address.desc_drp_addr + drpai_obj_info.data_inout.start_address, drpai_obj_info.drpai_address.desc_drp_size);
+    if ( PRE_SUCCESS != ret )
+    {
+       RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to write file data %s/drp_desc.bin",dir.c_str());
+       return PRE_ERROR;
+    }
+       
+
+    std::vector<uint8_t> drp_param_data;
+    ret = ReadFileData(&drp_param_data, dir+"/drp_param.bin", drpai_obj_info.drpai_address.drp_param_size);
+    if ( PRE_SUCCESS < ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to read file %s/drp_param.bin",dir.c_str());
+        return PRE_ERROR;
+    }
+    ret = LoadDataToMem(&drp_param_data, drpai_obj_info.drpai_address.drp_param_addr + drpai_obj_info.data_inout.start_address, drpai_obj_info.drpai_address.drp_param_size);
+    if ( PRE_SUCCESS != ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to write file data %s/drp_param.bin",dir.c_str());
+        return PRE_ERROR;
+    }
+
+    std::vector<uint8_t> weight_data;
+    ret = ReadFileData(&weight_data, dir+"/weight.bin", drpai_obj_info.drpai_address.weight_size);
+    if ( PRE_SUCCESS < ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to read file %s/weight.bin",dir.c_str());
+        return PRE_ERROR;
+    }
+    ret = LoadDataToMem(&weight_data, drpai_obj_info.drpai_address.weight_addr + drpai_obj_info.data_inout.start_address, drpai_obj_info.drpai_address.weight_size);
+    if ( PRE_SUCCESS != ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to write file data %s/weight.bin",dir.c_str());
+        return PRE_ERROR;
+    }
+
+    std::vector<uint8_t> aimac_param_cmd_data;
+    ret = ReadFileData(&aimac_param_cmd_data, dir+"/aimac_param_cmd.bin", drpai_obj_info.drpai_address.aimac_param_cmd_size);
+    if ( PRE_SUCCESS < ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to read file %s/aimac_param_cmd.bin",dir.c_str());
+        return PRE_ERROR;
+    }
+    ret = LoadDataToMem(&aimac_param_cmd_data, drpai_obj_info.drpai_address.aimac_param_cmd_addr + drpai_obj_info.data_inout.start_address, drpai_obj_info.drpai_address.aimac_param_cmd_size);
+    if ( PRE_SUCCESS != ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to write file data %s/aimac_param_cmd.bin",dir.c_str());
+        return PRE_ERROR;
+    }
+
+    std::vector<uint8_t> aimac_param_desc_data;
+    ret = ReadFileData(&aimac_param_desc_data, dir+"/aimac_param_desc.bin", drpai_obj_info.drpai_address.aimac_param_desc_size);
+    if ( PRE_SUCCESS < ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to read file %s/aimac_param_desc.bin",dir.c_str());
+        return PRE_ERROR;
+    }
+    ret = LoadDataToMem(&aimac_param_desc_data, drpai_obj_info.drpai_address.aimac_param_desc_addr + drpai_obj_info.data_inout.start_address, drpai_obj_info.drpai_address.aimac_param_desc_size);
+    if ( PRE_SUCCESS != ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to write file data %s/aimac_param_desc.bin",dir.c_str());
+        return PRE_ERROR;
+    }
+ 
+    std::vector<uint8_t> aimac_cmd_data;
+    ret = ReadFileData(&aimac_cmd_data, dir+"/aimac_cmd.bin", drpai_obj_info.drpai_address.aimac_cmd_size);
+    if ( PRE_SUCCESS < ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to read file %s/aimac_cmd.bin",dir.c_str());
+        return PRE_ERROR;
+    }
+    ret = LoadDataToMem(&aimac_cmd_data, drpai_obj_info.drpai_address.aimac_cmd_addr + drpai_obj_info.data_inout.start_address, drpai_obj_info.drpai_address.aimac_cmd_size);
+    if ( PRE_SUCCESS != ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to write file data %s/aimac_cmd.bin",dir.c_str());
+        return PRE_ERROR;
+    }
+
+    return PRE_SUCCESS;
+}
+
+/*****************************************
+* Function Name : LoadDataToMem
+* Description   : Loads a drp_param.bin to memory via DRP-AI Driver
+* Arguments     : data = filename to be written to memory
+*                 from = memory start address where the data is written
+*                 size = data size to be written
+* Return value  : 0 if succeeded
+*                 not 0 otherwise
+******************************************/
+uint8_t PreRuntime::LoadDataToMem(std::vector<uint8_t> *data, unsigned long from, unsigned long size)
+{
+    int          drpai_fd = drpai_obj_info.drpai_fd;
+    drpai_data_t drpai_data;
+    uint8_t      ret = 0;
+
+    errno = 0;
+    drpai_data.address = from;
+    drpai_data.size    = size;
+    ret = ioctl(drpai_fd, DRPAI_ASSIGN, &drpai_data);
+    if ( -1 == ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to run DRPAI_ASSIGN : errno=%d",errno);
+        return PRE_ERROR;
+    }
+    ret = write(drpai_fd, data->data(), size);
+    if ( -1 == ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to write with DRPAI_ASSIGN : errno=%d",errno);
+        return PRE_ERROR;
+    }
+
+    return PRE_SUCCESS;
+}
+
+/*****************************************
+* Function Name : ReadFileData
+* Description   : Loads a drp_param.bin
+* Arguments     : data = container to store the file contents
+*                 file = filename to be read
+*                 size = data size to be read
+* Return value  : 0 if succeeded
+*                 not 0 otherwise
+******************************************/
+uint8_t PreRuntime::ReadFileData(std::vector<uint8_t> *data, std::string file, unsigned long size)
+{
+    errno = 0;
+    data->resize(size);
+    data->clear();
+
+    std::ifstream ifs(file);
+    if (!ifs)
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to open %s: errno=%d",file.c_str(),errno);
+        return PRE_ERROR;
+    }
+
+    /* Store file data to internal vector */
+    std::istreambuf_iterator<char> it(ifs);
+    std::istreambuf_iterator<char> last;
+    for (; it != last; ++it)
+    {
+        data->push_back(*it);
+    }
+    /* Check the param_data size is appropriate */
+    if (size != data->size())
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to read %s: errno=%d",file.c_str(),errno);
+        return PRE_ERROR;
+    }
+    ifs.close();
+
+    return PRE_SUCCESS;
+}
+
+/*****************************************
+* Function Name : ParseParamInfo
+* Description   : Loads a drp_param_info.txt.
+* Arguments     : info_file = filename to be loaded.
+* Return value  : 0 if succeeded
+*                 not 0 otherwise
+******************************************/
+uint8_t PreRuntime::ParseParamInfo(const std::string info_file)
+{
+    const std::string offset_add      = OP_HEAD;
+    const std::string layer_name      = OP_LAYER_NAME;
+    const std::string drp_lib         = OP_LIB;
+    const std::string param_head      = PRAM_HEAD;
+    const std::string param_value     = PARAM_VALUE;
+    const std::string param_offset    = PARAM_OFFSET;
+    const std::string param_size      = PARAM_SIZE;
+    std::string str         = "";
+    std::string str_return  = "";
+    std::string element     = "";
+    std::string str_value   = "";
+    s_op_param_t tmp_param;
+    int  drpai_fd = drpai_obj_info.drpai_fd;
+    drpai_assign_param_t drpai_param;
+    uint32_t drp_param_info_size;
+    errno = 0;
+    
+    /*Get param info file size*/
+    std::ifstream param_file_for_size(info_file, std::ifstream::ate);
+    drp_param_info_size = static_cast<uint32_t>(param_file_for_size.tellg());
+    param_file_for_size.close();
+    drpai_param.info_size = drp_param_info_size;
+    drpai_param.obj.address = drpai_obj_info.drpai_address.drp_param_addr + drpai_obj_info.data_inout.start_address;
+    drpai_param.obj.size = drpai_obj_info.drpai_address.drp_param_size;
+    
+    if (0 != ioctl(drpai_fd, DRPAI_ASSIGN_PARAM, &drpai_param))
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to run DRPAI_ASSIGN_PARAM : errno=%d %s %d",errno,__FILE__,__LINE__);
+        return PRE_ERROR;
+    }
+    
+    /* Open param info file */
+    std::vector<uint8_t> param_info_data;
+    int ret;
+    ret = ReadFileData(&param_info_data, info_file, drp_param_info_size);
+    if ( PRE_SUCCESS < ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to read file %s",info_file.c_str());
+        return PRE_ERROR;
+    }
+    uint8_t param_info_array[param_info_data.size()];
+    std::copy(param_info_data.begin(),param_info_data.end(),param_info_array);
+    if ( 0 > write(drpai_fd, param_info_array, drp_param_info_size))
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to write PARAM_INFO to DRP-AI Driver : errno=%d",errno);
+        return PRE_ERROR;
+    }
+    return PRE_SUCCESS;
+}
+
+/*****************************************
+* Function Name : GetStartAddress
+* Description   : Check the user input start_addr is valid and return the valid address
+* Arguments     : addr = address to be checked.
+*               : drpai_data = DRP-AI memory area details.
+* Return value  : start address for Pre-Runtime Object files
+*                 INVALID_ADDR if user input is invalid
+******************************************/
+uint64_t PreRuntime::GetStartAddress(uint64_t addr, drpai_data_t drpai_data)
+{
+    uint64_t drpai_mem_addr_end = drpai_data.address+drpai_data.size - 1;
+    if (INVALID_ADDR == addr)
+    {
+        /*If user did not specify the start_addr, use DRP-AI memory area start address.*/
+        return drpai_data.address;
+    }
+    if ((drpai_data.address > addr)|| drpai_mem_addr_end < addr ) 
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Not in DRP-AI memory area.");
+        return INVALID_ADDR;
+    }
+    if (0 != (addr % 64))
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Not 64-byte aligned.");
+        return INVALID_ADDR;
+    }
+    return addr;
+}
+
+/*****************************************
+* Function Name : Load
+* Description   : Loads PreRuntime Object data.
+* Arguments     : pre_dir = folder name to be loaded.
+*               : start_addr = start address that object files are dynamically allocated.
+*                              default value is INVALID_ADDR.
+*               : mode       = pre or post mode.
+*                              default value is MODE_PRE.
+* Return value  : 0 if succeeded
+*                 not 0 otherwise
+******************************************/
+uint8_t PreRuntime::Load(const std::string pre_dir, uint32_t start_addr, uint8_t mode)
+{
+    return Load(pre_dir, (uint64_t)start_addr);
+}
+
+uint8_t PreRuntime::Load(const std::string pre_dir, uint64_t start_addr)
+{
+    uint8_t ret = 0;
+    struct stat statBuf;
+    std::string tmp_dir = "/";
+    std::string dir = pre_dir;
+    std::string tmp_address_file = dir+"/addr_map.txt";
+    const std::string drpai_param_file = dir + "/drp_param_info.txt";
+
+    /* Delete unnecessary slush */
+    if (dir.size() >= tmp_dir.size() &&
+            dir.find(tmp_dir, dir.size() - tmp_dir.size()) != std::string::npos)
+    {
+        dir = dir.erase(dir.size()-1);
+    }
+    /* Check whether directory exists*/
+    if (0 != stat(dir.c_str(),&statBuf))
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Directory %s not found",dir.c_str());
+        return PRE_ERROR;
+    }
+
+    /*Check if PreRuntime Object files are generated from PreRuntime Compile Module*/
+    if (0 == stat(tmp_address_file.c_str(),&statBuf))
+    {
+        obj_prefix = dir;
+    }
+
+    /*Define necessary filename*/
+    const std::string address_file = dir+"/addr_map.txt";
+
+    errno = 0;
+    /*Open DRP-AI Driver*/
+    drpai_obj_info.drpai_fd = open("/dev/drpai0", O_RDWR);
+    if (PRE_SUCCESS > drpai_obj_info.drpai_fd )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to open DRP-AI Driver : errno=%d",errno);
+        return PRE_ERROR;
+    }
+
+    /* Get DRP-AI Memory Area Address via DRP-AI Driver */
+    ret = ioctl(drpai_obj_info.drpai_fd , DRPAI_GET_DRPAI_AREA, &drpai_data0);
+    if (-1 == ret)
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to get DRP-AI Memory Area : errno=%d",errno);
+        return PRE_ERROR;
+    }
+
+    /* Read Address Map List file */
+    ret = ReadAddrmapTxt(address_file);
+    if (PRE_SUCCESS < ret)
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to read Address Map List %s",address_file.c_str());
+        return PRE_ERROR;
+    }
+
+    if(start_addr == INVALID_ADDR)
+    {
+        this->Occupied_size = drpai_obj_info.drpai_address.desc_drp_addr + drpai_obj_info.drpai_address.desc_drp_size;
+        this->Occupied_size = (Occupied_size + 0xffffff) & 0xff000000;
+        start_addr = drpai_data0.address + drpai_data0.size - Occupied_size;
+    }
+    else
+    {
+        this->Occupied_size = drpai_data0.size - (start_addr - drpai_data0.address);
+    }
+
+    /* Set the DRP virtual start address to 0, indicating the actual 40-bit physical address. */
+    errno = 0;
+    drpai_adrconv_t drpai_adrconv;
+    this->start_addr_v2h = start_addr;
+    drpai_adrconv.conv_address = start_addr;
+    drpai_adrconv.org_address  = drpai_obj_info.drpai_address.data_in_addr; //Currently, data_in_addr contained the actual starting address.
+    drpai_adrconv.size         = this->Occupied_size;
+    drpai_adrconv.mode         = DRPAI_ADRCONV_MODE_REPLACE;
+    if ( PRE_SUCCESS != ioctl(drpai_obj_info.drpai_fd , DRPAI_SET_ADRCONV, &drpai_adrconv))
+    {
+       RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to run DRPAI_SET_ADRCONV : errno=%d",errno);
+       return PRE_ERROR;
+    }
+
+    /*Define the start address.*/
+    /*drpai_obj_info.drpai_address.data_in_addr maybe 0x00000000. */
+    drpai_obj_info.data_inout.start_address = drpai_adrconv.conv_address - drpai_obj_info.drpai_address.data_in_addr;
+
+    /*Parse drp_param_info.txt*/
+    ret = ParseParamInfo(drpai_param_file);
+    if ( PRE_SUCCESS < ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to read param info file: %s",drpai_param_file.c_str());
+        return PRE_ERROR;
+    }
+    
+    /*Write binary parameters for drpai.*/
+    ret = WritePrerunData(dir);
+    if ( PRE_SUCCESS != ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to write parameters. ");
+        return PRE_ERROR;
+    }
+
+    return PRE_SUCCESS;
+}
+
+/*****************************************
+* Function Name : GetResult
+* Description   : Function to save the DRP-AI output. Uses DRP-AI Driver
+* Arguments     : output_ptr = pointer to the buffer which stores DRP-AI output
+*                 output_addr = memory address that DRP-AI output is stored.
+*                 output_size = memory size of DRP-AI output
+* Return value  : 0 if succeeded
+*                 not 0 otherwise
+******************************************/
+uint8_t PreRuntime::GetResult(unsigned long output_addr, unsigned long output_size)
+{
+    int8_t ret = 0;
+    drpai_data_t drpai_data;
+    drpai_data.address = output_addr;
+    drpai_data.size = output_size;
+
+    /*Free internal buffer if its memory is already allocated */
+    if(internal_buffer != NULL )
+    {
+        free(internal_buffer);
+    }
+
+    internal_buffer = (uint32_t*) malloc(drpai_data.size);
+
+    if(internal_buffer == NULL)
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to malloc PreRuntime internal buffer.");
+        return PRE_ERROR;
+    }
+    internal_buffer_size = (uint32_t) (drpai_data.size);
+
+    errno = 0;
+    /* Assign the memory address and size to be read */
+    ret = ioctl(drpai_obj_info.drpai_fd , DRPAI_ASSIGN, &drpai_data);
+    if (-1 == ret)
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to run DRPAI_ASSIGN: errno=%d",errno);
+        return PRE_ERROR;
+    }
+
+    /* Read the memory via DRP-AI Driver and store the output to buffer */
+    errno = 0;
+    ret = read(drpai_obj_info.drpai_fd , internal_buffer, drpai_data.size);
+    if ( -1 == ret )
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to read via DRP-AI Driver: errno=%d",errno);
+        return PRE_ERROR;
+    }
+
+    return PRE_SUCCESS;
+}
+
+/*****************************************
+* Function Name : SetInput
+* Description   : 
+*                 
+* Arguments     : indata = pointer to input data
+*              
+* Return value  : true if succeeded
+*                 false error;
+******************************************/
+int PreRuntime::SetInput(void *indata)
+{
+    uint8_t ret = 0;
+    /* Write input data to data_in_addr.*/
+    drpai_data_t input;
+    input.address = drpai_obj_info.drpai_address.data_in_addr + drpai_obj_info.data_inout.start_address;
+    input.size    = drpai_obj_info.drpai_address.data_in_size;
+    ret = ioctl(drpai_obj_info.drpai_fd , DRPAI_ASSIGN, &input);
+    if (-1 == ret)
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to run DRPAI_ASSIGN in SetInput(): errno=%d",errno);
+        return PRE_ERROR;
+    }
+    ret = write(drpai_obj_info.drpai_fd , indata, input.size);
+    if (-1 == ret)
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to write via DRP-AI Driver in SetInput(): errno=%d",errno);
+        return PRE_ERROR;
+    }
+
+    return PRE_SUCCESS;
+}	
+
+/*****************************************
+* Function Name : Pre
+* Description   : Function to change paramter, run inference and get result.
+*                 To use this function, all param values must be defined.
+* Arguments     : param = pointer to parameter to be changed.
+*                 out_ptr = pointer to store output buffer starting pointer
+*                 out_size = size of output buffer
+* Return value  : 0 if succeeded
+*                 not 0 otherwise
+******************************************/
+uint8_t PreRuntime::Pre(s_preproc_param_t* param, void** out_ptr, uint32_t* out_size)
+{
+    if((param->pre_in_addr & 0x800000000000) != 0)
+    {
+        /* Virtual address in linux user space */
+        SetInput((void *)param->pre_in_addr);
+
+        #ifndef WITH_V2H_DEV
+        return Pre(out_ptr, out_size, (uint64_t)(drpai_obj_info.drpai_address.data_in_addr + drpai_obj_info.data_inout.start_address));
+        #else
+        // If you don't have rzv2h-dev, don't care.
+        return Pre(out_ptr, out_size, (uint64_t)(drpai_obj_info.drpai_address.data_in_addr));
+        #endif
+    }
+    else
+    {
+
+        if(this->mapped_in_addr_v2h != param->pre_in_addr){
+	    int ret = 0;
+
+            drpai_adrconv_t drpai_adrconv;
+            drpai_adrconv.conv_address = this->start_addr_v2h;
+            drpai_adrconv.org_address  = drpai_obj_info.drpai_address.data_in_addr; //Currently, data_in_addr contained the actual starting address.
+            drpai_adrconv.size         = this->Occupied_size;
+            drpai_adrconv.mode         = DRPAI_ADRCONV_MODE_REPLACE;
+            ret = ioctl(drpai_obj_info.drpai_fd, DRPAI_SET_ADRCONV, &drpai_adrconv);
+            if (0 != ret)
+            {
+                RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to run SET_ADRCONV(1) for DRP-AI input image : errno=%d",errno);
+                return PRE_ERROR;
+            }
+
+            this->mapped_in_addr_v2h = param->pre_in_addr;
+            drpai_adrconv.conv_address  = param->pre_in_addr & 0xffffff000000;
+            drpai_adrconv.org_address   = 0xD0000000;
+            drpai_adrconv.size          = 0x20000000; /*(drpai_obj_info.drpai_address.data_in_size + 0xffffff) & 0xff000000;*/
+            drpai_adrconv.mode          = DRPAI_ADRCONV_MODE_ADD;
+            ret = ioctl(drpai_obj_info.drpai_fd, DRPAI_SET_ADRCONV, &drpai_adrconv);
+    
+            if (0 != ret)
+            {
+                RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to run SET_ADRCONV(2) for DRP-AI input image : errno=%d",errno);
+                return PRE_ERROR;
+            }
+        }
+
+        #ifndef WITH_V2H_DEV
+        return Pre(out_ptr, out_size, (uint64_t)param->pre_in_addr);
+        #else
+        // If you don't have rzv2h-dev, don't care.
+        return Pre(out_ptr, out_size, (uint64_t)0xD0000000);
+        #endif
+    }
+}
+
+uint8_t PreRuntime::Pre(void** out_ptr, uint32_t* out_size, uint64_t phyaddr)
+{
+    uint8_t ret = 0;
+    drpai_data_t proc[DRPAI_INDEX_NUM];
+    struct timespec ts_start, ts_end;
+    drpai_status_t drpai_status;
+    fd_set rfds;
+    struct timespec tv;
+    int8_t ret_drpai;
+    double preproc_time = 0;
+    sigset_t sigset;
+
+
+    sigemptyset(&sigset);
+    sigaddset(&sigset, SIGUSR1);
+
+    proc[DRPAI_INDEX_INPUT].address            = phyaddr;
+    proc[DRPAI_INDEX_INPUT].size               = drpai_obj_info.drpai_address.data_in_size;
+    proc[DRPAI_INDEX_DRP_CFG].address          = drpai_obj_info.drpai_address.drp_config_addr + drpai_obj_info.data_inout.start_address;
+    proc[DRPAI_INDEX_DRP_CFG].size             = drpai_obj_info.drpai_address.drp_config_size;
+    proc[DRPAI_INDEX_DRP_PARAM].address        = drpai_obj_info.drpai_address.drp_param_addr  + drpai_obj_info.data_inout.start_address;
+    proc[DRPAI_INDEX_DRP_PARAM].size           = drpai_obj_info.drpai_address.drp_param_size;
+    proc[DRPAI_INDEX_AIMAC_DESC].address       = drpai_obj_info.drpai_address.desc_aimac_addr + drpai_obj_info.data_inout.start_address;
+    proc[DRPAI_INDEX_AIMAC_DESC].size          = drpai_obj_info.drpai_address.desc_aimac_size;
+    proc[DRPAI_INDEX_DRP_DESC].address         = drpai_obj_info.drpai_address.desc_drp_addr   + drpai_obj_info.data_inout.start_address;
+    proc[DRPAI_INDEX_DRP_DESC].size            = drpai_obj_info.drpai_address.desc_drp_size;
+    proc[DRPAI_INDEX_WEIGHT].address           = drpai_obj_info.drpai_address.weight_addr     + drpai_obj_info.data_inout.start_address;
+    proc[DRPAI_INDEX_WEIGHT].size              = drpai_obj_info.drpai_address.weight_size;
+    proc[DRPAI_INDEX_OUTPUT].address           = drpai_obj_info.drpai_address.data_out_addr   + drpai_obj_info.data_inout.start_address;
+    proc[DRPAI_INDEX_OUTPUT].size              = drpai_obj_info.drpai_address.data_out_size;
+    proc[DRPAI_INDEX_AIMAC_CMD].address        = drpai_obj_info.drpai_address.aimac_param_cmd_addr   + drpai_obj_info.data_inout.start_address;
+    proc[DRPAI_INDEX_AIMAC_CMD].size           = drpai_obj_info.drpai_address.aimac_param_cmd_size;
+    proc[DRPAI_INDEX_AIMAC_PARAM_DESC].address = drpai_obj_info.drpai_address.aimac_param_desc_addr   + drpai_obj_info.data_inout.start_address;
+    proc[DRPAI_INDEX_AIMAC_PARAM_DESC].size    = drpai_obj_info.drpai_address.aimac_param_desc_size;
+    proc[DRPAI_INDEX_AIMAC_PARAM_CMD].address  = drpai_obj_info.drpai_address.aimac_cmd_addr   + drpai_obj_info.data_inout.start_address;
+    proc[DRPAI_INDEX_AIMAC_PARAM_CMD].size     = drpai_obj_info.drpai_address.aimac_cmd_size;
+
+#ifdef DEBUG_LOG
+    float diff = 0;
+    timespec_get(&ts_start, TIME_UTC);
+#endif
+
+    /* Wait till DRP-AI ends */
+    errno = 0;
+    if ( PRE_SUCCESS != ioctl(drpai_obj_info.drpai_fd , DRPAI_START, &proc[0]))
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to run DRPAI_START : errno=%d",errno);
+        return PRE_ERROR;
+    }
+
+    /* Wait till DRP-AI ends */
+    FD_ZERO(&rfds);
+    FD_SET(drpai_obj_info.drpai_fd , &rfds);
+    tv.tv_sec = 5;
+    tv.tv_nsec = 0;
+
+    ret_drpai = pselect(drpai_obj_info.drpai_fd +1, &rfds, NULL, NULL, &tv, &sigset);
+
+    if(0 == ret_drpai)
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] DRP-AI timed out : errno=%d",errno);
+        return PRE_ERROR;
+    }
+    else if (-1 == ret_drpai)
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to run DRP-AI Driver pselect : errno=%d",errno);
+        return PRE_ERROR;
+    }
+
+    if (FD_ISSET(drpai_obj_info.drpai_fd , &rfds))
+    {
+        errno = 0;
+        ret_drpai = ioctl(drpai_obj_info.drpai_fd, DRPAI_GET_STATUS, &drpai_status);
+        if (-1 == ret_drpai)
+        {
+            RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to run DRPAI_GET_STATUS : errno=%d",errno);
+            return PRE_ERROR;
+        }
+
+    }
+#ifdef DEBUG_LOG
+    /*Stop Timer */
+    timespec_get(&ts_end, TIME_UTC);
+    preproc_time = timedifference_msec(ts_start, ts_end);
+    RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[TIME] PreRuntime DRP-AI processing time : %.2f msec",preproc_time);
+
+    timespec_get(&ts_start, TIME_UTC);
+#endif
+    /* Obtain result. Result is stored in internal_buffer */
+    ret = GetResult(proc[DRPAI_INDEX_OUTPUT].address, proc[DRPAI_INDEX_OUTPUT].size);
+    if (PRE_SUCCESS < ret)
+    {
+        RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[ERROR] Failed to get result.");
+        return PRE_ERROR;
+    }
+#ifdef DEBUG_LOG
+    timespec_get(&ts_end, TIME_UTC);
+    diff = timedifference_msec(ts_start, ts_end);
+    RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "[TIME] GetResult() Processing Time : %.2f msec",diff);
+#endif
+
+    *out_ptr = internal_buffer;
+    *out_size = internal_buffer_size;
+
+    return PRE_SUCCESS;
+}
diff --git a/darknet_drp_ros/src/ascii.cpp b/darknet_drp_ros/src/ascii.cpp
new file mode 100644
index 0000000..ecd1a08
--- /dev/null
+++ b/darknet_drp_ros/src/ascii.cpp
@@ -0,0 +1,116 @@
+/***********************************************************************************************************************
+* Copyright (C) 2023 Renesas Electronics Corporation. All rights reserved.
+***********************************************************************************************************************/
+/***********************************************************************************************************************
+* File Name    : ascii.cpp
+* Version      : 0.90
+* Description  : RZ/V2H DRP-AI Sample Application for Megvii-Base Detection YOLOX with MIPI/USB Camera
+***********************************************************************************************************************/
+
+/*****************************************
+* Includes
+******************************************/
+/* ASCII header */
+#include "ascii.h"
+
+/*******************************************************************************
+* Global Tables
+*******************************************************************************/
+const char g_ascii_table[][6] =
+{
+  { 0x00, 0x00, 0x00, 0x00, 0x00, 0x00},      /* ' '*/
+  { 0x00, 0x00, 0x79, 0x00, 0x00, 0x00},      /* ! */
+  { 0x00, 0x70, 0x00, 0x70, 0x00, 0x00},      /* " */
+  { 0x22, 0x7F, 0x22, 0x7F, 0x22, 0x00},      /* # */
+  { 0x12, 0x2A, 0x7F, 0x2A, 0x24, 0x00},      /* $ */
+  { 0x62, 0x64, 0x08, 0x13, 0x23, 0x00},      /* % */
+  { 0x36, 0x49, 0x55, 0x22, 0x05, 0x00},      /* & */
+  { 0x00, 0x00, 0x60, 0x00, 0x00, 0x00},      /* ' */
+  { 0x00, 0x1C, 0x22, 0x41, 0x00, 0x00},      /* ( */
+  { 0x00, 0x41, 0x22, 0x1C, 0x00, 0x00},      /* ) */
+  { 0x24, 0x18, 0x7E, 0x18, 0x24, 0x00},      /* * */
+  { 0x08, 0x08, 0x3E, 0x08, 0x08, 0x00},      /* + */
+  { 0x00, 0x05, 0x06, 0x00, 0x00, 0x00},      /* , */
+  { 0x08, 0x08, 0x08, 0x08, 0x08, 0x00},      /* - */
+  { 0x00, 0x03, 0x03, 0x00, 0x00, 0x00},      /* . */
+  { 0x02, 0x04, 0x08, 0x10, 0x20, 0x00},      /* / */
+  { 0x3E, 0x45, 0x49, 0x51, 0x3E, 0x00},      /* 0 */
+  { 0x00, 0x21, 0x7F, 0x01, 0x00, 0x00},      /* 1 */
+  { 0x21, 0x43, 0x45, 0x49, 0x71, 0x00},      /* 2 */
+  { 0x42, 0x41, 0x51, 0x69, 0x46, 0x00},      /* 3 */
+  { 0x0C, 0x14, 0x24, 0x7F, 0x04, 0x00},      /* 4 */
+  { 0x72, 0x51, 0x51, 0x51, 0x4E, 0x00},      /* 5 */
+  { 0x1E, 0x29, 0x49, 0x49, 0x06, 0x00},      /* 6 */
+  { 0x40, 0x47, 0x48, 0x50, 0x60, 0x00},      /* 7 */
+  { 0x36, 0x49, 0x49, 0x49, 0x36, 0x00},      /* 8 */
+  { 0x30, 0x49, 0x49, 0x4A, 0x3C, 0x00},      /* 9 */
+  { 0x00, 0x66, 0x66, 0x00, 0x00, 0x00},      /* : */
+  { 0x00, 0x35, 0x36, 0x00, 0x00, 0x00},      /* ; */
+  { 0x08, 0x14, 0x22, 0x41, 0x00, 0x00},      /* < */
+  { 0x14, 0x14, 0x14, 0x14, 0x14, 0x00},      /* = */
+  { 0x00, 0x41, 0x22, 0x14, 0x08, 0x00},      /* > */
+  { 0x20, 0x40, 0x45, 0x48, 0x30, 0x00},      /* ? */
+  { 0x38, 0x45, 0x5D, 0x59, 0x3E, 0x00},      /* @ */
+  { 0x1F, 0x24, 0x44, 0x24, 0x1F, 0x00},      /* A */
+  { 0x7F, 0x49, 0x49, 0x49, 0x36, 0x00},      /* B */
+  { 0x3E, 0x41, 0x41, 0x41, 0x22, 0x00},      /* C */
+  { 0x7F, 0x41, 0x41, 0x22, 0x1C, 0x00},      /* D */
+  { 0x7F, 0x49, 0x49, 0x49, 0x41, 0x00},      /* E */
+  { 0x7F, 0x48, 0x48, 0x48, 0x40, 0x00},      /* F */
+  { 0x3E, 0x41, 0x49, 0x49, 0x2F, 0x00},      /* G */
+  { 0x7F, 0x08, 0x08, 0x08, 0x7F, 0x00},      /* H */
+  { 0x00, 0x41, 0x7F, 0x41, 0x00, 0x00},      /* I */
+  { 0x02, 0x01, 0x41, 0x7E, 0x40, 0x00},      /* J */
+  { 0x7F, 0x08, 0x14, 0x22, 0x41, 0x00},      /* K */
+  { 0x7F, 0x01, 0x01, 0x01, 0x01, 0x00},      /* L */
+  { 0x7F, 0x20, 0x18, 0x20, 0x7F, 0x00},      /* M */
+  { 0x7F, 0x10, 0x08, 0x04, 0x7F, 0x00},      /* N */
+  { 0x3E, 0x41, 0x41, 0x41, 0x3E, 0x00},      /* O */
+  { 0x7F, 0x48, 0x48, 0x48, 0x30, 0x00},      /* P */
+  { 0x3E, 0x41, 0x45, 0x42, 0x3D, 0x00},      /* Q */
+  { 0x7F, 0x48, 0x4C, 0x4A, 0x31, 0x00},      /* R */
+  { 0x32, 0x49, 0x49, 0x49, 0x26, 0x00},      /* S */
+  { 0x40, 0x40, 0x7F, 0x40, 0x40, 0x00},      /* T */
+  { 0x7E, 0x01, 0x01, 0x01, 0x7E, 0x00},      /* U */
+  { 0x7C, 0x02, 0x01, 0x02, 0x7C, 0x00},      /* V */
+  { 0x7E, 0x01, 0x0E, 0x01, 0x7E, 0x00},      /* W */
+  { 0x63, 0x14, 0x08, 0x14, 0x63, 0x00},      /* X */
+  { 0x70, 0x08, 0x07, 0x08, 0x70, 0x00},      /* Y */
+  { 0x43, 0x45, 0x49, 0x51, 0x61, 0x00},      /* Z */
+  { 0x00, 0x7F, 0x41, 0x00, 0x00, 0x00},      /* [ */
+  { 0x20, 0x10, 0x08, 0x04, 0x02, 0x00},      /* "\" */
+  { 0x00, 0x00, 0x41, 0x7F, 0x00, 0x00},      /* ] */
+  { 0x00, 0x20, 0x40, 0x20, 0x00, 0x00},      /* ^ */
+  { 0x01, 0x01, 0x01, 0x01, 0x01, 0x00},      /* _ */
+  { 0x00, 0x40, 0x20, 0x00, 0x00, 0x00},      /* ' */
+  { 0x02, 0x15, 0x15, 0x0F, 0x01, 0x00},      /* a */
+  { 0x00, 0x7F, 0x11, 0x11, 0x0E, 0x00},      /* b */
+  { 0x00, 0x0E, 0x11, 0x11, 0x11, 0x00},      /* c */
+  { 0x0E, 0x11, 0x11, 0x7F, 0x00, 0x00},      /* d */
+  { 0x0E, 0x15, 0x15, 0x15, 0x0C, 0x00},      /* e */
+  { 0x00, 0x10, 0x3F, 0x50, 0x50, 0x00},      /* f */
+  { 0x08, 0x15, 0x15, 0x15, 0x1E, 0x00},      /* g */
+  { 0x00, 0x7F, 0x10, 0x10, 0x0F, 0x00},      /* h */
+  { 0x00, 0x11, 0x5F, 0x01, 0x00, 0x00},      /* i */
+  { 0x02, 0x01, 0x01, 0x5E, 0x00, 0x00},      /* j */
+  { 0x00, 0x7F, 0x04, 0x0A, 0x11, 0x00},      /* k */
+  { 0x00, 0x41, 0x7F, 0x01, 0x00, 0x00},      /* l */
+  { 0x1F, 0x10, 0x0F, 0x10, 0x0F, 0x00},      /* m */
+  { 0x00, 0x1F, 0x10, 0x10, 0x0F, 0x00},      /* n */
+  { 0x0E, 0x11, 0x11, 0x11, 0x0E, 0x00},      /* 0 */
+  { 0x1F, 0x14, 0x14, 0x14, 0x08, 0x00},      /* p */
+  { 0x08, 0x14, 0x14, 0x14, 0x1F, 0x00},      /* q */
+  { 0x00, 0x1F, 0x08, 0x10, 0x10, 0x00},      /* r */
+  { 0x09, 0x15, 0x15, 0x15, 0x12, 0x00},      /* s */
+  { 0x00, 0x10, 0x7E, 0x11, 0x01, 0x00},      /* t */
+  { 0x00, 0x1E, 0x01, 0x01, 0x1F, 0x00},      /* u */
+  { 0x1C, 0x02, 0x01, 0x02, 0x1C, 0x00},      /* v */
+  { 0x1E, 0x01, 0x06, 0x01, 0x1E, 0x00},      /* w */
+  { 0x11, 0x0A, 0x04, 0x0A, 0x11, 0x00},      /* x */
+  { 0x18, 0x05, 0x05, 0x1E, 0x00, 0x00},      /* y */
+  { 0x11, 0x13, 0x15, 0x19, 0x11, 0x00},      /* z */
+  { 0x00, 0x08, 0x36, 0x41, 0x00, 0x00},      /* { */
+  { 0x00, 0x00, 0x7F, 0x00, 0x00, 0x00},      /* | */
+  { 0x00, 0x41, 0x36, 0x08, 0x00, 0x00},      /* } */
+  { 0x00, 0x20, 0x40, 0x20, 0x40, 0x00}       /* ~ */
+  };
diff --git a/darknet_drp_ros/src/ascii.h b/darknet_drp_ros/src/ascii.h
new file mode 100644
index 0000000..13e54aa
--- /dev/null
+++ b/darknet_drp_ros/src/ascii.h
@@ -0,0 +1,20 @@
+/***********************************************************************************************************************
+* Copyright (C) 2023 Renesas Electronics Corporation. All rights reserved.
+***********************************************************************************************************************/
+/***********************************************************************************************************************
+* File Name    : ascii.h
+* Version      : 0.90
+* Description  : RZ/V2H DRP-AI Sample Application for Megvii-Base Detection YOLOX with MIPI/USB Camera
+***********************************************************************************************************************/
+
+/* Multiple inclusion prevention macro */
+#ifndef ASCII_H
+#define ASCII_H
+
+/******************************************************************************
+Macro Definitions
+******************************************************************************/
+extern const char g_ascii_table[][6];
+
+/* ASCII_H */
+#endif
diff --git a/darknet_drp_ros/src/box.cpp b/darknet_drp_ros/src/box.cpp
new file mode 100644
index 0000000..86128bb
--- /dev/null
+++ b/darknet_drp_ros/src/box.cpp
@@ -0,0 +1,149 @@
+/***********************************************************************************************************************
+* Copyright (C) 2023 Renesas Electronics Corporation. All rights reserved.
+***********************************************************************************************************************/
+/***********************************************************************************************************************
+* File Name    : box.cpp
+* Version      : 0.90
+* Description  : RZ/V2H DRP-AI Sample Application for Megvii-Base Detection YOLOX with MIPI/USB Camera
+***********************************************************************************************************************/
+
+/*****************************************
+* Includes
+******************************************/
+#include "box.h"
+
+/*****************************************
+* Function Name : overlap
+* Description   : Function to compute the overlapped data between coordinate x with size w
+* Arguments     : x1 = 1-dimensional coordinate of first line
+*                 w1 = size of fist line
+*                 x2 = 1-dimensional coordinate of second line
+*                 w2 = size of second line
+* Return value  : overlapped line size
+******************************************/
+float overlap(float x1, float w1, float x2, float w2)
+{
+    float l1 = x1 - w1/2;
+    float l2 = x2 - w2/2;
+    float left = l1 > l2 ? l1 : l2;
+    float r1 = x1 + w1/2;
+    float r2 = x2 + w2/2;
+    float right = r1 < r2 ? r1 : r2;
+    return right - left;
+}
+
+/*****************************************
+* Function Name : box_intersection
+* Description   : Function to compute the area of intersection of Box a and b
+* Arguments     : a = Box 1
+*                 b = Box 2
+* Return value  : area of intersection
+******************************************/
+float box_intersection(Box a, Box b)
+{
+    float w = overlap(a.x, a.w, b.x, b.w);
+    float h = overlap(a.y, a.h, b.y, b.h);
+    if(w < 0 || h < 0)
+    {
+        return 0;
+    }
+    float area = w*h;
+    return area;
+}
+
+/*****************************************
+* Function Name : box_union
+* Description   : Function to compute the area of union of Box a and b
+* Arguments     : a = Box 1
+*                 b = Box 2
+* Return value  : area of union
+******************************************/
+float box_union(Box a, Box b)
+{
+    float i = box_intersection(a, b);
+    float u = a.w*a.h + b.w*b.h - i;
+    return u;
+}
+
+/*****************************************
+* Function Name : box_iou
+* Description   : Function to compute the Intersection over Union (IoU) of Box a and b
+* Arguments     : a = Box 1
+*                 b = Box 2
+* Return value  : IoU
+******************************************/
+float box_iou(Box a, Box b)
+{
+    return box_intersection(a, b)/box_union(a, b);
+}
+
+/*****************************************
+* Function Name : filter_boxes_nms
+* Description   : Apply Non-Maximum Suppression (NMS) to get rid of overlapped rectangles.
+* Arguments     : det= detected rectangles
+*                 size = number of detections stored in det
+*                 th_nms = threshold for nms
+* Return value  : -
+******************************************/
+void filter_boxes_nms(std::vector<detection> &det, int32_t size, float th_nms)
+{
+    int32_t count = size;
+    int32_t i = 0;
+    int32_t j = 0;
+    Box a;
+    Box b;
+    float b_intersection = 0;
+
+    /** Interation for the comparision source */
+    for (i = 0; i < count; i++)
+    {
+        /** Skip i-th process if the comparision source is already suppressed. */
+        if ( 0 == det[i].prob )
+        {
+            continue;
+        }
+
+        /** Load the coordinate of the comparision source. */
+        a = det[i].bbox;
+        
+        /** Interation for the comparision destination.  */
+        for (j = i+1; j < count; j++)
+        {
+            /** Skip j-th process if the comparision destination is already suppressed */
+            if ( 0 == det[j].prob )
+            {
+                continue;
+            }
+
+            /** Skip j-th process if the classes between the source and destination are same. */
+            if (det[i].c != det[j].c)
+            {
+                continue;
+            }
+
+            /** Load the coordinate of the comparision source. */
+            b = det[j].bbox;
+
+            /** Suppression check with NMS algorithm. */
+            b_intersection = box_intersection(a, b);
+            if ((box_iou(a, b)>th_nms) || (b_intersection >= a.h * a.w - 1) || (b_intersection >= b.h * b.w - 1))
+            {
+                /** The one having the lesser probability will be suppressed */
+                if (det[i].prob > det[j].prob)
+                {
+                    /** Suppress the comparision destination. */
+                    det[j].prob= 0;
+                }
+                else
+                {
+                    /** Suppress the comparision source. */
+                    det[i].prob= 0;
+
+                    /** Skip the loop of comparision destination if the comparision source is suppressed. */
+                    break;
+                }
+            }
+        }
+    }
+    return;
+}
diff --git a/darknet_drp_ros/src/box.h b/darknet_drp_ros/src/box.h
new file mode 100644
index 0000000..d069827
--- /dev/null
+++ b/darknet_drp_ros/src/box.h
@@ -0,0 +1,45 @@
+/***********************************************************************************************************************
+* Copyright (C) 2023 Renesas Electronics Corporation. All rights reserved.
+***********************************************************************************************************************/
+/***********************************************************************************************************************
+* File Name    : box.h
+* Version      : 0.90
+* Description  : RZ/V2H DRP-AI Sample Application for Megvii-Base Detection YOLOX with MIPI/USB Camera
+***********************************************************************************************************************/
+
+#ifndef BOX_H
+#define BOX_H
+
+#include <vector>
+#include <stdio.h>
+#include <math.h>
+#include <stdlib.h>
+
+/*****************************************
+* Box : Bounding box coordinates and its size
+******************************************/
+typedef struct
+{
+    float x, y, w, h;
+} Box;
+
+/*****************************************
+* detection : Detected result
+******************************************/
+typedef struct detection
+{
+    Box bbox;
+    int32_t c;
+    float prob;
+} detection;
+
+/*****************************************
+* Functions
+******************************************/
+float box_iou(Box a, Box b);
+float overlap(float x1, float w1, float x2, float w2);
+float box_intersection(Box a, Box b);
+float box_union(Box a, Box b);
+void filter_boxes_nms(std::vector<detection> &det, int32_t size, float th_nms);
+
+#endif
diff --git a/darknet_drp_ros/src/define.h b/darknet_drp_ros/src/define.h
new file mode 100644
index 0000000..ec25137
--- /dev/null
+++ b/darknet_drp_ros/src/define.h
@@ -0,0 +1,238 @@
+/***********************************************************************************************************************
+* Copyright (C) 2023 Renesas Electronics Corporation. All rights reserved.
+***********************************************************************************************************************/
+/***********************************************************************************************************************
+* File Name    : define.h
+* Version      : 0.90
+* Description  : RZ/V2H DRP-AI Sample Application for Megvii-Base Detection YOLOX with MIPI/USB Camera
+***********************************************************************************************************************/
+
+#ifndef DEFINE_MACRO_H
+#define DEFINE_MACRO_H
+
+/*****************************************
+* includes
+******************************************/
+#include <stdlib.h>
+#include <stdio.h>
+#include <unistd.h>
+#include <fcntl.h>
+#include <sys/ioctl.h>
+#include <sys/mman.h>
+#include <sys/stat.h>
+#include <errno.h>
+#include <vector>
+#include <map>
+#include <fstream>
+#include <math.h>
+#include <iomanip>
+#include <cstring>
+#include <float.h>
+#include <atomic>
+#include <semaphore.h>
+#include <numeric>
+/*****************************************
+* Macro for YOLOX
+******************************************/
+/* Input Camera support */
+/* n = 0: USB Camera, n = 1: eCAM22 */
+#define INPUT_CAM_TYPE 0
+
+/* Output Camera Size */
+#define CAM_INPUT_FHD
+#define IMAGE_OUTPUT_FHD
+#define MIPI_CAM_RES "1920x1080"
+
+/*Time Measurement Flag*/
+//#define DEBUG_TIME_FLG
+
+/*Display AI frame rate*/
+#define DISP_AI_FRAME_RATE
+
+/* Padding input mode to maintain the aspect ratio of DRP-AI input image.
+   This mode requires the DRP-AI object file having the squared input size CAM_IMAGE_WIDTH x CAM_IMAGE_WIDTH.
+   0: No padding, 
+   1: With padding (maintains the aspect ratio) */
+#define DRPAI_INPUT_PADDING (1)
+
+#if(1)  // TVM
+/* DRP-AI memory offset for model object file*/
+#define DRPAI_MEM_OFFSET            (0X38E0000)
+#endif  // TVM
+
+/*****************************************
+* Static Variables for YOLOX
+* Following variables need to be changed in order to custormize the AI model
+*  - drpai_prefix0 = directory name of DRP-AI Object files (DRP-AI Translator output)
+******************************************/
+/* Anchor box information */
+const static double anchors[] =
+{
+    1.08,   1.19,
+    3.42,   4.41,
+    6.63,   11.38,
+    9.42,   5.11,
+    16.62,  10.52
+};
+
+/*****************************************
+* Macro for YoloX
+******************************************/
+/* Number of class to be detected */
+#define NUM_CLASS                   (20)
+/* Number for [region] layer num parameter */
+#define NUM_BB                      (1)
+/* Number of output layers. This value MUST match with the length of num_grids[] below */
+#define NUM_INF_OUT_LAYER   (3)
+/* Number of grids in the image. The length of this array MUST match with the NUM_INF_OUT_LAYER */
+const static uint8_t num_grids[] = { 80,40,20 };
+/* Number of DRP-AI output */
+const static uint32_t num_inf_out =  (NUM_CLASS + 5) * NUM_BB * num_grids[0] * num_grids[0]
+                                + (NUM_CLASS + 5) * NUM_BB * num_grids[1] * num_grids[1]
+                                + (NUM_CLASS + 5) * NUM_BB * num_grids[2] * num_grids[2];/* Thresholds */
+
+#define TH_PROB                     (0.5f)
+#define TH_NMS                      (0.5f)
+/* Size of input image to the model */
+#define MODEL_IN_W                  (640)
+#define MODEL_IN_H                  (640)
+#define INPUT_W                    (640)
+#define INPUT_H                    (640)
+
+/*****************************************
+* Macro for Application
+******************************************/
+/*Maximum DRP-AI Timeout threshold*/
+#define DRPAI_TIMEOUT               (5)
+#if (1) // TVM
+/* DRP_MAX_FREQ and DRPAI_FREQ are the   */
+/* frequency settings for DRP-AI.        */
+/* Basically use the default values      */
+
+#define DRP_MAX_FREQ                (2)
+/* DRP_MAX_FREQ can be set from 2 to 127 */
+/* 2: 420MHz                             */
+/* 3: 315MHz                             */
+/* ...                                   */
+/* 127: 9.84MHz                          */
+/* Calculation Formula:                  */
+/*     1260MHz /(DRP_MAX_FREQ + 1)       */
+
+#define DRPAI_FREQ                  (2)
+/* DRPAI_FREQ can be set from 1 to 127   */
+/* 1,2: 1GHz                             */
+/* 3: 630MHz                             */
+/* 4: 420MHz                             */
+/* 5: 315MHz                             */
+/* ...                                   */
+/* 127: 10MHz                            */
+/* Calculation Formula:                  */
+/*     1260MHz /(DRPAI_FREQ - 1)         */
+/*     (When DRPAI_FREQ = 3 or more.)    */
+#endif  // TVM
+
+/*Camera:: Capture Image Information*/
+#ifdef CAM_INPUT_VGA
+#define CAM_IMAGE_WIDTH             (640)
+#define CAM_IMAGE_HEIGHT            (480)
+#else /* CAM_INPUT_FHD */
+#define CAM_IMAGE_WIDTH             (1920)
+#define CAM_IMAGE_HEIGHT            (1080)
+#endif
+
+#define CAM_IMAGE_CHANNEL_YUY2      (2)
+#define CAM_IMAGE_SIZE              (CAM_IMAGE_WIDTH * CAM_IMAGE_HEIGHT * CAM_IMAGE_CHANNEL_YUY2)
+
+/*Camera:: Capture Information */
+#if INPUT_CAM_TYPE == 1
+#define CAP_BUF_NUM                 (6)
+#define INPUT_CAM_NAME              "MIPI Camera"
+#else /* INPUT_CAM_TYPE */
+#define CAP_BUF_NUM                 (3)
+#define INPUT_CAM_NAME              "USB Camera"
+#endif /* INPUT_CAM_TYPE */
+
+/*DRP-AI Input image information*/
+#if (1) == DRPAI_INPUT_PADDING
+/*** DRP-AI input is assigned to the buffer having the size of CAM_IMAGE_WIDTH^2 */
+#define DRPAI_IN_WIDTH              (CAM_IMAGE_WIDTH)
+#define DRPAI_IN_HEIGHT             (CAM_IMAGE_WIDTH) 
+#define DRPAI_IN_CHANNEL_YUY2       (CAM_IMAGE_CHANNEL_YUY2)
+#else
+/** DRP-AI input is assigned to the buffer having the size of camera image. */
+#define DRPAI_IN_WIDTH              (CAM_IMAGE_WIDTH)
+#define DRPAI_IN_HEIGHT             (CAM_IMAGE_HEIGHT)
+#define DRPAI_IN_CHANNEL_YUY2       (CAM_IMAGE_CHANNEL_YUY2)
+#endif
+
+/*Wayland:: Wayland Information */
+#ifdef IMAGE_OUTPUT_HD
+#define IMAGE_OUTPUT_WIDTH          (1280)
+#define IMAGE_OUTPUT_HEIGHT         (720)
+#else /* IMAGE_OUTPUT_FHD */
+#define IMAGE_OUTPUT_WIDTH          (1920)
+#define IMAGE_OUTPUT_HEIGHT         (1080)
+#endif
+
+/*DRP-AI Input image information*/
+#ifdef CAM_INPUT_VGA
+#define DRPAI_OUT_WIDTH             (960)
+#define DRPAI_OUT_HEIGHT            (720)
+#else
+#define DRPAI_OUT_WIDTH             (IMAGE_OUTPUT_WIDTH)
+#define DRPAI_OUT_HEIGHT            (IMAGE_OUTPUT_HEIGHT)
+#endif
+
+#define IMAGE_CHANNEL_BGRA          (4)
+#define WL_BUF_NUM                  (2)
+
+/*input image memory area Information*/
+#define IMG_AREA_ORG_ADDRESS        (0xD0000000)    /* Note: Don't change this address */
+#define IMG_AREA_CNV_ADDRESS        (0x58000000)    /* CMA area start address used by mmngr */
+#define IMG_AREA_SIZE               (0x20000000)    /* CMA area size */
+
+#define IMAGEBUF                    (IMAGE_OUTPUT_WIDTH * IMAGE_OUTPUT_HEIGHT * IMAGE_CHANNEL_BGRA)
+#if (1) == DRPAI_INPUT_PADDING
+#define DRPAIBUF                    (CAM_IMAGE_WIDTH * CAM_IMAGE_WIDTH * CAM_IMAGE_CHANNEL_YUY2)
+#else   /* (1) == DRPAI_INPUT_PADDING */
+#define DRPAIBUF                    (CAM_IMAGE_WIDTH * CAM_IMAGE_HEIGHT * CAM_IMAGE_CHANNEL_YUY2)
+#endif  /* (1) == DRPAI_INPUT_PADDING */
+
+/*Image:: Text information to be drawn on image*/
+#define CHAR_SCALE_LARGE            (0.8)
+#define CHAR_SCALE_SMALL            (0.7)
+#define CHAR_THICKNESS              (2)
+#define LINE_HEIGHT                 (30) /*in pixel*/
+#define LINE_HEIGHT_OFFSET          (20) /*in pixel*/
+#define TEXT_WIDTH_OFFSET           (10) /*in pixel*/
+#define BOX_LINE_SIZE               (3)  /*in pixel*/
+#define BOX_HEIGHT_OFFSET           (30) /*in pixel*/
+#define BOX_TEXT_HEIGHT_OFFSET      (8)  /*in pixel*/
+#define CHAR_SCALE_FONT             (0.8)
+#define WHITE_DATA                  (0xFFFFFFu) /* in RGB */
+#define BLACK_DATA                  (0x000000u)
+
+/*Waiting Time*/
+#define WAIT_TIME                   (1000) /* microseconds */
+
+/*Timer Related*/
+#define CAPTURE_TIMEOUT             (20)  /* seconds */
+#define AI_THREAD_TIMEOUT           (20)  /* seconds */
+#define DISPLAY_THREAD_TIMEOUT      (20)  /* seconds */
+#define KEY_THREAD_TIMEOUT          (5)   /* seconds */
+#define TIME_COEF                   (1)
+
+/*Buffer size for writing data to memory via DRP-AI Driver.*/
+#define BUF_SIZE                    (1024)
+
+/*Array size*/
+#define SIZE_OF_ARRAY(array) (sizeof(array)/sizeof(array[0]))
+
+/*****************************************
+* For image.cpp
+******************************************/
+/*For drawing the bounding box label on image*/
+#define FONTDATA_WIDTH              (6)
+#define FONTDATA_HEIGHT             (8)
+
+#endif
diff --git a/darknet_drp_ros/src/define_color.h b/darknet_drp_ros/src/define_color.h
new file mode 100644
index 0000000..08949be
--- /dev/null
+++ b/darknet_drp_ros/src/define_color.h
@@ -0,0 +1,67 @@
+/***********************************************************************************************************************
+* Copyright (C) 2023 Renesas Electronics Corporation. All rights reserved.
+***********************************************************************************************************************/
+/***********************************************************************************************************************
+* File Name    : define_color.h
+* Version      : 0.90
+* Description  : RZ/V2H DRP-AI Sample Application for Megvii-Base Detection YOLOX with MIPI/USB Camera
+***********************************************************************************************************************/
+#ifndef DEFINE_COLOR_H
+#define DEFINE_COLOR_H
+
+/*****************************************
+* color
+******************************************/
+/* Pascal VOC dataset label list */
+const static std::vector<std::string> label_file_map = 
+{ 
+    "aeroplane",
+    "bicycle",
+    "bird",
+    "boat",
+    "bottle",
+    "bus",
+    "car",
+    "cat",
+    "chair",
+    "cow",
+    "diningtable",
+    "dog",
+    "horse",
+    "motorbike",
+    "person",
+    "pottedplant", 
+    "sheep",
+    "sofa",
+    "train",
+    "tvmonitor" 
+};
+
+/* box color list */
+const static unsigned int box_color[] =
+{
+    (0xFFFF00u),
+    (0xFF0000u),
+    (0xC0C0C0u),
+    (0xFFA07Au),
+    (0xFF1493u),
+    (0x006400u),
+    (0x00BFFFu),
+    (0xDAA520u),
+    (0xFF00FFu),
+    (0xFFC0CBu),
+    (0x008000u),
+    (0x800080u),
+    (0xFFA500u),
+    (0x1E90FFu),
+    (0x7CFC00u),
+    (0xF000F0u),
+    (0xF000FFu),
+    (0xFF00FFu),
+    (0xFF00FFu),
+    (0xFF0FFFu)
+};
+
+
+#endif
+
diff --git a/darknet_drp_ros/src/image.cpp b/darknet_drp_ros/src/image.cpp
new file mode 100644
index 0000000..8b78e18
--- /dev/null
+++ b/darknet_drp_ros/src/image.cpp
@@ -0,0 +1,574 @@
+/***********************************************************************************************************************
+* Copyright (C) 2023 Renesas Electronics Corporation. All rights reserved.
+***********************************************************************************************************************/
+/***********************************************************************************************************************
+* File Name    : image.cpp
+* Version      : 0.90
+* Description  : RZ/V2H DRP-AI Sample Application for Megvii-Base Detection YOLOX with MIPI/USB Camera
+***********************************************************************************************************************/
+
+/*****************************************
+* Includes
+******************************************/
+#include "image.h"
+#include <opencv2/opencv.hpp>
+
+// ROS
+#include "rclcpp/rclcpp.hpp"
+#include "rclcpp_action/rclcpp_action.hpp"
+#include "std_msgs/msg/header.hpp"
+#include "sensor_msgs/msg/image.hpp"
+#include "geometry_msgs/msg/point.hpp"
+#include "image_transport/image_transport.hpp"
+
+Image::Image()
+{
+
+}
+
+
+Image::~Image()
+{
+
+}
+
+/*****************************************
+* Function Name : get_H
+* Description   : Function to get the image height
+*                 This function is NOT used currently.
+* Arguments     : -
+* Return value  : img_h = current image height
+******************************************/
+uint32_t Image::get_H()
+{
+    return img_h;
+}
+
+
+/*****************************************
+* Function Name : get_W
+* Description   : Function to get the image width
+*                 This function is NOT used currently.
+* Arguments     : -
+* Return value  : img_w = current image width
+******************************************/
+uint32_t Image::get_W()
+{
+    return img_w;
+}
+
+
+/*****************************************
+* Function Name : get_C
+* Description   : Function to set the number of image channel
+*                 This function is NOT used currently.
+* Arguments     : c = new number of image channel to be set
+* Return value  : -
+******************************************/
+uint32_t Image::get_C()
+{
+    return img_c;
+}
+
+/*****************************************
+* Function Name : get_img
+* Description   : Function to return the camera buffer
+* Arguments     : -
+* Return value  : camera buffer
+******************************************/
+uint8_t* Image::get_img(uint8_t id)
+{
+    return img_buffer[id];
+}
+
+uint8_t* Image::get_overlay_img(uint8_t id)
+{
+    return overlay_buffer[id];
+}
+
+
+/*****************************************
+* Function Name : init
+* Description   : Function to initialize img_buffer in Image class
+*                 This application uses udmabuf in order to
+*                 continuous memory area for DRP-AI input data
+* Arguments     : w = input image width in YUYV
+*                 h = input image height in YUYV
+*                 c = input image channel in YUYV
+*                 ow = output image width in BGRA to be displayed via Wayland
+*                 oh = output image height in BGRA to be displayed via Wayland
+*                 oc = output image channel in BGRA to be displayed via Wayland
+*                 mem = pointer to the memory for the display buffer
+* Return value  : 0 if succeeded
+*                 not 0 otherwise
+******************************************/
+
+uint8_t Image::init(uint32_t w, uint32_t h, uint32_t c,
+                    uint32_t ow, uint32_t oh, uint32_t oc, void *mem)
+{
+    int32_t i;
+    
+    /*Initialize input image information */
+    img_w = w;
+    img_h = h;
+    img_c = c;
+    /*Initialize output image information*/
+    out_w = ow;
+    out_h = oh;
+    out_c = oc;
+
+    uint32_t out_size = out_w * out_h * out_c;
+
+    for (i = 0; i < WL_BUF_NUM; i++)
+    {
+        img_buffer[i] =(unsigned char*)mem+(i*out_size);
+    }
+
+    return 0;
+}
+
+/*****************************************
+* Function Name : write_char
+* Description   : Display character in overlap buffer
+* Arguments     : code = code to be displayed
+*                 x = X coordinate to display character
+*                 y = Y coordinate to display character
+*                 color = character color
+* Return value  : -
+******************************************/
+void Image::write_char(char code,  uint32_t x,  uint32_t y, uint32_t color, uint32_t backcolor)
+{
+    uint32_t height;
+    uint32_t width;
+    char * p_pattern;
+    uint8_t mask = 0x80;
+
+    if ((code >= 0x20) && (code <= 0x7e))
+    {
+        p_pattern = (char *)&g_ascii_table[code - 0x20][0];
+    }
+    else
+    {
+        p_pattern = (char *)&g_ascii_table[10][0]; /* '*' */
+    }
+
+    /* Drawing */
+    for (height = 0; height < font_h; height++)
+    {
+        for (width = 0; width < font_w; width++)
+        {
+            if (p_pattern[width] & mask)
+            {
+                draw_point_yuyv( width + x, height + y , color );
+            }
+            else
+            {
+                draw_point_yuyv( width + x, height + y , backcolor );
+            }
+        }
+        mask = (uint8_t)(mask >> 1);
+    }
+    return;
+}
+
+/*****************************************
+* Function Name : write_string_rgb
+* Description   : OpenCV putText() in RGB
+* Arguments     : str = string to be drawn
+*                 x = bottom left coordinate X of string to be drawn
+*                 y = bottom left coordinate Y of string to be drawn
+*                 scale = scale for letter size
+*                 color = letter color must be in RGB, e.g. white = 0xFFFFFF
+* Return Value  : -
+******************************************/
+void Image::write_string_rgb(std::string str, uint32_t align_type,  uint32_t x, uint32_t y, float scale, uint32_t color)
+{
+    uint8_t thickness = CHAR_THICKNESS;
+    /*Extract RGB information*/
+    uint8_t r = (color >> 16) & 0x0000FF;
+    uint8_t g = (color >>  8) & 0x0000FF;
+    uint8_t b = color & 0x0000FF;
+    int ptx = 0;
+    int pty = 0;
+    /*OpenCV image data is in BGRA */
+    cv::Mat bgra_image(out_h, out_w, CV_8UC4, img_buffer[buf_id]);
+
+    int baseline = 0;
+    cv::Size size = cv::getTextSize(str.c_str(), cv::FONT_HERSHEY_SIMPLEX, scale, thickness + 2, &baseline);
+    if (align_type == 1)
+    {
+        ptx = x;
+        pty = y;
+    }
+    else if (align_type == 2)
+    {
+        ptx = out_w - (size.width + x);
+        pty = y;
+    }
+    /*Color must be in BGR order*/
+    cv::putText(bgra_image, str.c_str(), cv::Point(ptx, pty), cv::FONT_HERSHEY_SIMPLEX, scale, cv::Scalar(0x00, 0x00, 0x00, 0xFF), thickness + 2);
+    cv::putText(bgra_image, str.c_str(), cv::Point(ptx, pty), cv::FONT_HERSHEY_SIMPLEX, scale, cv::Scalar(b, g, r, 0xFF), thickness);
+}
+/*****************************************
+* Function Name : write_string_rgb
+* Description   : OpenCV putText() in RGB
+* Arguments     : str = string to be drawn
+*                 x = bottom left coordinate X of string to be drawn
+*                 y = bottom left coordinate Y of string to be drawn
+*                 scale = scale for letter size
+*                 color = letter color must be in RGB, e.g. white = 0xFFFFFF
+* Return Value  : -
+******************************************/
+void Image::write_string_rgb_boundingbox(std::string str, uint32_t align_type,  uint32_t x_min, uint32_t y_min, uint32_t x_max, uint32_t y_max,float scale, uint32_t color)
+{
+    uint8_t thickness = CHAR_THICKNESS;
+    /*Extract RGB information*/
+    uint8_t r = (color >> 16) & 0x0000FF;
+    uint8_t g = (color >>  8) & 0x0000FF;
+    uint8_t b = color & 0x0000FF;
+	
+    int ptx = 0;
+    int pty = 0;
+    /*OpenCV image data is in BGRA */
+    cv::Mat bgra_image(out_h, out_w, CV_8UC4, img_buffer[buf_id]);
+
+    int baseline = 0;
+    cv::rectangle(bgra_image, cv::Point(x_min,y_min), cv::Point(x_max,y_max), cv::Scalar(b, g, r, 0xFF), BOX_LINE_SIZE);
+    
+    cv::Size size = cv::getTextSize(str.c_str(), cv::FONT_ITALIC, scale, thickness + 2, &baseline);
+    if (align_type == 1)
+    {
+        ptx = x_min;
+        pty = y_min;
+    }
+    else if (align_type == 2)
+    {
+        ptx = img_w - (size.width + x_min);
+        pty = y_min;
+    }
+    cv::rectangle(bgra_image, cv::Point(ptx-BOX_LINE_SIZE+1,pty-BOX_HEIGHT_OFFSET), cv::Point(ptx+size.width,pty), cv::Scalar(b, g, r, 0xFF), cv::FILLED);
+    /*Color must be in BGR order*/
+    cv::putText(bgra_image, str.c_str(), cv::Point(ptx, pty-BOX_TEXT_HEIGHT_OFFSET), cv::FONT_ITALIC, scale, cv::Scalar(0x00, 0x00, 0x00, 0xFF), thickness);
+}
+/*****************************************
+* Function Name : write_string
+* Description   : Display character string in overlap buffer
+* Arguments     : pcode = A pointer to the character string to be displayed
+*                 x = X coordinate to display character string
+*                 y = Y coordinate to display character string
+*                 color = character string color
+* Return Value  : -
+******************************************/
+void Image::write_string(const char * pcode, uint32_t x, uint32_t y, uint32_t color, uint32_t backcolor)
+{
+    uint32_t i;
+    uint32_t len = strlen(pcode);
+
+    x = x < 0 ? 2 : x;
+    x = (x > img_w - (i * font_w)) ? img_w - (i * font_w)-2 : x;
+    y = y < 0 ? 2 : y;
+    y = (y > img_h - font_h) ? img_h - font_h - 2 : y;
+
+    for (i = 0; i < len; i++)
+    {
+        write_char(pcode[i], (x + (i * font_w)), y, color, backcolor);
+    }
+
+    return;
+}
+
+/*****************************************
+* Function Name : draw_point_yuyv
+* Description   : Draw a single point on YUYV image
+* Arguments     : x = X coordinate to draw a point
+*                 y = Y coordinate to draw a point
+*                 color = point color
+* Return Value  : -
+******************************************/
+void Image::draw_point_yuyv(int32_t x, int32_t y, uint32_t color)
+{
+    uint32_t x0 = (uint32_t)x & ~0x1;
+
+    uint32_t draw_u = (color >> 8) & 0xFF;
+    uint32_t draw_v = (color >> 0) & 0xFF;
+
+    uint32_t target_u = img_buffer[buf_id][(y * img_w + x0) * img_c + 1];
+    uint32_t target_v = img_buffer[buf_id][(y * img_w + x0) * img_c + 3];
+
+    img_buffer[buf_id][(y * img_w + x0) * img_c + 1] = (draw_u + target_u) / 2;
+    img_buffer[buf_id][(y * img_w + x0) * img_c + 3] = (draw_v + target_v) / 2;
+
+    if ((x & 1) == 0)
+    {
+        img_buffer[buf_id][(y * img_w + x0) * img_c]     = (color >> 16) & 0xFF;
+    }
+    else
+    {
+        img_buffer[buf_id][(y * img_w + x0) * img_c + 2] = (color >> 16) & 0xFF;
+    }
+    return;
+}
+
+/*****************************************
+* Function Name : draw_line
+* Description   : Draw a single line
+* Arguments     : x0 = X coordinate of a starting point
+*                 y0 = Y coordinate of a starting point
+*                 x1 = X coordinate of a end point
+*                 y1 = Y coordinate of a end point
+*                 color = line color
+* Return Value  : -
+******************************************/
+void Image::draw_line(int32_t x0, int32_t y0, int32_t x1, int32_t y1, uint32_t color)
+{
+    int32_t dx = x1 - x0;
+    int32_t dy = y1 - y0;
+    int32_t sx = 1;
+    int32_t sy = 1;
+    float de;
+    int32_t i;
+
+    /* Change direction */
+    if (0 > dx)
+    {
+        dx *= -1;
+        sx *= -1;
+    }
+
+    if (0 > dy)
+    {
+        dy *= -1;
+        sy *= -1;
+    }
+
+    draw_point_yuyv(x0, y0, color);
+
+    if (dx > dy)
+    {
+        /* Horizontal Line */
+        for (i = dx, de = i / 2; i; i--)
+        {
+            x0 += sx;
+            de += dy;
+            if(de > dx)
+            {
+                de -= dx;
+                y0 += sy;
+            }
+            draw_point_yuyv(x0, y0, color);
+        }
+    }
+    else
+    {
+        /* Vertical Line */
+        for (i = dy, de = i / 2; i; i--)
+        {
+            y0 += sy;
+            de += dx;
+            if(de > dy)
+            {
+                de -= dy;
+                x0 += sx;
+            }
+            draw_point_yuyv(x0, y0, color);
+        }
+    }
+    return;
+}
+
+/*****************************************
+* Function Name : draw_rect
+* Description   : Draw a rectangle
+* Arguments     : x = X coordinate of the center of rectangle
+*                 y = Y coordinate of the center of rectangle
+*                 w = width of the rectangle
+*                 h = height of the rectangle
+*                 str = string to label the rectangle
+* Return Value  : -
+******************************************/
+void Image::draw_rect(int32_t x, int32_t y, int32_t w, int32_t h, const char * str,uint32_t color)
+{
+    int32_t x_min = x - round(w / 2.);
+    int32_t y_min = y - round(h / 2.);
+    int32_t x_max = x + round(w / 2.) - 1;
+    int32_t y_max = y + round(h / 2.) - 1;
+    /* Check the bounding box is in the image range */
+    x_min = x_min < 1 ? 1 : x_min;
+    x_max = ((img_w - 2) < x_max) ? (img_w - 2) : x_max;
+    y_min = y_min < 1 ? 1 : y_min;
+    y_max = ((img_h - 2) < y_max) ? (img_h - 2) : y_max;
+
+    /* Draw the bounding box and class and probability*/
+    write_string_rgb_boundingbox(str,1,x_min, y_min,x_max,y_max,CHAR_SCALE_FONT,color);
+
+    return;
+}
+
+
+/*****************************************
+* Function Name : convert_format
+* Description   : Convert YUYV image to BGRA format
+* Arguments     : -
+* Return value  : -
+******************************************/
+void Image::convert_format()
+{
+#ifdef DEBUG_TIME_FLG
+    using namespace std;
+    chrono::system_clock::time_point start, end;
+    start = chrono::system_clock::now();
+#endif // DEBUG_TIME_FLG
+
+    uint8_t* pd = img_buffer[buf_id];
+    uint8_t buffer[img_w * img_h * out_c];
+    int pix_count = 0;
+    for (int i = 0; i < img_h * img_w / 2; i++)
+    {
+        int y0 = (int)pd[0] - 16;
+        int u0 = (int)pd[1] - 128;
+        int y1 = (int)pd[2] - 16;
+        int v0 = (int)pd[3] - 128;
+
+        pd += 4;
+        buffer[pix_count++] = Clip((298 * y0 + 516 * u0 + 128) >> 8); // blue
+        buffer[pix_count++] = Clip((298 * y0 - 100 * u0 - 208 * v0 + 128) >> 8); // green
+        buffer[pix_count++] = Clip((298 * y0 + 409 * v0 + 128) >> 8); // red
+        buffer[pix_count++] = 255;
+
+        buffer[pix_count++] = Clip((298 * y1 + 516 * u0 + 128) >> 8); // blue
+        buffer[pix_count++] = Clip((298 * y1 - 100 * u0 - 208 * v0 + 128) >> 8); // green
+        buffer[pix_count++] = Clip((298 * y1 + 409 * v0 + 128) >> 8); // red
+        buffer[pix_count++] = 255;
+    }
+    memcpy(img_buffer[buf_id], &buffer, img_w * img_h * out_c);
+
+#ifdef DEBUG_TIME_FLG
+    end = chrono::system_clock::now();
+    double time = static_cast<double>(chrono::duration_cast<chrono::microseconds>(end - start).count() / 1000.0);
+    RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "Convert YUYV To BGRA Time : %lf[ms]\n", time);
+#endif // DEBUG_TIME_FLG
+}
+
+uint8_t Image::Clip(int value)
+{
+    //unsigned char ret = (uint8_t)std::round(value);
+    if (value > 255)
+    {
+        value = 255;
+    }
+    if (value < 0)
+    {
+        value = 0;
+    }
+    return value;
+}
+
+
+/*****************************************
+* Function Name : convert_size
+* Description   : Scale down the input data (1920x1080) to the output data (1280x720) using OpenCV.
+* Arguments     : -
+* Return value  : -
+******************************************/
+void Image::convert_size(int in_w, int resize_w, bool is_padding)
+{
+    if (in_w == resize_w)
+    {
+        return;
+    }
+
+    cv::Mat org_image(img_h, img_w, CV_8UC4, img_buffer[buf_id]);
+    cv::Mat resize_image;
+    /* Resize */
+    cv::resize(org_image, resize_image, cv::Size(), 1.0 * resize_w / in_w, 1.0 * resize_w / in_w);
+	
+    if (is_padding)
+    {
+        cv::Mat dst_image;
+        copyMakeBorder(resize_image, dst_image, 0, 0, (out_w - resize_w) / 2, (out_w - resize_w) / 2, cv::BORDER_CONSTANT, cv::Scalar(0, 0, 0, 255));
+        memcpy(img_buffer[buf_id], dst_image.data, out_w * out_h * out_c);
+    }
+    else
+    {
+        memcpy(img_buffer[buf_id], resize_image.data, out_w * out_h * out_c);
+    }
+}
+
+/*****************************************
+* Function Name : camera_to_image
+* Description   : Function to copy the external image buffer data to img_buffer
+*                 This is only place where the buf_id is updated.
+* Arguments     : buffer = buffer to copy the image data
+*                 size = size of buffer
+* Return value  : none
+******************************************/
+void Image::camera_to_image(const uint8_t* buffer, int32_t size)
+{
+    /* Update buffer id */
+    buf_id = ++buf_id % WL_BUF_NUM;
+    memcpy(img_buffer[buf_id], buffer, sizeof(uint8_t)*size);
+}
+
+
+/*****************************************
+* Function Name : at
+* Description   : Get the value of img_buffer at index a.
+*                 This function is NOT used currently.
+* Arguments     : a = index of img_buffer
+* Return Value  : value of img_buffer at index a
+******************************************/
+uint8_t Image::at(int32_t a)
+{
+    return img_buffer[buf_id][a];
+}
+
+/*****************************************
+* Function Name : set
+* Description   : Set the value of img_buffer at index a.
+*                 This function is NOT used currently.
+* Arguments     : a = index of img_buffer
+*                 val = new value to be set
+* Return Value  : -
+******************************************/
+void Image::set(int32_t a, uint8_t val)
+{
+    img_buffer[buf_id][a] = val;
+    return;
+}
+/*****************************************
+* Function Name : get_buf_id
+* Description   : Get the value of the buf_id.
+* Arguments     : -
+* Return Value  : value of buf_id-
+******************************************/
+uint8_t Image::get_buf_id(void)
+{
+    return buf_id;
+}
+
+
+/*****************************************
+* Function Name : reset_overlay_img
+* Description   : -
+* Arguments     : -
+* Return Value  : -
+******************************************/
+void Image::reset_overlay_img()
+{
+#ifdef DEBUG_TIME_FLG
+    using namespace std;
+    chrono::system_clock::time_point start, end;
+    start = chrono::system_clock::now();
+#endif // DEBUG_TIME_FLG
+
+    cv::Mat src_image = cv::Mat::zeros(out_h, out_w, CV_8UC4);
+    uint8_t* dst = overlay_buffer[buf_id];
+    uint8_t* src = src_image.data;
+    memcpy(dst, src, out_w * out_h * out_c);
+
+#ifdef DEBUG_TIME_FLG
+    end = chrono::system_clock::now();
+    double time = static_cast<double>(chrono::duration_cast<chrono::microseconds>(end - start).count() / 1000.0);
+    RCLCPP_INFO(rclcpp::get_logger("darknet_drp_ros"), "Reset Overlay Buffer Time : %lf[ms]\n", time);
+#endif // DEBUG_TIME_FLG
+}
diff --git a/darknet_drp_ros/src/image.h b/darknet_drp_ros/src/image.h
new file mode 100644
index 0000000..173064f
--- /dev/null
+++ b/darknet_drp_ros/src/image.h
@@ -0,0 +1,65 @@
+/***********************************************************************************************************************
+* Copyright (C) 2023 Renesas Electronics Corporation. All rights reserved.
+***********************************************************************************************************************/
+/***********************************************************************************************************************
+* File Name    : image.h
+* Version      : 0.90
+* Description  : RZ/V2H DRP-AI Sample Application for Megvii-Base Detection YOLOX with MIPI/USB Camera
+***********************************************************************************************************************/
+
+#ifndef IMAGE_H
+#define IMAGE_H
+
+#include "define.h"
+#include "ascii.h"
+
+class Image
+{
+    public:
+        Image();
+        ~Image();
+
+        uint8_t* img_buffer[WL_BUF_NUM];
+        uint8_t* overlay_buffer[WL_BUF_NUM];
+        uint8_t get_buf_id();
+        void write_string_rgb(std::string str, uint32_t align_type, uint32_t x, uint32_t y, float size, uint32_t color);
+        void write_string_rgb_boundingbox(std::string str, uint32_t align_type,  uint32_t x_min, uint32_t y_min, uint32_t x_max, uint32_t y_max,float scale, uint32_t color);
+
+        uint32_t get_H();
+        uint32_t get_W();
+        uint32_t get_C();
+        uint8_t* get_img(uint8_t id);
+        uint8_t* get_overlay_img(uint8_t id);
+        uint8_t at(int32_t a);
+        void set(int32_t a, uint8_t val);
+
+        uint8_t init(uint32_t w, uint32_t h, uint32_t c, uint32_t ow, uint32_t oh, uint32_t oc, void *mem);
+        void draw_rect(int32_t x, int32_t y, int32_t w, int32_t h, const char* str,uint32_t color);
+        void reset_overlay_img();
+        void convert_format();
+        void convert_size(int in_w, int resize_w, bool is_padding);
+        void camera_to_image(const uint8_t* buffer, int32_t size);
+    private:
+        uint8_t buf_id = 0;
+
+        /* Input Image (YUYV from V4L2) Information */
+        uint32_t img_h;
+        uint32_t img_w;
+        uint32_t img_c;
+        /* Output Image (BGRA for Wayland) Information */
+        uint32_t out_h;
+        uint32_t out_w;
+        uint32_t out_c;
+
+        uint32_t front_color        = BLACK_DATA;
+        uint32_t back_color         = WHITE_DATA;
+        uint8_t font_w              = FONTDATA_WIDTH;
+        uint8_t font_h              = FONTDATA_HEIGHT;
+        void draw_point_yuyv(int32_t x, int32_t y, uint32_t color);
+        void draw_line(int32_t x0, int32_t y0, int32_t x1, int32_t y1, uint32_t color);
+        void write_char(char code,  uint32_t x,  uint32_t y, uint32_t color, uint32_t backcolor);
+        void write_string(const char * pcode, uint32_t x, uint32_t y, uint32_t color, uint32_t backcolor);
+        uint8_t Clip(int value);
+};
+
+#endif
diff --git a/darknet_drp_ros/src/main.cpp b/darknet_drp_ros/src/main.cpp
new file mode 100644
index 0000000..96b7cca
--- /dev/null
+++ b/darknet_drp_ros/src/main.cpp
@@ -0,0 +1,1016 @@
+/***********************************************************************************************************************
+* Copyright (C) 2023 Renesas Electronics Corporation. All rights reserved.
+***********************************************************************************************************************/
+/***********************************************************************************************************************
+* File Name    : main.cpp
+* Version      : 0.90
+* Description  : RZ/V2H DRP-AI Sample Application for Megvii-Base Detection YOLOX with MIPI/USB Camera
+***********************************************************************************************************************/
+
+/*****************************************
+* Includes
+******************************************/
+/*DRP-AI TVM[*1] Runtime*/
+#include "MeraDrpRuntimeWrapper.h"
+/*Pre-processing Runtime Header*/
+#include "PreRuntime.h"
+
+/*DRPAI Driver Header*/
+#include <linux/drpai.h>
+/*Definition of Macros & other variables*/
+#include "define.h"
+#include "define_color.h"
+/*Image control*/
+#include "image.h"
+/*box drawing*/
+#include "box.h"
+/*Mutual exclusion*/
+#include <mutex>
+
+/* opencv */
+#include <opencv2/opencv.hpp>
+#include <opencv2/imgproc/imgproc.hpp>
+#include <opencv2/highgui/highgui.hpp>
+#include <opencv2/objdetect/objdetect.hpp>
+#include <cv_bridge/cv_bridge.h>
+#include "main.h"
+
+
+using namespace std;
+namespace drpai {
+/*****************************************
+* Global Variables
+******************************************/
+/*Multithreading*/
+static mutex mtx;
+
+/*Flags*/
+static atomic<uint8_t> inference_start (0);
+
+/*Global Variables*/
+static float drpai_output_buf[num_inf_out];
+static uint64_t capture_address;
+static uint8_t buf_id;
+static Image img;
+
+/*AI Inference for DRPAI*/
+static int drpai_fd0 = -1;
+/* DRP-AI TVM[*1] Runtime object */
+MeraDrpRuntimeWrapper runtime;
+/* Pre-processing Runtime object */
+PreRuntime preruntime;
+
+static double drpai_time = 0;
+#ifdef DISP_AI_FRAME_RATE
+static double ai_fps = 0;
+static double cap_fps = 0;
+static double proc_time_capture = 0;
+static uint32_t array_cap_time[30] = {1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000};
+#endif /* DISP_AI_FRAME_RATE */
+static uint32_t disp_time = 0;
+static uint32_t array_drp_time[30] = {1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000};
+static uint32_t array_disp_time[30] = {1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000};
+
+static vector<detection> det;
+
+
+static double pre_time = 0;
+static double post_time = 0;
+static double ai_time = 0;
+
+/*****************************************
+* Function Name     : float16_to_float32
+* Description       : Function by Edgecortex. Cast uint16_t a into float value.
+* Arguments         : a = uint16_t number
+* Return value      : float = float32 number
+******************************************/
+float float16_to_float32(uint16_t a)
+{
+    return __extendXfYf2__<uint16_t, uint16_t, 10, float, uint32_t, 23>(a);
+}
+
+/*****************************************
+* Function Name : timedifference_msec
+* Description   : compute the time differences in ms between two moments
+* Arguments     : t0 = start time
+*                 t1 = stop time
+* Return value  : the time difference in ms
+******************************************/
+double DRPAINode::timedifference_msec(struct timespec t0, struct timespec t1)
+{
+    return (t1.tv_sec - t0.tv_sec) * 1000.0 + (t1.tv_nsec - t0.tv_nsec) / 1000000.0;
+}
+
+/*****************************************
+* Function Name : get_result
+* Description   : Get DRP-AI Output from memory via DRP-AI Driver
+* Arguments     : -
+* Return value  : 0 if succeeded
+*                 not 0 otherwise
+******************************************/
+int8_t DRPAINode::get_result()
+{
+    int8_t ret = 0;
+    int32_t i = 0;
+    int32_t output_num = 0;
+    std::tuple<InOutDataType, void*, int64_t> output_buffer;
+    int64_t output_size;
+    uint32_t size_count = 0;
+
+    /* Get the number of output of the target model. */
+    output_num = runtime.GetNumOutput();
+    size_count = 0;
+    /*GetOutput loop*/
+    for (i = 0;i<output_num;i++)
+    {
+        /* output_buffer below is tuple, which is { data type, address of output data, number of elements } */
+        output_buffer = runtime.GetOutput(i);
+        /*Output Data Size = std::get<2>(output_buffer). */
+        output_size = std::get<2>(output_buffer);
+
+        /*Output Data Type = std::get<0>(output_buffer)*/
+        if (InOutDataType::FLOAT16 == std::get<0>(output_buffer))
+        {
+            /*Output Data = std::get<1>(output_buffer)*/
+            uint16_t* data_ptr = reinterpret_cast<uint16_t*>(std::get<1>(output_buffer));
+
+            for (int j = 0; j<output_size; j++)
+            {
+                /*FP16 to FP32 conversion*/
+                drpai_output_buf[j + size_count]=float16_to_float32(data_ptr[j]);
+            }
+        }
+        else if (InOutDataType::FLOAT32 == std::get<0>(output_buffer))
+        {
+            /*Output Data = std::get<1>(output_buffer)*/
+            float* data_ptr = reinterpret_cast<float*>(std::get<1>(output_buffer));
+            for (int j = 0; j<output_size; j++)
+            {
+                drpai_output_buf[j + size_count]=data_ptr[j];
+            }
+        }
+        else
+        {
+            RCLCPP_INFO(this->get_logger(), "[ERROR] Output data type : not floating point.");
+            ret = -1;
+            break;
+        }
+        size_count += output_size;
+    }
+    return ret;
+}
+
+/*****************************************
+* Function Name : sigmoid
+* Description   : Helper function for YOLO Post Processing
+* Arguments     : x = input argument for the calculation
+* Return value  : sigmoid result of input x
+******************************************/
+double DRPAINode::sigmoid(double x)
+{
+    return 1.0/(1.0 + exp(-x));
+}
+
+/*****************************************
+* Function Name : softmax
+* Description   : Helper function for YOLO Post Processing
+* Arguments     : val[] = array to be computed softmax
+* Return value  : -
+******************************************/
+void DRPAINode::softmax(float val[NUM_CLASS])
+{
+    float max_num = -FLT_MAX;
+    float sum = 0;
+    int32_t i;
+    for ( i = 0 ; i<NUM_CLASS ; i++ )
+    {
+        max_num = max(max_num, val[i]);
+    }
+
+    for ( i = 0 ; i<NUM_CLASS ; i++ )
+    {
+        val[i]= (float) exp(val[i] - max_num);
+        sum+= val[i];
+    }
+
+    for ( i = 0 ; i<NUM_CLASS ; i++ )
+    {
+        val[i]= val[i]/sum;
+    }
+    return;
+}
+
+/*****************************************
+* Function Name : index
+* Description   : Get the index of the bounding box attributes based on the input offset.
+* Arguments     : n = output layer number.
+*                 offs = offset to access the bounding box attributesd.
+*                 channel = channel to access each bounding box attribute.
+* Return value  : index to access the bounding box attribute.
+******************************************/
+int32_t DRPAINode::index(uint8_t n, int32_t offs, int32_t channel)
+{
+    uint8_t num_grid = num_grids[n];
+    return offs + channel * num_grid * num_grid;
+}
+
+/*****************************************
+* Function Name : offset
+* Description   : Get the offset nuber to access the bounding box attributes
+*                 To get the actual value of bounding box attributes, use index() after this function.
+* Arguments     : n = output layer number [0~2].
+*                 b = Number to indicate which bounding box in the region [0~2]
+*                 y = Number to indicate which region [0~13]
+*                 x = Number to indicate which region [0~13]
+* Return value  : offset to access the bounding box attributes.
+******************************************/
+int32_t DRPAINode::offset(uint8_t n, int32_t b, int32_t y, int32_t x)
+{
+    uint8_t num = num_grids[n];
+    uint32_t prev_layer_num = 0;
+    int32_t i = 0;
+
+    for (i = 0 ; i < n; i++)
+    {
+        prev_layer_num += NUM_BB *(NUM_CLASS + 5)* num_grids[i] * num_grids[i];
+    }
+    return prev_layer_num + b *(NUM_CLASS + 5)* num * num + y * num + x;
+}
+
+/*****************************************
+* Function Name : R_Post_Proc
+* Description   : Process CPU post-processing for YoloX
+* Arguments     : floatarr = drpai output address
+* Return value  : -
+******************************************/
+void DRPAINode::R_Post_Proc(float* floatarr)
+{
+    /* Following variables are required for correct_region_boxes in Darknet implementation*/
+    /* Note: This implementation refers to the "darknet detector test" */
+    vector<detection> det_buff;
+    float new_w, new_h;
+    float correct_w = 1.;
+    float correct_h = 1.;
+    if ((float) (MODEL_IN_W / correct_w) < (float) (MODEL_IN_H/correct_h) )
+    {
+        new_w = (float) MODEL_IN_W;
+        new_h = correct_h * MODEL_IN_W / correct_w;
+    }
+    else
+    {
+        new_w = correct_w * MODEL_IN_H / correct_h;
+        new_h = MODEL_IN_H;
+    }
+
+    int32_t n = 0;
+    int32_t b = 0;
+    int32_t y = 0;
+    int32_t x = 0;
+    int32_t offs = 0;
+    int32_t i = 0;
+    float tx = 0;
+    float ty = 0;
+    float tw = 0;
+    float th = 0;
+    float tc = 0;
+    float center_x = 0;
+    float center_y = 0;
+    float box_w = 0;
+    float box_h = 0;
+    float objectness = 0;
+    uint8_t num_grid = 0;
+    uint8_t anchor_offset = 0;
+    float classes[NUM_CLASS];
+    float max_pred = 0;
+    int32_t pred_class = -1;
+    float probability = 0;
+    detection d;
+    //YOLOX
+    int stride = 0;
+    vector<int> strides = {8, 16, 32};
+
+    for (n = 0; n<NUM_INF_OUT_LAYER; n++)
+    {
+        num_grid = num_grids[n];
+        anchor_offset = 2 * NUM_BB * (NUM_INF_OUT_LAYER - (n + 1));
+
+        for (b = 0;b<NUM_BB;b++)
+        {
+           stride = strides[n];
+            for (y = 0;y<num_grid;y++)
+            {
+                for (x = 0;x<num_grid;x++)
+                {
+                    offs = offset(n, b, y, x);
+                    tc = floatarr[index(n, offs, 4)];
+
+                    objectness = tc;
+
+                    if (objectness > TH_PROB)
+                    {
+                        /* Get the class prediction */
+                        for (i = 0;i < NUM_CLASS;i++)
+                        {
+                            classes[i] = floatarr[index(n, offs, 5+i)];
+                        }
+
+                        max_pred = 0;
+                        pred_class = -1;
+                        for (i = 0; i < NUM_CLASS; i++)
+                        {
+                            if (classes[i] > max_pred)
+                            {
+                                pred_class = i;
+                                max_pred = classes[i];
+                            }
+                        }
+
+                        /* Store the result into the list if the probability is more than the threshold */
+                        probability = max_pred * objectness;
+                        if (probability > TH_PROB)
+                        {
+                            tx = floatarr[offs];
+                            ty = floatarr[index(n, offs, 1)];
+                            tw = floatarr[index(n, offs, 2)];
+                            th = floatarr[index(n, offs, 3)];
+
+                            /* Compute the bounding box */
+                            /*get_yolo_box/get_region_box in paper implementation*/
+                            center_x = (tx+ float(x))* stride;
+                            center_y = (ty+ float(y))* stride;
+                            center_x = center_x  / (float) MODEL_IN_W;
+                            center_y = center_y  / (float) MODEL_IN_H;
+                            box_w = exp(tw) * stride;
+                            box_h = exp(th) * stride;
+                            box_w = box_w / (float) MODEL_IN_W;
+                            box_h = box_h / (float) MODEL_IN_H;
+                            
+                            /* Adjustment for size */
+                            /* correct_yolo/region_boxes */
+                            center_x = (center_x - (MODEL_IN_W - new_w) / 2. / MODEL_IN_W) / ((float) new_w / MODEL_IN_W);
+                            center_y = (center_y - (MODEL_IN_H - new_h) / 2. / MODEL_IN_H) / ((float) new_h / MODEL_IN_H);
+                            box_w *= (float) (MODEL_IN_W / new_w);
+                            box_h *= (float) (MODEL_IN_H / new_h);
+
+                            center_x = round(center_x * DRPAI_IN_WIDTH);
+                            center_y = round(center_y * DRPAI_IN_HEIGHT);
+                            box_w = round(box_w * DRPAI_IN_WIDTH);
+                            box_h = round(box_h * DRPAI_IN_HEIGHT);
+                            
+                            Box bb = {center_x, center_y, box_w, box_h};
+                            d = {bb, pred_class, probability};
+                            det_buff.push_back(d);
+                        }
+                    }
+                }
+            }
+        }
+    }
+    /* Non-Maximum Supression filter */
+    filter_boxes_nms(det_buff, det_buff.size(), TH_NMS);
+
+    img.convert_format();
+    draw_bounding_box();
+
+    cv::Mat out_image(CAM_IMAGE_HEIGHT, CAM_IMAGE_WIDTH, CV_8UC4, img.img_buffer[0]);
+
+    // Publish bounding box
+    darknet_ros_msgs::msg::BoundingBoxes boundingBoxesResults_;
+    int seq = 0;
+    for (int i = 0; i < det_buff.size(); i++)
+    {
+        if (det_buff[i].prob == 0)
+        {
+            continue;
+        }
+        darknet_ros_msgs::msg::BoundingBox boundingBox;
+        boundingBox.class_id = label_file_map[det_buff[i].c];
+        boundingBox.id = det_buff[i].c;
+        boundingBox.probability = det_buff[i].prob;
+        boundingBox.xmin = det_buff[i].bbox.x - round(det_buff[i].bbox.w / 2.);
+        boundingBox.ymin = det_buff[i].bbox.y - round(det_buff[i].bbox.h / 2.);
+        boundingBox.xmax = det_buff[i].bbox.x + round(det_buff[i].bbox.w / 2.) - 1;
+        boundingBox.ymax = det_buff[i].bbox.y + round(det_buff[i].bbox.h / 2.) - 1;
+
+        boundingBox.xmin = boundingBox.xmin < 1 ? 1 : boundingBox.xmin;
+        boundingBox.ymin = boundingBox.ymin < 1 ? 1 : boundingBox.ymin;
+        boundingBox.xmax = ((img.get_W() - 2) < boundingBox.xmax) ? (img.get_W() - 2) : boundingBox.xmax;
+        boundingBox.ymax = ((img.get_H() - 2) < boundingBox.ymax) ? (img.get_H() - 2) : boundingBox.ymax;
+        boundingBoxesResults_.bounding_boxes.push_back(boundingBox);
+        seq++;
+    }
+    boundingBoxesResults_.header.stamp = this->now();
+    boundingBoxesResults_.header.frame_id = "detection";
+    boundingBoxesResults_.image_header = imageHeader_;
+    boundingBoxesPublisher_->publish(boundingBoxesResults_);
+
+    // Publish object count
+    darknet_ros_msgs::msg::ObjectCount msg;
+    msg.header.stamp = this->now();
+    msg.header.frame_id = "detection";
+    msg.count = seq;
+    objectPublisher_->publish(msg);
+
+    cv_bridge::CvImage cvImage;
+    cvImage.header.stamp = this->now();
+    cvImage.header.frame_id = "detection_image";
+    cvImage.encoding = "bgra8";
+    cvImage.image = out_image;
+    sensor_msgs::msg::Image ros_img;
+    cvImage.toImageMsg(ros_img);
+    detectionImagePublisher_->publish(ros_img);
+
+    mtx.lock();
+    /* Clear the detected result list */
+    det.clear();
+    copy(det_buff.begin(), det_buff.end(), back_inserter(det));
+    mtx.unlock();
+    return ;
+}
+
+/*****************************************
+* Function Name : draw_bounding_box
+* Description   : Draw bounding box on image.
+* Arguments     : -
+* Return value  : 0 if succeeded
+*               not 0 otherwise
+******************************************/
+void DRPAINode::draw_bounding_box(void)
+{
+    vector<detection> det_buff;
+    stringstream stream;
+    string result_str;
+    int32_t i = 0;
+    uint32_t color=0;
+ 
+    mtx.lock();
+    copy(det.begin(), det.end(), back_inserter(det_buff));
+    mtx.unlock();
+
+    /* Draw bounding box on RGB image. */
+    for (i = 0; i < det_buff.size(); i++)
+    {
+        /* Skip the overlapped bounding boxes */
+        if (det_buff[i].prob == 0) continue;
+        
+        color = box_color[det_buff[i].c];
+        /* Clear string stream for bounding box labels */
+        stream.str("");
+        /* Draw the bounding box on the image */
+        stream << fixed << setprecision(2) << det_buff[i].prob;
+        result_str = label_file_map[det_buff[i].c]+ " "+ stream.str();
+        img.draw_rect((int)det_buff[i].bbox.x, (int)det_buff[i].bbox.y, (int)det_buff[i].bbox.w, (int)det_buff[i].bbox.h, result_str.c_str(),color);
+    }
+    return;
+}
+
+/*****************************************
+* Function Name : R_Inf_Thread
+* Description   : Executes the DRP-AI inference thread
+* Arguments     : none
+* Return value  : -
+******************************************/
+void *DRPAINode::R_Inf_Thread()
+{
+    /*Semaphore Variable*/
+    int32_t inf_sem_check = 0;
+    int32_t inf_cnt = -1;
+    
+    /*Variable for getting Inference output data*/
+    void* output_ptr;
+    uint32_t out_size;
+    /*Variable for Pre-processing parameter configuration*/
+    s_preproc_param_t in_param;
+
+    /*Variable for checking return value*/
+    int8_t ret = 0;
+    /*Variable for Performance Measurement*/
+
+    static struct timespec inf_start_time;
+    static struct timespec inf_end_time;
+    static struct timespec pre_start_time;
+    static struct timespec pre_end_time;
+    static struct timespec post_start_time;
+    static struct timespec post_end_time;
+    static struct timespec drp_prev_time = { .tv_sec = 0, .tv_nsec = 0, };
+
+    RCLCPP_INFO(this->get_logger(), "Inference Thread Starting");
+    RCLCPP_INFO(this->get_logger(), "Inference Loop Starting");
+    /*Inference Loop Start*/
+    while(1)
+    {
+        inf_cnt++;
+        while(1)
+        {
+            /*Gets the Termination request semaphore value. If different then 1 Termination was requested*/
+            /*Checks if sem_getvalue is executed wihtout issue*/
+            errno = 0;
+            if (bExec == false) {
+                goto ai_inf_end;
+            }
+            /*Checks if image frame from Capture Thread is ready.*/
+            if (inference_start.load())
+            {
+                break;
+            }
+            usleep(WAIT_TIME);
+        }
+
+        in_param.pre_in_addr    = /*(uintptr_t)*/ capture_address;
+        /*Gets Pre-process starting time*/
+        ret = timespec_get(&pre_start_time, TIME_UTC);
+        if (0 == ret)
+        {
+            RCLCPP_INFO(this->get_logger(), "[ERROR] Failed to get Pre-process Start Time");
+            goto err;
+        }
+        ret = preruntime.Pre(&in_param, &output_ptr, &out_size);
+        if (0 < ret)
+        {
+            RCLCPP_INFO(this->get_logger(), "[ERROR] Failed to run DRPAI_START: errno=%d", errno);
+            goto err;
+        }
+        /*Gets AI Pre-process End Time*/
+        ret = timespec_get(&pre_end_time, TIME_UTC);
+        if ( 0 == ret)
+        {
+            RCLCPP_INFO(this->get_logger(), "[ERROR] Failed to Get Pre-process End Time");
+            goto err;
+        }
+        /*Set Pre-processing output to be inference input. */
+        runtime.SetInput(0, (float*)output_ptr);
+        /*Pre-process Time Result*/
+        pre_time = (timedifference_msec(pre_start_time, pre_end_time) * TIME_COEF);
+
+        /*Gets inference starting time*/
+        ret = timespec_get(&inf_start_time, TIME_UTC);
+        if (0 == ret)
+        {
+            RCLCPP_INFO(this->get_logger(), "[ERROR] Failed to get Inference Start Time");
+            goto err;
+        }
+
+        runtime.Run(drpai_freq);
+
+        /*Gets AI Inference End Time*/
+        ret = timespec_get(&inf_end_time, TIME_UTC);
+        if ( 0 == ret)
+        {
+            RCLCPP_INFO(this->get_logger(), "[ERROR] Failed to Get Inference End Time");
+            goto err;
+        }
+        /*Inference Time Result*/
+        ai_time = (timedifference_msec(inf_start_time, inf_end_time) * TIME_COEF);
+
+        /*Gets Post-process starting time*/
+        ret = timespec_get(&post_start_time, TIME_UTC);
+        if (0 == ret)
+        {
+            RCLCPP_INFO(this->get_logger(), "[ERROR] Failed to get Post-process Start Time");
+            goto err;
+        }
+
+        /*Process to read the DRPAI output data.*/
+        ret = get_result();
+        if (0 != ret)
+        {
+            RCLCPP_INFO(this->get_logger(), "[ERROR] Failed to get result from memory.");
+            goto err;
+        }
+        /*Preparation for Post-Processing*/
+        /*CPU Post-Processing For YOLOX*/
+        R_Post_Proc(drpai_output_buf);
+
+        /* R_Post_Proc time end*/
+        ret = timespec_get(&post_end_time, TIME_UTC);
+        if (0 == ret)
+        {
+            RCLCPP_INFO(this->get_logger(), "[ERROR] Failed to Get R_Post_Proc End Time");
+            goto err;
+        }
+        post_time = (timedifference_msec(post_start_time, post_end_time)*TIME_COEF);
+
+        /*Display Processing Time On Log File*/
+        drpai_time = timedifference_msec(inf_start_time, inf_end_time) * TIME_COEF;
+        int idx = inf_cnt % SIZE_OF_ARRAY(array_drp_time);
+        ai_time = (uint32_t)((timedifference_msec(inf_start_time, inf_end_time) * TIME_COEF));
+        array_drp_time[idx] = ai_time;
+        drp_prev_time = inf_end_time;
+        uint32_t total_time = ai_time + pre_time + post_time;
+
+#ifdef DISP_AI_FRAME_RATE
+        int arraySum = std::accumulate(array_drp_time, array_drp_time + SIZE_OF_ARRAY(array_drp_time), 0);
+        double arrayAvg = 1.0 * arraySum / SIZE_OF_ARRAY(array_drp_time);
+        ai_fps = 1.0 / arrayAvg * 1000.0 + 0.5;
+        RCLCPP_INFO(this->get_logger(), "AI Frame Rate %d [fps]", (int32_t)ai_fps);
+#endif /* DISP_AI_FRAME_RATE */
+
+        inference_start.store(0);
+    }
+    /*End of Inference Loop*/
+
+/*Error Processing*/
+err:
+/*AI Thread Termination*/
+ai_inf_end:
+    /*To terminate the loop in Capture Thread.*/
+    RCLCPP_INFO(this->get_logger(), "AI Inference Thread Terminated");
+    pthread_exit(NULL);
+}
+
+void DRPAINode::cameraCallback(const sensor_msgs::msg::Image::ConstSharedPtr & msg)
+{
+    cv_bridge::CvImagePtr cam_image;
+    cam_image = cv_bridge::toCvCopy(msg, "rgb8");
+    uint8_t * img_buffer0;
+    
+    img_buffer0 = (uint8_t *)drpai_buf_->mem;
+
+    // If the interface is down, keep the image
+    if (!inference_start.load())
+    {
+        if (cam_image)
+        {
+            recv_img = cam_image->image.clone();
+            imageHeader_ = msg->header;
+
+            // resize
+            if (recv_img.size().width != CAM_IMAGE_WIDTH ||
+                            recv_img.size().height != CAM_IMAGE_HEIGHT)
+            {
+                cv::resize(recv_img, recv_img, cv::Size(CAM_IMAGE_WIDTH, CAM_IMAGE_HEIGHT));
+            }
+            // The weight of yolo is YUYV, so convert it to YUYV
+            uint64_t idx;
+            for (idx = 0; idx < CAM_IMAGE_WIDTH * CAM_IMAGE_HEIGHT; idx++) {
+                double r = recv_img.data[3 * idx + 0];
+                double g = recv_img.data[3 * idx + 1];
+                double b = recv_img.data[3 * idx + 2];
+                double y = 0.257 * r + 0.504 * g + 0.098 * b + 16.0;
+                double u = -0.148 * r - 0.291 * g + 0.439 * b + 128.0;
+                double v = 0.439 * r - 0.368 * g - 0.071 * b + 128.0;
+                double uv;
+                if ((idx % 2) == 0) {
+                    uv = u;
+                } else {
+                    uv = v;
+                }
+                if (y < 0) y = 0;
+                if (y > 255) y = 255;
+                if (uv < 0) uv = 0;
+                if (uv > 255) uv = 255;
+                img.img_buffer[0][2 * idx + 0] = (uint8_t)y;
+                img.img_buffer[0][2 * idx + 1] = (uint8_t)uv;
+                img_buffer0[2 * idx + 0] = (uint8_t)y;
+                img_buffer0[2 * idx + 1] = (uint8_t)uv;
+            }
+            // launch the interface
+            int ret = image_buffer_flush_dmabuf(image_buf_->idx, image_buf_->size);
+            if (0 != ret)
+            {
+                RCLCPP_INFO(this->get_logger(), "[ERROR] flush dmabuf error");
+                return;
+            }
+            ret = image_buffer_flush_dmabuf(drpai_buf_->idx, drpai_buf_->size);
+            if (0 != ret)
+            {
+                RCLCPP_INFO(this->get_logger(), "[ERROR] flush dmabuf error (drpai buffer) ");
+                return;
+            }
+            inference_start.store(1);
+        }
+    }
+    return;
+}
+
+/*****************************************
+* Function Name : get_drpai_start_addr
+* Description   : Function to get the start address of DRPAImem.
+* Arguments     : drpai_fd: DRP-AI file descriptor
+* Return value  : If non-zero, DRP-AI memory start address.
+*                 0 is failure.
+******************************************/
+uint64_t DRPAINode::get_drpai_start_addr(int drpai_fd)
+{
+    int ret = 0;
+    drpai_data_t drpai_data;
+
+    errno = 0;
+
+    /* Get DRP-AI Memory Area Address via DRP-AI Driver */
+    ret = ioctl(drpai_fd , DRPAI_GET_DRPAI_AREA, &drpai_data);
+    if (-1 == ret)
+    {
+        std::cerr << "[ERROR] Failed to get DRP-AI Memory Area : errno=" << errno << std::endl;
+        return 0;
+    }
+
+    return drpai_data.address;
+}
+
+/*****************************************
+* Function Name : set_drp_freq
+* Description   : Function to set the DRP frequency.
+* Arguments     : drpai_fd: DRP-AI file descriptor
+* Return value  : 0 if succeeded
+*                 not 0 otherwise
+******************************************/
+int DRPAINode::set_drp_freq(int drpai_fd)
+{
+    int ret = 0;
+    uint32_t data;
+
+    errno = 0;
+    data = drp_max_freq;
+    ret = ioctl(drpai_fd , DRPAI_SET_DRP_MAX_FREQ, &data);
+    if (-1 == ret)
+    {
+        std::cerr << "[ERROR] Failed to set DRP Max Frequency : errno=" << errno << std::endl;
+        return -1;
+    }
+
+    return 0;
+}
+
+/*****************************************
+* Function Name : init_drpai
+* Description   : Function to initialize DRP-AI.
+* Arguments     : drpai_fd: DRP-AI file descriptor
+* Return value  : If non-zero, DRP-AI memory start address.
+*                 0 is failure.
+******************************************/
+uint64_t DRPAINode::init_drpai(int drpai_fd)
+{
+    int ret = 0;
+    uint64_t drpai_addr = 0;
+
+    /*Get DRP-AI memory start address*/
+    drpai_addr = get_drpai_start_addr(drpai_fd);
+    if (drpai_addr == 0)
+    {
+        return 0;
+    }
+
+    /*Set DRP-AI frequency*/
+    ret = set_drp_freq(drpai_fd);
+    if (ret != 0)
+    {
+        return 0;
+    }
+
+    return drpai_addr;
+}
+
+int32_t DRPAINode::main_entry()
+{
+    using std::placeholders::_1;
+    drpai_path = "/darknet_drp_ros";
+    declare_parameter("config_path", drpai_path);
+    declare_parameter("drpai_freq", drpai_freq);
+    declare_parameter("drp_max_freq", drp_max_freq);
+
+    get_parameter("confi_path", drpai_path);
+    get_parameter("drpai_freq", drpai_freq);
+    get_parameter("drp_max_freq", drp_max_freq);
+
+    imageSubscriber_ = image_transport::create_subscription(this, 
+                            std::string("/camera/image_raw"),
+                            std::bind(&DRPAINode::cameraCallback, this, _1),
+                            "raw");
+    objectPublisher_ = this->create_publisher<darknet_ros_msgs::msg::ObjectCount>(
+                            std::string("found_object"), 1);
+    boundingBoxesPublisher_ = this->create_publisher<darknet_ros_msgs::msg::BoundingBoxes>(
+                            std::string("bounding_boxes"), 1);
+    detectionImagePublisher_ = this->create_publisher<sensor_msgs::msg::Image>(
+                            std::string("detection_image"), 1);
+
+    int8_t main_proc = 0;
+    int8_t ret = 0;
+    int8_t ret_main = 0;
+
+    InOutDataType input_data_type;
+    bool runtime_status = false;
+
+    uint8_t * img_buffer0;
+
+    RCLCPP_INFO(this->get_logger(),"************************************************");
+    RCLCPP_INFO(this->get_logger(),"  RZ/V2H DRP-AI Sample Application");
+    RCLCPP_INFO(this->get_logger(),"  Model : Lightnet YOLOX | %s", drpai_path.c_str());
+    RCLCPP_INFO(this->get_logger(),"  Input : USB Camera");
+    RCLCPP_INFO(this->get_logger(),"************************************************");
+
+    image_buf_ = (image_dma_buffer*)malloc(sizeof(image_buf_));
+    ret = image_buffer_alloc_dmabuf(image_buf_, IMAGEBUF);
+    if (-1 == ret)
+    {
+        RCLCPP_INFO(this->get_logger(), "[ERROR] Failed to Allocate DMA buffer for the image_buf_");
+        return -1;
+    }
+
+    uint64_t drpaimem_addr_start = 0;
+    
+    errno = 0;
+    int drpai_fd0 = open("/dev/drpai0", O_RDWR);
+    if (0 > drpai_fd0)
+    {
+        RCLCPP_INFO(this->get_logger(), "[ERROR] Failed to open DRP-AI Driver : errno=%d", errno);
+        goto end_threads;
+    }
+    
+    /*Initialzie DRP-AI (Get DRP-AI memory address and set DRP-AI frequency)*/
+    drpaimem_addr_start = init_drpai(drpai_fd0);
+    if (drpaimem_addr_start == 0)
+    {
+        goto end_threads;
+    }
+
+    /*Load pre_dir object to DRP-AI */
+    ret = preruntime.Load(drpai_path + "/preprocess");
+    if (0 < ret)
+    {
+        RCLCPP_INFO(this->get_logger(), "[ERROR] Failed to run Pre-processing Runtime Load().");
+        goto end_threads;
+    }
+
+    runtime_status = runtime.LoadModel(drpai_path, drpaimem_addr_start);
+
+    if(!runtime_status)
+    {
+        RCLCPP_INFO(this->get_logger(), "[ERROR] Failed to load model.");
+        goto end_threads;
+    }
+
+    /*Get input data */
+    input_data_type = runtime.GetInputDataType(0);
+    if (InOutDataType::FLOAT32 == input_data_type)
+    {
+        /*Do nothing*/
+    }
+    else if (InOutDataType::FLOAT16 == input_data_type)
+    {
+        RCLCPP_INFO(this->get_logger(), "[ERROR] Input data type : FP16.");
+        /*If your model input data type is FP16, use std::vector<uint16_t> for reading input data. */
+        goto end_threads;
+    }
+    else
+    {
+        RCLCPP_INFO(this->get_logger(), "[ERROR] Input data type : neither FP32 nor FP16.");
+        goto end_threads;
+    }
+
+    /* Create drpai_buffer */
+    drpai_buf_ = (image_dma_buffer*)malloc(sizeof(image_dma_buffer));
+    ret = image_buffer_alloc_dmabuf(drpai_buf_,DRPAIBUF);
+    if (-1 == ret)
+    {
+        RCLCPP_INFO(this->get_logger(), "[ERROR] Failed to Allocate DMA buffer for the drpai_buf");
+        ret_main = ret;
+        goto end_threads;
+    }
+    img_buffer0 = (uint8_t *)drpai_buf_->mem;
+#if (1) == DRPAI_INPUT_PADDING
+    /** Fill buffer with the brightness 114. */
+    for( uint32_t i = 0; i < CAM_IMAGE_WIDTH * CAM_IMAGE_WIDTH * CAM_IMAGE_CHANNEL_YUY2; i += 4 )
+    {
+        /// Y =  0.299R + 0.587G + 0.114B
+        img_buffer0[i]   = 114;    
+        img_buffer0[i+2] = 114;
+        /// U = -0.169R - 0.331G + 0.500B + 128
+        img_buffer0[i+1] = 128;
+        /// V =  0.500R - 0.419G - 0.081B + 128
+        img_buffer0[i+3] = 128;
+    }
+#endif  /* (1) == DRPAI_INPUT_PADDING */
+    capture_address = drpai_buf_->phy_addr;
+
+    /*Initialize Image object.*/
+    ret = img.init(CAM_IMAGE_WIDTH, CAM_IMAGE_HEIGHT, CAM_IMAGE_CHANNEL_YUY2, IMAGE_OUTPUT_WIDTH, IMAGE_OUTPUT_HEIGHT, IMAGE_CHANNEL_BGRA, image_buf_->mem);
+    if (0 != ret)
+    {
+        RCLCPP_INFO(this->get_logger(), "[ERROR] Failed to initialize Image object.");
+        ret_main = ret;
+        goto end_threads;
+    }
+
+    /*Create Inference Thread*/
+    ai_inf_thread = std::thread(&DRPAINode::R_Inf_Thread, this);
+
+end_threads:
+    return ret_main;
+}
+
+void DRPAINode::terminate()
+{
+    int ret;
+    bExec = false;
+    ai_inf_thread.join();
+    
+    image_buffer_free_dmabuf(drpai_buf_);
+    free(drpai_buf_);
+    drpai_buf_ = NULL;
+
+    image_buffer_free_dmabuf(image_buf_);
+    free(image_buf_);
+    image_buf_ = NULL;
+
+    /*Close DRP-AI Driver.*/
+    if (0 < drpai_fd0)
+    {
+        errno = 0;
+        ret = close(drpai_fd0);
+        if (0 != ret)
+        {
+            RCLCPP_INFO(this->get_logger(), "[ERROR] Failed to close DRP-AI Driver: errno=%d", errno);
+        }
+    }
+    RCLCPP_INFO(this->get_logger(), "Application End");
+    return ;
+}
+
+/*****************************************
+* Function Name : image_buffer_alloc_dmabuf
+* Description   : Allocate a DMA buffer for the image
+* Arguments     : buffer = pointer to the image_dma_buffer struct
+* Return value  : 0 if succeeded
+*                 not 0 otherwise
+******************************************/
+int8_t DRPAINode::image_buffer_alloc_dmabuf(struct image_dma_buffer *buffer, int buf_size)
+{
+    MMNGR_ID id;
+    uint32_t phard_addr;
+    void *puser_virt_addr;
+    int m_dma_fd;
+
+    buffer->size = buf_size;
+    mmngr_alloc_in_user_ext(&id, buffer->size, &phard_addr, &puser_virt_addr, MMNGR_VA_SUPPORT_CACHED, NULL);
+    memset((void*)puser_virt_addr, 0, buffer->size);
+    buffer->idx = id;
+    buffer->mem = (void *)puser_virt_addr;
+    buffer->phy_addr = phard_addr;
+    if (!buffer->mem)
+    {
+        return -1;
+    }
+    mmngr_export_start_in_user_ext(&id, buffer->size, phard_addr, &m_dma_fd, NULL);
+    buffer->dbuf_fd = m_dma_fd;
+    return 0;
+}
+
+/*****************************************
+* Function Name : image_buffer_free_dmabuf
+* Description   : free a DMA buffer for the image
+* Arguments     : buffer = pointer to the image_dma_buffer struct
+* Return value  : -
+******************************************/
+void DRPAINode::image_buffer_free_dmabuf(struct image_dma_buffer *buffer)
+{
+    mmngr_free_in_user_ext(buffer->idx);
+    return;
+}
+
+/*****************************************
+* Function Name : image_buffer_flush_dmabuf
+* Description   : flush a DMA buffer for the image
+* Arguments     : buffer = pointer to the image_dma_buffer struct
+* Return value  : 0 if succeeded
+*                 not 0 otherwise
+******************************************/
+int DRPAINode::image_buffer_flush_dmabuf(uint32_t idx, uint32_t size)
+{
+    int mm_ret = 0;
+    
+    /* Flush capture image area cache */
+    mm_ret = mmngr_flush(idx, 0, size);
+    
+    return mm_ret;
+}
+
+DRPAINode::DRPAINode() : Node("darknet_drp_ros")
+{
+}
+
+DRPAINode::~DRPAINode()
+{
+}
+} /* namespace drpai */
+
+
+int main(int argc, char** argv) {
+  rclcpp::init(argc, argv);
+
+  auto drpai_node = std::make_shared<drpai::DRPAINode>();
+
+  drpai_node->main_entry();
+  
+  rclcpp::Rate loop_rate(60);
+  int cnt = 0;
+  while(rclcpp::ok()){
+    rclcpp::spin_some(drpai_node);
+    loop_rate.sleep();
+  }
+  drpai_node->terminate();
+
+  rclcpp::shutdown();
+
+  return 0;
+}
diff --git a/darknet_drp_ros/src/main.h b/darknet_drp_ros/src/main.h
new file mode 100644
index 0000000..d65f477
--- /dev/null
+++ b/darknet_drp_ros/src/main.h
@@ -0,0 +1,91 @@
+// ROS
+#include "rclcpp/rclcpp.hpp"
+#include "rclcpp_action/rclcpp_action.hpp"
+#include "std_msgs/msg/header.hpp"
+#include "sensor_msgs/msg/image.hpp"
+#include "geometry_msgs/msg/point.hpp"
+#include "image_transport/image_transport.hpp"
+
+#include "darknet_ros_msgs/msg/bounding_boxes.hpp"
+#include "darknet_ros_msgs/msg/bounding_box.hpp"
+#include "darknet_ros_msgs/msg/object_count.hpp"
+#include "darknet_ros_msgs/action/check_for_objects.hpp"
+
+/* This block of code is only accessible from C code. */
+#ifdef __cplusplus
+extern "C" {
+#endif
+#include <mmngr_user_public.h>
+#include <mmngr_buf_user_public.h>
+#ifdef __cplusplus
+}
+#endif
+
+namespace drpai {
+class DRPAINode : public rclcpp::Node
+{
+ public:
+  struct image_dma_buffer
+  {
+   /* The index of the buffer. */
+   uint32_t idx;
+   /* The file descriptor for the DMA buffer. */
+   uint32_t dbuf_fd;
+   /* The size of the buffer in bytes. */
+   uint32_t size;
+   /* The physical address of DMA buffer. */
+   uint32_t phy_addr;
+   /* The pointer to the memory for the buffer. */
+   void *mem;           
+  };
+  explicit DRPAINode();
+  ~DRPAINode();
+  int32_t start_proc();
+  int32_t main_entry();
+  void terminate();
+  void *R_Inf_Thread();
+
+  void R_Post_Proc(float* floatarr);
+  int8_t R_Main_Process(void);
+  double timedifference_msec(struct timespec t0, struct timespec t1);
+  void draw_bounding_box(void);
+
+#if (1) //TVM
+  uint64_t get_drpai_start_addr(int drpai_fd);
+  int set_drp_freq(int drpai_fd);
+  uint64_t init_drpai(int drpai_fd);
+#endif
+
+  void cameraCallback(const sensor_msgs::msg::Image::ConstSharedPtr & msg);
+  std_msgs::msg::Header imageHeader_;
+
+  //! ROS subscriber and publisher.
+  image_transport::Subscriber imageSubscriber_;
+  rclcpp::Publisher<darknet_ros_msgs::msg::ObjectCount>::SharedPtr objectPublisher_;
+  rclcpp::Publisher<darknet_ros_msgs::msg::BoundingBoxes>::SharedPtr boundingBoxesPublisher_;
+  rclcpp::Publisher<sensor_msgs::msg::Image>::SharedPtr detectionImagePublisher_;
+  struct image_dma_buffer *image_buf_;
+  struct image_dma_buffer *drpai_buf_;
+
+  int8_t image_buffer_alloc_dmabuf(struct image_dma_buffer *buffer, int buf_size);
+  void image_buffer_free_dmabuf(struct image_dma_buffer *buffer);
+  int image_buffer_flush_dmabuf(uint32_t idx, uint32_t size);
+
+  int32_t ceil3(int32_t num, int32_t base);
+  int8_t get_result();
+  double sigmoid(double x);
+  void softmax(float val[NUM_CLASS]);
+  int32_t index(uint8_t n, int32_t offs, int32_t channel);
+  int32_t offset(uint8_t n, int32_t b, int32_t y, int32_t x);
+
+  cv::Mat recv_img;
+  int drpai_freq = DRPAI_FREQ;
+  int drp_max_freq = DRP_MAX_FREQ;
+  std::string drpai_path;
+  std::thread ai_inf_thread;
+
+  bool bExec = true;
+};
+
+} /* namespace drpai */
+
diff --git a/darknet_ros/test/ObjectDetection.cpp b/darknet_drp_ros/test/ObjectDetection.cpp
similarity index 100%
rename from darknet_ros/test/ObjectDetection.cpp
rename to darknet_drp_ros/test/ObjectDetection.cpp
diff --git a/darknet_ros/test/object_detection.test b/darknet_drp_ros/test/object_detection.test
similarity index 100%
rename from darknet_ros/test/object_detection.test
rename to darknet_drp_ros/test/object_detection.test
diff --git a/darknet_ros/test/test_main.cpp b/darknet_drp_ros/test/test_main.cpp
similarity index 100%
rename from darknet_ros/test/test_main.cpp
rename to darknet_drp_ros/test/test_main.cpp
diff --git a/darknet_ros/test/yolov2.yaml b/darknet_drp_ros/test/yolov2.yaml
similarity index 100%
rename from darknet_ros/test/yolov2.yaml
rename to darknet_drp_ros/test/yolov2.yaml
diff --git a/darknet_ros/yolo_network_config/cfg/yolov2-tiny-voc.cfg b/darknet_drp_ros/yolo_network_config/cfg/yolov2-tiny-voc.cfg
similarity index 100%
rename from darknet_ros/yolo_network_config/cfg/yolov2-tiny-voc.cfg
rename to darknet_drp_ros/yolo_network_config/cfg/yolov2-tiny-voc.cfg
diff --git a/darknet_ros/yolo_network_config/cfg/yolov2-tiny.cfg b/darknet_drp_ros/yolo_network_config/cfg/yolov2-tiny.cfg
similarity index 100%
rename from darknet_ros/yolo_network_config/cfg/yolov2-tiny.cfg
rename to darknet_drp_ros/yolo_network_config/cfg/yolov2-tiny.cfg
diff --git a/darknet_ros/yolo_network_config/cfg/yolov2-voc.cfg b/darknet_drp_ros/yolo_network_config/cfg/yolov2-voc.cfg
similarity index 100%
rename from darknet_ros/yolo_network_config/cfg/yolov2-voc.cfg
rename to darknet_drp_ros/yolo_network_config/cfg/yolov2-voc.cfg
diff --git a/darknet_ros/yolo_network_config/cfg/yolov2.cfg b/darknet_drp_ros/yolo_network_config/cfg/yolov2.cfg
similarity index 100%
rename from darknet_ros/yolo_network_config/cfg/yolov2.cfg
rename to darknet_drp_ros/yolo_network_config/cfg/yolov2.cfg
diff --git a/darknet_ros/yolo_network_config/cfg/yolov3-voc.cfg b/darknet_drp_ros/yolo_network_config/cfg/yolov3-voc.cfg
similarity index 100%
rename from darknet_ros/yolo_network_config/cfg/yolov3-voc.cfg
rename to darknet_drp_ros/yolo_network_config/cfg/yolov3-voc.cfg
diff --git a/darknet_ros/yolo_network_config/cfg/yolov3.cfg b/darknet_drp_ros/yolo_network_config/cfg/yolov3.cfg
similarity index 100%
rename from darknet_ros/yolo_network_config/cfg/yolov3.cfg
rename to darknet_drp_ros/yolo_network_config/cfg/yolov3.cfg
diff --git a/darknet_ros/yolo_network_config/weights/.gitignore b/darknet_drp_ros/yolo_network_config/weights/.gitignore
similarity index 100%
rename from darknet_ros/yolo_network_config/weights/.gitignore
rename to darknet_drp_ros/yolo_network_config/weights/.gitignore
diff --git a/darknet_ros/yolo_network_config/weights/how_to_download_weights.txt b/darknet_drp_ros/yolo_network_config/weights/how_to_download_weights.txt
similarity index 100%
rename from darknet_ros/yolo_network_config/weights/how_to_download_weights.txt
rename to darknet_drp_ros/yolo_network_config/weights/how_to_download_weights.txt
diff --git a/darknet_ros/CMakeLists.txt b/darknet_ros/CMakeLists.txt
deleted file mode 100644
index 56dbad5..0000000
--- a/darknet_ros/CMakeLists.txt
+++ /dev/null
@@ -1,260 +0,0 @@
-cmake_minimum_required(VERSION 3.5)
-project(darknet_ros)
-
-set(CMAKE_CXX_STANDARD 17)
-
-# Define path of darknet folder here.
-find_path(DARKNET_PATH
-  NAMES "README.md"
-  HINTS "${CMAKE_CURRENT_SOURCE_DIR}/../darknet/")
-message(STATUS "Darknet path dir = ${DARKNET_PATH}")
-add_definitions(-DDARKNET_FILE_PATH="${DARKNET_PATH}")
-
-# Find CUDA
-find_package(CUDA QUIET)
-if (CUDA_FOUND)
-  find_package(CUDA REQUIRED)
-  message(STATUS "CUDA Version: ${CUDA_VERSION_STRINGS}")
-  message(STATUS "CUDA Libararies: ${CUDA_LIBRARIES}")
-  set(
-    CUDA_NVCC_FLAGS
-    ${CUDA_NVCC_FLAGS};
-    -O3
-    -gencode arch=compute_30,code=sm_30
-    -gencode arch=compute_35,code=sm_35
-    -gencode arch=compute_50,code=[sm_50,compute_50]
-    -gencode arch=compute_52,code=[sm_52,compute_52]
-    -gencode arch=compute_61,code=sm_61
-    -gencode arch=compute_62,code=sm_62
-  )
-  add_definitions(-DGPU)
-else()
-  list(APPEND LIBRARIES "m")
-endif()
-
-# Find X11
-message ( STATUS "Searching for X11..." )
-find_package ( X11 REQUIRED )
-if ( X11_FOUND )
-  include_directories ( ${X11_INCLUDE_DIR} )
-  link_libraries ( ${X11_LIBRARIES} )
-  message ( STATUS " X11_INCLUDE_DIR: " ${X11_INCLUDE_DIR} )
-  message ( STATUS " X11_LIBRARIES: " ${X11_LIBRARIES} )
-endif ( X11_FOUND )
-
-# Find rquired packeges
-find_package(OpenCV REQUIRED)
-include_directories(${OpenCV_INCLUDE_DIRS})
-
-find_package(ament_cmake REQUIRED)
-find_package(rclcpp REQUIRED)
-find_package(rclpy REQUIRED)
-find_package(rclcpp_action REQUIRED)
-find_package(std_msgs REQUIRED)
-find_package(image_transport REQUIRED)
-find_package(cv_bridge REQUIRED)
-find_package(sensor_msgs REQUIRED)
-find_package(darknet_ros_msgs REQUIRED)
-find_package(ament_index_cpp REQUIRED)
-
-set(dependencies
-    rclcpp
-    rclpy
-    rclcpp_action
-    std_msgs
-    image_transport
-    cv_bridge
-    sensor_msgs
-    darknet_ros_msgs
-    ament_index_cpp
-)
-
-# Enable OPENCV in darknet
-# add_definitions(-DOPENCV)
-add_definitions(-O4 -g)
-
-include_directories(
-  ${DARKNET_PATH}/src
-  ${DARKNET_PATH}/include
-  include
-  ${catkin_INCLUDE_DIRS}
-)
-
-set(PROJECT_LIB_FILES
-    src/YoloObjectDetector.cpp                    src/image_interface.c
-)
-
-set(DARKNET_CORE_FILES
-    ${DARKNET_PATH}/src/activation_layer.c        ${DARKNET_PATH}/src/im2col.c
-    ${DARKNET_PATH}/src/activations.c             ${DARKNET_PATH}/src/image.c
-    ${DARKNET_PATH}/src/avgpool_layer.c           ${DARKNET_PATH}/src/layer.c
-    ${DARKNET_PATH}/src/batchnorm_layer.c         ${DARKNET_PATH}/src/list.c
-    ${DARKNET_PATH}/src/blas.c                    ${DARKNET_PATH}/src/local_layer.c
-    ${DARKNET_PATH}/src/box.c                     ${DARKNET_PATH}/src/lstm_layer.c
-    ${DARKNET_PATH}/src/col2im.c                  ${DARKNET_PATH}/src/matrix.c
-    ${DARKNET_PATH}/src/connected_layer.c         ${DARKNET_PATH}/src/maxpool_layer.c
-    ${DARKNET_PATH}/src/convolutional_layer.c     ${DARKNET_PATH}/src/network.c
-    ${DARKNET_PATH}/src/cost_layer.c              ${DARKNET_PATH}/src/normalization_layer.c
-    ${DARKNET_PATH}/src/crnn_layer.c              ${DARKNET_PATH}/src/option_list.c
-    ${DARKNET_PATH}/src/crop_layer.c              ${DARKNET_PATH}/src/parser.c
-    ${DARKNET_PATH}/src/cuda.c                    ${DARKNET_PATH}/src/region_layer.c
-    ${DARKNET_PATH}/src/data.c                    ${DARKNET_PATH}/src/reorg_layer.c
-    ${DARKNET_PATH}/src/deconvolutional_layer.c   ${DARKNET_PATH}/src/rnn_layer.c
-    ${DARKNET_PATH}/src/demo.c                    ${DARKNET_PATH}/src/route_layer.c
-    ${DARKNET_PATH}/src/detection_layer.c         ${DARKNET_PATH}/src/shortcut_layer.c
-    ${DARKNET_PATH}/src/dropout_layer.c           ${DARKNET_PATH}/src/softmax_layer.c
-    ${DARKNET_PATH}/src/gemm.c                    ${DARKNET_PATH}/src/tree.c
-    ${DARKNET_PATH}/src/gru_layer.c               ${DARKNET_PATH}/src/utils.c
-    ${DARKNET_PATH}/src/upsample_layer.c          ${DARKNET_PATH}/src/logistic_layer.c
-    ${DARKNET_PATH}/src/l2norm_layer.c            ${DARKNET_PATH}/src/yolo_layer.c
-
-    ${DARKNET_PATH}/examples/art.c                ${DARKNET_PATH}/examples/lsd.c
-    ${DARKNET_PATH}/examples/attention.c          ${DARKNET_PATH}/examples/nightmare.c
-    ${DARKNET_PATH}/examples/captcha.c            ${DARKNET_PATH}/examples/regressor.c
-    ${DARKNET_PATH}/examples/cifar.c              ${DARKNET_PATH}/examples/rnn.c
-    ${DARKNET_PATH}/examples/classifier.c         ${DARKNET_PATH}/examples/segmenter.c
-    ${DARKNET_PATH}/examples/coco.c               ${DARKNET_PATH}/examples/super.c
-    ${DARKNET_PATH}/examples/darknet.c            ${DARKNET_PATH}/examples/tag.c
-    ${DARKNET_PATH}/examples/detector.c           ${DARKNET_PATH}/examples/yolo.c
-    ${DARKNET_PATH}/examples/go.c
-)
-
-set(DARKNET_CUDA_FILES
-    ${DARKNET_PATH}/src/activation_kernels.cu     ${DARKNET_PATH}/src/crop_layer_kernels.cu
-    ${DARKNET_PATH}/src/avgpool_layer_kernels.cu  ${DARKNET_PATH}/src/deconvolutional_kernels.cu
-    ${DARKNET_PATH}/src/blas_kernels.cu           ${DARKNET_PATH}/src/dropout_layer_kernels.cu
-    ${DARKNET_PATH}/src/col2im_kernels.cu         ${DARKNET_PATH}/src/im2col_kernels.cu
-    ${DARKNET_PATH}/src/convolutional_kernels.cu  ${DARKNET_PATH}/src/maxpool_layer_kernels.cu
-)
-
-set_source_files_properties(${PROJECT_LIB_FILES} PROPERTIES LANGUAGE CXX)
-
-if (CUDA_FOUND)
-
-  link_directories(
-    ${CUDA_TOOLKIT_ROOT_DIR}/lib64
-  )
-
-  cuda_add_library(${PROJECT_NAME}_lib
-    ${PROJECT_LIB_FILES} ${DARKNET_CORE_FILES}
-    ${DARKNET_CUDA_FILES}
-  )
-  
-  ament_target_dependencies(${PROJECT_NAME}_lib ${dependencies})
-
-  target_link_libraries(${PROJECT_NAME}_lib
-    cuda
-    cudart
-    cublas
-    curand
-  )
-
-  cuda_add_executable(${PROJECT_NAME}
-    src/yolo_object_detector_node.cpp
-  )
-  
-  ament_target_dependencies(${PROJECT_NAME} ${dependencies})
-
-else()
-
-  add_library(${PROJECT_NAME}_core_lib
-    ${DARKNET_CORE_FILES}
-  )
-
-  add_library(${PROJECT_NAME}_lib
-    ${PROJECT_LIB_FILES}
-  )
-  ament_target_dependencies(${PROJECT_NAME}_lib ${dependencies})
-  target_compile_definitions(${PROJECT_NAME}_lib PRIVATE -DOPENCV)
-
-  add_executable(${PROJECT_NAME}
-    src/yolo_object_detector_node.cpp
-  )
-  ament_target_dependencies(${PROJECT_NAME} ${dependencies})
-
-endif()
-
-target_link_libraries(${PROJECT_NAME}_lib
-  m
-  pthread
-  stdc++
-  ${OpenCV_LIBRARIES}
-  ${catkin_LIBRARIES}
-  ${OpenCV_LIBS}
-)
-target_compile_definitions(${PROJECT_NAME}_lib PRIVATE -DOPENCV)
-
-target_link_libraries(${PROJECT_NAME}
-  ${PROJECT_NAME}_lib
-  ${PROJECT_NAME}_core_lib
-)
-target_compile_definitions(${PROJECT_NAME} PRIVATE -DOPENCV)
-
-install(TARGETS ${PROJECT_NAME}_lib ${PROJECT_NAME}
-  ARCHIVE DESTINATION lib
-  LIBRARY DESTINATION lib
-  RUNTIME DESTINATION lib/${PROJECT_NAME}
-)
-
-
-install(
-  DIRECTORY include/
-  DESTINATION include/
-  FILES_MATCHING PATTERN "*.h"
-)
-
-# Download yolov2-tiny.weights
-set(PATH "${CMAKE_CURRENT_SOURCE_DIR}/yolo_network_config/weights")
-set(FILE "${PATH}/yolov2-tiny.weights")
-message(STATUS "Checking and downloading yolov2-tiny.weights if needed ...")
-if (NOT EXISTS "${FILE}")
-  message(STATUS "... file does not exist. Downloading now ...")
-  execute_process(COMMAND wget http://pjreddie.com/media/files/yolov2-tiny.weights -P ${PATH})
-endif()
-
-# Download yolov3.weights
-set(FILE "${PATH}/yolov3.weights")
-message(STATUS "Checking and downloading yolov3.weights if needed ...")
-if (NOT EXISTS "${FILE}")
-  message(STATUS "... file does not exist. Downloading now ...")
-  execute_process(COMMAND wget http://pjreddie.com/media/files/yolov3.weights -P ${PATH})
-endif()
-
-install(DIRECTORY yolo_network_config/cfg yolo_network_config/weights DESTINATION share/${PROJECT_NAME}/yolo_network_config/)
-install(DIRECTORY launch config DESTINATION share/${PROJECT_NAME}/)
-
-#############
-## Testing ##
-#############
-
-if(BUILD_TESTING)
-  # Download yolov2.weights
-  set(PATH "${CMAKE_CURRENT_SOURCE_DIR}/yolo_network_config/weights")
-  set(FILE "${PATH}/yolov2.weights")
-  message(STATUS "Checking and downloading yolov2.weights if needed ...")
-  if (NOT EXISTS "${FILE}")
-    message(STATUS "... file does not exist. Downloading now ...")
-    execute_process(COMMAND wget http://pjreddie.com/media/files/yolov2.weights -P ${PATH})
-  endif()
-
-  find_package(ament_lint_auto REQUIRED)
-  ament_lint_auto_find_test_dependencies()
-
-  find_package(ament_cmake_gtest REQUIRED)
-  
-  #ament_add_gtest(${PROJECT_NAME}_object_detection-test
-  #  test/object_detection.test
-  #  test/test_main.cpp
-  #  test/ObjectDetection.cpp
-  #)
-  #target_link_libraries(${PROJECT_NAME}_object_detection-test
-  #  ${PROJECT_NAME}_lib
-  #)
-endif()
-
-
-ament_export_include_directories(include)
-ament_export_libraries(${PROJECT_NAME}_lib)
-ament_export_dependencies(${dependencies})
-
-ament_package()
\ No newline at end of file
diff --git a/darknet_ros/include/darknet_ros/YoloObjectDetector.hpp b/darknet_ros/include/darknet_ros/YoloObjectDetector.hpp
deleted file mode 100644
index 1314455..0000000
--- a/darknet_ros/include/darknet_ros/YoloObjectDetector.hpp
+++ /dev/null
@@ -1,261 +0,0 @@
-/*
- * YoloObjectDetector.h
- *
- *  Created on: Dec 19, 2016
- *      Author: Marko Bjelonic
- *   Institute: ETH Zurich, Robotic Systems Lab
- */
-
-#pragma once
-
-// c++
-#include <math.h>
-#include <string>
-#include <vector>
-#include <iostream>
-#include <pthread.h>
-#include <thread>
-#include <chrono>
-#include <shared_mutex>
-
-// ROS
-#include "rclcpp/rclcpp.hpp"
-#include "rclcpp_action/rclcpp_action.hpp"
-#include "std_msgs/msg/header.hpp"
-#include "sensor_msgs/msg/image.hpp"
-#include "geometry_msgs/msg/point.hpp"
-#include "image_transport/image_transport.h"
-
-// OpenCv
-#include <opencv2/imgproc/imgproc.hpp>
-#include <opencv2/highgui/highgui.hpp>
-#include <opencv2/objdetect/objdetect.hpp>
-#include <cv_bridge/cv_bridge.h>
-
-// darknet_ros_msgs
-#include "darknet_ros_msgs/msg/bounding_boxes.hpp"
-#include "darknet_ros_msgs/msg/bounding_box.hpp"
-#include "darknet_ros_msgs/msg/object_count.hpp"
-#include "darknet_ros_msgs/action/check_for_objects.hpp"
-
-// Darknet.
-#ifdef GPU
-#include "cuda_runtime.h"
-#include "curand.h"
-#include "cublas_v2.h"
-#endif
-
-extern "C" {
-#include "network.h"
-#include "detection_layer.h"
-#include "region_layer.h"
-#include "cost_layer.h"
-#include "utils.h"
-#include "parser.h"
-#include "box.h"
-#include "darknet_ros/image_interface.h"
-#include <sys/time.h>
-}
-
-extern "C" void ipl_into_image(IplImage* src, image im);
-extern "C" image ipl_to_image(IplImage* src);
-extern "C" void show_image_cv(image p, const char *name, IplImage *disp);
-
-namespace darknet_ros {
-
-//! Bounding box of the detected object.
-typedef struct
-{
-  float x, y, w, h, prob;
-  int num, Class;
-} RosBox_;
-
-typedef struct
-{
-  IplImage* image;
-  std_msgs::msg::Header header;
-} IplImageWithHeader_;
-
-class YoloObjectDetector : public rclcpp::Node
-{
- public:
-  /*!
-   * Constructor.
-   */
-  explicit YoloObjectDetector();
-
-  /*!
-   * Destructor.
-   */
-  ~YoloObjectDetector();
-
-  /*!
-   * Initialize the ROS connections.
-   */
-  void init();
-
- private:
-  /*!
-   * Reads and verifies the ROS parameters.
-   * @return true if successful.
-   */
-  bool readParameters();
-
-  /*!
-   * Callback of camera.
-   * @param[in] msg image pointer.
-   */
-  void cameraCallback(const sensor_msgs::msg::Image::ConstSharedPtr & msg);
-
-
-  //! Typedefs.
-  using CheckForObjectsAction = darknet_ros_msgs::action::CheckForObjects;
-  using GoalHandleCheckForObjectsAction = rclcpp_action::ServerGoalHandle<CheckForObjectsAction>;
-
-  /*!
-   * Check for objects action goal callback.
-   */
-  rclcpp_action::GoalResponse checkForObjectsActionGoalCB(
-    const rclcpp_action::GoalUUID & uuid,
-    std::shared_ptr<const CheckForObjectsAction::Goal> goal);
-
-  /*!
-   * Check for objects action preempt callback.
-   */
-  rclcpp_action::CancelResponse checkForObjectsActionPreemptCB(
-    const std::shared_ptr<GoalHandleCheckForObjectsAction> goal_handle);
-
-  /*!ºº
-   * Check for objects action accept callback.
-   */
-  void checkForObjectsActionAcceptedCB(
-    const std::shared_ptr<GoalHandleCheckForObjectsAction> goal_handle);
-
-  /*!
-   * Check if a preempt for the check for objects action has been requested.
-   * @return false if preempt has been requested or inactive.
-   */
-  bool isCheckingForObjects() const;
-
-  /*!
-   * Publishes the detection image.
-   * @return true if successful.
-   */
-  bool publishDetectionImage(const cv::Mat& detectionImage);
-
-  //! Class labels.
-  int numClasses_;
-  std::vector<std::string> classLabels_;
-
-  //! Check for objects action server.
-  rclcpp_action::Server<CheckForObjectsAction>::SharedPtr checkForObjectsActionServer_;
-  bool action_active_;
-  bool preempt_requested_;
-  std::shared_ptr<GoalHandleCheckForObjectsAction> goal_handle_;
-
-  //! Advertise and subscribe to image topics.
-  std::shared_ptr<image_transport::ImageTransport> it_;
-
-  //! ROS subscriber and publisher.
-  image_transport::Subscriber imageSubscriber_;
-  rclcpp::Publisher<darknet_ros_msgs::msg::ObjectCount>::SharedPtr objectPublisher_;
-  rclcpp::Publisher<darknet_ros_msgs::msg::BoundingBoxes>::SharedPtr boundingBoxesPublisher_;
-
-  //! Detected objects.
-  std::vector<std::vector<RosBox_> > rosBoxes_;
-  std::vector<int> rosBoxCounter_;
-  darknet_ros_msgs::msg::BoundingBoxes boundingBoxesResults_;
-
-  //! Camera related parameters.
-  int frameWidth_;
-  int frameHeight_;
-
-  //! Publisher of the bounding box image.
-  rclcpp::Publisher<sensor_msgs::msg::Image>::SharedPtr detectionImagePublisher_;
-
-  // Yolo running on thread.
-  std::thread yoloThread_;
-
-  // Darknet.
-  char **demoNames_;
-  image **demoAlphabet_;
-  int demoClasses_;
-
-  network *net_;
-  std_msgs::msg::Header headerBuff_[3];
-  image buff_[3];
-  image buffLetter_[3];
-  int buffId_[3];
-  int buffIndex_ = 0;
-  IplImage * ipl_;
-  float fps_ = 0;
-  float demoThresh_ = 0;
-  float demoHier_ = .5;
-  int running_ = 0;
-
-  int demoDelay_ = 0;
-  int demoFrame_ = 3;
-  float **predictions_;
-  int demoIndex_ = 0;
-  int demoDone_ = 0;
-  float *lastAvg2_;
-  float *lastAvg_;
-  float *avg_;
-  int demoTotal_ = 0;
-  double demoTime_;
-
-  RosBox_ *roiBoxes_;
-  bool viewImage_;
-  bool enableConsoleOutput_;
-  int waitKeyDelay_;
-  int fullScreen_;
-  char *demoPrefix_;
-
-  std_msgs::msg::Header imageHeader_;
-  cv::Mat camImageCopy_;
-  std::shared_mutex mutexImageCallback_;
-
-  bool imageStatus_ = false;
-  std::shared_mutex mutexImageStatus_;
-
-  bool isNodeRunning_ = true;
-  std::shared_mutex mutexNodeStatus_;
-
-  int actionId_;
-  std::shared_mutex mutexActionStatus_;
-
-  // double getWallTime();
-
-  int sizeNetwork(network *net);
-
-  void rememberNetwork(network *net);
-
-  detection *avgPredictions(network *net, int *nboxes);
-
-  void *detectInThread();
-
-  void *fetchInThread();
-
-  void *displayInThread(void *ptr);
-
-  void *displayLoop(void *ptr);
-
-  void *detectLoop(void *ptr);
-
-  void setupNetwork(char *cfgfile, char *weightfile, char *datafile, float thresh,
-                    char **names, int classes,
-                    int delay, char *prefix, int avg_frames, float hier, int w, int h,
-                    int frames, int fullscreen);
-
-  void yolo();
-
-  IplImageWithHeader_ getIplImageWithHeader();
-
-  bool getImageStatus(void);
-
-  bool isNodeRunning(void);
-
-  void *publishInThread();
-};
-
-} /* namespace darknet_ros*/
diff --git a/darknet_ros/include/darknet_ros/image_interface.h b/darknet_ros/include/darknet_ros/image_interface.h
deleted file mode 100644
index 2aa1353..0000000
--- a/darknet_ros/include/darknet_ros/image_interface.h
+++ /dev/null
@@ -1,22 +0,0 @@
-/*
- * image_interface.h
- *
- *  Created on: Dec 19, 2016
- *      Author: Marko Bjelonic
- *   Institute: ETH Zurich, Robotic Systems Lab
- */
-
-#ifndef IMAGE_INTERFACE_H
-#define IMAGE_INTERFACE_H
-
-#include "opencv2/highgui/highgui_c.h"
-#include "opencv2/imgproc/imgproc_c.h"
-#include "opencv2/core/version.hpp"
-
-#include "image.h"
-
-static float get_pixel(image m, int x, int y, int c);
-image **load_alphabet_with_file(char *datafile);
-void generate_image(image p, IplImage *disp);
-
-#endif
diff --git a/darknet_ros/launch/darknet_ros.launch.py b/darknet_ros/launch/darknet_ros.launch.py
deleted file mode 100644
index 0cd39ec..0000000
--- a/darknet_ros/launch/darknet_ros.launch.py
+++ /dev/null
@@ -1,63 +0,0 @@
-import os
-
-from ament_index_python.packages import get_package_share_directory
-
-from launch import LaunchDescription
-from launch.actions import DeclareLaunchArgument, IncludeLaunchDescription, SetEnvironmentVariable
-from launch.launch_description_sources import PythonLaunchDescriptionSource
-from launch.substitutions import LaunchConfiguration
-from launch_ros.actions import Node
-
-def generate_launch_description():
-  darknet_ros_share_dir = get_package_share_directory('darknet_ros')
-
-  image = LaunchConfiguration('image', default = '/camera/rgb/image_raw')
-  yolo_weights_path = LaunchConfiguration('yolo_weights_path', default = darknet_ros_share_dir + '/yolo_network_config/weights')
-  yolo_config_path = LaunchConfiguration('yolo_config_path', default = darknet_ros_share_dir + '/yolo_network_config/cfg')
-  ros_param_file = LaunchConfiguration('ros_param_file', default = darknet_ros_share_dir + 'config/ros.yaml')
-  network_param_file = LaunchConfiguration('network_param_file', default = darknet_ros_share_dir + 'config/yolov2-tiny.yaml')
-
-  declare_image_cmd = DeclareLaunchArgument(
-    'image',
-    default_value = '/camera/rgb/image_raw',
-    description = 'Image topic')
-  declare_yolo_weights_path_cmd = DeclareLaunchArgument(
-    'yolo_weights_path',
-    default_value = darknet_ros_share_dir + '/yolo_network_config/weights',
-    description = 'Path to yolo weights') 
-  declare_yolo_config_path_cmd = DeclareLaunchArgument(
-    'yolo_config_path',
-    default_value = darknet_ros_share_dir + '/yolo_network_config/cfg',
-    description = 'Path to yolo config') 
-  declare_ros_param_file_cmd = DeclareLaunchArgument(
-    'ros_param_file',
-    default_value = darknet_ros_share_dir + '/config/ros.yaml',
-    description = 'Path to file with ROS related config')  
-  declare_network_param_file_cmd = DeclareLaunchArgument(
-    'network_param_file',
-    default_value = darknet_ros_share_dir + '/config/yolov2-tiny.yaml',
-    description = 'Path to file with network param file')  
-
-  darknet_ros_cmd = Node(
-    package='darknet_ros',
-    node_executable='darknet_ros',
-    node_name='darknet_ros',
-    output='screen',
-    parameters=[ros_param_file, network_param_file,
-      {
-        "config_path": yolo_config_path, 
-        "weights_path": yolo_weights_path,
-      },
-    ])
-
-  ld = LaunchDescription()
-
-  ld.add_action(declare_image_cmd)
-  ld.add_action(declare_yolo_weights_path_cmd)
-  ld.add_action(declare_yolo_config_path_cmd)
-  ld.add_action(declare_ros_param_file_cmd)
-  ld.add_action(declare_network_param_file_cmd)
-  
-  ld.add_action(darknet_ros_cmd)
-
-  return ld
diff --git a/darknet_ros/src/YoloObjectDetector.cpp b/darknet_ros/src/YoloObjectDetector.cpp
deleted file mode 100644
index 67d5c3b..0000000
--- a/darknet_ros/src/YoloObjectDetector.cpp
+++ /dev/null
@@ -1,821 +0,0 @@
-/*
- * YoloObjectDetector.cpp
- *
- *  Created on: Dec 19, 2016
- *      Author: Marko Bjelonic
- *   Institute: ETH Zurich, Robotic Systems Lab
- */
-
-// yolo object detector
-#include "darknet_ros/YoloObjectDetector.hpp"
-
-// Check for xServer
-#include <X11/Xlib.h>
-
-#ifdef DARKNET_FILE_PATH
-std::string darknetFilePath_ = DARKNET_FILE_PATH;
-#else
-#error Path of darknet repository is not defined in CMakeLists.txt.
-#endif
-
-namespace darknet_ros {
-
-char *cfg;
-char *weights;
-char *data;
-char **detectionNames;
-
-YoloObjectDetector::YoloObjectDetector()
-    : Node("darknet_ros"),
-      numClasses_(0),
-      classLabels_(0),
-      rosBoxes_(0),
-      rosBoxCounter_(0),
-      action_active_(false),
-      preempt_requested_(false)
-{
-  RCLCPP_INFO(get_logger(), "[YoloObjectDetector] Node started.");
-
-  declare_parameter("image_view.enable_opencv", true);
-  declare_parameter("image_view.wait_key_delay", 3);
-  declare_parameter("image_view.enable_console_output", false);
-  declare_parameter("yolo_model.detection_classes.names", std::vector<std::string>(0));
-
-  declare_parameter("yolo_model.threshold.value", 0.3f);
-  declare_parameter("yolo_model.weight_file.name", std::string("yolov2-tiny.weights"));
-  declare_parameter("weights_path", std::string("/default"));
-
-  declare_parameter("yolo_model.config_file.name", std::string("yolov2-tiny.cfg"));
-  declare_parameter("config_path", std::string("/default"));
-
-  declare_parameter("subscribers.camera_reading.topic", std::string("/camera/image_raw"));
-  declare_parameter("subscribers.camera_reading.queue_size", 1);
-  declare_parameter("publishers.object_detector.topic", std::string("found_object"));
-  declare_parameter("publishers.object_detector.queue_size", 1);
-  declare_parameter("publishers.object_detector.latch", false);
-  declare_parameter("publishers.bounding_boxes.topic", std::string("bounding_boxes"));
-  declare_parameter("publishers.bounding_boxes.queue_size", 1);
-  declare_parameter("publishers.bounding_boxes.latch", false);
-  declare_parameter("publishers.detection_image.topic", std::string("detection_image"));
-  declare_parameter("publishers.detection_image.queue_size", 1);
-  declare_parameter("publishers.detection_image.latch", true);
-
-  declare_parameter("actions.camera_reading.topic", std::string("check_for_objects"));
-}
-
-YoloObjectDetector::~YoloObjectDetector()
-{
-  {
-    std::unique_lock<std::shared_mutex> lockNodeStatus(mutexNodeStatus_);
-    isNodeRunning_ = false;
-  }
-  yoloThread_.join();
-}
-
-bool YoloObjectDetector::readParameters()
-{
-  // Load common parameters.
-  get_parameter("image_view.enable_opencv", viewImage_);
-  get_parameter("image_view.wait_key_delay", waitKeyDelay_);
-  get_parameter("image_view.enable_console_output", enableConsoleOutput_);
-
-  // Check if Xserver is running on Linux.
-  if (XOpenDisplay(NULL)) {
-    // Do nothing!
-    RCLCPP_INFO(get_logger(), "[YoloObjectDetector] Xserver is running.");
-  } else {
-    RCLCPP_INFO(get_logger(), "[YoloObjectDetector] Xserver is not running.");
-    viewImage_ = false;
-  }
-
-  // Set vector sizes.
-  get_parameter("yolo_model.detection_classes.names", classLabels_);
-  numClasses_ = classLabels_.size();
-  rosBoxes_ = std::vector<std::vector<RosBox_> >(numClasses_);
-  rosBoxCounter_ = std::vector<int>(numClasses_);
-
-  return true;
-}
-
-void YoloObjectDetector::init()
-{
-  // Read parameters from config file.
-  if (!readParameters()) {
-    rclcpp::shutdown();
-  }
-
-
-  RCLCPP_INFO(get_logger(), "[YoloObjectDetector] init().");
-
-  // Initialize deep network of darknet.
-  std::string weightsPath;
-  std::string configPath;
-  std::string dataPath;
-  std::string configModel;
-  std::string weightsModel;
-
-  // Threshold of object detection.
-  float thresh;
-  get_parameter("yolo_model.threshold.value", thresh);
-
-  // Path to weights file.
-  get_parameter("yolo_model.weight_file.name", weightsModel);
-  get_parameter("weights_path", weightsPath);
-  weightsPath += "/" + weightsModel;
-  weights = new char[weightsPath.length() + 1];
-  strcpy(weights, weightsPath.c_str());
-
-  // Path to config file.
-  get_parameter("yolo_model.config_file.name", configModel);
-  get_parameter("config_path", configPath);
-  configPath += "/" + configModel;
-  cfg = new char[configPath.length() + 1];
-  strcpy(cfg, configPath.c_str());
-
-  // Path to data folder.
-  dataPath = darknetFilePath_;
-  dataPath += "/data";
-  data = new char[dataPath.length() + 1];
-  strcpy(data, dataPath.c_str());
-
-  // Get classes.
-  detectionNames = (char**) realloc((void*) detectionNames, (numClasses_ + 1) * sizeof(char*));
-  for (int i = 0; i < numClasses_; i++) {
-    detectionNames[i] = new char[classLabels_[i].length() + 1];
-    strcpy(detectionNames[i], classLabels_[i].c_str());
-  }
-
-  // Load network.
-  setupNetwork(cfg, weights, data, thresh, detectionNames, numClasses_,
-                0, 0, 1, 0.5, 0, 0, 0, 0);
-  yoloThread_ = std::thread(&YoloObjectDetector::yolo, this);
-
-  // Initialize publisher and subscriber.
-  std::string cameraTopicName;
-  int cameraQueueSize;
-  std::string objectDetectorTopicName;
-  int objectDetectorQueueSize;
-  bool objectDetectorLatch;
-  std::string boundingBoxesTopicName;
-  int boundingBoxesQueueSize;
-  bool boundingBoxesLatch;
-  std::string detectionImageTopicName;
-  int detectionImageQueueSize;
-  bool detectionImageLatch;
-
-  get_parameter("subscribers.camera_reading.topic", cameraTopicName);
-  get_parameter("subscribers.camera_reading.queue_size", cameraQueueSize);
-  get_parameter("publishers.object_detector.topic", objectDetectorTopicName);
-  get_parameter("publishers.object_detector.queue_size", objectDetectorQueueSize);
-  get_parameter("publishers.object_detector.latch", objectDetectorLatch);
-  get_parameter("publishers.bounding_boxes.topic", boundingBoxesTopicName);
-  get_parameter("publishers.bounding_boxes.queue_size", boundingBoxesQueueSize);
-  get_parameter("publishers.bounding_boxes.latch", boundingBoxesLatch);
-  get_parameter("publishers.detection_image.topic", detectionImageTopicName);
-  get_parameter("publishers.detection_image.queue_size", detectionImageQueueSize);
-  get_parameter("publishers.detection_image.latch", detectionImageLatch);
-
-  it_ = std::make_shared<image_transport::ImageTransport>(shared_from_this());
-  
-  using std::placeholders::_1;
-  imageSubscriber_ = it_->subscribe(cameraTopicName, cameraQueueSize,
-    std::bind(&YoloObjectDetector::cameraCallback, this, _1));
-
-  rclcpp::QoS object_publisher_qos(objectDetectorQueueSize);
-  if (objectDetectorLatch) {
-    object_publisher_qos.transient_local();
-  }
-  objectPublisher_ = this->create_publisher<darknet_ros_msgs::msg::ObjectCount>(
-    objectDetectorTopicName, object_publisher_qos);
-    
-  rclcpp::QoS bounding_boxes_publisher_qos(boundingBoxesQueueSize);
-  if (boundingBoxesLatch) {
-    bounding_boxes_publisher_qos.transient_local();
-  }
-  boundingBoxesPublisher_ = this->create_publisher<darknet_ros_msgs::msg::BoundingBoxes>(
-      boundingBoxesTopicName, bounding_boxes_publisher_qos);
-
-  rclcpp::QoS detection_image_publisher_qos(detectionImageQueueSize);
-  if (detectionImageLatch) {
-    detection_image_publisher_qos.transient_local();
-  }
-  detectionImagePublisher_ = this->create_publisher<sensor_msgs::msg::Image>(
-    detectionImageTopicName, detection_image_publisher_qos);
-
-  // Action servers.
-  std::string checkForObjectsActionName;
-  get_parameter("actions.camera_reading.topic", checkForObjectsActionName);
-
-  using std::placeholders::_2;
-  this->checkForObjectsActionServer_ = rclcpp_action::create_server<CheckForObjectsAction>(
-    this->get_node_base_interface(),
-    this->get_node_clock_interface(),
-    this->get_node_logging_interface(),
-    this->get_node_waitables_interface(),
-    "checkForObjectsActionName",
-    std::bind(&YoloObjectDetector::checkForObjectsActionGoalCB, this, _1, _2),
-    std::bind(&YoloObjectDetector::checkForObjectsActionPreemptCB, this, _1),
-    std::bind(&YoloObjectDetector::checkForObjectsActionAcceptedCB, this, _1));
-}
-
-void YoloObjectDetector::cameraCallback(const sensor_msgs::msg::Image::ConstSharedPtr & msg)
-{
-  RCLCPP_DEBUG(get_logger(), "[YoloObjectDetector] USB image received.");
-
-  cv_bridge::CvImagePtr cam_image;
-
-  try {
-    cam_image = cv_bridge::toCvCopy(msg, "bgr8");
-  } catch (cv_bridge::Exception& e) {
-    RCLCPP_ERROR(get_logger(), "cv_bridge exception: %s", e.what());
-    return;
-  }
-
-  if (cam_image) {
-    {
-      std::unique_lock<std::shared_mutex> lockImageCallback(mutexImageCallback_);
-      imageHeader_ = msg->header;
-      camImageCopy_ = cam_image->image.clone();
-    }
-    {
-      std::unique_lock<std::shared_mutex> lockImageStatus(mutexImageStatus_);
-      imageStatus_ = true;
-    }
-    frameWidth_ = cam_image->image.size().width;
-    frameHeight_ = cam_image->image.size().height;
-  }
-  return;
-}
-
-rclcpp_action::GoalResponse YoloObjectDetector::checkForObjectsActionGoalCB(
-  const rclcpp_action::GoalUUID & uuid,
-  std::shared_ptr<const CheckForObjectsAction::Goal> goal)
-{
-  RCLCPP_DEBUG(get_logger(), "[YoloObjectDetector] Start check for objects action.");
-
-  auto imageAction = goal->image;
-
-  cv_bridge::CvImagePtr cam_image;
-
-  try {
-    cam_image = cv_bridge::toCvCopy(imageAction, "bgr8");
-  } catch (cv_bridge::Exception& e) {
-    RCLCPP_ERROR(get_logger(), "cv_bridge exception: %s", e.what());
-    rclcpp_action::GoalResponse::REJECT;
-  }
-
-  if (cam_image) {
-    {
-      std::unique_lock<std::shared_mutex> lockImageCallback(mutexImageCallback_);
-      camImageCopy_ = cam_image->image.clone();
-    }
-    {
-      std::unique_lock<std::shared_mutex> lockImageCallback(mutexActionStatus_);
-      actionId_ = goal->id;
-    }
-    {
-      std::unique_lock<std::shared_mutex> lockImageStatus(mutexImageStatus_);
-      imageStatus_ = true;
-    }
-    frameWidth_ = cam_image->image.size().width;
-    frameHeight_ = cam_image->image.size().height;
-  }
-  preempt_requested_ = false;
-  return rclcpp_action::GoalResponse::ACCEPT_AND_EXECUTE;
-}
-
-rclcpp_action::CancelResponse
-YoloObjectDetector::checkForObjectsActionPreemptCB(
-  const std::shared_ptr<GoalHandleCheckForObjectsAction> goal_handle)
-{
-  RCLCPP_DEBUG(get_logger(), "[YoloObjectDetector] Preempt check for objects action.");
-  preempt_requested_ = true;
-  return rclcpp_action::CancelResponse::ACCEPT;
-}
-
-void
-YoloObjectDetector::checkForObjectsActionAcceptedCB(
-  const std::shared_ptr<GoalHandleCheckForObjectsAction> goal_handle)
-{
-  RCLCPP_DEBUG(get_logger(), "[YoloObjectDetector] action accepted.");
-  action_active_ = true;
-  goal_handle_ = goal_handle;
-}
-
-bool YoloObjectDetector::isCheckingForObjects() const
-{
-  return (rclcpp::ok() && action_active_ && !preempt_requested_);
-}
-
-bool YoloObjectDetector::publishDetectionImage(const cv::Mat& detectionImage)
-{
-  if (detectionImagePublisher_->get_subscription_count() < 1)
-    return false;
-  cv_bridge::CvImage cvImage;
-  cvImage.header.stamp = this->now();
-  cvImage.header.frame_id = "detection_image";
-  cvImage.encoding = "bgr8";
-  cvImage.image = detectionImage;
-  detectionImagePublisher_->publish(*cvImage.toImageMsg());
-  RCLCPP_DEBUG(get_logger(), "Detection image has been published.");
-  return true;
-}
-
-// double YoloObjectDetector::getWallTime()
-// {
-//   struct timeval time;
-//   if (gettimeofday(&time, NULL)) {
-//     return 0;
-//   }
-//   return (double) time.tv_sec + (double) time.tv_usec * .000001;
-// }
-
-int YoloObjectDetector::sizeNetwork(network *net)
-{
-  int i;
-  int count = 0;
-  for(i = 0; i < net->n; ++i){
-    layer l = net->layers[i];
-    if(l.type == YOLO || l.type == REGION || l.type == DETECTION){
-      count += l.outputs;
-    }
-  }
-  return count;
-}
-
-void YoloObjectDetector::rememberNetwork(network *net)
-{
-  int i;
-  int count = 0;
-  for(i = 0; i < net->n; ++i){
-    layer l = net->layers[i];
-    if(l.type == YOLO || l.type == REGION || l.type == DETECTION){
-      memcpy(predictions_[demoIndex_] + count, net->layers[i].output, sizeof(float) * l.outputs);
-      count += l.outputs;
-    }
-  }
-}
-
-detection *YoloObjectDetector::avgPredictions(network *net, int *nboxes)
-{
-  int i, j;
-  int count = 0;
-  fill_cpu(demoTotal_, 0, avg_, 1);
-  for(j = 0; j < demoFrame_; ++j){
-    axpy_cpu(demoTotal_, 1./demoFrame_, predictions_[j], 1, avg_, 1);
-  }
-  for(i = 0; i < net->n; ++i){
-    layer l = net->layers[i];
-    if(l.type == YOLO || l.type == REGION || l.type == DETECTION){
-      memcpy(l.output, avg_ + count, sizeof(float) * l.outputs);
-      count += l.outputs;
-    }
-  }
-  detection *dets = get_network_boxes(net, buff_[0].w, buff_[0].h, demoThresh_, demoHier_, 0, 1, nboxes);
-  return dets;
-}
-
-void *YoloObjectDetector::detectInThread()
-{
-  running_ = 1;
-  float nms = .4;
-
-  layer l = net_->layers[net_->n - 1];
-  float *X = buffLetter_[(buffIndex_ + 2) % 3].data;
-  float *prediction = network_predict(net_, X);
-
-  rememberNetwork(net_);
-  detection *dets = 0;
-  int nboxes = 0;
-  dets = avgPredictions(net_, &nboxes);
-
-  if (nms > 0) do_nms_obj(dets, nboxes, l.classes, nms);
-
-  if (enableConsoleOutput_) {
-    printf("\033[2J");
-    printf("\033[1;1H");
-    printf("\nFPS:%.1f\n",fps_);
-    printf("Objects:\n\n");
-  }
-  image display = buff_[(buffIndex_+2) % 3];
-  draw_detections(display, dets, nboxes, demoThresh_, demoNames_, demoAlphabet_, demoClasses_);
-
-  // extract the bounding boxes and send them to ROS
-  int i, j;
-  int count = 0;
-  for (i = 0; i < nboxes; ++i) {
-    float xmin = dets[i].bbox.x - dets[i].bbox.w / 2.;
-    float xmax = dets[i].bbox.x + dets[i].bbox.w / 2.;
-    float ymin = dets[i].bbox.y - dets[i].bbox.h / 2.;
-    float ymax = dets[i].bbox.y + dets[i].bbox.h / 2.;
-
-    if (xmin < 0)
-      xmin = 0;
-    if (ymin < 0)
-      ymin = 0;
-    if (xmax > 1)
-      xmax = 1;
-    if (ymax > 1)
-      ymax = 1;
-
-    // iterate through possible boxes and collect the bounding boxes
-    for (j = 0; j < demoClasses_; ++j) {
-      if (dets[i].prob[j]) {
-        float x_center = (xmin + xmax) / 2;
-        float y_center = (ymin + ymax) / 2;
-        float BoundingBox_width = xmax - xmin;
-        float BoundingBox_height = ymax - ymin;
-
-        // define bounding box
-        // BoundingBox must be 1% size of frame (3.2x2.4 pixels)
-        if (BoundingBox_width > 0.01 && BoundingBox_height > 0.01) {
-          roiBoxes_[count].x = x_center;
-          roiBoxes_[count].y = y_center;
-          roiBoxes_[count].w = BoundingBox_width;
-          roiBoxes_[count].h = BoundingBox_height;
-          roiBoxes_[count].Class = j;
-          roiBoxes_[count].prob = dets[i].prob[j];
-          count++;
-        }
-      }
-    }
-  }
-
-  // create array to store found bounding boxes
-  // if no object detected, make sure that ROS knows that num = 0
-  if (count == 0) {
-    roiBoxes_[0].num = 0;
-  } else {
-    roiBoxes_[0].num = count;
-  }
-
-  free_detections(dets, nboxes);
-  demoIndex_ = (demoIndex_ + 1) % demoFrame_;
-  running_ = 0;
-  return 0;
-}
-
-
-void ipl_into_image_cp(IplImage* src, image im)
-{
-    unsigned char *data = (unsigned char *)src->imageData;
-    int h = src->height;
-    int w = src->width;
-    int c = src->nChannels;
-    int step = src->widthStep;
-    int i, j, k;
-
-    for(i = 0; i < h; ++i){
-        for(k= 0; k < c; ++k){
-            for(j = 0; j < w; ++j){
-                im.data[k*w*h + i*w + j] = data[i*step + j*c + k]/255.;
-            }
-        }
-    }
-}
-
-void *YoloObjectDetector::fetchInThread()
-{
-  {
-    std::shared_lock<std::shared_mutex> lock(mutexImageCallback_);
-    IplImageWithHeader_ imageAndHeader = getIplImageWithHeader();
-    IplImage* ROS_img = imageAndHeader.image;
-    ipl_into_image_cp(ROS_img, buff_[buffIndex_]);
-    headerBuff_[buffIndex_] = imageAndHeader.header;
-    buffId_[buffIndex_] = actionId_;
-  }
-  rgbgr_image(buff_[buffIndex_]);
-  letterbox_image_into(buff_[buffIndex_], net_->w, net_->h, buffLetter_[buffIndex_]);
-  return 0;
-}
-
-
-float get_pixel_cp(image m, int x, int y, int c)
-{
-    assert(x < m.w && y < m.h && c < m.c);
-    return m.data[c*m.h*m.w + y*m.w + x];
-}
-
-int windows = 0;
-
-void show_image_cv_cp(image p, const char *name, IplImage *disp)
-{
-    int x,y,k;
-    if(p.c == 3) rgbgr_image(p);
-    //normalize_image(copy);
-
-    char buff[256];
-    //sprintf(buff, "%s (%d)", name, windows);
-    sprintf(buff, "%s", name);
-
-    int step = disp->widthStep;
-    cvNamedWindow(buff, CV_WINDOW_NORMAL); 
-    //cvMoveWindow(buff, 100*(windows%10) + 200*(windows/10), 100*(windows%10));
-    ++windows;
-    for(y = 0; y < p.h; ++y){
-        for(x = 0; x < p.w; ++x){
-            for(k= 0; k < p.c; ++k){
-                disp->imageData[y*step + x*p.c + k] = (unsigned char)(get_pixel_cp(p,x,y,k)*255);
-            }
-        }
-    }
-    if(0){
-        int w = 448;
-        int h = w*p.h/p.w;
-        if(h > 1000){
-            h = 1000;
-            w = h*p.w/p.h;
-        }
-        IplImage *buffer = disp;
-        disp = cvCreateImage(cvSize(w, h), buffer->depth, buffer->nChannels);
-        cvResize(buffer, disp, CV_INTER_LINEAR);
-        cvReleaseImage(&buffer);
-    }
-    cvShowImage(buff, disp);
-}
-
-void *YoloObjectDetector::displayInThread(void *ptr)
-{
-  show_image_cv_cp(buff_[(buffIndex_ + 1)%3], "YOLO V3", ipl_);
-  int c = cv::waitKey(waitKeyDelay_);
-  if (c != -1) c = c%256;
-  if (c == 27) {
-      demoDone_ = 1;
-      return 0;
-  } else if (c == 82) {
-      demoThresh_ += .02;
-  } else if (c == 84) {
-      demoThresh_ -= .02;
-      if(demoThresh_ <= .02) demoThresh_ = .02;
-  } else if (c == 83) {
-      demoHier_ += .02;
-  } else if (c == 81) {
-      demoHier_ -= .02;
-      if(demoHier_ <= .0) demoHier_ = .0;
-  }
-  return 0;
-}
-
-void *YoloObjectDetector::displayLoop(void *ptr)
-{
-  while (1) {
-    displayInThread(0);
-  }
-}
-
-void *YoloObjectDetector::detectLoop(void *ptr)
-{
-  while (1) {
-    detectInThread();
-  }
-}
-
-
-image **load_alphabet_with_file_cp(char *datafile) {
-  int i, j;
-  const int nsize = 8;
-  image **alphabets = (image**)calloc(nsize, sizeof(image));
-  char* labels = "/labels/%d_%d.png";
-  char * files = (char *) malloc(1 + strlen(datafile)+ strlen(labels) );
-  strcpy(files, datafile);
-  strcat(files, labels);
-  for(j = 0; j < nsize; ++j){
-    alphabets[j] = (image*)calloc(128, sizeof(image));
-    for(i = 32; i < 127; ++i){
-      char buff[256];
-      sprintf(buff, files, i, j);
-      alphabets[j][i] = load_image_color(buff, 0, 0);
-    }
-  }
-  return alphabets;
-}
-
-void YoloObjectDetector::setupNetwork(char *cfgfile, char *weightfile, char *datafile, float thresh,
-                                      char **names, int classes,
-                                      int delay, char *prefix, int avg_frames, float hier, int w, int h,
-                                      int frames, int fullscreen)
-{
-  demoPrefix_ = prefix;
-  demoDelay_ = delay;
-  demoFrame_ = avg_frames;
-  image **alphabet = load_alphabet_with_file_cp(datafile);
-  demoNames_ = names;
-  demoAlphabet_ = alphabet;
-  demoClasses_ = classes;
-  demoThresh_ = thresh;
-  demoHier_ = hier;
-  fullScreen_ = fullscreen;
-  printf("YOLO V3\n");
-  net_ = load_network(cfgfile, weightfile, 0);
-  set_batch_network(net_, 1);
-}
-
-void generate_image_cp(image p, IplImage *disp)
-{
-    int x,y,k;
-    if(p.c == 3) rgbgr_image(p);
-    //normalize_image(copy);
-
-    int step = disp->widthStep;
-    for(y = 0; y < p.h; ++y){
-        for(x = 0; x < p.w; ++x){
-            for(k= 0; k < p.c; ++k){
-                disp->imageData[y*step + x*p.c + k] = (unsigned char)(get_pixel_cp(p,x,y,k)*255);
-            }
-        }
-    }
-}
-
-image ipl_to_image_cp(IplImage* src)
-{
-    int h = src->height;
-    int w = src->width;
-    int c = src->nChannels;
-    image out = make_image(w, h, c);
-    ipl_into_image_cp(src, out);
-    return out;
-}
-
-void YoloObjectDetector::yolo()
-{
-  const auto wait_duration = std::chrono::milliseconds(2000);
-  while (!getImageStatus()) {
-    printf("Waiting for image.\n");
-    if (!isNodeRunning()) {
-      return;
-    }
-    std::this_thread::sleep_for(wait_duration);
-  }
-
-  std::thread detect_thread;
-  std::thread fetch_thread;
-
-  srand(2222222);
-
-  int i;
-  demoTotal_ = sizeNetwork(net_);
-  predictions_ = (float **) calloc(demoFrame_, sizeof(float*));
-  for (i = 0; i < demoFrame_; ++i){
-      predictions_[i] = (float *) calloc(demoTotal_, sizeof(float));
-  }
-  avg_ = (float *) calloc(demoTotal_, sizeof(float));
-
-  layer l = net_->layers[net_->n - 1];
-  roiBoxes_ = (darknet_ros::RosBox_ *) calloc(l.w * l.h * l.n, sizeof(darknet_ros::RosBox_));
-
-  {
-    std::shared_lock<std::shared_mutex> lock(mutexImageCallback_);
-    IplImageWithHeader_ imageAndHeader = getIplImageWithHeader();
-    IplImage* ROS_img = imageAndHeader.image;
-    buff_[0] = ipl_to_image_cp(ROS_img);
-    headerBuff_[0] = imageAndHeader.header;
-  }
-  buff_[1] = copy_image(buff_[0]);
-  buff_[2] = copy_image(buff_[0]);
-  headerBuff_[1] = headerBuff_[0];
-  headerBuff_[2] = headerBuff_[0];
-  buffLetter_[0] = letterbox_image(buff_[0], net_->w, net_->h);
-  buffLetter_[1] = letterbox_image(buff_[0], net_->w, net_->h);
-  buffLetter_[2] = letterbox_image(buff_[0], net_->w, net_->h);
-  ipl_ = cvCreateImage(cvSize(buff_[0].w, buff_[0].h), IPL_DEPTH_8U, buff_[0].c);
-
-  int count = 0;
-
-  if (!demoPrefix_ && viewImage_) {
-      cv::namedWindow("YOLO V3", cv::WINDOW_NORMAL);
-    if (fullScreen_) {
-      cv::setWindowProperty("YOLO V3", cv::WND_PROP_FULLSCREEN, cv::WINDOW_FULLSCREEN);
-    } else {
-      cv::moveWindow("YOLO V3", 0, 0);
-      cv::resizeWindow("YOLO V3", 640, 480);
-    }
-  }
-
-  demoTime_ = what_time_is_it_now();
-
-  while (!demoDone_) {
-    buffIndex_ = (buffIndex_ + 1) % 3;
-    fetch_thread = std::thread(&YoloObjectDetector::fetchInThread, this);
-    detect_thread = std::thread(&YoloObjectDetector::detectInThread, this);
-    if (!demoPrefix_) {
-      fps_ = 1./(what_time_is_it_now() - demoTime_);
-      demoTime_ = what_time_is_it_now();
-      if (viewImage_) {
-        displayInThread(0);
-      } else {
-        generate_image_cp(buff_[(buffIndex_ + 1)%3], ipl_);
-      }
-      publishInThread();
-    } else {
-      char name[256];
-      sprintf(name, "%s_%08d", demoPrefix_, count);
-      save_image(buff_[(buffIndex_ + 1) % 3], name);
-    }
-    fetch_thread.join();
-    detect_thread.join();
-    ++count;
-    if (!isNodeRunning()) {
-      demoDone_ = true;
-    }
-  }
-
-}
-
-IplImageWithHeader_ YoloObjectDetector::getIplImageWithHeader()
-{
-  IplImage* ROS_img = new IplImage();
-  *ROS_img = cvIplImage(camImageCopy_);
-  IplImageWithHeader_ header = {.image = ROS_img, .header = imageHeader_};
-  return header;
-}
-
-bool YoloObjectDetector::getImageStatus(void)
-{
-  std::shared_lock<std::shared_mutex> lock(mutexImageStatus_);
-  return imageStatus_;
-}
-
-bool YoloObjectDetector::isNodeRunning(void)
-{
-  std::shared_lock<std::shared_mutex> lock(mutexNodeStatus_);
-  return isNodeRunning_;
-}
-
-void *YoloObjectDetector::publishInThread()
-{
-  // Publish image.
-  cv::Mat cvImage = cv::cvarrToMat(ipl_);
-  if (!publishDetectionImage(cv::Mat(cvImage))) {
-    RCLCPP_DEBUG(get_logger(), "Detection image has not been broadcasted.");
-  }
-
-  // Publish bounding boxes and detection result.
-  int num = roiBoxes_[0].num;
-  if (num > 0 && num <= 100) {
-    for (int i = 0; i < num; i++) {
-      for (int j = 0; j < numClasses_; j++) {
-        if (roiBoxes_[i].Class == j) {
-          rosBoxes_[j].push_back(roiBoxes_[i]);
-          rosBoxCounter_[j]++;
-        }
-      }
-    }
-
-    darknet_ros_msgs::msg::ObjectCount msg;
-    msg.header.stamp = this->now();
-    msg.header.frame_id = "detection";
-    msg.count = num;
-    objectPublisher_->publish(msg);
-
-    for (int i = 0; i < numClasses_; i++) {
-      if (rosBoxCounter_[i] > 0) {
-        darknet_ros_msgs::msg::BoundingBox boundingBox;
-
-        for (int j = 0; j < rosBoxCounter_[i]; j++) {
-          int xmin = (rosBoxes_[i][j].x - rosBoxes_[i][j].w / 2) * frameWidth_;
-          int ymin = (rosBoxes_[i][j].y - rosBoxes_[i][j].h / 2) * frameHeight_;
-          int xmax = (rosBoxes_[i][j].x + rosBoxes_[i][j].w / 2) * frameWidth_;
-          int ymax = (rosBoxes_[i][j].y + rosBoxes_[i][j].h / 2) * frameHeight_;
-
-          boundingBox.class_id = classLabels_[i];
-          boundingBox.id = i;
-          boundingBox.probability = rosBoxes_[i][j].prob;
-          boundingBox.xmin = xmin;
-          boundingBox.ymin = ymin;
-          boundingBox.xmax = xmax;
-          boundingBox.ymax = ymax;
-          boundingBoxesResults_.bounding_boxes.push_back(boundingBox);
-        }
-      }
-    }
-    boundingBoxesResults_.header.stamp = this->now();
-    boundingBoxesResults_.header.frame_id = "detection";
-    boundingBoxesResults_.image_header = headerBuff_[(buffIndex_ + 1) % 3];
-    boundingBoxesPublisher_->publish(boundingBoxesResults_);
-  } else {
-    darknet_ros_msgs::msg::ObjectCount msg;
-    msg.header.stamp = this->now();
-    msg.header.frame_id = "detection";
-    msg.count = 0;
-    objectPublisher_->publish(msg);
-  }
-  if (isCheckingForObjects()) {
-    RCLCPP_DEBUG(get_logger(), "[YoloObjectDetector] check for objects in image.");
-    auto result = std::make_shared<CheckForObjectsAction::Result>();
-
-    result->id = buffId_[0];
-    result->bounding_boxes = boundingBoxesResults_;
-    goal_handle_->succeed(result);
-    action_active_ = false;
-  }
-  boundingBoxesResults_.bounding_boxes.clear();
-  for (int i = 0; i < numClasses_; i++) {
-    rosBoxes_[i].clear();
-    rosBoxCounter_[i] = 0;
-  }
-
-  return 0;
-}
-
-
-} /* namespace darknet_ros*/
diff --git a/darknet_ros/src/image_interface.c b/darknet_ros/src/image_interface.c
deleted file mode 100644
index 8ee77cd..0000000
--- a/darknet_ros/src/image_interface.c
+++ /dev/null
@@ -1,52 +0,0 @@
-/*
- * image_interface.c
- *
- *  Created on: Dec 19, 2016
- *      Author: Marko Bjelonic
- *   Institute: ETH Zurich, Robotic Systems Lab
- */
-
-#include "darknet_ros/image_interface.h"
-
-static float get_pixel(image m, int x, int y, int c)
-{
-    assert(x < m.w && y < m.h && c < m.c);
-    return m.data[c*m.h*m.w + y*m.w + x];
-}
-
-image **load_alphabet_with_file(char *datafile) {
-  int i, j;
-  const int nsize = 8;
-  image **alphabets = (image**)calloc(nsize, sizeof(image));
-  char* labels = "/labels/%d_%d.png";
-  char * files = (char *) malloc(1 + strlen(datafile)+ strlen(labels) );
-  strcpy(files, datafile);
-  strcat(files, labels);
-  for(j = 0; j < nsize; ++j){
-    alphabets[j] = (image*)calloc(128, sizeof(image));
-    for(i = 32; i < 127; ++i){
-      char buff[256];
-      sprintf(buff, files, i, j);
-      alphabets[j][i] = load_image_color(buff, 0, 0);
-    }
-  }
-  return alphabets;
-}
-
-#ifdef OPENCV
-void generate_image(image p, IplImage *disp)
-{
-    int x,y,k;
-    if(p.c == 3) rgbgr_image(p);
-    //normalize_image(copy);
-
-    int step = disp->widthStep;
-    for(y = 0; y < p.h; ++y){
-        for(x = 0; x < p.w; ++x){
-            for(k= 0; k < p.c; ++k){
-                disp->imageData[y*step + x*p.c + k] = (unsigned char)(get_pixel(p,x,y,k)*255);
-            }
-        }
-    }
-}
-#endif
diff --git a/darknet_ros/src/yolo_object_detector_node.cpp b/darknet_ros/src/yolo_object_detector_node.cpp
deleted file mode 100644
index b9bc067..0000000
--- a/darknet_ros/src/yolo_object_detector_node.cpp
+++ /dev/null
@@ -1,24 +0,0 @@
-/*
- * yolo_obstacle_detector_node.cpp
- *
- *  Created on: Dec 19, 2016
- *      Author: Marko Bjelonic
- *   Institute: ETH Zurich, Robotic Systems Lab
- */
-
-#include "darknet_ros/YoloObjectDetector.hpp"
-#include "rclcpp/rclcpp.hpp"
-
-int main(int argc, char** argv) {
-  rclcpp::init(argc, argv);
-
-  auto yoloObjectDetector = std::make_shared<darknet_ros::YoloObjectDetector>();
-
-  yoloObjectDetector->init();
-  
-  rclcpp::spin(yoloObjectDetector->get_node_base_interface());
-
-  rclcpp::shutdown();
-
-  return 0;
-}
